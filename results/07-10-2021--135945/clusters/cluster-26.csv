text,title,id,project_number,terms,administration,organization,mechanism,year,cost,funding,score
"Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics Abstract Support is requested for a Keystone Symposia conference entitled Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics, organized by Drs. Jose M. Lora and Timothy K. Lu. The conference will be held in Breckenridge, Colorado from March 29- April 1, 2019. Synthetic Biology tools and principles have matured tremendously over the last decade and have reached extraordinary levels of sophistication, both in eukaryotic and prokaryotic systems. Synthetic biology as a therapeutic modality is starting to enter multiple clinical studies and has the potential to have a significant impact on medicine across a wide range of diseases (e.g., metabolic, immune-mediated, cancer, and neurologic diseases). This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine. While there are conferences that capture synthetic biology in only a few talks mixed in among other various topics, there is a paucity of conferences focused on synthetic biology as drugs to treat disease. However, due to the rapid pace of fundamental scientific advances along with an expanding number of biotechnology companies and emerging clinical studies with synthetic biology at their core, this conference will be highly relevant for a wide audience of scientists both from academia and industry. In addition, other meetings in this field have a highly technology-driven focus on synthetic biology techniques with relatively little attention given to biological and medical context. Ultimately, this Keystone Symposia conference should inspire researchers from diverse backgrounds to discuss synthetic biology via many new angles. PROJECT NARRATIVE Over the past two decades, tremendous advances have been made in the use of biological parts to engineer systems that can effectively direct living cells for a vast variety of purposes (a.k.a. synthetic biology). Synthetic biology is being used to construct more effective therapies in diseases such as cancer, but there are remaining obstacles to the clinical translation of these therapies. This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine.",Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics,9913772,R13EB029305,"['Academia', 'Address', 'Area', 'Attention', 'Biological', 'Biomedical Research', 'Biotechnology', 'Cells', 'Clinical Research', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Colorado', 'Computers', 'Disease', 'Educational workshop', 'Engineering', 'Future', 'Genetic Engineering', 'Genetic Screening', 'Human', 'Immune', 'Industrialization', 'Industry', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medical', 'Medicine', 'Metabolic', 'Methodology', 'Modality', 'Neurologic', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Preventive', 'Process', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Scientific Advances and Accomplishments', 'Scientist', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Work', 'clinical application', 'clinical practice', 'clinical translation', 'combinatorial', 'design', 'effective therapy', 'graduate student', 'meetings', 'nervous system disorder', 'next generation', 'novel diagnostics', 'posters', 'symposium', 'synthetic biology', 'targeted treatment', 'tool']",NIBIB,KEYSTONE SYMPOSIA,R13,2020,10000,559385,-0.006511848911433166
"ADAR-editing landscape dysregulation in neuropsychiatric disorders Project Abstract:  Adenosine deaminase acting on RNA (ADAR) editing plays a major role in shaping transcriptome diversity by creating variant isoforms that enable fine-tuning of calcium-mediated excitatory and other signaling needed for brain development, neural plasticity and mood regulation. The spatio-temporal ADAR editing landscapes are tightly regulated by controlling ADAR expression levels to preserve preferential binding and editing. Previous studies have shown that activation of the interferon pathways of the innate immune system – such as those seen in viral infections - leads to increased expression of ADAR1p150, which ultimately results in changes to ADAR editing patterns. Furthermore, common side effects to innate immune activation by interferon alpha therapies include increased risk of depression and suicide. The changes in spatio-temporal regulation of editing patterns can lead to a wide spectrum of neurological symptoms, including neuropsychiatric disorders (e.g., decreased ADAR editing in the serotonin receptor subunit2C in the prefrontal cortex observed in individuals who commit suicide). Yet, our understanding of ADAR editing landscapes remain cursory. Advances in high throughput RNA-seq enable more accurate variant calling from the sequencing reads, providing a way to map ADAR editing patterns in the transcriptome. However, there are no computational pipelines focused on ADAR editing that are easy to use, are reproducible and can handle large scale analysis. I have recently built a pipeline to handle meta-analysis of RNA-seq data that incorporates variant calling steps, but further work is needed to validate this tool to assure accuracy and reproducibility of results. It can then be used to map the spatio-temporal variation of ADAR editing landscapes. The proposed project will study ADAR editing landscapes in the following ways: (i) new computational pipelines will be benchmarked to use variant calling with RNA-seq datasets using simulated reads, (ii) ADAR editing landscape diversity in the publicly available human samples will be mapped; the computational predictions and hypotheses generated from the pipeline will be validated using (iii) measuring calcium flux in cells with known differential ADAR editing landscapes caused by PolyI:C (viral infection mimic) treatment. The proposed work will yield a validated pipeline capable of mapping ADAR editing landscapes with machine learning algorithms. Defining ADAR editing landscapes is paramount to biomarker discovery and can influence precision medicine applications in diagnosis and treatment of neuropsychiatric disorders. This project will allow for me to gain the knowledge base necessary to become an independent researcher with a unique skill set of both computational and benchwork methods to advance the field of neuroscience. Project Narrative Inferring ADAR editing landscapes and their link with ion homeostasis and excitatory signaling in the brain is important for understanding, diagnosing or staging neurological and neuropsychiatric disorders, including major depressive disorder and suicide. This proposed project will develop and validate computational tools to use RNA-seq from publicly available datasets for ADAR editing inferences and to delineate patterns of editing changes in cells experiencing viral infections. Overall, this project will give me the training to build my unique skill set of both computational and experimental methods that will enable me as an independent researcher to bridge the gap between bioinformatics and experimental researchers and translate my findings into precision medicine.",ADAR-editing landscape dysregulation in neuropsychiatric disorders,9992699,F31MH123131,"['Accounting', 'Anxiety', 'Benchmarking', 'Binding', 'Bioinformatics', 'Brain', 'Calcium', 'Cardiovascular Diseases', 'Cause of Death', 'Cell Culture Techniques', 'Cells', 'Complex', 'Computer Analysis', 'Custom', 'Data', 'Data Set', 'Databases', 'Depression and Suicide', 'Development', 'Diagnosis', 'Economic Burden', 'Etiology', 'Frequencies', 'Fura-2', 'Genes', 'Genetic Transcription', 'Genotype-Tissue Expression Project', 'Glutamate Receptor', 'High-Throughput RNA Sequencing', 'Homeostasis', 'Human', 'Image', 'Immune response', 'Immune system', 'Immunohistochemistry', 'Individual', 'Innate Immune System', 'Interferon Activation', 'Interferon-alpha', 'Ions', 'Lead', 'Link', 'Major Depressive Disorder', 'Maps', 'Measures', 'Mediating', 'Meta-Analysis', 'Methods', 'Molecular', 'Nervous system structure', 'Neurologic Symptoms', 'Neuronal Plasticity', 'Neurosciences', 'PF4 Gene', 'Pathway interactions', 'Pattern', 'Permeability', 'Play', 'Population', 'Prefrontal Cortex', 'Protein Isoforms', 'Proteins', 'RNA', 'RNA Editing', 'Regulation', 'Reproducibility', 'Reproducibility of Results', 'Research Personnel', 'Risk', 'Role', 'Sampling', 'Shapes', 'Signal Transduction', 'Site', 'Staging', 'Suicide', 'Testing', 'Training', 'Translating', 'United States', 'Validation', 'Variant', 'Viral', 'Virus Diseases', 'Western Blotting', 'Work', 'accomplished suicide', 'adenosine deaminase', 'biomarker discovery', 'computational pipelines', 'computerized tools', 'data visualization', 'detector', 'differential expression', 'disability-adjusted life years', 'dopaminergic differentiation', 'excitotoxicity', 'experience', 'immune activation', 'in silico', 'innate immune pathways', 'insight', 'knowledge base', 'machine learning algorithm', 'mood regulation', 'nerve stem cell', 'nervous system disorder', 'neuropsychiatric disorder', 'neurotransmission', 'novel marker', 'precision medicine', 'preservation', 'relating to nervous system', 'release of sequestered calcium ion into cytoplasm', 'serotonin receptor', 'side effect', 'skills', 'social', 'spatiotemporal', 'suicidal risk', 'tool', 'transcriptome', 'transcriptome sequencing', 'virtual machine']",NIMH,KENT STATE UNIVERSITY,F31,2020,29830,5062280,-0.08184354456405145
"Genetic Dissection of Cortical Parvalbumin Interneuron Subtypes Abstract The inhibitory control and dynamic tuning of cortical circuits is mediated by a diversity of GABAergic cell types, but the biological basis of interneuron identity and diversity is not well understood. Here, we combine developmental genetic, anatomic and transcriptomic approaches to define and discover bona fide cell types within a broad class of cortical interneurons. Parvalbumin containing, fast-spiking basket cells (PVCs) are the largest population of interneurons in the neocortex and integrate in infragranular, granular (layer IV), and supragranular circuits, each with unique input/output connectivity. Recent findings from our laboratory and others suggest heterogeneity in PVC morphology, synaptic properties, and connectivity, but it is uncertain how many of these represent distinct subtypes. Using a developmental genetic strategy, we take advantage of the inside-out laminar specification of PVCs to identify and characterize subtypes based on lineage and birth time restricted cohorts. PVCs are derived from the medial ganglionic eminence (MGE), and the transition from progenitor to differentiated neuron is marked by the upregulation of proneural transcription factors. By intersecting inducible Ascl1-CreER and Dlx1-CreER mice with PV-Flp mice and an intersectional reporter and inducing in mid-to-late embryogenesis, we have begun parsing adult laminar PVC subtypes for multifactorial single-cell analysis. We quantify the laminar position and morphology of lineage restricted and birth-dated PVC cohorts. We will also carry out single cell RNAseq to analyze their transcription profiles. The integration of morphological and anatomical characterization with single cell RNAseq will increase our understanding of cell identity in PVCs and can potentially uncover new underlying cellular properties. Because PVCs are implicated in schizophrenia, autism, and other mental disorders, their complete profiling at the single cell level could aid in understanding pathophysiology and suggest better treatment strategies. Project Narrative Public Health Relevance: About 1 in 5 Americans are afflicted with mental health disorders such as schizophrenia, Alzheimer’s disease, and autism, placing a considerable burden on individuals and health care institutions across the country. Parvalbumin interneurons are the most prevalent inhibitory cells in the neocortex and their dysfunction implicated across many disorders, though their precise circuit integration is not well understood. This research proposal will lay the foundation for a single-cell understanding of the individual cell types that underlie this powerful “brake” mechanism and identify specific molecular targets that can hopefully lead to better therapeutic strategies.",Genetic Dissection of Cortical Parvalbumin Interneuron Subtypes,9853835,F31MH114529,"['Adult', 'Alzheimer&apos', 's Disease', 'American', 'Anatomy', 'Bar Codes', 'Bioinformatics', 'Biological', 'Birth', 'Catalogs', 'Cells', 'Classification Scheme', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Country', 'Data Set', 'Databases', 'Date of birth', 'Development', 'Disease', 'Dissection', 'Embryo', 'Embryonic Development', 'Epilepsy', 'Exhibits', 'Expression Profiling', 'Fluorescent in Situ Hybridization', 'Foundations', 'Functional disorder', 'Ganglia', 'Gene Expression', 'Genetic', 'Genetic Screening', 'Genetic Transcription', 'Healthcare', 'Heterogeneity', 'Individual', 'Institution', 'Interneurons', 'Label', 'Laboratories', 'Lead', 'Maps', 'Medial', 'Mediating', 'Mental disorders', 'Messenger RNA', 'Methods', 'Molecular', 'Molecular Profiling', 'Molecular Target', 'Morphology', 'Mus', 'Myoepithelial cell', 'Neocortex', 'Neuroglia', 'Neurons', 'Nucleotides', 'Output', 'Parvalbumins', 'Pattern', 'Phenotype', 'Physiological', 'Population', 'Positioning Attribute', 'Pregnancy', 'Property', 'Proteins', 'Radial', 'Regulation', 'Reporter', 'Research Proposals', 'Resolution', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Statistical Methods', 'Stratum Granulosum', 'Synapses', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Up-Regulation', 'autism spectrum disorder', 'base', 'cell type', 'cohort', 'design', 'developmental genetics', 'differential expression', 'gamma-Aminobutyric Acid', 'genetic approach', 'molecular marker', 'new therapeutic target', 'novel', 'progenitor', 'public health relevance', 'screening', 'single cell analysis', 'single-cell RNA sequencing', 'supervised learning', 'tool', 'transcription factor', 'transcriptome', 'transcriptomics', 'treatment strategy']",NIMH,STATE UNIVERSITY NEW YORK STONY BROOK,F31,2020,35430,77607041,-0.013698674279919928
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,10228145,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'comorbidity', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2020,59206,607172798,-0.011420145153188595
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,9979523,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2020,77243,2966077,0.012427371457186299
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,9952803,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2020,92359,570146095,-0.012106488828437977
"Investigating how mechanical connectivity yields developmental robustness ABSTRACT  It is essential for the fate of an organism that key morphogenetic processes occur reproducibly even under tissue damage or environmental perturbations. While much is known about how genetic redundancy and regulation achieves robust development, less is understood about how a tissue mechanically ensures reproducible shape change when perturbed. This project uncovers how populations of physically interacting cells mechanically respond to challenging conditions and modify their collective behavior to still sculpt the correct final shape.  One way for cells to coordinate tissue-scale forces and movements is through direct mechanical connections. In fact, many developing tissues exhibit supracellular networks of actomyosin connections that link hundreds of cells. A large roadblock has been with the challenges of imaging and quantifying subcellular protein at the tissue scale. I adapted a topological smoothing algorithm originally used to trace high-noise filamentous structure of galaxies in the Universe to data to trace high-noise filamentous myosin structure in confocal images. This allowed for the first quantification of a supracellular myosin network across an entire tissue over developmental time. Subsequent analysis adopting techniques from network theory allowed me to identify that the robust folding of the Drosophila fruit fly embryo during ventral furrow formation is mechanically ensured by patterns in the supracellular network spanning its ventral cells.  This newly discovered importance of supracellular networks in coordinating robust shape change highlights the need for a comprehensive understanding of how supracellular networks form, and how their patterns impact the function and robustness of a population of cells. Deciphering robustness at the tissue-level, where the displacement and fate of hundreds of cells must be considered, requires techniques at the interface of cell and developmental biology, biophysics and computer science. The proposed project will take a highly interdisciplinary approach to identify how supracellular network patterns are controlled molecularly, at the cell level, and via tissue constraints. As well, how heterogeneity in tissue-level patterns impacts morphogenetic robustness will be addressed. Together this comprehensive study of the structure and function of supracellular networks will represent a new way to interpret mechanical robustness across diverse developing tissues. As well, a generalized description of mechanical robustness has the potential to uncover new paths to predict and control tissue malformation, which would represent a significant advance for both developmental biology and fetal medicine. PROJECT NARRATIVE The robust establishment of correct shape is essential for proper tissue function. Tissue shape change is a mechanical process that necessitates the coordinated force generation and motion of thousands of cells. Identifying how physically interacting cells mechanically respond to challenging conditions and modify their behavior to still sculpt the correct final shape will shed light onto many congenital disorders that result from morphogenetic dysregulation.",Investigating how mechanical connectivity yields developmental robustness,9950519,K99GM136915,"['Actomyosin', 'Address', 'Adopted', 'Affect', 'Algorithms', 'Architecture', 'Behavior', 'Biophysics', 'Cell Culture Techniques', 'Cell Size', 'Cells', 'Cellular biology', 'Congenital Abnormality', 'Congenital Disorders', 'Data', 'Development', 'Developmental Biology', 'Disease', 'Drosophila genus', 'Early Diagnosis', 'Embryo', 'Engineering', 'Ensure', 'Exhibits', 'Galaxy', 'Generations', 'Genetic', 'Heterogeneity', 'Image', 'In Vitro', 'Light', 'Link', 'Location', 'Machine Learning', 'Maternal-fetal medicine', 'Mechanics', 'Molecular', 'Morphogenesis', 'Morphology', 'Motion', 'Movement', 'Myosin ATPase', 'Neural Tube Defects', 'Noise', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Process', 'Property', 'Proteins', 'Regulation', 'Reproducibility', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Transportation', 'Work', 'cohesion', 'computer science', 'confocal imaging', 'congenital heart disorder', 'fetal', 'fetal medicine', 'fly', 'in vivo', 'interdisciplinary approach', 'malformation', 'mechanical force', 'mechanical properties', 'novel', 'optogenetics', 'theories', 'tissue-level behavior', 'transmission process']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,K99,2020,98836,113554200,-0.007023419722209185
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10115288,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'Visualization', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'machine learning method', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2020,99860,5161939,-0.008540638079986274
"A computer vision toolbox for computational analysis of nonverbal social communication PROJECT SUMMARY We will develop novel computer vision tools to reliably and precisely measure nonverbal social communication through quantifying communicative facial and bodily expressions. Our tools will be designed and developed in order to maximize their usability by non-engineer behavioral scientists, filling the enormous gap between engineering advances and their clinical accessibility. Significance: Social interaction inherently relies on perception and production of coordinated face and body expressions. Indeed, atypical face and body movements are observed in many disorders, impacting social interaction and communication. Traditional systems for quantifying nonverbal communication (e.g., FACS, BAP) require extensive training and coding time. Their tedious coding requirements drastically limits their scalability and reproducibility. While an extensive literature exists on advanced computer vision and machine learning techniques for face and body analysis, there is no well-established method commonly used in mental health community to quantify production of facial and bodily expressions or efficiently capture individual differences in nonverbal communication in general. As a part of this proposal, we will develop a computer vision toolbox including tools that are both highly granular and highly scalable, to allow for measurement of complex social behavior in large and heterogeneous populations. Approach: Our team will develop tools that provide granular metrics of nonverbal social behavior, including localized face and body kinematics, characteristics of elicited expressions, and imitation performance. Our tools will facilitate measurement of social communication both within a person and between people, to allow for assessment of individual social communication cues as well as those that occur within bidirectional social contexts. Preliminary Data: We have developed and applied novel computer vision tools to assess: (1) diversity of mouth motion during conversational speech (effect size d=1.0 in differentiating young adults with and without autism during a brief natural conversation), (2) interpersonal facial coordination (91% accuracy in classifying autism diagnosis in young adults during a brief natural conversation, replicated in an independent child sample), and (3) body action imitation (85% accuracy in classifying autism diagnosis based on body imitation performance). As apart of current proposal, we will develop more generic methods that can be used in normative and clinical samples. Aims. In Aim 1, we will develop tools to automatically quantify fine-grained face movements and their coordination during facial expression production; in Aim 2, we will develop tools to quantify body joint kinematics and their coordination during bodily expression production; in Aim 3, we will demonstrate the tools’ ability to yield dimensional metrics using machine learning. Impact: Our approach is designed for fast and rigorous assessment of nonverbal social communication, providing a scalable solution to measure individual variability, within a dimensional and transdiagnostic framework. PROJECT NARRATIVE This project develops novel tools for measuring nonverbal social communication as manifested through facial and bodily expressions. Using advanced computer vision and machine learning methodologies, we will quantify humans’ communicative social behavior. The results of this project will impact public health by facilitating a rich characterization of normative development of social functioning, providing access to precise phenotypic information for neuroscience and genetics studies, and by measuring subtle individual differences to determine whether some interventions or treatments work better than others.",A computer vision toolbox for computational analysis of nonverbal social communication,9946780,R01MH122599,"['Adolescent', 'Age', 'Area', 'Behavior', 'Behavioral', 'Behavioral Research', 'Behavioral Sciences', 'Characteristics', 'Child', 'Clinical', 'Code', 'Communication', 'Community Health', 'Complex', 'Computational Technique', 'Computer Analysis', 'Computer Vision Systems', 'Cues', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Educational Materials', 'Engineering', 'Expression Profiling', 'Face', 'Facial Expression', 'Genetic study', 'Goals', 'Gold', 'Grain', 'Grant', 'Human', 'Individual', 'Individual Differences', 'Intervention', 'Joints', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Motion', 'Movement', 'Nature', 'Neurologic', 'Neurosciences', 'Nonverbal Communication', 'Oral cavity', 'Participant', 'Perception', 'Performance', 'Persons', 'Phenotype', 'Population Heterogeneity', 'Production', 'Public Health', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Sampling', 'Science', 'Scientist', 'Sex Differences', 'Social Behavior', 'Social Development', 'Social Environment', 'Social Functioning', 'Social Interaction', 'Speech', 'System', 'Techniques', 'Teenagers', 'Time', 'Training', 'Translations', 'Validation', 'Work', 'analysis pipeline', 'autism spectrum disorder', 'automated algorithm', 'base', 'behavior measurement', 'behavioral health', 'clinical application', 'computerized tools', 'design', 'individual variation', 'interest', 'kinematics', 'novel', 'open source', 'sex', 'social', 'social communication', 'tool', 'usability', 'young adult']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2020,150000,178185562,-0.024526777504132364
"Bioethics of syndrome diagnosis using 3D image analysis Project Summary/Abstract This supplement will address the unintended consequences and collateral damage that arise when facial recognition software is used for medical purposes, such as for syndrome diagnosis as in our Facebase-funded project. In Aim 1, we will determine whether the accuracy of this technology varies based on self-reported race, sex and age. In this aim, we examine our existing database for evidence of bias based on self-reported race, sex or age. We further determine the extent to which these variables influence classification performance. To the extent sample sizes allow, we will carry this analysis to the level of specific syndromes. Finally, we will use anonymized reference datasets of non-syndromic faces to compare false positive rates based on NIH race definitions, sex and age. The outcome of this aim is to objectively establish bias and estimate the effects of under-representation across race, age and sex categories within our data. In Aim 2, we will determine how the reports of race-, sex- and age-based bias in facial recognition technology may influence views of the technology and its application amongst researchers and clinicians. This aim will establish the extent to which the storing of large databases of facial images and the application of machine learning processes to them for diagnostic purposes may raise privacy concerns. The concerns investigated will include potential hacks into protected health information; fear relating to the bias in some facial recognition software (and, potentially, in the Facebase database); and fear of discrimination in the application of the technology, such as by insurers. The outcome will be a white paper that targets a high-profile journal, summarizing the findings and defining crucial issues that should guide the development of facial imaging for disease diagnosis and clinical usage. Project Narrative Our supplement application will address the important question of unintended consequences and collateral damage when facial recognition software is used for medical purposes, such as for syndrome diagnosis as in our Facebase-funded project. The use of large facial recognition databases in medicine represents a frontier that arrives with tremendous potential but undeniable risks. Our central aims are: (1) determine whether the accuracy of this technology varies based on self-reported race, sex and age; and (2) determine how the reports of race-, sex- and age-based bias in facial recognition technology may influence views of the technology and its application amongst researchers and clinicians.",Bioethics of syndrome diagnosis using 3D image analysis,10132648,U01DE028729,"['3-Dimensional', 'Address', 'Age', 'Authoritarianism', 'Bioethical Issues', 'Bioethics', 'Biometry', 'Categories', 'Classification', 'Clinic', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Computational Biology', 'Country', 'Data', 'Data Science', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Ethics', 'Face', 'FaceBase', 'Fright', 'Funding', 'General Hospitals', 'Generations', 'Genes', 'Genetic Diseases', 'Health', 'Hereditary Disease', 'Image', 'Image Analysis', 'Insurance Carriers', 'Journals', 'Libraries', 'Machine Learning', 'Medical', 'Medicine', 'Outcome', 'Paper', 'Pathology', 'Patient Self-Report', 'Patient imaging', 'Performance', 'Privacy', 'Private Sector', 'Process', 'Psychiatry', 'Public Sector', 'Race', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sample Size', 'San Francisco', 'Secure', 'Syndrome', 'Technology', 'Three-Dimensional Image', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'craniofacial', 'disease diagnosis', 'facial recognition software', 'frontier', 'human data', 'intervention cost', 'new technology', 'professor', 'repository', 'sex', 'tool']",NIDCR,UNIVERSITY OF SOUTHERN CALIFORNIA,U01,2020,152200,324592664,-0.006254022157052689
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,10258317,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data warehouse', 'database design', 'deep learning', 'heuristics', 'improved', 'in silico', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'personalized diagnostics', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2020,157500,254622553,-0.006979546066623485
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9969443,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data standards', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'large datasets', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'public repository', 'repository', 'research and development', 'software development', 'software infrastructure', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2020,158388,758431960,0.013329724983238688
"Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions Project Summary/Abstract DNA sequencing has spawned the “microbiome revolution” -- thousands of microbes and a dizzying number of microbial interactions that are associated with human health and disease. Unfortunately, most species in the microbiome are known only by a (partial) genome. The limited phenotypic data on newly discovered bacteria reveal species that behave unlike any of our model organisms. While genome-scale modeling plays an important role in understanding the microbiome, the paucity of phenotypic data for most species prevents detailed simulation of the microbial communities that affect our health. This project will develop an automated system for profiling, synthesizing, and modeling microbial communities. The center of our approach is Deep Phenotyping, an automated robotic platform that performs complex growth experiments on demand. Data from Deep Phenotyping will be used to train metabolic and statistical models of the oral pathogens Streptococcus mutans and Candida albicans to predict conditions that keep both microbes in a nonpathogenic state. Project Narrative The microbiome revolution has uncovered thousands of species of bacteria with roles in health and disease. This project automates the identification of interactions between environments, genes, and the microbes that live in and around us. Understanding these interactions is a critical step in re-engineering the microbiome to improve human health.","Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions",9852330,R21EB027396,"['Affect', 'Animal Model', 'Antibiotics', 'Area', 'Bacteria', 'Biochemical Pathway', 'Bioinformatics', 'Biological', 'Biological Assay', 'Candida albicans', 'Carbon', 'Coculture Techniques', 'Collaborations', 'Combinatorics', 'Communities', 'Complex', 'Computer software', 'DNA sequencing', 'Data', 'Development', 'Disease', 'Engineering', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Future', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Human Microbiome', 'Hybrids', 'Image', 'Individual', 'Knock-out', 'Knowledge', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Metabolic', 'Methods', 'Microbe', 'Microbiology', 'Modeling', 'Oral', 'Oral candidiasis', 'Pathway interactions', 'Phenotype', 'Play', 'Positioning Attribute', 'Regulator Genes', 'Research Personnel', 'Robotics', 'Role', 'Shapes', 'Source', 'Statistical Models', 'Streptococcus mutans', 'Structure', 'System', 'Technology', 'Time', 'Training', 'Work', 'base', 'combinatorial', 'cost', 'design', 'dysbiosis', 'experience', 'experimental study', 'fitness', 'fungus', 'genome-wide', 'improved', 'instrumentation', 'large datasets', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microorganism interaction', 'network models', 'open source', 'oral pathogen', 'pathogenic fungus', 'phenotypic data', 'preference', 'prevent', 'screening', 'simulation', 'transcription factor', 'transcriptome sequencing', 'transposon sequencing']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,178949,76545728,-0.019801634092548998
"Mobile based Nanoplasmonic Quantification of Mtb-derived Exosomes in Serum for Pediatric TB diagnosis Project Summary/Abstract  There were an estimated 10.4 million tuberculosis (TB) cases, and 170,000 TB pediatric deaths in 2015, with >95% of TB deaths occur in low- and middle-income countries (LMIC). Rapid diagnosis is essential for improved TB outcomes, but diagnosis is more difficult in children, since children are less likely to exhibit typical TB symptoms and have paucibacillary (few bacteria) TB cases that are more difficult to detect by current methods, while parents are often resistant to stressful TB sample collection procedures. We therefore propose to explore a novel rapid, accurate, low-cost and easy-to-use mobile phone-based blood test for pediatric TB diagnosis in LMIC settings. Our novel detection method rapidly quantifies circulating extracellular vesicles (EVs) derived from host cells infected with the TB pathogen Mycobacterium tuberculosis (Mtb). Our preliminary data indicate that we can rapidly quantitate EVs carrying Mtb biomarkers, such as lipoarabinomannan and LpqH, in pediatric TB patient blood samples using a mobile-phone-based dark-field microscope (MDFM) platform. These findings support our long-term goal to develop a low-cost system to improve pediatric TB diagnosis in LMIC settings. We also anticipate that this system will allow rapid treatment monitoring to improve therapy and reduce exposure of pediatric patients to toxic anti-TB drugs. To achieve these outcomes we propose to pursue three goals.  We collected our preliminary data with a MDFM that imaged transmitted light, but plan to design, develop, and validate the Aim 1 compact MDFM with a reflected light path to decrease the size of the device, simplify imagery, and increase the physical stability of the system. We will also develop a user-friendly application for image capture and data analysis on this platform. These features should markedly increase its feasibility for use in LMIC settings. Aim 2 will optimize assay performance for LMIC settings by redesigning assay materials for long-term storage under ambient conditions, and by determining optimal incubation times for different LMIC ambient temperature ranges. Aim 3 will analyze candidate Mtb-EV markers, including lipoarabinomannan and LpqH, build and a diagnostic model based on a multiple logistic regression algorithm, and validate diagnostic thresholds in separate validation cohort of pediatric TB patients and healthy controls with traceable clinical information. It will also compare the diagnostic performance of this multi-marker Mtb-EV assay to traditional diagnostic methods to evaluate its relative diagnostic performance.  Our approach offers several innovative features valuable for pediatric TB control. It quantifies stable TB biomarkers on EVs in serum (1µL), rather than detecting Mtb in difficult to obtain, variable, non-quantitative and infectious biopsies. It employs a novel, compact MDFM and a nanoparticle-based end-point assay that is stable at ambient conditions. Finally, the ability of this approach to quantitate Mtb-EVs should allow rapid evaluation of disease severity for real-time monitoring of treatment efficacy and cures to minimize toxic drug exposure times. Project Narrative There is an urgent need for novel approaches for rapid diagnosis of pediatric tuberculosis cases to improve patient outcomes in low- and middle-income countries, which may lack resources and trained personnel. This proposal will develop a mobile phone-based device and a rapid tuberculosis assay that detects circulating extracellular vesicles secreted by infected cells in blood, both of which will be inexpensive and user-friendly to allow easy use by individuals with minimal training in resource-limited areas. This low-risk, high-reward approach is fundamentally different from traditional diagnostic methods, and it offers several advantages for diagnosis of pediatric tuberculosis cases, including the use of serum rather than sputum or other biopsies that can be difficult to obtain in young children.",Mobile based Nanoplasmonic Quantification of Mtb-derived Exosomes in Serum for Pediatric TB diagnosis,10019544,R21EB026347,"['Algorithms', 'Area', 'Bacillus', 'Bacteria', 'Biological Assay', 'Biological Markers', 'Biopsy', 'Blood', 'Blood Circulation', 'Blood Tests', 'Blood specimen', 'Car Phone', 'Caregivers', 'Cells', 'Cessation of life', 'Child', 'Childhood', 'Clinical', 'Dark-Field Microscope', 'Data', 'Data Analyses', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic Sensitivity', 'Disease', 'Drug Exposure', 'End Point Assay', 'Evaluation', 'Exhibits', 'Goals', 'Health Personnel', 'Healthcare', 'High Prevalence', 'Housing', 'Human Resources', 'Image', 'Imagery', 'Individual', 'Infrastructure', 'Label', 'Light', 'Logistic Regressions', 'Measures', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Mycobacterium tuberculosis', 'Mycobacterium tuberculosis antigens', 'Nature', 'Outcome', 'Parents', 'Patient-Focused Outcomes', 'Patients', 'Pediatric cohort', 'Performance', 'Procedures', 'Reading', 'Resistance', 'Resources', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Serum', 'Severities', 'Severity of illness', 'Slide', 'Sputum', 'Stress', 'Symptoms', 'System', 'Telephone', 'Temperature', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Tuberculosis', 'Validation', 'antibody conjugate', 'base', 'clinical translation', 'communicable disease diagnosis', 'cost', 'cost effective', 'design', 'diagnostic accuracy', 'diagnostic assay', 'disease diagnosis', 'disorder control', 'exosome', 'extracellular vesicles', 'high reward', 'improved', 'innovation', 'interest', 'lens', 'lipoarabinomannan', 'low and middle-income countries', 'microscopic imaging', 'nanoparticle', 'nanoplasmonic', 'novel', 'novel strategies', 'pathogen', 'pediatric patients', 'portability', 'prototype', 'rapid diagnosis', 'rapid technique', 'real time monitoring', 'regression algorithm', 'sample collection', 'screening', 'transmission process', 'treatment response', 'tuberculosis diagnostics', 'tuberculosis drugs', 'user-friendly']",NIBIB,TULANE UNIVERSITY OF LOUISIANA,R21,2020,179885,92601146,0.01219297167180661
"Turning a sequence barcode into a spectral barcode for single-cell analysis. Project Summary: The use of sequence barcodes has enabled high-throughput transcriptomic analysis of single cells. But one challenge remains – there is no method to map the physical assessments of single cells and the downstream transcriptomic data of single cells to the same cells of origin. This is because currently sequence barcodes are only read by sequencing which takes place after all single cells are lysed, reverse transcription is completed, and cDNA are amplified and pooled. In order to perform transcriptomic analysis and physical assessments on the same single cells, we will need a method that allows us to decipher the sequence barcodes while in the process of single-cell physical interrogation. Our goal in this proposed research is to develop a new method to turn sequence barcodes into spectral barcodes that can be read locally in the process. The proposed sequence- barcode-reading technique, if it can be realized, will have substantial impact to the single-cell community as it will become the only method to map the physical assessments and the downstream molecular analysis data to the same cells of origin in a high-throughput, streamlined format. Project Narrative: High-throughput single-cell analysis has advanced our knowledge in developmental biology and disease origins. But currently there is no method to map the physical and transcriptional analysis data of single cells to the same cells of origin. Here we propose to develop a method to overcome this limitation and enable both physical and molecular interrogation performed on the same single cells.",Turning a sequence barcode into a spectral barcode for single-cell analysis.,9898410,R21GM129617,"['Address', 'Architecture', 'Bar Codes', 'Bioinformatics', 'Biology', 'Bypass', 'Cell Nucleus', 'Cells', 'Code', 'Color', 'Complementary DNA', 'Cytoplasm', 'DNA', 'DNA Probes', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Development', 'Developmental Biology', 'Encapsulated', 'Fluorescence', 'Fluorescent Probes', 'Genetic Transcription', 'Genomics', 'Goals', 'Hybrids', 'Hydrogels', 'Image', 'Individual', 'Knowledge', 'Libraries', 'Light', 'Machine Learning', 'Maps', 'Mechanics', 'Metals', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Mining', 'Molecular', 'Molecular Analysis', 'Motivation', 'Nature', 'Nuclear', 'Nucleic Acids', 'Nucleotides', 'Phenotype', 'Physical assessment', 'Process', 'Reading', 'Reporter', 'Research', 'Reverse Transcription', 'Series', 'Silver', 'Specificity', 'Stretching', 'Techniques', 'Technology', 'Testing', 'base', 'cell community', 'cost', 'design', 'developmental disease', 'droplet sequencing', 'experimental study', 'fluorescence imaging', 'interest', 'multiplex detection', 'nanocluster', 'nanoparticle', 'next generation', 'nucleobase', 'screening', 'single cell analysis', 'technology development', 'tool', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R21,2020,181900,91740242,-0.0010246369455960392
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10056062,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data warehouse', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,188198,570146095,-0.017319379667736057
"Mentoring in Immunometabolic Dysregulation in TB and TB/HIV Tuberculosis (TB) is the leading cause of death among people living with HIV (PLWH) worldwide. Despite recent scientific advances, significant gaps remain in our understanding of the immune mechanisms responsible for control and eradication of Mycobacterium tuberculosis (Mtb) infection. PLWH with latent TB infection (LTBI) have a ~10% annual risk of progressing to TB disease, however currently available tests for LTBI diagnosis have reduced sensitivity in this population and are not able to predict which latently infected individuals are at highest risk for developing TB for targeted preventive therapy. Emerging data from clinically relevant animal models suggest that LTBI and active TB represent a spectrum of immune responses and host pathology, with increasing metabolic changes and immune dysregulation during the transition to TB disease. We have identified unique serum metabolite and microRNA (miRNA) profiles that are able to discriminate between patients with TB and those with non-TB lung disease. However, these novel TB signatures have not been assessed prospectively to identify PLWH and HIV-negative persons with LTBI who are at increased risk for TB progression. In order to address this significant knowledge gap, in Aim 1 of the current research program, trainees will leverage the Indian and South African RePORT longitudinal biorepositories of household contacts of TB index cases to test the hypothesis that TB is a chronic inflammatory disease associated with profound changes in immune regulation and metabolism prior to the onset of clinical signs and symptoms. Another major barrier to global TB eradication efforts is the lengthy and complicated current anti-tubercular regimen, which is associated with medical nonadherence and the emergence of drug resistance. Recently, attention has focused on host-directed adjunctive therapies aimed at optimizing immune responses to the pathogen and improving lung damage. Lipid-laden macrophages (foam cells) are central to maintaining chronic TB infection by providing a favorable niche in which antimicrobial functions are down-regulated, and by inducing caseation and tissue damage. Recent work has shown that foam-cell-rich and necrotic areas of TB granulomas are particularly enriched in triglycerides. Mtb infection is associated with dysregulation of two cellular pathways involved in triglyceride homeostasis: a pro-lipogenic pathway involving protein kinase B and mTOR complex 1 (Akt/mTORC1), and an anti- lipogenic pathway involving AMP-activated protein kinase and the sirtuins (AMPK/SIRT). In Aim 2, trainees will use longitudinal clinical samples from RePORT study participants and experimental infections ex vivo to characterize: (i) the relationship between activation of these pathways and control of clinical Mtb infection, and the effect of anti-lipogenic treatments on antimycobacterial functions of human macrophages infected ex vivo. The research aims will be integrated with a mentoring strategy for mentees that fosters development of high impact patient-oriented research with a pathway to independence. Tuberculosis (TB) remains among the most deadly infections worldwide, especially among people living with HIV. Current available tests are not able to accurately detect persons at the highest risk of developing TB, and curing the disease requires at least 6 months of therapy because the TB bacteria can avoid being killed by the immune system and currently available drugs. In the current proposal, physician scientists will receive training in a variety of complementary disciplines, and use several cutting-edge experimental and modeling techniques to analyze samples from patients with TB and TB/HIV, with the ultimate goal of identifying new biomarkers that can predict TB disease and host-directed therapies that can shorten TB treatment.",Mentoring in Immunometabolic Dysregulation in TB and TB/HIV,9975724,K24AI143447,"['5&apos', '-AMP-activated protein kinase', 'Address', 'Animal Model', 'Antibiotics', 'Antimycobacterial Agents', 'Archives', 'Area', 'Attention', 'Automobile Driving', 'Bacteria', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Cause of Death', 'Chronic', 'Clinical', 'Clinical Data', 'Complex', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Drug resistance', 'Environment', 'Experimental Models', 'FRAP1 gene', 'Foam Cells', 'Fostering', 'Goals', 'HIV', 'HIV Seronegativity', 'HIV Seropositivity', 'HIV/TB', 'Homeostasis', 'Household', 'Human', 'Immune', 'Immune response', 'Immune system', 'Immunocompetent', 'Individual', 'Infection', 'International', 'Knowledge', 'Lesion', 'Lipid-Laden Macrophage', 'Lipids', 'Lung diseases', 'Machine Learning', 'Medical', 'Mentors', 'Metabolic', 'Metabolism', 'MicroRNAs', 'Mycobacterium tuberculosis', 'Necrosis', 'Outcome', 'Participant', 'Pathology', 'Pathway interactions', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Population', 'Prevention', 'Preventive therapy', 'Proto-Oncogene Proteins c-akt', 'Pulmonary Tuberculosis', 'Regimen', 'Reporting', 'Research', 'Resources', 'Risk', 'Sampling', 'Scientific Advances and Accomplishments', 'Scientist', 'Serum', 'Signs and Symptoms', 'Sirtuins', 'South African', 'Specimen', 'Systems Biology', 'Techniques', 'Testing', 'Tissues', 'Training', 'Triglycerides', 'Tuberculosis', 'Validation', 'Whole Blood', 'Work', 'World Health Organization', 'antimicrobial', 'biobank', 'biosignature', 'career', 'chronic inflammatory disease', 'clinically relevant', 'cohort', 'cytokine', 'high risk', 'immunoregulation', 'improved', 'indexing', 'lifetime risk', 'lung injury', 'macrophage', 'monocyte', 'mycobacterial', 'novel', 'pathogen', 'patient oriented research', 'peripheral blood', 'prevent', 'programs', 'prospective', 'tool', 'transcriptome', 'transcriptome sequencing', 'tuberculosis granuloma', 'tuberculosis treatment']",NIAID,JOHNS HOPKINS UNIVERSITY,K24,2020,191195,807432003,-0.03152743206249209
"Host Proteomic Biosignatures for a Urine-based Diagnosis of Pulmonary Tuberculosis in Children PROJECT ABSTRACT Tuberculosis (TB) is a leading cause of mortality in children worldwide. Difficulty in obtaining sputum and a low sputum bacillary load are major barriers to diagnosis, and necessitate the development of a non-sputum, biomarker-based assay for childhood intrathoracic TB disease. Host biomarker discovery for childhood TB requires a greater focus on downstream proteins and their post-translational modifications (PTMs) that are more likely to be specific to a disease phenotype and can be more easily translated into a point-of-care test. With the support of this K23 award, Dr. Devan Jaganath will identify a host proteomic biosignature in urine that can achieve the goal accuracy for a triage and/or diagnostic test for pulmonary TB in children. To complete this objective, he will leverage an ongoing prospective cohort of symptomatic children being evaluated for intrathoracic TB in Kampala, Uganda, with the extensive proteomic facilities available at the University of California, San Francisco (UCSF). In Aim 1, he will perform targeted mass spectrometry on urine samples from children with confirmed vs. unlikely TB, and examine the abundance and ubiquitylation of 10 host proteins that have prior evidence of specific interactions with M. tuberculosis (Mtb) proteins as candidate biomarkers. In Aim 2, he will use shotgun mass spectrometry on the urine samples to identify all host proteins and their PTMs that can differentiate TB status as novel biomarkers, and perform pathway analysis to determine the subset with functional relevance to Mtb pathogenesis. In Aim 3, he will apply machine learning analyses to identify the smallest combination of biomarkers that can achieve the target accuracy thresholds for a triage and/or diagnostic test for intrathoracic TB disease. He will then evaluate the performance of promising biosignatures in an independent, prospectively enrolled test set. Through this approach, Dr. Jaganath seeks to optimize biomarker discovery for childhood TB diagnosis by coupling prospective clinical cohorts with a targeted and untargeted high-throughput approach to comprehensively examine non-sputum samples for host biomarkers for children. Dr. Jaganath's career goal is to be a physician scientist who translates non-sputum biomarkers into clinical tools that can improve the care of children with TB. To support his path to independence, the proposed work will be paired with a dedicated, multidisciplinary mentorship team and training in international pediatric TB biomarker studies, bioinformatics for proteomic analysis, and machine learning. UCSF is an outstanding environment that is committed to junior investigators with extensive resources for research and career development, and Mulago National Referral Hospital in Uganda is a leader in pediatric TB research, and has the established infrastructure for ongoing enrollment and sample collection. The findings will support an NIH R01 application to validate the biomarkers and biosignatures in large, diverse cohorts in comparison to existing non-sputum diagnostics. Thus, the K23 award will provide Dr. Jaganath with the critical mentorship, training, resources and experience to become an independent investigator who can make important contributions to the field of childhood TB. PROJECT NARRATIVE More than half of the estimated tuberculosis (TB) disease cases in children worldwide have not been reported to the health system, and 96% of pediatric TB deaths are in children not started on treatment. The proposed project seeks to address the key barriers in diagnosing pulmonary TB in children through discovery of a host proteomic biosignature in urine. The findings will be relevant to the public health efforts to reduce the burden of TB in children and will support the development of a non-invasive, non-sputum based assay for childhood TB disease at the point-of-care.",Host Proteomic Biosignatures for a Urine-based Diagnosis of Pulmonary Tuberculosis in Children,10038668,K23HL153581,"['Address', 'Adult', 'Age', 'Bedside Testings', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Blood', 'California', 'Cessation of life', 'Child', 'Child Care', 'Childhood', 'Clinical', 'Consensus', 'Coupling', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Sensitivity', 'Diagnostic tests', 'Disease', 'Enrollment', 'Environment', 'Evaluation', 'Funding', 'Gene Expression', 'Gene Expression Profile', 'Goals', 'Health system', 'Hospital Referrals', 'Human', 'Immune response', 'Immunoassay', 'Infection', 'Infrastructure', 'International', 'Lead', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Mycobacterium tuberculosis', 'Nested Case-Control Study', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Physicians', 'Post-Translational Protein Processing', 'Prospective cohort', 'Proteins', 'Proteome', 'Proteomics', 'Public Health', 'Pulmonary Tuberculosis', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'San Francisco', 'Scientist', 'Shotguns', 'Site', 'Specificity', 'Sputum', 'Testing', 'Training', 'Translating', 'Triage', 'Tuberculosis', 'Uganda', 'United States National Institutes of Health', 'Universities', 'Urine', 'Work', 'accurate diagnosis', 'base', 'biomarker discovery', 'biomarker panel', 'biosignature', 'candidate marker', 'career', 'career development', 'cohort', 'disease phenotype', 'experience', 'improved', 'mortality', 'multidisciplinary', 'novel', 'novel marker', 'point of care', 'pre-clinical', 'prospective', 'protein biomarkers', 'research and development', 'sample collection', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K23,2020,209400,685608202,0.004400285824354073
"Real time optimization of electron-based fragmentation for middle and top-down proteomics in mass spectrometry The identification and quantification of biological macromolecules remains challenging despite major advances in the speed, resolution and mass accuracy of modern mass spectrometers. A key weakness with current instrumentation lies in the methods used to induce fragmentation. The reliance in particular on collision-induced dissociation (CID) has limited such analyses to bottom-up workflows of trypsin-digested peptides of 10-30 residues. At e-MSion, we have developed an efficient electron-fragmentation technology called ExD for large proteins and are now co-marketed our ExD Option with Agilent, and soon will be with Thermo and Waters instruments. What has really captured the interest of the biopharma and top-down communities in the past year is the exceptional sequence coverage of native proteins we obtain with the same ExD cell. The resulting spectra are less congested than those obtained with currently available ETD/UVPD/CID fragmentation methodologies. We have shown that our technology works faster and gives cleaner spectra with more complete dissociation with larger macromolecular protein complexes than has ever been possible before, while still preserving labile post translational modifications. In addition, fragmentation with higher energy electrons can be used to provide complementary data to improve protein and glycan identification. The challenge now has become how to optimally collect and process these data to maximize the utility of ExD fragmentation. Last summer, Xilinx released its Versal Adaptive Compute Acceleration Platform (ACAP), a massively parallel processor with 50 billion transistors targeted to transform digital signal processing, handling of big data and artificial intelligence. This ACAP technology has already accelerated Illumina DNA sequence assembly by 90-fold. Our feasibility question asks how to effectively harness this new highly parallelized technology to preprocess complex top-down mass spectra on- the-fly. This will allow us to actively optimize data acquisition by enabling adaptive operation of the ExD cell and mass spectrometer. The objective is to maximize both fragmentation and dissociation of native proteins, enabling faster and comprehensive characterization of challenging proteoforms important to the biopharmaceutical industry and biomedical researchers.  Success will offer an extremely fast, cost-effective solution to characterize complexes of macromolecules under native conditions with increased accuracy, speed, and fewer misidentifications. Our ExD technology with the Versal ACAP can be both retrofitted into existing mass spectrometers as well as being available in new generations of mass spectrometers at a price below other less-effective alternative fragmentation technologies like ETD and UVPD. Thus, it will provide new abilities for many NIH investigators to advance basic research, probe disease mechanisms and permit more sophisticated searches for both diagnostic and therapeutic biomarkers. Even with all of the scientific progress made to date, the complexity of disease-affected tissues still challenges our ability to probe what makes people sick. The goal of this Phase I SBIR project is to develop a powerful computer technology to aid in characterizing biological molecules that will improve the diagnosis and treatment of diseases ranging from arthritis, cancer, diabetes to heart disease and neurodegeneration.",Real time optimization of electron-based fragmentation for middle and top-down proteomics in mass spectrometry,10081127,R43GM139467,"['Acceleration', 'Affect', 'Arthritis', 'Artificial Intelligence', 'Automobile Driving', 'Basic Science', 'Big Data', 'Biological', 'Biological Products', 'Biological Response Modifier Therapy', 'Businesses', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computers', 'Continuous Infusion', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Collection', 'Diabetes Mellitus', 'Diagnosis', 'Digital Signal Processing', 'Disease', 'Dissociation', 'Electronics', 'Electrons', 'Engineering', 'Face', 'Family', 'Feasibility Studies', 'Generations', 'Goals', 'Grant', 'Health', 'Heart Diseases', 'Individual', 'Industrialization', 'Industry', 'Ions', 'Isoleucine', 'Laboratories', 'Leucine', 'Macromolecular Complexes', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Methodology', 'Methods', 'Modernization', 'Multiprotein Complexes', 'Nerve Degeneration', 'Noise', 'Optics', 'Peptides', 'Periodicity', 'Phase', 'Polysaccharides', 'Post-Translational Protein Processing', 'Price', 'Process', 'Protein Analysis', 'Protein Fragment', 'Proteins', 'Proteomics', 'Reading', 'Research Personnel', 'Resolution', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'Techniques', 'Technology', 'Time', 'Tissues', 'Transistors', 'Trypsin', 'United States National Institutes of Health', 'Vendor', 'Water', 'Work', 'base', 'blind', 'computational platform', 'computerized data processing', 'cost effective', 'data acquisition', 'diagnostic biomarker', 'disulfide bond', 'electron energy', 'encryption', 'experience', 'fragment X', 'improved', 'instrument', 'instrumentation', 'interest', 'macromolecule', 'mass spectrometer', 'meetings', 'operation', 'preservation', 'programs', 'protein complex', 'signal processing', 'success', 'therapeutic biomarker']",NIGMS,"E-MSION, INC.",R43,2020,212830,959155,-0.043695650860067034
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9989196,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'automated algorithm', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2020,222618,340417756,0.003073712914243487
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10224492,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,233900,641965656,0.004054461492287791
"Pan-vaccine Analysis to Test the Impact of Cytomegalovirus on Vaccine Efficacy PROJECT SUMMARY/ABSTRACT Cytomegalovirus (CMV) infects around 50% of the US population. Even though the CMV exists in a latent state in healthy individuals, it profoundly shapes the immune system. Recent studies suggest that the CMV infection alters the immune response to influenza vaccine. However, the exact effect of CMV on the efficacy of the influenza vaccine remains controversial. In addition, how CMV shapes the immune responses toward other vaccines are unknown. We hypothesize that latent CMV infection induces critical changes in the immune system, which alters the efficacy of multiple types of vaccines. The ImmPort database currently hosts 133 vaccine studies, covering 21 types of vaccines, creating an unprecedented opportunity for us to test our hypothesis. We will perform a comprehensive meta-analysis to test the relationship between CMV and vaccine efficacies, and will use state-of-art statistical models (e.g., Dynamic Bayesian Network) to identify the mechanism by which CMV alters the vaccine response. Leveraging the group's expertise in computational immunology and rich datasets on ImmPort, we will address the following aims. Aim1: Test the effect of CMV on influenza vaccine outcome. We will perform a meta-analysis of 60 influenza studies available on ImmPort to test the impact of CMV. We will quantify and standardize the efficacy of influenza vaccine across studies, which are measured by hemagglutinin inhibition (HAI) assays before and after the vaccination. We will also determine the CMV infection status in subjects, either directly from serological tests or indirectly from immune- phenotyping data using cutting-edge machine learning tools. We will then test if CMV increases the response to influenza vaccine by analyzing data from all studies in a unified statistical framework while taking the heterogeneity between studies into account. Aim2: Bayesian network analysis of influenza vaccine response. We will harmonize multimodal immune-phenotyping data from the influenza vaccine studies, including transcriptomics data, cytometry data, and cytokine measurements. We will use state-of-art network analysis methods (e.g., Dynamic Bayesian network) to model the interplay between the immune components over time. Using the Bayesian network, we will investigate the mechanism by which CMV shapes the outcome of influenza vaccination. Aim3: Explore the effect of CMV infection on other vaccines. We will extend our analysis to vaccines other than influenza vaccine, (e.g., West Nile, Hepatitis B, yellow fever, malaria, and Tuberculosis). We will quantify the vaccine efficacy using assays specific to the vaccine type, such as Controlled Human Malaria Infection (CHMI) for the malaria vaccine and Plaque Reduction Neutralization Test for the yellow fever vaccine. We will perform separate network analyses to characterize the relationship between CMV and the immune response of individual vaccines. We will then perform joint analysis across vaccine types to identify the common impact of CMV across vaccine types. PROJECT NARRATIVE Infectious diseases remain an urgent problem, resulting in an estimated 3 million deaths worldwide and more than 110,000 deaths in the United States annually, but the efficacy of vaccines against many infectious diseases remains suboptimal, including malaria, influenza, and dengue. To improve the vaccines, it is crucial to understand the factors that affect the immune response toward vaccines. In this study, we investigate how cytomegalovirus affects the efficacy of multiple vaccines, providing valuable information for improving the design of vaccines.",Pan-vaccine Analysis to Test the Impact of Cytomegalovirus on Vaccine Efficacy,10026284,UH2AI153016,"['Address', 'Affect', 'Bayesian Analysis', 'Bayesian Modeling', 'Bayesian Network', 'Biological Assay', 'Cells', 'Cessation of life', 'Communicable Diseases', 'Communities', 'Computer Models', 'Cytomegalovirus', 'Cytomegalovirus Infections', 'Cytomegalovirus Vaccines', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dengue', 'Diagnosis', 'Disease', 'Goals', 'Hemagglutinin', 'Hepatitis', 'Hepatitis B', 'Herpesviridae', 'Heterogeneity', 'Human', 'Immune', 'Immune response', 'Immune system', 'Immunology', 'Individual', 'Influenza', 'Influenza vaccination', 'Joints', 'Knowledge', 'Machine Learning', 'Malaria', 'Malaria Vaccines', 'Measurement', 'Measures', 'Meta-Analysis', 'Methods', 'Modeling', 'Neutralization Tests', 'Outcome', 'Outcome Measure', 'Pathway Analysis', 'Population', 'Research', 'Research Personnel', 'Resources', 'Serologic tests', 'Shapes', 'Standardization', 'Statistical Models', 'Testing', 'Time', 'Tuberculosis', 'United States', 'Vaccination', 'Vaccine Design', 'Vaccines', 'Validation', 'Virus', 'Virus Latency', 'West Nile virus', 'Yellow Fever', 'Yellow Fever Vaccine', 'cytokine', 'design', 'improved', 'individual response', 'influenza virus vaccine', 'malaria infection', 'multimodality', 'network models', 'pathogen', 'phenotypic data', 'response', 'tool', 'transcriptomics', 'vaccine efficacy', 'vaccine response', 'vaccine trial']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",UH2,2020,242126,685608202,-0.002964213888090223
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,10022332,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'comorbidity', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2020,243885,607172798,-0.011420145153188595
"Signature of profiling and staging the progression of TB from infection to disease. Project Summary/Abstract Tuberculosis (TB) is the leading cause of infectious disease mortality worldwide. Nearly one-third of the world's population is infected with Mycobacterium tuberculosis (MTB). More than 10.4 million new cases of active TB disease develop annually, leading to 1.4 million deaths due to the disease each year. Despite widespread efforts to study of the etiology of disease, the development and global introduction of an effective treatment regimen, and sensitive diagnostics for identifying pulmonary TB disease, efforts to control this pandemic are falling short, largely due to a lack of a clear understanding of the pathogenic progression from MTB infection to active clinical disease. In addition, Existing gene expression studies have presented more than three dozen biomarkers to predict TB related outcomes such as identifying active TB disease, predicting risk of treatment failure, or predicting which patients will progress to active TB disease. These have been developed and refined using multiple technologies and using a diverse set of computational and machine learning prediction algorithms, but most are focused on two-class comparison (e.g. TB vs. LTBI). In this proposal, we propose to compile and harmonize dozens of existing RNA-sequencing datasets for TB outcomes. We will use these compiled data to develop a computational platform and interactive visualization tools for profiling TB signatures across all existing datasets. We plan to use this curated data and software platform to develop a more refined molecular map of progression from TB infection to active disease. Consistent with a recently presented models for TB disease development, we hypothesize that we will be able to identify gene expression patterns associated with stages on the TB disease spectrum, including: uninfected or eliminated infection, controlled or truly latent infection, future progressors or incipient disease, subclinical TB disease, and active clinical TB disease. We believe that existing gene expression data and signatures will allow us to identify distinct transcriptional profiles for each stage, and hence develop a multi-class machine learning approach for classifying patients into their corresponding stage. Overall, this proposal contributes to the field by compiling existing gene expression data and developing a wholistic map of TB progression from infection to active disease. In addition, we will provide a curated dataset and metadata in an accessible format for more than three dozen existing TB studies, and allow others to access and explore these data through a user-friendly profiling platform. Project Narrative We will compile existing TB gene expression data and develop a wholistic map of TB progression from infection to active disease. We will provide curated data for dozens of existing TB RNA-sequencing datasets, and allow others to access and explore these data through a user-friendly software toolkit and platform.",Signature of profiling and staging the progression of TB from infection to disease.,10048427,R21AI154387,"['Biological Markers', 'Blood specimen', 'Cessation of life', 'Clinical', 'Communicable Diseases', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease Progression', 'Etiology', 'Evaluation', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Immunologic Factors', 'Individual', 'Infection', 'Language', 'Learning', 'Machine Learning', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'Mycobacterium tuberculosis', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Performance', 'Population', 'Pulmonary Tuberculosis', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Staging', 'Technology', 'Treatment Failure', 'Treatment Protocols', 'Tuberculosis', 'Validation', 'Visualization', 'Visualization software', 'Work', 'base', 'biomarker validation', 'comorbidity', 'computational platform', 'data harmonization', 'data tools', 'demographics', 'effective therapy', 'falls', 'genetic signature', 'genomic biomarker', 'interactive tool', 'latent infection', 'molecular modeling', 'molecular pathology', 'mortality', 'multiple datasets', 'novel', 'pandemic disease', 'prediction algorithm', 'screening', 'transcriptome sequencing', 'treatment response', 'treatment risk', 'user friendly software', 'user-friendly']",NIAID,BOSTON UNIVERSITY MEDICAL CAMPUS,R21,2020,260741,164685352,0.01708195836458349
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10019459,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2020,291252,807432003,-0.010558669584727622
"Automated Molecular Identity Disambiguator (AutoMID) PROJECT SUMMARY Small molecules are one of the most important classes of therapeutics alleviating suffering and in many cases death for hundreds of millions of people worldwide. Small molecules also serve as invaluable tools to study biology, often with the goal to validate novel targets for the development of future therapeutic drugs. Reproducibility of experimental results and the interoperability and reusability of resulting datasets depend on accurate descriptions of associated research objects, and most critically on correct representations of small molecules that are tested in biological assays. For example, it is not possible to develop predictive models of protein target - small molecule interactions if their chemical structure representations are not correct. Many factors contribute to errors in reported chemical structures in small molecule screening and omics reference databases, scientific publications, and many other web-based resources and documents. Because of the complexity of representing small molecules chemical structure graphs and the lack of thorough curation, errors are frequently introduced by non-experts and error propagation across different digital research assets is a pervasive problem. To address this challenging problem via a scalable approach, we propose the Automated Molecular Identity Disambiguator (AutoMID). AutoMID will be usable in batch mode at scale via an API, for example to assist chemical structure standardization and registration by maintainers of digital research assets, and also via interactive (UI) mode for everyday researchers to quickly and easily validate or correct their small molecule representations. AutoMID will leverage extensive highly standardized linked databases of chemical structures and associated information including names, synonyms, biological activity and physical properties and their sources / provenance and leverage expert rules and AI to enable reliable disambiguation of chemical structure identities at scale. PROJECT NARRATIVE Small molecules are one of the most important types of drugs. They also serve as invaluable tools to study biology. The complexity of representing chemical graphs and the lack of thorough curation leads to frequent small molecule structure errors, which propagate across digital research assets, impeding their interoperability and reusability. To address this challenging problem, we propose the Automated Molecular Identity Disambiguator (AutoMID). Built on expert knowledge and AI, AutoMID will enable researchers and maintainers of data repositories to reliably identify and resolve ambiguities in chemical structures at scale.",Automated Molecular Identity Disambiguator (AutoMID),9987129,R01LM013391,"['Address', 'Adoption', 'Biological', 'Biological Assay', 'Biology', 'Categories', 'Cessation of life', 'Chemical Structure', 'Chemicals', 'Classification', 'Complex', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Deposition', 'Detection', 'Development', 'FAIR principles', 'Future', 'Goals', 'Graph', 'Hand', 'Hybrids', 'In Vitro', 'Individual', 'Knowledge', 'Legal patent', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Metadata', 'Modeling', 'Molecular', 'Molecular Structure', 'Names', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Privatization', 'Property', 'Proteins', 'Publications', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Semantics', 'Source', 'Standardization', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Training', 'base', 'cheminformatics', 'data harmonization', 'data modeling', 'data warehouse', 'design', 'digital', 'high throughput screening', 'improved', 'in silico', 'in vivo', 'interoperability', 'knowledge curation', 'novel', 'online resource', 'physical property', 'predictive modeling', 'relational database', 'screening', 'small molecule', 'software systems', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2020,293345,157845771,-0.031131371268108794
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,9855035,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'disease phenotype', 'driver mutation', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'machine learning method', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistical learning', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,305167,511185245,-0.007616496737782076
"Sample-specific Models for Molecular Portraits of Diseases in Precision Medicine A fundamental challenge in precision medicine is to understand the patterns of differentiation between individuals. To address this challenge, we propose to go beyond the traditional `one disease--one model' view of bioinformatics and pursue a new view built upon personalized patient models that facilitates precision medicine by leveraging both commonalities within a patient cohort as well as signatures unique to every individual patient. With the emergence of large-scale databases such as The Cancer Genome Atlas (TCGA), the International Cancer Genome Consortium (ICGC), and the Gene Expression Omnibus (GEO), which collect multi-omic data on many different diseases, a new “pan-omics” and “pan-disease” paradigm has emerged to jointly analyze all patients in a disease cohort while accounting for patient-specific effects. An example of this is the recently released Pan-Cancer Atlas. At the same time, next generation statistical tools to accurately and rigorously draw the necessary inferences are lacking. In this project we propose a series of mathematically rigorous, statistically sound, and computationally feasible approaches to infer sample-specific models, providing a more complete view of heterogeneous datasets. By bringing together ideas from the machine learning, statistics, and mathematical optimization communities, we provide a rigorous framework for precision medicine via sample-specific statistical models. Crucially, we propose to analyze this framework and prove strong theoretical guarantees under weak assumptions--this dramatically distinguishes our framework from much of the existing literature. Towards these goals, we propose the following aims: Aim 1: Discovery of new molecular profiles with sample-specific statistical models. We propose a general framework for inferring sample-specific models with low-rank structure based on the novel concept of distance-matching. This allows us to infer statistical models at the level of a single patient without overfitting, and is general enough to be applied for prediction, classification, and network inference as well as a variety of diseases and phenotypes. Aim 2: Multimodal approaches to personalized diagnosis--contextually interpretable models for actionable clinical decision support. In order to translate these models into practice, we propose a novel interpretable predictive model that supports complex, multimodal data types such as images and text combined with high-level interpretable features such as SNP data, gender, age, etc. This framework simultaneously boosts the accuracy of clinical predictions by exploiting sample heterogeneity while providing human-digestable explanations for the predictions being made. Aim 3: Next-generation precision medicine--algorithms and software for personalized estimation. To put our models into practical use, we will develop new algorithms for interpretable prediction of personalized clinical outcomes and visualization of personalized statistical models. All of our tools will be combined into a user-friendly software package called PrecisionX that will be freely available to researchers and clinicians everywhere. RELEVANCE (See instructions): Personalization with data is a critical challenge whenever decisions must be made at scale, and has applications that go beyond precision medicine; businesses, educational institutions, and financial institutions are among the many players that have acknowledged a stake in this complex problem. We expect the proposed work to provide a rigorous foundation for personalization with large and high-dimensional datasets, finding use throughout the broader scientific community as well as with industry and educational institutions. Alongside our collaboration with Pitt/UPMC, we will work with physicians and data scientists for practical feedback as well as provide training in the methods developed. n/a",Sample-specific Models for Molecular Portraits of Diseases in Precision Medicine,10133782,R01GM140467,"['Accounting', 'Address', 'Age', 'Algorithmic Software', 'Algorithms', 'Atlases', 'Bioinformatics', 'Businesses', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Scientist', 'Data Set', 'Disease', 'Feedback', 'Foundations', 'Gender', 'Gene Expression', 'Goals', 'Heterogeneity', 'Human', 'Image', 'Individual', 'Industry', 'Institution', 'Instruction', 'International', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Methods', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Outcome', 'Patients', 'Pattern', 'Physicians', 'Portraits', 'Research Personnel', 'Sampling', 'Series', 'Statistical Models', 'Structure', 'Text', 'The Cancer Genome Atlas', 'Time', 'Training', 'Translating', 'Visualization', 'Work', 'base', 'cancer genome', 'clinical decision support', 'clinically actionable', 'cohort', 'disease phenotype', 'heterogenous data', 'high dimensionality', 'individual patient', 'large-scale database', 'molecular modeling', 'multimodal data', 'multimodality', 'next generation', 'novel', 'personalized diagnostics', 'personalized predictions', 'precision medicine', 'predictive modeling', 'sound', 'statistics', 'tool', 'user friendly software']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2020,305566,30434536,-0.003177577267010503
"Image-guided Biocuration of Disease Pathways From Scientific Literature Realization of precision medicine ideas requires an unprecedented rapid pace of translation of biomedical discoveries into clinical practice. However, while many non-canonical disease pathways and uncommon drug actions, which are of vital importance for understanding individual patient-specific disease pathways, are accumulated in the literature, most are not organized in databases. Currently, such knowledge is curated manually or semi-automatically in a very limited scope. Meanwhile, the volume of biomedical information in PubMed (currently 28 million publications) keeps growing by more than a million articles per year, which demands more efficient and effective biocuration approaches.  To address this challenge, a novel biocuration method for automatic extraction of disease pathways from figures and text of biomedical articles will be developed.  Specific Aim 1: To develop focused benchmark sets of articles to assess the performance of the biocuration pipeline.  Specific Aim 2: To develop a method for extraction of components of disease pathways from articles’ figures based on deep-learning techniques.  Specific Aim 3: To develop a method for reconstruction of disease-specific pathways through enrichment and through graph neural network (GNN) approaches.  Specific Aim 4: To conduct a comprehensive evaluation of the pipeline.  The overarching goal of this project is to develop a computer-based automatic biocuration ecosystem for rapid transformation of free-text biomedical literature into a machine-processable format for medical applications.  The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. It will especially benefit cancer patients for which up-to-date knowledge of newly discovered molecular mechanisms and drug actions is critical. The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. In this project, a novel biocuration method for an automatic extraction of disease mechanisms from figures and text in scientific literature will be developed. These mechanisms will be stored in a database for further querying to assist in medical diagnosis and treatment.",Image-guided Biocuration of Disease Pathways From Scientific Literature,9987133,R01LM013392,"['Address', 'Architecture', 'Benchmarking', 'Biological', 'Cancer Patient', 'Communities', 'Computers', 'Databases', 'Deposition', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Pathway', 'Ecosystem', 'Elements', 'Evaluation', 'Feedback', 'Genes', 'Goals', 'Graph', 'Health', 'Image', 'Informatics', 'Knowledge', 'Label', 'Language', 'Link', 'Literature', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Medical', 'Methods', 'Molecular', 'Molecular Analysis', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'PubMed', 'Publications', 'Regulation', 'Reporting', 'Research', 'Retrieval', 'Selection Criteria', 'Signal Pathway', 'Source', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'Translations', 'Visual', 'Work', 'base', 'clinical practice', 'deep learning', 'design', 'detector', 'drug action', 'image guided', 'improved', 'individual patient', 'knowledge base', 'knowledge curation', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'precision medicine', 'reconstruction', 'success', 'text searching', 'tool', 'usability']",NLM,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2020,313495,63611576,-0.007079767251049403
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9872178,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'data analysis pipeline', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'programmed cell death protein 1', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2020,314000,560644462,-0.014118750287225616
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10016840,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2020,330502,560644462,0.012304324662541376
"Combining chemical and computational tools for predictive models of microbiome communities ABSTRACT The gut microbiome has a tremendous impact on health and disease, actively contributing to obesity, diabetes, inflammatory bowel disease, cardiovascular diseases, and several poorly understood neurological disorders. We do not yet have the necessary tools to precisely probe these microbial communities, though such tools could unlock extensive benefits to human health. Elucidating the contributions of individual species or consortia of bacteria would provide a rational basis for understanding microbiota-controlled disease and lead to novel therapies. To carry out the fundamental research planned in this proposal, we will tackle three major problems: First, we will build the first set of molecular tools that effectively and precisely modulate the microbiome bacteria; second, we will analyze the multiscale dynamics of microbial communities; and third, we will construct an ingestible biosensor for real-time monitoring of microbiome populations. Although antibiotics and fecal transplants can reconfigure microbial consortia, they do not precisely target individual bacteria. Conversely, antimicrobial peptides (AMPs) have evolved to selectively attack pathogenic bacteria but do not target microbiome bacteria, constituting desirable scaffolds for molecular engineering and potential sources of microbiome-targeting agents. We will develop a new computational peptide design methodology, based on classical and hybrid-quantum mechanical molecular dynamics (MD) simulations, to create a groundbreaking assessment of the dynamical and emergent properties of AMPs. Chemical synthesis and large-scale screening will confirm predicted selectivity against microbiome species, and a machine learning workflow will connect sequences of individual peptides to their dynamics and activity. We will then apply the synthetic AMPs to interrogate the human microbiome by selectively removing species during bacterial consortia experiments, to be carried out in bioreactors, under regular or anaerobic conditions. We will pair our experiments with whole-cell metabolic network models, providing a systems biology perspective to the analysis of inter-species interactions. An integrated ingestible biosensing device will be developed to monitor the microbiome by electrochemically sensing unique biomarkers from gut microbes. This will provide the first real-time measurements of microbiome composition and will be integrated to our bioreactors for testing, to ultimately be used for in vivo tests. This work will build the first set of molecular and computational tools for microbiome engineering and will lay the foundation to address critical gaps in our understanding of the gut micro-environment, and of the contributions of gut bacteria to the etiology of disease. Grounded in our demonstrated expertise in synthetic biology, computer science, microbiology, and electrical engineering, this project will provide a computational- experimental framework for developing a peptide encyclopedia for the gut microbiome, in line with NIH's public health mission and goals. PROJECT NARRATIVE  The gut microbiome plays roles in nutrition, immunity, metabolism, and several poorly understood neurological disorders. Suitable tools, however, do not yet exist for engineering the microbial communities that constitute the human microbiome. The proposed research introduces the first molecular tools to precisely understand the functions of microbiome communities in our health and disease in order to then delineate therapeutic interventions for diseases mediated by the gut microbiota, thereby addressing NIH's public health mission.",Combining chemical and computational tools for predictive models of microbiome communities,10029354,R35GM138201,"['Address', 'Anaerobic Bacteria', 'Antibiotics', 'Bacteria', 'Biochemical Pathway', 'Biological Markers', 'Bioreactors', 'Biosensing Techniques', 'Biosensor', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Communities', 'Devices', 'Diabetes Mellitus', 'Disease', 'Electrical Engineering', 'Encyclopedias', 'Engineering', 'Etiology', 'Foundations', 'Goals', 'Health', 'Human', 'Human Microbiome', 'Hybrids', 'Immunity', 'Individual', 'Inflammatory Bowel Diseases', 'Lead', 'Machine Learning', 'Mechanics', 'Mediating', 'Metabolism', 'Methodology', 'Microbiology', 'Mission', 'Molecular', 'Molecular Computations', 'Monitor', 'Obesity', 'Peptides', 'Play', 'Population', 'Property', 'Public Health', 'Research', 'Role', 'Source', 'Systems Biology', 'Testing', 'Therapeutic Intervention', 'United States National Institutes of Health', 'Work', 'antimicrobial peptide', 'base', 'chemical synthesis', 'computer science', 'computerized tools', 'design', 'experimental study', 'fecal transplantation', 'fundamental research', 'gut bacteria', 'gut microbes', 'gut microbiome', 'gut microbiota', 'in vivo evaluation', 'microbial community', 'microbiome', 'microbiome composition', 'microbiota', 'molecular dynamics', 'nervous system disorder', 'network models', 'novel therapeutics', 'nutrition', 'pathogenic bacteria', 'predictive modeling', 'quantum', 'real time monitoring', 'scaffold', 'screening', 'synthetic biology', 'targeted agent', 'temporal measurement', 'tool']",NIGMS,UNIVERSITY OF PENNSYLVANIA,R35,2020,342713,593605914,-0.036267190021701846
"N3C & All of Us Research Program Collaborative Project Project Summary/Abstract The COVID-19 pandemic presents unprecedented clinical and public health challenges. Though institutions collect large amounts of clinical data about COVID-19 cases, these datasets individually might not be diverse enough to draw population level conclusions. Also, statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. To tackle this problem, NCATS introduced the National COVID Cohort Collaborative (N3C), an open science, community-based initiative to share patient level data for analysis. The initiative requires participating institutions to share information about their COVID-19 patients in a standard-driven way, including demographics, vital signs, diagnoses, laboratory results, medications, and other treatments. The data from multiple institutions will be merged and consolidated, and access will be provided to investigators through a centralized analytical platform. The COVID-19 data sharing collaboration with the N3C initiative offers a mechanism to initiate collaborations with other NIH sponsored data sharing programs, such as the All of Us Research Program (AoURP). This administrative supplement will support efforts to clean and standardize data at VCU, and to transfer it to the N3C data repository. The supplement will also assist in introducing new services at the Wright Center to support our investigators to use the N3C resources. It will also enable collaboration with the AoURP by establishing a pipeline to collect and transmit consented patients' EHR data and by building on existing community outreach pathways to recruit additional participants for the AoURP. The project will be overseen by the PI/Executive Committee and supervised by the Director of Research Informatics. Procedures and services developed at our local CTSA hub will be shared and disseminated to the CTSA network. Project Narrative NIH/NCATS has been working on the National COVID Cohort Collaborative (N3C), which aims to build a centralized national data resource to be used by the research community to study the COVID-19 pandemic and identify potential treatments as the pandemic continues to evolve. The COVID-19 data sharing collaboration with the N3C initiative also offers a mechanism to initiate collaborations with the All of Us Research Program (AoURP). This administrative supplement will support the creation and management of a data extraction and transfer pipeline to the N3C and AoURP data repositories from VCU.",N3C & All of Us Research Program Collaborative Project,10217339,UL1TR002649,"['Administrative Supplement', 'All of Us Research Program', 'COVID-19', 'COVID-19 pandemic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communities', 'Community Outreach', 'Consent', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Effectiveness', 'Funding Opportunities', 'Goals', 'Health', 'Health Status', 'Individual', 'Informatics', 'Infrastructure', 'Institution', 'Laboratories', 'Outcomes Research', 'Participant', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Procedures', 'Public Health', 'Research', 'Research Personnel', 'Resource Informatics', 'Resources', 'Services', 'Supervision', 'Testing', 'Translational Research', 'United States National Institutes of Health', 'base', 'biomedical informatics', 'clinical center', 'cohort', 'coronavirus disease', 'data resource', 'data sharing', 'data standards', 'data warehouse', 'demographics', 'design', 'improved', 'informatics infrastructure', 'innovation', 'large scale data', 'multi-site trial', 'network informatics', 'open data', 'pandemic disease', 'parent grant', 'programs', 'recruit', 'response', 'statistical and machine learning', 'tool']",NCATS,VIRGINIA COMMONWEALTH UNIVERSITY,UL1,2020,346608,90243698,-0.02600994513838964
"Modeling the Incompleteness and Biases of Health Data Modeling the Incompleteness and Biases of Health Data Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. Existing efforts for missing health data imputation often focus on only cross-sectional correlation (e.g., correlation across subjects or across variables) but neglect autocorrelation (e.g., correlation across time points). Moreover, they often focus on modeling incompleteness but neglect the biases in health data. Modeling both the incompleteness and bias may contribute to better understanding of health data and better support clinical decision making. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets. Aim 1 introduces the MICA framework to jointly consider cross-sectional correlation and auto-correlation. In Aim 2, we will augment MICA to be bias-aware (hence BAMICA) to account for biases stemmed from multiple roots such as healthcare process and use them as features in imputing missing health data. This augmentation is achieved by a novel recurrent neural network architecture that keeps track of both evolution of health data variables and bias factors. In Aim 3, we will supplement unstructured clinical notes to structured health data for modeling incompleteness and biases using a novel architecture of graph neural network on top of memory network. We will apply graph neural networks to process clinical notes in order to learn proper representations as input to the memory networks for imputation and downstream predictive modeling tasks. Depending on the clinical problem and data availability, not all modules may be needed. Thus our proposed BAMICA framework is designed to be flexible and consists of selectable modules to meet some or all of the above needs. In summary, our proposal bridges a key knowledge gap in jointly modeling incompleteness and biases in health data and utilizes unstructured clinical notes to supplement and augment such modeling in order to better support predictive modeling and clinical decision making. We will demonstrate generalizability by experimenting on four large clinical and cohort study datasets, and by scaling up to the eMERGE network spanning 11 institutions nationwide. We will disseminate the open-source framework. The principled and flexible framework generated by this project will bring significant methodological advancement and have a direct impact on enhancing discovery from health data. Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets.",Modeling the Incompleteness and Biases of Health Data,9941499,R01LM013337,"['Adoption', 'Algorithms', 'Architecture', 'Awareness', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Collection', 'Communities', 'Computer software', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Diagnostic tests', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Evolution', 'Functional disorder', 'General Hospitals', 'Goals', 'Graph', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Hour', 'Individual', 'Inpatients', 'Institution', 'Intuition', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Learning', 'Measurement', 'Medical', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Regimen', 'Research', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Structure', 'Symptoms', 'System', 'Test Result', 'Testing', 'Time', 'Training', 'Validation', 'clinical decision support', 'clinical decision-making', 'data mining', 'data quality', 'design', 'experimental study', 'flexibility', 'health care service utilization', 'health data', 'improved', 'lifetime risk', 'machine learning algorithm', 'neglect', 'neural network', 'neural network architecture', 'novel', 'open source', 'patient population', 'personalized diagnostics', 'personalized therapeutic', 'predictive modeling', 'recurrent neural network', 'scale up', 'social health determinants', 'stem', 'structured data', 'text searching', 'tool', 'trait']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2020,348397,367414121,-0.022758013849188956
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9889134,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'machine learning method', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,356625,323604360,0.011753235746555743
"Center for Machine Learning in Urology PROJECT SUMMARY We propose to establish an Exploratory Center for Interdisciplinary Research in Benign Urology at the Children’s Hospital of Philadelphia (CHOP) and the University of Pennsylvania (Penn), the central mission of which is to apply machine learning to improve the understanding of the pathophysiology, diagnosis, risk stratification, and prediction of treatment responses of benign urological disease among children and adults. The proposed CHOP/Penn Center for Machine Learning in Urology (CMLU) addresses critical structural and scientific barriers that impede the development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. Structurally, urologic research occurs in silos, with little interaction among investigators that study different diseases or different populations (e.g. pediatric and adult). Scientifically, analysis of imaging and other types complex data is limited by inter-observer variability, and incomplete utilization of available information. This proposal overcomes these barriers by applying cutting-edge approaches in machine learning to analyze CT images that are routinely obtained for evaluation of individuals with kidney stone disease. Central to the CHOP/Penn CMLU is the partnership of urologists and experts in machine learning, which will bring a new approach to generating knowledge that advances research and clinical care. In addition, the CMLU will expand the urologic research community by providing a research platform and standalone machine learning executables that could be applied to other datasets. The Center’s mission will be achieved through the following Aims, with progress assessed through systematic evaluation: Aim 1. To expand the research base investigating benign urological disease. We will establish a community with the research base, particularly with the KURe, UroEpi programs, other P20 Centers, and O’Brien Centers. We will build this community by providing mini-coaching clinics to facilitate application of machine learning to individual projects, developing an educational hub for synchronous and asynchronous engagement with the research base, and making freely available all source codes and standalone executables for all machine learning tools. Aim 2. To improve prediction of ureteral stone passage using machine learning of CT images. The CMLU has developed deep learning methods that segment and automate measurement of urinary stones and adjacent renal anatomy. In the Research Project, we will compare these methods to existing segmentation methods and the current gold standard of manual measurement. We will then extract informative features from thousands of CT scans to predict the probability of spontaneous passage of ureteral stones for children and adults evaluated in the CHOP and Penn healthcare systems. Aim 3. To foster collaboration in benign urological disease research across levels of training and centers through an Educational Enrichment Program. We will amplify interactions across institutions and engage investigators locally and nationally by providing summer research internships, and interinstitutional exchange program, and an annual research symposium. PROJECT NARRATIVE The proposed CHOP/Penn O’Brien Center for Machine Learning in Urology addresses critical structural and scientific barriers that impede development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. This application overcomes these barriers by applying cutting- edge approaches in machine learning to analyze complex imaging data for individuals with kidney stone disease.The Center’s strategic vision of using machine learning to generate knowledge that improves diagnosis, risk stratification strategies, and prediction of outcomes among children and adults will be achieved through the implementation of a Educational Enrichment Program and a Research Project.",Center for Machine Learning in Urology,10133362,P20DK127488,"['Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Benign', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Investigator', 'Code', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Educational Status', 'Evaluation', 'Fostering', 'Functional disorder', 'Funding', 'Future', 'Gold', 'Healthcare Systems', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internships', 'Interobserver Variability', 'Investigation', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Lead', 'Longevity', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Mission', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pediatric Hospitals', 'Pennsylvania', 'Philadelphia', 'Population', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Probability', 'Publishing', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk stratification', 'Site', 'Source Code', 'Structure', 'Students', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Urinary Calculi', 'Urologic Diseases', 'Urologist', 'Urology', 'Vision', 'Visit', 'X-Ray Computed Tomography', 'base', 'clinical care', 'complex data ', 'deep learning', 'deep neural network', 'design', 'experience', 'feature selection', 'human error', 'improved', 'interdisciplinary collaboration', 'interest', 'learning strategy', 'novel strategies', 'outcome prediction', 'peer', 'programs', 'routine imaging', 'senior faculty', 'skills', 'summer research', 'symposium', 'tool', 'urologic', 'web page']",NIDDK,CHILDREN'S HOSP OF PHILADELPHIA,P20,2020,358890,178185562,-0.010108357562625852
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,9874005,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2020,360227,169622494,0.006632375985280172
"Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties ABSTRACT Mesenchymal stem cells (MSCs) have broad-based potential in regenerative medicine cell therapies and can be isolated from a variety of different tissues. Though MSCs from different tissues are phenotypically similar, a barrier to their clinical use is the high variability of their trophic and regenerative properties. This variability suggests that inherent differences exist in the molecular machinery guiding MSC properties between different MSC populations, yet, to date, these differences are ill-defined. To this end, we have preliminary evidence that MSC phenotypes correlate to their regenerative outcomes. In this study, we aim to elucidate how the molecular and cellular properties of distinct MSC populations determine their regenerative properties. Our hypothesis is that MSCs from different tissues have different regenerative properties which correlate to specific molecular profiles defined by gene expression and transcriptional activity. To test this hypothesis, the project proposed has three Specific Aims (SAs). In SA1, we will determine how tissue-specificity dictates gene expression and dynamic transcription factor activity of distinct MSCs. SA2 will determine how differences in the cellular and molecular properties of MSCs correlate to MSC phenotype. Finally, in SA3, we will determine how the molecular profiles and cellular activities of MSCs dictate their regenerative properties. Findings of the proposed study will provide novel insights about how the distinct molecular profiles of MSCs dictate their biological and physiological properties. In a therapeutic context, this would enable the development of innovative screening technologies for MSC therapies to identify and enrich for the most appropriate MSC for the specific therapeutic application. PROPOSAL NARRATIVE Stem cell therapies are emerging as a new treatment approach to regenerate lost tissues, treat ischemic disorders, and treat chronic inflammatory conditions. Many of these approaches use stem cells from adults which are present in various regions throughout the body. Our research team is working to better understand how and why these adult stem cells behave the way they do so that we can better determine how to use them in different therapies to treat debilitating health conditions.",Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties,9954044,R01DE028657,"['Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Angiogenic Factor', 'Automobile Driving', 'Biological', 'Biological Process', 'Bone Marrow', 'Bone Regeneration', 'Bone Tissue', 'Cell Culture Techniques', 'Cell Separation', 'Cell Therapy', 'Cells', 'Chronic', 'Clinical', 'Clinical Trials', 'Computer Models', 'Data', 'Dental', 'Dental Pulp', 'Development', 'Disease', 'ENG gene', 'Emerging Technologies', 'Fatty acid glycerol esters', 'Funding Mechanisms', 'Gene Expression', 'Gene Expression Profile', 'Genetic Transcription', 'Gingiva', 'Health', 'Immunophenotyping', 'Inflammation', 'Inflammatory', 'Knowledge', 'Link', 'Maintenance', 'Mesenchymal Stem Cells', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Muscle', 'Natural regeneration', 'Operative Surgical Procedures', 'Oral', 'Osteogenesis', 'Outcome', 'Pathway interactions', 'Performance', 'Phenotype', 'Physiological', 'Population', 'Population Heterogeneity', 'Production', 'Property', 'Regenerative Medicine', 'Regulation', 'Reporting', 'Research', 'Rodent Model', 'Role', 'Signal Pathway', 'Sorting - Cell Movement', 'Specificity', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Tooth structure', 'United States National Institutes of Health', 'Work', 'adult stem cell', 'alveolar bone', 'angiogenesis', 'base', 'bone', 'clinical translation', 'healthy volunteer', 'in vivo', 'innovation', 'insight', 'interest', 'machine learning algorithm', 'molecular phenotype', 'next generation sequencing', 'novel', 'oral tissue', 'osteogenic', 'population based', 'regenerative', 'regenerative therapy', 'screening', 'self-renewal', 'stem cell differentiation', 'stem cell population', 'stem cell therapy', 'stem cells', 'stemness', 'transcription factor', 'transcriptome']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,405389,641965656,-0.009687340574927908
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,10024094,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'behavioral phenotyping', 'comorbidity', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2020,422740,560644462,-0.0008056122579985953
"Stakeholder Guidance to Anticipate and Address Ethical Challenges in Applications of Machine Learning and Artificial Intelligence in Algorithmic Medicine: a Novel Empirical Approach PROJECT ABSTRACT The potential for artificial intelligence applications, specifically machine learning, to prevent, predict, and help manage disease sparks immense hope not only for the individuals affected, but also for the overall health of populations. Particularly exciting examples of these novel computing strategies are increasingly found in the development of deep learning algorithms for medical use. Already embedded in our daily lives, algorithms have begun to impact human-decision making, from recruitment and hiring of employees to criminal sentencing. Outside of medicine, recognition of the ways algorithms may reflect, reproduce, and perpetuate bias has led to an explosion of theoretical and empirical research on the subject. There is an increasing awareness of potential algorithmic weaknesses, including some that raise concerns about fundamental issues of fairness, justice, and bias. The need to anticipate and address emerging ethical issues in algorithmic medicine is time- sensitive. As health care systems increasingly utilize algorithms for patient identification, diagnosis, and treatment direction, the consequences of algorithmic bias yield real and significant costs. Numerous stakeholders are responsible for the development, application and interpretation of algorithms in medicine, and yet there has been very little engagement of stakeholders most affected by these learning systems and tools. The overarching goal of this empirical and hypothesis driven project is to articulate the landscape of ethical concerns and the issues emerging in the context of the development, refinement, and application of machine learning in algorithmic medicine. First, we determine the distinct ethical issues and problems encountered in the development, refinement, and application of machine learning, by querying the perspectives of a diverse array of stakeholders involved—machine learning researchers, clinicians, ethicists, and patients. Using the new insights generated from the first half, we will conduct an evidence-based, information-sharing vignette survey to understand the impact of the contexts of algorithms on the ethically salient perspectives of physicians—those poised to implement such innovation in their own decision-making for the care of patients. Maximizing our established record of expertise in empirical ethics investigations, this sequence of projects leverages access to the exceptional machine learning research conducted at Stanford University, including work by NIH-funded investigators, and provides extensive, systematically collected data on ethical issues encountered and anticipated throughout the development and implementation of algorithms. Finally, the project develops and refines an evidence-informed information-sharing survey for use in better understanding how physicians react to intelligent systems. PROJECT NARRATIVE  Machine learning-driven algorithmic medicine now faces an urgent need to anticipate and address emerging ethical issues. For machine learning applications in algorithmic medicine, the failure to examine ethical issues from the perspective of stakeholders will inevitably limit the ecological validity and utility of the algorithms and threaten society's future embrace of these innovations. A hypothesis-driven, empirical study is needed to anticipate and address ethical concerns, and provide clinicians, machine learning researchers, policymakers, and the public with evidence to better enable ethical application and translation of algorithms in medicine.",Stakeholder Guidance to Anticipate and Address Ethical Challenges in Applications of Machine Learning and Artificial Intelligence in Algorithmic Medicine: a Novel Empirical Approach,10099785,R01TR003505,"['Address', 'Adoption', 'Affect', 'Agreement', 'Algorithm Design', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Attitude', 'Awareness', 'Clinical', 'Clinical Investigator', 'Complex', 'Data', 'Decision Making', 'Development', 'Diagnosis', 'Dimensions', 'Disclosure', 'Disease Management', 'Effectiveness', 'Empirical Research', 'Employee', 'Ensure', 'Ethical Issues', 'Ethicists', 'Ethics', 'Evaluation', 'Expert Systems', 'Explosion', 'Face', 'Failure', 'Familiarity', 'Funding', 'Future', 'Goals', 'Health', 'Healthcare Systems', 'Human', 'Human Resources', 'Individual', 'Interview', 'Investigation', 'Judgment', 'Justice', 'Knowledge', 'Learning', 'Machine Learning', 'Medical', 'Medicine', 'Methodology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Perception', 'Persons', 'Physicians', 'Play', 'Randomized', 'Research', 'Research Personnel', 'Role', 'Science', 'Shapes', 'Societies', 'Structure', 'Surveys', 'System', 'Time', 'Training', 'Translations', 'Trust', 'United States National Institutes of Health', 'Universities', 'Work', 'clinical decision-making', 'clinical risk', 'cost', 'court', 'deep learning algorithm', 'evidence base', 'experience', 'improved', 'innovation', 'insight', 'meetings', 'multidisciplinary', 'novel', 'patient population', 'population health', 'precision medicine', 'prevent', 'recruit', 'response', 'tool']",NCATS,STANFORD UNIVERSITY,R01,2020,429327,560644462,-0.010194001813541681
"Designing neutralization antibodies against Sars-Cov-2 Project Summary COVID-19 has become a worldwide pandemic whose rapid spread and mortality rate threatens millions of lives and the global economic system. Developing effective treatment such as neutralization antibodies is an urgent need. We propose here to develop a new method to design antibodies strongly bind to the SARS-CoV-2 receptor binding domain (RBD) that is necessary for viral entrance to human cells. We will develop a novel approach that combines directed evolution, deep sequencing and interpretable neural network models to efficiently identify strong and specific antibodies. This method will allow analyzing large sequencing data sets of antibody variants against the SARS-CoV-2 RBD in order to derive superior binders that do not exist in the original library. Iteration through directed evolution and computational design will efficiently identify neutralization antibody candidates that can be used as potent therapeutics to treat COVID-19. Narrative: Developing neutralization antibodies is critical to provide effective treatment for Covid-19.",Designing neutralization antibodies against Sars-Cov-2,10173204,R21AI158114,"['2019-nCoV', 'Affinity', 'Amino Acids', 'Antibodies', 'Binding', 'COVID-19', 'Cells', 'Cessation of life', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Directed Molecular Evolution', 'Economics', 'Epitopes', 'Future', 'Gene Library', 'Histones', 'Human', 'Human Engineering', 'Immunoglobulin G', 'Lead', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Mutate', 'Mutation', 'Nature', 'Network-based', 'Neural Network Simulation', 'Peptides', 'Positioning Attribute', 'Process', 'Reporting', 'Resistance', 'Screening procedure', 'Solubility', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Variant', 'Viral', 'Virus', 'Virus Diseases', 'base', 'clinical efficacy', 'data archive', 'deep learning', 'deep sequencing', 'design', 'drug candidate', 'effective therapy', 'machine learning method', 'mortality', 'mutant', 'neural network', 'neutralizing antibody', 'novel strategies', 'pandemic disease', 'receptor binding', 'screening', 'trend']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2020,433750,524978793,-0.020686519993883167
"DEVELOP NOVEL DEEP LEARNING AND COMBINATORIAL OPTIMIZATION METHODS TO IDENTIFY KEY DISEASE REGULATORY ELEMENTS FOR SINGLE-CELL DATA Contact Principal Investigator / Project Leader: Yang, Mary Organization: University of Arkansas Little Rock Title: DEVELOP NOVEL DEEP LEARNING AND COMBINATORIAL OPTIMIZATION METHODS TO IDENTIFY KEY DISEASE REGULATORY ELEMENTS FOR SINGLE-CELL DATA Abstract Text: Description: Traditional bulk sequencing measures the average of cell population constituents, inevitably masking the intrinsic cell-to-cell heterogeneity. Single-cell technologies, on the other hand, enable a high-resolution measurement for each individual cell, providing new opportunities to capture cell population diversity and dissect the heterogeneity of complex diseases. Meanwhile, the high-sparsity and the relatively small number of sequencing reads pose new data analytic challenges. In this proposed project, we will develop innovative computational methods for single-cell RNA sequencing (scRNA-seq) data analysis and integration to identify key regulatory elements that underlie disease heterogeneity and drive disease development. The scRNA-seq data contains substantial proportion of zero expression counts due to low capture efficiency and stochastic gene expression. We will develop a novel data-driven deep learning model to recover the missing values. Our model utilizes a deep learning algorithm to capture complex and latent distributions of missing values without assuming an underlying distribution, thus, ensuring effective performance across various scRNA-seq generated by different protocols. scRNA-seq profiles enable characterization of unique transcriptome for each cell type. We hypothesize that disrupted expression patterns accompanying the disease development in different cell types are controlled by sequential alterations of the activity and connectivity in the regulatory networks. Hence, using scRNA-seq data, we will first infer cell lineage trajectories. Then, we will develop a novel deep neural network method to reconstruct cellular regulatory networks according to pseudo-time ordering of the cell types. With a new network alignment model, we will exploit the dynamic changes of regulations in the disease process, revealing key regulators and providing cell type-specific drug targets. The fulfillment of the proposed project will facilitate single-cell genomic and biomedical research efforts allowing for a much broader, cross-disciplinary understanding of the underlying mechanisms of complex diseases. The proposed project will be devised into capstone projects and will be primarily completed by undergraduate students under the PI's supervision with the assistance of a graduate student. The project will serve as a vehicle to equip undergraduate students with essential research skills and interdisciplinary knowledge, and to stimulate the students' ambition to pursue careers in the biomedical science. This project will create a multidisciplinary platform in a comprehensive university setting that encourages undergraduate students to engage in biomedical research.! Public Health Relevance Statement: This R15 project aims to provide novel deep learning and hybrid statistical methods to tackle challenges with a focus on single-cell genomic data to improve our understanding of disease evolution mechanisms and advance treatment strategies for the complex diseases. Our approaches enable the reconstruction of cell type-specific regulatory networks and infer dysregulated pathways in different cell types and the integration of the research efforts made on the bulk-level, hence, lead to further discoveries, accurate diagnosis and new cell type-specific therapies. With the processes of this R15 project, we will engage and continue to recruit undergraduate students from diverse backgrounds focusing on their research skills development and incorporate the scientific investigations for this project into their college education and provide broader careers.",DEVELOP NOVEL DEEP LEARNING AND COMBINATORIAL OPTIMIZATION METHODS TO IDENTIFY KEY DISEASE REGULATORY ELEMENTS FOR SINGLE-CELL DATA,9965550,R15GM137288,"['Accountability', 'Arkansas', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Differentiation process', 'Cell Lineage', 'Cells', 'Combinatorial Optimization', 'Complex', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Development', 'Disease', 'Drug Targeting', 'Education', 'Educational Models', 'Ensure', 'Evolution', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic Programming', 'Genetic Transcription', 'Genomics', 'Heterogeneity', 'Hybrids', 'Individual', 'Information Sciences', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Masks', 'Measurable', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Noise', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Philosophy', 'Population', 'Population Heterogeneity', 'Principal Investigator', 'Process', 'Production', 'Protocols documentation', 'Regulation', 'Regulatory Element', 'Reporting', 'Research', 'Research Activity', 'Resolution', 'Resources', 'Schedule', 'Scholarship', 'Science', 'Signal Pathway', 'Signal Transduction', 'Statistical Methods', 'Students', 'Supervision', 'Technology', 'Text', 'Therapeutic', 'Time', 'Training', 'Transference', 'Universities', 'Work', 'Yang', 'accurate diagnosis', 'base', 'career', 'cell type', 'college', 'data integration', 'data modeling', 'deep learning', 'deep learning algorithm', 'deep neural network', 'differential expression', 'disease heterogeneity', 'education research', 'genomic data', 'graduate student', 'improved', 'innovation', 'insight', 'multidisciplinary', 'novel', 'pedagogy', 'precision medicine', 'public health relevance', 'reconstruction', 'recruit', 'single cell sequencing', 'single cell technology', 'single-cell RNA sequencing', 'skill acquisition', 'skills', 'success', 'transcriptome', 'treatment strategy', 'undergraduate student']",NIGMS,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R15,2020,443854,443854,-0.006410902401212671
"Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models Project Summary Amyotrophic lateral sclerosis (ALS) and Frontotemporal Dementia FTD are devastating neurodegenerative disorders that lie on a genetic and mechanistic continuum. ALS is a disease of motor neurons that that is almost uniformly lethal within only 3-5 years of diagnosis. FTD is a heterogeneous, rapidly progressing syndrome that is among the top three causes of presenile dementia. About 10% of ALS cases are caused by dominantly transmitted gene defects. SOD1 and FUS mutations cause aggressive motor neuron pathology while TDP43 mutations cause ALS-FTD. Further, wild type FUS and TDP43 are components of abnormal inclusions in many FTD cases, suggesting a mechanistic link between these disorders. Early phenotypes are of particular interest because these could lead to targeted interventions aimed at the root cause of the disorder that could stem the currently inexorable disease progression. Elucidating such early, potentially shared characteristics of these disorders should be greatly aided by: 1) knock-in animal models expressing familial ALS-FTD genes; 2) sensitive, rigorous and objective behavioral phenotyping methods to analyze and compare models generated in different laboratories. In published work the co-PIs applied their first-generation, machine vision-based automated phenotyping method, ACBM ‘1.0’ (automated continuous behavioral monitoring) to detect and quantify the earliest-observed phenotypes in Tdp43Q331K knock-in mice. This method entails continuous video recording for 5 days to generate >14 million frames/mouse. These videos are then scored by a trained computer vision system. In addition to its sensitivity, objectivity and reproducibility, a major advantage of this method is the ability to acquire and archive video recordings and to analyze the data at sites, including the Cloud, remote from those of acquisition. We will use Google Cloud TPUs supercomputers that have been designed from the ground up to accelerate cutting-edge machine learning workloads, with a special focus on deep learning. We will analyze this data using Bayesian hierarchical spline models that describe the different mouse behaviors along the circadian rhythm. The current proposal has two main goals: 1) Use deep learning to refine and apply a Next Generation ACBM - ‘2.0’ - that will allow for more sensitive, expansive and robust automated behavioral phenotyping of four novel knock-in models along with the well characterized SOD1G93A transgenic mouse. 2) To establish and validate procedures to enable remote acquisition of video recording data with cloud-based analysis. Our vision is to establish sensitive, robust, objective, and open-source machine vision-based behavioral analysis tools that will be widely available to researchers in the field. Since all the computer-annotated video data is standardized in ACBM 2.0 and will be archived, we envision a searchable ‘behavioral database’, that can be freely mined and analyzed. Such tools are critical to accelerate the development of novel and effective therapeutics for ALS-FTD. Narrative ALS and Frontotemporal Dementia (FTD) are devastating, rapidly progressing diseases and current treatments are of limited value. In this proposal a neuroscientist and a computer scientist have teamed up to develop a new machine vision-based method for behavioral analysis novel mouse models of ALS-FTD. The ultimate goal is to reveal early phenotypes in ALS-FTD models that can be used in understanding disease pathology and in the development of new therapeutic targets.",Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models,9979408,R21NS112743,"['Amyotrophic Lateral Sclerosis', 'Animal Model', 'Archives', 'Behavior', 'Behavior monitoring', 'Behavioral', 'Characteristics', 'Circadian Rhythms', 'Computer Vision Systems', 'Computers', 'Data', 'Data Set', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Expression Profiling', 'Familial Amyotrophic Lateral Sclerosis', 'Frontotemporal Dementia', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Goals', 'Hour', 'Human', 'Intervention', 'Knock-in', 'Knock-in Mouse', 'Laboratories', 'Lead', 'Link', 'Machine Learning', 'Methods', 'Modeling', 'Motor Neuron Disease', 'Motor Neurons', 'Mus', 'Mutation', 'Neurodegenerative Disorders', 'Paralysed', 'Pathology', 'Phenotype', 'Plant Roots', 'Presenile Dementia', 'Procedures', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Respiratory Paralysis', 'Scientist', 'Site', 'Standardization', 'Syndrome', 'TensorFlow', 'Time', 'Training', 'Transgenic Mice', 'Transgenic Organisms', 'Treatment Efficacy', 'Video Recording', 'Vision', 'Work', 'Workload', 'base', 'behavioral phenotyping', 'cloud based', 'data archive', 'deep learning', 'design', 'frontotemporal lobar dementia-amyotrophic lateral sclerosis', 'interest', 'knockin animal', 'machine vision', 'mouse model', 'new therapeutic target', 'next generation', 'novel', 'open source', 'programs', 'protein TDP-43', 'stem', 'supercomputer', 'superoxide dismutase 1', 'tool']",NINDS,BROWN UNIVERSITY,R21,2020,446875,127562714,0.0004356847553961942
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10029418,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2020,447500,327644200,0.001364847332812337
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and affect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable of discovering local and global alteration of matter without the need to apriori select an anatomical region of interest. The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image datasets is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focuses on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10139715,R42MH118845,"['Affect', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Blood flow', 'Brain', 'Clinical', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Data Set', 'Databases', 'Detection', 'Deterioration', 'Diffuse', 'Disease', 'Drug Screening', 'Goals', 'Grain', 'HIV', 'Image', 'Image Analysis', 'Internet', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Measures', 'Medical Imaging', 'Metabolic', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurologic', 'Neurologic Effect', 'Neurosurgeon', 'Online Systems', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Analysis', 'Population Study', 'Positioning Attribute', 'Process', 'Questionnaires', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Software Validation', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Variant', 'Visualization', 'Washington', 'analysis pipeline', 'base', 'data access', 'data infrastructure', 'deep learning', 'experience', 'gray matter', 'high throughput screening', 'image registration', 'imaging capabilities', 'improved', 'insight', 'interest', 'metabolic rate', 'morphometry', 'nervous system disorder', 'neurodegenerative dementia', 'novel', 'programs', 'prototype', 'regional difference', 'research and development', 'shape analysis', 'software development', 'software infrastructure', 'task analysis', 'tool', 'usability', 'web app', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R42,2020,456359,5161939,-0.009503156458966896
"Novel Statistical Inference for Biomedical Big Data Project Summary This project develops novel statistical inference procedures for biomedical big data (BBD), including data from diverse omics platforms, various medical imaging technologies and electronic health records. Statistical inference, i.e., assess- ing uncertainty, statistical signiﬁcance and conﬁdence, is a key step in computational pipelines that aim to discover new disease mechanisms and develop effective treatments using BBD. However, the development of statistical inference procedures for BBD has lagged behind technological advances. In fact, while point estimation and variable selection procedures for BBD have matured over the past two decades, existing inference procedures are either limited to simple methods for marginal inference and/or lack the ability to integrate biomedical data across multiple studies and plat- forms. This paucity is, in large part, due to the challenges of statistical inference in high-dimensional models, where the number of features is considerably larger than the number of subjects in the study. Motivated by our team's extensive and complementary expertise in analyzing multi-omics data from heterogenous studies, including the TOPMed project on which multiple team members currently collaborate, the current proposal aims to address these challenges. The ﬁrst aim of the project develops a novel inference procedure for conditional parameters in high-dimensional models based on dimension reduction, which facilitates seamless integration of external biological information, as well as biomedical data across multiple studies and platforms. To expand the application of this method to very high-dimensional models that arise in BBD applications, the second aim develops a data-adaptive screening procedure for selecting an optimal subset of relevant variables. The third aim develops a novel inference procedure for high-dimensional mixed linear models. This method expands the application domain of high-dimensional inference procedures to studies with longitu- dinal data and repeated measures, which arise commonly in biomedical applications. The fourth aim develops a novel data-driven procedure for controlling the false discovery rate (FDR), which facilitates the integration of evidence from multiple BBD sources, while minimizing the false negative rate (FNR) for optimal discovery. Upon evaluation using ex- tensive simulation experiments and application to multi-omics data from the TOPMed project, the last aim implements the proposed methods into easy-to-use open-source software tools leveraging the R programming language and the capabilities of the Galaxy workﬂow system, thus providing an expandable platform for further developments for BBD methods and tools. Public Health Relevance Biomedical big data (BBD), including large collections of omics data, medical imaging data, and electronic health records, offer unprecedented opportunities for discovering disease mechanisms and developing effective treatments. However, despite their tremendous potential, discovery using BBD has been hindered by computational challenges, including limited advances in statistical inference procedures that allow biomedical researchers to investigate uncon- founded associations among biomarkers of interest and various biological phenotypes, while integrating data from multiple BBD sources. The current proposal bridges this gap by developing novel statistical machine learning methods and easy-to-use open-source software for statistical inference in BBD, which are designed to facilitate the integration of data from multiple studies and platforms.",Novel Statistical Inference for Biomedical Big Data,9969887,R01GM133848,"['Address', 'Adoption', 'Behavioral', 'Big Data Methods', 'Biological', 'Biological Assay', 'Biological Markers', 'Code', 'Collection', 'Communities', 'Computer software', 'Data', 'Data Sources', 'Development', 'Dimensions', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Galaxy', 'Genetic study', 'Goals', 'Heart', 'Imaging technology', 'Individual', 'Linear Models', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular', 'Multiomic Data', 'Outcome', 'Phenotype', 'Procedures', 'R programming language ', 'Research Personnel', 'Sample Size', 'Scientist', 'Screening procedure', 'Software Tools', 'Structure', 'System', 'Testing', 'Trans-Omics for Precision Medicine', 'Uncertainty', 'Work', 'base', 'big biomedical data', 'computational pipelines', 'data integration', 'design', 'diverse data', 'effective therapy', 'experimental study', 'heterogenous data', 'high dimensionality', 'interest', 'machine learning method', 'member', 'novel', 'open source', 'public health relevance', 'screening', 'simulation', 'statistical and machine learning', 'structured data', 'tool', 'treatment strategy', 'user friendly software']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,456980,533302350,-0.0015064013912804118
"Scientific Questions: A New Target for Biomedical NLP Project Summary  Natural language processing (NLP) technology is now widespread (e.g. Google Translate) and has several important applications in biomedical research. We propose a new target for NLP: extraction of scientific questions stated in publications. A system that automatically captures and organizes scientific questions from across the biomedical literature could have a wide range of significant impacts, as attested to in our diverse collection of support letters from researchers, journal editors, educators and scientific foundations. Prior work focused on making binary (or probabilistic) assessments of whether a text is hedged or uncertain, with the goal of downgrading such statements in information extraction tasks—not computationally capturing what the uncertainty is about. In contrast, we propose an ambitious plan to identify, represent, integrate and reason about the content of scientific questions, and to demonstrate how this approach can be used to address two important new use cases in biomedical research: contextualizing experimental results and enhancing literature awareness. Contextualizing results is the task of linking elements of genome-scale results to open questions across all of biomedical research. Literature awareness is the ability to understand important characteristics of large, dynamic collections of research publications as a whole. We propose to produce rich computational representations of the dynamic evolution of research questions, and to prototype textual and visual interfaces to help students and researchers explore and develop a detailed understanding of key open scientific questions in any area of biomedical research. Project Narrative The scientific literature is full of statements of important unsolved questions. By using artificial intelligence systems to identify and categorize these questions, the proposed work would help other researchers discover when their findings might address an important question in another scientific area. This work would also make it easier for students, journal editors, conference organizers and others understand where science is headed by tracking the evolution of scientific questions.",Scientific Questions: A New Target for Biomedical NLP,10069773,R01LM013400,"['Address', 'Area', 'Artificial Intelligence', 'Awareness', 'Biomedical Research', 'Characteristics', 'Collection', 'Computerized Patient Records', 'Cues', 'Data', 'Elements', 'Environment', 'Evolution', 'Expert Systems', 'Foundations', 'Genes', 'Goals', 'Gold', 'Information Retrieval', 'Journals', 'Letters', 'Link', 'Literature', 'Manuals', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Phenotype', 'Proteomics', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Semantics', 'Services', 'Signal Transduction', 'Source', 'Students', 'System', 'Taxonomy', 'Technology', 'Text', 'Time', 'Translating', 'Uncertainty', 'Update', 'Visual', 'Work', 'design', 'dynamical evolution', 'experimental study', 'genome wide association study', 'genome-wide', 'graduate student', 'high throughput screening', 'innovation', 'journal article', 'news', 'novel', 'pharmacovigilance', 'prototype', 'symposium', 'text searching', 'tool', 'transcriptome sequencing', 'trend']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2020,462393,292134808,-0.0004222664784902235
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9979659,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'MeSH Thesaurus', 'Measures', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'large scale data', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'public repository', 'specific biomarkers']",NLM,UNIVERSITY OF CENTRAL FLORIDA,U01,2020,467177,16827427,0.0032234255516245367
"Next Generation Testing Strategies for Assessment of Genotoxicity Project Summary  It is well recognized that current batteries of genetic toxicology assays exhibit two critical deficiencies. First, the throughput capacity of in vitro mammalian cell genotoxicity tests is low, and does not meet current needs. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no consideration for potency, and virtually no information is provided about molecular targets and mechanisms. These deficiencies in hazard characterization prevent genotoxicity data from optimally contributing to modern risk assessments, where this information is essential. We will address these major problems with current in vitro mammalian cell genetic toxicity assays by developing methods and associated commercial assay kits that dramatically enhance throughput capacity, and delineate genotoxicants' primary molecular targets, while simultaneously providing information about potency. Once biomarkers and a family of multiplexed assays have been developed for these purposes, an interlaboratory trial will be performed with prototype assay kits to assess the transferability of the methods. Project Narrative  DNA damage that cannot be faithfully repaired results in gene mutation and/or chromosomal aberrations, and these effects are known to contribute to cancer and other severe diseases. Thus, there is an important need for sensitive assays to evaluate chemicals for genotoxic and other deleterious effects. The work proposed herein will address issues that have plagued genotoxicity assessments for the last several decades: low throughput, lack of potency metrics, and little to no information about molecular targets. We will address these major problems with current genetic toxicity assays by developing new methods and associated commercial assay kits.",Next Generation Testing Strategies for Assessment of Genotoxicity,9838229,R44ES029014,"['Address', 'Affect', 'Aneugens', 'Antioxidants', 'Appearance', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Biological Response Modifiers', 'Bleomycin', 'Caspase', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemicals', 'Chromosome abnormality', 'Chromosomes', 'Classification', 'Cleaved cell', 'Colcemid', 'Companions', 'Complex', 'Computer Models', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'DNA-PKcs', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Dose', 'Epitopes', 'Etoposide', 'Exhibits', 'Family', 'GADD45A gene', 'Gamma-H2AX', 'Gene Mutation', 'Genetic', 'Goals', 'Harvest', 'Histone H3', 'Human', 'In Vitro', 'Intercalating Agents', 'Investigation', 'Kinetics', 'Label', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Modification', 'Molecular Target', 'Mutagenicity Tests', 'NF-kappa B', 'Nuclear', 'Pathway interactions', 'Phase', 'Physiologic pulse', 'Procedures', 'Protocols documentation', 'Reagent', 'Reference Values', 'Risk Assessment', 'Schedule', 'Scheme', 'Series', 'Stains', 'TP53 gene', 'Testing', 'Time', 'Toxic effect', 'Toxicogenetics', 'Training', 'Validation', 'Work', 'aurora kinase', 'base', 'clastogen', 'computerized tools', 'design', 'experimental study', 'genotoxicity', 'hazard', 'inhibitor/antagonist', 'next generation', 'prediction algorithm', 'prevent', 'prototype', 'random forest', 'repaired', 'response', 'targeted agent', 'tool', 'treatment optimization', 'virtual']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2020,474671,651293,-0.011034855094520369
"Predicting Human Olfactory Perception from Molecular Structure PROJECT SUMMARY Modern technology makes it possible to capture a visual scene as a photograph, alter it, send it to another country nearly instantaneously, and store it without concern for degradation. None of this is currently possible in olfaction. Although perfumers and flavorists are adept at mixing odorous molecules to produce a desired perceptual effect, the rules underlying this process are poorly understood at a quantitative level. Current methods for displaying odors to a subject are akin to requiring a Polaroid of every visual stimulus of interest. A more efficient method for probing the olfactory system would be to use a set of 'primary odors'—some limited number of odors from which all other complex odors could be reproduced by appropriate mixtures. Both auditory and visual stimuli have been digitized, and this will eventually be possible in olfaction as well. Predicting odor from chemical structure has been a problem in the field since its inception, but recent advances in machine learning algorithms have made great progress in analogous problems, such as facial recognition. The research proposed here will combine these machine learning techniques with high quality human psychophysics to understand how to predict the smell of a molecule or mixture of odorants, which will ultimately help improve our understanding of disease diagnosis using odors as well as eating-related health and illness. HEALTH RELEVANCE The sense of smell plays a critical role in preferences and aversions for specific foods. The proposed research will combine machine learning techniques with high quality human psychophysics to create a model that can predict the smell of odorous molecules. This model will allow us to describe and control odors, which will increase our understanding of food preference and eating-related health and wellness.",Predicting Human Olfactory Perception from Molecular Structure,9887973,R01DC017757,"['Algorithms', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Code', 'Collection', 'Color', 'Communities', 'Complex', 'Complex Mixtures', 'Country', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Eating', 'Enrollment', 'Face', 'Food', 'Food Preferences', 'Frequencies', 'Health', 'Human', 'Ligands', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Molecular Structure', 'Neurosciences', 'Non-linear Models', 'Numerical value', 'Odors', 'Olfactory Pathways', 'Perception', 'Play', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Role', 'Smell Perception', 'Stimulus', 'Techniques', 'Technology', 'Training', 'Translating', 'Vision', 'Visual', 'Vocabulary', 'Work', 'auditory stimulus', 'base', 'computer monitor', 'disease diagnosis', 'experience', 'high dimensionality', 'improved', 'in silico', 'interest', 'machine learning algorithm', 'member', 'novel', 'physical property', 'predictive modeling', 'predictive test', 'preference', 'receptor', 'relating to nervous system', 'single molecule', 'visual stimulus']",NIDCD,MONELL CHEMICAL SENSES CENTER,R01,2020,496911,6406933,-0.011354988213204967
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10017950,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,513041,641965656,0.004054461492287791
"Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye Age-related macular degeneration (AMD) is the leading cause of blindness in the elderly in the developed world; no cure exists and prevalence is rising rapidly. Because only primates have a macula and since no model of AMD exists in non-human primates, the disease course can only be elucidated through in-depth study of humans. Blindness in AMD is caused by progressive and irreversible death of rod and cone photoreceptors secondary to degeneration of the retinal pigment epithelium (RPE) that is essential for their health and function. Clinical imaging and histology have informed us greatly about the later stages of disease but fundamental knowledge to understand how AMD diverges from normal aging at onset is lacking. With advanced adaptive optics ophthalmoscopy (AOO) imaging methods, combined with clinical imaging and visual function testing, we will characterize healthy human retinal aging in cross-sectional study, by defining the in vivo RPE-photoreceptor cellular organization and microscopic autofluorescence variation with age and wavelength. This will produce the largest quantitative in vivo normative dataset of AOO cell-based metrics to date and we will use this data to generate new quantitative analysis tools needed to evaluate emerging therapies designed to prevent or slow vision loss in AMD (Aim 1). In a case-control study, we will then compare normal photoreceptor topography and RPE cell morphometry to clinically defined early AMD to quantitatively define the earliest cellular changes in AMD that can be detected in vivo. This work will identify the cellular alterations and phenotypes that differentiate normal aging from early AMD to facilitate early onset detection. These results will be contextualized by comparison to tissue-level alterations seen with aging and early AMD in clinical imaging, specifically choriocapillaris decline and drusen (Aim 2). The results of this study will result in a paradigm shift from the use of clinical diagnosis and classification systems for AMD that rely solely on tissue- level biomarkers or traditional funduscopic clinical signs to those that rely on rigorous quantitative in vivo cell- based metrics. Together, this knowledge and these tools will lay the foundation needed to develop and evaluate new preventative therapies that are needed to limit or prevent vision loss in AMD. Project Narrative Age-related macular degeneration is the leading cause of blindness in the elderly in the US and is a significant public health issue that is projected to worsen due to the rapidly aging population. Here we aim to understand how retinal cells change in normal aging and how these normal age-related changes differ from the changes that lead to age-related macular degeneration. This project will allow us to detect age-related macular degeneration earlier and will produce new tools to monitor retinal cells that will facilitate the development and testing of preventative therapies to slow or prevent vision loss in age-related macular degeneration.",Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye,9973645,R01EY030517,"['Age', 'Age related macular degeneration', 'Aging', 'Area', 'Atrophic', 'Biological Markers', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Case-Control Studies', 'Cells', 'Cessation of life', 'Choroid', 'Classification', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Cross-Sectional Studies', 'Cytoplasmic Granules', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic Procedure', 'Disease', 'Drusen', 'Elderly', 'Evaluation', 'Eye', 'Foundations', 'Genetic', 'Goals', 'Health', 'Histology', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Lead', 'Lipofuscin', 'Machine Learning', 'Maps', 'Melanins', 'Methods', 'Microscopic', 'Modeling', 'Monitor', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Perfusion', 'Phenotype', 'Photoreceptors', 'Prevalence', 'Preventive therapy', 'Preventive treatment', 'Primate Diseases', 'Primates', 'Public Health', 'Retina', 'Retinal Cone', 'Retinal Degeneration', 'Retinal Photoreceptors', 'Risk', 'Secondary to', 'Spatial Distribution', 'Structure', 'Structure of retinal pigment epithelium', 'System', 'Techniques', 'Technology', 'Testing', 'Therapy Evaluation', 'Time', 'Tissues', 'Variant', 'Vertebrate Photoreceptors', 'Vision', 'Work', 'adaptive optics', 'age related', 'aging population', 'base', 'clinical Diagnosis', 'clinical decision-making', 'clinical imaging', 'cohort', 'early onset', 'fluorophore', 'healthy aging', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'macula', 'morphometry', 'multimodality', 'neurovascular unit', 'nonhuman primate', 'normal aging', 'prevent', 'restorative treatment', 'retinal imaging', 'retinal rods', 'therapy design', 'tool']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,527040,570146095,-0.016481834760155707
"SPOTs: Optical Technologies for Instantly Quantifying Multicellular Response Profiles PROJECT SUMMARY/ABSTRACT Human organ systems require temporally and spatially coordinated multicellular actions at a macroscale to actuate, sustain, or terminate dedicated and vital functions. Cells that comprise discrete or distributed physiologic systems that fail to respond to appropriate stimuli with coordination may cause significant morbidity and often mortality. Collective and coordinated physiologic activities typically involve millions to billions of cells that may span large physical distances. Technologies for quantifying the electrical, chemical, and mechanical coupling in these multicellular systems are critically important to understanding the underlying mechanisms of disease and develop therapeutic approaches. However, no technology currently exists to quantify rapid mechanical cell responses to transmitted distal perturbations for all cells within a collection of cells. This multi- PI proposal (Chiou (contact PI) and Teitell) aims to develop a new platform imaging technology called SPOT (single pixel optical technology) for concurrent and direct measurements of cellular traction forces over a 1.0 x 1.0 cm2 field of view (FOV) with cellular spatial resolution, and a 1,000 frames/sec temporal resolution. SPOT provides a 4-order of magnitude larger FOV than conventional traction force microscopy. Cardiomyocytes (CMs) are the test bed here because of a high potential for impact in cardiovascular disease, the leading cause of mortality in the Western World. We will demonstrate the ability for SPOT to determine quantitative indices of abnormalities for human CM contraction and relaxation in healthy and diseased states. We will establish proof of concept studies in SPOT screens for small molecules that augment or affect CM contraction in desmoplakin deficient states. We will build a platform that integrates SPOT for direct contraction force measurements and Optical Mapping for electrical property measurements for sheets of CMs. This will enable, for the first time, studies of temporal and spatial electromechanical coupling behaviors for sheets of CMs at single cell resolution. We will distinguish different subtypes of CMs, their distributions, their interactions, and their phenotypic responses under external perturbations. And we will apply this platform to investigate the structural and electromechanical coupling properties of hESC-derived CMs by integrating quantitative biomass and stiffness data measured using non-invasive live cell interferometry (LCI). Changes in biomass and cell stiffness are druggable biophysical parameters with correlates to mechanical contraction/relaxation cycles of CMs. In addition to detailed studies of CMs that have the potential to impact the number one killer of US citizens, SPOT applications should have utility and provide new insights in additional settings that require cell or tissue traction-force generation. Such settings could include models in a dish for wound healing, cancer cell metastasis, or models of diseases that affect cell and tissue structural integrity, such as connective tissue disorders Ehlers-Danlos or Marfan syndromes. PROJECT NARATIVE Our proposal is exclusively technology development but portends public health relevance because we will invent a way to quantify previously undiscoverable interactions and mechanical responses to external and internal perturbations in interconnected biological systems, as occurs in physiologic and pathologic states. We will develop, test and fine-tune a new technology platform called SPOT (Single Pixel Optical Technology) to extract mechanical responses at cellular resolution in a very wide field, in real-time, concurrently for all cells in a sheet to enable studies and potentially new-age therapeutics that are currently impossible.",SPOTs: Optical Technologies for Instantly Quantifying Multicellular Response Profiles,9972477,R01GM127985,"['Address', 'Affect', 'Age', 'Area', 'Arrhythmogenic Right Ventricular Dysplasia', 'Beds', 'Behavior', 'Biomass', 'Cardiac', 'Cardiac Myocytes', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Collection', 'Color', 'Connective Tissue Diseases', 'Coupling', 'Data', 'Defect', 'Development', 'Disease', 'Disease model', 'Distal', 'Drug Screening', 'Electrophysiology (science)', 'Fibroblasts', 'Future', 'Generations', 'Genes', 'Genetic Diseases', 'Giant Cells', 'Goals', 'Heart Atrium', 'Human', 'Imaging technology', 'Interferometry', 'Left', 'Machine Learning', 'Marfan Syndrome', 'Measurement', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Neoplasm Metastasis', 'Optics', 'Pathologic', 'Pharmacology Study', 'Phenotype', 'Physiological', 'Population', 'Process', 'Property', 'Relaxation', 'Reporting', 'Resolution', 'Series', 'Spottings', 'Stimulus', 'Structure', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Traction', 'Traction Force Microscopy', 'Transplantation', 'Ventricular', 'Western World', 'biological systems', 'biophysical properties', 'body system', 'cancer cell', 'design', 'desmoplakin', 'electrical measurement', 'electrical property', 'human embryonic stem cell', 'human pluripotent stem cell', 'imaging platform', 'improved', 'indexing', 'insight', 'instrument', 'mechanical properties', 'mortality', 'new technology', 'patch clamp', 'prospective', 'public health relevance', 'regenerative', 'response', 'screening', 'small molecule', 'technology development', 'temporal measurement', 'tool', 'wound healing']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,530374,673201228,-0.004231545200966919
"An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics Immune-repertoire sequence, which consists of an individual's millions of unique antibody and T-cell receptor (TCR) genes, encodes a dynamic and highly personalized record of an individual's state of health. Our long- term goal is to develop the computational models and tools necessary to read this record, to one day be able diagnose diverse infections, autoimmune diseases, cancers, and other conditions directly from repertoire se- quence. The key problem is how to find patterns of specific diseases in repertoire sequence, when repertoires are so complex. Our hypothesis is that a combination of bottom-up (sequence-level) and top-down (systems- level) modeling can reveal these patterns, by encoding repertoires as simple but highly informative models that can be used to build highly sensitive and specific disease classifiers. In preliminary studies, we introduced two new modeling approaches for this purpose: (i) statistical biophysics (bottom-up) and (ii) functional diversity (top-down), and showed their ability to elucidate patterns related to vaccination status (97% accuracy), viral infection, and aging. Building on these studies, we will test our hypothesis through two specific aims: (1) We will develop models and classifiers based on the bottom-up approach, statistical biophysics; and (2) we will de- velop the top-down approach, functional diversity, to improve these classifiers. To achieve these aims, we will use our extensive collection of public immune-repertoire datasets, beginning with 391 antibody and TCR da- tasets we have characterized previously. Our team has deep and complementary expertise in developing computational tools for finding patterns in immune repertoires (Dr. Arnaout) and in the mathematics that under- lie these tools (Dr. Altschul), with additional advice available as needed regarding machine learning (Dr. AlQuraishi). This proposal is highly innovative for how our two new approaches address previous issues in the field. (i) Statistical biophysics uses a powerful machine-learning method called maximum-entropy modeling (MaxEnt), improving on past work by tailoring MaxEnt to learn patterns encoded in the biophysical properties (e.g. size and charge) of the amino acids that make up antibodies/TCRs; these properties ultimately determine what targets antibodies/TCRs can bind, and therefore which sequences are present in different diseases. (ii) Functional diversity fills a key gap in how immunological diversity has been measured thus far, by factoring in whether different antibodies/TCRs are likely to bind the same target. This proposal is highly significant for (i) developing an efficient, accurate, generative, and interpretable machine-learning method for finding diagnostic patterns in repertoire sequence; (ii) applying a robust mathematical framework to the measurement of immuno- logical diversity; (iii) impacting clinical diagnostics; and (iv) adding a valuable new tool for integrative/big-data medicine. The expected outcome of this proposal is an integrated pair of robust and well validated new tools/models for classifying specific disease exposures directly from repertoire sequence. This proposal in- cludes plans to make these tools widely available, to maximize their positive impact across medicine. The proposed research is relevant to public health because B cells/antibodies and T cells play vital roles across such a vast range of health conditions, from infection, to autoimmunity, to cancer, that the ability to de- code what they are doing would be an important step forward for diagnosing these conditions. The proposed research is relevant to the NIH's mission of fostering fundamental creative discoveries, innovative research strategies, and their applications as a basis for ultimately protecting and improving health, specifically relating to the diagnosis of human diseases.",An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics,10050030,R01AI148747,"['Address', 'Affect', 'Aging', 'Amino Acid Motifs', 'Amino Acids', 'Antibodies', 'Autoimmune Diseases', 'Autoimmunity', 'B-Lymphocytes', 'Base Sequence', 'Big Data', 'Binding', 'Biophysics', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Code', 'Collection', 'Complex', 'Computer Models', 'Data Set', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Entropy', 'Fostering', 'Gene Frequency', 'Genes', 'Goals', 'Health', 'Human', 'Immune', 'Immunology', 'Individual', 'Infection', 'Influenza vaccination', 'Intuition', 'Learning', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mission', 'Modeling', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Physics', 'Play', 'Population Heterogeneity', 'Privatization', 'Property', 'Public Health', 'Reading', 'Reporting', 'Research', 'Role', 'Sample Size', 'Sampling', 'Sampling Errors', 'Signs and Symptoms', 'Speed', 'Statistical Study', 'System', 'T-Cell Receptor', 'T-Cell Receptor Genes', 'T-Lymphocyte', 'Testing', 'United States National Institutes of Health', 'Vaccination', 'Virus Diseases', 'Work', 'base', 'biophysical properties', 'clinical diagnostics', 'computerized tools', 'diagnostic accuracy', 'human disease', 'immunological diversity', 'improved', 'information model', 'innovation', 'machine learning method', 'multidisciplinary', 'multilevel analysis', 'novel', 'novel strategies', 'tool']",NIAID,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2020,535171,135941803,-0.008823877230751183
"Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system Abstract Numerous small vessels making up the central nervous system blood and lymphatic vascular networks are heterogeneous and region-specific dynamic structures, whose segments, position, shape and function can change in response to physiological and pathophysiological conditions. To date it has not been possible to integrate blood and lymphatic vascular elements and their microenvironment to achieve a holistic quantitative characterization of the combined brain and meningeal tissue-scale vascular networks, its structure and function in normal and disease states. This application proposes to develop microscopy- based high-throughput image analysis techniques for automated extraction of blood and lymphatic vascular networks enabling quantitative morphodynamic characterization of cerebrovascular microenvironment changes in two intracranial compartments – the brain and dura mater. The study will focus on new algorithms for precise region-specific microvessel registration, mosaicing, segmentation, fusion and colocalization for constructing large tissue scale spatially aligned dual blood/lymphatic vascular network structural maps in the animals of both sexes, as well as characterization of heterogeneities of microvascular networks, including blood and lymphatic vasculature, under estrogen and sleep deprivation (the conditions relevant to multiple cerebrovascular disorders) compared to physiological settings. In other words, advanced microscopy-based techniques will be used to image blood and lymphatic vessels at sub-micron resolution in dura mater and the brain, and then cutting-edge deep machine learning imaging analysis methods will be employed to segment and quantify these vessels, their geometry, vessel wall structure, functionality, and interrelationship. Detailed structural analysis of microvascular networks is essential for accurate evaluation of the distribution of physical forces, substrate delivery and tissue clearance of waste, as well as sex differences and consequences of intracranial networks remodeling under physiological and pathological conditions. This will create knowledge enabling a better understanding of the pathogenesis of vascular impairments under estrogen and sleep deprivation, identify common molecular mechanisms and the efficacy and effectiveness of different therapeutic treatments. Without the ability to construct total structural and functional blood/lymphatic vascular network maps from studies limited to individual tissue component parts, it is little wonder that translation from the molecular and cellular levels to the whole organ and system levels is deficient and hinders translational progress towards a comprehensive understanding of the pathophysiology associated with a range of neurological disorders. Detailed analysis of structural relationships of both blood and lymphatic circulation in the brain system will have a direct impact on our general understanding of vascular function in brain/meningeal communication, and the cause and resolution of numerous diseases resulting from intracranial vascular disorders including impact of sex hormone (estrogen) deprivation, sleep deprivation, migraines, stroke, multiple sclerosis, dural arterio-venous fistulae, intradural hygroma and hematoma, spontaneous cerebral spinal fluid leaks, and intradural aneurysms that can lead to the development of neurological and cognitive impairment, including Alzheimer's. Quantitative description of blood and lymphatic vessel network structures using image analytics and machine learning algorithms distributed as software tools will have broad applications to quantification of other thin complex curvilinear anatomical structures (i.e. nerves, neuronal circuits, neurons, and neuroglia). The new software for blood and vessel network measurement will enable translation of fundamental pathophysiological knowledge gained from this proposal towards the development and assessment of the effectiveness of treatments and therapeutic interventions to enhance health, lengthen life, and reduce illness and disability associated with a range of neurological disorders.",Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system,9914136,R01NS110915,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Aneurysm', 'Animals', 'Arteriovenous fistula', 'Blood', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Brain', 'Brain Mapping', 'Cardiovascular system', 'Cephalic', 'Cerebrospinal Fluid', 'Cerebrovascular Disorders', 'Chronic', 'Chronic Insomnia', 'Communication', 'Complex', 'Computer software', 'Cystic Lymphangioma', 'Detection', 'Development', 'Disease', 'Dura Mater', 'Dural Arteriovenous Fistulas', 'Effectiveness', 'Elements', 'Estrogens', 'Evaluation', 'Female', 'Functional disorder', 'Geometry', 'Gonadal Steroid Hormones', 'Health', 'Hematoma', 'Heterogeneity', 'Hybrids', 'Image', 'Image Analysis', 'Imaging Techniques', 'Impaired cognition', 'Impairment', 'Individual', 'Knowledge', 'Lead', 'Life', 'Link', 'Lymphatic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Meningeal', 'Metabolism', 'Methods', 'Microscopy', 'Migraine', 'Modeling', 'Molecular', 'Morphology', 'Mosaicism', 'Multiple Sclerosis', 'Mus', 'Nerve', 'Neuraxis', 'Neuroglia', 'Neurologic', 'Neurons', 'Optical Coherence Tomography', 'Parietal', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Physiological', 'Positioning Attribute', 'Resolution', 'Route', 'Sex Differences', 'Shapes', 'Site', 'Sleep', 'Sleep Deprivation', 'Sleep Disorders', 'Sleep disturbances', 'Software Tools', 'Stroke', 'Structure', 'Subdural Hematoma', 'Subdural Hygroma', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Thinness', 'Tissues', 'Translations', 'Treatment Effectiveness', 'Vascular Diseases', 'Vascular remodeling', 'Vascular resistance', 'Venous', 'associated symptom', 'base', 'body system', 'cerebral microvasculature', 'cerebrovascular', 'clinically relevant', 'confocal imaging', 'deep learning', 'deprivation', 'disability', 'geometric structure', 'in vivo', 'lymphatic circulation', 'lymphatic vasculature', 'lymphatic vessel', 'machine learning algorithm', 'male', 'microleakage', 'nervous system disorder', 'neuronal circuitry', 'noninvasive diagnosis', 'novel', 'response', 'sex', 'sleep pattern', 'solute', 'stem', 'submicron', 'tool', 'wasting']",NINDS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2020,540520,63611576,-0.014318657202621593
"Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS) Project Abstract  Per- and polyfluoroalkyl substances (PFAS) are a family of over 5000 man-made chemicals that are ubiquitous in the environment, due to their chemical stability and bioaccumulative properties. Many of these “forever chemicals” have been linked with health concerns, including strong evidence of developmental health and harm to hormone-sensitive tissues. Manufacturers continue to substitute new PFAS for which exposure- based health risks are unknown. There is an urgent public health need to determine the effects of PFAS in use on both mammary gland development and increased breast cancer incidence. Current exposure studies use rodent models that require cumbersome end-point analyses as well as large monetary and time investments.  Our proposal is aimed at developing an in vitro to in vivo extrapolation (IVIVE) pipeline of mammary gland development and maintenance to identify and prioritize potentially toxic PFAS, to ultimately mitigate number of animals needed for environmental exposure studies. Our approach is to develop in vitro models of the mammary gland of increasing complexity but decreasing throughput, identifying links between high-throughput and high- complexity model endpoint readouts to best prioritize large chemical libraries. A key technology to establish links across multiple in vitro culture platforms is optical coherence tomography-based structural-functional imaging (OCT-SFI), developed by MPI Oldenburg, which non-invasively visualizes label-free cells, their intracellular motility, and morphology of formed spheroids, within optically turbid tissue models.  Our first specific aim advances a high-throughput paper-based culture system, developed by MPI Lockett, to study mammary epithelial cell invasion in physiologically relevant tissue microenvironments. The platform will evaluate 96 different exposure conditions in parallel. Our second specific aim employs 3D co-culture models that include fibroblasts to model stromal signaling known to affect mammary gland development. OCT-SFI will provide cellular motility and morphology of the organotypic spheroids that form in these cultures. Finally, our third aim will screen a library of 40 PFAS, with a particular focus on the perfluoroethercarboxylic acids (PFECAs) currently used in industrial coatings. In addition, 12 PFAS will be screened for which there is existing in vivo rodent model data available, and comparisons between in vitro assay outputs and in vivo gland remodeling will be used to refine the assay models and establish initial thresholds for screening.  The models developed as part of this proposal will thus be predictive of biology, enabling the high-throughput capability needed for future screening of all PFAS as well as other emerging endocrine disruptors. The project’s risk is balanced by the known imaging capabilities of OCT-SFI to probe responses in 3D spheroid and paper- based co-cultures. The high-throughput nature of this IVIVE pipeline makes it ideal for screening libraries of potential toxicants, providing information-rich datasets of spatially and temporally resolved morphological and molecular changes across the tissue-like structures. Project Narrative This proposal aims to develop a pipeline to screen and prioritize libraries of potentially toxic man-made chemicals found in the environment for further analyses, with particular emphasis on per- and poly-fluoroalkyl substances (PFAS) of which there are over 5000 currently known. Current environmental exposure testing methods evaluate mammary gland development in live mice because the mammary gland is highly susceptible to chemical exposure; yet, such methods are slow and expensive. Our proposal uses mammary cell culture models in increasingly complex, tissue-like environments, in combination with high-speed 3D optical imaging techniques, and ultimately compare the platform with a few candidate PFAS against existing data in live mice, setting the stage for future high-throughput screening of potential environmental toxicants.",Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS),10152786,R01ES032730,"['3-Dimensional', 'Acids', 'Affect', 'Animals', 'Architecture', 'Biological Assay', 'Biology', 'Biometry', 'Breast Cancer Epidemiology', 'Breast Epithelial Cells', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Cellular Morphology', 'Characteristics', 'Chemical Exposure', 'Chemicals', 'Clinical Trials', 'Coculture Techniques', 'Complex', 'Data', 'Data Set', 'Development', 'Endocrine Disruptors', 'Environment', 'Environmental Exposure', 'Epithelial', 'Epithelium', 'Estrogen receptor positive', 'Exposure to', 'Family', 'Fiber', 'Fibroblasts', 'Functional Imaging', 'Future', 'Gene Proteins', 'Gland', 'Growth', 'Health', 'Hormones', 'Imaging Techniques', 'In Vitro', 'Incidence', 'Industrialization', 'Investments', 'Label', 'Libraries', 'Link', 'Maintenance', 'Malignant Neoplasms', 'Mammary gland', 'Manufacturer Name', 'Mesenchymal', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'Mus', 'National Institute of Environmental Health Sciences', 'Nature', 'North Carolina', 'Odds Ratio', 'Optical Coherence Tomography', 'Optics', 'Output', 'Paper', 'Pathology', 'Physiological', 'Poly-fluoroalkyl substances', 'Property', 'Public Health', 'Rattus', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Rodent', 'Rodent Model', 'S-Phase Fraction', 'Scanning', 'Scoring Method', 'Signal Transduction', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'Toxic Environmental Substances', 'Up-Regulation', 'Work', 'assay development', 'base', 'carcinogenesis', 'carcinogenicity', 'cell motility', 'chemical stability', 'data modeling', 'deep learning', 'deep learning algorithm', 'high throughput screening', 'imaging capabilities', 'in vitro Assay', 'in vitro Model', 'in vivo', 'intercellular communication', 'machine learning algorithm', 'malignant breast neoplasm', 'malignant phenotype', 'mammary epithelium', 'mammary gland development', 'man', 'model design', 'non-invasive imaging', 'novel', 'optical imaging', 'premalignant', 'protein biomarkers', 'response', 'screening', 'small molecule libraries', 'three dimensional cell culture', 'three-dimensional modeling', 'tool', 'toxicant']",NIEHS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,559511,511185245,-0.012381958700744105
"A Transfer Learning Framework for Creating Subject-Specific Musculoskeletal Models of the Hand PROJECT SUMMARY Restoring hand function remains an elusive goal for many clinical conditions, including stroke, osteoarthritis, tetraplegia, amputation, and traumatic injury. The hand’s anatomical complexity makes restoring hand function particularly challenging because altering any one parameter in the hand can have cascading effects that are difficult to predict, but essential to control. In this proposal, as a critical step toward informing personalized treatments for the hand, we will study how subject-specific differences influence hand function. Completion of this proposal will rely on collection of three datasets that are designed to provide varying levels of biomechanical detail and require varying levels of effort to collect. Briefly, these datasets include (1) a simulation dataset containing 500,000 simulations fully describing all musculoskeletal parameters involved in hand force production, (2) a dense, biomechanical datasets that describes the kinematics, kinetics, and muscle activity required for hand force production in 30 adults, and (3) a sparse, clinically-inspired dataset that describes demographics, anthropometrics, and clinical metrics of hand function in 1000 adults. In Aim 1, we will leverage the first two datasets to design a data-driven analysis framework that identifies the most important biomechanical parameter(s) and maps how those parameters influence hand force production. Completion of this aim will elucidate the biomechanical mechanisms that modulate hand force production and evaluate the ability to use simulation data, instead of experimental data, to identify these mechanisms. In Aim 2, we will leverage all three datasets to create a transfer learning framework capable of efficiently and accurately predicting subject-specific muscle force-generating parameters from easy to collect clinical data. We specifically focus on muscle force- generating parameters because these parameters remain challenging to quickly and accurately estimate, are known to vary across the population, and are highly related to functional metrics like strength. Completion of this aim will provide a new approach for rapidly estimating subject-specific musculoskeletal parameters, thereby enabling efficient creation of subject-specific models and potentially catalyzing use of such models in a clinical setting. Overall, the results from this study could enhance our ability to provide personalized diagnoses and prognoses for individuals suffering from hand impairments. PROJECT NARRATIVE The proposed project aims to understand the biomechanical mechanisms underlying force production in the hand. Specifically, we utilize machine learning methods to examine how subject-specific differences influence hand force production and create subject-specific computer models from easy to obtain clinical data. The results, which integrate modeling with an individual’s clinical data, could enhance our ability to provide personalized diagnoses and prognoses for individuals suffering from hand impairments.",A Transfer Learning Framework for Creating Subject-Specific Musculoskeletal Models of the Hand,10040078,R21EB030068,"['Address', 'Adult', 'Amputation', 'Anatomy', 'Biomechanics', 'Clinical', 'Clinical Data', 'Code', 'Collection', 'Complex', 'Computer Models', 'Computer Simulation', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Diagnostic', 'Floor', 'Future', 'Goals', 'Hand', 'Hand Strength', 'Hand functions', 'Individual', 'Joints', 'Kinetics', 'Learning', 'Maps', 'Methods', 'Modeling', 'Muscle', 'Musculoskeletal', 'Musculoskeletal System', 'Outcome', 'Patients', 'Perception', 'Physics', 'Population', 'Production', 'Psychological Transfer', 'Quadriplegia', 'Research', 'Sensory', 'Stroke', 'Study Subject', 'System', 'Testing', 'Traumatic injury', 'Work', 'Wrist', 'base', 'bone', 'computational platform', 'computerized tools', 'deep neural network', 'demographics', 'design', 'experimental study', 'grasp', 'hand dysfunction', 'hand rehabilitation', 'individual patient', 'kinematics', 'machine learning method', 'motor control', 'neural network', 'neuromuscular', 'novel strategies', 'open-access repositories', 'personalized diagnostics', 'personalized medicine', 'prognostic', 'random forest', 'simulation', 'tool']",NIBIB,UNIVERSITY OF FLORIDA,R21,2020,560939,188894159,-0.013338107970345906
"Computational and Statistical Framework to Model Tissue Shape and Mechanics PROJECT SUMMARY  The morphologic and mechanical characteristics of a tissue are fundamental to understanding the development, homeostasis, and pathology of the human body. During the previous period of funding, we developed statistical shape modeling (SSM) methods and applied these to the study of structural hip disease. We also developed the initial framework to integrate SSM with finite element (FE) analysis to enable the study of shape and mechanics together. If incorporated into clinical practice, SSM and FE analysis could identify features of the anatomy likely responsible for injury, remodeling, or repair. Geometry needed for SSM and FE models is typically generated by segmentation of volumetric imaging data. This step can be painstakingly slow, error prone, and cost prohibitive, which hampers clinical application of these computational techniques. We have created a deep machine learning algorithm ‘DeepSSM’ that uses a convolutional neural network to establish the correspondence model directly from unsegmented images. In Aim 1 we will apply DepSSM to improve clinical understanding of structural hip disease by characterizing differences in anatomy between symptomatic and asymptomatic individuals; these morphometric comparisons will identify anatomic features most telling of disease, thereby guiding improvements in diagnosis. Computational advancements have simplified the process to generate patient-specific FE models, enabling clinically focused research. However, there is no framework to collectively visualize, compare, and interpret (i.e., post-process) results from multiple FE models. Currently, inter-subject comparisons require oversimplifications such as averaging results over subjectively defined regions. In Aim 2 we will develop new post-processing methods to collectively visualize, interpret and statistically analyze FE results across multiple subjects and study groups. We will map FE results to synthetic anatomies representing statistically meaningful distributions using the correspondence model. Statistical parametric mapping will be applied to preserve anatomic detail through statistical testing. We will use our published FE models of hip joint mechanics as the test system. Finally, volumetric images provide a wealth of information that is delivered to physicians in a familiar format. Yet, tools are not available to interpret model data with clinical findings from volumetric images. In Aim 3, we will develop methods that evaluate relationships between shape, mechanics, and clinical findings gleaned from imaging through integrated statistical tests and semi-automatic medical image annotation tools that utilize standard ontologies. Quantitative CT and MRI images of the hip, which estimate bone density and cartilage ultrastructure, respectively, will be evaluated as test datasets. To impart broad impact, we will disseminate our methods to the community as open source software that will call core functionality provided by existing, open source software that has a large user base (FEBio, ShapeWorks). PROJECT NARRATIVE The proposed technology will provide the methodologies necessary to increase the clinical acceptance and applicability of computer models. These models measure three-dimensional tissue shape and estimate tissue mechanics, providing information that cannot be measured conventionally. We will implement these methods into software that can be used by the public free-of-charge.",Computational and Statistical Framework to Model Tissue Shape and Mechanics,9972694,R01EB016701,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anatomy', 'Architecture', 'Bone Density', 'Cardiology', 'Cartilage', 'Characteristics', 'Charge', 'Clinical', 'Communities', 'Computational Technique', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Finite Element Analysis', 'Foundations', 'Funding', 'Geometry', 'Glean', 'Grooming', 'Hip Joint', 'Hip region structure', 'Homeostasis', 'Human Pathology', 'Human body', 'Image', 'Individual', 'Injury', 'Intuition', 'Libraries', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Mechanics', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Neurology', 'Ontology', 'Orthopedics', 'Pathology', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Procedures', 'Process', 'Publishing', 'Quantitative Evaluations', 'Research', 'Resources', 'Scheme', 'Shapes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Model', 'Tissues', 'Training', 'Validation', 'X-Ray Computed Tomography', 'annotation  system', 'base', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data modeling', 'disease diagnosis', 'improved', 'in vivo', 'machine learning algorithm', 'novel', 'open source', 'predictive modeling', 'preservation', 'relating to nervous system', 'repaired', 'shape analysis', 'simulation', 'three-dimensional modeling', 'tool']",NIBIB,UNIVERSITY OF UTAH,R01,2020,563658,228951281,-0.007011021789163516
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,9935719,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Asses', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2020,599090,340417756,-0.003971563656162011
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,9941090,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Catalogs', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2020,605875,560644462,-0.0047938901387048274
"Rapid fungal identification and antifungal susceptibility testing through quantitative, multiplexed RNA detection PROJECT SUMMARY / ABSTRACT  Timely diagnostics for fungal infections are sorely needed to guide effective therapy. Invasive fungal infections are increasing in prevalence, causing millions of deaths each year worldwide, and drug resistance poses a rising threat. Due in large part to slow, outmoded diagnostics that require days of culture to identify the pathogen and report its antifungal susceptibility profile, mortality from invasive fungal infections can exceed 40%. This in turn leads clinicians to rely on empiric and prophylactic use of antifungals that may be ineffective, cause needless toxicity, and select for resistance. Rapid precision diagnostic assays are critically needed to improve patient outcomes and guide efficient deployment of our limited antifungal arsenal.  To address this urgent public health need, in response to a specific funding opportunity announcement on “Advancing Development of Rapid Fungal Diagnostics” (PA-19-080), this proposal describes a strategy for rapid fungal identification and antifungal susceptibility testing based on RNA signatures. This approach relies on a novel paradigm for pathogen diagnostics, recently validated in bacteria and implemented on a simple, robust, quantitative, multiplexed fluorescent hybridization assay on the NanoString platform. Detection of highly abundant, conserved ribosomal RNA (rRNA) sequences enables broad-range, ultrasensitive pathogen identification. Meanwhile, quantifying key messenger RNA levels following antimicrobial exposure enables phenotypic antimicrobial susceptibility testing (AST), relying on the principle that cells that are dying or growth- arrested are transcriptionally distinct within minutes from those that are not (Bhattacharyya et al, Nature Medicine, in press). Because this approach to AST measures gene expression as an early phenotypic change in susceptible strains, it does not rely on foreknowledge of the genetic basis of resistance in order to classify susceptibility, and can thus be generalized to any pathogen-antimicrobial pair.  This proposal aims to first computationally design and experimentally validate a set of hybridization probes to uniquely recognize the 18S and 28S rRNA from each of 48 clinically significant fungal pathogens that together cause the vast majority of invasive fungal infections in humans. Preliminary data show that these rRNA targets are abundant enough to detect a single fungal cell without amplification, enabling ultrasensitive detection in <4 hours directly from clinical samples. Next, RNA-Seq will be used to profile transcriptional changes in 12 common fungal pathogens for which resistance has important clinical consequences in response to treatment with the three major classes of antifungals. Antifungal-responsive transcripts that best classify fungal isolates as susceptible or resistant will be chosen by adapting machine learning algorithms that were developed for this purpose in bacteria. Finally, both approaches will be piloted on simulated and real clinical fungal samples. Preliminary data suggest that these approaches can identify fungi within <4 hours from a primary sample, and deliver AST results within <6 hours of a positive fungal culture. PROJECT NARRATIVE Fungal infections are common, increasing in frequency and severity, and cause considerable morbidity and mortality. Early recognition of invasive fungal infection, and prompt initiation of effective antifungal therapy, are key to improving patient outcomes. This proposal aims to adapt a novel paradigm for rapid pathogen identification and antimicrobial susceptibility testing through the quantitative detection of RNA signatures to transform fungal diagnostics.","Rapid fungal identification and antifungal susceptibility testing through quantitative, multiplexed RNA detection",10034036,R01AI153405,"['Address', 'Advanced Development', 'Antibiotics', 'Antifungal Agents', 'Antifungal Therapy', 'Antimicrobial susceptibility', 'Aspergillus', 'Azoles', 'Bacteria', 'Bacterial Infections', 'Bacterial RNA', 'Biological Assay', 'Biopsy Specimen', 'Blood', 'Bronchoalveolar Lavage', 'Candida', 'Candida auris', 'Cells', 'Cessation of life', 'Class Zygomycetes', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Microbiology', 'Collaborations', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Drug resistance', 'Frequencies', 'Funding Opportunities', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Profiling', 'Genetic', 'Genetic Transcription', 'Genotype', 'Goals', 'Growth', 'Hour', 'Human', 'Immunoglobulin Variable Region', 'Measures', 'Medical', 'Medicine', 'Messenger RNA', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Multi-Drug Resistance', 'Mycoses', 'Nature', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Phenotype', 'Phylogenetic Analysis', 'Polyenes', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Public Health', 'RNA', 'RNA Sequences', 'RNA, Ribosomal, 28S', 'Reporting', 'Resistance', 'Ribosomal RNA', 'Sampling', 'Severities', 'Skin', 'Specimen', 'Speed', 'Sputum', 'Swab', 'Symptoms', 'Taxonomy', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Transcript', 'Urine', 'Work', 'antimicrobial', 'base', 'clinically significant', 'computational pipelines', 'design', 'diagnostic assay', 'effective therapy', 'efflux pump', 'experience', 'fungus', 'improved', 'machine learning algorithm', 'microbial', 'mortality', 'nano-string', 'novel', 'novel strategies', 'overexpression', 'pathogen', 'pathogenic fungus', 'patient population', 'personalized diagnostics', 'prophylactic', 'random forest', 'resistance mechanism', 'response', 'transcriptome sequencing', 'transcriptomics', 'treatment response']",NIAID,"BROAD INSTITUTE, INC.",R01,2020,645818,191864802,-0.008136190224530073
"Predicting tuberculosis outcomes using genotypic and biomarker signatures PROJECT SUMMARY/ABSTRACT Tuberculosis (TB) is caused by an infectious pathogen, Mycobacterium tuberculosis (M.tb) in susceptible individuals, but we cannot yet classify or predict outcomes in those prone to pulmonary TB disease versus those prone to resistance. In part, this reflects knowledge gaps regarding genotypes that may increase susceptibility, and in validated disease correlates (e.g. serum of lung protein biomarkers) measured individually, or combined signatures. We address these knowledge gaps by using Diversity Outbred (DO) mice, a population with abundant genetic diversity and heterozygosity, like the human population. Also, like humans, a low dose M.tb infection of DO mice produces a spectrum of outcomes, from highly susceptible to highly resistant, and many intermediate outcomes. In this proposal, we use the DO population to: 1) Identify and test the capacity of genotypic (alleles and statistically significant loci) to predict outcomes such as diagnostic category (class); and 2) To identify and test lung and serum biomarker (protein) and granuloma signatures to determine diagnostic category (class); and 3) To identify and test serum biomarker (protein) signatures that can forecast disease onset, within a 3-week window before illness manifests clinically. The best performing signatures will be tested using samples from humans. Collectively, results from these studies will generate new translatable knowledge regarding correlates of pulmonary TB (useful for diagnostics), and genotypic and serum protein signatures (useful for prognostics). PROJECT NARRATIVE Mycobacterium tuberculosis (M.tb) causes tuberculosis (TB) in millions of susceptible humans each year. It is well known that humans respond variably to M.tb infection, yet we are unable to predict outcomes with accuracy. Here, we use the Diversity Outbred (DO) mouse population to identify and test genotypic, serum, and lung biomarker signatures to accurately predict outcomes. Findings are also validated in samples from humans.",Predicting tuberculosis outcomes using genotypic and biomarker signatures,9849329,R01HL145411,"['AIDS/HIV problem', 'Address', 'Adult', 'Aerosols', 'Alleles', 'Animal Model', 'Bacillus', 'Biological Markers', 'Blood', 'Categories', 'Classification', 'Clinical', 'Consensus', 'Data', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outcome', 'Dose', 'Genetic Variation', 'Genotype', 'Granuloma', 'Harvest', 'Heterozygote', 'Human', 'Image', 'Image Analysis', 'Inbred Strain', 'Individual', 'Infection', 'Intervention', 'Knowledge', 'Lung', 'Malaria', 'Malignant Neoplasms', 'Measures', 'Minority', 'Modeling', 'Morbidity - disease rate', 'Mus', 'Mycobacterium tuberculosis', 'Necrosis', 'Onset of illness', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Population', 'Predisposition', 'Process', 'Production', 'Proteins', 'Pulmonary Tuberculosis', 'Quantitative Trait Loci', 'Resistance', 'Sampling', 'Serum', 'Serum Proteins', 'Structure', 'Testing', 'Time', 'Training', 'Tuberculosis', 'Vehicle crash', 'base', 'human pathogen', 'improved', 'individual patient', 'learning algorithm', 'model development', 'novel diagnostics', 'novel marker', 'outcome forecast', 'outcome prediction', 'pathogen', 'predictive marker', 'predictive modeling', 'prognostic', 'protein biomarkers', 'public health intervention', 'response', 'supervised learning', 'survival outcome', 'tool', 'transmission process', 'tuberculosis diagnostics']",NHLBI,TUFTS UNIVERSITY BOSTON,R01,2020,655091,65064605,-0.020571104046835167
"Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB) Project Summary We request a high-flux x-ray source and to acquire new team expertise in segmentation from microCT images, in order to apply a new 3D form of histology developed through our parent R24 to begin to characterize the cellular and tissue geometries of COVID-19-associated Acute Respiratory Distress Syndrome (ARDS) pneumonia, our pandemic’s most common cause of death. Our novel imaging tool, X-ray histotomography, is based on microCT of fixed and metal-stained tissue. It is unique among 3D imaging methods as the only nondestructive way to achieve pan-cellular imaging (allowing characterization of all cell types and tissues) and is potentially practical. Histotomography uniquely allows direct comparison with today’s 2D standard of tissue diagnosis, histology, capable of producing both 3D renderings and undistorted 2D slices at any angle and any slice thickness. Unlike histology, we will also allow us to precisely characterize cellular arrangements into tissues after fixing and staining of samples with metal. The ability to volumetrically characterize cell types and their arrangements in acute respiratory distress syndrome (ARDS) is particularly important because it is what kills most patients in coronavirus-based pandemics, including SARS (severe acute respiratory syndrome coronavirus) in 2003, MERS (Middle East respiratory syndrome coronavirus) in 2012, COVID-19 now. The proposed work will increase our preparedness for future pandemics. ARDS lungs are an ideal human tissue model for mathematically defining human disease because all cell types are affected. The proposed work with COVID-19 lungs will increase the precision with which we understand the different stages of coronavirus lung infection and serve as a model for characterizing the Geometry of Disease across all organ systems. Histotomography in the parent R24 is currently limited to animal models, focusing on the zebrafish. The supplement will allow us to translate our work to human health, which was originally envisioned by the PI, as part of defining the “Geometry of Disease”. Our experience with this technology tells us that we will be able to characterize the numbers of each of the basic inflammatory cell types, including lymphocytes, neutrophils, and macrophages (which are morphologically distinct) in terms of numbers, volumes, shapes, and density in the inflamed tissue, and to also characterize the changes in the lung epithelia (bronchial ciliated epithelial cells and pneumocytes, cell death, and the filling of airways with fluid and fibrinous exudate, and vascular inflammation. In addition to quantitation of tissue changes, we will also be able to visualize pathological change in the tissues using virtual reality. Histotomography will serve as a way to validate a humanized mouse model of COVID-19 infection by comparing the quantitative changes with those in human autopsy samples. We will be comparing both standard histological sections and histotomographic images from adjacent tissue. Machine learning will ultimately allow us to automate recognition of cell types and pathological change. The proposed augmentation of our instrumentation and expertise will facilitate definitions of the “Geometry of Disease” across organ systems. Project narrative We request an equipment upgrade and acquisition of expertise to accelerate progress and to pilot the translational use of our ORIP-funded technology to provide the first 3D understanding of the pathogenesis of COVID-19 pneumonia. Histotomography, a new 3D form of histology based on microCT, is the first practical way to turn the current standard of 2D, qualitative, tissue analytics into quantitative, morphometrics that is inclusive of all cell types and tissue architecture. Organismal and tissue phenotyping at both scales makes possible the first 3D, complete phenotyping of cells and tissue architecture, promising to transform human tissue diagnostics, preclinical toxicology, and more comprehensive high-throughput genetic, chemical and disease phenomics.",Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB),10169023,R24OD018559,"['3-Dimensional', 'Adult Respiratory Distress Syndrome', 'Affect', 'Alveolar', 'American', 'Animal Model', 'Architecture', 'Area', 'Autopsy', 'Biology', 'COVID-19', 'COVID-19 pandemic', 'Cause of Death', 'Cell Death', 'Cell Volumes', 'Cells', 'Cellular Structures', 'Cessation of life', 'Characteristics', 'Chemicals', 'Cicatrix', 'Clinical', 'Control Animal', 'Coronavirus', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Edema', 'Epithelial', 'Epithelial Cells', 'Epithelium', 'Equipment', 'Evaluation', 'Exudate', 'Female', 'Floods', 'Funding', 'Future', 'Genetic', 'Geometry', 'Health', 'Histologic', 'Histology', 'Human', 'Image', 'Imaging Device', 'Infection', 'Inflammatory', 'Intelligence', 'Knowledge', 'Leadership', 'Liquid substance', 'Location', 'Lung', 'Lung diseases', 'Lung infections', 'Lymphocyte', 'Machine Learning', 'Mathematics', 'Measurement', 'Metals', 'Microscopy', 'Middle East Respiratory Syndrome', 'Middle East Respiratory Syndrome Coronavirus', 'Modeling', 'Monoclonal Antibody R24', 'Morphology', 'Mus', 'Negative Staining', 'Normal tissue morphology', 'Outcome', 'Parents', 'Pathogenesis', 'Pathologic', 'Patients', 'Pattern', 'Phenotype', 'Pneumonia', 'Preclinical Testing', 'Procedures', 'Process', 'Productivity', 'Radiology Specialty', 'Readiness', 'Resolution', 'Resources', 'Roentgen Rays', 'SARS coronavirus', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Severe Acute Respiratory Syndrome', 'Shapes', 'Slice', 'Source', 'Specimen', 'Stains', 'Structure of parenchyma of lung', 'Synchrotrons', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Imaging', 'Time', 'Tissue Model', 'Tissue Stains', 'Tissue imaging', 'Tissues', 'Toxicology', 'Training', 'Transgenic Mice', 'Translating', 'Work', 'Zebrafish', 'automated segmentation', 'base', 'body system', 'cell type', 'cellular imaging', 'computational basis', 'density', 'efficacy evaluation', 'experience', 'experimental study', 'human disease', 'human imaging', 'human morbidity', 'human mortality', 'human tissue', 'humanized mouse', 'imaging modality', 'improved', 'instrumentation', 'macrophage', 'male', 'mathematical model', 'microCT', 'mouse model', 'neutrophil', 'novel', 'pandemic disease', 'parent project', 'phenomics', 'pneumocyte', 'pre-clinical', 'reconstruction', 'submicron', 'targeted treatment', 'therapeutic evaluation', 'vascular inflammation', 'virtual reality']",OD,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,R24,2020,655483,68045551,-0.107899947782114
"PREMIERE: A PREdictive Model Index and Exchange REpository The confluence of new machine learning (ML) data-driven approaches; increased computational power; and access to the wealth of electronic health records (EHRs) and other emergent types of data (e.g., omics, imaging, mHealth) are accelerating the development of biomedical predictive models. Such models range from traditional statistical approaches (e.g., regression) through to more advanced deep learning techniques (e.g., convolutional neural networks, CNNs), and span different tasks (e.g., biomarker/pathway discovery, diagnostic, prognostic). Two issues have become evident: 1) as there are no comprehensive standards to support the dissemination of these models, scientific reproducibility is problematic, given challenges in interpretation and implementation; and 2) as new models are put forth, methods to assess differences in performance, as well as insights into external validity (i.e., transportability), are necessary. Tools moving beyond the sharing of data and model “executables” are needed, capturing the (meta)data necessary to fully reproduce a model and its evaluation. The objective of this R01 is the development of an informatics standard supporting the requisite information for scientific reproducibility for statistical and ML-based biomedical predictive models; from this foundation, we then develop new computational approaches to compare models' performance. We begin by extending the current Predictive Model Markup Language (PMML) standard to fully characterize biomedical datasets and harmonize variable definitions; to elucidate the algorithms involved in model creation (e.g., data preprocessing, parameter estimation); and to explain the validation methodology. Importantly, models in this PMML format will become findable, accessible, interoperable, and reusable (i.e., following FAIR principles). We then propose novel meth- ods to compare and contrast predictive models, assessing transportability across datasets. While metrics exist for comparing models (e.g., c-statistics, calibration), often the required case-level information is not available to calculate these measures. We thus introduce an approach to simulate cases based on a model's reported da- taset statistics, enabling such calculations. Different levels of transportability are then assigned to the metrics, determining the extent to which a selected model is applicable to a given population/cohort (i.e., helping answer the question, can I use this published model with my own data?). We tie these efforts together in our proposed framework, the PREdictive Model Index & Exchange REpository (PREMIERE). We will develop an online portal and repository for model sharing around PREMIERE, and our efforts will include fostering a community of users to guide its development through workshops, model-thons, and other activities. To demonstrate these efforts, we will bootstrap PREMIERE with predictive models from a targeted domain (risk assessment in imaging-based lung cancer screening). Our efforts to evaluate these developments will engage a range of stakeholders (model developers, users) to inform the completeness of our standard; and biostatisticians and clinical experts to guide assessment of model transportability. PROGRAM NARRATIVE With growing access to information contained in the electronic health record and other data sources, the appli- cation of statistical and machine learning methods are generating more biomedical predictive models. However, there are significant challenges to reproducing these models for purposes of comparison and application in new environments/populations. This project develops informatics standards to facilitate the sharing and reproducibil- ity of these models, enabling a suite of comparative methods to evaluate model transportability.",PREMIERE: A PREdictive Model Index and Exchange REpository,10016297,R01EB027650,"['Access to Information', 'Address', 'Algorithms', 'Area', 'Attention', 'Bayesian Network', 'Big Data', 'Biological Markers', 'Calibration', 'Characteristics', 'Clinical', 'Communities', 'Computational Biology', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Decision Making', 'Decision Trees', 'Dermatology', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Ecosystem', 'Educational workshop', 'Electronic Health Record', 'Environment', 'Evaluation', 'FAIR principles', 'Fostering', 'Foundations', 'Goals', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Language', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Medical', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Ophthalmology', 'Pathway interactions', 'Performance', 'Population', 'Publications', 'Publishing', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Reporting', 'Reproducibility', 'Reproduction', 'Research Personnel', 'Risk Assessment', 'Source', 'Techniques', 'Testing', 'Training', 'Validation', 'Variant', 'Work', 'base', 'bioimaging', 'biomarker discovery', 'case-based', 'cohort', 'collaborative environment', 'comparative', 'computer aided detection', 'convolutional neural network', 'data sharing', 'deep learning', 'design', 'experience', 'feature selection', 'indexing', 'innovation', 'insight', 'interest', 'interoperability', 'learning network', 'lung basal segment', 'lung cancer screening', 'mHealth', 'machine learning method', 'model development', 'novel', 'novel strategies', 'online repository', 'predictive modeling', 'prognostic', 'repository', 'software repository', 'statistical and machine learning', 'statistics', 'stem', 'tool', 'web portal']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,673491,673201228,-0.004168644364665592
"Scalable platform for optimizing human cardiac tissue engineering via optical pacing and on-demand oxygenation PROJECT SUMMARY Induced pluripotent stem cell-derived cardiomyocytes (iPS-CM) are emerging as an invaluable in vitro human experimental platform for disease modeling, drug discovery, cardiotoxicity screening, gene editing and functional genomics. For the first time, cardiac electrophysiology has access to a scalable human experimental model, which, currently, offers the only path to personalized (cardiac) medicine as patient-derived iPS-CMs can be generated on a progressively faster time scale. The clear potential of this technology motivates efforts to address the main criticisms facing iPS-CMs, namely the need for further maturation and reduction of phenotype heterogeneity. As multiple approaches are being pursued to improve iPS-CM maturation and to approximate the functionality of the adult human myocardium, we argue that combinatorial optimizations necessitate new high-throughput (HT) technology and automation. The overall goal of this project is to develop and validate a scalable platform for optimizing cardiac tissue engineering via chronic reconfigurable optical pacing and “on-demand” oxygenation for gaining mechanistic insights into cardiac metabolism and electrophysiology, a platform we call ChROME. Chronic electrical stimulation is a viable lead to iPS-CM maturation, yet it has remained under-explored, specifically as related to the role of mass transport and oxygenation during such stimulation. Leveraging our expertise in the theoretical and experimental use of optogenetic tools for cardiac applications (Entcheva) and automation (Kostov, Li, Entcheva, Kay), we propose to design and validate the first-generation HT-ChROME platform, that will integrate continuous monitoring of key physiological parameters. Our team’s expertise in optical oxygen sensing (Kostov), in-house manufacturing of “on-demand” oxygenation nanocarriers (perfluorocarbons, PFC) (Kay) and metabolic characterization (Kay, Beard) will be applied to address the increased metabolic demands during stimulation. The ability to quantify “functional maturation” by relevant measures (voltage, calcium, contraction) in a high-throughput manner (Entcheva) in 2D and 3D cardiac tissue constructs (Vunjak-Novakovic), using our automated platform OptoDyCE (all-optical dynamic cardiac electrophysiology) is critical in this undertaking. Employing these HT tools and other imaging and omics modalities (Popratiloff, Horvath), we will elucidate the spectrum of responses triggered by chronic stimulation of iPS-CMs: beneficial/maturation effects vs. pathological overload effects, depending on load and oxygenation conditions. The proposed HT-ChROME platform represents a critical step in resolving issues impeding progress with iPS-CMs to accelerate their wide-spread adoption in basic and translational applications. The obtained large-scale data will inform a new generation of biophysical models linking human cardiac metabolism and electrophysiology. PROJECT NARRATIVE Recent advances in stem-cell technology enable patient-derived cells to be turned into functional heart cells, and this is an exciting direction towards personalized medicine; yet, there are many challenges in optimizing these cardiomyocytes to better mimic the real heart – a problem that the proposed engineering tools will help resolve.",Scalable platform for optimizing human cardiac tissue engineering via optical pacing and on-demand oxygenation,9839658,R01HL144157,"['3-Dimensional', 'Address', 'Adoption', 'Adult', 'Affect', 'Automation', 'Biological', 'Calcium', 'Cardiac', 'Cardiac Electrophysiologic Techniques', 'Cardiac Myocytes', 'Cardiotoxicity', 'Cells', 'Chronic', 'Combinatorial Optimization', 'Data', 'Disease model', 'Electric Stimulation', 'Engineering', 'Event', 'Experimental Models', 'Fluorocarbons', 'Frequencies', 'Future', 'Generations', 'Genes', 'Goals', 'Heart', 'Heterogeneity', 'Hip region structure', 'Human', 'Human Engineering', 'Image', 'In Vitro', 'Incubators', 'Lead', 'Light', 'Link', 'Longitudinal Studies', 'Measures', 'Mechanics', 'Mediating', 'Medicine', 'Metabolic', 'Metabolism', 'Mitochondria', 'Modality', 'Modeling', 'Monitor', 'Myocardium', 'NADH', 'Optics', 'Oxygen', 'Oxygen Consumption', 'Pathologic', 'Patients', 'Phenotype', 'Physiologic pulse', 'Physiological', 'Regression Analysis', 'Role', 'Site', 'Technology', 'Testing', 'Time', 'Tissue Engineering', 'Tissues', 'Transcriptional Regulation', 'Viral', 'Work', 'biophysical model', 'cardiac tissue engineering', 'design', 'drug discovery', 'functional genomics', 'heart cell', 'heart metabolism', 'high throughput technology', 'improved', 'induced pluripotent stem cell', 'insight', 'large scale data', 'machine learning algorithm', 'nanocarrier', 'optogenetics', 'personalized medicine', 'programs', 'response', 'screening', 'side effect', 'stem cell technology', 'tool', 'transcriptomics', 'voltage']",NHLBI,GEORGE WASHINGTON UNIVERSITY,R01,2020,706471,86807134,-0.020157812777274058
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,9920211,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'data quality', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2020,709525,593605914,-0.006333877160946754
"Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors Project Summary Scientific understanding of adaptive immune receptors (i.e. antibodies and T cell receptors) has the potential to revolutionize prophylaxis, diagnosis, and treatment of disease. High‐throughput DNA sequencing and functional experiments have now brought the study of adaptive immune receptors into the big‐data era. To realize this potential of these data they must be matched with appropriately powerful analytical techniques. Existing probabilistic and mechanistic models are insufficient to capture the complexities of these data, while a naïve application of machine learning cannot leverage our profound existing knowledge of the immune system. The goal of this project is to blend deep learning with mechanistic modeling in order to predict and understand the evolution and function of adaptive immune receptors. Aim 1: Develop generative models of immune receptor sequences that capture the complexity of real adaptive immune receptor repertoires. These will combine deep learning along with our knowledge of VDJ recombination, and provide a rigorous platform for detailed repertoire comparison. Aim 2: Develop quantitative mechanistic models of antibody somatic hypermutation that incorporate the underlying biochemical processes. Estimate intractable likelihoods using deep learning to infer important latent variables, and validate models using knock‐out experiments in cell lines. Aim 3: Develop hybrid deep learning models to predict binding properties from sequence data, combining large experimentally‐derived binding data with even larger sets of immune sequences from human immune memory samples. Incorporate structural information via 3D convolution or distance‐based penalties. These tools will reveal the full power of immune repertoire data for medical applications. We will obtain more rigorous comparisons of repertoires via their distribution in a relevant space. These will reveal the effects of immune perturbations such as vaccination and disease, allowing us to pick out sequences that are impacted by these perturbations. We will have a greater quantitative understanding of somatic hypermutation in vivo, and statistical models that appropriately capture long‐range effects of collections of mutations. We will also have algorithms that will be able to combine repertoire data and sparse binding data to predict binding properties. Put together, these advances will enable rational vaccine design, treatment for autoimmune disease, and identification of T cells that are promising candidates for cancer immunotherapy. Project Narrative Adaptive immune receptors (i.e. antibodies and T cell receptors) enable our body to fight off disease, “remember” pathogens, and train the immune system through vaccination. Immunologists have learned via high‐throughput sequencing that adaptive immune receptors have a truly remarkable diversity. In this proposal, we develop machine‐learning methods for these sequence data, which will allow us to predict the maturation, statistical distribution, and binding properties of adaptive immune receptors, and thus to better design vaccinations, autoimmune disease treatment, and immunotherapy treatment for cancer.",Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors,9938424,R01AI146028,"['3-Dimensional', 'Algorithms', 'Animal Model', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Autoimmune Diseases', 'Automobile Driving', 'Big Data', 'Binding', 'Biochemical', 'Biochemical Process', 'Categories', 'Cell Line', 'Characteristics', 'Collection', 'Complement', 'Complex', 'Data', 'Data Set', 'Dependence', 'Diagnosis', 'Disease', 'Entropy', 'Evolution', 'Exposure to', 'Foundations', 'Gene Conversion', 'Generations', 'Goals', 'High-Throughput DNA Sequencing', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Immune', 'Immune response', 'Immune system', 'Immunoglobulin Somatic Hypermutation', 'Immunologic Memory', 'Immunologic Receptors', 'Immunological Models', 'Immunologics', 'Immunologist', 'Immunology', 'Immunotherapy', 'In Vitro', 'Individual', 'Knock-out', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Pathway interactions', 'Population', 'Procedures', 'Process', 'Property', 'Prophylactic treatment', 'Resolution', 'Sampling', 'Science', 'Statistical Distributions', 'Statistical Methods', 'Statistical Models', 'Structure', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'V(D)J Recombination', 'Vaccination', 'Vaccine Design', 'Vaccines', 'Validation', 'Work', 'algorithm training', 'analytical tool', 'base', 'biochemical model', 'cancer immunotherapy', 'cancer therapy', 'complex data ', 'deep learning', 'deep neural network', 'deep sequencing', 'design', 'experimental study', 'fighting', 'functional group', 'in vivo', 'insertion/deletion mutation', 'large datasets', 'machine learning method', 'markov model', 'pathogen', 'progenitor', 'receptor', 'repaired', 'response', 'success', 'three dimensional structure', 'tool']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2020,710049,758431960,-0.02168773040878217
"Identifying individuals at risk of progression to active tuberculosis Project Summary Almost 2 billion people are infected with Mycobacterium tuberculosis (Mtb), the causative agent of tuberculosis (TB). Approximately 10% of these individuals will progress to active TB disease over their lifetimes, but there is currently no clinical test to distinguish those that will progress to active TB disease, from those that will not. If we are to realize the World Health Organization's (WHO) goal of a world free of TB by 2035, the massive reservoir of TB infection must be addressed with a cost-effective, ethical therapy for preventing progression, based on treating only those most likely to progress. A diagnostic test that can accurately predict the risk of progression is critical for treating these high-risk individuals and the eradication of TB. Our goal is to develop such an assay. Our central hypothesis is that five independent host immune biomarkers, combined into a single multimetric signature will predict progression from latent to active TB with at least 90% sensitivity and specificity. We will test this hypothesis and achieve our goal by implementing the following specific aims: Aim 1: Compile a comprehensive dataset of biomarkers in a prospective cohort of individuals who are at risk of progressing to active TB. Working with the Moldova Ministry of Health's National TB Program, we will enroll 3,685 close contacts of active TB cases. All participants will be followed for two years to determine who progresses to active TB. We expect to identify ≥ 140 progressors. We will assess three previously established blood-based predictors of active TB progression, and two novel assays. We will verify the performance of previously published biomarkers in this population to discriminate progressors from non-progressors and identify new candidate biomarkers using RNA-Seq of antigen stimulated PBMC and detection of Mtb-peptides by NanoDisk MS. Aim 2: Use a discovery set of samples to develop predictive models of progression to active TB. Using data from 140 progressors and 140 non-progressors from Aim 1 we will (1) Verify the performance of existing biomarkers, (2) Use a cross-validation to identify new candidate biomarkers, and (3) derive predictive models using logistic regression and machine learning methods to identify optimal biomarker signatures that best predict progression to active TB within 12 months. Aim 3: Verify the ability of the model to predict progression to active TB disease. Using the same approach as Aim 1, we will enroll a new set of 1,340 household contacts of active TB and identify at least 60 progressors and 60 matched non-progressors and verify clinically the sensitivity/specificity of our models and biosignatures (Aim 2) to predict progression to active disease. A combined host biomarker signature that can predict TB progression from a small blood volume will have significant impact on the WHO End TB Program. PROJECT NARRATIVE Almost 2 billion people are infected with Mycobacterium tuberculosis, the causative agent of tuberculosis (TB). Approximately 10% of these individuals will progress to active TB disease over their lifetimes, but there is currently no test to distinguish those that will progress from those that will not. We propose to develop a multimetric signature of host biomarkers that together will have a sensitivity and specificity of ≥ 90% for predicting progression to active TB in one year, a critical first step to developing cost-effective and ethical treatment plans in order to reach the World Health Organization goal of Ending TB by 2035.",Identifying individuals at risk of progression to active tuberculosis,9852419,R01AI137681,"['Address', 'Antigens', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Volume', 'Cells', 'Characteristics', 'Child', 'Clinical', 'Clinical Sensitivity', 'Data', 'Data Set', 'Detection', 'Diagnostic tests', 'Disease', 'Enrollment', 'Ethics', 'Event', 'Filtration', 'Flow Cytometry', 'Foundations', 'Freezing', 'Frequencies', 'Gender', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Goals', 'Health', 'Household', 'Immune', 'Immune response', 'Immunologic Markers', 'Individual', 'Interferons', 'Logistic Regressions', 'Lymphocyte', 'Modeling', 'Moldova', 'Mycobacterium tuberculosis', 'Mycobacterium tuberculosis antigens', 'National Health Programs', 'Organizational Objectives', 'Outcomes Research', 'Participant', 'Patients', 'Peptide Fragments', 'Peptides', 'Performance', 'Peripheral Blood Mononuclear Cell', 'Plasma', 'Population', 'Procedures', 'Production', 'Prospective cohort', 'Proteins', 'Publications', 'Publishing', 'RNA', 'Research Personnel', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Specificity', 'T cell response', 'T-Lymphocyte', 'Testing', 'Tuberculosis', 'Validation', 'World Health Organization', 'age group', 'base', 'biobank', 'biomarker performance', 'biosignature', 'blood-based biomarker', 'candidate marker', 'classification algorithm', 'clinical Diagnosis', 'cohort', 'cost effective', 'deep neural network', 'enzyme linked immunospot assay', 'falls', 'follow-up', 'high risk', 'indexing', 'innovation', 'machine learning method', 'monocyte', 'nanodisk', 'novel', 'novel diagnostics', 'predictive modeling', 'predictive test', 'prevent', 'programs', 'progression marker', 'random forest', 'research clinical testing', 'support vector machine', 'transcriptome sequencing', 'transmission process', 'treatment planning']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,711592,524978793,0.01651517394111411
"A ""Culture"" Shift: Integrated Bacterial Screening and Antibacterial Susceptibility Test on Microfluidic Digital Array for Bloodstream Infections PROJECT SUMMARY The ability for clinicians to effectively treat bacterial infections with targeted antibacterials in the acute-care settings hinges on diagnostics capable of identifying the pathogen broadly and determining its susceptibility to antibacterials in a timely manner. Bloodstream infection (BSI) is a particularly representative disease because it is the leading cause of death due to infections with rapid disease progression. Unfortunately, the inconvenient delay of blood culture for definitive diagnosis contributes to widespread empiric use of broad- spectrum antibacterials and emergence of multi-drug-resistant pathogens. Toward addressing this critical unmet need, we propose to develop a new molecular diagnostic platform that integrates bacterial detection, species identification (ID), and antibacterial susceptibility testing (AST) from blood samples in a streamlined test. The expected sample-to-answer turnaround time is 90 min for ID and as early as 2-3 hr for AST. Such integrated diagnostic solution within the proposed timeframe will transform acute-care clinicians’ ability to establish diagnosis of bacterial infections, need for infection control, and antibacterial treatment based on objective data to improve clinical outcome. Using an innovative microfluidic digital array chip for assaying single cells as a backbone technology, we propose to develop a new molecular diagnostic platform which promises rapid ID and AST and allows customizable workflow and assay tailored to the clinical scenario while adjustable based on real-time results. The array chip seamlessly integrates digitization of cells, brief incubation (under various drug conditions), single-cell PCR (scPCR) or reverse transcriptase PCR (scRT-PCR) and single-cell high-resolution melt (scHRM). Thereby, bacterial pathogen can be detected at the level of single-cells, identified based on species- specific melt curves, and their antibacterial susceptibility profile subsequently assessed by measuring changes in rRNA level as a biosynthetic marker of cell viability. ScPCR/scRT-PCR enables sensitive detection and absolute quantification of rRNA of individual cells critical to rapid and reliable differentiation between viable and no-viable cells; while scHRM overcomes a key limitation of bulk HRM to resolve multiple species for diagnosing polymicrobial infections or discarding contaminations. Since both ID and AST do not rely on culture, they reduce total turnaround time from days to minutes/hours. We have assembled a superb team of multi-disciplinary investigators and industry advisors with complementary expertise and strong track record of team science. We propose the following aims:1) to develop a streamlined BSI diagnostic protocol for integrated ID and AST; 2) to develop a microfluidic array chip that enables ID and AST with single-cell resolution; 3) to develop instrument and analysis programs for single- cell ID and AST; and 4) to demonstrate the single-cell diagnostic platform, we will perform analytical and pilot clinical validation studies. PROJECT NARRATIVE The main goal of this research project is to develop a single-cell pathogen diagnostic platform which integrates broad-range bacterial detection, species identification (ID) and antibacterial susceptibility testing (AST) in a streamlined test.","A ""Culture"" Shift: Integrated Bacterial Screening and Antibacterial Susceptibility Test on Microfluidic Digital Array for Bloodstream Infections",9878741,R01AI137272,"['Acute', 'Address', 'Anti-Bacterial Agents', 'Bacterial Infections', 'Biological Assay', 'Blood', 'Blood Cells', 'Blood Tests', 'Blood specimen', 'Cause of Death', 'Cell Separation', 'Cell Survival', 'Cells', 'Clinical', 'Cytolysis', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Goals', 'Gold', 'Hour', 'Individual', 'Industry', 'Infection', 'Infection Control', 'Libraries', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microfluidics', 'Nutritional', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Predisposition', 'Preparation', 'Protocols documentation', 'RNA-Directed DNA Polymerase', 'Recombinant DNA', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Ribosomal RNA', 'Sampling', 'Science', 'Sepsis', 'Technology', 'Testing', 'Time', 'Transcript', 'Validation', 'Vertebral column', 'Whole Blood', 'acute care', 'automated algorithm', 'base', 'chromatin immunoprecipitation', 'classification algorithm', 'clinical decision-making', 'design', 'digital', 'empowered', 'imager', 'improved', 'innovation', 'instrument', 'melting', 'molecular diagnostics', 'mortality', 'multi-drug resistant pathogen', 'multidisciplinary', 'novel', 'pathogen', 'pathogenic bacteria', 'programs', 'prospective', 'prototype', 'rRNA Precursor', 'screening', 'validation studies']",NIAID,JOHNS HOPKINS UNIVERSITY,R01,2020,721177,807432003,-0.007188917334106158
"Precision immunoprofiling to reveal diagnostic biomarkers of latent TB infection PROJECT SUMMARY  Tuberculosis (TB) is among the leading causes of mortality worldwide with an estimated 2 billion individuals currently infected. Latent tuberculosis infection (LTBI) is the most common form of TB infection affecting 13 million Americans. While many with LTBI remain asymptomatic, an estimated 10% of immunocompetent patients with LTBI will reactivate to active TB, and will become infectious. LTBI is treatable with a prolonged antibiotic treatment; however, potential side effects motivate the development of new diagnostic approaches that can identify with high specificity patients at the highest risk of reactivation, for who therapy would be most beneficial.  The tuberculin skin test (TST) and interferon-γ release assays (IGRAs) are commonly used for TB and LTBI screening. Both tests provide good measures of TB exposure; however, neither is effective at diagnosing LTBI (positive predictive values <5%). Moreover, neither provide any prognostic stratification based upon reactivation risk. Both the TST and IGRAs probe immunological memory to TB-related antigen challenges and we hypothesize that a more nuanced and personalized approach to monitoring immune responses to both TB- specific and non-specific antigens might reveal new approaches to LTBI diagnosis and patient stratification.  Enabling a new, individualized approach to LTBI diagnostics, we propose to combine high throughput, multiplexed inflammatory biomarker detection strategies and powerful bioinformatics tools that allow for the identification of previously obscured multi-marker diagnostic signatures of LTBI status and reactivation risk. Silicon photonic microring resonators are an enabling technology for biomarker analysis due to their intrinsic scalability and multiplexing capabilities. Applied to the detection of cytokine panels, this technology supports the rapid immune profiling of individual samples under both TB-specific and non-specific antigen stimulation conditions. Machine learning algorithms will be utilized to analyze the resulting dense data streams to facilitate selection of key diagnostic signatures forming the basis for predictive model development and deployment. This powerful analytical combination is supplemented by deep expertise in clinical diagnosis and treatment of TB and LTBI, and an enabling collaboration and connection to subjects from an international location with high TB burden and exposure in a healthcare worker population subjected to regularly-scheduled and repeated LTBI screening.  The resulting diagnostic workflow and machine learning feature selection approaches will reveal multiplexed biomarker signatures that have strong positive predictive correlation with LTBI status (+ or -). This approach will also further stratify LTBI+ subjects on the basis of reactivation potential, thus providing a fundamentally new approach to identifying subjects that are most likely to benefit from therapeutic intervention. The end result of this project will be a new precision medicine-based diagnostic strategy that is vastly superior to the current state-of-the-art and offers the potential to transform current clinical practice. PROJECT NARRATIVE Tuberculosis (TB) affects an estimated one third of the world’s population and an asymptomatic latent state of tuberculosis infection (LTBI) is extremely common. Unfortunately, there are not any good clinical tests that can definitely diagnose LTBI, making it difficult to identify patients that should be treated to prevent reactivation to active TB, which is infectious. We will integrate cutting edge measurement technologies and machine learning bioinformatic approaches to identify and test multiplexed biomarker signatures that will transform clinical TB management by enabling personalized diagnosis of LTBI and the stratification of individuals with the highest potential for reactivation.",Precision immunoprofiling to reveal diagnostic biomarkers of latent TB infection,10006790,R01AI141591,"['Affect', 'Algorithms', 'American', 'Antibiotic Therapy', 'Antibiotics', 'Antigens', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Clinical', 'Clinical Treatment', 'Collaborations', 'Complex', 'Cytokine Network Pathway', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Management', 'Eligibility Determination', 'Generations', 'Goals', 'Gold', 'Health Personnel', 'Immune', 'Immune response', 'Immunocompetent', 'Immunologic Markers', 'Immunologic Memory', 'Immunologic Monitoring', 'Individual', 'Infection', 'Inflammatory', 'Informatics', 'Interferons', 'International', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Modeling', 'Patients', 'Peripheral', 'Peripheral Blood Mononuclear Cell', 'Plasma', 'Population', 'Predictive Value', 'Prevention strategy', 'Regimen', 'Residual state', 'Risk', 'Sampling', 'Schedule', 'Silicon', 'Specificity', 'Stratification', 'Technology', 'Testing', 'Therapeutic Intervention', 'Translations', 'Tuberculin Test', 'Tuberculosis', 'Whole Blood', 'antigen challenge', 'base', 'bioinformatics tool', 'clinical Diagnosis', 'clinical practice', 'cytokine', 'data streams', 'diagnostic accuracy', 'diagnostic biomarker', 'feature selection', 'high risk', 'immune function', 'immunoregulation', 'improved', 'individual variation', 'latent infection', 'machine learning algorithm', 'model development', 'monocyte', 'mortality', 'novel diagnostics', 'novel strategies', 'patient stratification', 'personalized approach', 'personalized diagnostics', 'photonics', 'precision medicine', 'predictive marker', 'predictive modeling', 'prevent', 'prognostic', 'prospective', 'response', 'screening', 'side effect', 'targeted treatment', 'tool', 'treatment strategy', 'tuberculosis treatment']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,722295,641965656,0.02073798573989649
"Improving predictive capacity of models for universal influenza vaccine development The need for improved and more universally protective influenza vaccines is well recognized. Central to efforts towards improvements is the development of animal models more predictive of the human response to immunization and/or infection. Indeed, this need has been highlighted by the NIAID Strategic Plan for a Universal Influenza Vaccine. While animal models may never be able to fully predict the human response, understanding their full strengths and weaknesses and identifying the optimal models for different purposes is a significant public health need and is the scientific premise behind our proposed objectives. These objectives, which are built upon our extensive use of influenza animal models, are to optimize animal modeling of immunologic imprinting, to improve vaccine efficacy testing, and to identify immune correlates of protection and boosting immune responses. Our overall goal is to provide superior preclinical models to support universal influenza vaccine development. We will achieve this goal through three complementary and interrelated specific aims, 1) optimal modeling of human serologic responses to repeat influenza antigen exposure in animal models; 2) improving the quantitative nature of the ferret influenza challenge model; and 3) defining serologic correlates of influenza virus induced clinical symptoms. Our ability to conduct these aims is supported through our participation in, and collaboration with, a recently NIAID-funded human infant cohort, the DIVINCI study. We will mirror the influenza antigen exposures of a selection of these infants in three animal models and compare immunologic data sets to identify which most accurately reflects the human response (Aim 1). This marriage of human and animal data sets and samples offers an innovative way forward and will provide a unique set of differentially primed animals with which to determine immune correlates of novel physiologic parameters of infection and immune responses (Aim 2) using original machine learning algorithms (Aim 3). Current models for influenza vaccine development suffer from poor predictability of the human response. Through an innovative combination of approaches that use data from longitudinal human cohorts, we intend to greatly enhance the reliability and value of these models in universal influenza vaccine testing.",Improving predictive capacity of models for universal influenza vaccine development,9950635,R01AI150745,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Antigens', 'Antiviral Agents', 'Area', 'Cavia', 'Clinical', 'Clinical Research', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Ensure', 'Exposure to', 'Family suidae', 'Ferrets', 'Funding', 'Future', 'Goals', 'Hamsters', 'Human', 'Immune', 'Immune response', 'Immunity', 'Immunization', 'Immunological Models', 'Immunologics', 'Individual', 'Infant', 'Infection', 'Influenza', 'Influenza A Virus, H3N2 Subtype', 'Information Systems', 'Lasso', 'Lung', 'Marriage', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Mus', 'National Institute of Allergy and Infectious Disease', 'Natural History', 'Nature', 'Organ', 'Outcome', 'Output', 'Pathogenesis', 'Performance', 'Physiological', 'Population', 'Pre-Clinical Model', 'Predictive Value', 'Primates', 'Property', 'Public Health', 'Reagent', 'Recording of previous events', 'Research', 'Sampling', 'Seasons', 'Serological', 'Strategic Planning', 'Symptoms', 'System', 'Telemetry', 'Time', 'United States', 'Upper respiratory tract', 'Vaccinated', 'Vaccine Production', 'Vaccines', 'Virulence', 'Virus Replication', 'Whole Body Plethysmography', 'animal data', 'animal model development', 'cohort', 'efficacy testing', 'flexibility', 'human data', 'human model', 'imprint', 'improved', 'influenza virus vaccine', 'influenzavirus', 'innovation', 'machine learning algorithm', 'mouse development', 'multitask', 'next generation', 'novel', 'preclinical evaluation', 'product development', 'research and development', 'response', 'safety study', 'tool', 'transmission process', 'universal influenza vaccine', 'universal vaccine', 'vaccine candidate', 'vaccine development', 'vaccine effectiveness', 'vaccine efficacy', 'vaccine evaluation']",NIAID,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,R01,2020,723996,114256597,-0.011536330093366114
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,9965720,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Streptococcus pyogenes', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2020,741796,46216755,-0.023479316341423508
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10082215,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2020,749858,749858,-0.012298999199149169
"Mobilize Center: Models for Mobile Sensing and Precision Rehabilitation Limited mobility due to conditions like osteoarthritis (OA), cerebral palsy, and Parkinson’s disease affects millions of individuals, at enormous personal and societal cost. Rehabilitation can dramatically improve mobility and function, but current rehabilitation practice requires in-person guidance by a skilled clinician, increasing expense and limiting access. Mobile sensing technologies are now ubiquitous and have the potential to measure patient function and guide treatment outside the clinic, but they currently fail to capture the characteristics of motion required to accurately monitor function and customize treatment. Millions of low-cost mobile sensors are generating terabytes of data that could be analyzed in combination with other data, such as images, clinical records, and video, to enable studies of unprecedented scale, but machine learning models for analyzing these large-scale, heterogeneous, time-varying data are lacking.  To address these challenges, we will establish a Biomedical Technology Resource Center —The Mobilize Center. Through the leadership of an experienced scientific team, we will create and disseminate innovative tools to quantify movement biomechanics with mobile sensors.  Specifically, we will:  1. Push the bounds of what we can measure via wearable sensors using models that compute muscle  and joint forces and metabolic cost of locomotion. These models, based on biomechanical and machine  learning models, will be disseminated via our newly created OpenSense software, which will be used  by thousands of researchers to gain new insights into patient biomechanics using mobile sensors.  2. Meet the need for tools that analyze data about movement dynamics and develop machine learning  models to analyze and generate insights from unstructured, high-dimensional data, including time-  series (e.g., from mobile sensors), images (e.g., MRI), and video (e.g., smartphone video of a patient’s gait).  3. Provide tools needed to intervene in the real-world. We will develop algorithms to accurately quantify  kinematics outside the lab for long durations using data from inertial measurement units (IMUs). We will  also build behavioral models to adapt and personalize goal setting, drawing on movement records from  6 million individuals, as well as health goals and exercise for 1.7 million people.  Through intensive interactions with our Collaborative Projects, we will focus on improving rehabilitation outcomes for individuals with limited mobility due to osteoarthritis, obesity, Parkinson’s disease, and cerebral palsy. The Center’s tools and services will enable researchers to revolutionize how we diagnose, monitor, and treat mobility disorders, providing tools needed to deliver precision rehabilitation at low cost and on a massive scale in the future. Limited mobility due to conditions like osteoarthritis, cerebral palsy, and Parkinson’s affects millions of individuals, at a great cost to public health and personal well-being. Rehabilitation can dramatically improve mobility and function, but current rehabilitation practice requires in- person guidance by a skilled clinician, increasing expense and limiting access. This project will revolutionize how we diagnose, monitor, and treat mobility limitations and enable personalized rehabilitation at low cost and on a massive scale using wearable sensing technology in the future.",Mobilize Center: Models for Mobile Sensing and Precision Rehabilitation,9855893,P41EB027060,"['Address', 'Affect', 'Algorithms', 'Behavioral Model', 'Biomechanics', 'Biomedical Engineering', 'Biomedical Technology', 'Cellular Phone', 'Cerebral Palsy', 'Characteristics', 'Clinic', 'Clinical', 'Communities', 'Computer software', 'Custom', 'Data', 'Data Science', 'Degenerative polyarthritis', 'Diagnosis', 'Disease', 'Documentation', 'Educational workshop', 'Engineering', 'Exercise', 'Exposure to', 'Feedback', 'Foundations', 'Freezing', 'Future', 'Gait', 'Goals', 'Guidelines', 'Home environment', 'Human', 'Image', 'Individual', 'Joints', 'Leadership', 'Literature', 'Locomotion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Metabolic', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Muscle', 'Obesity', 'Parkinson Disease', 'Pathologic', 'Patients', 'Personal Satisfaction', 'Persons', 'Public Health', 'Records', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Resources', 'Series', 'Services', 'Software Tools', 'Time', 'Training', 'Vision', 'base', 'biomechanical model', 'biomedical informatics', 'cohesion', 'coral', 'cost', 'evidence base', 'experience', 'handheld mobile device', 'health goals', 'improved', 'improved functioning', 'improved mobility', 'individualized medicine', 'industry partner', 'innovation', 'insight', 'joint loading', 'kinematics', 'large scale data', 'mHealth', 'mobile computing', 'multidimensional data', 'open source', 'programs', 'sensor', 'sensor technology', 'smart watch', 'societal costs', 'symposium', 'terabyte', 'tool', 'tool development', 'wearable sensor technology']",NIBIB,STANFORD UNIVERSITY,P41,2020,752316,560644462,0.00511619074405657
"Clinical and genetic analysis of retinopathy of prematurity Project Summary The long-term goal of this project is to establish a quantitative framework for retinopathy of prematurity (ROP) care based on clinical, imaging, genetic, and informatics principles. In the previous grant period, we have developed artificial intelligence methods for ROP diagnosis, but real-world adoption has been limited by lack of prospective validation and by perception of these systems as “black boxes” that do not explain their rationale for diagnosis. Furthermore, although biomedical research data are being generated at an enormous pace, much less work has been done to integrate disparate scientific findings across the spectrum from genomics to imaging to clinical medicine. This renewal will address current gaps in knowledge in these areas. Our overall hypotheses are that developing a quantitative framework for ROP care using artificial intelligence and analytics will improve clinical disease management, that building “explainable” artificial intelligence systems will enhance clinical acceptance and educational opportunities, and that analysis of relationships among clinical, imaging, environmental, and genetic findings, in ROP will improve understanding of disease pathogenesis and risk. These hypotheses will be tested using three Specific Aims: (1) Evaluation performance of an artificial intelligence system for ROP diagnosis and screening prospectively. This will include: (a) recruit a target of over 2000 eye exams including wide-angle retinal images from 375 subjects at 5 centers, (b) optimize an image quality detection algorithm we have recently developed, and (c) analyze system accuracy for ROP diagnosis and screening (using a novel quantitative vascular severity scale). (2) Improve the interpretability of our existing artificial intelligence methods for ROP diagnosis. This will include: (a) increase “explainability” of systems by combining deep learning with traditional feature extraction methods, (b) develop neural networks to identify changes between serial images, and (c) evaluate these methods through systematic feedback by experts. (3) Develop integrated models for ROP pathogenesis and risk. This will include: (a) build and improve ROP risk prediction models based on clinical, image, and demographic features, and (b) integrate genetic, imaging, clinical, and environmental variables through genetic risk prediction by machine learning, by investigating casual relationships with genetic variants and genetic risk scores, and by incorporating SNP associations with gene expression measurements to identify functional genes of ROP. Ultimately, these studies will significantly reduce barriers to adoption of technologies such as artificial intelligence for clinicians, and will demonstrate a prototype for health information management which combines genotypic and phenotypic data. This project will be performed by a multi-disciplinary team of investigators who have worked successfully together for nearly 10 years, and who have expertise in ophthalmology, biomedical informatics, computer science, computational biology, ophthalmic genetics, genetic analysis, and statistical genetics. Project Narrative ROP is a leading cause of childhood blindness in the US and throughout the world, and the number of infants at risk for disease is increasing as the rate of premature birth rises. Rapidly-progressive changes associated with retinal vascular development may be visualized by clinical examination, captured by wide-angle imaging, and analyzed genetically. This project will develop, enhance, and validate artificial intelligence and analytic tools to help clinicians identify infants at risk for severe ROP using image analysis, genetic analysis, and integrative informatics that combines these factors – while also providing insight about disease pathogenesis.",Clinical and genetic analysis of retinopathy of prematurity,9974137,R01EY019474,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Bioinformatics', 'Biomedical Research', 'Blindness', 'Blood Vessels', 'Caring', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Research', 'Cohort Studies', 'Computational Biology', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Environment', 'Evaluation', 'Expert Systems', 'Feedback', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Infant', 'Informatics', 'Information Management', 'International', 'Knowledge', 'Longitudinal Studies', 'Machine Learning', 'Macular degeneration', 'Measurement', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular Genetics', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Other Genetics', 'Oxygen', 'Paper', 'Pathogenesis', 'Peer Review', 'Perception', 'Performance', 'Phenotype', 'Predisposition', 'Premature Birth', 'Premature Infant', 'Publishing', 'Randomized', 'Reference Standards', 'Research', 'Research Personnel', 'Retina', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Severities', 'System', 'Technology', 'Testing', 'United States', 'Validation', 'Work', 'analytical tool', 'base', 'biomedical informatics', 'care delivery', 'clinical Diagnosis', 'clinical examination', 'clinical phenotype', 'clinical risk', 'clinically significant', 'computer science', 'data access', 'data integration', 'deep learning', 'diagnosis standard', 'disorder risk', 'feature extraction', 'genetic analysis', 'genetic variant', 'high risk', 'imaging genetics', 'improved', 'insight', 'multidisciplinary', 'multiple data types', 'neovascular', 'neural network', 'novel', 'phenotypic data', 'prospective', 'prototype', 'real world application', 'recruit', 'retinal imaging', 'risk prediction model', 'screening', 'serial imaging']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,764279,304670088,-0.0215960932291776
"Investigating bacterial contributions to TB treatment response: a focus on in-host pathogen dynamics Project Summary/Abstract Rapid and accurate methods to monitor tuberculosis (TB) treatment response do not currently exist. Efforts to improve outcomes have focused on early identification of rifampicin susceptibility followed by prompt treatment initiation and adherence monitoring. The rapid molecular susceptibility tests most often used give dichotomous cutoffs. Recent studies though show that minimum inhibitory concentrations (MICs) just below these breakpoints also predict poor outcomes. Even if a patient takes most of their therapy, clinical response can still vary substantially. Delays in sputum clearance (culture conversion from growth to no growth) can range from a few days to 5 months and failure or relapse rates can be as high as 20% in drug-susceptible TB. During the weeks to months of human infection and antibiotic treatment, in host Mtb populations experience substantial measurable genetic changes. These changes may be neutral or allow pathogen adaption to immune, antibiotic or metabolic pressure, e.g. low iron or cobalamin levels that may result in heritable drug tolerance and resistance phenotypes. Here we propose to study in host longitudinal pathogen dynamics including changes in population diversity over time and identify genes under selection to shed light on host-pathogen interactions. The study of in host pathogen dynamics can improve our understanding of cure from infection and pave the way for the use of whole genome sequencing for monitoring treatment response, circumventing the delays and biohazards of traditional culture-based approaches. We additionally propose the development of a genome- based predictor of MIC and to assess if MIC predictions are associated with delays in culture conversion and poor clinical response. We will systematically study pathogen samples from a well characterized TB treatment patient cohort (NIAID TRUST TB cohort in Worcester, South Africa -PI Dr. Jacobson) combining long and deep short-read sequencing to resolve full genome assemblies and variants at low allele frequency. We have strong preliminary data that long-read sequencing unmasks more Mtb genetic diversity than detectable by short-read sequencing alone and have previously characterized directional selection in a subset of genes including resistance loci, the B12 biosynthesis pathway, and PPE genes known to interact with host innate defense. The proposed work is enabled by our methodological expertise in population genetics, machine learning and resistance prediction for clonal bacteria like Mtb and will allow, for the first time, the study of directional and diversifying selection on the full repertoire of Mtb genetic variation. It will also allow the training of an MIC prediction model on a large ~17,000 isolate dataset curated across studies and geographies. Both study aims promise to inform our understanding of how pathogen genetic variation affects Mtb survival in host and the response to treatment. Project Narrative Patients with tuberculosis (TB) can benefit greatly if we could identify signs of poor response earlier and adjust therapy intensity accordingly. Innovations in DNA isolation and sequencing technologies now enable the study of TB pathogen populations in an individual patient with very high resolution. Here, we propose to use these technologies and a highly well-characterized cohort of South African TB patients to investigate how pathogen population genetic changes link to pathogen survival and treatment response, laying the foundation for improvements in clinical treatment monitoring using DNA sequencing.",Investigating bacterial contributions to TB treatment response: a focus on in-host pathogen dynamics,10100014,R01AI155765,"['Adherence', 'Adopted', 'Affect', 'Aftercare', 'Alcohol abuse', 'Alcohol consumption', 'Anabolism', 'Antibiotic Therapy', 'Antibiotics', 'Attenuated', 'Bacteria', 'Biohazardous Substance', 'Bioinformatics', 'Biological', 'Biological Response Modifiers', 'Clinical', 'Clinical Treatment', 'Cobalamin', 'Communicable Diseases', 'Complex', 'DNA', 'DNA sequencing', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Drug Kinetics', 'Drug Tolerance', 'Drug resistance', 'ELF3 gene', 'Early Intervention', 'Early identification', 'Evaluation', 'Evolution', 'Failure', 'Family', 'Foundations', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic approach', 'Genomics', 'Genotype', 'Geography', 'Growth', 'HIV', 'Heritability', 'Human', 'Immune', 'Immune response', 'Immune system', 'Immunocompetence', 'Immunotherapeutic agent', 'Individual', 'Infection', 'Integration Host Factors', 'Intervention', 'Iron', 'Isoniazid resistance', 'Knowledge', 'Light', 'Link', 'Machine Learning', 'Measurable', 'Metabolic', 'Methodology', 'Methods', 'Minimum Inhibitory Concentration measurement', 'Minor', 'Molecular', 'Monitor', 'Mutation', 'Mycobacterium tuberculosis', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Population Genetics', 'Population Heterogeneity', 'Prediction of Response to Therapy', 'Predisposition', 'Race', 'Recurrent disease', 'Regulator Genes', 'Relapse', 'Resistance', 'Resistance development', 'Resolution', 'Rifampin', 'Role', 'Sampling', 'Source', 'South Africa', 'South African', 'Specific qualifier value', 'Specimen', 'Speed', 'Sputum', 'Structure', 'Technology', 'Test Result', 'Testing', 'Time', 'Time Study', 'Training', 'Treatment Failure', 'Treatment Protocols', 'Treatment outcome', 'Tuberculosis', 'Variant', 'Virulent', 'Work', 'arm', 'base', 'clinical predictors', 'cohort', 'experience', 'genetic variant', 'genome sequencing', 'genomic variation', 'high risk', 'immunological status', 'immunoregulation', 'improved', 'improved outcome', 'in silico', 'individual patient', 'innovation', 'medication compliance', 'novel', 'pathogen', 'pathogen genomics', 'predictive modeling', 'pressure', 'prevent', 'prospective', 'real time monitoring', 'recruit', 'resistance gene', 'resistant strain', 'response', 'statistical and machine learning', 'treatment response', 'tuberculosis treatment', 'whole genome']",NIAID,HARVARD MEDICAL SCHOOL,R01,2020,781859,178569161,-0.016492906990611157
"A New Approach to an Old Problem: Redesigning Latent Tuberculosis Screening and Treatment SUMMARY/ABSTRACT In 2015, tuberculosis (TB) surpassed HIV as the number one cause of infectious disease deaths worldwide. In the U.S., California has the highest incidence and largest number of TB cases in the nation, comprising nearly one-quarter of all new active TB cases in 2017. More than 80% of active TB disease in the U.S. is due to reactivation, which could be prevented via screening and treatment of LTBI. Yet, adoption of the latent TB screening and treatment guidelines has been extremely poor. The screening guidelines are inefficient and rely on data that are almost never available to clinicians, and the treatment guidelines are confusing. Further, treatment initiation and completion rates are low for patients with LTBI and the barriers to successful treatment are poorly understood. To address these missed opportunities, we will use expansive electronic health record data across 2 of the largest healthcare institutions in California as well as qualitative data from LTBI stakeholders to conduct three specific aims. For Aim 1, we will look at current gaps in screening practices for LTBI, as well as gaps in the guidelines themselves, by simulating what it would look like if screening was being perfectly implemented. To do this, we will collect laboratory testing data for LTBI stratified by characteristics of interest and will use modeling to estimate the number of TB cases prevented by current screening as a measure of effectiveness. We will use simulation models to estimate effectiveness of optimal screening. For Aim 2, we will develop and validate new screening and treatment guidelines for LTBI based on variables widely available in electronic health records. First, we will use machine learning and traditional regression to identify risk factors for positive LTBI tests and reactivation TB. Next, we will assign risk scores to each risk factor, and will use joint probability analyses to identify populations at greatest need for screening and treatment. To estimate performance of the newly proposed strategy, we will use simulation modeling. For Aim 3, we will develop and pilot a culturally-tailored educational video intervention to improve LTBI treatment initiation and completion. We will first identify barriers to treatment adherence through qualitative interviews with patients and providers and will subsequently develop a short video based on findings from the interview. We will perform an individually randomized efficacy trial to assess impact of the intervention on initiation and treatment completion rates. The approach is innovative because we propose a complete re-framing of the current U.S. LTBI control strategy in a way that dramatically enhances ease-of-use for frontline providers. Results of this work will make a significant contribution to public health by providing low-cost and easily expandable solutions to address ongoing and substantial gaps in the current LTBI care continuum. PROJECT NARRATIVE California has the highest incidence and largest number of tuberculosis (TB) cases in the contiguous U.S., of which 80% are due to reactivation. These TB cases can be prevented via screening and treatment of latent tuberculosis infection (LTBI), yet, current adoption of the latent TB screening and treatment guidelines has been extremely poor. We will leverage expansive electronic health record data from two of the largest healthcare organizations in California to create and validate a new LTBI screening and treatment approach that can vastly improve identification and successful treatment of LTBI.",A New Approach to an Old Problem: Redesigning Latent Tuberculosis Screening and Treatment,9943464,R01AI151072,"['Address', 'Adoption', 'California', 'Caring', 'Cessation of life', 'Characteristics', 'Collaborations', 'Communicable Diseases', 'Continuity of Patient Care', 'Data', 'Disease', 'Educational Intervention', 'Effectiveness', 'Electronic Health Record', 'Guidelines', 'HIV', 'Healthcare', 'Incidence', 'Individual', 'Infection Control', 'Institution', 'Intervention', 'Interview', 'Joints', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Modeling', 'Patient Care', 'Patients', 'Performance', 'Pharmacy facility', 'Population', 'Population Heterogeneity', 'Positioning Attribute', 'Probability', 'Provider', 'Public Health', 'Randomized', 'Recording of previous events', 'Research', 'Resources', 'Risk', 'Risk Factors', 'System', 'Testing', 'Time', 'Translating', 'Tuberculosis', 'United States', 'Work', 'barrier to care', 'base', 'clinical practice', 'compare effectiveness', 'cost', 'data resource', 'effectiveness measure', 'efficacy trial', 'evidence base', 'experience', 'health care service organization', 'improved', 'innovation', 'interest', 'member', 'models and simulation', 'novel strategies', 'point of care', 'prevent', 'racial and ethnic', 'screening', 'screening guidelines', 'screening program', 'simulation', 'treatment adherence', 'treatment guidelines', 'wasting']",NIAID,KAISER FOUNDATION RESEARCH INSTITUTE,R01,2020,800637,111231681,-0.020452323827131174
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9975252,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Anti-Tumor Necrosis Factor Therapy', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Individual', 'Institution', 'Intuition', 'Leukocyte Chemotaxis', 'Lymphocyte Immunophenotypings', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Sampling', 'Series', 'Stains', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'analysis pipeline', 'base', 'big-data science', 'clinical diagnostics', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'education resources', 'human disease', 'improved', 'inquiry-based learning', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'myocardial injury', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2020,801165,3808719,0.01589493525220291
"An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis Project Summary  Improved methods for the bedside diagnosis and evaluation of neuromuscular disorders are needed. One technology that is finding increasing use for this purpose is electrical impedance myography (EIM). In EIM, a very weak, high frequency electrical current is passed through a muscle of interest and the resulting surface voltages are measured. Disease associated alterations in the composition and microstructural features of the muscle produce characteristic changes that can be used to help classify specific conditions and grade disease severity. To date, most studies using EIM analysis have utilized a fairly limited data set for disease assessment. While effective, this approach ignores a great deal of information locked within the impedance data, including those values that can assist in predicting specific muscle features (such as myofiber diameter) and the presence of pathological change (e.g., fat or connective tissue deposition). In addition, as it stands, the data set is challenging for the clinician to understand without a detailed knowledge of impedance theory. Myolex, Inc is a small business concern located in Boston, MA has as its main focus the development of EIM technologies for clinical use. Myolex recently completed a Phase 1 SBIR that demonstrated the potential capability of machine learning based classification algorithms to effectively discriminate healthy muscle from diseased and to discriminate one disease from another. In this proposed work, we will greatly advance this concept by embodying classification algorithms into a powerful new software suite for Myolex’s current EIM system, the mView. Our underlying hypothesis is that EIM data analysis can be automated to the point that classification systems can provide data on disease diagnosis as well as disease severity for improved ease-of-use. We propose to study this hypothesis via 2 specific aims. In Specific Aim 1, we will design a software suite capable of assisting with artifact-free data collection to be incorporated into our current EIM system, the mViewTM. Then using classification paradigms based on a prodigious amount of previous collected data, we will develop an automated data analysis tool to help provide data on disease category as well as microscopic features, muscle based on the impedance data alone using Microsoft’s Azure Cloud platform. In Specific Aim 2, we will test this developed software suite in a total of180 adult and pediatric neuromuscular disease patients and healthy participants evaluated at Ohio State University Wexner Medical Center (adults) and Boston Children’s Hospital (children). During this data collection period, the Ohio State and Boston Children’s researchers will have real- time access to Myolex staff to provide feedback and have questions/problems answered and addressed. The user interface will continue to be refined and classification algorithms improved. At the conclusion of this work, a new diagnostic tool will be developed for potential 510(k) FDA approval. It will serve as the basis for a continuously self-refining system as additional data sets are collected by end-users employing them in regular clinical use. Project Narrative  Electrical impedance myography (EIM) is a valuable technique to assist with the evaluation of a variety of conditions affecting nerve and muscle. However, to date, only simplistic EIM outcomes have been utilized to assess muscle condition. In this proposed work, we will develop a software platform using machine learning to be incorporated into current EIM technology to allow for automated diseased classification and characterization using the entire large EIM data set collected with each muscle measurement. This will serve as the basis for a new, powerful and convenient tool for neuromuscular diagnosis that will continue to advance over time.",An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis,10002324,R44NS113756,"['Address', 'Adult', 'Affect', 'Algorithmic Software', 'Amyotrophic Lateral Sclerosis', 'Area', 'Back Pain', 'Boston', 'Businesses', 'Caliber', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Classification', 'Clinical', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Set', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Duchenne muscular dystrophy', 'Effectiveness', 'Electrodes', 'Ensure', 'Evaluation', 'Fatty acid glycerol esters', 'Feedback', 'Fiber', 'Frequencies', 'Functional disorder', 'Health', 'Inclusion Body Myositis', 'Individual', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Medical Technology', 'Medical center', 'Methods', 'Microscopic', 'Morphologic artifacts', 'Muscle', 'Muscular Dystrophies', 'Myography', 'Myopathy', 'Myositis', 'Nerve', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Ohio', 'Outcome', 'Participant', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Provider', 'Radiculopathy', 'Research Personnel', 'Role', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Work', 'advanced analytics', 'base', 'classification algorithm', 'cloud based', 'cloud platform', 'commercialization', 'complex data ', 'data acquisition', 'design', 'diagnosis evaluation', 'disease classification', 'disease diagnosis', 'electric impedance', 'feature extraction', 'improved', 'indexing', 'interest', 'machine learning algorithm', 'method development', 'nerve injury', 'neuromuscular', 'novel diagnostics', 'pediatric patients', 'physical therapist', 'prototype', 'sarcopenia', 'software development', 'success', 'theories', 'tool', 'usability', 'user friendly software', 'user-friendly', 'voltage']",NINDS,"MYOLEX, INC.",R44,2020,869698,869698,0.0034304829883875514
"Human Tumor Atlas Network: Data Coordinating Center Supplement This proposal is a collaboration with the HTAN Data Coordination Center DCC and describes an Image Data Project aimed at developing and deploying the technology needed for storage, distribution and basic analysis of cell and tissue images collected by multiple HTAN Centers. Multiplexed tissue images are an important type of data for nearly all of the centers contributing to the HTAN (second only to single cell sequencing data in number of centers collecting data). However, the software needed to visualize, analyze, manage, and share multiplexed images of tissues and tumors is underdeveloped. The initial availability of SARDANA images has highlighted the challenges faced by HTAN, including the DCC, in deploying an infrastructure for distributing large and complex images. We therefore propose a two-year HTAN Image Data Project (IDP) led by the DCC and HMS PCA focused on the rapid development and deployment of image informatic systems and computational resources for image management and analysis. Our goal is to put in place a functional first-generation system no later than summer 2020 and to then steadily refine the system so that it becomes the backbone of cross-functional HTAN atlases. As a matter of necessity, we will start with informatic systems and software that are either available today or in a relatively advanced state of development. However, we expect to evaluate these choices throughout the IDP and change course as necessary to incorporate potentially superior approaches. We will also support the diverse needs and formats of centers using different data collection methods. Aim 1 will focus on the deployment and progressive improvement of a cloud-based database for image management based on the OMERO standard as well as a parallel system for access to primary data. Aim 2 will develop and deploy software for visualizing HTAN image data by the general public. The IDP will use the existing MCWG and DAWG mechanisms for oversight and reporting, and all centers will be invited to participate. Within IDP, the HMS PCA will take primary responsibility for initial deployment of image informatics software. The DCC and HMS will jointly undertake software development and code hardening, and the DCC will take the lead in user assistance and software deployment, particularly in year two. Images of tumor specimens obtained from biopsy or surgery are one of the primary ways in which cancer is diagnosed and staged by pathologists, but such images have typically lacked molecular detail. The highly multiplexed tissue images being collected by HTAN will fundamentally change this, and it is therefore essential that the data be efficiently and widely distributed. The HTAN Image Data Project IDP will address an acute need for software for data dissemination and visualization.",Human Tumor Atlas Network: Data Coordinating Center Supplement,10206514,U24CA233243,"['Acute', 'Address', 'Atlases', 'Bioinformatics', 'Biopsy', 'Client', 'Code', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Databases', 'Development', 'Diagnosis', 'European', 'General Population', 'Generations', 'Goals', 'Human', 'Image', 'Imaging Device', 'Informatics', 'Infrastructure', 'Institutes', 'Lead', 'Malignant Neoplasms', 'Manuscripts', 'Methods', 'Modeling', 'Molecular', 'Operative Surgical Procedures', 'Output', 'Pathologist', 'Performance', 'Reporting', 'Side', 'Slide', 'Software Tools', 'Specimen', 'System', 'Technology', 'Testing', 'Tissue imaging', 'Tissues', 'Vertebral column', 'Visualization', 'base', 'cancer imaging', 'cellular imaging', 'cloud based', 'computing resources', 'data dissemination', 'data management', 'data resource', 'data visualization', 'imaging Segmentation', 'imaging informatics', 'improved', 'machine learning algorithm', 'multiplexed imaging', 'programs', 'relational database', 'single cell sequencing', 'software development', 'supervised learning', 'tumor']",NCI,DANA-FARBER CANCER INST,U24,2020,926364,174094914,-0.008627709617693428
"Multiplexed Antigen-Specific Antibody Fc Profiling on a Chip for Point-of-Care Diagnosis of TB in HIV-infected Children Abstract: Tuberculosis (TB) is a leading cause of death in children, with an estimated 1 million children affected, and more than 200,000 deaths in children yearly due to TB. HIV coinfection has been estimated to contribute to more than 35% of TB-related deaths in children in Africa, making the collision of the HIV and TB epidemics one of the most lethal to date. Both HIV infection as well as HIV-exposure in utero, among HIV-exposed but uninfected (HEU) children, have been linked to higher risks for the development of TB among young children. Failures to prevent TB disease and devastation has been attributed to the lack of an effective vaccine as well as our inability to diagnose children under the age of 5 due to the difficulty in obtaining sputum and the paucibacillary nature of the disease in young children. Thus, an inexpensive biomarker-based diagnostic test tailored for pediatric TB using non-sputum samples that could be used at the point of care in resource-limited settings could profoundly improve TB treatment and prevent deaths in children, especially in those under 5 years of age. While Mtb-specific antibody titer-based diagnostics have performed poorly in the past, due to the inability of accurately distinguishing between active TB disease from latent TB infection (LTBI), recent data from our group has shown that Mtb-specific antibody glycosylation shifts significantly across disease states. Moreover, this antigen-specific antibody glycosylation approach reliably classifies individuals into active and latent disease states across HIV infection status, across geographies and can even distinguish recent Typhoid infection among children in endemic areas. Based on these observations, a simple binding-based assay was developed that can rapidly, sensitively, and specifically detect changes in Mtb-specific antibody glycosylation from a small sample volume offering an opportunity for the first time to develop an antigen-specific antibody glycosylation diagnostic for pediatric TB from a microliter-scale sample. Given that HIV+, HEU, or unexposed children may target distinct Mtb antigens, here we have assembled a multi-disciplinary team and program termed FASTER-Kids (Fc Antibody Signatures for TubERculosis in children) that will: 1) Define the landscape of Mtb-specific antibody glycosylation responses that distinguish children with TB, 2) Develop a point-of-care test that will rapidly capture these specific antibody responses and glycosylation changes from microliters of blood. Ultimately, this collaborative structure will enable the iterative improvement and development of this simple, rapid, inexpensive diagnostic to manage TB infection in young children. Based on accumulating data pointing to highly significant shifts in TB-specific antibody glycosylation across latent and active TB disease, the goal of this proposal is to develop an inexpensive, simple, reliable TB-specific antibody-based point-of-care diagnostic to manage TB disease in children under the age of 5.",Multiplexed Antigen-Specific Antibody Fc Profiling on a Chip for Point-of-Care Diagnosis of TB in HIV-infected Children,9986268,R01AI152158,"['5 year old', 'Acute', 'Adult', 'Affect', 'Africa', 'Age', 'Antibodies', 'Antibody Response', 'Antibody titer measurement', 'Antigen Targeting', 'Antigens', 'Area', 'Bedside Testings', 'Binding', 'Biological Assay', 'Biological Markers', 'Blood', 'Cause of Death', 'Cessation of life', 'Child', 'Childhood', 'Classification', 'Clinical', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Drops', 'Electrical Engineering', 'Enrollment', 'Epidemic', 'Exposure to', 'Failure', 'Geography', 'Goals', 'HIV', 'HIV Infections', 'HIV/TB', 'Immunologist', 'Individual', 'Infant', 'Infection', 'Inflammatory', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Mycobacterium tuberculosis', 'Nature', 'Polysaccharides', 'Population', 'Preparation', 'Pulmonary Tuberculosis', 'Reporting', 'Resources', 'Sampling', 'Scheme', 'Sensitivity and Specificity', 'Serologic tests', 'Serum', 'Severities', 'South Africa', 'Specificity', 'Sputum', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Translating', 'Tuberculosis', 'Typhoid Fever', 'Vaccines', 'base', 'co-infection', 'cohort', 'diagnostic accuracy', 'glycosylation', 'high risk', 'improved', 'microchip', 'miniaturize', 'multidisciplinary', 'novel', 'pathogen', 'pediatrician', 'point of care', 'point-of-care diagnostics', 'prenatal exposure', 'prevent', 'programs', 'prospective', 'response', 'sensor', 'tuberculosis treatment']",NIAID,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,974009,551214295,-0.08115388859873002
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,9965942,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data warehouse', 'database design', 'deep learning', 'heuristics', 'improved', 'in silico', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'personalized diagnostics', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2020,989602,254622553,-0.006979546066623485
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,9970170,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'automated algorithm', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'machine learning algorithm', 'multidisciplinary', 'pathogen', 'point of care', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2020,991540,51931732,0.004959573977544058
"Opera Phenix High-Content Imaging System for Drug Discovery PROJECT SUMMARY The University of Pittsburgh Drug Discovery Institute (UPDDI) is requesting funds to purchase the Perkin Elmer OPERA PHENIX high speed, high resolution spinning disk confocal High-Content Screening (HCS) device. The Opera Phenix will replace two Molecular Devices ImageXpress Ultra high content readers purchased in 2008, which are critical to multiple NIH-, DoD-, and Foundation-funded projects at the University of Pittsburgh, but are no longer supported by the manufacturer and have been decommissioned. We have determined that one Opera Phenix instrument can replace the two IXUs. The Phenix is a third generation HCS instrument that will be essential to satisfy the diverse needs of users that the UPDDI serves. No comparable instruments exist at the University of Pittsburgh, the University of Pittsburgh Medical Center, and Carnegie Mellon University. Over the last decade, HCS has become a standard in the pharmaceutical industry for target identification, phenotypic screening, as well as toxicology, and in academia for large-scale biological studies, where cell-by- cell quantitation is critical. The UPDDI has been an academic pioneer in the application of HCS and serves an extensive number of collaborators across campus that require and rely on HCS, ranging from neurodegeneration, organ regeneration, cancer, liver diseases, organotypic model development, and traumatic brain injury. Our diverse user groups’ needs emphasize discovery models of physiological relevance and high complexity, and therefore require fast, high resolution 2D, 3D, and kinetic imaging and maximum flexibility in image analysis. The large number of HCS users working in the UPDDI further demands a fast system to permit effective sharing of instrument time, and an integrated database with off-site user access to perform off- line analysis. Key requirements for an HCS imager therefore are superior speed in acquiring z-series of images at high resolution of thick specimens in aqueous matrices, mature yet flexible image algorithms, and seamless integration of instrument software with system, public,and custom-developed UPDDI databases. The only instrument that meets all of these criteria is the Opera Phenix because it has 1) fast laser-based illumination and the ability to acquire multiple channels simultaneously 2) water immersion objectives that eliminate non-matching refractive indices, which limit spherical aberrations of air and oil objectives at longer working distances and require adjustment of correction collars depending on imaging depth; 3) a powerful suite of user-friendly yet flexible image analysis routines including a 3D module, advanced texture and morphology analysis, and intuitive and user-friendly machine learning; and 4) the ability to perform seamless “adaptive high-resolution imaging”, i.e., pre-scanning a large area at low magnification, followed by automated “on-the- fly” switching to higher magnification to acquire high resolution images of user-defined regions of interest. The Opera Phenix is the only instrument on the market that is capable of fulfilling the demands of the University of Pittsburgh’s diverse drug discovery community. PROJECT NARRATIVE Modern drug discovery increasingly demands better and more disease relevant models and the ability to analyze them. High-content screening (HCS) has become indispensable in the analysis of such models as it permits the analysis of cells, their constituents, and interactions in their proper biological context. The third generation HCS instrument, Opera Phenix, produces the quality and quantity of data from cells, tissues and experimental animals that are required for computational and systems biological investigations, while at the same time providing the throughput needed for automated screening.",Opera Phenix High-Content Imaging System for Drug Discovery,9935240,S10OD028450,"['3-Dimensional', 'Academia', 'Air', 'Algorithms', 'Area', 'Biological', 'Cells', 'Communities', 'Computer software', 'Custom', 'Databases', 'Devices', 'Drug Industry', 'Foundations', 'Funding', 'Generations', 'Image', 'Image Analysis', 'Immersion', 'Institutes', 'Intuition', 'Kinetics', 'Lasers', 'Lighting', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical center', 'Molecular', 'Morphology', 'Nerve Degeneration', 'Oils', 'Phenotype', 'Reader', 'Refractive Indices', 'Resolution', 'Scanning', 'Series', 'Site', 'Specimen', 'Speed', 'System', 'Texture', 'Thick', 'Time', 'Toxicology', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Universities', 'Water', 'aqueous', 'base', 'drug discovery', 'flexibility', 'high resolution imaging', 'imager', 'imaging system', 'instrument', 'interest', 'model development', 'organ regeneration', 'physiologic model', 'screening', 'user-friendly']",OD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,S10,2020,1010594,570146095,-0.02967498116664016
"THE SEARCH FOR COVID-19 PREVENTION AND CURE: ADDRESSING THE CRITICAL ROLE OF INNATE/ADAPTIVE IMMUNITY BY INTEGRATING NOVEL INFORMATICS, TRANSLATIONAL TECHNOLOGIES, AND ONGOING CLINICAL TRIAL RESEARCH Individual CTSA hubs are leading the national clinical and translational research efforts in developing new approaches to address the COVID-19 pandemic. This crucial role was natural. Long before the current crisis, CTSA hubs were committed to translation, building multidisciplinary teams of investigators and community partners, overcoming regulatory burdens, ensuring quality in clinical and human research, developing transformative informatics, and disruptive technologies for diagnostics and therapeutics. In this proposal, we build on our center’s active participation in meaningful clinical trials (e.g., the NIH Remdesivir RCT), the early creation of a biospecimen repository from COVID-19 patients, institutional commitment and fundraising that led to a $3.5 million pilot fund distribution, a robust and accessible clinical database repository, and the ongoing work of an NCATS-supported CTSA Collaboration Innovation Award (a coalition of the J. Craig Venter Institute, UCSD, UCI, and Stanford) focused on artificial intelligence approaches for the analysis of flow cytometry data. Using the emerging informatics framework of supervised generalized canonical correlation for integrative data analysis, we will link clinical data from COVID-19 patients enrolled in a variety of trials and at various stages of disease with innovative in vitro evaluation of innate and adaptive immunity, an area still poorly understood in SARS-CoV-2 pathology, obtained from patient biospecimens to obtain mechanistic insights of COVID-19 pathogenesis at a systems level. Innate and adaptive immunity are particularly relevant to COVID-19 disease pathogenesis because they play key, but distinct, roles at all phases of the illness (initial tissue-virus interaction; systemic responses; the cell-mediated cytokine storm leading to multi- organ failure and death, likely long after levels of viremia have fallen; and, ultimately, protective immunity). The current CCIA novel flow cytometry informatics research permits elucidation of dynamic cellular immune responses related to the COVID-19 pandemic that were heretofore unobservable. Using Hi-DAFi for mass cytometry analysis, validated informatics pipelines for single cell transcriptomics analysis, and cutting-edge statistical data integration and machine learning strategies tied back to the available clinical data we will be able to discover novel associations between cellular biomarkers and disease state, a particular therapy, and disease mediating factors such as age, health disparities, and the presence of other diseases or conditions like obesity. This information will aid in critical efforts to target new therapies and possibly identify idiosyncratic individual physiologic variables that render certain patients who seem to have no known comorbidities more vulnerable to severe COVID-19 disease. Finally, the robust connection between the UCI hub and both regional and national networks (e.g., BRAID, the coalition of the 5 UC CTSAs, and NCATS Trial Innovation Network) will provide an unprecedented opportunity to rapidly disseminate clinically relevant discoveries and engage the talent and insight of the many clinicians and scientists working tirelessly to end this pandemic. BLANK PER PA-18-591","THE SEARCH FOR COVID-19 PREVENTION AND CURE: ADDRESSING THE CRITICAL ROLE OF INNATE/ADAPTIVE IMMUNITY BY INTEGRATING NOVEL INFORMATICS, TRANSLATIONAL TECHNOLOGIES, AND ONGOING CLINICAL TRIAL RESEARCH",10158982,UL1TR001414,"['2019-nCoV', 'Acceleration', 'Address', 'Age', 'Antibody titer measurement', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Award', 'B-Lymphocytes', 'Back', 'Biological Assay', 'Biological Markers', 'Biological Specimen Banks', 'Biomedical Research', 'Blood Circulation', 'Blood specimen', 'COVID-19', 'COVID-19 pandemic', 'Cardiovascular system', 'Cells', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communities', 'Controlled Clinical Trials', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Enrollment', 'Ensure', 'Evaluation', 'Failure', 'Flow Cytometry', 'Foundations', 'Funding', 'Future', 'Genetic Determinism', 'Genetic Transcription', 'Goals', 'Health', 'Human', 'IL6 gene', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Immunologics', 'Immunology', 'Immunology procedure', 'In Vitro', 'Incidence', 'Individual', 'Industry', 'Infection', 'Inflammatory', 'Informatics', 'Institutes', 'Institution', 'Interleukin-10', 'Leadership', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Molecular', 'Monitor', 'Multiomic Data', 'Natural Immunity', 'Nucleic Acids', 'Obesity', 'Paper', 'Participant', 'Pathogenesis', 'Pathology', 'Patients', 'Phase', 'Physiological', 'Placebos', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Research', 'Research Personnel', 'Resources', 'Respiratory distress', 'Role', 'Sampling', 'Schedule', 'Scientist', 'Serologic tests', 'Severity of illness', 'Signal Transduction', 'Supervision', 'Symptoms', 'System', 'T-Lymphocyte', 'TNF gene', 'Talents', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Trials', 'Therapy Clinical Trials', 'Tissues', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Vaccines', 'Validation', 'Viral Load result', 'Viremia', 'Virus', 'Work', 'adaptive immunity', 'clinical database', 'clinically relevant', 'comorbidity', 'computer framework', 'computing resources', 'cytokine', 'cytokine release syndrome', 'data integration', 'data warehouse', 'dissemination research', 'early detection biomarkers', 'enzyme linked immunospot assay', 'experience', 'feature selection', 'health disparity', 'innovation', 'insight', 'interest', 'learning strategy', 'meetings', 'multidisciplinary', 'multiple omics', 'new therapeutic target', 'novel', 'novel strategies', 'pandemic disease', 'predictive marker', 'remdesivir', 'repository', 'respiratory', 'response', 'statistical and machine learning', 'transcriptome sequencing', 'transcriptomics', 'treatment response', 'virus genetics']",NCATS,UNIVERSITY OF CALIFORNIA-IRVINE,UL1,2020,1088735,167717872,-0.007311113810926369
"Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria PROJECT SUMMARY Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacterial infections are increasing in incidence and novel antibiotics are urgently needed to combat this growing threat to public health. A major roadblock to the development of novel antibiotics is our poor understanding of the structural features of small molecules that correlate with bacterial penetration and efflux. As a result, while potent biochemical inhibitors can often be identified for new targets, developing them into compounds with whole-cell antibacterial activity has proven challenging. To address this critical problem, we propose herein a comprehensive, multidisciplinary approach to develop quantitative models to predict small-molecule penetration and efflux in Gram-negative bacteria. We have pioneered a general platform for systematic, quantitative evaluation of small-molecule accumulation in bacteria, using label-free LC-MS/MS detection and multivariate cheminformatic analysis. We have also developed unique isogenic strain sets of wild-type, hyperporinated, efflux-knockout, and doubly-compromised E. coli, P. aeruginosa, and A. baumannii that allow us to dissect the individual contributions of outer/inner membrane penetration and active efflux to net accumulation, using a kinetic model that accurately recapitulates available experimental data. Moreover, we have developed machine learning and neural network approaches to QSAR (quantitative structure–activity relationship) modeling of pharmacological properties that will now be used to develop predictive cheminformatic models for Gram-negative accumulation, penetration, and efflux. This project will be carried out by a multidisciplinary SPEAR-GN Project Team (Small-molecule Penetration & Efflux in Antibiotic-Resistant Gram-Negatives, “speargun”) involving the labs of Derek Tan (MSK, PI), Helen Zgurskaya (OU, PI), Bradley Sherborne (Merck, Lead Collaborator), Valentin Rybenkov (OU, Co-I), Adam Duerfeldt (OU, Co-I), Carl Balibar (Merck, Collaborator), and David McLaren (Merck, Collaborator), comprising extensive combined expertise in organic and diversity-oriented synthesis, biochemistry, microbiology, high- throughput screening, mass spectrometry, biophysical modeling, cheminformatics, and medicinal chemistry. Herein, we will design and synthesize chemical libraries with diverse structural and physicochemical properties; analyze their accumulation in the isogenic strain sets in both high-throughput and high-density assay formats; extract kinetic parameters for penetration and efflux from the resulting experimental datasets; develop and validate robust QSAR models for accumulation, penetration, and efflux; and demonstrate the utility of these models in medicinal chemistry campaigns to develop novel Gram-negative antibiotics against three targets. This project will provide a major advance in the field of antibacterial drug discovery, providing powerful enabling tools to the scientific community to address this major threat to public health. PUBLIC HEALTH RELEVANCE Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacteria pose a growing threat to public health in the U.S. and globally. A major obstacle to the development of new antibiotics to combat such infections is our poor understanding of the chemical requirements for small molecules to enter Gram-negative cells and to avoid ejection by efflux pumps. The proposed comprehensive, multidisciplinary research program aims to develop predictive computational tools to identify such molecules by carrying out large-scale, quantitative analyses of the accumulation of diverse small molecules in Gram-negative bacteria. These tools will then enable medicinal chemistry campaigns to develop novel antibiotics.",Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria,9982190,R01AI136795,"['Acinetobacter baumannii', 'Address', 'Algorithmic Software', 'Anti-Bacterial Agents', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Bacteria', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Availability', 'Cells', 'Chemicals', 'Communities', 'Data', 'Data Set', 'Detection', 'Development', 'Effectiveness', 'Escherichia coli', 'Gram-Negative Bacteria', 'Gram-Negative Bacterial Infections', 'Human', 'Incidence', 'Individual', 'Infection', 'Interdisciplinary Study', 'Kinetics', 'Knock-out', 'Label', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Membrane', 'Microbiology', 'Modeling', 'Oral', 'Partner in relationship', 'Penetration', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Property', 'Pseudomonas aeruginosa', 'Public Health', 'Quantitative Evaluations', 'Quantitative Structure-Activity Relationship', 'Role', 'Structure', 'Testing', 'Variant', 'analog', 'base', 'biophysical model', 'cell envelope', 'cheminformatics', 'combat', 'computerized tools', 'density', 'design', 'drug discovery', 'efflux pump', 'high throughput screening', 'improved', 'inhibitor/antagonist', 'interdisciplinary approach', 'kinetic model', 'lead optimization', 'learning network', 'multidisciplinary', 'neural network', 'novel', 'predictive modeling', 'programs', 'prospective', 'public health relevance', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool']",NIAID,SLOAN-KETTERING INST CAN RESEARCH,R01,2020,1239304,185946435,-0.01827211596627451
"Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt Founded in 1965 as one of the original Intellectual and Developmental Disorders Research Centers (IDDRC), the Vanderbilt Kennedy Center (VKC) IDDRC serves as the central nexus across Vanderbilt for interdisciplinary research, communication, and training in intellectual and developmental disabilities (IDD). The VKC IDDRC serves as a trans-institutional institute that brings together over 200 faculty from 38 departments in 10 schools at Vanderbilt. The VKC’s mission to facilitate discoveries that inform best practices to improve the lives of people with IDD and their families. This mission is met by leveraging our outstanding institutional resources and support, partnering with disability communities, and capitalizing on synergistic interactions across the VKC’s federally-designated centers: the VKC IDDRC, a University Center of Excellence in Developmental Disabilities and a Leadership Education in Neurodevelopmental Disabilities program. The IDDRC as the centerpiece of the VKC is the foundational organizing structure that creates a “Center culture” wherein research and discovery permeates the VKC’s broader training and service activities, thus enhancing the translational research goals of the IDDRC. Demonstrable IDDRC success includes 976 investigator- authored publications and robust NIH funding to Vanderbilt to support IDD-related research ($52.6M in FY20). Harnessing and leveraging this trans-institutional strength to focus on unique challenges in IDD, the overarching goal of the next phase of the IDDRC is to develop precision care for IDD by providing infrastructure and scientific leadership to enable rapid translation of basic discoveries into high- impact IDD interventions and treatments. Three global Aims guide the IDDRC’s work. Aim 1 provides core services to enable and disseminate impactful research on individualizing treatments based upon the causes, mechanisms, and contributing co-morbid sequelae of IDD; Aim 2 focuses on incorporating innovative methods and approaches to enhance multidisciplinary IDD research; and Aim 3 proposes to conduct a signature research project to improve the precision use of antipsychotic medication in people with autism. Across these Aims and five Cores supported by the IDDRC (Administrative, Clinical Translational, Translational Neuroscience, Behavioral Phenotyping, and Data Sciences), three themes permeate our work: (1) recruitment of highly-skilled researchers not currently conducting IDD research (non-traditional researchers); (2) inclusion of IDD participants into research studies that currently do not include IDD (non-traditional subjects); and (3) incorporation of novel scientific approaches and methods (non-traditional approaches). Our IDDRC is ideally posed to enable rapid discovery of precision care approaches by supporting 50 investigators leading 70 research projects (15 from NICHD) and, as highlighted by the Signature Research Project, to promote and implement generative, novel, and impactful research directions, thus meeting the NICHD’s vision of applying newly evolved technologies and approaches to rapidly accelerate the prevention and/or amelioration of IDDs. PUBLIC HEALTH RELEVANCE: As a group, intellectual and developmental disabilities, including Down syndrome and autism spectrum disorder, have dramatic effects on affected people’s and their caregiver’s lives. Unfortunately, there remains a lack of understanding about what causes these disabilities and, critically, how to treat them with targeted therapies. The Vanderbilt Kennedy Center’s Intellectual and Developmental Disabilities Research Center serves as the hub for Vanderbilt’s research efforts focusing on improving the lives of people with intellectual and developmental disabilities by understanding the causes of these disorders and developing and testing therapies tailored to each individual’s precise needs.",Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt,10085550,P50HD103537,"['Academic Medical Centers', 'Affect', 'Antipsychotic Agents', 'Basic Science', 'Behavioral', 'Biomedical Research', 'Caregivers', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communication', 'Communities', 'Computerized Medical Record', 'Data', 'Data Science', 'Development', 'Developmental Disabilities', 'Diagnosis', 'Disease', 'Disease model', 'Down Syndrome', 'Education', 'Evaluation', 'Faculty', 'Family', 'Foundations', 'Funding', 'Future', 'Gap Junctions', 'Genotype', 'Goals', 'Image', 'Individual', 'Infrastructure', 'Institutes', 'Intellectual and Developmental Disabilities Research Centers', 'Intellectual functioning disability', 'Interdisciplinary Study', 'Intervention', 'Leadership', 'Longevity', 'Machine Learning', 'Medical Records', 'Methods', 'Mission', 'Modeling', 'National Institute of Child Health and Human Development', 'Neurodevelopmental Disability', 'Obesity', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Pilot Projects', 'Policy Research', 'Prevention', 'Problem behavior', 'Publications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Sampling', 'Schools', 'Series', 'Services', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Universities', 'Vision', 'Weight Gain', 'Work', 'autism spectrum disorder', 'base', 'behavioral phenotyping', 'clinical translation', 'comorbidity', 'cost effective', 'developmental disease', 'disability', 'drug-induced weight gain', 'experience', 'image processing', 'implementation science', 'improved', 'individualized medicine', 'innovation', 'large datasets', 'lectures', 'meetings', 'multidisciplinary', 'novel', 'personalized approach', 'personalized care', 'personalized medicine', 'population based', 'pragmatic trial', 'predictive modeling', 'programs', 'public health relevance', 'recruit', 'research study', 'success', 'targeted treatment', 'translational neuroscience', 'trial comparing']",NICHD,VANDERBILT UNIVERSITY MEDICAL CENTER,P50,2020,1387605,377931988,-0.025529166446536727
"Childhood ‘Omics’ and Mycobacterium tuberculosis-derived BiOsignatures (COMBO) for TB diagnosis in high HIV prevalence settings PROJECT SUMMARY There is an urgent need to develop non-sputum biomarker-based triage and diagnostic tests for childhood tuberculosis (TB). This is particularly important for young children with HIV infection, who have high TB-related mortality but often cannot produce sputum and have lower sputum bacillary burden. Biomarker discovery for childhood TB requires ultra-sensitive platforms to measure low-abundant Mycobacterium tuberculosis (Mtb) proteins in clinical samples and greater investigation of host proteins, post-translational modifications of proteins, and metabolites that are more likely than upstream RNA expression to reflect the host-pathogen interactions that lead to TB disease. The overall objective of the proposed project is to identify Mtb- and/or host-derived biosignatures in children that can achieve World Health Organization (WHO) target product profile (TPP) accuracy thresholds for a non-sputum biomarker-based triage or diagnostic test for childhood TB. We hypothesize that biosignatures that combine Mtb proteins and host biomarkers with evidence of functional relevance to TB pathogenesis or immunity will have the best diagnostic performance. To assess this hypothesis, we will conduct biomarker discovery and initial clinical validation studies using samples from three well- characterized pediatric TB cohorts in Uganda, The Gambia and South Africa. In Aim 1, we will use an ultra- sensitive electrochemoluminescence (ECL)-based immunoassay to assess the presence of Mtb proteins ESAT- 6, CFP-10, MPT64, MPT32, and Ag85B in a discovery set of banked blood and urine samples from 100 children under 5 years old with confirmed TB and 200 with unlikely TB per NIH consensus definitions (50% HIV prevalence in both groups). In Aim 2, we will use the same discovery set to perform targeted and untargeted mass spectrometry with functional assessment through pathway analysis, in vitro models and in vivo mouse models to identify host proteins, post-translational modifications and metabolites that distinguish children with confirmed versus unlikely TB. In Aim 3, we will use the candidate Mtb and host biomarkers identified in Aims 1 and 2 to derive biosignatures with up to 10 analytes consisting of Mtb proteins only, host biomarkers only, and both Mtb- and host-derived biomarkers. Biosignatures that meet WHO TPP criteria in the discovery set will 1) be evaluated in an independent test set of banked samples from 300 children under 5 years old (100 with confirmed TB, 200 with unlikely TB; 50% HIV prevalence in each group) to verify diagnostic accuracy and establish cut- offs and 2) be evaluated in a prospective cohort of 350 children under 5 years old using the pre-select cut-offs and both microbiological and clinical reference standards. Completion of these aims will result in identification of promising biosignatures that can be further validated in large-scale field studies and translated into point-of-care triage and/or diagnostic tests for childhood TB. PROJECT NARRATIVE The inability to quickly and accurately diagnose tuberculosis (TB) in children and initiate treatment is a major contributor to the high mortality of childhood TB worldwide. This study will identify novel Mtb- and host-derived biomarkers, and determine the best biomarker panels (i.e., biosignatures) that can meet the World Health Organization-recommended diagnostic accuracy thresholds for a TB triage or diagnostic test. If successful, the results will the first step needed to make progress toward addressing the critical unmet need for non-sputum biomarker-based tests for childhood TB.",Childhood ‘Omics’ and Mycobacterium tuberculosis-derived BiOsignatures (COMBO) for TB diagnosis in high HIV prevalence settings,9986338,R01AI152161,"['5 year old', 'Address', 'Africa South of the Sahara', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Banks', 'Cause of Death', 'Child', 'Childhood', 'Clinical', 'Communicable Diseases', 'Consensus', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Enrollment', 'Evaluation', 'Failure', 'Gambia', 'Gene Expression', 'Gene Targeting', 'Genetic Transcription', 'HIV', 'HIV Infections', 'HIV/TB', 'Human', 'Immunity', 'Immunoassay', 'In Vitro', 'Investigation', 'Knock-out', 'Lead', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Microbiology', 'Modeling', 'Mus', 'Mycobacterium tuberculosis', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Plasma', 'Post-Translational Protein Processing', 'Prevalence', 'Probability', 'Prospective cohort', 'Proteins', 'ROC Curve', 'Reference Standards', 'Resolution', 'Role', 'Sampling', 'South Africa', 'Specificity', 'Sputum', 'Symptoms', 'Testing', 'Translating', 'Translations', 'Triage', 'Tryptophan', 'Tuberculosis', 'Uganda', 'United States National Institutes of Health', 'Urine', 'Validation', 'World Health Organization', 'accurate diagnosis', 'base', 'bioinformatics pipeline', 'biomarker discovery', 'biomarker panel', 'biosignature', 'clinical research site', 'clinically relevant', 'co-infection', 'cohort', 'cost', 'diagnostic accuracy', 'field study', 'in vitro Model', 'in vivo', 'in vivo Model', 'ion mobility', 'macrophage', 'mortality', 'mouse model', 'multiple omics', 'next generation', 'novel', 'pathogen', 'point of care', 'point-of-care diagnostics', 'prospective', 'protein metabolite', 'success', 'targeted biomarker', 'transcriptomics', 'tuberculosis diagnostics', 'validation studies']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,1503586,685608202,-0.026708616726499896
"High-Performance Compute Cluster for Comprehensive Cancer and Infectious Diseases Research Project Summary/Abstract Fred Hutch respectfully requests funds to upgrade the current 523-node, 3328-core high performance computing (HPC) cluster, which was created in 2004 and expanded in 2006, 2010 (S10 funds), 2013, 2015 (S10 funds), and 2018. 456 end of life nodes (1824 cores) will be replaced and 144 nodes (3456 cores) will be added, creating a new 211-node, 4996-core system with an overall 50% increase in core count, 60% increase in processing power, and more than 100% increase in memory capacity over the old system. The expanded capacity will enable deep and efficient analysis of our research studies and accommodate 20% annual growth in computing intensive research, much of which is not possible on the current cluster. The core user group for the new HPC cluster consists of at least 37 NIH-funded research groups participating in this proposal, however as much as 85 groups use the cluster regularly. Their biomedical research is aimed at eradicating cancer and other diseases and dependent on computationally intensive technical approaches such as development of novel statistical analysis or machine learning methods, for example for assessing immune correlates to facilitate vaccine development, analyzing large scale clinical trials or to develop software tools for the analysis of large-scale immunological datasets, DNA and RNA sequencing, modeling prostate cancer outcomes, studies of the human microbiome, modeling of cancers, mRNA, miRNA, and structural variant detection, structural biology with Cryo- EM, modeling of infectious agents and pandemics, computational modeling, prediction and design of macromolecular structures and interactions, identifying drivers of neoplasia and an international consortium improving colorectal cancer detection using GWAS, whole genome sequencing and genome-wide gene- environment (GxE) studies as well as research in diabetes, mhealth and cardiovascular diseases. Several of the Major Users at Fred Hutch are currently experiencing substantial delays in accomplishing their work using the current cluster. Others have projects that cannot be done at all on the existing instrument. (see Research Projects section for details). The Scientific Computing department (SciComp) has operated the current HPC cluster for more than 10 years and has a staff with a combined experience of over 150 years. The proposed new HPC cluster will be installed in available space in a Fred Hutch datacenter. The expanded cluster will address both immediate and future needs of our user community, supporting NIH-funded research at Fred Hutch. Funded research at our Center will greatly benefit from the increased data-processing capacity and improved performance of the requested HPC cluster, including applications of machine learning to the study of clinical trial efficacy, comparison of immune system receptors to identify responses to specific pathogens/diseases, modeling of carcinogenesis. Besides multiple infectious diseases Fred Hutch researches all types of cancer and our computationally intensive investigators tend to focus on colon, prostate, brain, Barrett’s esophagus, lung and liquid tumors such as leukemia. Project Narrative (Public Health Relevance) We are requesting an expansion of our high-performance computing (HPC) cluster to provide capacity for the growing computational needs in a broad range of biomedical research studies at our Center. Access to fast and reliable computational power is critically important for analyzing the exploding amounts of data produced by large-scale clinical and epidemiological studies, as well as scientific instruments such as genome sequencers and electron microscopes. The prevention, detection, and treatment of cancer, HIV, and other life-threatening diseases are major areas of NIH-funded research at our Center that will greatly benefit from the improved performance of the requested HPC cluster, including large-scale clinical and epidemiologic studies of various cancers, modeling of vaccine efficacy, and infectious disease transmission and proteomic-based biomarker discovery.",High-Performance Compute Cluster for Comprehensive Cancer and Infectious Diseases Research,9940345,S10OD028685,"['Address', 'Barrett Esophagus', 'Biomedical Research', 'Brain', 'Cancer Model', 'Cardiovascular Diseases', 'Clinical Trials', 'Colon', 'Communicable Diseases', 'Communities', 'Computer Models', 'Cryoelectron Microscopy', 'DNA sequencing', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease model', 'Environment', 'Funding', 'Future', 'Genes', 'Growth', 'High Performance Computing', 'Human Microbiome', 'Immune', 'Immune system', 'Immunologics', 'Infectious Agent', 'Infectious Diseases Research', 'International', 'Liquid substance', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Memory', 'Messenger RNA', 'MicroRNAs', 'Modeling', 'Molecular Structure', 'Neoplasms', 'Performance', 'Prostate', 'Prostate Cancer Outcomes Study', 'Research', 'Research Personnel', 'Research Project Grants', 'Software Tools', 'Statistical Data Interpretation', 'Structure', 'System', 'United States National Institutes of Health', 'Work', 'cancer type', 'carcinogenesis', 'cluster computing', 'colorectal cancer screening', 'computerized data processing', 'design', 'efficacy clinical trial', 'end of life', 'experience', 'genome sequencing', 'genome wide association study', 'genome-wide', 'improved', 'instrument', 'leukemia', 'mHealth', 'machine learning method', 'microbiome research', 'novel', 'pandemic disease', 'pathogen', 'prostate cancer model', 'receptor', 'research study', 'response', 'scientific computing', 'software development', 'structural biology', 'transcriptome sequencing', 'tumor', 'vaccine development', 'variant detection', 'whole genome']",OD,FRED HUTCHINSON CANCER RESEARCH CENTER,S10,2020,2000000,758431960,-0.0459237116347899
"Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities. This suggests that abnormalities are subtle, and perhaps postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a collaboration supported by our concluding Fogarty project, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images produced as part of our concluding Fogarty project, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the arrangement of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high-resolution images of Bielschowsy stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This yields clear and measurable images of individual axons. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin-related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models to combine these various types of data with known properties of CNS white matter and myelin to build a model of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. In the process of completing these scientific aims, we will pursue the pedagogic goals of training the first two professional biostatisticians in Macedonia, and an academic pathologist. We will also hold a seminar course for biological researchers to build awareness and understanding of the power of biostatistical and other computational methods to enrich their research. NARRATIVE Our ongoing Fogarty/NIMH research project in Macedonia (R01 MH060877, “Building Schizophrenia Research in Macedonia”), has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale.",Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia,9953486,R56MH117769,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Architecture', 'Autopsy', 'Awareness', 'Axon', 'Biochemical', 'Biochemistry', 'Biological', 'Biological Assay', 'Biometry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Charge', 'Collaborations', 'Complex', 'Computer-Assisted Diagnosis', 'Computers', 'Computing Methodologies', 'Confocal Microscopy', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electron Microscope', 'Electrons', 'Fiber', 'Goals', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Individual', 'Informatics', 'International', 'Knowledge', 'Learning', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurable', 'Measurement', 'Measures', 'Medical', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Microscopy', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Morphology', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofilament Proteins', 'Paraffin', 'Pathologist', 'Pathology', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Schizophrenia', 'Scientist', 'Silver Staining', 'Stains', 'Statistical Data Interpretation', 'Statistical Methods', 'Structural Models', 'Students', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Transcript', 'Translational Research', 'Triad Acrylic Resin', 'base', 'cognitive function', 'computerized', 'computerized tools', 'data modeling', 'deep neural network', 'diffusion anisotropy', 'high resolution imaging', 'histological image', 'histological studies', 'imaging study', 'innovation', 'interest', 'low and middle-income countries', 'microscopic imaging', 'multidimensional data', 'multimodality', 'network models', 'novel', 'pedagogy', 'reconstruction', 'sex', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R56,2019,10000,68331629,-0.03479447227727382
"Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)? PROJECT SUMMARY The North Coast Conference on Precision Medicine is a national annual mid-sized conference series held in Cleveland, Ohio. The conference series aims to serve as a venue for the continuing education and exchange of scientific ideas related to the rapidly evolving and highly interdisciplinary landscape that is precision medicine research. The topics for each conference coincide with the national conversation and research agenda set by national research programs focused on precision medicine. The 2018 conference is a symposium that will focus on issues related to return of genomic results both in clinical and research settings with an emphasis on diverse populations. The conference will be organized as a traditional format with invited speakers from among national experts for topics ranging from issues returning research results to culturally diverse participants and family members, inclusion of diverse patient and participant populations in the Clinical Sequencing Evidence- Generating Research (CSER) consortium and the Trans-Omics for Precision Medicine (TOPMed) Program, pharmacogenomics-guided dosing and race/ethnicity, strategies used to return results, among others. 2019 and beyond conference topics are being considered from previous symposia attendees and trends in precision medicine research. Odd-numbered year conferences include a workshop component that has previously covered outcome and exposure variable extraction from electronic health records. Future workshop topics being considered include integration of multiple ‘omics, drug response in different populations, pharmacogenomics clinical implementation, precision medicine in cancer, data sharing and informed consent, and the use of apps for recruitment, diagnosis, follow-up, and treatment. Our second major objective of this conference series is the promotion of diversity in the biomedical workforce. It is well-known that the pipeline from training to full professor for women in biomedical research is leaky whereas the pipeline for under-represented minorities is practically non-existent. Drawing from national and local sources, we vet women and under-represented minorities for every invited speaker opportunity, thereby providing valuable career currency and networking opportunities. We will also encourage women and under-represented minorities, particularly at the trainee level, to attend and participate in this conference series to spur interest in pursuing precision medicine research as a career. Overall, the North Coast Conference on Precision Medicine series is a valuable addition to the national conference landscape, and with its unique location and low cost to participants, will serve as an important educational opportunity as precision medicine research accelerates in earnest. PROJECT NARRATIVE The North Coast Conference on Precision Medicine is a yearly fall conference series in Cleveland, Ohio designed as a continuing education forum in the burgeoning area of precision medicine research. The conference brings together national experts on a host of topics ranging from bioethics to bioinformatics to biomedical informatics to speak and lead workshops on timely challenges posed in translating complex genomic and health data into clinical practice. The conference series also serves to promote diversity in the biomedical workforce. This year’s symposium will focus issues related to return of genomic results in both clinical and research settings with an emphasis on diverse populations.",Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)?,9762963,R13HG010286,"['Academic Medical Centers', 'Acceleration', 'African American', 'Area', 'Back', 'Big Data', 'Bioethics', 'Bioinformatics', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Computational Biology', 'Computer Simulation', 'Continuing Education', 'Custom', 'Data', 'Databases', 'Diagnosis', 'Dose', 'Educational workshop', 'Electronic Health Record', 'Ensure', 'Ethnic Origin', 'Family member', 'Funding', 'Future', 'Generations', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidental Findings', 'Informed Consent', 'Infrastructure', 'Institution', 'Knowledge', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mining', 'Names', 'Ohio', 'Outcome', 'PMI cohort', 'Participant', 'Pathogenicity', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Population Heterogeneity', 'Prevention', 'Process', 'Race', 'Research', 'Research Personnel', 'Resources', 'Schedule', 'Science', 'Series', 'Source', 'Surveys', 'Technology', 'Time', 'Training', 'Trans-Omics for Precision Medicine', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Minority', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'Woman', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'clinical care', 'clinical implementation', 'clinical practice', 'clinical sequencing', 'clinically relevant', 'cost', 'cost effective', 'data sharing', 'design', 'falls', 'follow-up', 'forging', 'frontier', 'genome-wide', 'genomic data', 'health data', 'health disparity', 'health information technology', 'incentive program', 'individual patient', 'interest', 'medical specialties', 'multiple omics', 'patient population', 'point of care', 'posters', 'precision medicine', 'programs', 'recruit', 'response', 'science education', 'senior faculty', 'symposium', 'trend']",NHGRI,CASE WESTERN RESERVE UNIVERSITY,R13,2019,10000,197030888,-0.02298008683283107
"Feature Learning For Improved Multiplex Disease Diagnosis Abstract This proposal is for CATTS, a feature learning technique optimized for use in multiplex mass spectrometry (MS) fingerprinting assays. MS fingerprints consist of a large number of chemical species, leading to very high dimensional feature spaces, and subsequent high false-discovery rates. CATTS aims to reduce the size of this space, by using knowledge of the underlying biochemistry, as well as general-purpose clustering algorithms. Our preliminary results demonstrate that, when used as a feature-learning technique for a variety of classification methods, CATTS significantly improves assay sensitivity. This proposal takes our existing implementation of CATTS and extends it to support additional feature learning algorithms and classification methods. Additionally, its performance as a multiplex assay strategy will be tested on both protein and lipid MS fingerprint libraries, with an eye towards commercialization.. Relevance to public health: The detection of pathogens via mass spectroscopy fingerprinting is rapidly becoming a standard technique for clinical microbiology. However, high false detection rates and conflicting multiple identifications limit applicability, and make interpretation of results difficult. Our work on CATTS aims to improve the statistical performance of these assays. Preliminary results from studies on one dataset we intend to apply CATTS to suggest that UTIs and, in some cases antimicrobial resistance, can be detected, directly from patient samples. However, the statistical methods currently employed aren't reliable enough - the further development of CATTS will accelerate the development of this, and other mass-spectroscopy-based assays..",Feature Learning For Improved Multiplex Disease Diagnosis,9813280,R43GM128538,"['Algorithms', 'Antimicrobial Resistance', 'Biochemistry', 'Biodiversity', 'Biological Assay', 'Chemicals', 'Classification', 'Clinical Microbiology', 'Conflict (Psychology)', 'Data Set', 'Decision Trees', 'Detection', 'Development', 'Dimensions', 'Eye', 'Fingerprint', 'Immune', 'Knowledge', 'Learning', 'Libraries', 'Lipids', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Modeling', 'Noise', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Process', 'Protein Fingerprints', 'Proteins', 'Public Health', 'Reporting', 'Research', 'Sampling', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Testing', 'Work', 'base', 'commercialization', 'disease diagnosis', 'feeding', 'high dimensionality', 'improved', 'learning algorithm', 'learning strategy', 'neural network', 'novel', 'random forest', 'vector']",NIGMS,"DEURION, LLC",R43,2019,14770,0,-0.015495582162583609
"Feature Learning For Improved Multiplex Disease Diagnosis Abstract This proposal is for CATTS, a feature learning technique optimized for use in multiplex mass spectrometry (MS) fingerprinting assays. MS fingerprints consist of a large number of chemical species, leading to very high dimensional feature spaces, and subsequent high false-discovery rates. CATTS aims to reduce the size of this space, by using knowledge of the underlying biochemistry, as well as general-purpose clustering algorithms. Our preliminary results demonstrate that, when used as a feature-learning technique for a variety of classification methods, CATTS significantly improves assay sensitivity. This proposal takes our existing implementation of CATTS and extends it to support additional feature learning algorithms and classification methods. Additionally, its performance as a multiplex assay strategy will be tested on both protein and lipid MS fingerprint libraries, with an eye towards commercialization.. Relevance to public health: The detection of pathogens via mass spectroscopy fingerprinting is rapidly becoming a standard technique for clinical microbiology. However, high false detection rates and conflicting multiple identifications limit applicability, and make interpretation of results difficult. Our work on CATTS aims to improve the statistical performance of these assays. Preliminary results from studies on one dataset we intend to apply CATTS to suggest that UTIs and, in some cases antimicrobial resistance, can be detected, directly from patient samples. However, the statistical methods currently employed aren't reliable enough - the further development of CATTS will accelerate the development of this, and other mass-spectroscopy-based assays..",Feature Learning For Improved Multiplex Disease Diagnosis,9813275,R43GM128538,"['Algorithms', 'Antimicrobial Resistance', 'Biochemistry', 'Biodiversity', 'Biological Assay', 'Chemicals', 'Classification', 'Clinical Microbiology', 'Conflict (Psychology)', 'Data Set', 'Decision Trees', 'Detection', 'Development', 'Dimensions', 'Eye', 'Fingerprint', 'Immune', 'Knowledge', 'Learning', 'Libraries', 'Lipids', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Modeling', 'Noise', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Process', 'Protein Fingerprints', 'Proteins', 'Public Health', 'Reporting', 'Research', 'Sampling', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Testing', 'Work', 'base', 'commercialization', 'disease diagnosis', 'feeding', 'high dimensionality', 'improved', 'learning algorithm', 'learning strategy', 'neural network', 'novel', 'random forest', 'vector']",NIGMS,"DEURION, LLC",R43,2019,25298,0,-0.015495582162583609
"Genetic Dissection of Cortical Parvalbumin Interneuron Subtypes Abstract The inhibitory control and dynamic tuning of cortical circuits is mediated by a diversity of GABAergic cell types, but the biological basis of interneuron identity and diversity is not well understood. Here, we combine developmental genetic, anatomic and transcriptomic approaches to define and discover bona fide cell types within a broad class of cortical interneurons. Parvalbumin containing, fast-spiking basket cells (PVCs) are the largest population of interneurons in the neocortex and integrate in infragranular, granular (layer IV), and supragranular circuits, each with unique input/output connectivity. Recent findings from our laboratory and others suggest heterogeneity in PVC morphology, synaptic properties, and connectivity, but it is uncertain how many of these represent distinct subtypes. Using a developmental genetic strategy, we take advantage of the inside-out laminar specification of PVCs to identify and characterize subtypes based on lineage and birth time restricted cohorts. PVCs are derived from the medial ganglionic eminence (MGE), and the transition from progenitor to differentiated neuron is marked by the upregulation of proneural transcription factors. By intersecting inducible Ascl1-CreER and Dlx1-CreER mice with PV-Flp mice and an intersectional reporter and inducing in mid-to-late embryogenesis, we have begun parsing adult laminar PVC subtypes for multifactorial single-cell analysis. We quantify the laminar position and morphology of lineage restricted and birth-dated PVC cohorts. We will also carry out single cell RNAseq to analyze their transcription profiles. The integration of morphological and anatomical characterization with single cell RNAseq will increase our understanding of cell identity in PVCs and can potentially uncover new underlying cellular properties. Because PVCs are implicated in schizophrenia, autism, and other mental disorders, their complete profiling at the single cell level could aid in understanding pathophysiology and suggest better treatment strategies. Project Narrative Public Health Relevance: About 1 in 5 Americans are afflicted with mental health disorders such as schizophrenia, Alzheimer’s disease, and autism, placing a considerable burden on individuals and health care institutions across the country. Parvalbumin interneurons are the most prevalent inhibitory cells in the neocortex and their dysfunction implicated across many disorders, though their precise circuit integration is not well understood. This research proposal will lay the foundation for a single-cell understanding of the individual cell types that underlie this powerful “brake” mechanism and identify specific molecular targets that can hopefully lead to better therapeutic strategies.",Genetic Dissection of Cortical Parvalbumin Interneuron Subtypes,9648030,F31MH114529,"['Adult', 'Alzheimer&apos', 's Disease', 'American', 'Anatomy', 'Bioinformatics', 'Biological', 'Birth', 'Catalogs', 'Cells', 'Classification Scheme', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Country', 'Data Set', 'Databases', 'Date of birth', 'Development', 'Disease', 'Dissection', 'Embryo', 'Embryonic Development', 'Epilepsy', 'Exhibits', 'Expression Profiling', 'Fluorescent in Situ Hybridization', 'Foundations', 'Functional disorder', 'Ganglia', 'Gene Expression', 'Genetic', 'Genetic Screening', 'Genetic Transcription', 'Healthcare', 'Heterogeneity', 'Individual', 'Institution', 'Interneurons', 'Label', 'Laboratories', 'Lead', 'Maps', 'Medial', 'Mediating', 'Mental disorders', 'Messenger RNA', 'Methods', 'Molecular', 'Molecular Profiling', 'Molecular Target', 'Morphology', 'Mus', 'Myoepithelial cell', 'Neocortex', 'Neuroglia', 'Neurons', 'Nucleotides', 'Output', 'Parvalbumins', 'Pattern', 'Phenotype', 'Physiological', 'Population', 'Positioning Attribute', 'Pregnancy', 'Property', 'Proteins', 'Radial', 'Regulation', 'Reporter', 'Research Proposals', 'Resolution', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Statistical Methods', 'Stratum Granulosum', 'Synapses', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Up-Regulation', 'autism spectrum disorder', 'base', 'cell type', 'cohort', 'design', 'developmental genetics', 'differential expression', 'gamma-Aminobutyric Acid', 'genetic approach', 'intersectionality', 'molecular marker', 'new therapeutic target', 'novel', 'progenitor', 'public health relevance', 'screening', 'single cell analysis', 'supervised learning', 'tool', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'treatment strategy']",NIMH,STATE UNIVERSITY NEW YORK STONY BROOK,F31,2019,34926,77607041,-0.013698674279919928
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9750736,R01EB021396,"['3-Dimensional', 'Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'data pipeline', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'off-label use', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2019,100000,5161939,-0.0006179874470693047
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9747977,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2019,115051,685608202,0.0032234255516245367
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9806367,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2019,184118,340417756,0.003073712914243487
"Mobile based Nanoplasmonic Quantification of Mtb-derived Exosomes in Serum for Pediatric TB diagnosis Project Summary/Abstract  There were an estimated 10.4 million tuberculosis (TB) cases, and 170,000 TB pediatric deaths in 2015, with >95% of TB deaths occur in low- and middle-income countries (LMIC). Rapid diagnosis is essential for improved TB outcomes, but diagnosis is more difficult in children, since children are less likely to exhibit typical TB symptoms and have paucibacillary (few bacteria) TB cases that are more difficult to detect by current methods, while parents are often resistant to stressful TB sample collection procedures. We therefore propose to explore a novel rapid, accurate, low-cost and easy-to-use mobile phone-based blood test for pediatric TB diagnosis in LMIC settings. Our novel detection method rapidly quantifies circulating extracellular vesicles (EVs) derived from host cells infected with the TB pathogen Mycobacterium tuberculosis (Mtb). Our preliminary data indicate that we can rapidly quantitate EVs carrying Mtb biomarkers, such as lipoarabinomannan and LpqH, in pediatric TB patient blood samples using a mobile-phone-based dark-field microscope (MDFM) platform. These findings support our long-term goal to develop a low-cost system to improve pediatric TB diagnosis in LMIC settings. We also anticipate that this system will allow rapid treatment monitoring to improve therapy and reduce exposure of pediatric patients to toxic anti-TB drugs. To achieve these outcomes we propose to pursue three goals.  We collected our preliminary data with a MDFM that imaged transmitted light, but plan to design, develop, and validate the Aim 1 compact MDFM with a reflected light path to decrease the size of the device, simplify imagery, and increase the physical stability of the system. We will also develop a user-friendly application for image capture and data analysis on this platform. These features should markedly increase its feasibility for use in LMIC settings. Aim 2 will optimize assay performance for LMIC settings by redesigning assay materials for long-term storage under ambient conditions, and by determining optimal incubation times for different LMIC ambient temperature ranges. Aim 3 will analyze candidate Mtb-EV markers, including lipoarabinomannan and LpqH, build and a diagnostic model based on a multiple logistic regression algorithm, and validate diagnostic thresholds in separate validation cohort of pediatric TB patients and healthy controls with traceable clinical information. It will also compare the diagnostic performance of this multi-marker Mtb-EV assay to traditional diagnostic methods to evaluate its relative diagnostic performance.  Our approach offers several innovative features valuable for pediatric TB control. It quantifies stable TB biomarkers on EVs in serum (1µL), rather than detecting Mtb in difficult to obtain, variable, non-quantitative and infectious biopsies. It employs a novel, compact MDFM and a nanoparticle-based end-point assay that is stable at ambient conditions. Finally, the ability of this approach to quantitate Mtb-EVs should allow rapid evaluation of disease severity for real-time monitoring of treatment efficacy and cures to minimize toxic drug exposure times. Project Narrative There is an urgent need for novel approaches for rapid diagnosis of pediatric tuberculosis cases to improve patient outcomes in low- and middle-income countries, which may lack resources and trained personnel. This proposal will develop a mobile phone-based device and a rapid tuberculosis assay that detects circulating extracellular vesicles secreted by infected cells in blood, both of which will be inexpensive and user-friendly to allow easy use by individuals with minimal training in resource-limited areas. This low-risk, high-reward approach is fundamentally different from traditional diagnostic methods, and it offers several advantages for diagnosis of pediatric tuberculosis cases, including the use of serum rather than sputum or other biopsies that can be difficult to obtain in young children.",Mobile based Nanoplasmonic Quantification of Mtb-derived Exosomes in Serum for Pediatric TB diagnosis,9773333,R21EB026347,"['Algorithms', 'Area', 'Bacillus (bacterium)', 'Bacteria', 'Biological Assay', 'Biological Markers', 'Biopsy', 'Blood', 'Blood Circulation', 'Blood Tests', 'Blood specimen', 'Car Phone', 'Caregivers', 'Cells', 'Cessation of life', 'Child', 'Childhood', 'Clinical', 'Dark-Field Microscope', 'Data', 'Data Analyses', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic Sensitivity', 'Disease', 'Drug Exposure', 'End Point Assay', 'Evaluation', 'Exhibits', 'Goals', 'Health Personnel', 'Healthcare', 'High Prevalence', 'Housing', 'Human Resources', 'Image', 'Imagery', 'Individual', 'Infrastructure', 'Label', 'Light', 'Logistic Regressions', 'Measures', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Mycobacterium tuberculosis', 'Mycobacterium tuberculosis antigens', 'Nature', 'Outcome', 'Parents', 'Patient-Focused Outcomes', 'Patients', 'Pediatric cohort', 'Performance', 'Procedures', 'Reading', 'Resistance', 'Resources', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Serum', 'Severities', 'Severity of illness', 'Slide', 'Sputum', 'Stress', 'Symptoms', 'System', 'Telephone', 'Temperature', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Tuberculosis', 'Validation', 'antibody conjugate', 'base', 'clinical translation', 'communicable disease diagnosis', 'cost', 'cost effective', 'design', 'diagnostic accuracy', 'diagnostic assay', 'disease diagnosis', 'disorder control', 'exosome', 'extracellular vesicles', 'high reward', 'improved', 'innovation', 'interest', 'lens', 'lipoarabinomannan', 'low and middle-income countries', 'microscopic imaging', 'nanoparticle', 'nanoplasmonic', 'novel', 'novel strategies', 'pathogen', 'pediatric patients', 'portability', 'prototype', 'rapid diagnosis', 'rapid technique', 'real time monitoring', 'regression algorithm', 'sample collection', 'screening', 'transmission process', 'treatment response', 'tuberculosis diagnostics', 'tuberculosis drugs', 'user-friendly']",NIBIB,TULANE UNIVERSITY OF LOUISIANA,R21,2019,186679,92601146,0.01219297167180661
"Mentoring in Immunometabolic Dysregulation in TB and TB/HIV Tuberculosis (TB) is the leading cause of death among people living with HIV (PLWH) worldwide. Despite recent scientific advances, significant gaps remain in our understanding of the immune mechanisms responsible for control and eradication of Mycobacterium tuberculosis (Mtb) infection. PLWH with latent TB infection (LTBI) have a ~10% annual risk of progressing to TB disease, however currently available tests for LTBI diagnosis have reduced sensitivity in this population and are not able to predict which latently infected individuals are at highest risk for developing TB for targeted preventive therapy. Emerging data from clinically relevant animal models suggest that LTBI and active TB represent a spectrum of immune responses and host pathology, with increasing metabolic changes and immune dysregulation during the transition to TB disease. We have identified unique serum metabolite and microRNA (miRNA) profiles that are able to discriminate between patients with TB and those with non-TB lung disease. However, these novel TB signatures have not been assessed prospectively to identify PLWH and HIV-negative persons with LTBI who are at increased risk for TB progression. In order to address this significant knowledge gap, in Aim 1 of the current research program, trainees will leverage the Indian and South African RePORT longitudinal biorepositories of household contacts of TB index cases to test the hypothesis that TB is a chronic inflammatory disease associated with profound changes in immune regulation and metabolism prior to the onset of clinical signs and symptoms. Another major barrier to global TB eradication efforts is the lengthy and complicated current anti-tubercular regimen, which is associated with medical nonadherence and the emergence of drug resistance. Recently, attention has focused on host-directed adjunctive therapies aimed at optimizing immune responses to the pathogen and improving lung damage. Lipid-laden macrophages (foam cells) are central to maintaining chronic TB infection by providing a favorable niche in which antimicrobial functions are down-regulated, and by inducing caseation and tissue damage. Recent work has shown that foam-cell-rich and necrotic areas of TB granulomas are particularly enriched in triglycerides. Mtb infection is associated with dysregulation of two cellular pathways involved in triglyceride homeostasis: a pro-lipogenic pathway involving protein kinase B and mTOR complex 1 (Akt/mTORC1), and an anti- lipogenic pathway involving AMP-activated protein kinase and the sirtuins (AMPK/SIRT). In Aim 2, trainees will use longitudinal clinical samples from RePORT study participants and experimental infections ex vivo to characterize: (i) the relationship between activation of these pathways and control of clinical Mtb infection, and the effect of anti-lipogenic treatments on antimycobacterial functions of human macrophages infected ex vivo. The research aims will be integrated with a mentoring strategy for mentees that fosters development of high impact patient-oriented research with a pathway to independence. Tuberculosis (TB) remains among the most deadly infections worldwide, especially among people living with HIV. Current available tests are not able to accurately detect persons at the highest risk of developing TB, and curing the disease requires at least 6 months of therapy because the TB bacteria can avoid being killed by the immune system and currently available drugs. In the current proposal, physician scientists will receive training in a variety of complementary disciplines, and use several cutting-edge experimental and modeling techniques to analyze samples from patients with TB and TB/HIV, with the ultimate goal of identifying new biomarkers that can predict TB disease and host-directed therapies that can shorten TB treatment.",Mentoring in Immunometabolic Dysregulation in TB and TB/HIV,9846869,K24AI143447,"['5&apos', '-AMP-activated protein kinase', 'Address', 'Animal Model', 'Antibiotics', 'Antimycobacterial Agents', 'Archives', 'Area', 'Attention', 'Automobile Driving', 'Bacteria', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Cause of Death', 'Chronic', 'Clinical', 'Clinical Data', 'Complex', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Drug resistance', 'Environment', 'Experimental Models', 'FRAP1 gene', 'Foam Cells', 'Fostering', 'Goals', 'HIV', 'HIV Seronegativity', 'HIV Seropositivity', 'HIV/TB', 'Homeostasis', 'Household', 'Human', 'Immune', 'Immune response', 'Immune system', 'Individual', 'Infection', 'Inflammatory', 'International', 'Knowledge', 'Lesion', 'Lipid-Laden Macrophage', 'Lipids', 'Lung diseases', 'Machine Learning', 'Medical', 'Mentors', 'Metabolic', 'Metabolism', 'MicroRNAs', 'Mycobacterium tuberculosis', 'Necrosis', 'Outcome', 'Participant', 'Pathology', 'Pathway interactions', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Population', 'Prevention', 'Preventive therapy', 'Proto-Oncogene Proteins c-akt', 'Pulmonary Tuberculosis', 'Regimen', 'Reporting', 'Research', 'Resources', 'Risk', 'Sampling', 'Scientific Advances and Accomplishments', 'Scientist', 'Serum', 'Signs and Symptoms', 'Sirtuins', 'South African', 'Specimen', 'Systems Biology', 'Techniques', 'Testing', 'Tissues', 'Training', 'Triglycerides', 'Tuberculosis', 'Validation', 'Whole Blood', 'Work', 'World Health Organization', 'antimicrobial', 'biobank', 'biosignature', 'career', 'clinically relevant', 'cohort', 'cytokine', 'high risk', 'immunoregulation', 'improved', 'indexing', 'lifetime risk', 'lung injury', 'macrophage', 'monocyte', 'mycobacterial', 'novel', 'pathogen', 'patient oriented research', 'peripheral blood', 'prevent', 'programs', 'prospective', 'tool', 'transcriptome', 'transcriptome sequencing', 'tuberculosis granuloma', 'tuberculosis treatment']",NIAID,JOHNS HOPKINS UNIVERSITY,K24,2019,191195,807432003,-0.03152743206249209
"High throughput cell screening for toxic metal exposure Project Summary The overall objective of this research project is to develop a novel approach for high throughput screening of individual cells based on holographic imaging. To achieve this goal, we propose to implement a new quantitative phase imaging modality, holographic cytomtery, which incorporates several novel technical advances to enable high throughput imaging. Holographic cytometry (HC) will bring the high sensitivity of quantitative phase microscopy (QPM) to imaging of cells flowing through microfluidic devices. While QPM has been used for cell analysis previously, typically only a handful of cells have been imaged. To enable significant application of QPM for fundamental cell biology and clinical studies, it is necessary to move to a high throughput implementation. Technical advances needed to realize the high resolution HC system include use of high speed line scan cameras, microfluidic chips with multiple parallel channels, and light from a pulsed laser source to enable stroboscopic illumination. In order to efficiently analyze and process this data set, rapid analysis software will be developed that leverages the highly parallel processing capabilities of graphics processing units and machine learning algorithms to enable automated classification. The proposed HC method can be applied to imaging a wide range of flowing cells. To demonstrate the utility of the approach, we will initially target the measurement of cancerous progression due to environmental toxicant exposure. We have conducted a preliminary study that shows QPM can detect early changes in the biomechanical properties of cells due to arsenic exposure. In the proposed project, we seek to develop QPM based biomarkers of pre-cancerous change that will enable rapid assessesment. QPM has not been implemented in such a format to date and thus is not yet a feasible approach for clinical or research studies. To meet the goal of high throughput imaging with QPM, the following Specific Aims are proposed: 1. Develop new instrumentation for high speed imaging using off axis digital holography. 2. Implement high throughput analysis methods based on machine learning 3. Test and validate high throughput system with pilot studies of heavy metal exposed epithelial cells to show the approach can detect early pre-cancerous changes due to environmental toxicant exposure. Upon completion of this project, we will have realized a high throughput imaging cytometry system for research and clinical applications. Project Narrative  The proposed research will develop a new high throughput cellular screening technology based on quantitative phase image of cells flowing in a microfluidic chip. This technology will allow researchers and doctors to obtain holographic images of every single cell in a sample in a short amount of time which can then be analyzed by a computer. This would offer the opportunity to evaluate the characteristics of populations of cells for understanding changes in public health due to environmental factors.",High throughput cell screening for toxic metal exposure,9732537,R21ES029791,"['Arsenic', 'Biological', 'Biological Assay', 'Biological Markers', 'Biomechanics', 'Cancerous', 'Cells', 'Cellular biology', 'Classification', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Cytology', 'Cytometry', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Descriptor', 'Development', 'Discrimination', 'Disease', 'Environmental Exposure', 'Environmental Risk Factor', 'Epithelial Cells', 'Evaluation', 'Exhibits', 'Exposure to', 'Functional disorder', 'Future', 'Geometry', 'Goals', 'Heavy Metals', 'Holography', 'Image', 'Image Cytometry', 'Individual', 'Lasers', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Mechanics', 'Metal exposure', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscopy', 'Morphology', 'Motion', 'Neoplasm Metastasis', 'Phase', 'Phenotype', 'Physiologic pulse', 'Pilot Projects', 'Population Characteristics', 'Premalignant', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Sampling', 'Scanning', 'Source', 'Speed', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Toxic Environmental Substances', 'Toxicant exposure', 'automated analysis', 'base', 'cancer cell', 'carcinogenesis', 'cellular imaging', 'clinical application', 'detector', 'digital', 'high throughput analysis', 'high throughput screening', 'imaging approach', 'imaging modality', 'instrument', 'instrumentation', 'machine learning algorithm', 'machine vision', 'mechanical properties', 'microscopic imaging', 'nanoscale', 'novel', 'novel strategies', 'parallel computer', 'parallel processing', 'prevent', 'research clinical testing', 'research study', 'screening', 'shear stress', 'systems research', 'tool', 'toxic metal']",NIEHS,DUKE UNIVERSITY,R21,2019,194177,607172798,0.008092570817457954
"Turning a sequence barcode into a spectral barcode for single-cell analysis. Project Summary: The use of sequence barcodes has enabled high-throughput transcriptomic analysis of single cells. But one challenge remains – there is no method to map the physical assessments of single cells and the downstream transcriptomic data of single cells to the same cells of origin. This is because currently sequence barcodes are only read by sequencing which takes place after all single cells are lysed, reverse transcription is completed, and cDNA are amplified and pooled. In order to perform transcriptomic analysis and physical assessments on the same single cells, we will need a method that allows us to decipher the sequence barcodes while in the process of single-cell physical interrogation. Our goal in this proposed research is to develop a new method to turn sequence barcodes into spectral barcodes that can be read locally in the process. The proposed sequence- barcode-reading technique, if it can be realized, will have substantial impact to the single-cell community as it will become the only method to map the physical assessments and the downstream molecular analysis data to the same cells of origin in a high-throughput, streamlined format. Project Narrative: High-throughput single-cell analysis has advanced our knowledge in developmental biology and disease origins. But currently there is no method to map the physical and transcriptional analysis data of single cells to the same cells of origin. Here we propose to develop a method to overcome this limitation and enable both physical and molecular interrogation performed on the same single cells.",Turning a sequence barcode into a spectral barcode for single-cell analysis.,9586857,R21GM129617,"['Address', 'Architecture', 'Bioinformatics', 'Biology', 'Bypass', 'Cell Nucleus', 'Cells', 'Code', 'Color', 'Complementary DNA', 'Cytoplasm', 'DNA', 'DNA Probes', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Development', 'Developmental Biology', 'Encapsulated', 'Fluorescence', 'Fluorescent Probes', 'Genetic Transcription', 'Genomics', 'Goals', 'Hybrids', 'Hydrogels', 'Image', 'Individual', 'Knowledge', 'Libraries', 'Light', 'Machine Learning', 'Maps', 'Mechanics', 'Metals', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Mining', 'Molecular', 'Molecular Analysis', 'Motivation', 'Nature', 'Nuclear', 'Nucleic Acids', 'Nucleotides', 'Phenotype', 'Physical assessment', 'Process', 'Reading', 'Reporter', 'Research', 'Reverse Transcription', 'Series', 'Silver', 'Specificity', 'Stretching', 'Techniques', 'Technology', 'Testing', 'base', 'cell community', 'cost', 'design', 'developmental disease', 'droplet sequencing', 'experimental study', 'fluorescence imaging', 'interest', 'multiplex detection', 'nanocluster', 'nanoparticle', 'next generation', 'nucleobase', 'screening', 'single cell analysis', 'technology development', 'tool', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R21,2019,215902,91740242,-0.0010246369455960392
"Automated end-to-end retinal screening system with robotic image capture and deep learning analysis Abstract  In this SBIR project, we propose EyeScreenBot, an end-to-end automated retinal im- age capture and analysis system, comprising a self-driven, robotic fundus camera plat- form for automated image capture and a deep learning-based image analysis engine for generation of automated screening outcome. With the large, growing, and aging popula- tion and the increased prevalence of diabetes, a large number of people are at risk for vision loss due to several eye diseases including diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma. Although eye screening is effective in re- ducing vision loss, there are not enough clinical personnel and eye-care experts for pop- ulation-wide eye screening. Recent advances with automated image analysis are helping alleviate the situation, but they are still limited by the need for good quality images of the patients captured by trained technicians or expensive retinal cameras equipped for auto- mated capture. EyeScreenBot will be developed to provide a truly end-to-end screening solution that is cost-effective and suitable for deployment in primary care clinics or op- tometrist sites, addressing both automated capture and subsequent automated analysis, all without the need for trained technicians or eye experts at the point of care. When deployed and commercialized, this device will rapidly aid scaling of eye screening for the masses, thereby having an enormous impact in improving the quality and accessibility of eye care and helping reduce preventable vision loss. Narrative EyeScreenBot, an end-to-end automated screening system with intelligent image capture and analysis, will truly enable eye screening at massive scale, which is necessary and urgent since the population at risk for preventable vision loss due to retinal diseases (such as diabetic retinopathy) is growing at a staggering rate. Triaging and identification of at-risk patients will allow for timely intervention to prevent, slow, or even reverse the disease progression and loss of vision.",Automated end-to-end retinal screening system with robotic image capture and deep learning analysis,9847891,R43EY029652,"['Address', 'Age', 'Age related macular degeneration', 'Algorithms', 'Area', 'Blindness', 'California', 'Caring', 'Clinic', 'Clinical', 'Color', 'Computational algorithm', 'Computer Vision Systems', 'County', 'Coupled', 'Development', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease Progression', 'Evaluation', 'Eye', 'Eye diseases', 'Fundus', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Hand', 'Health', 'Health Services', 'Human', 'Human Resources', 'Image', 'Image Analysis', 'Institutes', 'Intelligence', 'Intervention', 'Intuition', 'Los Angeles', 'Manuals', 'Mass Screening', 'Measures', 'Medical', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Pilot Projects', 'Population', 'Populations at Risk', 'Prevalence', 'Primary Health Care', 'Process', 'Pupil', 'Retinal', 'Retinal Diseases', 'Risk', 'Robot', 'Robotics', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Software Engineering', 'Surveys', 'System', 'Systems Analysis', 'Testing', 'Time', 'Training', 'Triage', 'Universities', 'Validation', 'Visual impairment', 'Work', 'aging population', 'automated analysis', 'automated image analysis', 'base', 'cost effective', 'deep learning', 'deep learning algorithm', 'design', 'diabetic', 'digital imaging', 'experience', 'fundus imaging', 'improved', 'interest', 'macula', 'point of care', 'portability', 'prevent', 'professor', 'programs', 'retinal imaging', 'robot interface', 'robotic system', 'screening', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2019,218618,1300000,-0.002263009570845827
"Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions Project Summary/Abstract DNA sequencing has spawned the “microbiome revolution” -- thousands of microbes and a dizzying number of microbial interactions that are associated with human health and disease. Unfortunately, most species in the microbiome are known only by a (partial) genome. The limited phenotypic data on newly discovered bacteria reveal species that behave unlike any of our model organisms. While genome-scale modeling plays an important role in understanding the microbiome, the paucity of phenotypic data for most species prevents detailed simulation of the microbial communities that affect our health. This project will develop an automated system for profiling, synthesizing, and modeling microbial communities. The center of our approach is Deep Phenotyping, an automated robotic platform that performs complex growth experiments on demand. Data from Deep Phenotyping will be used to train metabolic and statistical models of the oral pathogens Streptococcus mutans and Candida albicans to predict conditions that keep both microbes in a nonpathogenic state. Project Narrative The microbiome revolution has uncovered thousands of species of bacteria with roles in health and disease. This project automates the identification of interactions between environments, genes, and the microbes that live in and around us. Understanding these interactions is a critical step in re-engineering the microbiome to improve human health.","Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions",9651956,R21EB027396,"['Affect', 'Animal Model', 'Antibiotics', 'Area', 'Bacteria', 'Biochemical Pathway', 'Bioinformatics', 'Biological', 'Biological Assay', 'Candida albicans', 'Carbon', 'Coculture Techniques', 'Collaborations', 'Combinatorics', 'Communities', 'Complex', 'Computer software', 'DNA sequencing', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Future', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Human Microbiome', 'Hybrids', 'Image', 'Individual', 'Knock-out', 'Knowledge', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Metabolic', 'Methods', 'Microbe', 'Microbiology', 'Modeling', 'Oral', 'Oral candidiasis', 'Pathway interactions', 'Phenotype', 'Play', 'Positioning Attribute', 'Regulator Genes', 'Research Personnel', 'Robotics', 'Role', 'Shapes', 'Source', 'Statistical Models', 'Streptococcus mutans', 'Structure', 'System', 'Technology', 'Time', 'Training', 'Work', 'base', 'combinatorial', 'cost', 'design', 'dysbiosis', 'experience', 'experimental study', 'fitness', 'fungus', 'genome-wide', 'improved', 'instrumentation', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microorganism interaction', 'network models', 'open source', 'oral pathogen', 'pathogenic fungus', 'phenotypic data', 'preference', 'prevent', 'screening', 'simulation', 'transcription factor', 'transcriptome sequencing', 'transposon sequencing']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2019,219161,76545728,-0.019801634092548998
"Integrated Microbial Screening and Antimicrobial Susceptibility Test on Microfluidic Digital Array for Diagnosis of Urinary Tract Infections Abstract COMBiNATi will work with Stanford University to bring the world’s first integrated ID+AST UTI diagnostic platform to the market by combining COMBiNATi’s “one-click” cost-effective dPCR platform with Stanford’s pathogen identification (ID) HRMA algorithm for broad detection, deep characterization and absolute quantification of UTI pathogens. By the end of the Phase 1 project, we will deliver the prototype instrument for ID and AST, scale-ready consumables for dPCR + HRM and culture + qPCR, machine-learning software algorithm for melt curve analysis, and prove the feasibility by identifying and quantifying the top two urinary tract infection bacteria. We will first develop two consumables: an 100k partition ID chip and a 32-lane, 10k partition per lane AST plate based on the micro-injection molding design rules established by COMBiNATi. An integrated system with thermal control and imaging capability will then be developed for HRM and qPCR processes. The prototype system will then be transferred to Stanford University where mock samples including both isolated bacteria and contrived urine samples will be tested on the platform for integrated pathogen ID and AST determination. Narrative Urinary Tract Infection (UTI) is one of the most common community-acquired bacterial infection. However, like other bacterial infections, standard culture-based diagnosis of UTI requires at least 2-3 days from sample acquisition to result reporting. Despite technological advancements, the process remains time- consuming and requires significant technical expertise. Automated instruments remain bulky and still require clonal isolation of the pathogens from the body fluid samples prior to AST. Additionally, the lack of definitive microbiological diagnosis that is rapid enough to achieve evidence-based treatment has driven the over- and misuse of broad-spectrum antibiotics. We believe the proposed integrated ID + AST platform has the potential to enable deep genetic analyses of clinical samples to provide rapid precision UTI triage and MIC determination in a timely and cost-efficient manner to positively impact patient care as well as promote the use of narrow spectrum antibiotics to favorably impact antibiotic resistance profiles.",Integrated Microbial Screening and Antimicrobial Susceptibility Test on Microfluidic Digital Array for Diagnosis of Urinary Tract Infections,9777415,R41AI145604,"['Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Ampicillin', 'Antibiotic Resistance', 'Antibiotic susceptibility', 'Antibiotics', 'Antimicrobial susceptibility', 'Bacteria', 'Bacterial Infections', 'Biological Assay', 'Body Fluids', 'Ceftriaxone', 'Cell Separation', 'Cells', 'Ciprofloxacin', 'Clinical', 'Communities', 'Computer software', 'Consumption', 'Data', 'Databases', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Escherichia coli', 'Evidence based treatment', 'Genomic DNA', 'Gentamicins', 'Growth', 'Individual', 'Injections', 'Klebsiella pneumonia bacterium', 'Laboratories', 'Liquid substance', 'Machine Learning', 'Methods', 'Microbiology', 'Microfluidics', 'Minimum Inhibitory Concentration measurement', 'Modality', 'Molds', 'Molecular', 'Patient Care', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Process', 'Protocols documentation', 'Reagent', 'Reporting', 'Resistance profile', 'Resolution', 'Sampling', 'Small Business Technology Transfer Research', 'System', 'Technical Expertise', 'Testing', 'Time', 'Triage', 'Trimethoprim-Sulfamethoxazole', 'Universities', 'Urinary tract infection', 'Urine', 'Uropathogen', 'Work', 'base', 'cost effective', 'cost efficient', 'design', 'digital', 'genetic analysis', 'imaging capabilities', 'instrument', 'melting', 'microbial', 'operation', 'pathogen', 'prototype', 'response', 'scale up', 'screening', 'success']",NIAID,"COMBINATI, INC.",R41,2019,224658,599695,-0.008130032679328103
"Adaptive & Individualized AAC The heterogeneity of the more than 1.3% of Americans who suffer from severe physical impairments (SPIs) preclude the use of common augmentative or alternative communication (AAC) solutions such as manual signs, gestures or dexterous interaction with a touchscreen for communication. While efforts to develop alternative access methods through eye or head tracking have provided some communication advancements for these individuals, all current technologies suffer from the same fundamental limitation: existing AAC devices require patients to conform to generic communication access methods and interfaces rather than the device conforming to the user. Consequently, AAC users are forced to settle for interventions that require excessive training and cognitive workload only to deliver extremely slow information transfer rates (ITRs) and recurrent communication errors that ultimately deprive them of the fundamental human right of communication. To meet this health need, we propose the first smart-AAC system designed using individually adaptive access methods and AAC interfaces to accommodate the unique manifestations of motor impairments specific to each user. Preliminary research by our team of speech researchers at Madonna Rehabilitation Hospital (Communication Center Lab) and Boston University (STEPP Lab), utilizing wearable sensors developed by our group (Altec, Inc) have already demonstrated that metrics based on surface electromyographic (sEMG) and accelerometer measures of muscle activity and movement for head-mediated control can be combined with optimizable AAC interfaces to improve ITRs when compared with traditional unoptimized AAC devices. Leveraging this pilot work, our team is now proposing a Phase I project to demonstrate the proof-of-concept that a single sEMG/IMU hybrid sensor worn on the forehead can provide improvements in ITR and communication accuracy when integrated with an AAC interface that is optimized through machine learning algorithms. The prototype system will be tested and compared to a conventional (non-adaptable) interface in subjects with SPI at a collaborative clinical site. Assistance by our speech and expert-AAC collaborators will ensure that all phases of technology development are patient-centric and usable in the context of clinical care. In Phase II we will build upon this proof-of-concept to design a smart-AAC system with automated optimization software that achieves dynamic learning which adapts to intra-individual changes in function through disease progression or training as well as inter-individual differences in motor impairments for a diverse set of users with spinal cord injury, traumatic brain injury, cerebral palsy, ALS, and other SPIs. The innovation is the first and only AAC technology that combines advancements in wearable-sensor access with interfaces that are autonomously optimized to the user, thereby reducing the resources and training needed to achieve effective person-centric communication in SPI, through improved HMI performance and reduced workload. This project addresses the fundamental mission of NIDCD (National Institute for Deafness and Communication Disorders) to provide a direct means of assisting communication for people with severe physical impairments caused by stroke, high level spinal cord injury, neural degeneration, or neuromuscular disease. Leveraging wearable access technology (which has barely been explored for AAC users), we will develop a first-of-its-kind adaptive tablet interface tailored to individual users through advanced movement classification algorithms. Through these efforts, we aim to provide an improved Human Machine Interface (HMI) that is able to accommodate varying degrees of inter- and intra-subject residual motor function and context dependent impairments to provide individuals with SPI the opportunity for improved societal integration and quality of life.",Adaptive & Individualized AAC,9907832,R43DC018437,"['Accelerometer', 'Address', 'American', 'Boston', 'Cerebral Palsy', 'Child', 'Cognitive', 'Communication', 'Communication Methods', 'Communication impairment', 'Computer software', 'Custom', 'Development', 'Devices', 'Diagnosis', 'Disease Progression', 'Ensure', 'Eye', 'Facial Muscles', 'Fatigue', 'Forehead', 'Gestures', 'Goals', 'Head', 'Head Movements', 'Health', 'Heterogeneity', 'Hospitals', 'Human Rights', 'Hybrids', 'Image', 'Imaging problem', 'Impairment', 'Individual', 'Individual Differences', 'Institutes', 'Intervention', 'Intuition', 'Learning', 'Linguistics', 'Manuals', 'Measures', 'Mediating', 'Methods', 'Mission', 'Motor', 'Motor Manifestations', 'Movement', 'Muscle', 'National Institute on Deafness and Other Communication Disorders', 'Nerve Degeneration', 'Neuromuscular Diseases', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Population Heterogeneity', 'Quality of life', 'Recurrence', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Resources', 'Series', 'Signal Transduction', 'Speech', 'Spinal cord injury', 'Stroke', 'Surface', 'System', 'Tablets', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Traumatic Brain Injury', 'United States National Aeronautics and Space Administration', 'Universities', 'User-Computer Interface', 'Variant', 'Work', 'Workload', 'alternative communication', 'base', 'classification algorithm', 'clinical care', 'clinical research site', 'communication device', 'deafness', 'design', 'experimental study', 'improved', 'innovation', 'kinematics', 'machine learning algorithm', 'mathematical model', 'motor impairment', 'novel', 'prototype', 'rehabilitation engineering', 'rehabilitation science', 'sensor', 'sensor technology', 'signal processing', 'technology development', 'touchscreen', 'two-dimensional', 'wearable device']",NIDCD,"ALTEC, INC.",R43,2019,224701,1532918,-0.056005753926303324
"Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images ABSTRACT Manual analysis of biomedical images by researchers and pathologists has the potential to introduce bias and error that compromise the reliability of research and clinical findings. These problems are significant barriers to delivering the most beneficial evidence-based medicine, developing effective medical treatments, and promoting confidence in scientific inquiry. Identification of biomarkers and cellular targets following microscopy requires manual analysis of biomedical images, which is time intensive, difficult, and prone to bias and errors. Unintentional bias and attentional limitations during analysis of biomarkers can underlie poor reproducibility of findings in biomedical research and potentially introduce error in clinical diagnostics. We recently developed a “beta” software package designed to improve automation and standardization of image analysis, called “PIPSQUEAK” (Perineuronal net Intensity Program for the Standardization and Quantification of Extracellular matrix Analysis Kit). Since its publication in 2016, PIPSQUEAK beta has amassed approximately 1,300 users worldwide who use it to quantify the intensity and number of perineuronal nets and other neural markers in the brain. This technology significantly increases data reliability between image raters and decreases the time required for analysis by more than 100-fold. However, PIPSQUEAK beta currently uses target detection algorithms that require high-contrast images to automatically identify neurons as clusters of bright pixels on dark backgrounds. A significant current limitation to PIPSQUEAK beta, and other available imaging programs, is that detection of biomarkers can be difficult unless image conditions are ideal. Suboptimal conditions, like high background staining, off-target structures, overlapping or clustered biomarkers, and atypical morphologies, can lead to artifacts and consequently to inaccurate results and erroneous conclusions. Here, we propose to develop a user-friendly artificial intelligence (AI) platform for the automated detection of targeted biomarkers in digital microscopy that reduces this error by learning to distinguish between true cellular biomarkers and artifacts. We propose to integrate AI capabilities into our PIPSQUEAK technology to produce an adaptive, high-throughput, biomedical image analysis platform that quickly and accurately identifies biomarker targets from bench to bedside. A key advantage is that this AI program will be user friendly and available online, making it highly accessible to basic researchers and to technicians and clinicians identifying human pathologies. Thus, successful development of our AI program has a high translational potential. The goal of this proposal is 1) to develop and validate a machine learning model that is capable of detecting common histological marker morphologies in digital microscopy, and 2) to test the feasibility of adapting our AI platform to new biomarker datasets with minimal additional supervised training. Our end goal is to advance the reliability and speed of research findings and clinical diagnoses by making this technology widely available to researchers and clinicians. PROJECT NARRATIVE Manual analysis of biomedical images by researchers and pathologists has the potential to introduces bias and error that compromise the reliability of research and clinical findings; problems which are significant barriers to delivering the most beneficial evidence-based medicine and developing effective medical treatments. Application of artificial intelligence for the detection of disease or cellular targets has the potential to improve the reliability of research findings and clinical diagnoses, while reducing waste, time, and expense. We propose a method to improve the quality of biomedical research reproducibility and clinical diagnoses by developing a high-throughput, adaptive artificial intelligence platform for automated analysis of cellular and disease targets in digital microscopy images, which will be made available to scientists and clinicians as a user-friendly analysis platform.",Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images,9845994,R43GM134789,"['Abbreviations', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Automation', 'Biological Markers', 'Biomedical Research', 'Brain', 'Cell Line', 'Cell model', 'Cellular Morphology', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Coupled', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Evidence Based Medicine', 'Extracellular Matrix', 'FOS gene', 'Fluorescence', 'Future', 'Glial Fibrillary Acidic Protein', 'Goals', 'Histologic', 'Histology', 'Human Pathology', 'Image', 'Image Analysis', 'Immunoassay', 'Immunohistochemistry', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Medical', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Neurons', 'Nuclear', 'Pathologist', 'Performance', 'Procedures', 'Psychological Transfer', 'Publications', 'Rattus', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Shapes', 'Speed', 'Stains', 'Standardization', 'Structure', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Banks', 'Tissue Model', 'Tissue imaging', 'Tissues', 'Training', 'Zebrafish', 'automated analysis', 'base', 'bench to bedside', 'bioimaging', 'biomarker identification', 'cell type', 'cellular targeting', 'clinical Diagnosis', 'clinical diagnostics', 'contrast imaging', 'design', 'digital', 'digital imaging', 'extracellular', 'histological specimens', 'histological stains', 'imaging biomarker', 'imaging program', 'improved', 'interest', 'lateral line', 'microscopic imaging', 'predictive marker', 'programs', 'relating to nervous system', 'software as a service', 'statistics', 'targeted biomarker', 'tool', 'user-friendly', 'wasting']",NIGMS,"REWIRE NEUROSCIENCE, LLC",R43,2019,224915,0,0.004974685325601658
"Cell line identification with DNA replication timing fingerprints Project Summary Cultured cell lines have been widely used for basic research to study cell function, as models for disease, and for drug screening. Correct identification of the cell lines used is necessary to make the right scientific conclusions and replicate experiments. Cell lines in culture can be contaminated by foreign cells, which may rapidly displace the original cells. The routine verification of the identity of cultured cells should be performed, but a majority of laboratories do not monitor the identity of their cell lines, and many cell lines are misidentified. Analyses of cells submitted to major repositories such as the DSMZ (Deutsche Sammlung von Mikroorganismen und Zellkulturen) and the ATCC (American Type Culture Collection) have found that 15-40% of cell lines submitted by investigators are misidentified. The costs, effort, and time required to confirm the identity of cell lines have been a barrier to adoption of cell line identification as a routine quality control measure. Current technologies for identifying cultured cells are limited, and their cost is a barrier for small scale use. In this SBIR phase I application, we aim to develop a novel tool for cell line and cell type identification using DNA replication timing (RT) fingerprints, which are RT values at specific genomic regions. In our previous studies, we have discovered that DNA RT was highly specific to different cell lines and cell types and this specificity can be exploited for the purpose of cell line/type identification (PLoS Comp Biol, 2011; Genome Research, 2010; Genome Research 2015). A patent for RT fingerprint identification and use has been issued in 2016. Recently, we have applied this technology to identify common markers between distinct progeroid diseases (PNAS, 2017). A novel segmentation method, called iSeg, for segmenting genomic and epigenomic data has also been developed in our lab (BMC Bioinformatics, In Press), which can be used to further improve the identification of RT fingerprints. We propose to collect a large number of DNA RT profiles for a diverse set of cell lines and cell types and develop RT fingerprints for their identification. A web server will be built to take users’ input of RT data and output the cell line best matched with the input data. The web server can also take data of new cell lines from users to allow continually developing our models and database. RT fingerprints can be measured cost-effectively using polymerase chain reaction (PCR) experiment. Since the total cost for obtaining RT fingerprint for one sample is around $100, which can be further reduced when scaled up, our method makes it possible to routinely check the identity of cultured cells. Project narrative This SBIR phase I application aims to develop a novel tool for cell line and cell type identification using DNA replication timing fingerprints, which can be measured cost- effectively using polymerase chain reaction (PCR) experiment. A web server will be built to take users’ input of replication timing data and output the cell line best matched with the input data. The web server can also take data of new cell lines from users to allow continually developing our models and database.",Cell line identification with DNA replication timing fingerprints,9776322,R43GM131546,"['Acute Lymphocytic Leukemia', 'Adoption', 'American Type Culture Collection', 'Basic Science', 'Bioinformatics', 'Cell Line', 'Cell physiology', 'Cells', 'Cost Measures', 'Cultured Cells', 'DNA Replication Timing', 'Data', 'Databases', 'Disease', 'Disease model', 'Drug Screening', 'Fingerprint', 'Gene Expression', 'Genome', 'Genomic Segment', 'Genomics', 'Human', 'Laboratories', 'Legal patent', 'Length', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Output', 'Patients', 'Pattern', 'Phase', 'Polymerase Chain Reaction', 'Probability', 'Public Domains', 'Quality Control', 'Research', 'Research Personnel', 'Sampling', 'Small Business Innovation Research Grant', 'Specificity', 'Technology', 'Testing', 'Time', 'Xenograft procedure', 'base', 'cell type', 'cost', 'epigenomics', 'experimental study', 'improved', 'novel', 'off-patent', 'repository', 'scale up', 'tool', 'web server']",NIGMS,"INSILICOM, LLC",R43,2019,225000,0,-0.0051024932519273865
"A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides Abstract/Summary In this SBIR, we propose to validate our handcrafted image analysis algorithm for auto-detecting Mycobacterium tuberculosis (MTB) in a digitized sputum smear. Once validated in a blinded study against manual microscopy and culture (the gold standard), we will try to improve our handcrafted algorithm by integrating, where appropriate, deep-learning approaches (via Convolutional Neural Networks (CNN)). Our novel diagnostic device (the Diascopic iON platform) uses automated image analysis to detect pathogens of interest. Through a blinded study (400 slides), we will assess the iON's effectiveness in detecting MTB. Our aim is to achieve >99% accuracy vs. microscopy, and sensitivity-specificity vs. culture of 80% and 99%, respectively. Currently, the iON platform can detect MTB on a Ziehl-Neelsen (ZN) stained sputum smear in less than 60 seconds, with accuracy of 95% vs. microscopy. The primary objective of this SBIR is to meet or exceed the minimal requirements for the WHO Target Product Profile (published 2014) of a rapid sputum-based test for detecting TB at the microscopy-center level of the health-care system. We will accomplish this feasibility study through a collaborative effort with the Case Western Reserve University-Uganda (UCRC) research team. A full-slide digitization and automated image analysis of 400 ZN slides is planned while on the ground in Uganda. Results will be published in an appropriate peer-reviewed journal for dissemination to the relevant TB pathology and provider community. A secondary objective of this SBIR is to improve our handcrafted algorithm through the use of deep- learning techniques (CNN). We will collaborate with Dr. Madabhushi (Case Western Reserve) - a world leader in Deep Learning methodologies – on this portion of the study. We are optimistic that by combining our handcrafted approach with a deep-learning approach, we can identify MTB bacilli more effectively (i.e. faster and more accurately). We will leverage the lessons-learned in this study to develop algorithms for other developing-world diseases like Onchocerca (river blindness), Plasmodium (malaria), and Shistomes (schistosomaisis). Successful completion of this SBIR will show that the iON can truly become a platform for automated pathogen detection, which will shift lab practices toward faster & more standardized routines that are performed by unskilled workers. If we're successful in this Phase I SBIR, we will develop auto-detect algorithms for 3-4 other pathogens in a phase II SBIR. We will then market the iON platform to resource-limited clinics in countries adversely affected by developing-world diseases. It is our experience that such clinics are seeking a rapid, low cost, accurate and simple diagnostic tool to improve their efficiency and their ability to detect and treat diseases. Narrative This SBIR is a validation study of a digital pathology platform to detect TB in digitized Ziehl–Neelsen (ZN) slides. We aim to establish a high accuracy (>99%) vs. manual microscopy and a sensitivity & specificity of 80% and 99%, respectively, vs. culture. The TB analysis occurs rapidly, with results available in <60 seconds. We will investigate whether algorithm improvements are possible by combining our handcrafted approach with deep-learning approaches to improve accuracy and efficiency. If high accuracy and sensitivity-specificity can be achieved for TB detection, this low-cost technology can have a significant impact on TB laboratory operations around the world. The technology can also be applied to other pathogens whose primary method of detection is microscopy.",A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides,9851233,R43EB028736,"['Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Bacillus (bacterium)', 'Blinded', 'Case Study', 'Clinic', 'Clinical', 'Color', 'Communities', 'Complex', 'Country', 'DNA', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Feasibility Studies', 'Funding', 'Gold', 'Hand', 'Health Status', 'Healthcare Systems', 'Image', 'Image Analysis', 'Infection', 'Infrastructure', 'Ions', 'Journals', 'Laboratories', 'Low income', 'Malaria', 'Manuals', 'Methodology', 'Methods', 'Microscopy', 'Morbidity - disease rate', 'Mycobacterium tuberculosis', 'Ocular Onchocerciasis', 'Onchocerca', 'Pathogen detection', 'Pathology', 'Patient Care', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Plasmodium', 'Preparation', 'Process', 'Provider', 'Publishing', 'Quality Control', 'Readiness', 'Reporting', 'Research', 'Resources', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Small Business Innovation Research Grant', 'Specificity', 'Specimen', 'Sputum', 'Stains', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tuberculosis', 'Uganda', 'Universities', 'automated image analysis', 'base', 'cohort', 'commercialization', 'convolutional neural network', 'cost', 'deep learning', 'digital pathology', 'experience', 'improved', 'innovation', 'interest', 'man', 'mortality', 'novel', 'novel diagnostics', 'operation', 'pathogen', 'portability', 'prevent', 'remote location', 'tool', 'tuberculosis diagnostics', 'validation studies']",NIBIB,"DIASCOPIC, LLC",R43,2019,225000,0,-0.007415404243157988
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,9927093,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Comorbidity', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2019,253545,607172798,-0.011420145153188595
"QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring Modern health monitoring devices at hospitals and wearable sensors in households generate a large amount of time series data at high rate, capturing the physiological status of patients in a real-lime fashion. The premise is that these technology advances enable a data-driven healthcare system that starts making fast, accurate, objective and inexpensive decisions based upon data, in addition to an individual physician's experience and preference. However, there is a significant gap in the mathematical theory and computational tools to promptly extract actionable information from multi-modal non-stationary time series data in a robust and tractable manner, which has become a serious roadblock to further utilize bigger data for better healthcare monitoring. The goal of this research program is to develop a mathematical framework for extracting time-frequency and geometric representations of multi-modal physiological data, in an online and robust manner, and use them to design machine learning algorithms to improve real-lime health monitoring. Specifically, we hypothesize that the development of time-series and geometric methods for large streaming multi-modal monitoring data will lead to more accurate diagnosis on various physiological monitoring applications, including detection and prediction of rare events such as seizure and arrhythmia, classification of sleep stages for newborns and children, and real-time artifact removal of physiological data. To achieve our goal, we plan to develop novel theoretical and computational tools for analyzing non-stationary multi-modal time series data with noise, corruption and missing data as well as real-time algorithms for filtering and event detection from such data. The tools and algorithms will be applied on clinical tasks at the Nationwide Children's Hospital. In addition, the real-time workflow will be implemented on Hadoop clusters with a mission of public sharing of both data and software. The development from the interdisciplinary team composed of mathematicians, biomedical informaticians as well as the hospital will not only transform the frontiers of mathematics knowledge, but also significantly impact clinical applications, data science education, and the development of the $11 O billion emerging market of wireless health. The goal of this project is to develop a series of novel computational theory and software to extract physiological information from the large multi-modal data streams generated by modern health monitoring devices. The tools will be applied to various clinical tasks such as detection and prediction of seizure and arrhythmia and classification of sleep stages for newborns and children, aiming for more accurate diagnosis.",QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring,9771321,R01EB025018,"['Address', 'Algorithms', 'Arrhythmia', 'Behavior', 'Big Data', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Science', 'Detection', 'Development', 'Diagnostic', 'Education', 'Environment', 'Event', 'Excision', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Household', 'Human body', 'Individual', 'Infant', 'Knowledge', 'Limes', 'Machine Learning', 'Mathematics', 'Measures', 'Methods', 'Mission', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Nature', 'Newborn Infant', 'Noise', 'Outcome', 'Patients', 'Pattern', 'Pediatric Hospitals', 'Physicians', 'Physiologic Monitoring', 'Physiological', 'Property', 'Public Domains', 'Research', 'Resources', 'Seizures', 'Series', 'Sleep Stages', 'Stream', 'Techniques', 'Technology', 'Time', 'Universities', 'Validation', 'Wireless Technology', 'accurate diagnosis', 'base', 'biological systems', 'clinical application', 'clinical practice', 'computerized tools', 'design', 'diagnostic biomarker', 'education resources', 'experience', 'frontier', 'geometric methodologies', 'graduate student', 'heart rate variability', 'improved', 'insight', 'machine learning algorithm', 'mathematical theory', 'monitoring device', 'multimodal data', 'multimodality', 'novel', 'preference', 'programs', 'science education', 'signal processing', 'student training', 'theories', 'tool', 'wearable device']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2019,255543,30434536,-0.010088772471875661
"UC Davis Alzheimer's Core Center PROJECT SUMMARY/ABSTRACT As reflected in recent budget increases in the National Institutes of Health, and in line with the National Alzheimer’s Project Act, there is a need to enhance and leverage resources to decrease dementia disparities and change the trajectory of Alzheimer’s disease and related dementias. To fill this gap, we seek to enhance the University of California Davis Alzheimer’s Disease Center (UCD ADC), which contains a diverse ethnoracial cohort (having Hispanic, Black, and non-Hispanic White decedents), through implementation of digital pathology within our Neuropathology Core. This implementation will allow for rapid transmission of pathological data for consultation and collaborations, distribution of materials for educational purposes, tissue specimen archiving, and image analysis. In addition, by having a digital pathology with immunofluorescent capabilities will allow for viewing of the distribution (including overlap) of multiple proteins at one time within a tissue specimen. This can enhance biological studies by providing spatial relationships of proteins resulting in a deeper phenotype of disease. This supplement application is designed to support equipment and leverage and enhance infrastructure to allow the UCD ADC the ability to 1) purchase a whole slide image system to digitize existing and future histologically stained samples 2) leverage and enhance current servers and database systems to allow for storage and rapid retrieval of digital images and their data and 3) leverage and enhance hardware to develop and deploy pipelines for quantitative computational methodologies for pathologies found within a diverse ethnoracial cohort of Alzheimer’s disease brains. The UCD ADC continues to excel and expand in its research initiatives to collect and provide brain specimens and pathological data on a diverse population of individuals at various stages of cognitive ability and dementia risk. This supplement will further enable suitable infrastructure for enhancement of current collaborations and facilitate emerging collaborations by providing a means to share and analysis pathology on digitized whole slide images. PROJECT NARRATIVE Digital microscopy paired with machine learning algorithms has aided in diagnosis and provide more quantitative pathology data to unlock the secrets of diseases. These technologies are needed within the dementia field, specifically in diverse cohorts, as disease presentations may differ. By implementing state of the art imaging systems and analysis, the goals of this supplement are to enhance the ADC’s ability to provide greater access to high quality pathological data for educational, consultation and collaborative purposes, infrastructure to pursue digital solutions for more quantitative analysis, and safe secure storage of histologic specimens.",UC Davis Alzheimer's Core Center,9852188,P30AG010129,"['Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Archives', 'Autopsy', 'Back', 'Basic Science', 'Biological', 'Brain', 'Brain Diseases', 'Budgets', 'California', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Consultations', 'Data', 'Database Management Systems', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Educational Materials', 'Equipment', 'Extramural Activities', 'Future', 'Generations', 'Genetic', 'Genetic Variation', 'Glass', 'Glean', 'Goals', 'Grant', 'Heterogeneity', 'Hispanics', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Individual', 'Infrastructure', 'Infusion procedures', 'Knowledge', 'Measurement', 'Measures', 'Medical Genetics', 'Methods', 'Microscope', 'Microscopy', 'Modernization', 'Neurodegenerative Disorders', 'Not Hispanic or Latino', 'Outcome', 'Paper', 'Pathologic', 'Pathologist', 'Pathology', 'Phenotype', 'Population Heterogeneity', 'Proteins', 'Publishing', 'Research', 'Research Infrastructure', 'Resources', 'Retrieval', 'Sampling', 'Scientist', 'Secure', 'Senile Plaques', 'Slide', 'Specimen', 'Stains', 'Structure', 'Systems Analysis', 'Technology', 'Thioflavin S', 'Time', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Work', 'analysis pipeline', 'base', 'beta pleated sheet', 'cognitive ability', 'cohort', 'cost effective', 'data resource', 'data sharing', 'dementia risk', 'design', 'digital', 'digital imaging', 'digital pathology', 'disease phenotype', 'histological specimens', 'histological stains', 'human tissue', 'imaging system', 'machine learning algorithm', 'neuropathology', 'novel therapeutic intervention', 'spatial relationship', 'synergism', 'transmission process', 'whole slide imaging']",NIA,UNIVERSITY OF CALIFORNIA AT DAVIS,P30,2019,289154,254622553,-0.046877907169052886
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9787575,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2019,291536,5161939,-0.008540638079986274
"UVPD-MS Characterization of Lipopolysaccharides Abstract. Gram-negative bacteria have caused many of the most persistent infections as well as some of the deadliest pandemics in the world. Some strains have developed resistant to all available drugs, thus leading to increasing mortality from previously treatable bacterial infections. The National Strategy for Combating Antibiotic-Resistant Bacteria released by the White House in September 2014 focused on the need for (i) advancing the development of methods for identification and characterization of bacteria, (ii) accelerating basic research for new antibiotics, and (iii) improving capabilities for surveillance of antibiotic-resistant bacteria. This proposal focuses on the development of innovative tandem mass spectrometry approaches for characterization of lipopolysaccharides (LPS), the primary constituent of the outer membrane of Gram-negative bacteria that protects the membrane from chemical attack and is recognized by the immune system during pathogenic invasion. Structural characterization of LPS is critical to understanding how the structure of LPS influences immune stimulation as well as facilitating development of new antimicrobials and vaccines. This is a significant analytical challenge due to the branched structures and amphipathic properties of LPS. The escalating concerns about antibiotic resistance bacteria and the need for better avenues of defense against infectious diseases have motivated the proposed work. The objectives of this proposal are: Aim 1: Development of ultraviolet photodissociation (UVPD) mass spectrometry via hierarchical, decision-tree workflows for top-down characterization of LPS to facilitate high throughput analysis; Aim 2: Development of MS/MS approaches for serotyping of Gram-negative bacteria based on LPS; Aim 3: Examination of peptide/LPS interactions via native-spray mass spectrometry to provide both mechanistic information and screening capabilities for new antimicrobials, and Aim 4: Applications to a variety of structural problems related to the biosynthesis of LPS in Gram- negative bacteria and characterization of hybrid O-antigen/lipid A molecules in vesicle-based vaccines.  We have established a new collaboration with Dr. Bryan Davies' group to develop mass spectrometry methods to characterize peptide/lipid A interactions in support of the hunt for better antimicrobials. The continued collaboration with Dr. Stephen Trent's group emphasizes: (i) approaches for deciphering the biosynthetic pathways of bacterial LPS that endow them with the remarkable ability to re-design their outer membranes and develop antibiotic resistance, and (ii) innovative vaccine design based on antigenic LPS in vesicles.    Narrative: Gram-negative bacteria are responsible for some of the deadliest and more widespread pandemics in the world. The proposed work focuses on the development of advanced mass spectrometry approaches for characterization of complex lipopolysaccharides, including the endotoxic lipid A domains, that comprise the outer membrane of Gram-negative bacteria. The proposed work will be applied to evaluate new antimicrobials and support development of hybrid vaccines.",UVPD-MS Characterization of Lipopolysaccharides,9774073,R01GM103655,"['Acylation', 'Address', 'Advanced Development', 'Affinity', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Architecture', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Bacterial Vaccines', 'Basic Science', 'Binding', 'Catalogs', 'Cells', 'Chemical Warfare', 'Code', 'Collaborations', 'Combating Antibiotic Resistant Bacteria', 'Communicable Diseases', 'Complex', 'Complex Mixtures', 'Custom', 'Databases', 'Decision Trees', 'Development', 'Distal', 'Exhibits', 'Focus Groups', 'Glycolipids', 'Gram-Negative Bacteria', 'Hybrids', 'Hydrophobicity', 'Immune system', 'Immunization', 'Infection', 'Ions', 'Lipid A', 'Lipopolysaccharide Biosynthesis Pathway', 'Lipopolysaccharides', 'Mass Spectrum Analysis', 'Membrane', 'Methodology', 'Methods', 'Modification', 'Molecular', 'O Antigens', 'Oligosaccharides', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphorylation', 'Polysaccharides', 'Process', 'Production', 'Property', 'Publishing', 'Resistance', 'Serotyping', 'Structure', 'System', 'Tail', 'Vaccine Design', 'Vaccines', 'Variant', 'Vesicle', 'Virulence', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'cell envelope', 'chronic infection', 'design', 'high throughput analysis', 'hydrophilicity', 'improved', 'innovation', 'innovative technologies', 'inorganic phosphate', 'instrument', 'method development', 'mortality', 'novel', 'novel therapeutics', 'pandemic disease', 'response', 'screening', 'sugar', 'tandem mass spectrometry', 'ultraviolet']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2019,297043,91740242,-0.011252393542071502
"PiNDA - Fully integrated software platform for Preimplantation Genetic Testing - Aneuploidy (PGT-A) PROJECT SUMMARY  Since its inception 40 years ago, in vitro fertilization (IVF) has resulted in the birth of more than 1 million babies in the United States, and has revolutionized the field of reproductive medicine. Unfortunately, the success rate of IVF is still exceedingly low, especially for women >40 years old, with only 15.5% of implanted embryos resulting in pregnancy. This is partly due to the cytological method used for pre-implantation screening, which cannot detect the most common genetic defect during IVF, aneuploidy (i.e. chromosomal copy-number variation). Aneuploidy is linked to higher rates of miscarriage, and occurs more often in women >40 years of age; thus, aneuploidy has been a frequent target for genetic screening to improve IVF outcomes.  Pre-implantation genetic testing for aneuploidy (PGT-A) refers to a variety of techniques aimed at detecting changes in chromosomal copy number, with the goal of identifying high-quality euploid embryos for implantation. Recent advances in next-generation sequencing (NGS) technologies have made it possible to screen embryos at higher levels of precision, and across a wider range of genetic defects, including mosaicism, triploidy and single nucleotide polymorphisms (SNPs). Despite these remarkable advances, there are still significant challenges with PGT-A sequencing. Indeed, the most commonly implemented software for PGT-A (i.e. BlueFuse® ) are bundled with specific sequencing platforms (i.e. VeriSeq®), and are only designed to test for aneuploidy. Furthermore, existing pipelines are not user-friendly or customizable, which is a serious obstacle prohibiting the use of NGS by clinicians / embryologists. A more accessible bioinformatics platform is desperately needed that will bridge the gap between PGT-A sequencing and IVF outcomes.  Basepair™ is an innovator in efficient, user-friendly, web-based NGS analysis systems, with fully automated ChIP-, RNA-, ATAC-, and DNA-Seq bioinformatics pipelines available online. Here, Basepair will deliver PiNDA™, the first fully integrated software solution for comprehensive PGT-A analysis. In Aim 1, we will develop modules to test for specific chromosomal abnormalities, including mosaicism and triploidy, and validate each model with training data derived from somatic cell lines with known chromosomal aberrations. In Aim 2, we will integrate our modules into the PiNDA software system, creating a user-friendly, web-based interface that will perform full data analysis (raw data to full summary report) in <15 minutes, with no manual input required. Final data will be accessible via Basepair’s online portal, facilitating rapid data transfer from embryologists to physicians, and supporting the integration of NGS tests in IVF. Our innovative bioinformatics platform will accelerate NGS analysis for IVF, improving rates of pregnancy and advancing research in the success of IVF procedures. PROJECT NARRATIVE  In vitro fertilization (IVF) methods have begun to leverage next-generation sequencing technologies for pre-implantation genetic testing of aneuploidy (PGT-A), expanding the array of chromosomal abnormalities that can be accurately detected. However, the vast majority of software can only distinguish one type of genetic defect (i.e. aneuploidy), are difficult to use, and are tied to distinct sequencing platforms, limiting the clinical utility of resulting analyses. Basepair™ Inc. is a pioneer in user-friendly, web-based bioinformatics pipelines, providing comprehensive services for a wide range of sequencing projects. Here, Basepair will develop an inclusive suite of software for PGT-A, compatible with sequencing data from multiple platforms. This product will be of high value to the field and will help bridge the gap between advances in DNA sequencing and IVF technology.",PiNDA - Fully integrated software platform for Preimplantation Genetic Testing - Aneuploidy (PGT-A),9846492,R43HD100280,"['ATAC-seq', 'Age-Years', 'Algorithms', 'Aneuploid Cells', 'Aneuploidy', 'Bioinformatics', 'Biopsy', 'Birth', 'Cell Line', 'Cell division', 'Centers for Disease Control and Prevention (U.S.)', 'ChIP-seq', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Copy Number Polymorphism', 'Culture Media', 'Cytology', 'DNA sequencing', 'Data', 'Data Analyses', 'Embryo', 'Feedback', 'Fertility Agents', 'Fertilization in Vitro', 'Genetic Screening', 'Goals', 'Harvest', 'Implant', 'Letters', 'Link', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Morphology', 'Mosaicism', 'Mutation', 'Online Systems', 'Outcome', 'Phase', 'Physicians', 'Polymorphism Analysis', 'Pregnancy', 'Pregnancy Rate', 'Preimplantation Diagnosis', 'Procedures', 'Reporting', 'Reproductive Medicine', 'Research', 'Role', 'Sampling', 'Services', 'Single Nucleotide Polymorphism', 'Somatic Cell', 'Specificity', 'Spontaneous abortion', 'Summary Reports', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Training', 'Triploidy', 'United States', 'Uterus', 'Woman', 'analysis pipeline', 'aneuploidy analysis', 'cell free DNA', 'design', 'early embryonic stage', 'egg', 'implantation', 'improved', 'innovation', 'natural Blastocyst Implantation', 'next generation sequencing', 'phase 1 study', 'preimplantation', 'screening', 'sequencing platform', 'software development', 'software systems', 'sperm cell', 'success', 'transcriptome sequencing', 'user-friendly', 'web based interface']",NICHD,"BASEPAIR, INC.",R43,2019,298717,348442,-0.01326742195307425
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,9976740,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Heterogeneity', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2019,299197,807432003,-0.010558669584727622
"Rapid and broad pathogen profiling system for infection in newborn Abstract Worldwide, infectious disease remains the leading cause of neonatal mortality and results in one million newborn deaths each year. Rapid and precise profiling of pathogens is the key to targeted and effective clinical management of infectious disease. However, current diagnostic methods are slow, limited in breadth of detection, and often unreliable. Further, they have limited ability to detect polymicrobial infection and suffer from poor specificity due to an inability to distinguish clinically relevant from non-pathogenic DNA. Genotyping of pathogen genomic sequences using High Resolution Melt (HRM) provides a simple, rapid, and modern alternative to blood culture testing. HRM generates sequence specific melt curves in a closed-tube reaction as PCR-amplified DNA fragments are heated and disassociate. Our team has advanced this technology through the proof-of-concept stage, demonstrating that a novel digital PCR format for HRM can achieve accurate universal genotyping and quantification of DNA targets in under 3 hours. DNA sequences present in mixtures are individually amplified and identified using the principles of microfluidic sample partitioning and machine learning to enable sensitive specific polymicrobial detection of all the targets present in the DNA mixture. However, for clinical integration, critical innovations are needed. This includes optimization of our upstream processing steps to selectively capture, load, and detect DNA sequences from only viable pathogen cells from a small-volume (≤ 1mL) neonatal blood sample. Further, methods to establish linkages between pathogen identity and antibiotic resistance are needed at the single cell level to fully characterize and accurately quantitate the resistance profile of the pathogen population for precise targeted treatment. In phase I of this proposal, we will focus on refining sample preparation steps to (1) maximize our sensitivity and (2) enable co-localization of resistance markers with identified microbes. We hypothesize that we can efficiently capture pathogen load from blood, reducing interference from human cell contents and enable single cell analysis and quantitation of only viable pathogens while linking species identification and resistance. The processes and tests developed in this proposal will provide: 1) high negative predictive value to rule out bloodstream infection; and 2) specific identification and quantitation of pathogens along with co-localization of relevant antibiotic resistance genes for the targeted treatment of true infections while limiting influence from contaminants or environmental microbes of no clinical significance. In Phase II, the system will be developed to its beta form for testing in a clinical environment. Melio’s goal is to ultimately deliver a low-cost, small-footprint benchtop device compatible with the clinical workflow. Narrative We propose the development of a culture-independent molecular diagnostic test that will enable the rapid and precise detection of infections in newborns. This test uniquely combines the cutting-edge technologies of machine learning, microfluidic partitioning of samples for digital interrogation, and High-Resolution Melting of nucleic acids to create unique pathogen fingerprints for all high-risk bacterial, fungal, and viral pathogens and associated resistance marker(s) present in small-volume blood samples in under 3 hours. Such a timely and accurate test is needed for effective antimicrobial therapy in newborns suspected of infection to reduce antibiotic use in non-infected patients while aggressively treating those in need with narrow spectrum antibiotics targeted towards the offending pathogens.",Rapid and broad pathogen profiling system for infection in newborn,9778646,R43AI145567,"['Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Asses', 'Asthma', 'Bacteria', 'Biological Assay', 'Blood', 'Blood Circulation', 'Blood Volume', 'Blood specimen', 'Cells', 'Chemistry', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Communicable Diseases', 'Conserved Sequence', 'Custom', 'Cytolysis', 'DNA', 'DNA Sequence', 'DNA amplification', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Drug resistance', 'Emerging Technologies', 'Environment', 'Epidemiology', 'Fingerprint', 'Gene Targeting', 'Genome', 'Genomic DNA', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Hour', 'Human', 'Hypersensitivity', 'Immune response', 'Individual', 'Infection', 'Link', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Microbe', 'Microfluidics', 'Modernization', 'Molecular Diagnostic Testing', 'Neonatal', 'Neonatal Intensive Care Units', 'Neonatal Mortality', 'Neurodevelopmental Disorder', 'Newborn Infant', 'Noise', 'Nucleic Acids', 'Obesity', 'Organism', 'Outcome', 'Pathogen detection', 'Pathogenicity', 'Patient Care', 'Patients', 'Phase', 'Population', 'Predictive Value', 'Preparation', 'Process', 'Protocols documentation', 'Reaction', 'Reproducibility', 'Resistance', 'Resistance profile', 'Resolution', 'Respiratory distress', 'Running', 'Sampling', 'Sepsis', 'Specificity', 'Symptoms', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Tube', 'United States', 'Whole Blood', 'Work', 'antimicrobial', 'base', 'clinically relevant', 'clinically significant', 'cost', 'design', 'digital', 'genome sequencing', 'high risk', 'improved', 'innovation', 'instrumentation', 'machine learning algorithm', 'melting', 'microbial', 'microbiome research', 'neonatal sepsis', 'neonate', 'next generation', 'novel', 'pathogen', 'pathogen genome', 'pathogen genomics', 'pathogenic bacteria', 'pathogenic fungus', 'pathogenic virus', 'plasmid DNA', 'premature', 'prevent', 'resistance mechanism', 'single cell analysis', 'targeted treatment', 'whole genome']",NIAID,MELIOLABS INC.,R43,2019,299734,0,-0.017637118340685407
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,9658524,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'actionable mutation', 'base', 'disease phenotype', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'learning strategy', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2019,305167,511185245,-0.007616496737782076
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9705993,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'analysis pipeline', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2019,314000,560644462,-0.014118750287225616
"Common Fund Data Supplement: Integration of KOMP2 (IMPC) and PHAROS into MARRVEL 2.0 for machine learning-assisted rare variant prioritization Project Summary  This application is being submitted in response to NOT-RM-19-009 as a supplement to the parent award U54NS093793.  The Common Fund supports a number of resources that can significantly enhance gene and variant prioritization for study in the Model Organisms Screening Center of the Undiagnosed Diseases Network and beyond. To facilitate the use of these resources, we propose to create a tool that can be easily accessed by clinical geneticists and model organism scientists alike.  MARRVEL (Model organism Aggregated Resources for Rare Variant ExpLoration) was created two years ago because important data that is necessary for rare variant analysis for personalized medicine is spread throughout the internet in tens of different locations. To improve efficiency and streamline access to these data sources, we created a web-tool that allows users to query tens of data sources at once, including GTEx, and links to IMPC, the display portal for KOMP2.  In this proposal, our goal is to develop version 2 of MARRVEL to promote the use of Common Fund resources in the rare disease research community for manual and automated data analysis. This goal will be accomplished by developing MARRVEL 2.0 by integrating KOMP2 (IMPC) and PHAROS data and using the aggregated dataset to develop a machine-assisted gene and variant prioritization for diagnosis and animal model generation.  Our goals align with those of the NIH Common Fund to increase the utility of resources for broader use in the biomedical community. Project Narrative  We aim to promote the use of Common Fund resources and facilitate the diagnosis of rare diseases and the subsequent generation of animal models for the Undiagnosed Diseases Network and beyond. This goal will be accomplished by developing the web resource, MARRVEL 2.0.",Common Fund Data Supplement: Integration of KOMP2 (IMPC) and PHAROS into MARRVEL 2.0 for machine learning-assisted rare variant prioritization,9984757,U54NS093793,"['Affect', 'Animal Model', 'Artificial Intelligence', 'Award', 'Clinical', 'Collaborations', 'Communities', 'Country', 'Data', 'Data Analyses', 'Data Display', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Discipline', 'Disease', 'Disease model', 'Drosophila genus', 'Drug Targeting', 'Expert Systems', 'Family', 'Funding', 'Generations', 'Genes', 'Genetic Diseases', 'Genotype-Tissue Expression Project', 'Goals', 'Growth', 'Healthcare Systems', 'Human Genetics', 'Individual', 'Internet', 'Investigation', 'Knowledge', 'Link', 'Location', 'Machine Learning', 'Manuals', 'Medical', 'Medical Genetics', 'Modeling', 'Mus', 'Parents', 'Pathogenicity', 'Pharmaceutical Preparations', 'Phenotype', 'Process', 'Proteins', 'Rare Diseases', 'Research', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Suggestion', 'Symptoms', 'System', 'Testing', 'Therapeutic', 'Therapeutic Studies', 'Time', 'Training', 'United States National Institutes of Health', 'Variant', 'Visit', 'Yeasts', 'Zebrafish', 'base', 'data wrangling', 'design', 'experimental study', 'feeding', 'fly', 'genetic disorder diagnosis', 'genetic variant', 'human data', 'improved', 'interest', 'learning community', 'machine learning algorithm', 'model organisms databases', 'online resource', 'personalized medicine', 'phenotypic data', 'rare genetic disorder', 'rare variant', 'response', 'screening', 'supervised learning', 'tool', 'web-based tool']",NINDS,BAYLOR COLLEGE OF MEDICINE,U54,2019,320000,323604360,-0.010871681251858882
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9746721,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Infrastructure', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'classification algorithm', 'clinical practice', 'community involvement', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,334204,7208224,0.027073322220375878
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,9859232,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Dimensions', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'One-Step dentin bonding system', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2019,345016,560644462,0.012304324662541376
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9731544,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'repository', 'research and development', 'software development', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,350620,758431960,0.013329724983238688
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9608754,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2019,356625,323604360,0.011753235746555743
"A platform for mining, visualization and design of microbial interaction networks Project Summary One of the burning questions in the study of the human microbiome is whether and how it is possible to design specific strategies for rebalancing the taxonomic and functional properties of human-associated microbial communities, triggering the transition from “disease states” to “healthy states”. While empirical studies provide strong support for the idea that we may be able to cure, or at least  treat, a number of diseases by simply transplanting microbiomes, or inducing changes through taxonomic or environmental perturbations, to date little mechanistic understanding exists on how microbial communities work, and on how to extend microbiome research from an empirical science to a systematic, quantitative field of biomedicine. We propose here to establish a computational platform--   a database (Aim 1) with fully integrated analytical software (Aims 2 and 3) --- developed for and with the cooperation of the scientific community. The resource goes beyond cataloguing microbial abundances under different condition; its aim is to enable an understanding of networks of interacting species and their condition-dependence, with the goal of eventually facilitating disease diagnosis and prognosis, and designing therapeutic strategies for microbiome intervention. Our project is centered around three key aims: 1.	The creation of a Microbial Interaction Network Database (MIND), a public resource that will collect data on inter-species interactions from metagenomic sequencing projects, computer simulations and direct experiments. This database will be accessed through a web-based platform complemented with tools for microbial interaction network analysis and visualization, akin to highly fruitful tools previously developed for the study of genetic networks; the database will also serve as the public repository of microbial networks associated with human diseases; 2.	The implementation of an integrated tool for simulation of interspecies interactions under different environments, based on genomic data and whole-cell models of metabolism; 3.	The implementation of new algorithms for microbial community analysis and engineering. These algorithms, including stoichiometric, machine-learning and statistical approaches will facilitate a “synthetic ecology” approach to help design strategies (e.g. microbial transplants or probiotic mixtures) for preventing and targeting microbiome-associated diseases. Our work will fill a major gap in current microbiome research, creating the first platform for global microbial interaction data integration, mining and computation. Project Narrative Among the major developments of the genomic revolution has been the ability to identify thousands of microbial species and strains living in communities in 5 major habitats in the human body, and the recognition that the relative abundances of these populations is strongly correlated with environment: disease state, diet, treatment protocol and so on. A major challenge in utilizing the deluge of health relevant data is structuring it into a database that facilitates understanding inter-microbial interactions in these communities. The aim of this proposal is to create a database and integrated computational platform, open to and contributed to by the research community, which will greatly accelerate the conversion of data into health related actionable knowledge.","A platform for mining, visualization and design of microbial interaction networks",9638561,R01GM121950,"['Affect', 'Algorithms', 'Cataloging', 'Catalogs', 'Cell model', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Development', 'Diet', 'Discipline', 'Disease', 'Ecology', 'Ecosystem', 'Empirical Research', 'Engineering', 'Environment', 'Evolution', 'Future', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Habitats', 'Health', 'Human Biology', 'Human Microbiome', 'Human body', 'Imagery', 'Individual', 'Intervention', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Mediating', 'Metabolic', 'Metabolism', 'Metadata', 'Methods', 'Microbe', 'Mining', 'Nature', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Preventive Medicine', 'Probiotics', 'Property', 'Research', 'Resources', 'Science', 'Scientist', 'Structure', 'Taxonomy', 'Technology', 'Therapeutic', 'Time', 'Transplantation', 'Treatment Protocols', 'Work', 'base', 'computational platform', 'computer framework', 'data integration', 'data to knowledge', 'design', 'disease diagnosis', 'experimental study', 'feeding', 'genome-wide', 'genomic data', 'human disease', 'human microbiota', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microbiome research', 'microbiota transplantation', 'microorganism interaction', 'novel diagnostics', 'novel therapeutics', 'open source', 'outcome forecast', 'prevent', 'repository', 'simulation', 'tool', 'user-friendly']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2019,364865,61050884,-0.008315480054776607
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,9642618,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Effectiveness', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Imagery', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Universities', 'Virginia', 'absorption', 'artificial neural network', 'base', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2019,375602,169622494,0.006632375985280172
"Joint Analysis of Microbiome and Other Genomic Data Types PROJECT SUMMARY In the same way that the human genome project created invaluable genomic maps, the objective of this project is to develop methods for eventual construction of comprehensive genetic and metabolomic by microbome relationship maps. Such maps would be an invaluable resource for improving our understanding as to the underlying mechanisms by which microbes and –omics features influence human diseases and conditions, potentially leading to identification of novel therapeutic targets. To these ends, this proposal seeks to develop statistical and computational tools for mapping associations and interactions between microbes and other – omic features and for further utilizing other –omics to improve microbiome based prediction models. Specifically, motivated by studies examining the role of the vaginal microbiome and other –omics in birth outcomes and menopause, we aim to develop statistical methodology for (1) mapping genetic variants that influence microbiome composition so as to understand the innate component of the microbiome as well as learn mechanisms by which genetics influence outcomes; (2) creating global metabolic maps integrating both microbes and metabolites which will enable understanding of how perturbations might influence the system and identify key pathways for therapeutic target; (3) exploiting other –omics in constructing more accurate microbiome based prediction models for preterm birth; (4) developing, distributing and supporting software packages for the proposed methods. The methods are based on frameworks in which we have considerable experience, but novel technical contributions are made to accommodate features of the data such as population stratification and relatedness in genetics, phylogenetic structure, and compositionality, as well as practical considerations such as availability of samples and other –omics data. Consequently, these new methods have the potential for accelerating mechanistic and translational microbiome studies, developing vital resources for enabling systematic achievement of many biological, clinical, and public health problems that have eluded researchers for decades. PROJECT NARRATIVE The methods developed in this proposal will enable improved understanding of the interactions between microbes and other –omics, thus aiding in elucidation of the mechanisms by which microbes and –omic features influence health outcomes and aiding in identification of potential molecular targets. Further emphasis is placed on utilization of other –omics to develop microbiome based prediction models in pregnancy outcomes, improving early detection of women who are at risk of preterm delivery.",Joint Analysis of Microbiome and Other Genomic Data Types,9763572,R01GM129512,"['Achievement', 'Address', 'Area', 'Automobile Driving', 'Biological', 'Birth', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Early Diagnosis', 'Future', 'Genes', 'Genetic', 'Genomics', 'Grouping', 'Health', 'Human Genome Project', 'Joints', 'Lasso', 'Learning', 'Machine Learning', 'Maintenance', 'Maps', 'Medical', 'Menopause', 'Metabolic', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Modification', 'Molecular Target', 'Network-based', 'Outcome', 'Pathway interactions', 'Performance', 'Phylogenetic Analysis', 'Pregnancy Outcome', 'Premature Birth', 'Procedures', 'Public Health', 'Quantitative Trait Loci', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Structure', 'System', 'Taxonomy', 'Training', 'Woman', 'Work', 'base', 'biological systems', 'computerized tools', 'experience', 'genetic variant', 'genomic data', 'human disease', 'improved', 'interest', 'loss of function', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microbiome analysis', 'microbiome components', 'microbiome composition', 'microbiome research', 'new therapeutic target', 'novel', 'open source', 'population stratification', 'predictive modeling', 'simulation', 'software development', 'therapeutic target', 'tool', 'translational study', 'user friendly software', 'vaginal microbiome']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,396000,758431960,-0.02170399766671971
"Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties ABSTRACT Mesenchymal stem cells (MSCs) have broad-based potential in regenerative medicine cell therapies and can be isolated from a variety of different tissues. Though MSCs from different tissues are phenotypically similar, a barrier to their clinical use is the high variability of their trophic and regenerative properties. This variability suggests that inherent differences exist in the molecular machinery guiding MSC properties between different MSC populations, yet, to date, these differences are ill-defined. To this end, we have preliminary evidence that MSC phenotypes correlate to their regenerative outcomes. In this study, we aim to elucidate how the molecular and cellular properties of distinct MSC populations determine their regenerative properties. Our hypothesis is that MSCs from different tissues have different regenerative properties which correlate to specific molecular profiles defined by gene expression and transcriptional activity. To test this hypothesis, the project proposed has three Specific Aims (SAs). In SA1, we will determine how tissue-specificity dictates gene expression and dynamic transcription factor activity of distinct MSCs. SA2 will determine how differences in the cellular and molecular properties of MSCs correlate to MSC phenotype. Finally, in SA3, we will determine how the molecular profiles and cellular activities of MSCs dictate their regenerative properties. Findings of the proposed study will provide novel insights about how the distinct molecular profiles of MSCs dictate their biological and physiological properties. In a therapeutic context, this would enable the development of innovative screening technologies for MSC therapies to identify and enrich for the most appropriate MSC for the specific therapeutic application. PROPOSAL NARRATIVE Stem cell therapies are emerging as a new treatment approach to regenerate lost tissues, treat ischemic disorders, and treat chronic inflammatory conditions. Many of these approaches use stem cells from adults which are present in various regions throughout the body. Our research team is working to better understand how and why these adult stem cells behave the way they do so that we can better determine how to use them in different therapies to treat debilitating health conditions.",Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties,9835275,R01DE028657,"['Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Angiogenic Factor', 'Automobile Driving', 'Biological', 'Biological Process', 'Bone Marrow', 'Bone Regeneration', 'Bone Tissue', 'Cell Culture Techniques', 'Cell Separation', 'Cell Therapy', 'Cells', 'Chronic', 'Clinical', 'Clinical Trials', 'Computer Simulation', 'Data', 'Dental', 'Dental Pulp', 'Development', 'Disease', 'ENG gene', 'Emerging Technologies', 'Fatty acid glycerol esters', 'Funding Mechanisms', 'Gene Expression', 'Gene Expression Profile', 'Genetic Transcription', 'Gingiva', 'Health', 'Immunophenotyping', 'Inflammation', 'Inflammatory', 'Knowledge', 'Link', 'Maintenance', 'Mesenchymal Stem Cells', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Muscle', 'Natural regeneration', 'Operative Surgical Procedures', 'Oral', 'Osteogenesis', 'Outcome', 'Pathway interactions', 'Performance', 'Phenotype', 'Physiological', 'Population', 'Population Heterogeneity', 'Production', 'Property', 'Regenerative Medicine', 'Regulation', 'Reporting', 'Research', 'Rodent Model', 'Role', 'Signal Pathway', 'Sorting - Cell Movement', 'Specificity', 'Stem cells', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Tooth structure', 'United States National Institutes of Health', 'Work', 'adult stem cell', 'alveolar bone', 'angiogenesis', 'base', 'bone', 'clinical translation', 'healthy volunteer', 'in vivo', 'innovation', 'insight', 'interest', 'machine learning algorithm', 'molecular phenotype', 'next generation sequencing', 'novel', 'oral tissue', 'osteogenic', 'population based', 'regenerative', 'regenerative therapy', 'screening', 'self-renewal', 'stem cell differentiation', 'stem cell population', 'stem cell therapy', 'stemness', 'transcription factor', 'transcriptome']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,398630,641965656,-0.009687340574927908
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive, PhysioBank, was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. PhysioToolkit, its software collection, supports exploration and quantitative analyses of PhysioBank and similar data with a wide range of well-documented, rigorously tested open-source software that can be run on any platform. PhysioNet's team of researchers leverages results of other funded projects to drive the creation and enrichment of: i) Data collections that provide increasingly comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC III (Medical Information Mart for Intensive Care) Database of critical care patients; ii) Analytic methods that lead to more timely and accurate diagnoses of major public health problems (such as life-threatening cardiac arrhythmias, infant apneas, fall risk in older individuals and those with neurologic disease, and seizures), and iii) Elucidation of dynamical changes associated with a variety of pathophysiologic processes and aging (such as cardiopulmonary interactions during sleep disordered breathing syndromes); User interfaces, reference materials and services that add value and improve accessibility to PhysioNet's data and software (such as PhysioNetWorks, a virtual laboratory for data sharing). Impact: Cited in The White House Fact Sheet on Big Data Across the Federal Government (March 29, 2012), PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are inaccessible otherwise. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world- wide, growing community of researchers, clinicians, educators, students, and medical instrument and software developers, retrieve about 380 GB of data per day. By providing free access to its unique and wide-ranging data and software collections, PhysioNet is invaluable to studies that currently result in an impressive average of nearly 250 new scholarly articles per month by academic, clinical, and industry-affiliated researchers worldwide. Over the next year we aim to sustain and enhance PhysioNet's impact with new technology and data; and complete the 2019 PhysioNet/Computing in Cardiology Challenge on sepsis. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,9993811,R01GM104987,"['Aging', 'Algorithms', 'Apnea', 'Area', 'Arrhythmia', 'Big Data', 'Biomedical Research', 'Boston', 'Bypass', 'Cardiology', 'Cardiopulmonary', 'Categories', 'Clinical', 'Clinical Data', 'Cloud Service', 'Collection', 'Communities', 'Community Outreach', 'Complex', 'Computer software', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dedications', 'Development', 'Diagnostic radiologic examination', 'Entropy', 'FAIR principles', 'Federal Government', 'Functional disorder', 'Funding', 'Grant', 'Imagery', 'Individual', 'Industry', 'Infant', 'Infrastructure', 'Intensive Care', 'Israel', 'Journals', 'Laboratories', 'Lead', 'Licensing', 'Life', 'Link', 'Machine Learning', 'Maintenance', 'Medical', 'Medical center', 'Methods', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Phase Transition', 'Physiological', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Role', 'Running', 'Seizures', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Students', 'Switzerland', 'Syndrome', 'Testing', 'Thoracic Radiography', 'Time', 'United States National Institutes of Health', 'University Hospitals', 'Visit', 'accurate diagnosis', 'analytical method', 'clinical application', 'computerized data processing', 'computing resources', 'data archive', 'data sharing', 'experience', 'fall risk', 'heart rate variability', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'member', 'nervous system disorder', 'new technology', 'open source', 'preservation', 'repository', 'signal processing', 'software repository', 'symposium', 'time interval', 'virtual laboratory']",NIGMS,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2019,409563,135941803,-0.025038527486555415
"3D temperature control to study biological processes Project Summary Temperature control technology is necessary for a broad range of biologically relevant processes including organ-on-chip operation, biomolecular kinetics, cell growth, studying gene function with temperature-sensitive mutations, cancer cell resistance to hyperthermia treatments, protein crystallization, and DNA analysis. Most biosensing devices lack the needed temperature measurement accuracy and precise temperature control to understand the thermal mechanisms of these processes. For example, temperature variations of 0.2°C can activate heat shock proteins, increasing the resistance of cancer cells to thermal ablation treatment, but reported temperature accuracies are often near ±1°C. This proposal aims to revolutionize the biomedical temperature measurement and control ecosystem by developing technology, models, and validated devices capable of microscopic, spatially resolved temperature sensing and control at ±0.1°C accuracy (10x better than what is used in most biosensing systems). Microfluidics is a promising technology for an extremely broad range of biomedical applications that notably lacks the necessary temperature accuracies and spatial temperature control to effectively study biothermal mechanisms. This proposal intends to impact human health by developing disruptive temperature control tools to accelerate biomedical innovation in thermally sensitive processes. Our group recently demonstrated the capacity to measure temperature at a single point with fluorescent dyes, achieving a ±0.05°C noise floor by using machine learning techniques. We have also 3D printed a cell-based genotype and phenotype assay device with cell growth chambers, monoliths for mRNA capture & fluorescence measurement, and integrated pumps and valves in a volume of only 2.2 mm × 2.2 mm × 1 mm. Aims 1 and 2 of this proposal will build on these successes by developing 3D printing technologies that easily incorporate complex temperature sensing, heating, and cooling channels, coupled with multi-physics/CAD models to rapidly iterate through the prototype development cycle. These advances will be used in Aim 3 to construct a microscopically temperature-controlled chip to measure DNA melt curves to determine the zygosity of a Factor 5 Leiden. This will show that the technology can detect the subtle difference in melting temperature that is undetectable by most PCR machines, as a proof-of-concept before the technology can be applied to other biological process. The overall objective of these studies is to develop a suite of affordable technologies researchers can use to understand biothermal mechanisms to lay the foundation for advances in disease diagnosis, treatment, and prevention. Project Narrative The instruments we use to study the effects of temperature on biological processes are less accurate than humans’ own ability to perceive temperature changes. The proposed research will develop improved microscopic temperature sensing & control technologies and demonstrate them by performing DNA analysis in a 3D printed device. Because the technology is cheap and accurate, it will be widely accessible to any lab, increasing our ability to understand the fundamental role biothermal processes have in disease occurrence, diagnosis, and treatment.",3D temperature control to study biological processes,9732034,R15GM132868,"['3-Dimensional', '3D Print', 'Automation', 'Biochemistry', 'Biological', 'Biological Assay', 'Biological Process', 'Biomedical Research', 'Biosensing Techniques', 'Blood specimen', 'Cells', 'Complex', 'Coupled', 'Crystallization', 'Custom', 'DNA', 'DNA analysis', 'Development', 'Devices', 'Diagnosis', 'Discipline', 'Disease', 'Ecosystem', 'Electrical Engineering', 'Engineering', 'Environment', 'Factor Analysis', 'Factor V', 'Floor', 'Fluorescence', 'Fluorescent Dyes', 'Foundations', 'Future', 'General Population', 'Genotype', 'Geometry', 'Goals', 'Grant', 'Health', 'Heat Stress Disorders', 'Heat shock proteins', 'Heating', 'High temperature of physical object', 'Hour', 'Human', 'Hyperthermia', 'Institution', 'Kinetics', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Messenger RNA', 'Microfluidic Analytical Techniques', 'Microfluidic Microchips', 'Microfluidics', 'Microscopic', 'Modeling', 'Mutation', 'Noise', 'Outcome', 'Performance', 'Persons', 'Phenotype', 'Physics', 'Plant Resins', 'Prevention', 'Printing', 'Process', 'Proteins', 'Pump', 'Quantum Dots', 'Reagent', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Risk', 'Role', 'Sampling', 'Shapes', 'Single Nucleotide Polymorphism', 'Source', 'Spatial Distribution', 'System', 'Techniques', 'Technology', 'Temperature', 'Temperature Sense', 'Testing', 'Thermal Ablation Therapy', 'Thermometry', 'Thermoreceptors', 'Thromboembolism', 'Training', 'Variant', 'Venous', 'Work', 'base', 'biological systems', 'cancer cell', 'career', 'cell growth', 'computer science', 'design', 'disease diagnosis', 'experience', 'gene function', 'graduate student', 'hyperthermia treatment', 'improved', 'improved outcome', 'innovation', 'innovative technologies', 'instrument', 'melting', 'new technology', 'operation', 'organ on a chip', 'prototype', 'sensor', 'sensor technology', 'success', 'tool', 'undergraduate student']",NIGMS,BRIGHAM YOUNG UNIVERSITY,R15,2019,439058,6579725,-0.009170271447649442
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,9862231,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Comorbidity', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2019,450365,560644462,-0.0008056122579985953
"Next Generation Testing Strategies for Assessment of Genotoxicity Project Summary  It is well recognized that current batteries of genetic toxicology assays exhibit two critical deficiencies. First, the throughput capacity of in vitro mammalian cell genotoxicity tests is low, and does not meet current needs. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no consideration for potency, and virtually no information is provided about molecular targets and mechanisms. These deficiencies in hazard characterization prevent genotoxicity data from optimally contributing to modern risk assessments, where this information is essential. We will address these major problems with current in vitro mammalian cell genetic toxicity assays by developing methods and associated commercial assay kits that dramatically enhance throughput capacity, and delineate genotoxicants' primary molecular targets, while simultaneously providing information about potency. Once biomarkers and a family of multiplexed assays have been developed for these purposes, an interlaboratory trial will be performed with prototype assay kits to assess the transferability of the methods. Project Narrative  DNA damage that cannot be faithfully repaired results in gene mutation and/or chromosomal aberrations, and these effects are known to contribute to cancer and other severe diseases. Thus, there is an important need for sensitive assays to evaluate chemicals for genotoxic and other deleterious effects. The work proposed herein will address issues that have plagued genotoxicity assessments for the last several decades: low throughput, lack of potency metrics, and little to no information about molecular targets. We will address these major problems with current genetic toxicity assays by developing new methods and associated commercial assay kits.",Next Generation Testing Strategies for Assessment of Genotoxicity,9807074,R44ES029014,"['Address', 'Affect', 'Aneugens', 'Antioxidants', 'Appearance', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Biological Response Modifiers', 'Bleomycin', 'Caspase', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemicals', 'Chromosome abnormality', 'Chromosomes', 'Classification', 'Cleaved cell', 'Colcemid', 'Companions', 'Complex', 'Computer Simulation', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'DNA-PKcs', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Dose', 'Epitopes', 'Etoposide', 'Exhibits', 'Family', 'GADD45A gene', 'Gamma-H2AX', 'Gene Mutation', 'Genetic', 'Goals', 'Harvest', 'Histone H3', 'Human', 'In Vitro', 'Intercalating Agents', 'Investigation', 'Kinetics', 'Label', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Modification', 'Molecular Target', 'Mutagenicity Tests', 'NF-kappa B', 'Nuclear', 'Pathway interactions', 'Phase', 'Physiologic pulse', 'Procedures', 'Protocols documentation', 'Reagent', 'Reference Values', 'Risk Assessment', 'Schedule', 'Scheme', 'Series', 'Stains', 'TP53 gene', 'Testing', 'Time', 'Toxic effect', 'Toxicogenetics', 'Training', 'Validation', 'Work', 'aurora kinase', 'base', 'clastogen', 'computerized tools', 'design', 'experimental study', 'genotoxicity', 'hazard', 'inhibitor/antagonist', 'next generation', 'prediction algorithm', 'prevent', 'prototype', 'random forest', 'repaired', 'response', 'targeted agent', 'tool', 'treatment optimization', 'virtual']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2019,482291,651293,-0.011034855094520369
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9750520,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Personal Satisfaction', 'Persons', 'Phase', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'manufacturability', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2019,507856,0,-0.027809560557620183
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9784742,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data pipeline', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2019,533529,197030888,-0.005783915340385597
"Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system Abstract Numerous small vessels making up the central nervous system blood and lymphatic vascular networks are heterogeneous and region-specific dynamic structures, whose segments, position, shape and function can change in response to physiological and pathophysiological conditions. To date it has not been possible to integrate blood and lymphatic vascular elements and their microenvironment to achieve a holistic quantitative characterization of the combined brain and meningeal tissue-scale vascular networks, its structure and function in normal and disease states. This application proposes to develop microscopy- based high-throughput image analysis techniques for automated extraction of blood and lymphatic vascular networks enabling quantitative morphodynamic characterization of cerebrovascular microenvironment changes in two intracranial compartments – the brain and dura mater. The study will focus on new algorithms for precise region-specific microvessel registration, mosaicing, segmentation, fusion and colocalization for constructing large tissue scale spatially aligned dual blood/lymphatic vascular network structural maps in the animals of both sexes, as well as characterization of heterogeneities of microvascular networks, including blood and lymphatic vasculature, under estrogen and sleep deprivation (the conditions relevant to multiple cerebrovascular disorders) compared to physiological settings. In other words, advanced microscopy-based techniques will be used to image blood and lymphatic vessels at sub-micron resolution in dura mater and the brain, and then cutting-edge deep machine learning imaging analysis methods will be employed to segment and quantify these vessels, their geometry, vessel wall structure, functionality, and interrelationship. Detailed structural analysis of microvascular networks is essential for accurate evaluation of the distribution of physical forces, substrate delivery and tissue clearance of waste, as well as sex differences and consequences of intracranial networks remodeling under physiological and pathological conditions. This will create knowledge enabling a better understanding of the pathogenesis of vascular impairments under estrogen and sleep deprivation, identify common molecular mechanisms and the efficacy and effectiveness of different therapeutic treatments. Without the ability to construct total structural and functional blood/lymphatic vascular network maps from studies limited to individual tissue component parts, it is little wonder that translation from the molecular and cellular levels to the whole organ and system levels is deficient and hinders translational progress towards a comprehensive understanding of the pathophysiology associated with a range of neurological disorders. Detailed analysis of structural relationships of both blood and lymphatic circulation in the brain system will have a direct impact on our general understanding of vascular function in brain/meningeal communication, and the cause and resolution of numerous diseases resulting from intracranial vascular disorders including impact of sex hormone (estrogen) deprivation, sleep deprivation, migraines, stroke, multiple sclerosis, dural arterio-venous fistulae, intradural hygroma and hematoma, spontaneous cerebral spinal fluid leaks, and intradural aneurysms that can lead to the development of neurological and cognitive impairment, including Alzheimer's. Quantitative description of blood and lymphatic vessel network structures using image analytics and machine learning algorithms distributed as software tools will have broad applications to quantification of other thin complex curvilinear anatomical structures (i.e. nerves, neuronal circuits, neurons, and neuroglia). The new software for blood and vessel network measurement will enable translation of fundamental pathophysiological knowledge gained from this proposal towards the development and assessment of the effectiveness of treatments and therapeutic interventions to enhance health, lengthen life, and reduce illness and disability associated with a range of neurological disorders.",Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system,9712424,R01NS110915,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Aneurysm', 'Animals', 'Arteriovenous fistula', 'Blood', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Brain', 'Brain Mapping', 'Cardiovascular system', 'Cephalic', 'Cerebrospinal Fluid', 'Cerebrovascular Disorders', 'Chronic', 'Chronic Insomnia', 'Communication', 'Complex', 'Computer software', 'Cystic Lymphangioma', 'Detection', 'Development', 'Disease', 'Dura Mater', 'Dural Arteriovenous Fistulas', 'Effectiveness', 'Elements', 'Estrogens', 'Evaluation', 'Female', 'Functional disorder', 'Geometry', 'Gonadal Steroid Hormones', 'Health', 'Hematoma', 'Heterogeneity', 'Hybrids', 'Image', 'Image Analysis', 'Imaging Techniques', 'Impaired cognition', 'Impairment', 'Individual', 'Knowledge', 'Lead', 'Life', 'Link', 'Lymphatic', 'Lymphatic vessel', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Meningeal', 'Metabolism', 'Methods', 'Microscopy', 'Migraine', 'Modeling', 'Molecular', 'Morphology', 'Mosaicism', 'Multiple Sclerosis', 'Mus', 'Nerve', 'Neuraxis', 'Neuroglia', 'Neurologic', 'Neurons', 'Optical Coherence Tomography', 'Parietal', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Physiological', 'Positioning Attribute', 'Resolution', 'Route', 'Sex Differences', 'Shapes', 'Site', 'Sleep', 'Sleep Deprivation', 'Sleep Disorders', 'Sleep disturbances', 'Software Tools', 'Stroke', 'Structure', 'Subdural Hematoma', 'Subdural Hygroma', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Thinness', 'Tissues', 'Translations', 'Treatment Effectiveness', 'Vascular Diseases', 'Vascular remodeling', 'Vascular resistance', 'Venous', 'associated symptom', 'base', 'body system', 'cerebral microvasculature', 'cerebrovascular', 'clinically relevant', 'confocal imaging', 'deep learning', 'deprivation', 'disability', 'geometric structure', 'in vivo', 'lymphatic circulation', 'machine learning algorithm', 'male', 'microleakage', 'nervous system disorder', 'neuronal circuitry', 'noninvasive diagnosis', 'novel', 'response', 'sex', 'sleep pattern', 'solute', 'stem', 'submicron', 'tool', 'wasting']",NINDS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2019,540520,63611576,-0.014318657202621593
"Targeting Senescence for Biomarkers and Therapeutics Type 1 Diabetes is an organ-specific autoimmune disease characterized by hyperglycemia due to progressive loss of pancreatic beta cells. While there has been significant progress in understanding immune-mediated beta cell destruction, the role of beta cell dysfunction in the underlying etiology of T1D is less clear. We have discovered that pancreatic beta cells acquire a proinflammatory secretome reminiscent of SASP during T1D in mice and human. SASP beta cells can remodel the islet environment in a paracrine manner by promoting bystander senescence and immune surveillance. We have developed drugs that selectively eliminated SASP beta cells without altering the abundance of the major immune cell types involved in the disease. Significantly, elimination of SASP beta cells halted progression of beta cell destruction and was sufficient to prevent diabetes. In this proposal, we focus on human beta cells and characterize the non-cell autonomous effects of SASP on islet microenvironment and develop drugs that can selectively target human SASP beta cells. We utilize the secretory properties of SASP beta cells to identify biomarkers that can report on the efficacy of drug treatment and progression of the disease. Recent work from our laboratory has shown that beta cells acquire a proinflammatory secretome reminiscent of SASP during T1D and selective clearing of these cells prevented diabetes. In this proposal, we characterize the non-cell autonomous effects of senescent human beta cells on the islet microenvironment and develop senolytic compounds that can selectively target human SASP beta cells. We propose to identify biomarkers for assessing the efficacy of senolytic treatment and progression of the disease to pioneer new therapeutic approaches for T1D.",Targeting Senescence for Biomarkers and Therapeutics,9798318,R01DK121794,"['Address', 'Apoptosis', 'Autoimmune Diseases', 'Automobile Driving', 'BCL2 gene', 'Basement membrane', 'Beta Cell', 'Biological Markers', 'Blood specimen', 'Cells', 'Cellular Stress Response', 'Cellular biology', 'Characteristics', 'Chemicals', 'Chemotaxis', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Disease model', 'Dose-Limiting', 'Drug Design', 'Environment', 'Etiology', 'Extracellular Matrix', 'Family', 'Ferritin', 'Functional disorder', 'Generations', 'Human', 'Human Activities', 'Hyperglycemia', 'Immune', 'Immune response', 'Immunologic Surveillance', 'In Vitro', 'Inbred NOD Mice', 'Infiltration', 'Insulin-Dependent Diabetes Mellitus', 'Invaded', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Mediating', 'Morphology', 'Mus', 'Natural History', 'Organ', 'Organ Donor', 'Pathway interactions', 'Peripheral', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Pharmacotherapy', 'Phenotype', 'Property', 'Proteins', 'Reporting', 'Role', 'Sampling', 'Serum', 'Specificity', 'Structure', 'Structure of beta Cell of islet', 'Testing', 'Therapeutic', 'Thrombocytopenia', 'Tissues', 'Toxic effect', 'Translating', 'Transplantation', 'Work', 'biomarker discovery', 'cell type', 'clinically relevant', 'design', 'drug efficacy', 'experimental study', 'humanized mouse', 'in vitro Assay', 'in vivo', 'islet', 'lead optimization', 'learning strategy', 'member', 'migration', 'monocyte', 'mouse model', 'novel', 'novel therapeutic intervention', 'paracrine', 'preservation', 'prevent', 'repository', 'scaffold', 'screening', 'senescence', 'small molecule', 'tool', 'virtual']",NIDDK,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2019,550024,685608202,-0.021844987732307912
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,9739919,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Base Management', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistics', 'subchondral bone', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,588354,641965656,0.004054461492287791
"Predicting tuberculosis outcomes using genotypic and biomarker signatures PROJECT SUMMARY/ABSTRACT Tuberculosis (TB) is caused by an infectious pathogen, Mycobacterium tuberculosis (M.tb) in susceptible individuals, but we cannot yet classify or predict outcomes in those prone to pulmonary TB disease versus those prone to resistance. In part, this reflects knowledge gaps regarding genotypes that may increase susceptibility, and in validated disease correlates (e.g. serum of lung protein biomarkers) measured individually, or combined signatures. We address these knowledge gaps by using Diversity Outbred (DO) mice, a population with abundant genetic diversity and heterozygosity, like the human population. Also, like humans, a low dose M.tb infection of DO mice produces a spectrum of outcomes, from highly susceptible to highly resistant, and many intermediate outcomes. In this proposal, we use the DO population to: 1) Identify and test the capacity of genotypic (alleles and statistically significant loci) to predict outcomes such as diagnostic category (class); and 2) To identify and test lung and serum biomarker (protein) and granuloma signatures to determine diagnostic category (class); and 3) To identify and test serum biomarker (protein) signatures that can forecast disease onset, within a 3-week window before illness manifests clinically. The best performing signatures will be tested using samples from humans. Collectively, results from these studies will generate new translatable knowledge regarding correlates of pulmonary TB (useful for diagnostics), and genotypic and serum protein signatures (useful for prognostics). PROJECT NARRATIVE Mycobacterium tuberculosis (M.tb) causes tuberculosis (TB) in millions of susceptible humans each year. It is well known that humans respond variably to M.tb infection, yet we are unable to predict outcomes with accuracy. Here, we use the Diversity Outbred (DO) mouse population to identify and test genotypic, serum, and lung biomarker signatures to accurately predict outcomes. Findings are also validated in samples from humans.",Predicting tuberculosis outcomes using genotypic and biomarker signatures,9642291,R01HL145411,"['AIDS/HIV problem', 'Address', 'Adult', 'Aerosols', 'Alleles', 'Animal Model', 'Bacillus (bacterium)', 'Biological Markers', 'Blood', 'Categories', 'Classification', 'Clinical', 'Consensus', 'Data', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outcome', 'Dose', 'Genetic Variation', 'Genotype', 'Granuloma', 'Harvest', 'Heterozygote', 'Human', 'Image', 'Image Analysis', 'Inbred Strain', 'Individual', 'Infection', 'Intervention', 'Knowledge', 'Lung', 'Malaria', 'Malignant Neoplasms', 'Measures', 'Minority', 'Modeling', 'Morbidity - disease rate', 'Mus', 'Mycobacterium tuberculosis', 'Necrosis', 'Onset of illness', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Population', 'Predisposition', 'Process', 'Production', 'Proteins', 'Pulmonary Tuberculosis', 'Quantitative Trait Loci', 'Resistance', 'Sampling', 'Serum', 'Serum Proteins', 'Structure', 'Testing', 'Time', 'Training', 'Tuberculosis', 'Vehicle crash', 'base', 'human pathogen', 'improved', 'individual patient', 'learning algorithm', 'model development', 'novel diagnostics', 'novel marker', 'outcome forecast', 'outcome prediction', 'pathogen', 'predictive marker', 'predictive modeling', 'prognostic', 'protein biomarkers', 'public health intervention', 'response', 'supervised learning', 'survival outcome', 'tool', 'transmission process', 'tuberculosis diagnostics']",NHLBI,TUFTS UNIVERSITY BOSTON,R01,2019,617451,65064605,-0.020571104046835167
"An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis Project Summary  Improved methods for the bedside diagnosis and evaluation of neuromuscular disorders are needed. One technology that is finding increasing use for this purpose is electrical impedance myography (EIM). In EIM, a very weak, high frequency electrical current is passed through a muscle of interest and the resulting surface voltages are measured. Disease associated alterations in the composition and microstructural features of the muscle produce characteristic changes that can be used to help classify specific conditions and grade disease severity. To date, most studies using EIM analysis have utilized a fairly limited data set for disease assessment. While effective, this approach ignores a great deal of information locked within the impedance data, including those values that can assist in predicting specific muscle features (such as myofiber diameter) and the presence of pathological change (e.g., fat or connective tissue deposition). In addition, as it stands, the data set is challenging for the clinician to understand without a detailed knowledge of impedance theory. Myolex, Inc is a small business concern located in Boston, MA has as its main focus the development of EIM technologies for clinical use. Myolex recently completed a Phase 1 SBIR that demonstrated the potential capability of machine learning based classification algorithms to effectively discriminate healthy muscle from diseased and to discriminate one disease from another. In this proposed work, we will greatly advance this concept by embodying classification algorithms into a powerful new software suite for Myolex’s current EIM system, the mView. Our underlying hypothesis is that EIM data analysis can be automated to the point that classification systems can provide data on disease diagnosis as well as disease severity for improved ease-of-use. We propose to study this hypothesis via 2 specific aims. In Specific Aim 1, we will design a software suite capable of assisting with artifact-free data collection to be incorporated into our current EIM system, the mViewTM. Then using classification paradigms based on a prodigious amount of previous collected data, we will develop an automated data analysis tool to help provide data on disease category as well as microscopic features, muscle based on the impedance data alone using Microsoft’s Azure Cloud platform. In Specific Aim 2, we will test this developed software suite in a total of180 adult and pediatric neuromuscular disease patients and healthy participants evaluated at Ohio State University Wexner Medical Center (adults) and Boston Children’s Hospital (children). During this data collection period, the Ohio State and Boston Children’s researchers will have real- time access to Myolex staff to provide feedback and have questions/problems answered and addressed. The user interface will continue to be refined and classification algorithms improved. At the conclusion of this work, a new diagnostic tool will be developed for potential 510(k) FDA approval. It will serve as the basis for a continuously self-refining system as additional data sets are collected by end-users employing them in regular clinical use. Project Narrative  Electrical impedance myography (EIM) is a valuable technique to assist with the evaluation of a variety of conditions affecting nerve and muscle. However, to date, only simplistic EIM outcomes have been utilized to assess muscle condition. In this proposed work, we will develop a software platform using machine learning to be incorporated into current EIM technology to allow for automated diseased classification and characterization using the entire large EIM data set collected with each muscle measurement. This will serve as the basis for a new, powerful and convenient tool for neuromuscular diagnosis that will continue to advance over time.",An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis,9846955,R44NS113756,"['Address', 'Adult', 'Affect', 'Algorithmic Software', 'Amyotrophic Lateral Sclerosis', 'Area', 'Back Pain', 'Boston', 'Businesses', 'Caliber', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Classification', 'Clinical', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Set', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Duchenne muscular dystrophy', 'Effectiveness', 'Electrodes', 'Ensure', 'Evaluation', 'Fatty acid glycerol esters', 'Feedback', 'Fiber', 'Frequencies', 'Functional disorder', 'Health', 'Inclusion Body Myositis', 'Individual', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Medical Technology', 'Medical center', 'Methods', 'Microscopic', 'Morphologic artifacts', 'Muscle', 'Muscular Dystrophies', 'Myography', 'Myopathy', 'Myositis', 'Nerve', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Ohio', 'Outcome', 'Participant', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Provider', 'Radiculopathy', 'Research Personnel', 'Role', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Work', 'base', 'classification algorithm', 'cloud based', 'cloud platform', 'commercialization', 'data acquisition', 'design', 'diagnosis evaluation', 'disease classification', 'disease diagnosis', 'electric impedance', 'improved', 'indexing', 'interest', 'machine learning algorithm', 'method development', 'nerve injury', 'neuromuscular', 'novel diagnostics', 'pediatric patients', 'physical therapist', 'prototype', 'sarcopenia', 'software development', 'success', 'theories', 'tool', 'usability', 'user friendly software', 'user-friendly', 'voltage']",NINDS,"MYOLEX, INC.",R44,2019,621318,869698,0.0034304829883875514
"Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors Project Summary Scientific understanding of adaptive immune receptors (i.e. antibodies and T cell receptors) has the potential to revolutionize prophylaxis, diagnosis, and treatment of disease. High‐throughput DNA sequencing and functional experiments have now brought the study of adaptive immune receptors into the big‐data era. To realize this potential of these data they must be matched with appropriately powerful analytical techniques. Existing probabilistic and mechanistic models are insufficient to capture the complexities of these data, while a naïve application of machine learning cannot leverage our profound existing knowledge of the immune system. The goal of this project is to blend deep learning with mechanistic modeling in order to predict and understand the evolution and function of adaptive immune receptors. Aim 1: Develop generative models of immune receptor sequences that capture the complexity of real adaptive immune receptor repertoires. These will combine deep learning along with our knowledge of VDJ recombination, and provide a rigorous platform for detailed repertoire comparison. Aim 2: Develop quantitative mechanistic models of antibody somatic hypermutation that incorporate the underlying biochemical processes. Estimate intractable likelihoods using deep learning to infer important latent variables, and validate models using knock‐out experiments in cell lines. Aim 3: Develop hybrid deep learning models to predict binding properties from sequence data, combining large experimentally‐derived binding data with even larger sets of immune sequences from human immune memory samples. Incorporate structural information via 3D convolution or distance‐based penalties. These tools will reveal the full power of immune repertoire data for medical applications. We will obtain more rigorous comparisons of repertoires via their distribution in a relevant space. These will reveal the effects of immune perturbations such as vaccination and disease, allowing us to pick out sequences that are impacted by these perturbations. We will have a greater quantitative understanding of somatic hypermutation in vivo, and statistical models that appropriately capture long‐range effects of collections of mutations. We will also have algorithms that will be able to combine repertoire data and sparse binding data to predict binding properties. Put together, these advances will enable rational vaccine design, treatment for autoimmune disease, and identification of T cells that are promising candidates for cancer immunotherapy. Project Narrative Adaptive immune receptors (i.e. antibodies and T cell receptors) enable our body to fight off disease, “remember” pathogens, and train the immune system through vaccination. Immunologists have learned via high‐throughput sequencing that adaptive immune receptors have a truly remarkable diversity. In this proposal, we develop machine‐learning methods for these sequence data, which will allow us to predict the maturation, statistical distribution, and binding properties of adaptive immune receptors, and thus to better design vaccinations, autoimmune disease treatment, and immunotherapy treatment for cancer.",Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors,9800752,R01AI146028,"['3-Dimensional', 'Algorithms', 'Animal Model', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Autoimmune Diseases', 'Automobile Driving', 'Big Data', 'Binding', 'Biochemical', 'Biochemical Process', 'Categories', 'Cell Line', 'Characteristics', 'Collection', 'Complement', 'Complex', 'Data', 'Data Set', 'Dependence', 'Diagnosis', 'Disease', 'Entropy', 'Evolution', 'Exposure to', 'Foundations', 'Gene Conversion', 'Generations', 'Goals', 'High-Throughput DNA Sequencing', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Immune', 'Immune response', 'Immune system', 'Immunoglobulin Somatic Hypermutation', 'Immunologic Memory', 'Immunologic Receptors', 'Immunological Models', 'Immunologics', 'Immunologist', 'Immunology', 'Immunotherapy', 'In Vitro', 'Individual', 'Knock-out', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Pathway interactions', 'Population', 'Procedures', 'Process', 'Property', 'Prophylactic treatment', 'Resolution', 'Sampling', 'Science', 'Statistical Distributions', 'Statistical Methods', 'Statistical Models', 'Structure', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'V(D)J Recombination', 'Vaccination', 'Vaccine Design', 'Vaccines', 'Validation', 'Work', 'analytical tool', 'base', 'biochemical model', 'cancer immunotherapy', 'cancer therapy', 'deep learning', 'deep neural network', 'deep sequencing', 'design', 'experimental study', 'fighting', 'functional group', 'in vivo', 'insertion/deletion mutation', 'learning strategy', 'markov model', 'pathogen', 'progenitor', 'receptor', 'repaired', 'response', 'success', 'three dimensional structure', 'tool']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,632498,758431960,-0.02168773040878217
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,9713512,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Catalogs', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2019,647706,560644462,-0.0047938901387048274
"PREMIERE: A PREdictive Model Index and Exchange REpository The confluence of new machine learning (ML) data-driven approaches; increased computational power; and access to the wealth of electronic health records (EHRs) and other emergent types of data (e.g., omics, imaging, mHealth) are accelerating the development of biomedical predictive models. Such models range from traditional statistical approaches (e.g., regression) through to more advanced deep learning techniques (e.g., convolutional neural networks, CNNs), and span different tasks (e.g., biomarker/pathway discovery, diagnostic, prognostic). Two issues have become evident: 1) as there are no comprehensive standards to support the dissemination of these models, scientific reproducibility is problematic, given challenges in interpretation and implementation; and 2) as new models are put forth, methods to assess differences in performance, as well as insights into external validity (i.e., transportability), are necessary. Tools moving beyond the sharing of data and model “executables” are needed, capturing the (meta)data necessary to fully reproduce a model and its evaluation. The objective of this R01 is the development of an informatics standard supporting the requisite information for scientific reproducibility for statistical and ML-based biomedical predictive models; from this foundation, we then develop new computational approaches to compare models' performance. We begin by extending the current Predictive Model Markup Language (PMML) standard to fully characterize biomedical datasets and harmonize variable definitions; to elucidate the algorithms involved in model creation (e.g., data preprocessing, parameter estimation); and to explain the validation methodology. Importantly, models in this PMML format will become findable, accessible, interoperable, and reusable (i.e., following FAIR principles). We then propose novel meth- ods to compare and contrast predictive models, assessing transportability across datasets. While metrics exist for comparing models (e.g., c-statistics, calibration), often the required case-level information is not available to calculate these measures. We thus introduce an approach to simulate cases based on a model's reported da- taset statistics, enabling such calculations. Different levels of transportability are then assigned to the metrics, determining the extent to which a selected model is applicable to a given population/cohort (i.e., helping answer the question, can I use this published model with my own data?). We tie these efforts together in our proposed framework, the PREdictive Model Index & Exchange REpository (PREMIERE). We will develop an online portal and repository for model sharing around PREMIERE, and our efforts will include fostering a community of users to guide its development through workshops, model-thons, and other activities. To demonstrate these efforts, we will bootstrap PREMIERE with predictive models from a targeted domain (risk assessment in imaging-based lung cancer screening). Our efforts to evaluate these developments will engage a range of stakeholders (model developers, users) to inform the completeness of our standard; and biostatisticians and clinical experts to guide assessment of model transportability. PROGRAM NARRATIVE With growing access to information contained in the electronic health record and other data sources, the appli- cation of statistical and machine learning methods are generating more biomedical predictive models. However, there are significant challenges to reproducing these models for purposes of comparison and application in new environments/populations. This project develops informatics standards to facilitate the sharing and reproducibil- ity of these models, enabling a suite of comparative methods to evaluate model transportability.",PREMIERE: A PREdictive Model Index and Exchange REpository,9712304,R01EB027650,"['Access to Information', 'Address', 'Algorithms', 'Area', 'Attention', 'Bayesian Network', 'Big Data', 'Biological Markers', 'Calibration', 'Characteristics', 'Clinical', 'Communities', 'Computational Biology', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Decision Making', 'Decision Trees', 'Dermatology', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Ecosystem', 'Educational workshop', 'Electronic Health Record', 'Environment', 'Evaluation', 'FAIR principles', 'Fostering', 'Foundations', 'Goals', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Language', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Medical', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Ophthalmology', 'Pathway interactions', 'Performance', 'Population', 'Publications', 'Publishing', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Reporting', 'Reproducibility', 'Reproduction', 'Research Personnel', 'Risk Assessment', 'Source', 'Techniques', 'Testing', 'Training', 'Validation', 'Variant', 'Work', 'base', 'bioimaging', 'biomarker discovery', 'case-based', 'cohort', 'collaborative environment', 'comparative', 'computer aided detection', 'convolutional neural network', 'data sharing', 'deep learning', 'design', 'experience', 'indexing', 'innovation', 'insight', 'interest', 'interoperability', 'learning network', 'learning strategy', 'lung basal segment', 'lung cancer screening', 'mHealth', 'model development', 'novel', 'novel strategies', 'predictive modeling', 'prognostic', 'repository', 'software repository', 'statistics', 'stem', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2019,657823,673201228,-0.004168644364665592
"Accelerating phage evolution and tools via synthetic biology and machine learning Summary Phages, which are the naturally evolved predators of bacteria, may hold the key to combating bacterial pathogens, including the looming threat of multidrug resistant bacteria. Phages are viruses which while harmless to humans and have been successfully engineered as tools to separate, concentrate, and detect their bacterial hosts. Additionally, phages have been used as therapeutic agents to treat patients infected with pathogens resistant to known antibiotics. While the potential benefits of phages are numerous, certain limitations must be addressed in order to fully employ them. The central hypothesis of this proposal is that both top-down and bottom-up approaches can be utilized to design and synthesize novel phages, through a combination of synthetic biology and machine learning. This will result in phage-based tools with increased functionality and customizable host ranges. The rationale for the proposed research is that as the threat of bacterial infections including those with multi-drug resistance continues to grow, phages, which have evolved to efficiently recognize and kill bacteria, will become indispensable tools. Therefore, the ability to rapidly design and engineer new phages for biosensing and therapeutics will be a critical advantage to human health. The proposal contains three specific aims which are supported by preliminary data and cited literature. Aim 1: Site-directed conjugation for advanced phage-based biosensors and therapeutics. Under this aim, phages will be modified with alkyne-containing unnatural amino acids allowing their direct conjugation to 1) azide decorated magnetic nanoparticles, and 2) azide terminated polyethylene glycol. The modifications will allow the development of magnetic phages for bacteria separation and detection, and phages that are more effective therapeutics due to their ability to avoid a patient’s innate immune response, respectively. Aim 2: Decoding phage biorecognition elements using machine learning. In this aim, machine learning will be used to model the binding of phages and their bacterial hosts. The model will enable the prediction of host interactions as well as allow the design and synthesis of novel phage tail fibers which can target specific bacterial isolates. Aim 3: Repurposing phage biorecognition for a broader host ranges. Under the final aim, phage-binding proteins will be replaced with those known to recognize conserved regions of the bacterial LPS, resulting in a phage with a much broader host range. This approach is innovative because it uses top-down characterizations for bottom-up design and synthesis of novel phages. Traditional phage screening methods will be replaced with the rapid synthesis of phages, which are optimized for a particular bacterial isolate. Following the successful completion of the specific aims, the expected outcome is the design and synthesis of phages that can be used to target a selected group of bacteria within Enterobacteriaceae for advanced biosensing and therapeutics. A publically available computer model will allow rapid design of custom phage biorecognition elements which can be added to functionalized phages. These technologies will allow researchers to tip the scales of the co-evolutionary arms race between phage and bacteria. Narrative The project is relevant to public health because it accelerates the development of phage-based tools for the rapid detection of bacterial pathogens in human, food, and environmental samples, and the treatment of diseases from multidrug resistant bacteria by integrating machine learning and synthetic biology. Thus, it is specifically relevant to part of NIH's mission that pertains to the diagnosis, prevention, and cure of human diseases.",Accelerating phage evolution and tools via synthetic biology and machine learning,9714883,R01EB027895,"['Acinetobacter baumannii', 'Address', 'Alkynes', 'Amino Acid Sequence', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Azides', 'Bacteria', 'Bacterial Genome', 'Bacterial Infections', 'Bacteriophage T4', 'Bacteriophages', 'Binding', 'Binding Proteins', 'Biosensing Techniques', 'Biosensor', 'CRISPR/Cas technology', 'Capsid', 'Chemistry', 'Clinical', 'Computer Simulation', 'Consumption', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Drug resistance', 'Elements', 'Engineering', 'Enterobacteriaceae', 'Environment', 'Escherichia coli', 'Evolution', 'Family', 'Fiber', 'Food', 'Future', 'Genes', 'Genome', 'Goals', 'Health', 'Human', 'Infection', 'Innate Immune Response', 'Innate Immune System', 'Intervention', 'Life', 'Literature', 'Machine Learning', 'Magnetic nanoparticles', 'Magnetism', 'Methods', 'Mission', 'Modeling', 'Modification', 'Multi-Drug Resistance', 'Multidrug-resistant Acinetobacter', 'Multiple Bacterial Drug Resistance', 'Natural Immunity', 'Outcome', 'Patients', 'Phenotype', 'Polyethylene Glycols', 'Prevention', 'Process', 'Property', 'Public Health', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Site', 'Specificity', 'Surface', 'System', 'Tail', 'Technology', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Efficacy', 'United States National Institutes of Health', 'Viral', 'Virus', 'arm', 'base', 'combat', 'design', 'human disease', 'innovation', 'next generation', 'novel', 'pathogen', 'pathogenic bacteria', 'rapid detection', 'receptor', 'resistance mechanism', 'screening', 'synthetic biology', 'tool', 'unnatural amino acids']",NIBIB,CORNELL UNIVERSITY,R01,2019,666637,91477866,-0.02443623447690752
"Identifying individuals at risk of progression to active tuberculosis Project Summary Almost 2 billion people are infected with Mycobacterium tuberculosis (Mtb), the causative agent of tuberculosis (TB). Approximately 10% of these individuals will progress to active TB disease over their lifetimes, but there is currently no clinical test to distinguish those that will progress to active TB disease, from those that will not. If we are to realize the World Health Organization's (WHO) goal of a world free of TB by 2035, the massive reservoir of TB infection must be addressed with a cost-effective, ethical therapy for preventing progression, based on treating only those most likely to progress. A diagnostic test that can accurately predict the risk of progression is critical for treating these high-risk individuals and the eradication of TB. Our goal is to develop such an assay. Our central hypothesis is that five independent host immune biomarkers, combined into a single multimetric signature will predict progression from latent to active TB with at least 90% sensitivity and specificity. We will test this hypothesis and achieve our goal by implementing the following specific aims: Aim 1: Compile a comprehensive dataset of biomarkers in a prospective cohort of individuals who are at risk of progressing to active TB. Working with the Moldova Ministry of Health's National TB Program, we will enroll 3,685 close contacts of active TB cases. All participants will be followed for two years to determine who progresses to active TB. We expect to identify ≥ 140 progressors. We will assess three previously established blood-based predictors of active TB progression, and two novel assays. We will verify the performance of previously published biomarkers in this population to discriminate progressors from non-progressors and identify new candidate biomarkers using RNA-Seq of antigen stimulated PBMC and detection of Mtb-peptides by NanoDisk MS. Aim 2: Use a discovery set of samples to develop predictive models of progression to active TB. Using data from 140 progressors and 140 non-progressors from Aim 1 we will (1) Verify the performance of existing biomarkers, (2) Use a cross-validation to identify new candidate biomarkers, and (3) derive predictive models using logistic regression and machine learning methods to identify optimal biomarker signatures that best predict progression to active TB within 12 months. Aim 3: Verify the ability of the model to predict progression to active TB disease. Using the same approach as Aim 1, we will enroll a new set of 1,340 household contacts of active TB and identify at least 60 progressors and 60 matched non-progressors and verify clinically the sensitivity/specificity of our models and biosignatures (Aim 2) to predict progression to active disease. A combined host biomarker signature that can predict TB progression from a small blood volume will have significant impact on the WHO End TB Program. PROJECT NARRATIVE Almost 2 billion people are infected with Mycobacterium tuberculosis, the causative agent of tuberculosis (TB). Approximately 10% of these individuals will progress to active TB disease over their lifetimes, but there is currently no test to distinguish those that will progress from those that will not. We propose to develop a multimetric signature of host biomarkers that together will have a sensitivity and specificity of ≥ 90% for predicting progression to active TB in one year, a critical first step to developing cost-effective and ethical treatment plans in order to reach the World Health Organization goal of Ending TB by 2035.",Identifying individuals at risk of progression to active tuberculosis,9654700,R01AI137681,"['Address', 'Antigens', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Volume', 'Cells', 'Characteristics', 'Child', 'Clinical', 'Clinical Sensitivity', 'Data', 'Data Set', 'Detection', 'Diagnostic tests', 'Disease', 'Enrollment', 'Ethics', 'Event', 'Filtration', 'Flow Cytometry', 'Foundations', 'Freezing', 'Frequencies', 'Gender', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Goals', 'Health', 'Household', 'Immune', 'Immune response', 'Immunologic Markers', 'Individual', 'Interferons', 'Logistic Regressions', 'Lymphocyte', 'Machine Learning', 'Modeling', 'Moldova', 'Mycobacterium tuberculosis', 'Mycobacterium tuberculosis antigens', 'National Health Programs', 'Organizational Objectives', 'Outcomes Research', 'Participant', 'Patients', 'Peptide Fragments', 'Peptides', 'Performance', 'Peripheral Blood Mononuclear Cell', 'Plasma', 'Population', 'Procedures', 'Production', 'Prospective cohort', 'Proteins', 'Publications', 'Publishing', 'RNA', 'Research Personnel', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Specificity', 'T cell response', 'T-Lymphocyte', 'Testing', 'Tuberculosis', 'Validation', 'World Health Organization', 'age group', 'base', 'biobank', 'biomarker performance', 'biosignature', 'blood-based biomarker', 'candidate marker', 'classification algorithm', 'clinical Diagnosis', 'cohort', 'cost effective', 'deep neural network', 'enzyme linked immunospot assay', 'falls', 'follow-up', 'high risk', 'indexing', 'innovation', 'learning strategy', 'monocyte', 'nanodisk', 'novel', 'novel diagnostics', 'predictive modeling', 'predictive test', 'prevent', 'programs', 'random forest', 'research clinical testing', 'transcriptome sequencing', 'transmission process', 'treatment planning']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,715056,524978793,0.01651517394111411
"Scalable platform for optimizing human cardiac tissue engineering via optical pacing and on-demand oxygenation PROJECT SUMMARY Induced pluripotent stem cell-derived cardiomyocytes (iPS-CM) are emerging as an invaluable in vitro human experimental platform for disease modeling, drug discovery, cardiotoxicity screening, gene editing and functional genomics. For the first time, cardiac electrophysiology has access to a scalable human experimental model, which, currently, offers the only path to personalized (cardiac) medicine as patient-derived iPS-CMs can be generated on a progressively faster time scale. The clear potential of this technology motivates efforts to address the main criticisms facing iPS-CMs, namely the need for further maturation and reduction of phenotype heterogeneity. As multiple approaches are being pursued to improve iPS-CM maturation and to approximate the functionality of the adult human myocardium, we argue that combinatorial optimizations necessitate new high-throughput (HT) technology and automation. The overall goal of this project is to develop and validate a scalable platform for optimizing cardiac tissue engineering via chronic reconfigurable optical pacing and “on-demand” oxygenation for gaining mechanistic insights into cardiac metabolism and electrophysiology, a platform we call ChROME. Chronic electrical stimulation is a viable lead to iPS-CM maturation, yet it has remained under-explored, specifically as related to the role of mass transport and oxygenation during such stimulation. Leveraging our expertise in the theoretical and experimental use of optogenetic tools for cardiac applications (Entcheva) and automation (Kostov, Li, Entcheva, Kay), we propose to design and validate the first-generation HT-ChROME platform, that will integrate continuous monitoring of key physiological parameters. Our team’s expertise in optical oxygen sensing (Kostov), in-house manufacturing of “on-demand” oxygenation nanocarriers (perfluorocarbons, PFC) (Kay) and metabolic characterization (Kay, Beard) will be applied to address the increased metabolic demands during stimulation. The ability to quantify “functional maturation” by relevant measures (voltage, calcium, contraction) in a high-throughput manner (Entcheva) in 2D and 3D cardiac tissue constructs (Vunjak-Novakovic), using our automated platform OptoDyCE (all-optical dynamic cardiac electrophysiology) is critical in this undertaking. Employing these HT tools and other imaging and omics modalities (Popratiloff, Horvath), we will elucidate the spectrum of responses triggered by chronic stimulation of iPS-CMs: beneficial/maturation effects vs. pathological overload effects, depending on load and oxygenation conditions. The proposed HT-ChROME platform represents a critical step in resolving issues impeding progress with iPS-CMs to accelerate their wide-spread adoption in basic and translational applications. The obtained large-scale data will inform a new generation of biophysical models linking human cardiac metabolism and electrophysiology. PROJECT NARRATIVE Recent advances in stem-cell technology enable patient-derived cells to be turned into functional heart cells, and this is an exciting direction towards personalized medicine; yet, there are many challenges in optimizing these cardiomyocytes to better mimic the real heart – a problem that the proposed engineering tools will help resolve.",Scalable platform for optimizing human cardiac tissue engineering via optical pacing and on-demand oxygenation,9687111,R01HL144157,"['3-Dimensional', 'Address', 'Adoption', 'Adult', 'Affect', 'Automation', 'Biological', 'Calcium', 'Cardiac', 'Cardiac Electrophysiologic Techniques', 'Cardiac Myocytes', 'Cardiotoxicity', 'Cells', 'Chronic', 'Combinatorial Optimization', 'Data', 'Disease model', 'Electric Stimulation', 'Engineering', 'Event', 'Experimental Models', 'Fluorocarbons', 'Frequencies', 'Future', 'Generations', 'Genes', 'Goals', 'Heart', 'Heterogeneity', 'Hip region structure', 'Human', 'Human Engineering', 'Image', 'In Vitro', 'Incubators', 'Lead', 'Light', 'Link', 'Longitudinal Studies', 'Measures', 'Mechanics', 'Mediating', 'Medicine', 'Metabolic', 'Metabolism', 'Mitochondria', 'Modality', 'Modeling', 'Monitor', 'Myocardium', 'NADH', 'Optics', 'Oxygen', 'Oxygen Consumption', 'Pathologic', 'Patients', 'Phenotype', 'Physiologic pulse', 'Physiological', 'Regression Analysis', 'Role', 'Site', 'Technology', 'Testing', 'Time', 'Tissue Engineering', 'Tissues', 'Transcriptional Regulation', 'Viral', 'Work', 'biophysical model', 'cardiac tissue engineering', 'design', 'drug discovery', 'functional genomics', 'heart cell', 'heart metabolism', 'high throughput technology', 'improved', 'induced pluripotent stem cell', 'insight', 'machine learning algorithm', 'nanocarrier', 'optogenetics', 'personalized medicine', 'programs', 'response', 'screening', 'side effect', 'stem cell technology', 'tool', 'transcriptomics', 'voltage']",NHLBI,GEORGE WASHINGTON UNIVERSITY,R01,2019,728876,86807134,-0.020157812777274058
"Precision immunoprofiling to reveal diagnostic biomarkers of latent TB infection PROJECT SUMMARY  Tuberculosis (TB) is among the leading causes of mortality worldwide with an estimated 2 billion individuals currently infected. Latent tuberculosis infection (LTBI) is the most common form of TB infection affecting 13 million Americans. While many with LTBI remain asymptomatic, an estimated 10% of immunocompetent patients with LTBI will reactivate to active TB, and will become infectious. LTBI is treatable with a prolonged antibiotic treatment; however, potential side effects motivate the development of new diagnostic approaches that can identify with high specificity patients at the highest risk of reactivation, for who therapy would be most beneficial.  The tuberculin skin test (TST) and interferon-γ release assays (IGRAs) are commonly used for TB and LTBI screening. Both tests provide good measures of TB exposure; however, neither is effective at diagnosing LTBI (positive predictive values <5%). Moreover, neither provide any prognostic stratification based upon reactivation risk. Both the TST and IGRAs probe immunological memory to TB-related antigen challenges and we hypothesize that a more nuanced and personalized approach to monitoring immune responses to both TB- specific and non-specific antigens might reveal new approaches to LTBI diagnosis and patient stratification.  Enabling a new, individualized approach to LTBI diagnostics, we propose to combine high throughput, multiplexed inflammatory biomarker detection strategies and powerful bioinformatics tools that allow for the identification of previously obscured multi-marker diagnostic signatures of LTBI status and reactivation risk. Silicon photonic microring resonators are an enabling technology for biomarker analysis due to their intrinsic scalability and multiplexing capabilities. Applied to the detection of cytokine panels, this technology supports the rapid immune profiling of individual samples under both TB-specific and non-specific antigen stimulation conditions. Machine learning algorithms will be utilized to analyze the resulting dense data streams to facilitate selection of key diagnostic signatures forming the basis for predictive model development and deployment. This powerful analytical combination is supplemented by deep expertise in clinical diagnosis and treatment of TB and LTBI, and an enabling collaboration and connection to subjects from an international location with high TB burden and exposure in a healthcare worker population subjected to regularly-scheduled and repeated LTBI screening.  The resulting diagnostic workflow and machine learning feature selection approaches will reveal multiplexed biomarker signatures that have strong positive predictive correlation with LTBI status (+ or -). This approach will also further stratify LTBI+ subjects on the basis of reactivation potential, thus providing a fundamentally new approach to identifying subjects that are most likely to benefit from therapeutic intervention. The end result of this project will be a new precision medicine-based diagnostic strategy that is vastly superior to the current state-of-the-art and offers the potential to transform current clinical practice. PROJECT NARRATIVE Tuberculosis (TB) affects an estimated one third of the world’s population and an asymptomatic latent state of tuberculosis infection (LTBI) is extremely common. Unfortunately, there are not any good clinical tests that can definitely diagnose LTBI, making it difficult to identify patients that should be treated to prevent reactivation to active TB, which is infectious. We will integrate cutting edge measurement technologies and machine learning bioinformatic approaches to identify and test multiplexed biomarker signatures that will transform clinical TB management by enabling personalized diagnosis of LTBI and the stratification of individuals with the highest potential for reactivation.",Precision immunoprofiling to reveal diagnostic biomarkers of latent TB infection,9819449,R01AI141591,"['Affect', 'Algorithms', 'American', 'Antibiotic Therapy', 'Antibiotics', 'Antigens', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Clinical', 'Clinical Treatment', 'Collaborations', 'Complex', 'Cytokine Network Pathway', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Management', 'Eligibility Determination', 'Generations', 'Goals', 'Gold', 'Health Personnel', 'Immune', 'Immune response', 'Immunocompetent', 'Immunologic Markers', 'Immunologic Memory', 'Immunologic Monitoring', 'Individual', 'Infection', 'Inflammatory', 'Informatics', 'Interferons', 'International', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Modeling', 'Patients', 'Peripheral', 'Peripheral Blood Mononuclear Cell', 'Plasma', 'Population', 'Predictive Value', 'Prevention strategy', 'Regimen', 'Residual state', 'Risk', 'Sampling', 'Schedule', 'Silicon', 'Specificity', 'Stratification', 'Stream', 'Technology', 'Testing', 'Therapeutic Intervention', 'Translations', 'Tuberculin Test', 'Tuberculosis', 'Whole Blood', 'antigen challenge', 'base', 'bioinformatics tool', 'clinical Diagnosis', 'clinical practice', 'cytokine', 'diagnostic accuracy', 'diagnostic biomarker', 'high risk', 'immune function', 'immunoregulation', 'improved', 'individual variation', 'latent infection', 'machine learning algorithm', 'model development', 'monocyte', 'mortality', 'novel diagnostics', 'novel strategies', 'patient stratification', 'personalized approach', 'personalized diagnostics', 'photonics', 'precision medicine', 'predictive marker', 'predictive modeling', 'prevent', 'prognostic', 'prospective', 'response', 'screening', 'side effect', 'targeted treatment', 'tool', 'treatment strategy', 'tuberculosis treatment']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,754111,641965656,0.02073798573989649
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9754269,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Anti-Tumor Necrosis Factor Therapy', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Big Data', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Individual', 'Injury', 'Institution', 'Intuition', 'Leukocyte Chemotaxis', 'Lymphocyte Immunophenotypings', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Myocardial', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Sampling', 'Series', 'Stains', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'analysis pipeline', 'base', 'clinical diagnostics', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'education resources', 'human disease', 'improved', 'inquiry-based learning', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2019,794562,3808719,0.01589493525220291
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,9737676,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Quality', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2019,804907,593605914,-0.006333877160946754
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,9724344,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Streptococcus pyogenes', 'Streptococcus vaccine', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2019,872121,46216755,-0.023479316341423508
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,9748417,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'machine learning algorithm', 'multidisciplinary', 'pathogen', 'point of care', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,991540,51931732,0.004959573977544058
"Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria PROJECT SUMMARY Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacterial infections are increasing in incidence and novel antibiotics are urgently needed to combat this growing threat to public health. A major roadblock to the development of novel antibiotics is our poor understanding of the structural features of small molecules that correlate with bacterial penetration and efflux. As a result, while potent biochemical inhibitors can often be identified for new targets, developing them into compounds with whole-cell antibacterial activity has proven challenging. To address this critical problem, we propose herein a comprehensive, multidisciplinary approach to develop quantitative models to predict small-molecule penetration and efflux in Gram-negative bacteria. We have pioneered a general platform for systematic, quantitative evaluation of small-molecule accumulation in bacteria, using label-free LC-MS/MS detection and multivariate cheminformatic analysis. We have also developed unique isogenic strain sets of wild-type, hyperporinated, efflux-knockout, and doubly-compromised E. coli, P. aeruginosa, and A. baumannii that allow us to dissect the individual contributions of outer/inner membrane penetration and active efflux to net accumulation, using a kinetic model that accurately recapitulates available experimental data. Moreover, we have developed machine learning and neural network approaches to QSAR (quantitative structure–activity relationship) modeling of pharmacological properties that will now be used to develop predictive cheminformatic models for Gram-negative accumulation, penetration, and efflux. This project will be carried out by a multidisciplinary SPEAR-GN Project Team (Small-molecule Penetration & Efflux in Antibiotic-Resistant Gram-Negatives, “speargun”) involving the labs of Derek Tan (MSK, PI), Helen Zgurskaya (OU, PI), Bradley Sherborne (Merck, Lead Collaborator), Valentin Rybenkov (OU, Co-I), Adam Duerfeldt (OU, Co-I), Carl Balibar (Merck, Collaborator), and David McLaren (Merck, Collaborator), comprising extensive combined expertise in organic and diversity-oriented synthesis, biochemistry, microbiology, high- throughput screening, mass spectrometry, biophysical modeling, cheminformatics, and medicinal chemistry. Herein, we will design and synthesize chemical libraries with diverse structural and physicochemical properties; analyze their accumulation in the isogenic strain sets in both high-throughput and high-density assay formats; extract kinetic parameters for penetration and efflux from the resulting experimental datasets; develop and validate robust QSAR models for accumulation, penetration, and efflux; and demonstrate the utility of these models in medicinal chemistry campaigns to develop novel Gram-negative antibiotics against three targets. This project will provide a major advance in the field of antibacterial drug discovery, providing powerful enabling tools to the scientific community to address this major threat to public health. PUBLIC HEALTH RELEVANCE Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacteria pose a growing threat to public health in the U.S. and globally. A major obstacle to the development of new antibiotics to combat such infections is our poor understanding of the chemical requirements for small molecules to enter Gram-negative cells and to avoid ejection by efflux pumps. The proposed comprehensive, multidisciplinary research program aims to develop predictive computational tools to identify such molecules by carrying out large-scale, quantitative analyses of the accumulation of diverse small molecules in Gram-negative bacteria. These tools will then enable medicinal chemistry campaigns to develop novel antibiotics.",Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria,9761970,R01AI136795,"['Acinetobacter baumannii', 'Address', 'Algorithmic Software', 'Anti-Bacterial Agents', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Bacteria', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Availability', 'Cells', 'Chemicals', 'Communities', 'Data', 'Data Set', 'Detection', 'Development', 'Effectiveness', 'Escherichia coli', 'Gram-Negative Bacteria', 'Gram-Negative Bacterial Infections', 'Human', 'Incidence', 'Individual', 'Infection', 'Interdisciplinary Study', 'Kinetics', 'Knock-out', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Membrane', 'Microbiology', 'Modeling', 'Oral', 'Partner in relationship', 'Penetration', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Property', 'Pseudomonas aeruginosa', 'Public Health', 'Quantitative Evaluations', 'Quantitative Structure-Activity Relationship', 'Role', 'Structure', 'Testing', 'Variant', 'analog', 'base', 'biophysical model', 'cell envelope', 'cheminformatics', 'combat', 'computerized tools', 'density', 'design', 'drug discovery', 'efflux pump', 'high throughput screening', 'improved', 'inhibitor/antagonist', 'interdisciplinary approach', 'lead optimization', 'learning network', 'multidisciplinary', 'neural network', 'novel', 'off-label use', 'predictive modeling', 'programs', 'prospective', 'public health relevance', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool']",NIAID,SLOAN-KETTERING INST CAN RESEARCH,R01,2019,1212566,185946435,-0.01827211596627451
"New approaches to optimizing the application and measuring the impact of community-based tuberculosis interventions PROJECT SUMMARY Globally, tuberculosis (TB) kills more people each year than any other infectious disease, but around 40% of TB cases go undiagnosed each year. This leads to continued transmission and a slow rate of decline in global TB incidence. Community-based TB screening interventions are one strategy for increasing the early diagnosis and treatment of people with tuberculosis. Knowledge is lacking on when community-based TB screening interventions are likely to be fruitful and on the impact of these interventions on TB transmission. This study addresses the first of these knowledge gaps by identifying epidemiologic signals that predict high yields for community-based TB screening, and by assessing barriers to optimal implementation of community-based screening programs. It addresses the second knowledge gap by measuring transmission within communities that receive TB screening interventions, and by identifying potential sites of transmission both within and outside the community. Aim 1 applies random forest regression to data from a community-based screening program to create a decision tree that uses information about past TB patients to predict whether a commnity is likely to have high levels of undiagnosed TB in the present. Aim 2 is a mixed-methods study focusing on people who were missed by TB screening interventions, which will help understand the barriers to successful implementation. Aim 3 uses whole-genome sequencing of clinical isolates to determine the proportion of TB cases attributable to recent transmission within intervention communities, using this metric to evaluate the impact of screening interventions on transmission. Aim 4 uses social network analysis to identify sites of transmission within and outside intervention communities. The long-term goal of this work is to reduce global TB morbidity through improved community-based screening. PROJECT NARRATIVE This study seeks to understand (a) when community-based tuberculosis screening interventions are likely to be fruitful and (b) the impact these interventions have on tuberculosis transmission. This knowledge will improve community-based tuberculosis screening interventions and thus contribute to the reduction of global tuberculosis morbidity.",New approaches to optimizing the application and measuring the impact of community-based tuberculosis interventions,9781984,DP2MD015102,"['Address', 'Communicable Diseases', 'Communities', 'Data', 'Decision Trees', 'Early Diagnosis', 'Early treatment', 'Epidemiology', 'Goals', 'Incidence', 'Intervention', 'Knowledge', 'Measures', 'Methods', 'Morbidity - disease rate', 'Pathway Analysis', 'Patients', 'Signal Transduction', 'Site', 'Social Network', 'Tuberculosis', 'Work', 'base', 'clinical sequencing', 'community intervention', 'improved', 'novel strategies', 'random forest', 'screening', 'screening program', 'transmission process', 'whole genome']",NIMHD,BRIGHAM AND WOMEN'S HOSPITAL,DP2,2019,2353629,327644200,-0.006618751001947524
"IGF::OT::IGF  BIOINFORMATICS SUPPORT FOR THE NIEHS IN DIR & DNTP The purpose of this contract is to provide bioinformatic support to researchers in the Divisions of National Toxicology Program (DNTP) and Intramural Research (DIR) at the National Institute of Environmental Health Sciences (NIEHS). NIEHS researchers conduct studies that produce large amounts of data, varying in size and complexity. Fields of scientific study are diverse and include toxicology, genomics, transcriptomics, high throughput screening (HTS) data and data extraction from diverse text resources. The variety and complexity of NIEHS scientific studies dictates the need for innovative analytical techniques and the development of new software tools. Bioinformatic data analyses are required to support accurate and precise interpretation of study results. Specific bioinformatics needs include data analysis, data mining, creating bioinformatics pipelines for gene expression and pathway analysis and computational support for the vast amount of data collected through studies conducted at NIEHS and NIEHS contract laboratories. n/a",IGF::OT::IGF  BIOINFORMATICS SUPPORT FOR THE NIEHS IN DIR & DNTP,9915697,73201700001C,"['Artificial Intelligence', 'Bioinformatics', 'Biological Assay', 'ChIP-seq', 'Chemical Exposure', 'Chemicals', 'Contractor', 'Contracts', 'DNA Methylation', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Epigenetic Process', 'Evaluation', 'Exons', 'Gene Expression', 'Genes', 'Genomics', 'Informatics', 'Intramural Research', 'Knowledge', 'Laboratories', 'Literature', 'Measures', 'Mining', 'National Institute of Environmental Health Sciences', 'National Toxicology Program', 'Output', 'Pathway Analysis', 'Peer Review', 'Privatization', 'Programming Languages', 'Proteomics', 'Publications', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scientific Evaluation', 'Scientist', 'Series', 'Software Tools', 'Specific qualifier value', 'Technology', 'Text', 'Toxicogenomics', 'Toxicology', 'analysis pipeline', 'bioinformatics tool', 'bisulfite sequencing', 'cheminformatics', 'computational intelligence', 'data integration', 'data mining', 'differential expression', 'high throughput screening', 'innovation', 'meetings', 'metabolomics', 'method development', 'next generation sequencing', 'physical property', 'programs', 'screening', 'technique development', 'transcriptomics', 'whole genome']",NIEHS,"SCIOME, LLC",N01,2019,2464037,2510992,0.0007159653041694175
"Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)? PROJECT SUMMARY The North Coast Conference on Precision Medicine is a national annual mid-sized conference series held in Cleveland, Ohio. The conference series aims to serve as a venue for the continuing education and exchange of scientific ideas related to the rapidly evolving and highly interdisciplinary landscape that is precision medicine research. The topics for each conference coincide with the national conversation and research agenda set by national research programs focused on precision medicine. The 2018 conference is a symposium that will focus on issues related to return of genomic results both in clinical and research settings with an emphasis on diverse populations. The conference will be organized as a traditional format with invited speakers from among national experts for topics ranging from issues returning research results to culturally diverse participants and family members, inclusion of diverse patient and participant populations in the Clinical Sequencing Evidence- Generating Research (CSER) consortium and the Trans-Omics for Precision Medicine (TOPMed) Program, pharmacogenomics-guided dosing and race/ethnicity, strategies used to return results, among others. 2019 and beyond conference topics are being considered from previous symposia attendees and trends in precision medicine research. Odd-numbered year conferences include a workshop component that has previously covered outcome and exposure variable extraction from electronic health records. Future workshop topics being considered include integration of multiple ‘omics, drug response in different populations, pharmacogenomics clinical implementation, precision medicine in cancer, data sharing and informed consent, and the use of apps for recruitment, diagnosis, follow-up, and treatment. Our second major objective of this conference series is the promotion of diversity in the biomedical workforce. It is well-known that the pipeline from training to full professor for women in biomedical research is leaky whereas the pipeline for under-represented minorities is practically non-existent. Drawing from national and local sources, we vet women and under-represented minorities for every invited speaker opportunity, thereby providing valuable career currency and networking opportunities. We will also encourage women and under-represented minorities, particularly at the trainee level, to attend and participate in this conference series to spur interest in pursuing precision medicine research as a career. Overall, the North Coast Conference on Precision Medicine series is a valuable addition to the national conference landscape, and with its unique location and low cost to participants, will serve as an important educational opportunity as precision medicine research accelerates in earnest. PROJECT NARRATIVE The North Coast Conference on Precision Medicine is a yearly fall conference series in Cleveland, Ohio designed as a continuing education forum in the burgeoning area of precision medicine research. The conference brings together national experts on a host of topics ranging from bioethics to bioinformatics to biomedical informatics to speak and lead workshops on timely challenges posed in translating complex genomic and health data into clinical practice. The conference series also serves to promote diversity in the biomedical workforce. This year’s symposium will focus issues related to return of genomic results in both clinical and research settings with an emphasis on diverse populations.",Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)?,9612854,R13HG010286,"['Academic Medical Centers', 'Acceleration', 'African American', 'Area', 'Back', 'Big Data', 'Bioethics', 'Bioinformatics', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Computational Biology', 'Computer Simulation', 'Continuing Education', 'Custom', 'Data', 'Databases', 'Diagnosis', 'Dose', 'Educational workshop', 'Electronic Health Record', 'Ensure', 'Ethnic Origin', 'Family member', 'Funding', 'Future', 'Generations', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidental Findings', 'Informed Consent', 'Institution', 'Knowledge', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mining', 'Names', 'Ohio', 'Outcome', 'PMI cohort', 'Participant', 'Pathogenicity', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Population Heterogeneity', 'Prevention', 'Process', 'Race', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Schedule', 'Science', 'Series', 'Source', 'Surveys', 'Technology', 'Time', 'Training', 'Trans-Omics for Precision Medicine', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Minority', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'Woman', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'clinical care', 'clinical implementation', 'clinical practice', 'clinical sequencing', 'clinically relevant', 'cost', 'cost effective', 'data sharing', 'design', 'falls', 'follow-up', 'forging', 'frontier', 'genome-wide', 'genomic data', 'health data', 'health disparity', 'health information technology', 'incentive program', 'individual patient', 'interest', 'medical specialties', 'multiple omics', 'patient population', 'point of care', 'posters', 'precision medicine', 'programs', 'recruit', 'response', 'science education', 'senior faculty', 'symposium', 'trend']",NHGRI,CASE WESTERN RESERVE UNIVERSITY,R13,2018,10000,197030888,-0.02298008683283107
"Innovative text-mining tools to accelerate citation screening: comparative efficiency and impact on conclusions Project Summary Systematic reviews (SRs) synthesize and critically assess bodies of evidence to produce a comprehensive unbiased assessment of what is known. As such, SRs are vital for evidence-based decision-making. However, given the pace of new research, the process of developing an SR remains too slow. One particularly time-consuming step in the process is citation screening, which requires manual review of thousands of abstracts to identify only a small number of relevant studies. Screening such large numbers of studies is necessary because systematic reviewers place a high priority on identifying all relevant studies to avoid bias. Innovative citation screening tools, which utilize text-mining and new sophisticated machine learning methods, represent one potential solution. Abstrackr (Brown University) and EPPI-Reviewer (University College London) are off- the-shelf, web-based citation screening tools designed to improve screening efficiency. Both programs utilize machine- learning techniques to semi-automate the screening process by modeling the probability that each citation will meet criteria for inclusion. This allows efficiency gains through screening prioritization and screening truncation. With screening prioritization, citations are organized for screening from highest to lowest likelihood of inclusion. This allows earlier retrieval of full-text articles and facilitates workflow planning. Organizing citations by likelihood of inclusion also allows reviewers the option of truncating the screening process when remaining citations fall below a certain threshold. While promising, existing studies have predominantly been performed by computer scientists testing individual tools or comparing different modeling algorithms (e.g., various classifiers). To date, no studies have performed a direct comparison of citation screening tools. Similarly, although automatically excluding citations that fall below particular thresholds could substantively improve efficiency, adoption has been low due to concerns that relevant studies could be missed. However, how often studies would be missed and how important such omissions would be remains unknown. To address these knowledge gaps, this project will (1) Compare screening efficiency for two citation-screening tools, Abstrackr and EPPI-reviewer, and (2) Characterize the potential impact of using thresholds to exclude low probability studies automatically. To address aim 1, using citations from 3 large and 6 small completed evidence reports, we will compare Abstrackr to EPPI-Reviewer for citation screening. Using screening prioritization, we will assess what proportion of articles must be screened to identify all included studies (e.g., to achieve 100% sensitivity). For Aim 2, we will explore the potential impact of excluding all citations that fall below particular thresholds during the screening process. We will also assess to what extent missing these studies would alter report conclusions. By characterizing potential efficiency gains from new, innovative, and widely accessible tools, this project can facilitate wider adoption by evidence based practice centers seeking to speed systematic review production. Project Narrative Systematic reviews provide a comprehensive, unbiased assessment of a body of literature and are vital for timely, evidence-based decision-making. However, development of systematic reviews remains too slow, with one particularly time-consuming step being citation screening, in which thousands of research abstracts are manually reviewed to identify a small number of relevant studies. By testing potential gains in citation screening efficiency offered by two innovative, widely-accessible machine- learning tools (Abstrackr and EPPI–Reviewer), and determining if automatically excluding studies to improve speed compromises report conclusions, we hope to enable more rapid production of systematic reviews to inform clinicians and policy-makers and promote high quality, evidence-based patient care.",Innovative text-mining tools to accelerate citation screening: comparative efficiency and impact on conclusions,9435231,R03HS025859,[' '],AHRQ,ECRI INSTITUTE,R03,2018,95324,0,-0.041118263434088254
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9535994,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2018,100000,5161939,-0.0006179874470693047
"Discovery and characterization of novel ciliopathy protein complexes Abstract Ciliopathies are a collection of debilitating developmental disorders (e.g. Joubert syndrome, Meckel syndrome, Bardet-Biedl syndrome, orofaciodigital syndrome, polycystic kidney disease) which have no cures and limited but expensive treatments. Diagnosis and treatment is complicated due to ciliopathies causing multisystem pathologies and having large variance in their clinical presentations potentially resulting in neural tube defects, orofacial clefting, obesity, polycystic kidneys, retinal degeneration and in some cases, infant death. All ciliopathies are caused by dysfunctional cilia, the microtubule based organelle critical for cell-to-cell signaling, but currently there is limited understanding of the underlying molecular network responsible for proper cilia function. Recently, large-scale proteomic techniques have advanced where it is now possible to query the cell's molecular network and identify many new protein complexes. This proposal describes a research program that will 1) construct a ciliary complex map using proteomic techniques, 2) functionally characterize newly discovered ciliary complexes and 3) identify disruptions in complex assembly due to known ciliopathy mutations. Additional products of the proposed research will include a compendium of proteomic data on ciliated cells, statistical analysis tools for the discovery of protein complexes, functional characterization of critical ciliary processes and a more complete understanding of the underlying molecular network of ciliopathy disease states. This work aims to provide an important perspective of cilia biology in order to better understand the complex etiology and molecular causes of ciliopathies and potentially open new therapeutic avenues. Project Narrative Ciliopathies are a class of debilitating birth defects without known cures and limited but expensive treatments. Currently, we lack understanding of the underlying molecular network in ciliopathy patient cells and know even less about the causes of clinical presentations in ciliopathy patients. I propose to discover the differences in the molecular network between healthy cells and ciliopathy patient cells in an effort to better understand the molecular causes of clinical presentations possibly open new avenues for therapeutics.""""""",Discovery and characterization of novel ciliopathy protein complexes,9565420,K99HD092613,"['Affect', 'Alleles', 'Animal Model', 'Bardet-Biedl Syndrome', 'Biochemical', 'Biological', 'Biological Models', 'Biology', 'Cells', 'Cilia', 'Cilium Microtubule', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collection', 'Complement', 'Complex', 'Computational Biology', 'Congenital Abnormality', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Developmental Cell Biology', 'Diagnosis', 'Disease', 'Embryo', 'Etiology', 'Exhibits', 'Fractionation', 'Future', 'Gene Transfer Techniques', 'Human', 'Ion Exchange', 'Joubert syndrome', 'Link', 'Machine Learning', 'Maintenance', 'Maps', 'Mass Spectrum Analysis', 'Mentors', 'Molecular', 'Molecular Sieve Chromatography', 'Mus', 'Mutation', 'Neural Tube Defects', 'Obesity', 'Organelles', 'Orofaciodigital Syndromes', 'Pathology', 'Patients', 'Polycystic Kidney Diseases', 'Property', 'Proteins', 'Proteomics', 'Rana', 'Recording of previous events', 'Regulation', 'Research', 'Retinal Degeneration', 'Role', 'Sea Anemones', 'Sea Urchins', 'Severity of illness', 'Signal Transduction', 'Statistical Data Interpretation', 'Structural Models', 'Structure of ciliary processes', 'Syndrome', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Tissue Microarray', 'Tissues', 'Training', 'Work', 'Xenopus laevis', 'base', 'cell type', 'ciliopathy', 'clinically relevant', 'developmental disease', 'educational atmosphere', 'fly', 'human disease', 'in vivo', 'in vivo imaging', 'infant death', 'insight', 'loss of function', 'novel', 'novel therapeutics', 'orofacial cleft', 'particle', 'programs', 'protein complex', 'protein function', 'skills', 'success', 'tool']",NICHD,"UNIVERSITY OF TEXAS, AUSTIN",K99,2018,100205,91740242,-0.03984643661202651
"Alicanto:  Proteogenomic discovery of single chain antibodies in llama Antibodies are a key component of the adaptive immune system, released in response to disease in order to target foreign molecular surfaces. Due to their capacity for high target affinity and specificity, they’ve become one of the fastest growing classes of therapeutic molecules addressing a range of disease including infectious diseases, auto-immune diseases, and cancer. Camelids, including llamas, camels, and alpacas, produce a unique repertoire of antibodies that includes both dual chain antibodies and single chain antibodies. Single chain antibodies, due to their comparative structural simplicity, are simpler to express and develop at the scale required for therapeutics. In addition, single chain antibodies are able to bind to small epitopes, such as enzyme active sites, that would be hidden to larger, dual chain antibodies. The binding domain of the single chain antibody may be small enough to infiltrate traditionally difficult to access tissues, including crossing the blood-brain barrier.  Current approaches to single chain antibody discovery require the collection of cells that encode the antibody genes, including memory B cells and plasma cells. Target-specific antibodies are selected after the antibody transcripts are cloned into a display system, such as phage or yeast. While memory B cells and plasma cells represent only a minute fraction of the cells located in peripheral blood, target- specific antibodies are present in high concentration in blood after an infection. Each plasma cell can secrete thousands of antibodies per minute. Digital Proteomics is developing Alicanto, a technology that utilizes the antibodies circulating in blood to identify target-specific antibodies.  Alicanto integrates two sources of information about the antibody repertoire. First, Alicanto constructs a database of potential antigen-specific antibodies by performing next-generation sequencing of antibody transcripts. Next, Alicanto enriches for target-specific antibodies from the blood using affinity chromatography and subjects the antibodies to tandem mass spectrometry. Finally, Alicanto uses machine learning models to integrate the sequencing and mass spectrometry data to derive a collection of target-specific antibody candidates. For single chain antibody discovery, Alicanto will use specialized primers and enrichment techniques to isolate only the subset of the antibody repertoire that contains the single chain antibodies. Alicanto will be used to discover high affinity, single chain antibodies for development as therapeutic molecules. Antibodies are produced natively in humans to fight disease and the molecules have garnered significant attention due to their therapeutic potential. Single-chain antibodies, which are smaller than conventional antibodies, represent a new frontier for antibody-based therapeutics due to their ability to target molecular surfaces that would be hidden to larger antibodies, as well as the relative simplicity of their development. Digital Proteomics is developing Alicanto to discover single-chain antibodies in llama that can be developed into human therapies.",Alicanto:  Proteogenomic discovery of single chain antibodies in llama,9622824,R43AI141046,"['Active Sites', 'Adaptive Immune System', 'Address', 'Affinity', 'Affinity Chromatography', 'Alpaca', 'Antibodies', 'Antibody Repertoire', 'Antibody Therapy', 'Antigen Targeting', 'Antigens', 'Aspirate substance', 'Attention', 'Autoimmune Diseases', 'B cell repertoire', 'B-Lymphocytes', 'Bacteriophages', 'Binding', 'Blood', 'Blood - brain barrier anatomy', 'Bone Marrow', 'Brain', 'Camels', 'Cations', 'Cell Fraction', 'Cells', 'Characteristics', 'Cloning', 'Collection', 'Communicable Diseases', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Drug Kinetics', 'Enzymes', 'Epitopes', 'Exhibits', 'G-substrate', 'Gel', 'Genes', 'Genus staphylococcus', 'Homo', 'Human', 'Immunization', 'Immunization Schedule', 'Industry Standard', 'Infection', 'Lead', 'Libraries', 'Light', 'Llama', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Memory B-Lymphocyte', 'Methods', 'Microbe', 'Modeling', 'Molecular', 'Molecular Target', 'Monoclonal Antibodies', 'Organism', 'Oryctolagus cuniculus', 'Pharmacodynamics', 'Plasma Cells', 'Proteins', 'Proteomics', 'Protocols documentation', 'Publishing', 'Serum', 'Solid Neoplasm', 'Source', 'Specificity', 'Spleen', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Therapeutic', 'Thrombotic Thrombocytopenic Purpura', 'Time', 'Tissues', 'Transcript', 'Venoms', 'Whole Blood', 'Work', 'Yeasts', 'antibody engineering', 'biophysical properties', 'comparative', 'design', 'digital', 'dimer', 'fighting', 'frontier', 'melting', 'nanobodies', 'neglected tropical diseases', 'next generation sequencing', 'peripheral blood', 'polypeptide', 'preference', 'proteogenomics', 'response', 'sample collection', 'screening', 'tandem mass spectrometry', 'therapeutic candidate', 'transcriptomics']",NIAID,"DIGITAL PROTEOMICS, LLC",R43,2018,170108,2060151,-0.011554466213785787
"Next Generation Testing Strategies for Assessment of Genotoxicity Project Summary  It is well recognized that current batteries of genetic toxicology assays exhibit two critical deficiencies. First, the throughput capacity of in vitro mammalian cell genotoxicity tests is low, and does not meet current needs. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no consideration for potency, and virtually no information is provided about molecular targets and mechanisms. These deficiencies in hazard characterization prevent genotoxicity data from optimally contributing to modern risk assessments, where this information is essential. We will address these major problems with current in vitro mammalian cell genetic toxicity assays by developing methods and associated commercial assay kits that dramatically enhance throughput capacity, and delineate genotoxicants' primary molecular targets, while simultaneously providing information about potency. Once biomarkers and a family of multiplexed assays have been developed for these purposes, an interlaboratory trial will be performed with prototype assay kits to assess the transferability of the methods. Project Narrative  DNA damage that cannot be faithfully repaired results in gene mutation and/or chromosomal aberrations, and these effects are known to contribute to cancer and other severe diseases. Thus, there is an important need for sensitive assays to evaluate chemicals for genotoxic and other deleterious effects. The work proposed herein will address issues that have plagued genotoxicity assessments for the last several decades: low throughput, lack of potency metrics, and little to no information about molecular targets. We will address these major problems with current genetic toxicity assays by developing new methods and associated commercial assay kits.",Next Generation Testing Strategies for Assessment of Genotoxicity,9465735,R44ES029014,"['Address', 'Affect', 'Aneugens', 'Antioxidants', 'Appearance', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Biological Response Modifiers', 'Bleomycin', 'Caspase', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemicals', 'Chromosome abnormality', 'Chromosomes', 'Classification', 'Cleaved cell', 'Colcemid', 'Companions', 'Complex', 'Computer Simulation', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'DNA-PKcs', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Dose', 'Epitopes', 'Etoposide', 'Exhibits', 'Family', 'GADD45A gene', 'Gamma-H2AX', 'Gene Mutation', 'Genetic', 'Goals', 'Harvest', 'Histone H3', 'Human', 'In Vitro', 'Intercalating Agents', 'Investigation', 'Kinetics', 'Label', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Modification', 'Molecular Target', 'Mutagenicity Tests', 'NF-kappa B', 'Nuclear', 'Pathway interactions', 'Phase', 'Physiologic pulse', 'Procedures', 'Protocols documentation', 'Reagent', 'Reference Values', 'Risk Assessment', 'Schedule', 'Scheme', 'Series', 'Stains', 'TP53 gene', 'Testing', 'Time', 'Toxic effect', 'Toxicogenetics', 'Training', 'Validation', 'Work', 'aurora kinase', 'base', 'clastogen', 'computerized tools', 'design', 'experimental study', 'forest', 'genotoxicity', 'hazard', 'inhibitor/antagonist', 'next generation', 'prediction algorithm', 'prevent', 'prototype', 'repaired', 'response', 'targeted agent', 'tool', 'treatment optimization', 'virtual']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2018,178854,651293,-0.011034855094520369
"Feature Learning For Improved Multiplex Disease Diagnosis Abstract This proposal is for CATTS, a feature learning technique optimized for use in multiplex mass spectrometry (MS) fingerprinting assays. MS fingerprints consist of a large number of chemical species, leading to very high dimensional feature spaces, and subsequent high false-discovery rates. CATTS aims to reduce the size of this space, by using knowledge of the underlying biochemistry, as well as general-purpose clustering algorithms. Our preliminary results demonstrate that, when used as a feature-learning technique for a variety of classification methods, CATTS significantly improves assay sensitivity. This proposal takes our existing implementation of CATTS and extends it to support additional feature learning algorithms and classification methods. Additionally, its performance as a multiplex assay strategy will be tested on both protein and lipid MS fingerprint libraries, with an eye towards commercialization.. Relevance to public health: The detection of pathogens via mass spectroscopy fingerprinting is rapidly becoming a standard technique for clinical microbiology. However, high false detection rates and conflicting multiple identifications limit applicability, and make interpretation of results difficult. Our work on CATTS aims to improve the statistical performance of these assays. Preliminary results from studies on one dataset we intend to apply CATTS to suggest that UTIs and, in some cases antimicrobial resistance, can be detected, directly from patient samples. However, the statistical methods currently employed aren't reliable enough - the further development of CATTS will accelerate the development of this, and other mass-spectroscopy-based assays..",Feature Learning For Improved Multiplex Disease Diagnosis,9559527,R43GM128538,"['Algorithms', 'Antimicrobial Resistance', 'Biochemistry', 'Biodiversity', 'Biological Assay', 'Biological Neural Networks', 'Chemicals', 'Classification', 'Clinical Microbiology', 'Conflict (Psychology)', 'Data Set', 'Decision Trees', 'Detection', 'Development', 'Dimensions', 'Eye', 'Fingerprint', 'Immune', 'Knowledge', 'Learning', 'Libraries', 'Lipids', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Modeling', 'Noise', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Process', 'Protein Fingerprints', 'Proteins', 'Public Health', 'Reporting', 'Research', 'Sampling', 'Statistical Methods', 'System', 'Techniques', 'Testing', 'Work', 'base', 'commercialization', 'disease diagnosis', 'feeding', 'forest', 'high dimensionality', 'improved', 'learning strategy', 'novel', 'vector']",NIGMS,"DEURION, LLC",R43,2018,189594,0,-0.015495582162583609
"High throughput cell screening for toxic metal exposure Project Summary The overall objective of this research project is to develop a novel approach for high throughput screening of individual cells based on holographic imaging. To achieve this goal, we propose to implement a new quantitative phase imaging modality, holographic cytomtery, which incorporates several novel technical advances to enable high throughput imaging. Holographic cytometry (HC) will bring the high sensitivity of quantitative phase microscopy (QPM) to imaging of cells flowing through microfluidic devices. While QPM has been used for cell analysis previously, typically only a handful of cells have been imaged. To enable significant application of QPM for fundamental cell biology and clinical studies, it is necessary to move to a high throughput implementation. Technical advances needed to realize the high resolution HC system include use of high speed line scan cameras, microfluidic chips with multiple parallel channels, and light from a pulsed laser source to enable stroboscopic illumination. In order to efficiently analyze and process this data set, rapid analysis software will be developed that leverages the highly parallel processing capabilities of graphics processing units and machine learning algorithms to enable automated classification. The proposed HC method can be applied to imaging a wide range of flowing cells. To demonstrate the utility of the approach, we will initially target the measurement of cancerous progression due to environmental toxicant exposure. We have conducted a preliminary study that shows QPM can detect early changes in the biomechanical properties of cells due to arsenic exposure. In the proposed project, we seek to develop QPM based biomarkers of pre-cancerous change that will enable rapid assessesment. QPM has not been implemented in such a format to date and thus is not yet a feasible approach for clinical or research studies. To meet the goal of high throughput imaging with QPM, the following Specific Aims are proposed: 1. Develop new instrumentation for high speed imaging using off axis digital holography. 2. Implement high throughput analysis methods based on machine learning 3. Test and validate high throughput system with pilot studies of heavy metal exposed epithelial cells to show the approach can detect early pre-cancerous changes due to environmental toxicant exposure. Upon completion of this project, we will have realized a high throughput imaging cytometry system for research and clinical applications. Project Narrative  The proposed research will develop a new high throughput cellular screening technology based on quantitative phase image of cells flowing in a microfluidic chip. This technology will allow researchers and doctors to obtain holographic images of every single cell in a sample in a short amount of time which can then be analyzed by a computer. This would offer the opportunity to evaluate the characteristics of populations of cells for understanding changes in public health due to environmental factors.",High throughput cell screening for toxic metal exposure,9610235,R21ES029791,"['Algorithms', 'Arsenic', 'Biological', 'Biological Assay', 'Biological Markers', 'Biomechanics', 'Cancerous', 'Cell Count', 'Cells', 'Cellular biology', 'Classification', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Cytology', 'Cytometry', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Descriptor', 'Development', 'Discrimination', 'Disease', 'Environmental Exposure', 'Environmental Risk Factor', 'Epithelial Cells', 'Evaluation', 'Exhibits', 'Exposure to', 'Functional disorder', 'Future', 'Geometry', 'Goals', 'Heavy Metals', 'Holography', 'Image', 'Image Cytometry', 'Individual', 'Lasers', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Mechanics', 'Metal exposure', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscopy', 'Morphology', 'Motion', 'Neoplasm Metastasis', 'Phase', 'Phenotype', 'Physiologic pulse', 'Pilot Projects', 'Population Characteristics', 'Premalignant', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Sampling', 'Scanning', 'Source', 'Speed', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Toxic Environmental Substances', 'Toxicant exposure', 'Vision', 'base', 'cancer cell', 'carcinogenesis', 'cellular imaging', 'clinical application', 'detector', 'digital', 'high throughput analysis', 'high throughput screening', 'imaging approach', 'imaging modality', 'instrument', 'instrumentation', 'mechanical properties', 'microscopic imaging', 'nanoscale', 'novel', 'novel strategies', 'parallel computer', 'parallel processing', 'prevent', 'research clinical testing', 'research study', 'screening', 'shear stress', 'systems research', 'tool', 'toxic metal']",NIEHS,DUKE UNIVERSITY,R21,2018,209312,607172798,0.008092570817457954
"An integrated neural network analysis and video microscopy platform for fully automated particle tracking Project Summary/Abstract  Particle tracking (PT) is a biophysical tool for elucidating molecular interactions, transport phenomena of diverse species, and rheological properties of complex materials. PT experiments involve first obtaining high resolution videos that capture time-resolved increments of particles, followed by extraction of traces of entities of interest from videos in the form of spatial locations over time, a process we refer to as path conversion. Finally, quantitative analysis of the traces will yield diffusivities, viscoelasticity, etc.  Lung diseases, such as cystic fibrosis and COPD, are characterized by a highly viscoelastic mucus layer that is incapable of being cleared by mucociliary clearance. Not surprisingly, the viscoelasticity of mucus often directly reflects disease progression. A variety of mucolytics are being investigated, but due to the variable composition and properties of mucus between patients, effective mucolytics treatment will likely be different between individuals; too little/inappropriate mucolytics will not be effective in restoring mucus clearance, whereas too much may result in bronchorrhea. Although microbeads-based rheology has been performed on a variety of mucus specimens in basic research, the capacity for high throughput characterization of rheological properties of biological specimens in a clinical setting is currently not available. This limitation can be attributed to inefficiencies of path conversion: current PT software requires extensive human supervision/intervention to achieve accurate path conversion, not only resulting in poor reproducibility and throughput but also restricting its use to only expert labs. Our vision is to make PT as objective and easy to use as a simple plate reader that can be readily utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening), and research professionals. Towards this goal, we have created a neural network tracker (NNT) that automatically determines the location of all particles in each frame with zero user-input (i.e. no parameter for users to change), and retains the identity of all particles from frame to frame. The innovation is that NNT can robustly, reproducibly, and accurately track a wide range of 2D/3D videos with virtually no need for human intervention, achieving unparalleled time savings. We have already successfully deployed NNT over the Google cloud, which offers exceptional scalability. Nevertheless, for time-sensitive applications, such as an automated PT rheometer, the transfer of large video data files is likely prohibitive. Therefore, in this Phase I STTR, we seek to enable real-time NNT-based PT analysis on the local machine while video microscopy data is being acquired by the microscope, and allow data from PT analysis to drive the operation of the microscope. In Aim 1, we will integrate our NNT with a single objective fluorescence microscope system called Monoptes. Aim 2 will evaluate the performance of our NNT- Monoptes system. If successful, our technology would form the basis of a fully automated PT system capable of measuring rheological properties of fluids/materials or distribution of particle sizes in a 96-well plate format. Project Narrative Particle tracking is a powerful biophysical tool in life and physical sciences, but unfortunately, its application has been strongly limited by inefficiencies in accurately extracting particle traces from raw movies. Unlike conventional particle tracking methods, we have combined artificial intelligence and machine learning to create a software that can consistently provide superior and truly automated tracking performance compared to current alternatives. In this proposal, we will integrate this latest advance with sophisticated instrumentation to develop a microscope system capable of fully automated particle tracking microscopy in a 96-well plate format. If successful, the instrument will likely be utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening of patients), and research professionals.",An integrated neural network analysis and video microscopy platform for fully automated particle tracking,9620574,R41GM130202,"['Acceleration', 'Adopted', 'Antibodies', 'Artificial Intelligence', 'Basic Science', 'Binding', 'Biological', 'Biological Neural Networks', 'Biological Sciences', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Trials', 'Code', 'Complex', 'Computer software', 'Cystic Fibrosis', 'Data', 'Data Files', 'Decision Making', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease Progression', 'Drug Carriers', 'Drug Screening', 'Effectiveness', 'Elasticity', 'Engineering', 'Gaussian model', 'Goals', 'HIV Infections', 'Heterogeneity', 'Human', 'Image', 'Individual', 'Intervention', 'Liquid substance', 'Location', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Microspheres', 'Motion', 'Mucociliary Clearance', 'Mucolytics', 'Mucous body substance', 'Output', 'Particle Size', 'Particulate', 'Pathway Analysis', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Positioning Attribute', 'Process', 'Property', 'Radial', 'Reader', 'Reproducibility', 'Research', 'Resolution', 'Respiratory physiology', 'Rheology', 'Risk', 'Running', 'Sampling', 'Savings', 'Series', 'Small Business Technology Transfer Research', 'Software Tools', 'Specimen', 'Spottings', 'Supervision', 'System', 'Technology', 'TensorFlow', 'Time', 'Video Microscopy', 'Viscosity', 'Vision', 'Woman', 'base', 'biophysical tools', 'cloud based', 'drug development', 'experimental study', 'fluorescence microscope', 'innovation', 'instrument', 'instrumentation', 'interest', 'movie', 'novel', 'operation', 'particle', 'patient screening', 'physical science', 'pre-clinical', 'submicron', 'virtual', 'viscoelasticity']",NIGMS,"AI TRACKING SOLUTIONS, LLC",R41,2018,224894,0,0.0006665565074863977
"Assay Classifier Engine (ACE) for enhancing splice sensor assay performance SUMMARY:  The goal of this proposal is to improve the sensitivity and specificity of the Spinach-based splice sensor platform by developing a novel multiprobe (MP) assay design and a companion machine learning-based classification algorithm called assay classifier engine (ACE). Improvement in sensitivity and specificity of the splice sensor platform enables its application to detect endogenous RNA isoforms with low copy number and distinguish alternative RNA isoforms that share high degree of sequence similarities.  The aim of any assay development effort is to achieve excellent assay specificity and sensitivity. However, this is often a futile endeavor since specificity and sensitivity are two inversely correlated factors. The underlying reason for poor sensitivity or specificity is due to the off-target signals generated by competing molecules present in the sample. In the field of diagnostics, one of the ways these issues are addressed is to perform multiple single probe testing instead of one single probe testing. While individual singe probe assays might have poor specificity and sensitivity, when combined, these assays synergistically improve the sensitivity and specificity of the ultimate diagnostic determination. In the field of research and drug discovery, researchers have employed a multitude of strategies (e.g. signal amplification, reaction cascades, or sample enrichment) to improve sensitivity and MP design or strand displacement strategies to improve specificity. Some of the PCR- based methods have combined both enzyme-based signal amplification and MP strategies to improve assay determination. However, when it comes to detecting targets that are highly similar to their competitors, such as detecting single nucleotide polymorphism, DNA methylation, RNA modification and alternative splicing, there is still an unmet need for more sensitive and specific analytical methods.  In the past few years, Lucerna has developed Spinach-based sensors to detect intractable metabolites and biomolecules. One such sensor is the splice sensor, which is a Spinach-based sensor that can generate fluorescence signal based on the alternative RNA isoform of interest. One of the challenges encountered during splice sensor assay development is the lack of sensitivity toward low copy number RNA isoforms and low specificity when distinguishing two splice isoforms that share a high sequence similarity. To overcome this challenge in this proposal, we will develop a MP assay panel comprised of splice sensor variants that recognize the target RNA and the competitor with varying binding affinities and differing signal responses. We will use data sets generated from the MP assay to train a ML-based ACE algorithm to make target determination in test samples. Further, we will develop a quantitative MP data set and re-train the ACE algorithm to classify the assay signals into various categories based on target concentrations in the test sample. This new ACE algorithm will then be tested against conventional single probe assays to determine specificity and sensitivity improvement of the MP assay platform. PROJECT NARRATIVE: Improved specificity and sensitivity are highly sought-after features in assays where there are high similarity between the target and its competitors or when the target exists naturally in very low abundance. To address this unmet need, we will develop a fluorescence sensor-based multiprobe assay approach and a companion machine learning-based assay classifier engine (ACE). The ACE algorithm will integrate the multiprobe assay data and classify them based on trained machine learning models to make sample determination with enhanced specificity, sensitivity, and dynamic range than possible with conventional single probe assays.",Assay Classifier Engine (ACE) for enhancing splice sensor assay performance,9622514,R43GM130258,"['Address', 'Adopted', 'Affinity', 'Algorithms', 'Alternative Splicing', 'Area Under Curve', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Assay', 'Categories', 'Cells', 'Characteristics', 'Classification', 'Companions', 'Custom', 'DNA Methylation', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Enzyme-Linked Immunosorbent Assay', 'Enzymes', 'Evaluation', 'Exhibits', 'Fluorescence', 'Goals', 'Individual', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Nerve Degeneration', 'Nucleotides', 'Output', 'Pattern', 'Performance', 'Process', 'Protein Isoforms', 'RNA', 'RNA Splicing', 'Reaction', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Series', 'Side', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Specificity', 'Spinach - dietary', 'Technology', 'Testing', 'Time', 'Titrations', 'Training', 'Variant', 'analytical method', 'aptamer', 'assay development', 'base', 'cost', 'design', 'drug discovery', 'experience', 'improved', 'interest', 'novel', 'outcome forecast', 'predictive modeling', 'response', 'sensor', 'targeted biomarker']",NIGMS,"LUCERNA, INC.",R43,2018,224925,981315,-0.01181602483170915
"Towards automated phenotyping in epilepsy Over 5 million children and adults in the United States have had a diagnosis of epilepsy or a seizure disorder. However, treatment options for the epilepsies remain inadequate, because many patients suffer from uncontrolled seizures and from the negative side effects of treatment. A major obstacle to the faster development of new anti-convulsant therapies is the fact that rigorous preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). We propose to test if it is possible to perform objective, inexpensive and automated phenotyping of mice in various mouse models of acquired and genetic epilepsies. The approach rests on the recent recognition that mouse behaviors are structured in stereotyped modules at sub-second timescales that are arranged according to specific rules. These characteristic behavioral modules, and the transitions between them, can be identified without observer bias by combined 3D imaging and machine learning (ML) -assisted analytic methods. We propose to adopt this novel ML-assisted 3D video analysis technology to epilepsy research, in order to test if it can be used to identify mice with chronic temporal lobe epilepsy (TLE) during inter-ictal and ictal periods in two distinct experimental TLE models, and under various experimental conditions. In addition, we will also test whether the approach is able to automatically detect not only the overtly epileptic mice in a genetic model of severe childhood epilepsy (homozygous voltage-gated sodium channel β-subunit SCN1B-/- knock-out mice), but also distinguish the seemingly normal, non-epileptic, SCN1B+/- heterozygous mice from the wild-type controls. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user-independent, inexpensive analysis of acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will test if it is possible to objectively characterize epileptic phenotypes in mice using a breakthrough technology involving machine learning-assisted analysis of 3-dimensional video data of behavior. If successful, this innovative approach is expected to dramatically accelerate epilepsy research by enabling the objective, automated, inexpensive phenotyping of experimental animals to aid the testing of novel anticonvulsant therapies.",Towards automated phenotyping in epilepsy,9503816,R21NS102908,"['Adopted', 'Adult', 'Adverse effects', 'Animal Behavior', 'Animal Model', 'Animals', 'Anticonvulsants', 'Behavior', 'Behavioral', 'Characteristics', 'Child', 'Childhood', 'Chronic', 'Complex', 'Data', 'Development', 'Diagnosis', 'Electroencephalography', 'Epilepsy', 'Exhibits', 'Frequencies', 'Genetic', 'Genetic Models', 'Hippocampus (Brain)', 'Human', 'Human immunodeficiency virus test', 'Image', 'Knockout Mice', 'Machine Learning', 'Modeling', 'Monitor', 'Mus', 'Neurons', 'Observer Variation', 'Patients', 'Phenotype', 'Pilocarpine', 'Probability', 'Recurrence', 'Research', 'Rest', 'Seizures', 'Sodium Channel', 'Stereotyping', 'Structure', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Translational Research', 'United States', 'Wild Type Mouse', 'analytical method', 'base', 'cost', 'dravet syndrome', 'evidence base', 'high throughput analysis', 'innovation', 'kainate', 'learning strategy', 'mouse model', 'novel', 'novel therapeutics', 'pre-clinical', 'voltage']",NINDS,STANFORD UNIVERSITY,R21,2018,237423,560644462,-0.0008948635261738583
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9483579,R00AG046911,"['Address', 'Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Drug Screening', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'imaging modality', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'public health relevance', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2018,249000,32532200,-0.0030342911147281334
"QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring Modern health monitoring devices at hospitals and wearable sensors in households generate a large amount of time series data at high rate, capturing the physiological status of patients in a real-lime fashion. The premise is that these technology advances enable a data-driven healthcare system that starts making fast, accurate, objective and inexpensive decisions based upon data, in addition to an individual physician's experience and preference. However, there is a significant gap in the mathematical theory and computational tools to promptly extract actionable information from multi-modal non-stationary time series data in a robust and tractable manner, which has become a serious roadblock to further utilize bigger data for better healthcare monitoring. The goal of this research program is to develop a mathematical framework for extracting time-frequency and geometric representations of multi-modal physiological data, in an online and robust manner, and use them to design machine learning algorithms to improve real-lime health monitoring. Specifically, we hypothesize that the development of time-series and geometric methods for large streaming multi-modal monitoring data will lead to more accurate diagnosis on various physiological monitoring applications, including detection and prediction of rare events such as seizure and arrhythmia, classification of sleep stages for newborns and children, and real-time artifact removal of physiological data. To achieve our goal, we plan to develop novel theoretical and computational tools for analyzing non-stationary multi-modal time series data with noise, corruption and missing data as well as real-time algorithms for filtering and event detection from such data. The tools and algorithms will be applied on clinical tasks at the Nationwide Children's Hospital. In addition, the real-time workflow will be implemented on Hadoop clusters with a mission of public sharing of both data and software. The development from the interdisciplinary team composed of mathematicians, biomedical informaticians as well as the hospital will not only transform the frontiers of mathematics knowledge, but also significantly impact clinical applications, data science education, and the development of the $11 O billion emerging market of wireless health. The goal of this project is to develop a series of novel computational theory and software to extract physiological information from the large multi-modal data streams generated by modern health monitoring devices. The tools will be applied to various clinical tasks such as detection and prediction of seizure and arrhythmia and classification of sleep stages for newborns and children, aiming for more accurate diagnosis.",QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring,9568758,R01EB025018,"['Address', 'Algorithms', 'Arrhythmia', 'Behavior', 'Big Data', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Science', 'Detection', 'Development', 'Diagnostic', 'Education', 'Environment', 'Event', 'Excision', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Household', 'Human body', 'Individual', 'Infant', 'Knowledge', 'Limes', 'Machine Learning', 'Mathematics', 'Measures', 'Methods', 'Mission', 'Modality', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Nature', 'Newborn Infant', 'Noise', 'Outcome', 'Patients', 'Pattern', 'Pediatric Hospitals', 'Physicians', 'Physiologic Monitoring', 'Physiological', 'Property', 'Public Domains', 'Research', 'Resources', 'Seizures', 'Series', 'Sleep Stages', 'Stream', 'Techniques', 'Technology', 'Time', 'Universities', 'Validation', 'Wireless Technology', 'accurate diagnosis', 'base', 'biological systems', 'clinical application', 'clinical practice', 'computerized tools', 'design', 'diagnostic biomarker', 'experience', 'frontier', 'geometric methodologies', 'graduate student', 'heart rate variability', 'improved', 'insight', 'mathematical theory', 'monitoring device', 'multimodality', 'novel', 'preference', 'programs', 'science education', 'signal processing', 'student training', 'theories', 'tool', 'wearable device']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2018,258070,30434536,-0.010088772471875661
"Novel Nanopore-based RNA Sequencing using Nucleobase-specific Tags Project Summary Cost-effective, and accurate sequencing of RNA, composed of both canonical and modified bases, of any length, without conversion to cDNA, and without amplification are the objectives of this project, and the ultimate goal is to sequence the transcriptome, and determine in a time-sensitive manner relative distribution of its components. Such accomplishment will directly impact prevention, diagnosis, and cure of disease and materialize the promise of personalized medicine. Current methods, such as Illumina's RNA-Seq, and the single molecule approaches of Pacific Biosciences and of Oxford Nanopore Technologies, still lag behind in many of the critical attributes mentioned above. The unresolved issue with nanopore-based sequencing is the observation that ion current vs. time recording does not refer to a single nucleobase, but to a short sequence of 4 or more bases. The problem, partially resolved with the use of sophisticated algorithms and learning machines, appears intractable for RNA that includes numerous post-transcriptional base modifications. As an illustration, if a nanopore reads a sequence of 4 bases and the specific RNA to be sequenced has a total of 8 different nucleobases (4 canonical and 4 modified), then 48 = 65,536 signals need to be discriminated from within an ion current range of 20 to 40 pA with a standard deviation of ±1 pA; this is an impossible computational task. However, if the nanopore could sense one base at a time and yield distinct ion current for each base, there will be only 8 different recordings to distinguish from, a much simpler task. Our own published results indicate that oligodeoxynucleotides conjugated with a pyrimidine-specific tag (Osmium tetroxide 2,2'-bipyrimidine or OsBp) yield enzyme-free, slow/readable translocation via α- Hemolysin, and distinct ion current levels for intact, T(OsBp), and C(OsBp) bases, suggesting that a single tag can yield sequencing information on purine, T, and C. The latter leads to the conjecture that the presence of a second, purine-specific, label would allow identification of all four canonical bases. Furthermore each tag has intrinsic selectivity for one base over another, and this will provide a handle for additional discrimination among the modified bases. In this phase I proposal we aim to demonstrate (i) near 100% labeling (true positives) with 0% internucleotide bond cleavage, and 0% false positives for RNA(OsBp), as we have already shown for DNA(OsBp), (ii) comparable labeling attributes for a purine-specific tag, and (iii) readable translocation with single pyrimidine base discrimination for RNA(OsBp). Success in these efforts will lead to single base discrimination and sequencing of RNA, including a number of post-transcriptionally modified bases, and pave the road for sequencing the transcriptome. ! PUBLIC HEALTH RELEVANCE: Advances in personalized medicine for diagnosis and treatment of disease require sequencing the RNA transcriptome with technologies that are currently unavailable. Nanopore-systems that exhibit single-base discrimination, like the one addressed in this proposal, will allow sequencing the transcriptome in an accurate, timely, and cost-effective manner.",Novel Nanopore-based RNA Sequencing using Nucleobase-specific Tags,9506880,R43HG010051,"['Address', 'Algorithmic Software', 'Algorithms', 'Base Sequence', 'Belief', 'Biological Assay', 'Biological Sciences', 'Cells', 'Complementary DNA', 'DNA', 'Development', 'Diagnosis', 'Digit structure', 'Discrimination', 'Disease', 'Enzymes', 'Exhibits', 'Genetic Transcription', 'Goals', 'Hemolysin', 'In Vitro', 'Individual', 'Investigation', 'Ions', 'Label', 'Length', 'Machine Learning', 'Measures', 'Methods', 'Modification', 'Monitor', 'Nucleic Acids', 'Nucleotides', 'Oligonucleotides', 'Osmium Tetroxide', 'Phase', 'Platinum', 'Platinum Compounds', 'Prevention', 'Protocols documentation', 'Publishing', 'Purines', 'Pyrimidine', 'Pyrimidines', 'RNA', 'RNA Sequences', 'Readability', 'Residual state', 'Signal Transduction', 'Site', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Transfer RNA', 'VDAC1 gene', 'analytical tool', 'base', 'constriction', 'cost effective', 'design', 'improved', 'nanopore', 'new technology', 'novel', 'nucleobase', 'personalized medicine', 'public health relevance', 'sensor', 'single molecule', 'success', 'transcriptome', 'transcriptome sequencing']",NHGRI,"YENOS ANALYTICAL, LLC",R43,2018,280000,276817,-0.013137213966727393
"UVPD-MS Characterization of Lipopolysaccharides Abstract. Gram-negative bacteria have caused many of the most persistent infections as well as some of the deadliest pandemics in the world. Some strains have developed resistant to all available drugs, thus leading to increasing mortality from previously treatable bacterial infections. The National Strategy for Combating Antibiotic-Resistant Bacteria released by the White House in September 2014 focused on the need for (i) advancing the development of methods for identification and characterization of bacteria, (ii) accelerating basic research for new antibiotics, and (iii) improving capabilities for surveillance of antibiotic-resistant bacteria. This proposal focuses on the development of innovative tandem mass spectrometry approaches for characterization of lipopolysaccharides (LPS), the primary constituent of the outer membrane of Gram-negative bacteria that protects the membrane from chemical attack and is recognized by the immune system during pathogenic invasion. Structural characterization of LPS is critical to understanding how the structure of LPS influences immune stimulation as well as facilitating development of new antimicrobials and vaccines. This is a significant analytical challenge due to the branched structures and amphipathic properties of LPS. The escalating concerns about antibiotic resistance bacteria and the need for better avenues of defense against infectious diseases have motivated the proposed work. The objectives of this proposal are: Aim 1: Development of ultraviolet photodissociation (UVPD) mass spectrometry via hierarchical, decision-tree workflows for top-down characterization of LPS to facilitate high throughput analysis; Aim 2: Development of MS/MS approaches for serotyping of Gram-negative bacteria based on LPS; Aim 3: Examination of peptide/LPS interactions via native-spray mass spectrometry to provide both mechanistic information and screening capabilities for new antimicrobials, and Aim 4: Applications to a variety of structural problems related to the biosynthesis of LPS in Gram- negative bacteria and characterization of hybrid O-antigen/lipid A molecules in vesicle-based vaccines.  We have established a new collaboration with Dr. Bryan Davies' group to develop mass spectrometry methods to characterize peptide/lipid A interactions in support of the hunt for better antimicrobials. The continued collaboration with Dr. Stephen Trent's group emphasizes: (i) approaches for deciphering the biosynthetic pathways of bacterial LPS that endow them with the remarkable ability to re-design their outer membranes and develop antibiotic resistance, and (ii) innovative vaccine design based on antigenic LPS in vesicles.    Narrative: Gram-negative bacteria are responsible for some of the deadliest and more widespread pandemics in the world. The proposed work focuses on the development of advanced mass spectrometry approaches for characterization of complex lipopolysaccharides, including the endotoxic lipid A domains, that comprise the outer membrane of Gram-negative bacteria. The proposed work will be applied to evaluate new antimicrobials and support development of hybrid vaccines.",UVPD-MS Characterization of Lipopolysaccharides,9552867,R01GM103655,"['Acylation', 'Address', 'Advanced Development', 'Affinity', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Architecture', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Bacterial Vaccines', 'Basic Science', 'Binding', 'Catalogs', 'Cells', 'Chemical Warfare', 'Code', 'Collaborations', 'Combating Antibiotic Resistant Bacteria', 'Communicable Diseases', 'Complex', 'Complex Mixtures', 'Custom', 'Databases', 'Decision Trees', 'Development', 'Distal', 'Exhibits', 'Focus Groups', 'Glycolipids', 'Gram-Negative Bacteria', 'Hybrids', 'Hydrophobicity', 'Immune system', 'Immunization', 'Infection', 'Ions', 'Lipid A', 'Lipopolysaccharide Biosynthesis Pathway', 'Lipopolysaccharides', 'Mass Spectrum Analysis', 'Membrane', 'Methodology', 'Methods', 'Modification', 'Molecular', 'O Antigens', 'Oligosaccharides', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphorylation', 'Polysaccharides', 'Process', 'Production', 'Property', 'Publishing', 'Resistance', 'Serotyping', 'Structure', 'System', 'Tail', 'Vaccine Design', 'Vaccines', 'Variant', 'Vesicle', 'Virulence', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'cell envelope', 'chronic infection', 'design', 'high throughput analysis', 'hydrophilicity', 'improved', 'innovation', 'innovative technologies', 'inorganic phosphate', 'instrument', 'method development', 'mortality', 'novel', 'novel therapeutics', 'pandemic disease', 'response', 'screening', 'sugar', 'tandem mass spectrometry', 'ultraviolet']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2018,297043,91740242,-0.011252393542071502
"FAST platform for same-shift, complete antibiotic menu antibiotic susceptibility testing The goal of this Phase I SBIR proposal is to demonstrate utility to all major pathogenic bacterial strains of SeLux’s rapid, low-cost, phenotypic antibiotic susceptibility test (AST) system (fast-AST or FAST). Utilizing existing optical detectors and standard dried antibiotic microplates, and avoiding pitfalls of metabolic probes, FAST will potentially transform therapy of infections by significantly accelerating AST, thereby facilitating treatment with the optimal antibiotic. Aim 1 will apply FAST to hundreds of samples of pathogenic bacterial strains, while developing and optimizing a predictive algorithm for clinical utility. Aim 2 will extend the FAST platform to slow-growing strains and species as well. SeLux has demonstrated FAST to exceed FDA 510(k) requirements for minimum inhibitory concentration determinations for 25+ strains of Staphylococcus aureus and Escherichia coli with full antibiotic panels. Completion of the proposed aims will expand FAST to all major clinically-relevant, non-fastidious bacterial pathogens. SeLux’s interdisciplinary team has expertise in nanosensing, microbiology, and algorithm design and is buttressed by distinguished experts in Clinical Microbiology, Infectious Disease, and Machine Learning. The new paradigm in clinical medicine is value-based healthcare, which requires rapid and accurate diagnoses leading to optimal patient treatment. Nowhere is this more important than in treating infections, where doctors are currently forced to overprescribe broad-spectrum antibiotics during an agonizing 48+ hour wait for antibiotic susceptibility test (AST) results. The novel, rapid, low-cost AST platform described in this proposal promises to reduce this delay in treatment by as much as 30 hours. This advance would be transformative for the treatment of infections because current over-use of broad-spectrum antibiotics not only harms individual patients but is a primary contributor to the growing epidemic of antibiotic resistance.","FAST platform for same-shift, complete antibiotic menu antibiotic susceptibility testing",9464993,R43AI136125,"['Agreement', 'Algorithm Design', 'Algorithms', 'Amplifiers', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotic susceptibility', 'Antibiotics', 'Bacterial Antibiotic Resistance', 'Biological Assay', 'Blinded', 'Blood', 'Centers for Disease Control and Prevention (U.S.)', 'Chemicals', 'Clinical', 'Clinical Medicine', 'Clinical Microbiology', 'Combating Antibiotic Resistant Bacteria', 'Communicable Diseases', 'Detection', 'Development', 'Devices', 'Diagnostic', 'End Point Assay', 'Engineering', 'Ensure', 'Epidemic', 'Escherichia coli', 'Funding', 'Goals', 'Grant', 'Healthcare', 'Hour', 'Human', 'In Vitro', 'Infection', 'Institutes', 'Invaded', 'Laboratories', 'Length of Stay', 'Machine Learning', 'Metabolic', 'Methods', 'Microbiology', 'Minimum Inhibitory Concentration measurement', 'Optics', 'Pathogenicity', 'Patient Care', 'Patients', 'Phase', 'Phenotype', 'Plague', 'Positioning Attribute', 'Privatization', 'Quality of Care', 'Reagent', 'Recovery', 'Regulatory Affairs', 'Sampling', 'Sampling Studies', 'Scientist', 'Small Business Innovation Research Grant', 'Speed', 'Staphylococcus aureus', 'System', 'Test Result', 'Testing', 'Vancomycin', 'Work', 'accurate diagnosis', 'base', 'clinically relevant', 'combat', 'commercialization', 'cost', 'cost effectiveness', 'design', 'detector', 'individual patient', 'instrument', 'nanosensors', 'novel', 'optimal treatments', 'pathogen', 'performance tests', 'prediction algorithm', 'prototype', 'rapid diagnosis']",NIAID,"SELUX DIAGNOSTICS, INC.",R43,2018,298851,1000000,-0.008647387049059842
"Quantifying NETosis via Automated High Content Imaging Convolutional Neural Networks PROJECT SUMMARY NETosis was identified as a distinct mode of cell death in neutrophils more than a decade ago. Dysregulation of NETosis has been implicated in the etiology of human pathologies such as preeclampsia, sickle cell disease, systemic lupus erythematosus, multiple sclerosis, rheumatoid arthritis, sepsis, cystic fibrosis, lupus nephritis, and coagulopathies that include cancer-associated thrombosis. The literature consistently cites the lack of a standardized methodology for quantitation of NETosis as an impediment to basic and translational research. Thus, the premise is that there is a compelling, unmet need for a standardized, quantitative and automated method for the measurement of NETosis to accelerate neutrophil and inflammation-based research and facilitate the discovery and development of therapeutic compounds. The scope of this STTR project is to develop a high-throughput image analysis and quantitation method by using high content imaging and the revolutionary technology of convolutional neural networks (CNN) for the identification and quantitation of NETosis in human neutrophils. The target readout is based on the primary morphological difference between NETotic and non-NETotic nuclei--the decondensation of chromatin. This image-based quantitative method will be observer-independent and will enable robust and rapid evaluation of a large number of samples that would exceed any attempts at manual assessment. In Phase I we will complete the following Specific Aims: Aim 1: Optimize and standardize the high- throughput platform for quantitation of NETosis in adherent human neutrophils. This includes standard assay optimization procedures, training the CNN to identify and quantitate NETotic neutrophil, and demonstrating that the CNN reliably distinguishes between necrosis and NETosis, whose phenotypes appear similar to the human eye. Aim 2: Validate the NETosis assay biochemically and clinically. This includes concentration-response assays with NETosis agonists, assessment of NETosis inhibitors, and evaluation of the NETotic status of Sickle Cell Disease patient samples (a disease in which aberrant NETosis has been implicated). The expected outcome of this Phase I effort is to demonstrate proof-of-concept for this automated high- throughput NETosis assay. Further, we expect to provide insight into the utility of the assay for assessment of inhibitors of NETosis as therapeutic agents. Upon completion of our Phase I aims, our Phase II program will focus on further optimizing and validating this NETosis assay and preparing it for commercialization.   PROJECT NARRATIVE Aberrant NETosis has been implicated in the etiology of several inflammatory and autoimmune diseases. The lack of a standardized, quantitative and automated method for the measurement of NETosis is impeding basic and translational research. We have developed a high-throughput assay using convolutional neural networks to quantify NETosis in human neutrophils. This assay will accelerate neutrophil and inflammation-based research and facilitate the discovery and development of compounds with therapeutic potential.",Quantifying NETosis via Automated High Content Imaging Convolutional Neural Networks,9465292,R41AI131840,"['Agonist', 'Apoptosis', 'Autoimmune Diseases', 'Basic Science', 'Benchmarking', 'Biochemical', 'Biochemical Pathway', 'Biological Assay', 'Biological Neural Networks', 'Blood Coagulation Disorders', 'Caymans', 'Cell Death', 'Cell Death Process', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Clinical', 'Cystic Fibrosis', 'DNA', 'Data', 'Development', 'Diagnostic', 'Diagnostic tests', 'Diagnostics Research', 'Disease', 'Drug Screening', 'Ensure', 'Enzymes', 'Etiology', 'Evaluation', 'Eye', 'Histones', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Impairment', 'Infection', 'Inflammation', 'Inflammatory', 'Innate Immune Response', 'Letters', 'Literature', 'Lupus Nephritis', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Morphology', 'Multiple Sclerosis', 'Nature', 'Necrosis', 'Nuclear', 'Opportunistic Infections', 'Outcome', 'Pathway interactions', 'Patients', 'Peptide Hydrolases', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physical condensation', 'Population', 'Pre-Eclampsia', 'Predisposition', 'Procedures', 'Process', 'Publishing', 'Reproducibility', 'Research', 'Rheumatoid Arthritis', 'Sampling', 'Sepsis', 'Severity of illness', 'Sickle Cell Anemia', 'Side', 'Small Business Technology Transfer Research', 'Specificity', 'Stains', 'Standardization', 'Systemic Lupus Erythematosus', 'Technology', 'Therapeutic', 'Therapeutic Agents', 'Thrombosis', 'Training', 'Translational Research', 'antimicrobial', 'antimicrobial peptide', 'base', 'commercial application', 'commercialization', 'extracellular', 'high throughput screening', 'inhibitor/antagonist', 'innovation', 'insight', 'neutrophil', 'novel', 'patient population', 'predictive test', 'programs', 'response', 'suicidal', 'symptom management', 'therapeutic development', 'tool']",NIAID,"EPICYPHER, INC.",R41,2018,299751,5167535,-0.012909355718802713
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9679722,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Autistic Disorder', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2018,303226,5161939,-0.008540638079986274
"Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner Project Summary/Abstract This application is for a shared instrumentation grant from the Light Microscope Imaging Facility at Case Western Reserve University (CWRU) School of Medicine (SOM) to acquire a fully automated, high-capacity, high- resolution Hamamatsu Nanozoomer S60 slide scanner that can accommodate both brightfield and fluorescence imaging in single-slide and double-slide formats. We also request MicroDimensions 3D reconstruction and alignment software packages for manipulating and analyzing the whole slide images produced with the scanner. We need to replace a scanner that is not functioning properly. Our well-established shared core facility supports NIH-funded investigators by giving them access to state-of-the-art microscopy technologies that enhance collaborative, multidisciplinary research. Acquisition of this instrument will have a high impact on the biomedical research at CWRU and expand the scope of our NIH-funded projects. Several projects have been identified that will utilize the scanner and its associated analyses programs. These include: the genetic mechanisms underlying skin fibrosis and cranial bone development (Atit); the mechanisms behind the lifelong functions of transcription factors in axonal growth and architecture (Deneris); deep-learning for histologic image predictors of various diseases (Madabhushi); the development of diagnostic probes to discriminate between glioma subtypes for screening and survival therapies (Brady-Kalnay); the role of progesterone receptors in the control of parturition and the development of therapies to prevent preterm birth (Messiano); the mechanisms by which breast cancer stem cells overcome metastatic latency leading to disease recurrence and the biomarkers that could potentially identify those tumors likely to undergo this process (Schiemann); and the significance of cholesterol-related proteins in brain and retinal function (Pikuleva). Many additional projects of minor users and others at CWRU are anticipated. All of the proposed projects are in need of a high-capacity automated scanner acquiring whole slide images so that analyses can be applied to tissues that cover hundreds of fields of view, rather than the single regions of interest that can be acquired on a standard microscope. Narrative This proposal seeks to acquire a new, state-of-the-art high-speed, high content digital slide scanner for high resolution cellular and biomarker identfcation across large tissue areas. The dual mode (fluorescence and brightfield) allows flexibility in marker visualization while the software allows the automated alignment of whole slide images for multi-stain analysis and 3d reconstruction of serial section for in-depth analysis of specimens. This equipment is essential for our NIH disease-related studies providing a profound positive impact on a wide range of public health areas.",Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner,9489976,S10OD024981,"['Architecture', 'Biological Markers', 'Biomedical Research', 'Birth', 'Bone Development', 'Brain', 'Cephalic', 'Cholesterol', 'Computer software', 'Core Facility', 'Development', 'Diagnostic', 'Disease', 'Enhancement Technology', 'Funding', 'Genetic', 'Glioma', 'Grant', 'Interdisciplinary Study', 'Light Microscope', 'Microscope', 'Microscopy', 'Minor', 'Premature Birth', 'Process', 'Progesterone Receptors', 'Proteins', 'Recurrence', 'Research Personnel', 'Resolution', 'Retinal', 'Role', 'Slide', 'Tissues', 'United States National Institutes of Health', 'Universities', 'axon growth', 'cancer stem cell', 'deep learning', 'digital', 'equipment acquisition', 'fluorescence imaging', 'histological image', 'imaging facilities', 'instrumentation', 'interest', 'malignant breast neoplasm', 'medical schools', 'prevent', 'programs', 'reconstruction', 'screening', 'skin fibrosis', 'therapy development', 'transcription factor', 'tumor', 'whole slide imaging']",OD,CASE WESTERN RESERVE UNIVERSITY,S10,2018,303390,197030888,-0.011688409385313936
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,9445086,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'actionable mutation', 'base', 'disease phenotype', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'learning strategy', 'metabolomics', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,305167,511185245,-0.007616496737782076
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9579149,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2018,314000,560644462,-0.014118750287225616
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9525950,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,333515,7208224,0.027073322220375878
"A Modular Automated Platform for Large-scale Drosophila Experiments and Handling PROJECT SUMMARY / ABSTRACT Animal model systems are a powerful tool researchers use to investigate almost all aspects of biology: genetics, development, neuroscience, disease, and more. And fruit flies – Drosophila melanogaster – with their small size, easy care, and remarkable array of available genetic toolkits, occupy a sweet spot on the model organism spectrum. Over 75% of human diseases with a genetic basis have an analogue in the fly, and Drosophila have been a part of the research for six Nobel prizes. Furthermore, the advent of CRISPR/cas9 and other modern genetic tools has opened the door to modeling other diseases and pathways, leading to greater use of Drosophila for drug screens. A great deal of the work (and the majority of the budget) involved in fly experiments is tedious manual labor, and with advances in computer vision, machine learning, and other analytic techniques, the stage is set to automate many phenotypic screens. In this Phase I SBIR, we propose a robotic system – modular automated platform for large-scale experiments (MAPLE) – that can accomplish a wide variety of fly-handling tasks in Drosophila labs. This robot is the fruit fly version of a liquid handling robot, with a large, open workspace that can house a plethora of modules and several manipulators that can move small parts and animals around that workspace. Building on a collaboration between the de Bivort Lab and FlySorter completed in 2017, we will design, fabricate and validate a commercial system that can collect virgin flies, run behavioral assays, conduct drug screens, and adapt to the needs of fly labs through easy-to-code Python scripts. By strategically combining modules and instructions to the robot, MAPLE can perform a wide variety of tasks in a fly lab, saving experimentalists from repetitive chores, cutting labor costs, and increasing scientific output. Just as pipette robots have become standard equipment in wet labs, we envision our fly handling robot will be the engine that powers Drosophila labs in academia and pharma, enabling new kinds of experiments and freeing researchers from the drudgery of fly pushing. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are a powerful model organism used in the study of disease, neuroscience, development, genetics, and recently in drug screens, too, largely through phenotypic screening. This labor-intensive work is time consuming and expensive, and ripe for automation. We propose a fly-handling robot – analogous to a liquid pipetting robot in a wet lab – that can perform a variety of tasks in Drosophila labs, free researchers from the drudgery of fly pushing, and enable a broader spectrum of experiments that will increase scientific knowledge.",A Modular Automated Platform for Large-scale Drosophila Experiments and Handling,9623017,R43MH119092,"['Academia', 'Address', 'Affect', 'Air', 'Anesthesia procedures', 'Animal Model', 'Animals', 'Architecture', 'Automation', 'Basic Science', 'Behavior', 'Behavioral Assay', 'Biological Models', 'Biology', 'Budgets', 'CRISPR/Cas technology', 'Carbon Dioxide', 'Caring', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Data Collection', 'Deposition', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Screening', 'Drug usage', 'Ensure', 'Equipment', 'Feedback', 'Genetic', 'Genetic Screening', 'Genetic study', 'Grant', 'Hand', 'Human', 'Instruction', 'Knowledge', 'Libraries', 'Liquid substance', 'Machine Learning', 'Manuals', 'Modeling', 'Modernization', 'Neurosciences', 'Nobel Prize', 'Organism', 'Output', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Protocols documentation', 'Pythons', 'Reagent', 'Research', 'Research Personnel', 'Robot', 'Robotics', 'Running', 'Savings', 'Scanning', 'Small Business Innovation Research Grant', 'Speed', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Transgenic Organisms', 'Travel', 'Universities', 'Update', 'Vacuum', 'Work', 'analog', 'bone', 'cost', 'design', 'drug discovery', 'experimental study', 'flexibility', 'fly', 'graduate student', 'health science research', 'human disease', 'improved', 'operation', 'programs', 'repository', 'robot control', 'screening', 'tool', 'touchscreen']",NIMH,"FLYSORTER, LLC",R43,2018,348007,0,-0.025853050376759015
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9406318,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cancer Etiology', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2018,356625,323604360,0.011753235746555743
"A platform for mining, visualization and design of microbial interaction networks Project Summary One of the burning questions in the study of the human microbiome is whether and how it is possible to design specific strategies for rebalancing the taxonomic and functional properties of human-associated microbial communities, triggering the transition from “disease states” to “healthy states”. While empirical studies provide strong support for the idea that we may be able to cure, or at least  treat, a number of diseases by simply transplanting microbiomes, or inducing changes through taxonomic or environmental perturbations, to date little mechanistic understanding exists on how microbial communities work, and on how to extend microbiome research from an empirical science to a systematic, quantitative field of biomedicine. We propose here to establish a computational platform--   a database (Aim 1) with fully integrated analytical software (Aims 2 and 3) --- developed for and with the cooperation of the scientific community. The resource goes beyond cataloguing microbial abundances under different condition; its aim is to enable an understanding of networks of interacting species and their condition-dependence, with the goal of eventually facilitating disease diagnosis and prognosis, and designing therapeutic strategies for microbiome intervention. Our project is centered around three key aims: 1.	The creation of a Microbial Interaction Network Database (MIND), a public resource that will collect data on inter-species interactions from metagenomic sequencing projects, computer simulations and direct experiments. This database will be accessed through a web-based platform complemented with tools for microbial interaction network analysis and visualization, akin to highly fruitful tools previously developed for the study of genetic networks; the database will also serve as the public repository of microbial networks associated with human diseases; 2.	The implementation of an integrated tool for simulation of interspecies interactions under different environments, based on genomic data and whole-cell models of metabolism; 3.	The implementation of new algorithms for microbial community analysis and engineering. These algorithms, including stoichiometric, machine-learning and statistical approaches will facilitate a “synthetic ecology” approach to help design strategies (e.g. microbial transplants or probiotic mixtures) for preventing and targeting microbiome-associated diseases. Our work will fill a major gap in current microbiome research, creating the first platform for global microbial interaction data integration, mining and computation. Project Narrative Among the major developments of the genomic revolution has been the ability to identify thousands of microbial species and strains living in communities in 5 major habitats in the human body, and the recognition that the relative abundances of these populations is strongly correlated with environment: disease state, diet, treatment protocol and so on. A major challenge in utilizing the deluge of health relevant data is structuring it into a database that facilitates understanding inter-microbial interactions in these communities. The aim of this proposal is to create a database and integrated computational platform, open to and contributed to by the research community, which will greatly accelerate the conversion of data into health related actionable knowledge.","A platform for mining, visualization and design of microbial interaction networks",9420621,R01GM121950,"['Affect', 'Algorithms', 'Cataloging', 'Catalogs', 'Cell model', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Development', 'Diet', 'Discipline', 'Disease', 'Ecology', 'Ecosystem', 'Empirical Research', 'Engineering', 'Environment', 'Evolution', 'Future', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Habitats', 'Health', 'Human Biology', 'Human Microbiome', 'Human body', 'Imagery', 'Individual', 'Intervention', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Mediating', 'Metabolic', 'Metabolism', 'Metadata', 'Methods', 'Microbe', 'Mining', 'Nature', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Preventive Medicine', 'Probiotics', 'Property', 'Research', 'Resources', 'Science', 'Scientist', 'Structure', 'Taxonomy', 'Technology', 'Therapeutic', 'Time', 'Transplantation', 'Treatment Protocols', 'Work', 'base', 'computer framework', 'data integration', 'data to knowledge', 'design', 'disease diagnosis', 'experimental study', 'feeding', 'genome-wide', 'genomic data', 'human disease', 'human microbiota', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microbiome research', 'microbiota transplantation', 'microorganism interaction', 'novel diagnostics', 'novel therapeutics', 'open source', 'outcome forecast', 'prevent', 'repository', 'simulation', 'tool', 'user-friendly']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2018,374683,61050884,-0.008315480054776607
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9542210,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting', 'whole slide imaging']",NIAMS,UNIVERSITY OF FLORIDA,R01,2018,377571,188894159,-0.0007847043277427809
"Smartphone phenotype collection for diagnostic screening of mild cognitive impairment Project Summary This project addresses a critical need for early detection of mild cognitive impairment (MCI) and other Alzheimer's-related dementias (ADRD). Advances in smartphone hardware, computer vision, and machine learning have enabled the possibility of producing smartphone-based cognitive testing applications able to collect electronic sensor data and transform it into highly informative phenotypes that can serve as early indicators of future disease progression. In this project, we aim to develop a revolutionary new smartphone- based cognitive testing platform, called CTX, that will enable the rapid development and deployment of smartphone-based tests that can capture raw sensor streams in a synchronized fashion, subsample and compress the combined streams, and transmit them to a cloud server for subsequent analysis and modeling. CTX will provide a high-level application development framework that will significantly reduce the time and technical knowledge required to produce a smartphone-based cognitive testing application by providing an application programming interface (API) that enables developers to simply declare what sensor data should be collected and when. The framework will handle all the details of collecting the sensor data, synchronizing it, and transmitting it to a back-end server. The API will also have a variety of other high-level features to facilitate development of cognitive test apps. To demonstrate the feasibility of our vision for CTX, in Aim 1 of this project we will develop the software framework, back-end server software and a prototype smartphone app to exercise and validate many of the platform's features. For Aim 2, we will develop three different tests for this app to test saccade (eye movement) latency, verbal recall, and wrist mobility, each collecting a different type of sensor data (video, audio, and inertial measurement). These tests were selected because their results have been been shown to be predictive of MCI. We will implement phenotype extraction pipelines that employ advanced signal processing, machine learning, and computer vision algorithms to extract the target phenotypes from the sensor data collected for these tests and demonstrate they operate with sufficient accuracy to replicate published experimental designs. Successful completion of this project will eliminate the need for expensive and cumbersome phenotype collection equipment (e.g., eye tracking stations) and create the possibility of generating data from which MCI onset can be predicted. Data collected in Phase II via these and other such tests will enable us to apply our machine learning expertise to produce models able to predict transition to MCI that are both sensitive and specific, transforming any smartphone into an MCI risk assessment tool available for at-home use by millions of people. Project Narrative This NIH Phase I project will address the critical need for early detection of Alzheimer's Disease (AD) and Alzheimer's-related dementias (ADRD) by developing a revolutionary new smartphone-based cognitive testing platform that will provide individuals with an ongoing status of their cognitive health. Doctors who are given access to the results of these tests will be able to monitor patients more closely and provide more timely diagnoses. By studying test results from many people, researchers may someday be able to identify patterns that can distinguish mild cognitive impairment from normative age-related cognitive decline.",Smartphone phenotype collection for diagnostic screening of mild cognitive impairment,9679400,R43AG062072,"['Achievement', 'Address', 'Adult', 'Age', 'Age-associated memory impairment', 'Algorithms', 'Alzheimer disease detection', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease model', 'Apple', 'Assessment tool', 'Back', 'Big Data', 'Cellular Phone', 'Cognitive', 'Collection', 'Computer Vision Systems', 'Computer software', 'Cyclophosphamide', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic tests', 'Disease Progression', 'Early Diagnosis', 'Elderly', 'Emotional', 'Equipment', 'Exercise', 'Exhibits', 'Experimental Designs', 'Eye', 'Eye Movements', 'Face', 'Facial Expression', 'Forearm', 'Frequencies', 'Future', 'Genetic Risk', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Image', 'Individual', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Memory impairment', 'Methods', 'Modeling', 'Monitor', 'Patient Monitoring', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Publishing', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Risk Assessment', 'Rotation', 'Saccades', 'Scanning', 'Secure', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Software Framework', 'Software Tools', 'Stream', 'Tablets', 'Telephone', 'Test Result', 'Testing', 'Time', 'United States National Institutes of Health', 'Vision', 'Visuospatial', 'Work', 'Wrist', 'Yang', 'age related', 'age related cognitive change', 'application programming interface', 'base', 'cloud platform', 'cognitive development', 'cognitive task', 'cognitive testing', 'cohort', 'cost', 'crowdsourcing', 'data modeling', 'diagnostic screening', 'interest', 'markov model', 'mild cognitive impairment', 'predictive modeling', 'prototype', 'response', 'screening', 'sensor', 'signal processing', 'smartphone Application', 'software development', 'success']",NIA,"PARABON NANOLABS, INC.",R43,2018,394297,0,-0.055696001411898476
"Joint Analysis of Microbiome and Other Genomic Data Types PROJECT SUMMARY In the same way that the human genome project created invaluable genomic maps, the objective of this project is to develop methods for eventual construction of comprehensive genetic and metabolomic by microbome relationship maps. Such maps would be an invaluable resource for improving our understanding as to the underlying mechanisms by which microbes and –omics features influence human diseases and conditions, potentially leading to identification of novel therapeutic targets. To these ends, this proposal seeks to develop statistical and computational tools for mapping associations and interactions between microbes and other – omic features and for further utilizing other –omics to improve microbiome based prediction models. Specifically, motivated by studies examining the role of the vaginal microbiome and other –omics in birth outcomes and menopause, we aim to develop statistical methodology for (1) mapping genetic variants that influence microbiome composition so as to understand the innate component of the microbiome as well as learn mechanisms by which genetics influence outcomes; (2) creating global metabolic maps integrating both microbes and metabolites which will enable understanding of how perturbations might influence the system and identify key pathways for therapeutic target; (3) exploiting other –omics in constructing more accurate microbiome based prediction models for preterm birth; (4) developing, distributing and supporting software packages for the proposed methods. The methods are based on frameworks in which we have considerable experience, but novel technical contributions are made to accommodate features of the data such as population stratification and relatedness in genetics, phylogenetic structure, and compositionality, as well as practical considerations such as availability of samples and other –omics data. Consequently, these new methods have the potential for accelerating mechanistic and translational microbiome studies, developing vital resources for enabling systematic achievement of many biological, clinical, and public health problems that have eluded researchers for decades. PROJECT NARRATIVE The methods developed in this proposal will enable improved understanding of the interactions between microbes and other –omics, thus aiding in elucidation of the mechanisms by which microbes and –omic features influence health outcomes and aiding in identification of potential molecular targets. Further emphasis is placed on utilization of other –omics to develop microbiome based prediction models in pregnancy outcomes, improving early detection of women who are at risk of preterm delivery.",Joint Analysis of Microbiome and Other Genomic Data Types,9577818,R01GM129512,"['Achievement', 'Address', 'Area', 'Automobile Driving', 'Biological', 'Birth', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Early Diagnosis', 'Future', 'Genes', 'Genetic', 'Genomics', 'Grouping', 'Health', 'Human Genome Project', 'Joints', 'Lasso', 'Learning', 'Machine Learning', 'Maintenance', 'Maps', 'Medical', 'Menopause', 'Metabolic', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Modification', 'Molecular Target', 'Network-based', 'Outcome', 'Pathway interactions', 'Performance', 'Phylogenetic Analysis', 'Pregnancy Outcome', 'Premature Birth', 'Procedures', 'Public Health', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Structure', 'System', 'Taxonomy', 'Training', 'Woman', 'Work', 'base', 'biological systems', 'computerized tools', 'experience', 'genetic variant', 'genomic data', 'human disease', 'improved', 'interest', 'loss of function', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microbiome analysis', 'microbiome components', 'microbiome composition', 'microbiome research', 'new therapeutic target', 'novel', 'open source', 'population stratification', 'predictive modeling', 'simulation', 'software development', 'therapeutic target', 'tool', 'translational study', 'user friendly software', 'vaginal microbiome']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2018,396000,758431960,-0.02170399766671971
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions Project Summary/Abstract People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. Project Narrative People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9644103,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Personal Satisfaction', 'Persons', 'Phase', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'manufacturability', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2018,519349,0,-0.027161380004603188
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9527181,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2018,545116,685608202,0.0032234255516245367
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9548627,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2018,573677,197030888,-0.005783915340385597
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9533373,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Anti-Tumor Necrosis Factor Therapy', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Big Data', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Individual', 'Injury', 'Institution', 'Intuition', 'Leukocyte Chemotaxis', 'Lymphocyte Immunophenotypings', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Myocardial', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Sampling', 'Series', 'Stains', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'base', 'clinical diagnostics', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'human disease', 'improved', 'inquiry-based learning', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2018,787091,3808719,0.01589493525220291
"iFACS: Imaging Florescence Activated Cell Sorter to sort cells based on images iFACS: Imaging Florescence Activated Cell Sorter to sort cells based on images NanoCellect Biomedical, Inc. RESEARCH & RELATED Other Project Information 7. PROJECT SUMMARY Advances in reagents (e.g. CRiSPR) and analytical tools (e.g. flow cytometers) have improved the ability to alter and characterize cellular phenotypes. Ultimately, many key applications in biomedicine require efficient and accurate isolation of cell populations according to features contained in high content images. Unfortunately, microscopic laser microdissection systems have a throughput that is too slow to be practical in many applications; while the existing flow cytometers that can sort cells (fluorescence-activated cell sorters or FACS) provide only size, internal complexity, and fluorescence intensity information and lack the rich data of imaging. Another critical limitation is that the existing flow cytometers that can image, cannot sort cells. NanoCellect has made a highly affordable FACS to increase access to this important high-throughput tool for cell analysis. Here we propose to enhance our existing low-cost FACS with the ability to image cells and sort them based on image features. This will allow users to pursue new strategies in drug screening and mechanism of action research; as well as work with suspension cell lines, such as those that dominate the recent advances in immuno-oncology. In Phase I research, we have demonstrated the world's first imaging flow cytometer with cell sorting capabilities (iFACS) in a unique design of space-time coding with an optical spatial filter. The approach adds negligible cost to the system for the desirable features of cell imaging and sorting. To fully realize the enormous potential of the design and to meet the demands for most applications, in Phase II we will develop high-throughput image-based cell sorting with innovative image-guided gating schemes supported by machine learning and interactive user/machine interface. Essentially, image-based flow cytometry gating uses similar cell isolation criteria as the techniques of laser capture microdissection or cell aspiration to isolate cells of interest, with 10,000X throughput improvements to 1000+ cells per second. We envision such unique capabilities will become common, default features for tomorrow's users as the tool becomes as intuitive and ubiquitous as fluorescent microscopy. The proposed iFACS will be transformative and benefit numerous biomedical applications, such as isolation of cells based on organelle translocation, cell cycle analyses, detection and counting of phagocytosed particles, and protein co-localization, to name just a few. iFACS: Imaging Florescence Activated Cell Sorter to sort cells based on images NanoCellect Biomedical, Inc. RESEARCH & RELATED Other Project Information 8. PROJECT NARRATIVE The advances proposed here will allow NanoCellect to achieve its mission: to advance image-based fluorescence-activated cell sorting technology that can be placed in an affordable bench-top device. This will be achieved by integrating cell-imaging and cell-sorting, and relevant software into an easy-to-use package that extends the features of the existing WOLF® Cell Sorter.",iFACS: Imaging Florescence Activated Cell Sorter to sort cells based on images,9572551,R44DA042636,"['Action Research', 'Adopted', 'Algorithmic Software', 'Back', 'Benchmarking', 'Cell Cycle', 'Cell Line', 'Cell Separation', 'Cell Size', 'Cells', 'Cellular biology', 'Chromatin', 'Code', 'Computer software', 'Data', 'Detection', 'Devices', 'Dexamethasone', 'Drug Screening', 'Flow Cytometry', 'Fluorescence', 'Fluorescence-Activated Cell Sorting', 'Frequencies', 'Glucocorticoid Receptor', 'Histones', 'Image', 'Image Analysis', 'Immunooncology', 'Individual', 'Intuition', 'Lasers', 'Liquid substance', 'Machine Learning', 'Measures', 'Membrane', 'Methodology', 'Microdissection', 'Microfluidics', 'Microscopic', 'Microscopy', 'Mission', 'Mitosis', 'Morphology', 'Motion', 'Names', 'Nuclear', 'Optics', 'Organelles', 'Patients', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Phorbol Esters', 'Photons', 'Physiological', 'Population', 'Proteins', 'Reagent', 'Reporter', 'Research', 'Sampling', 'Scheme', 'Sorting - Cell Movement', 'Structure', 'Suspensions', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tube', 'Validation', 'Work', 'analytical tool', 'base', 'cellular imaging', 'commercialization', 'cost', 'design', 'detector', 'drug mechanism', 'experience', 'experimental study', 'fluorescence activated cell sorter device', 'gene therapy', 'high throughput analysis', 'image guided', 'image processing', 'imaging capabilities', 'improved', 'innovation', 'interest', 'laser capture microdissection', 'optical imaging', 'particle', 'photomultiplier', 'prevent', 'protein kinase C gamma', 'prototype', 'response', 'screening', 'sensor', 'tool']",NIDA,"NANOCELLECT BIOMEDICAL, INC.",R44,2018,794381,745884,0.0073613160263925346
"Identifying individuals at risk of progression to active tuberculosis Project Summary Almost 2 billion people are infected with Mycobacterium tuberculosis (Mtb), the causative agent of tuberculosis (TB). Approximately 10% of these individuals will progress to active TB disease over their lifetimes, but there is currently no clinical test to distinguish those that will progress to active TB disease, from those that will not. If we are to realize the World Health Organization's (WHO) goal of a world free of TB by 2035, the massive reservoir of TB infection must be addressed with a cost-effective, ethical therapy for preventing progression, based on treating only those most likely to progress. A diagnostic test that can accurately predict the risk of progression is critical for treating these high-risk individuals and the eradication of TB. Our goal is to develop such an assay. Our central hypothesis is that five independent host immune biomarkers, combined into a single multimetric signature will predict progression from latent to active TB with at least 90% sensitivity and specificity. We will test this hypothesis and achieve our goal by implementing the following specific aims: Aim 1: Compile a comprehensive dataset of biomarkers in a prospective cohort of individuals who are at risk of progressing to active TB. Working with the Moldova Ministry of Health's National TB Program, we will enroll 3,685 close contacts of active TB cases. All participants will be followed for two years to determine who progresses to active TB. We expect to identify ≥ 140 progressors. We will assess three previously established blood-based predictors of active TB progression, and two novel assays. We will verify the performance of previously published biomarkers in this population to discriminate progressors from non-progressors and identify new candidate biomarkers using RNA-Seq of antigen stimulated PBMC and detection of Mtb-peptides by NanoDisk MS. Aim 2: Use a discovery set of samples to develop predictive models of progression to active TB. Using data from 140 progressors and 140 non-progressors from Aim 1 we will (1) Verify the performance of existing biomarkers, (2) Use a cross-validation to identify new candidate biomarkers, and (3) derive predictive models using logistic regression and machine learning methods to identify optimal biomarker signatures that best predict progression to active TB within 12 months. Aim 3: Verify the ability of the model to predict progression to active TB disease. Using the same approach as Aim 1, we will enroll a new set of 1,340 household contacts of active TB and identify at least 60 progressors and 60 matched non-progressors and verify clinically the sensitivity/specificity of our models and biosignatures (Aim 2) to predict progression to active disease. A combined host biomarker signature that can predict TB progression from a small blood volume will have significant impact on the WHO End TB Program. PROJECT NARRATIVE Almost 2 billion people are infected with Mycobacterium tuberculosis, the causative agent of tuberculosis (TB). Approximately 10% of these individuals will progress to active TB disease over their lifetimes, but there is currently no test to distinguish those that will progress from those that will not. We propose to develop a multimetric signature of host biomarkers that together will have a sensitivity and specificity of ≥ 90% for predicting progression to active TB in one year, a critical first step to developing cost-effective and ethical treatment plans in order to reach the World Health Organization goal of Ending TB by 2035.",Identifying individuals at risk of progression to active tuberculosis,9501395,R01AI137681,"['Address', 'Algorithms', 'Antigens', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Volume', 'Cells', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Sensitivity', 'Data', 'Data Set', 'Detection', 'Diagnostic tests', 'Disease', 'Enrollment', 'Ethics', 'Event', 'Filtration', 'Flow Cytometry', 'Foundations', 'Freezing', 'Frequencies', 'Gender', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Goals', 'Health', 'Household', 'Immune', 'Immune response', 'Immunologic Markers', 'Individual', 'Interferon-alpha', 'Logistic Regressions', 'Lymphocyte', 'Machine Learning', 'Modeling', 'Moldova', 'Mycobacterium tuberculosis', 'Mycobacterium tuberculosis antigens', 'National Health Programs', 'Organizational Objectives', 'Outcomes Research', 'Participant', 'Patients', 'Peptide Fragments', 'Peptides', 'Performance', 'Peripheral Blood Mononuclear Cell', 'Plasma', 'Population', 'Procedures', 'Production', 'Prospective cohort', 'Proteins', 'Publications', 'Publishing', 'RNA', 'Research Personnel', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Specificity', 'T cell response', 'T-Lymphocyte', 'Testing', 'Tuberculosis', 'Validation', 'World Health Organization', 'age group', 'base', 'biobank', 'biomarker performance', 'biosignature', 'blood-based biomarker', 'candidate marker', 'clinical Diagnosis', 'cohort', 'cost effective', 'deep neural network', 'enzyme linked immunospot assay', 'falls', 'follow-up', 'forest', 'high risk', 'indexing', 'innovation', 'learning network', 'learning strategy', 'monocyte', 'nanodisk', 'novel', 'novel diagnostics', 'predictive modeling', 'predictive test', 'prevent', 'programs', 'research clinical testing', 'transcriptome sequencing', 'transmission process', 'treatment planning']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2018,798023,524978793,0.01651517394111411
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,9502903,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2018,879004,46216755,-0.023479316341423508
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9478117,U54AI117924,"['Address', 'Biological', 'Blood coagulation', 'Breast Cancer Risk Factor', 'Clinical', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'biomedical scientist', 'clinical investigation', 'clinical predictors', 'education research', 'graduate student', 'high dimensionality', 'improved', 'innovation', 'interest', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning', 'undergraduate student']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2018,897471,338121506,0.0021259529763443734
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,9577245,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'multidisciplinary', 'pathogen', 'point of care', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2018,1329765,51931732,0.004959573977544058
"Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria PROJECT SUMMARY Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacterial infections are increasing in incidence and novel antibiotics are urgently needed to combat this growing threat to public health. A major roadblock to the development of novel antibiotics is our poor understanding of the structural features of small molecules that correlate with bacterial penetration and efflux. As a result, while potent biochemical inhibitors can often be identified for new targets, developing them into compounds with whole-cell antibacterial activity has proven challenging. To address this critical problem, we propose herein a comprehensive, multidisciplinary approach to develop quantitative models to predict small-molecule penetration and efflux in Gram-negative bacteria. We have pioneered a general platform for systematic, quantitative evaluation of small-molecule accumulation in bacteria, using label-free LC-MS/MS detection and multivariate cheminformatic analysis. We have also developed unique isogenic strain sets of wild-type, hyperporinated, efflux-knockout, and doubly-compromised E. coli, P. aeruginosa, and A. baumannii that allow us to dissect the individual contributions of outer/inner membrane penetration and active efflux to net accumulation, using a kinetic model that accurately recapitulates available experimental data. Moreover, we have developed machine learning and neural network approaches to QSAR (quantitative structure–activity relationship) modeling of pharmacological properties that will now be used to develop predictive cheminformatic models for Gram-negative accumulation, penetration, and efflux. This project will be carried out by a multidisciplinary SPEAR-GN Project Team (Small-molecule Penetration & Efflux in Antibiotic-Resistant Gram-Negatives, “speargun”) involving the labs of Derek Tan (MSK, PI), Helen Zgurskaya (OU, PI), Bradley Sherborne (Merck, Lead Collaborator), Valentin Rybenkov (OU, Co-I), Adam Duerfeldt (OU, Co-I), Carl Balibar (Merck, Collaborator), and David McLaren (Merck, Collaborator), comprising extensive combined expertise in organic and diversity-oriented synthesis, biochemistry, microbiology, high- throughput screening, mass spectrometry, biophysical modeling, cheminformatics, and medicinal chemistry. Herein, we will design and synthesize chemical libraries with diverse structural and physicochemical properties; analyze their accumulation in the isogenic strain sets in both high-throughput and high-density assay formats; extract kinetic parameters for penetration and efflux from the resulting experimental datasets; develop and validate robust QSAR models for accumulation, penetration, and efflux; and demonstrate the utility of these models in medicinal chemistry campaigns to develop novel Gram-negative antibiotics against three targets. This project will provide a major advance in the field of antibacterial drug discovery, providing powerful enabling tools to the scientific community to address this major threat to public health. PUBLIC HEALTH RELEVANCE Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacteria pose a growing threat to public health in the U.S. and globally. A major obstacle to the development of new antibiotics to combat such infections is our poor understanding of the chemical requirements for small molecules to enter Gram-negative cells and to avoid ejection by efflux pumps. The proposed comprehensive, multidisciplinary research program aims to develop predictive computational tools to identify such molecules by carrying out large-scale, quantitative analyses of the accumulation of diverse small molecules in Gram-negative bacteria. These tools will then enable medicinal chemistry campaigns to develop novel antibiotics.",Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria,9486312,R01AI136795,"['Acinetobacter baumannii', 'Address', 'Algorithmic Software', 'Anti-Bacterial Agents', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Bacteria', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Availability', 'Biological Neural Networks', 'Cells', 'Chemicals', 'Communities', 'Data', 'Data Set', 'Detection', 'Development', 'Effectiveness', 'Escherichia coli', 'Gram-Negative Bacteria', 'Gram-Negative Bacterial Infections', 'Human', 'Incidence', 'Individual', 'Infection', 'Interdisciplinary Study', 'Kinetics', 'Knock-out', 'Label', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Membrane', 'Microbiology', 'Modeling', 'Oral', 'Partner in relationship', 'Penetration', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Property', 'Pseudomonas aeruginosa', 'Public Health', 'Quantitative Evaluations', 'Quantitative Structure-Activity Relationship', 'Role', 'Structure', 'Testing', 'Variant', 'analog', 'base', 'biophysical model', 'cell envelope', 'cheminformatics', 'combat', 'computerized tools', 'density', 'design', 'drug discovery', 'efflux pump', 'high throughput screening', 'improved', 'inhibitor/antagonist', 'interdisciplinary approach', 'lead optimization', 'learning network', 'multidisciplinary', 'novel', 'predictive modeling', 'programs', 'prospective', 'public health relevance', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool']",NIAID,SLOAN-KETTERING INST CAN RESEARCH,R01,2018,1527746,185946435,-0.01827211596627451
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9266344,U54AI117924,"['Address', 'Biological', 'Blood coagulation', 'Clinical', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'biomedical scientist', 'clinical investigation', 'clinical predictors', 'education research', 'graduate student', 'high dimensionality', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning', 'undergraduate student']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2017,18271,338121506,0.0021259529763443734
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9544350,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,25000,5161939,-0.0006179874470693047
"Development of integrative models for early liver toxicity assessment ﻿    DESCRIPTION (provided by applicant): Computational toxicology has become a critical area of research due to the burgeoning need to evaluate thousands of pharmaceutical and environmental chemicals with unknown toxicity profiles, the high demand in time and resources by current experimental toxicity testing, and the growing ethical concerns over animal use in toxicity studies. Despite tremendous efforts, little success has been attained thus far in the development of predictive computational models for toxicity, primarily due to the complexity of toxicity mechanisms as well as the lack of high-quality experimental data for model development.  A critical challenge in toxicity testing of chemicals is that toxicity effects are doe-dependent: the true toxic hits may show no toxicity at all at low dose level. Therefore, traditiona high-throughput screening (HTS) that test chemicals only at a single concentration is not suitable for toxicity screening. On the contrary, the recently developed quantitative high-throughput screening (qHTS) platforms can evaluate each chemical across a broad range of concentrations, and is gaining ever-increasing popularity as a tool for in vitro toxicity profiling The concentration-response information generated by qHTS are expected to provide more accurate and comprehensive information of the toxicity effects of chemicals, offering promising data that can be mined to estimate in vivo toxicities of chemicals. However, our previous studies showed that if processed inappropriately, such concentration-response information contribute little to improve the toxicity prediction. This is especially true when multiple types of qHTS data are used together. Therefore, in this study, we will extend our previous approaches to develop novel statistical and computational tools that can curate, preprocess, and normalize the concentration-response information from multiple different qHTS databases.  Traditionally, toxicity models are based on either the chemical data (such as the quantitative structure- activity relationship analysis), or the in vitro toxicity profiling data (such as the in vitro-in vivo extrapolations). Our previous experiences suggested that integrating biological descriptors such as the in vitro cytotoxicity profiles or the short-term toxigenomic data, with chemical structural features is able to predict rodent acute liver toxicity with reasonable accuracy. Therefore, the second part of this proposal will be devoted to develop novel computational models for hepatotoxicity prediction by integrating qHTS toxicity profiles and chemical structural information In Aim 1, we will curate, preprocess, and normalize collected public liver toxicity datasets. In ths study, we will model toxicity effects using multiple large public datasets such as HTS and qHTS bioassay data (Tox21[1] and ToxCast[2]), hepatotoxicity side effect reports on marketed failed drugs[3], the Liver Toxicity Knowledge Base Benchmark Dataset (LTKB-BD[4]), etc. Statistical methods for cross-study validation and quality control will be applied to the collected datasets to ensure computational compatibility and to select the appropriate datasets for analysis. In Aim 2, we will develop predictive models for chemicals' liver toxicity based on an integrative modeling workflow that will make use of both structural and in vitro toxicity profiles of a chemical. Our previous studies [5] showed that models using both in vitro toxicity profiles and chemical structural data have better accuracy for rodent acute liver toxicity than models using either data type alone. Here, we will develop a novel modeling workflow that start with defining the functional clusters of chemicals via curated qHTS toxicity profiles, and is followed by developing computational models to correlate chemical and biological data with overall toxicity risks in humans. The predictive models will be validated using independent datasets with over 800 compounds. In Aim 3, we propose to prioritize the qHTS profiling assays used in the model for future toxicity testing. We will evaluate all the in vitro assays as biological descriptors from thee perspectives, including descriptor importance in the integrative toxicity model, correlation with i vivo DILI outcomes, and level of information content estimated by a novel approach based on network analysis. PUBLIC HEALTH RELEVANCE: In this study we aim to develop computational models that can identify potential liver toxicants. Liver toxicity is a significant contributor to the high attition rate in drug development. Moreover, toxic chemicals in food, water, and consumer products all pose serious risks for liver toxicity. As a result, there is great interest in developing high-throughput, high-content experimental and computational tools to evaluate the liver toxicity of thousands of pharmaceutical and environmental chemicals. This study focuses on developing novel informatics tools that enable the extraction and integration of chemical concentration-response information from multiple quantitative high-throughput screening databases for model development, and developing statistical models that are able to integrate this concentration-response information with chemical structural features to predict their risk of liver toxicity.  ",Development of integrative models for early liver toxicity assessment,9333370,R03ES026397,"['Acute', 'Address', 'Adverse effects', 'Algorithms', 'Animals', 'Area', 'Benchmarking', 'Biological', 'Biological Assay', 'Chemical Models', 'Chemicals', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Dose', 'Dreams', 'Ensure', 'Ethics', 'Food', 'Future', 'Gene Expression', 'Genomics', 'Goals', 'Gold', 'Hepatotoxicity', 'Human', 'In Vitro', 'Informatics', 'International', 'Liver', 'Machine Learning', 'Marketing', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Environmental Health Sciences', 'Nature', 'Network-based', 'North Carolina', 'Outcome', 'Pathway Analysis', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Poison', 'Process', 'Productivity', 'Quality Control', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Resources', 'Risk', 'Rodent', 'Scientist', 'Shapes', 'Statistical Methods', 'Statistical Models', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicogenetics', 'Toxicology', 'Translational Research', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'Universities', 'Variant', 'Water', 'base', 'computational toxicology', 'computerized tools', 'consumer product', 'cost', 'cost effective', 'cytotoxicity', 'data modeling', 'drug development', 'drug market', 'drug withdrawal', 'environmental chemical', 'experience', 'high throughput screening', 'improved', 'in vitro Assay', 'in vivo', 'interest', 'knowledge base', 'liver injury', 'model development', 'novel', 'novel strategies', 'preclinical study', 'predictive modeling', 'programs', 'public health relevance', 'response', 'screening', 'success', 'tool', 'toxicant', 'validation studies']",NIEHS,UT SOUTHWESTERN MEDICAL CENTER,R03,2017,81000,225463847,-0.026093136592836703
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9355633,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,100000,5161939,-0.0006179874470693047
"Discovery and characterization of novel ciliopathy protein complexes Abstract Ciliopathies are a collection of debilitating developmental disorders (e.g. Joubert syndrome, Meckel syndrome, Bardet-Biedl syndrome, orofaciodigital syndrome, polycystic kidney disease) which have no cures and limited but expensive treatments. Diagnosis and treatment is complicated due to ciliopathies causing multisystem pathologies and having large variance in their clinical presentations potentially resulting in neural tube defects, orofacial clefting, obesity, polycystic kidneys, retinal degeneration and in some cases, infant death. All ciliopathies are caused by dysfunctional cilia, the microtubule based organelle critical for cell-to-cell signaling, but currently there is limited understanding of the underlying molecular network responsible for proper cilia function. Recently, large-scale proteomic techniques have advanced where it is now possible to query the cell's molecular network and identify many new protein complexes. This proposal describes a research program that will 1) construct a ciliary complex map using proteomic techniques, 2) functionally characterize newly discovered ciliary complexes and 3) identify disruptions in complex assembly due to known ciliopathy mutations. Additional products of the proposed research will include a compendium of proteomic data on ciliated cells, statistical analysis tools for the discovery of protein complexes, functional characterization of critical ciliary processes and a more complete understanding of the underlying molecular network of ciliopathy disease states. This work aims to provide an important perspective of cilia biology in order to better understand the complex etiology and molecular causes of ciliopathies and potentially open new therapeutic avenues. Project Narrative Ciliopathies are a class of debilitating birth defects without known cures and limited but expensive treatments. Currently, we lack understanding of the underlying molecular network in ciliopathy patient cells and know even less about the causes of clinical presentations in ciliopathy patients. I propose to discover the differences in the molecular network between healthy cells and ciliopathy patient cells in an effort to better understand the molecular causes of clinical presentations possibly open new avenues for therapeutics.""""""",Discovery and characterization of novel ciliopathy protein complexes,9371331,K99HD092613,"['Affect', 'Alleles', 'Alpha Cell', 'Animal Model', 'Bardet-Biedl Syndrome', 'Biochemical', 'Biological', 'Biological Models', 'Biology', 'Cells', 'Cilia', 'Cilium Microtubule', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collection', 'Complement', 'Complex', 'Computational Biology', 'Congenital Abnormality', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Developmental Cell Biology', 'Diagnosis', 'Disease', 'Embryo', 'Etiology', 'Exhibits', 'Fractionation', 'Future', 'Gene Transfer Techniques', 'Human', 'Ion Exchange', 'Joubert syndrome', 'Link', 'Machine Learning', 'Maintenance', 'Maps', 'Mass Spectrum Analysis', 'Mentors', 'Molecular', 'Molecular Sieve Chromatography', 'Mus', 'Mutation', 'Neural Tube Defects', 'Obesity', 'Organelles', 'Orofaciodigital Syndromes', 'Pathology', 'Patients', 'Polycystic Kidney Diseases', 'Property', 'Proteins', 'Proteomics', 'Rana', 'Recording of previous events', 'Regulation', 'Research', 'Retinal Degeneration', 'Role', 'Sea Anemones', 'Sea Urchins', 'Severity of illness', 'Signal Transduction', 'Statistical Data Interpretation', 'Structural Models', 'Structure of ciliary processes', 'Syndrome', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Tissue Microarray', 'Tissues', 'Training', 'Work', 'Xenopus laevis', 'base', 'cell type', 'ciliopathy', 'clinically relevant', 'developmental disease', 'educational atmosphere', 'fly', 'human disease', 'in vivo', 'in vivo imaging', 'infant death', 'insight', 'loss of function', 'novel', 'novel therapeutics', 'orofacial cleft', 'particle', 'programs', 'protein complex', 'protein function', 'skills', 'success', 'tool']",NICHD,"UNIVERSITY OF TEXAS, AUSTIN",K99,2017,100205,91740242,-0.03984643661202651
"Optimizing electrical impedance myography outcomes through data mining Project summary  Electrical impedance myography (EIM) is a non-invasive technology for the assessment of muscle that is based on the application of a weak, high frequency electrical current to a muscle and the measurement of the resulting surface voltages. The further development and application of EIM remains the main business focus of Skulpt, Inc, a small business concern based in Boston and San Francisco (Specific Aims just say San Francisco). Alterations to the condition of the muscle, including myocyte atrophy, fat and connective tissue deposition, and inflammation all alter the EIM data in predictable and consistent ways. To date, through Skulpt, EIM has been applied as a potential biomarker for assessing disease progression and response to therapy in a wide variety of neuromuscular disorders, including amyotrophic lateral sclerosis, Duchenne muscular dystrophy, and spinal muscular atrophy, as well as other disorders that impact muscle condition, such as disuse atrophy and sarcopenia (age related muscle loss); over 1000 people have been studied with Skulpt’s EIM technology. Whereas the results of these applications are promising, the analytic approaches taken to the data sets have been fairly basic, utilizing only simple single frequency or simplistic multifrequency values. However, with every single muscle measurement, over 240 individual data points are acquired at different frequencies, different depths of muscle penetration, and at different angles to the major muscle fiber direction. Moreover, each of the above studies has been done in isolation, and thus how results differ between diseases is unknown. Given the plethora of data, applying more sophisticated analytic approaches has the potential of yielding improved EIM measures. Moreover, collaborators have already collected an associated wealth of animal EIM data that will help further inform this analysis. Thus, in this proposed Phase 1 SBIR, we plan to apply a variety of data mining techniques to the vast set of data already accumulated at Skulpt, Inc such that improved EIM outcomes can be developed and implemented. In Specific Aim 1, we will study human data across all disease types evaluated to determine which data sets are most effective at discriminating diseased from healthy muscle as well as distinguishing between diseases. In Specific Aim 2, we will focus on finding the metrics that are most sensitive to the degree of muscle pathology in a specific disease. In both of these aims, we will evaluate how these new metrics are mirrored in already obtained animal data. In Specific Aim 3, we will study these metrics in a new set of data (a test set) that was not used to develop the analytical paradigms so as to ensure their robustness. With the conclusion of this work, we will plan to pursue a Phase 2 SBIR that will focus on the development of a software suite to assist in EIM data interpretation based upon these results followed by a prospective observational clinical study to evaluate the efficacy of these newly developed metrics for disease diagnosis and tracking of progression/response to therapy. Project Narrative  Electrical impedance myography (EIM) is a non-invasive technology for the assessment of muscle that remains the main focus of Skulpt, Inc. Considerable EIM data has already been collected in a variety of neuromuscular diseases. In this study, the investigators plan to perform a more detailed analysis of all data collected to date (so-called “data mining”), such that improved EIM outcomes can be developed that will be applied to future studies.",Optimizing electrical impedance myography outcomes through data mining,9466075,R43AR073114,"['Age', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Animals', 'Area', 'Atrophic', 'Back Pain', 'Boston', 'Businesses', 'Categories', 'Characteristics', 'Clinical', 'Clinical Research', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Set', 'Deposition', 'Development', 'Diagnostic', 'Disease', 'Disease Progression', 'Disease model', 'Disease remission', 'Disuse Atrophy', 'Duchenne muscular dystrophy', 'Electrodes', 'Electrophysiology (science)', 'Ensure', 'Fatty acid glycerol esters', 'Fiber', 'Frequencies', 'Functional disorder', 'Funding', 'Future', 'Glycogen storage disease type II', 'Health', 'Inclusion Bodies', 'Individual', 'Inflammation', 'Laboratories', 'Machine Learning', 'Measurement', 'Measures', 'Medical Technology', 'Methods', 'Mining', 'Muscle', 'Muscle Cells', 'Muscle Fibers', 'Muscular Dystrophies', 'Musculoskeletal', 'Myography', 'Myopathy', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Penetration', 'Phase', 'Play', 'Positioning Attribute', 'Radiculopathy', 'Research Personnel', 'Role', 'San Francisco', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Tissues', 'Validation', 'Work', 'animal data', 'base', 'commercialization', 'data mining', 'disease classification', 'disease diagnosis', 'electric impedance', 'human data', 'improved', 'indexing', 'neuromuscular', 'potential biomarker', 'prospective', 'response', 'sarcopenia', 'voltage']",NIAMS,"MYOLEX, INC.",R43,2017,149998,869698,-0.001186910829734032
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions Project Summary/Abstract People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. Project Narrative People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9407137,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Persons', 'Phase', 'Phonation', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2017,159267,0,-0.027161380004603188
"Towards automated phenotyping in epilepsy Over 5 million children and adults in the United States have had a diagnosis of epilepsy or a seizure disorder. However, treatment options for the epilepsies remain inadequate, because many patients suffer from uncontrolled seizures and from the negative side effects of treatment. A major obstacle to the faster development of new anti-convulsant therapies is the fact that rigorous preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). We propose to test if it is possible to perform objective, inexpensive and automated phenotyping of mice in various mouse models of acquired and genetic epilepsies. The approach rests on the recent recognition that mouse behaviors are structured in stereotyped modules at sub-second timescales that are arranged according to specific rules. These characteristic behavioral modules, and the transitions between them, can be identified without observer bias by combined 3D imaging and machine learning (ML) -assisted analytic methods. We propose to adopt this novel ML-assisted 3D video analysis technology to epilepsy research, in order to test if it can be used to identify mice with chronic temporal lobe epilepsy (TLE) during inter-ictal and ictal periods in two distinct experimental TLE models, and under various experimental conditions. In addition, we will also test whether the approach is able to automatically detect not only the overtly epileptic mice in a genetic model of severe childhood epilepsy (homozygous voltage-gated sodium channel β-subunit SCN1B-/- knock-out mice), but also distinguish the seemingly normal, non-epileptic, SCN1B+/- heterozygous mice from the wild-type controls. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user-independent, inexpensive analysis of acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will test if it is possible to objectively characterize epileptic phenotypes in mice using a breakthrough technology involving machine learning-assisted analysis of 3-dimensional video data of behavior. If successful, this innovative approach is expected to dramatically accelerate epilepsy research by enabling the objective, automated, inexpensive phenotyping of experimental animals to aid the testing of novel anticonvulsant therapies.",Towards automated phenotyping in epilepsy,9369284,R21NS102908,"['Adopted', 'Adult', 'Adverse effects', 'Animal Behavior', 'Animal Model', 'Animals', 'Anticonvulsants', 'Behavior', 'Behavioral', 'Characteristics', 'Child', 'Childhood', 'Chronic', 'Complex', 'Data', 'Development', 'Diagnosis', 'Electroencephalography', 'Epilepsy', 'Exhibits', 'Frequencies', 'Genetic', 'Genetic Models', 'Hippocampus (Brain)', 'Human', 'Human immunodeficiency virus test', 'Image', 'Knockout Mice', 'Machine Learning', 'Modeling', 'Monitor', 'Mus', 'Neurons', 'Observer Variation', 'Patients', 'Phenotype', 'Pilocarpine', 'Probability', 'Recurrence', 'Research', 'Rest', 'Seizures', 'Sodium Channel', 'Stereotyping', 'Structure', 'Syndrome', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Translational Research', 'United States', 'Wild Type Mouse', 'analytical method', 'base', 'cost', 'evidence base', 'high throughput analysis', 'innovation', 'kainate', 'learning strategy', 'mouse model', 'novel', 'novel therapeutics', 'pre-clinical', 'voltage']",NINDS,STANFORD UNIVERSITY,R21,2017,197528,560644462,-0.0008948635261738583
"SWIFT-ActiveScreener: research and development of an intelligent web-based document screening system Project Summary More than 4,000 systematic reviews are performed each year in the fields of environmental health and evidence- based medicine, with each review requiring, on average, between six months to one year of effort to complete. In order to remain accurate, systematic reviews require regular updates after their initial publication, with most reviews out of date within five years. In the screening phase of systematic review, researchers use detailed inclusion/exclusion criteria to decide whether each article in a set of candidate citations is relevant to the research question under consideration. For each article considered, a researcher reads the title and abstract and evaluates its content with respect to the prespecified criteria. A typical review may require screening thousands or tens of thousands of articles in this manner. Under the assumption that it takes a skilled reviewer 30-90 seconds, on average, to screen a single abstract, dual-screening a set of 10,000 abstracts may require between 150 to 500 hours of labor. We have shown in previous work that automated machine learning methods for article prioritization can reduce by more than 50% the human effort required to screen articles for inclusion in a systematic review. Recently, we have further extended these methods and packaged them into a web-based, collaborative systematic review software application called SWIFT-Active Screener. Active Screener has been used successfully to reduce the effort required to screen articles for systematic reviews conducted at a variety of organizations including the National Institute of Environmental Health Science (NIEHS), the United States Environmental Protection Agency (EPA), the United States Department of Agriculture (USDA), The Endocrine Disruption Exchange (TEDX), and the Evidence Based Toxicology Collaboration (EBTC). These early adopters have provided us with an abundance of useful data and user feedback, and we have identified several areas where we can continue to improve our methods and software. Our goal for the current proposal is to conduct additional research and development to make significant improvements to SWIFT-Active Screener, including several innovations that will be necessary for commercial success. The research we propose encompasses three specific aims: (1) Investigate several improvements to statistical algorithms used for article prioritization and recall estimation. We will explore promising avenues for further improving the performance of our existing algorithms and address critical technical issues that limit the applicability of our current methods (Aim 1 – Improved Statistical Models). (2) Explore ways in which we can improve our models and methods to handle the scenario in which an existing systematic review is updated with new data several years after its initial publication (Aim 2 – New Methods for Systematic Review Updates). (3) Investigate several questions related to scaling the system to support hundreds to thousands of simultaneous screeners (Aim 3 - Software Engineering for Scalability, Usability and Full Text Extraction). Project Narrative Systematic review is a formal process used widely in evidence-based medicine and environmental health research to identify, assess, and integrate the primary scientific literature with the goal of answering a specific, targeted question in pursuit of the current scientific consensus. By conducting research and development to build a web-based, collaborative systematic review software application that uses machine learning to prioritize documents for screening, we will make an important contribution toward ongoing efforts to automate systematic review. These efforts will serve to make systematic reviews both more efficient to produce and less expensive to maintain, a result which will greatly accelerate the process by which scientific consensus is obtained in a variety of medical and health-related disciplines having great public significance.",SWIFT-ActiveScreener: research and development of an intelligent web-based document screening system,9467160,R43ES029001,"['Address', 'Algorithms', 'Area', 'Collaborations', 'Computer software', 'Consensus', 'Data', 'Discipline', 'Endocrine disruption', 'Environmental Health', 'Evidence Based Medicine', 'Exclusion Criteria', 'Feedback', 'Goals', 'Health', 'Hour', 'Human', 'Literature', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'National Institute of Environmental Health Sciences', 'Online Systems', 'Performance', 'Phase', 'Process', 'Publications', 'Research', 'Research Personnel', 'Software Engineering', 'Statistical Algorithm', 'Statistical Models', 'System', 'Text', 'Toxicology', 'United States Department of Agriculture', 'United States Environmental Protection Agency', 'Update', 'Work', 'evidence base', 'improved', 'innovation', 'learning strategy', 'research and development', 'screening', 'success', 'systematic review', 'usability']",NIEHS,"SCIOME, LLC",R43,2017,211900,2510992,0.00399793700645379
"Software for OCT Analysis of Vascular Stents Software for OCT Analysis of Vascular Stents PI: Ronny Shalev, PhD, Dyad Medical Summary Dyad Medical, Inc. will create intravascular OCT (IVOCT) software for clinical, live time determination of stent apposition (OCTivat-live, the live time OCT image visualization and analysis tool) and for offline analysis of stent implantation (OCTivat-stent). Every year, 100s of thousands of patients in the US are treated with intra- vascular stents creating an opportunity for both solutions. Although advancements such as drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent design parameters include drug, material (bioresorbable vs metal), polymer composition, coatings to stimulate cell coverage, etc. To opti- mize designs, sensitive, in vivo assessments are needed for preclinical and clinical evaluations. Intravascular OCT (IVOCT) is the lone imaging modality with the resolution and contrast to meet this challenge. The Core Lab at CWRU is the premiere site in the world for manual analysis of IVOCT image data. A cardiologist analyst takes 6-16 hrs to analyze manually a single stent, and despite training and quality assurance measures, inter- analyst variability can limit the power to determine changes between stent designs. Building upon work at CWRU, we will develop advanced, highly automated software to greatly speed analysis, improve reproducibil- ity, increase accuracy, and harmonize analysis. Software will reduce costs by decreasing manual labor, and with improved reproducibility, possibly enable the use of historical data, eliminating cost of a control arm. Re- garding live time analysis, rather than manually reviewing >500 images in a pullback, with fast software, it will be possible to present the number and location of malapposed struts in 3D, providing instant feedback to phy- sicians on the need for additional dilatation with a larger balloon or higher pressure. In addition, we will auto- matically determine stent and vessel area along the length of the pullback, allowing us to compute stent ex- pansion and eccentricity, quantitative measures related to successful stent deployment, the most important de- terminant of outcome. IVOCT could also play a role at patient follow up. If a stent is well covered, then long- term anti-platelet therapy might be unnecessary, minimizing bleeding risk. If a stent has many uncovered struts, a therapeutic might prevent stent thrombosis or stimulate healing. Project Narrative: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies and improved deployment for improved treatment of vascular dis- ease.",Software for OCT Analysis of Vascular Stents,9407267,R43HL137500,"['Agreement', 'Algorithms', 'Area', 'Blinded', 'Blood Vessels', 'Cells', 'Classification', 'Clinical', 'Clinical Trials', 'Code', 'Computer software', 'Data', 'Detection', 'Devices', 'Dilatation - action', 'Doctor of Philosophy', 'Feedback', 'Follow-Up Studies', 'Heart', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Implant', 'Institutes', 'International', 'Ions', 'Laboratories', 'Length', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Metals', 'Methods', 'Myocardial Ischemia', 'Needs Assessment', 'Outcome', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Play', 'Polymers', 'Process', 'Reproducibility', 'Research Personnel', 'Resolution', 'Risk', 'Role', 'Services', 'Site', 'Speed', 'Stents', 'Surrogate Markers', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Variant', 'Vascular Diseases', 'Work', 'arm', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'image visualization', 'imaging modality', 'implantation', 'improved', 'in vivo', 'personalized diagnostics', 'preclinical evaluation', 'pressure', 'prevent', 'prototype', 'quality assurance', 'research clinical testing', 'restenosis', 'statistics', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,"DYAD MEDICAL, INC.",R43,2017,224744,1085076,-0.002679833709235888
"A high-throughput imaging and classification system for fruit flies PROJECT SUMMARY / ABSTRACT In this Phase I SBIR application, FlySorter proposes to development a high throughput imaging and classification system to aid research with fruit flies, a widely-used model organism relevant to both basic science as well as studies in human health. The use of animal model systems is essential for research in almost all aspects of biology: genetics, development, neuroscience, disease, physiology, and beyond. The fruit fly – Drosophila melanogaster – is small and easy to care for, but is complex enough an organism to provide a wealth of information that directly relates to human biology and health. Over 75% of human diseases with a genetic basis (including depression, alcoholism, certain forms of cancer, and many more) are either present or have an analog in Drosophila. Modern genetic tools, such as CRISPR/cas9, allow the creation of transgenic flies that provide the opportunity to study diseases, pathways and systems that don’t exist naturally in Drosophila. With these advances, fruit flies are becoming more frequently subjects for drugs screens. For all the advances in the biological tools and techniques applicable to flies, however, the limiting factor in many experiments is the manual labor involved in a few common tasks: moving flies from vial to vial or other lab equipment; classifying and sorting flies by sex, eye color and other phenotypes; and collecting virgin female flies before they mate so that they can be used in controlled crosses, etc. FlySorter’s patent-pending fly dispensing mechanism can reliably deliver a single organism from a vial containing hundreds of awake flies, and our novel FlyPlate system allows storage of individual flies in custom 96 well plates. FlySorter’s robotic fly handling system, co-developed with the de Bivort Lab at Harvard, is capable of manipulating and transporting those individual flies between vial, 96 well plate, and experimental apparatus. The next piece of the automation puzzle to solve is high throughput imaging and classification. To accomplish this goal, FlySorter will: 1) complete a prototype automated image capture hardware system; 2) adapt state-of-the-art computer vision and machine learning algorithms for use on Drosophila; and 3) build a module that can physically sort the classified flies into different vials. Once integrated into the existing FlySorter product ecosystem, this imaging and classification module will greatly expand the kinds of experiments and screens that can be automated, allowing for the study of larger populations or a wider variety of flies, reducing the impact of human error, and freeing up valuable time for researchers. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are one of the most widely used model organisms in biology, for research in genetics, development, neuroscience, disease, and much more. One of the most common tasks in Drosophila labs is sorting flies by various markers and phenotypes using a microscope and paintbrush. FlySorter aims to build an automated system for sorting flies using high resolution digital cameras and modern computer vision algorithms, which will obviate the need for such tedious manual labor.",A high-throughput imaging and classification system for fruit flies,9408980,R43OD023302,"['Air', 'Alcoholism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animal Model', 'Animals', 'Appearance', 'Automation', 'Basic Science', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Neural Networks', 'Biology', 'CRISPR/Cas technology', 'Caring', 'Classification', 'Code', 'Complex', 'Computer Vision Systems', 'Custom', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Pathway', 'Dorsal', 'Drosophila genus', 'Drosophila melanogaster', 'Ecosystem', 'Ensure', 'Eye', 'Eye Color', 'Female', 'Floor', 'Genes', 'Genetic', 'Genetic Screening', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Head', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Legal patent', 'Lighting', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mechanics', 'Mental Depression', 'Methodology', 'Microscope', 'Modernization', 'Motor', 'Mutation', 'Names', 'Neurosciences', 'Obesity', 'Optics', 'Organism', 'Partner in relationship', 'Phase', 'Phenotype', 'Physiology', 'Population', 'Preclinical Drug Evaluation', 'Pump', 'Research', 'Research Personnel', 'Resolution', 'Robot', 'Robotics', 'Sampling', 'Sclera', 'Shapes', 'Small Business Innovation Research Grant', 'Sorting - Cell Movement', 'Standardization', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transgenic Organisms', 'Universities', 'Vial device', 'Walking', 'Work', 'analog', 'awake', 'base', 'depression model', 'digital', 'digital imaging', 'experimental study', 'fly', 'genetic strain', 'human disease', 'improved', 'interest', 'laboratory equipment', 'male', 'meter', 'novel', 'phenotypic biomarker', 'prevent', 'prototype', 'sex', 'tool', 'virtual']",OD,"FLYSORTER, LLC",R43,2017,225000,0,0.005093484189490689
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9303234,R00AG046911,"['Address', 'Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'imaging modality', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'public health relevance', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2017,249000,32532200,-0.0030342911147281334
"UVPD-MS Characterization of Lipopolysaccharides Abstract. Gram-negative bacteria have caused many of the most persistent infections as well as some of the deadliest pandemics in the world. Some strains have developed resistant to all available drugs, thus leading to increasing mortality from previously treatable bacterial infections. The National Strategy for Combating Antibiotic-Resistant Bacteria released by the White House in September 2014 focused on the need for (i) advancing the development of methods for identification and characterization of bacteria, (ii) accelerating basic research for new antibiotics, and (iii) improving capabilities for surveillance of antibiotic-resistant bacteria. This proposal focuses on the development of innovative tandem mass spectrometry approaches for characterization of lipopolysaccharides (LPS), the primary constituent of the outer membrane of Gram-negative bacteria that protects the membrane from chemical attack and is recognized by the immune system during pathogenic invasion. Structural characterization of LPS is critical to understanding how the structure of LPS influences immune stimulation as well as facilitating development of new antimicrobials and vaccines. This is a significant analytical challenge due to the branched structures and amphipathic properties of LPS. The escalating concerns about antibiotic resistance bacteria and the need for better avenues of defense against infectious diseases have motivated the proposed work. The objectives of this proposal are: Aim 1: Development of ultraviolet photodissociation (UVPD) mass spectrometry via hierarchical, decision-tree workflows for top-down characterization of LPS to facilitate high throughput analysis; Aim 2: Development of MS/MS approaches for serotyping of Gram-negative bacteria based on LPS; Aim 3: Examination of peptide/LPS interactions via native-spray mass spectrometry to provide both mechanistic information and screening capabilities for new antimicrobials, and Aim 4: Applications to a variety of structural problems related to the biosynthesis of LPS in Gram- negative bacteria and characterization of hybrid O-antigen/lipid A molecules in vesicle-based vaccines.  We have established a new collaboration with Dr. Bryan Davies' group to develop mass spectrometry methods to characterize peptide/lipid A interactions in support of the hunt for better antimicrobials. The continued collaboration with Dr. Stephen Trent's group emphasizes: (i) approaches for deciphering the biosynthetic pathways of bacterial LPS that endow them with the remarkable ability to re-design their outer membranes and develop antibiotic resistance, and (ii) innovative vaccine design based on antigenic LPS in vesicles.    Narrative: Gram-negative bacteria are responsible for some of the deadliest and more widespread pandemics in the world. The proposed work focuses on the development of advanced mass spectrometry approaches for characterization of complex lipopolysaccharides, including the endotoxic lipid A domains, that comprise the outer membrane of Gram-negative bacteria. The proposed work will be applied to evaluate new antimicrobials and support development of hybrid vaccines.",UVPD-MS Characterization of Lipopolysaccharides,9320998,R01GM103655,"['Acylation', 'Address', 'Advanced Development', 'Affinity', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Architecture', 'Bacteria', 'Bacterial Infections', 'Bacterial Vaccines', 'Basic Science', 'Binding', 'Catalogs', 'Cells', 'Chemical Warfare', 'Code', 'Collaborations', 'Combating Antibiotic Resistant Bacteria', 'Communicable Diseases', 'Complex', 'Complex Mixtures', 'Custom', 'Databases', 'Decision Trees', 'Development', 'Distal', 'Exhibits', 'Focus Groups', 'Glycolipids', 'Gram-Negative Bacteria', 'Hybrids', 'Hydrophobicity', 'Immune system', 'Immunization', 'Infection', 'Ions', 'Lipid A', 'Lipopolysaccharide Biosynthesis Pathway', 'Lipopolysaccharides', 'Mass Spectrum Analysis', 'Membrane', 'Methodology', 'Methods', 'Modification', 'Molecular', 'O Antigens', 'Oligosaccharides', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphorylation', 'Polysaccharides', 'Process', 'Production', 'Property', 'Publishing', 'Resistance', 'Serotyping', 'Structure', 'System', 'Tail', 'Vaccine Design', 'Vaccines', 'Variant', 'Vesicle', 'Virulence', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'cell envelope', 'design', 'high throughput analysis', 'hydrophilicity', 'improved', 'innovation', 'innovative technologies', 'inorganic phosphate', 'instrument', 'method development', 'mortality', 'novel', 'novel therapeutics', 'pandemic disease', 'response', 'screening', 'sugar', 'tandem mass spectrometry', 'ultraviolet']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2017,297043,91740242,-0.011252393542071502
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9150601,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2017,326571,7208224,0.027073322220375878
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris�n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris�n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9264531,R01EY023279,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Categories', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Morphology', 'Nerve Fibers', 'Ophthalmoscopes', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'United States National Institutes of Health', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2017,339750,193405667,-0.0011073338999810231
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9260548,R01GM120033,"['Address', 'Algorithms', 'Alpha Cell', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cancer Etiology', 'Cardiovascular system', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical practice', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2017,356625,323604360,0.011753235746555743
"A platform for mining, visualization and design of microbial interaction networks Project Summary One of the burning questions in the study of the human microbiome is whether and how it is possible to design specific strategies for rebalancing the taxonomic and functional properties of human-associated microbial communities, triggering the transition from “disease states” to “healthy states”. While empirical studies provide strong support for the idea that we may be able to cure, or at least  treat, a number of diseases by simply transplanting microbiomes, or inducing changes through taxonomic or environmental perturbations, to date little mechanistic understanding exists on how microbial communities work, and on how to extend microbiome research from an empirical science to a systematic, quantitative field of biomedicine. We propose here to establish a computational platform--   a database (Aim 1) with fully integrated analytical software (Aims 2 and 3) --- developed for and with the cooperation of the scientific community. The resource goes beyond cataloguing microbial abundances under different condition; its aim is to enable an understanding of networks of interacting species and their condition-dependence, with the goal of eventually facilitating disease diagnosis and prognosis, and designing therapeutic strategies for microbiome intervention. Our project is centered around three key aims: 1.	The creation of a Microbial Interaction Network Database (MIND), a public resource that will collect data on inter-species interactions from metagenomic sequencing projects, computer simulations and direct experiments. This database will be accessed through a web-based platform complemented with tools for microbial interaction network analysis and visualization, akin to highly fruitful tools previously developed for the study of genetic networks; the database will also serve as the public repository of microbial networks associated with human diseases; 2.	The implementation of an integrated tool for simulation of interspecies interactions under different environments, based on genomic data and whole-cell models of metabolism; 3.	The implementation of new algorithms for microbial community analysis and engineering. These algorithms, including stoichiometric, machine-learning and statistical approaches will facilitate a “synthetic ecology” approach to help design strategies (e.g. microbial transplants or probiotic mixtures) for preventing and targeting microbiome-associated diseases. Our work will fill a major gap in current microbiome research, creating the first platform for global microbial interaction data integration, mining and computation. Project Narrative Among the major developments of the genomic revolution has been the ability to identify thousands of microbial species and strains living in communities in 5 major habitats in the human body, and the recognition that the relative abundances of these populations is strongly correlated with environment: disease state, diet, treatment protocol and so on. A major challenge in utilizing the deluge of health relevant data is structuring it into a database that facilitates understanding inter-microbial interactions in these communities. The aim of this proposal is to create a database and integrated computational platform, open to and contributed to by the research community, which will greatly accelerate the conversion of data into health related actionable knowledge.","A platform for mining, visualization and design of microbial interaction networks",9221662,R01GM121950,"['Affect', 'Algorithms', 'Cataloging', 'Catalogs', 'Cell model', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Development', 'Diet', 'Discipline', 'Disease', 'Ecology', 'Ecosystem', 'Empirical Research', 'Engineering', 'Environment', 'Evolution', 'Future', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Habitats', 'Health', 'Human', 'Human Biology', 'Human Microbiome', 'Human body', 'Imagery', 'Individual', 'Intervention', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Mediating', 'Metabolic', 'Metabolism', 'Metadata', 'Methods', 'Microbe', 'Mining', 'Nature', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Preventive Medicine', 'Probiotics', 'Property', 'Research', 'Resources', 'Science', 'Scientist', 'Structure', 'Taxonomy', 'Technology', 'Therapeutic', 'Time', 'Transplantation', 'Treatment Protocols', 'Work', 'base', 'computer framework', 'data integration', 'data to knowledge', 'design', 'disease diagnosis', 'experimental study', 'feeding', 'genome-wide', 'genomic data', 'human disease', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microbiota transplantation', 'microorganism interaction', 'novel diagnostics', 'novel therapeutics', 'open source', 'outcome forecast', 'prevent', 'repository', 'simulation', 'tool', 'user-friendly']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2017,377226,61050884,-0.008315480054776607
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9316507,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2017,379732,188894159,-0.0007847043277427809
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9403171,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Learning', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2017,548068,685608202,0.0032234255516245367
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9341177,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2017,579791,197030888,-0.005783915340385597
"iFACS: Imaging Florescence Activated Cell Sorter to sort cells based on images iFACS: Imaging Florescence Activated Cell Sorter to sort cells based on images NanoCellect Biomedical, Inc. RESEARCH & RELATED Other Project Information 7. PROJECT SUMMARY Advances in reagents (e.g. CRiSPR) and analytical tools (e.g. flow cytometers) have improved the ability to alter and characterize cellular phenotypes. Ultimately, many key applications in biomedicine require efficient and accurate isolation of cell populations according to features contained in high content images. Unfortunately, microscopic laser microdissection systems have a throughput that is too slow to be practical in many applications; while the existing flow cytometers that can sort cells (fluorescence-activated cell sorters or FACS) provide only size, internal complexity, and fluorescence intensity information and lack the rich data of imaging. Another critical limitation is that the existing flow cytometers that can image, cannot sort cells. NanoCellect has made a highly affordable FACS to increase access to this important high-throughput tool for cell analysis. Here we propose to enhance our existing low-cost FACS with the ability to image cells and sort them based on image features. This will allow users to pursue new strategies in drug screening and mechanism of action research; as well as work with suspension cell lines, such as those that dominate the recent advances in immuno-oncology. In Phase I research, we have demonstrated the world's first imaging flow cytometer with cell sorting capabilities (iFACS) in a unique design of space-time coding with an optical spatial filter. The approach adds negligible cost to the system for the desirable features of cell imaging and sorting. To fully realize the enormous potential of the design and to meet the demands for most applications, in Phase II we will develop high-throughput image-based cell sorting with innovative image-guided gating schemes supported by machine learning and interactive user/machine interface. Essentially, image-based flow cytometry gating uses similar cell isolation criteria as the techniques of laser capture microdissection or cell aspiration to isolate cells of interest, with 10,000X throughput improvements to 1000+ cells per second. We envision such unique capabilities will become common, default features for tomorrow's users as the tool becomes as intuitive and ubiquitous as fluorescent microscopy. The proposed iFACS will be transformative and benefit numerous biomedical applications, such as isolation of cells based on organelle translocation, cell cycle analyses, detection and counting of phagocytosed particles, and protein co-localization, to name just a few. iFACS: Imaging Florescence Activated Cell Sorter to sort cells based on images NanoCellect Biomedical, Inc. RESEARCH & RELATED Other Project Information 8. PROJECT NARRATIVE The advances proposed here will allow NanoCellect to achieve its mission: to advance image-based fluorescence-activated cell sorting technology that can be placed in an affordable bench-top device. This will be achieved by integrating cell-imaging and cell-sorting, and relevant software into an easy-to-use package that extends the features of the existing WOLF® Cell Sorter.",iFACS: Imaging Florescence Activated Cell Sorter to sort cells based on images,9409931,R44DA042636,"['Action Research', 'Adopted', 'Algorithmic Software', 'Back', 'Benchmarking', 'Cell Cycle', 'Cell Line', 'Cell Separation', 'Cell Size', 'Cells', 'Cellular biology', 'Chromatin', 'Code', 'Computer software', 'Data', 'Detection', 'Devices', 'Dexamethasone', 'Flow Cytometry', 'Fluorescence', 'Fluorescence-Activated Cell Sorting', 'Frequencies', 'Glucocorticoid Receptor', 'Histones', 'Image', 'Image Analysis', 'Immunooncology', 'Individual', 'Intuition', 'Lasers', 'Liquid substance', 'Machine Learning', 'Measures', 'Membrane', 'Methodology', 'Microdissection', 'Microfluidics', 'Microscopic', 'Microscopy', 'Mission', 'Mitosis', 'Morphology', 'Motion', 'Names', 'Nuclear', 'Optics', 'Organelles', 'Patients', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Phorbol Esters', 'Photons', 'Physiological', 'Population', 'Preclinical Drug Evaluation', 'Proteins', 'Reagent', 'Reporter', 'Research', 'Sampling', 'Scheme', 'Sorting - Cell Movement', 'Structure', 'Suspensions', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tube', 'Validation', 'Work', 'analytical tool', 'base', 'cellular imaging', 'commercialization', 'cost', 'design', 'detector', 'drug mechanism', 'experience', 'experimental study', 'fluorescence activated cell sorter device', 'gene therapy', 'high throughput analysis', 'image guided', 'image processing', 'imaging capabilities', 'improved', 'innovation', 'interest', 'laser capture microdissection', 'optical imaging', 'particle', 'photomultiplier', 'prevent', 'protein kinase C gamma', 'prototype', 'response', 'screening', 'sensor', 'tool']",NIDA,"NANOCELLECT BIOMEDICAL, INC.",R44,2017,705531,745884,0.0073613160263925346
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,9357870,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Protein Hybridization', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2017,720717,46216755,-0.023479316341423508
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9352387,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Big Data', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Individual', 'Injury', 'Institution', 'Intuition', 'Leukocyte Chemotaxis', 'Lymphocyte Immunophenotypings', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Myocardial', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Sampling', 'Series', 'Staining method', 'Stains', 'Standardization', 'TNF gene', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'base', 'clinical diagnostics', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'human disease', 'improved', 'inquiry-based learning', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2017,782929,3808719,0.01589493525220291
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9270103,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'education research', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2016,43143,338121506,0.0021259529763443734
"Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle,9282051,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'muscular system', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,58482,188894159,-0.001034643625556184
"Forecasting pulmonary inflammation from in vitro assay results for nanoparticles ﻿    DESCRIPTION (provided by applicant):  The rapidly developing field of nanotechnology shows promise by allowing designers to specifically select unique combinations of material properties as needed increasing the effectiveness of applications in medicine, coatings, lubrication, semiconductors, composites, and many others. These materials with their unique combinations of properties on exposure to humans may result in unanticipated hazards, however, putting workers in nanotechnology-related industries at risk. Traditional animal testing is expensive and too slow to evaluate potential risks for the current pace of new nanomaterial development. Both technology developers and regulators need more rapid methods to evaluate new nanomaterial configurations for their risk potential. Much hope is placed in high-throughput in vitro screening assays, but the relevance of these results to the potential for human disease or even the observed toxic effects in animal exposures is unclear. Some research has proposed Quantitative Structure Activity Relationships (QSARs) to predict in vitro nanomaterial toxicity in a few specific assays, but the applicability of these models to a wider group of materials, alternative in vitro assays, or in vivo toxicity has not been explored. If the primary exposure pathway for workers in the near term is inhalation, which in vitro assays will provide the most reliable risk information for that scenario? Two recently available data sources will permit this study to investigate this question: the Environmental Protection Agency's (EPA) ToxCast data for nanomaterials and the Nanomaterial Pulmonary Toxicity Database (NTDB), a collection of published peer reviewed studies observing pulmonary inflammation in rodents upon exposures to nanomaterials. This study will pursue the following specific aims: (1.) identify combinations of in vitro assay results that can reliably forecast the results of pulmonary inflammation results in rodents; (2.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to a wider array of in vitro toxicity assays; and (3.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to in vivo pulmonary inflammation results. This study will employ machine learning methods to cluster similar nanomaterials between the various in vitro and in vivo results, and to identify combinations of in vitro assays that rank order the toxicity of nanomaterials most similarly to pulmonary inflammation results in rodents considering also how changes in specific chemical and physical particle properties exacerbate or mitigate observed toxicity. This study addresses documented research needs in the National Occupational Research Agenda (NORA) cross- sector Nanotechnology program including specific goals in the Human Health and Informatics categories. Implementation complies with the Research to Practice (r2p) Initiative in its formulation, design, and implementation plan including industry an public outreach. The insight generated by this study will improve nanomaterial risk screening capabilities and focus attention and effort on those measurements and techniques proven to be most effective and reliable enabling better management and control of the risks faced by workers. PUBLIC HEALTH RELEVANCE:  Although toxicity risk information for nanoparticles is accumulating rapidly, the development of new nanomaterial configurations is proceeding too fast for our best risk assessment tools (i.e. animal testing) to keep up. The new availability of two large databases of in vitro assay results and pulmonary inflammation results in rodents will permit this study to investigate which in vitro assays provide the most predictive information about the results from in vivo exposures, and thus speed up the risk screening process for nanomaterials. The results of this study will have important implications for more quickly identifying new nanomaterial-related risks to workers.",Forecasting pulmonary inflammation from in vitro assay results for nanoparticles,9144793,R03OH010956,[' '],NIOSH,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R03,2016,66564,74382276,-0.0022077328084224948
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,9056632,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'education research', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2016,73173,338121506,0.0021259529763443734
"Development of integrative models for early liver toxicity assessment ﻿    DESCRIPTION (provided by applicant): Computational toxicology has become a critical area of research due to the burgeoning need to evaluate thousands of pharmaceutical and environmental chemicals with unknown toxicity profiles, the high demand in time and resources by current experimental toxicity testing, and the growing ethical concerns over animal use in toxicity studies. Despite tremendous efforts, little success has been attained thus far in the development of predictive computational models for toxicity, primarily due to the complexity of toxicity mechanisms as well as the lack of high-quality experimental data for model development.  A critical challenge in toxicity testing of chemicals is that toxicity effects are doe-dependent: the true toxic hits may show no toxicity at all at low dose level. Therefore, traditiona high-throughput screening (HTS) that test chemicals only at a single concentration is not suitable for toxicity screening. On the contrary, the recently developed quantitative high-throughput screening (qHTS) platforms can evaluate each chemical across a broad range of concentrations, and is gaining ever-increasing popularity as a tool for in vitro toxicity profiling The concentration-response information generated by qHTS are expected to provide more accurate and comprehensive information of the toxicity effects of chemicals, offering promising data that can be mined to estimate in vivo toxicities of chemicals. However, our previous studies showed that if processed inappropriately, such concentration-response information contribute little to improve the toxicity prediction. This is especially true when multiple types of qHTS data are used together. Therefore, in this study, we will extend our previous approaches to develop novel statistical and computational tools that can curate, preprocess, and normalize the concentration-response information from multiple different qHTS databases.  Traditionally, toxicity models are based on either the chemical data (such as the quantitative structure- activity relationship analysis), or the in vitro toxicity profiling data (such as the in vitro-in vivo extrapolations). Our previous experiences suggested that integrating biological descriptors such as the in vitro cytotoxicity profiles or the short-term toxigenomic data, with chemical structural features is able to predict rodent acute liver toxicity with reasonable accuracy. Therefore, the second part of this proposal will be devoted to develop novel computational models for hepatotoxicity prediction by integrating qHTS toxicity profiles and chemical structural information In Aim 1, we will curate, preprocess, and normalize collected public liver toxicity datasets. In ths study, we will model toxicity effects using multiple large public datasets such as HTS and qHTS bioassay data (Tox21[1] and ToxCast[2]), hepatotoxicity side effect reports on marketed failed drugs[3], the Liver Toxicity Knowledge Base Benchmark Dataset (LTKB-BD[4]), etc. Statistical methods for cross-study validation and quality control will be applied to the collected datasets to ensure computational compatibility and to select the appropriate datasets for analysis. In Aim 2, we will develop predictive models for chemicals' liver toxicity based on an integrative modeling workflow that will make use of both structural and in vitro toxicity profiles of a chemical. Our previous studies [5] showed that models using both in vitro toxicity profiles and chemical structural data have better accuracy for rodent acute liver toxicity than models using either data type alone. Here, we will develop a novel modeling workflow that start with defining the functional clusters of chemicals via curated qHTS toxicity profiles, and is followed by developing computational models to correlate chemical and biological data with overall toxicity risks in humans. The predictive models will be validated using independent datasets with over 800 compounds. In Aim 3, we propose to prioritize the qHTS profiling assays used in the model for future toxicity testing. We will evaluate all the in vitro assays as biological descriptors from thee perspectives, including descriptor importance in the integrative toxicity model, correlation with i vivo DILI outcomes, and level of information content estimated by a novel approach based on network analysis.    PUBLIC HEALTH RELEVANCE: In this study we aim to develop computational models that can identify potential liver toxicants. Liver toxicity is a significant contributor to the high attition rate in drug development. Moreover, toxic chemicals in food, water, and consumer products all pose serious risks for liver toxicity. As a result, there is great interest in developing high-throughput, high-content experimental and computational tools to evaluate the liver toxicity of thousands of pharmaceutical and environmental chemicals. This study focuses on developing novel informatics tools that enable the extraction and integration of chemical concentration-response information from multiple quantitative high-throughput screening databases for model development, and developing statistical models that are able to integrate this concentration-response information with chemical structural features to predict their risk of liver toxicity.  ",Development of integrative models for early liver toxicity assessment,9017336,R03ES026397,"['Acute', 'Address', 'Adverse effects', 'Algorithms', 'Animals', 'Area', 'Benchmarking', 'Biological', 'Biological Assay', 'Chemicals', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Dose', 'Dreams', 'Ensure', 'Ethics', 'Food', 'Future', 'Gene Expression', 'Genomics', 'Goals', 'Gold', 'Health', 'Hepatotoxicity', 'Human', 'In Vitro', 'Informatics', 'International', 'Liver', 'Machine Learning', 'Marketing', 'Mining', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Environmental Health Sciences', 'Nature', 'North Carolina', 'Outcome', 'Pathway Analysis', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Poison', 'Process', 'Productivity', 'Quality Control', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Resources', 'Risk', 'Rodent', 'Scientist', 'Shapes', 'Statistical Methods', 'Statistical Models', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicogenetics', 'Toxicology', 'Translational Research', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'Universities', 'Variant', 'Water', 'base', 'computerized tools', 'consumer product', 'cost', 'cost effective', 'cytotoxicity', 'data modeling', 'drug development', 'drug market', 'drug withdrawal', 'environmental chemical', 'experience', 'high throughput screening', 'improved', 'in vitro Assay', 'in vivo', 'interest', 'knowledge base', 'liver injury', 'model building', 'model development', 'novel', 'novel strategies', 'post-market', 'preclinical study', 'predictive modeling', 'programs', 'response', 'screening', 'success', 'tool', 'toxicant', 'validation studies']",NIEHS,UT SOUTHWESTERN MEDICAL CENTER,R03,2016,81000,225463847,-0.026093136592836703
"Empiric Testing and enhancement of web-based abstract screening tool(Abstrackr) EMPIRICAL TESTING AND ENHANCEMENT OF WEB-BASED ABSTRACT SCREENING TOOL (ABSTRACKR)  In this year-long project, we aim to empirically assess the performance and efficiency of state-of-the-art information analysis technologies to assist the production of systematic reviews and meta-analyses that are increasingly being used as a foundation for evidence-based medicine and stakeholder-driven comparative effectiveness reviews. We have developed AbstrackrTM (hereon, Abstrackr), a human-guided computerized abstract screening tool that aims to reduce the need to perform a tedious but crucial step of manually screening many thousands of abstracts generated by literature searches in order to retrieve a small fraction potentially relevant for further analysis. Abstrackr makes use of machine learning techniques, and is offered as a free web-based tool that enables management of the screening process.  We also aim to revise the web-interface of Abstrackr to make it more intuitive, user friendly, and add documentation and functionalities requested by users; and to revise Abstrackr’s back-end, which includes the way the software parses and analyses citations, fits machine learning models, and makes computations, to make it more efficient. These revisions will ensure that the tool becomes more robust, and that it remains usable for larger projects and for many teams.  The proposed work will be carried out by the developers of Abstrackr, comprising a highly experienced team of systematic review investigators and computer scientists at Brown University and the University of Texas at Austin, who have been working together for at least seven years. We will pursue dissemination of the findings of this assessment and of the revised tool through numerous channels including, but not limited to publication, presentation at conferences, exploring interest in its wider adoption by the Agency for Healthcare Research and Quality Evidence-based Practice Center Program, Cochrane Collaboration, and other groups conducting systematic reviews. We will also continue to make all code available online. Our aims are to: Aim 1. Empirically measure the efficiency and accuracy of the prediction algorithms in Abstrackr in the computer-assisted semi-automated screening of citations for eligibility in systematic reviews. Aim 2. Improve and add to the functionality of the Web-based Abstrackr software, based in part on enhancements suggested by a panel of identified heavy users. Systematic reviewing is a scientific approach to objectively summarizing the effectiveness and safety of existing treatments for diseases, a prerequisite for informed healthcare decision-making and systematic reviewers must read many thousands of medical study abstracts, the vast majority of which are completely irrelevant to the review at hand. This is hugely laborious and time consuming. We propose to assess the performance and efficiency of a computerized system that automatically excludes a large number of the irrelevant abstracts, thereby accelerating the process and expediting the application of the systematic review findings to patient care, and to augment the functionality of its public implementation.",Empiric Testing and enhancement of web-based abstract screening tool(Abstrackr),9168247,R03HS024812,[' '],AHRQ,BROWN UNIVERSITY,R03,2016,99999,127562714,0.00025411269175752894
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9176982,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Shapes', 'Slice', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Translations', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'abstracting', 'aging population', 'base', 'catalyst', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2016,100000,5161939,-0.0006179874470693047
"Supporting Systematic Review Production with Article Similarity Network Visualization PROJECT SUMMARY Systematic reviews (SRs), or systematic reviews of literature, summarize evidence drawn from high quality studies, and are often the preferred source of evidence-based practice (EBP). However, conducting an SR is labor-intensive and time consuming, typically requiring several months to complete. It has been reported that more than ten thousands of SRs are needed to synthesize existing medical knowledge. An Article screening process is one of the most intensive and time consuming steps, which requires SR researchers to screen a large amount of references, ranging from hundreds to more than 10,000 articles, depending on the size of a SR. In the past 10 years, machine learning model training approaches24-29 were developed to accelerate the article selection process through automation. However, they are not widely used due to diffusion challenges.7,14 Major obstacles include 1) a training sample is required to generate the automation algorithm. If the training sample is biased, the article selection process will systematically fail; 2) the automation approach is not made available for non-computer science specialists, therefore SR researchers will not be able to “fine-tune” the automation algorithm for particular conditions in various SR topics; 3) As there is no global automation algorithm, the generalizability is significantly limited; 4) It is difficult to assess the actual workload saved, while finding every relevant article is required in SR. We propose a new approach to provide views of article relationships in an article network. This is different from other bibliometric networks constructing citation, co-author, or co-occurrence networks. Article network is a simple and logical concept: visualizing article relationships and distribution based on articles' similarities in titles, abstracts, keywords, publication types, etc. SR researchers can also alter the article distribution by adjusting the similarities. This approach does not aim to suggest an end-point of the screening process. Rather, it provides a view of distribution for included, excluded, and undecided articles. In the proposed research, we will integrate advanced techniques to sparsify article networks with mixed sparsification methods, and improve the quality and efficiency of large network visualization layouts by constructing a multi-level network structure and advanced force model. We aim to provide approaches to sparsify and visualize article networks with more than 10,000 articles. Our approach is highly generalizable that it can be used for any health science topics. By viewing the article distribution, SR researchers will be able to screen a large amount of literature more efficiently. This approach can be integrated into current SR technologies and used directly by SR researchers. The success of this project can support SR production on any health science topics, and thus streamline their ultimate application in EBP paradigms. PROJECT NARRATIVE Systematic reviews (SRs) provide the highest quality of research evidence for patient care. To accelerate the production of SRs, we will implement advanced visualization techniques to view article relationships and distribution with article networks and in a timely and human readable manner. The success of the project will support SR production and thus streamline their ultimate application to evidence-based practice.",Supporting Systematic Review Production with Article Similarity Network Visualization,9227858,R03HS025047,[' '],AHRQ,OHIO STATE UNIVERSITY,R03,2016,100000,241268189,-0.0031975539468036755
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing. PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8998947,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'improved outcome', 'neovascular', 'novel', 'programs', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2016,180061,807432003,0.0025423802601172
"A Strength Analysis Tool for Studying Healthy Aging via Exercise in C. elegans ﻿    DESCRIPTION (provided by applicant): Exercise is arguably the most potent approach we can take to defer physical decline associated with aging and to protect against late onset diseases such as diabetes, cancer, and Alzheimer's disease. Molecular understanding of how exercise benefits translate into healthy aging is thus of definitive medical interest. We study fundamental processes relevant to healthy aging in the 959-celled nematode C. elegans. Recently we made a fascinating discovery-C. elegans can exercise (swim) to exhibit training benefits, and appear to gain benefits by molecular pathways conserved in humans. Our initial model development opens up a new research area for understanding how tissue-specific and organism-wide health benefits are induced by exercise, and creates a novel paradigm for identifying exercise mimetic drugs that might promote healthy aging. To really harvest the potential of this model, we need to measure the strength of the tiny C. elegans. We collaborated to develop a strength test in which trained animals thread through a matrix of deformable pillars, and the extent of pillar deflection is used to calculate force. Our ""NemaFlex"" force detection device is the quantitative foundation with which we expect to break new ground in understanding exercise impact on healthy aging. Here we propose required development to enhance assay throughput and pursue applications that will not only anchor this technology as an essential component of C. elegans exercise evaluation but also accelerate studies on exercise biology and healthy aging in this powerful model. Aim 1 is to develop a novel high throughput tool for direct strength evaluation in C. elegans.  This aim will generate an essential tool for analysis of C. elegans strength at multiple life stages, define the exercise regimen that will become the anchor protocol in the field, and reveal features of training in this model. Aim 2 is to use NemaFlex to evaluate exercise mimetic drugs & to facilitate focused pilot genetic screens. This aim will establish critical proof-of-principle for genetic and drug discovery using the NemaFlex. Aim 3 is to initiate dissection of the functional and molecular relationship between exercise and healthy aging, grounded in NemaFlex force measures of training benefits.  To begin, we will test how optimized strength training tracks with a broad spectrum of healthspan indicators that decline with age, we will investigate impact of cessation of training on aging quality, and we will ask if exercise mimetic drugs extend healthspan in the absence of training. Our goals will create novel technology that for the first time permits facile quantitativ analysis of exercise adaptations in the powerful C. elegans genetic model. Accomplishment of our tractable aims will anchor a new subfield of genetic investigation of exercise and healthy aging that may influence design of interventions that broadly promote health and defer aging. PUBLIC HEALTH RELEVANCE: Exercise has a profound positive impact on health of the aging population in that it protects against age-associated diseases including cancer, diabetes, and cardiovascular disease, at the same time it maintains muscle, immune system, and nervous system function in aging. We are developing the first exercise model in the simple animal C. elegans, in which training benefits appear mediated by conserved mechanisms and exercise promotes healthy aging. We will optimize a novel tool for direct strength measurement of these tiny 959-celled animals and show how our device can facilitate searches for exercise mimetic drugs and genes that are associated with training adaptations, and can also help define exercise impact on a broad range of healthy aging measures. The experimental advantages of C. elegans may yield unexpected insights that inspire development of novel interventions that protect against age-associated disease and age-associated decline.",A Strength Analysis Tool for Studying Healthy Aging via Exercise in C. elegans,9116734,R21AG050503,"['Address', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Animals', 'Area', 'Automation', 'Biological Assay', 'Biology', 'Biology of Aging', 'Caenorhabditis elegans', 'Cardiac', 'Cardiovascular Diseases', 'Cells', 'Collaborations', 'Computer Vision Systems', 'Detection', 'Development', 'Device Designs', 'Devices', 'Diabetes Mellitus', 'Disease', 'Dissection', 'Elderly', 'Engineering', 'Evaluation', 'Exercise', 'Exhibits', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Engineering', 'Genetic Models', 'Genetic Screening', 'Goals', 'Harvest', 'Health', 'Health Benefit', 'Human', 'Immune system', 'Intervention', 'Investigation', 'Late-Onset Disorder', 'Life', 'Longevity', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediating', 'Mediator of activation protein', 'Medical', 'Modeling', 'Molecular', 'Molecular Genetics', 'Muscle', 'Muscle function', 'Nematoda', 'Nervous System Physiology', 'Organism', 'Outcome', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Protocols documentation', 'Pump', 'Regimen', 'Reporting', 'Research', 'Staging', 'Swimming', 'System', 'Technology', 'Testing', 'Texas', 'Time', 'Tissues', 'Training', 'Translating', 'Work', 'age-related muscle loss', 'aging population', 'anti aging', 'base', 'cognitive function', 'design', 'drug discovery', 'exercise regimen', 'exercise training', 'experience', 'fascinate', 'healthy aging', 'immune function', 'improved', 'insight', 'interest', 'mimetics', 'model development', 'new technology', 'novel', 'programs', 'strength training', 'therapy design', 'tool']",NIA,TEXAS TECH UNIVERSITY,R21,2016,184503,5488393,-0.019575228624616237
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9213710,R00AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2016,249000,32532200,-0.0030342911147281334
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9126405,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,316467,188894159,-0.0007847043277427809
"UVPD-MS Characterization of Lipopolysaccharides Abstract. Gram-negative bacteria have caused many of the most persistent infections as well as some of the deadliest pandemics in the world. Some strains have developed resistant to all available drugs, thus leading to increasing mortality from previously treatable bacterial infections. The National Strategy for Combating Antibiotic-Resistant Bacteria released by the White House in September 2014 focused on the need for (i) advancing the development of methods for identification and characterization of bacteria, (ii) accelerating basic research for new antibiotics, and (iii) improving capabilities for surveillance of antibiotic-resistant bacteria. This proposal focuses on the development of innovative tandem mass spectrometry approaches for characterization of lipopolysaccharides (LPS), the primary constituent of the outer membrane of Gram-negative bacteria that protects the membrane from chemical attack and is recognized by the immune system during pathogenic invasion. Structural characterization of LPS is critical to understanding how the structure of LPS influences immune stimulation as well as facilitating development of new antimicrobials and vaccines. This is a significant analytical challenge due to the branched structures and amphipathic properties of LPS. The escalating concerns about antibiotic resistance bacteria and the need for better avenues of defense against infectious diseases have motivated the proposed work. The objectives of this proposal are: Aim 1: Development of ultraviolet photodissociation (UVPD) mass spectrometry via hierarchical, decision-tree workflows for top-down characterization of LPS to facilitate high throughput analysis; Aim 2: Development of MS/MS approaches for serotyping of Gram-negative bacteria based on LPS; Aim 3: Examination of peptide/LPS interactions via native-spray mass spectrometry to provide both mechanistic information and screening capabilities for new antimicrobials, and Aim 4: Applications to a variety of structural problems related to the biosynthesis of LPS in Gram- negative bacteria and characterization of hybrid O-antigen/lipid A molecules in vesicle-based vaccines.  We have established a new collaboration with Dr. Bryan Davies' group to develop mass spectrometry methods to characterize peptide/lipid A interactions in support of the hunt for better antimicrobials. The continued collaboration with Dr. Stephen Trent's group emphasizes: (i) approaches for deciphering the biosynthetic pathways of bacterial LPS that endow them with the remarkable ability to re-design their outer membranes and develop antibiotic resistance, and (ii) innovative vaccine design based on antigenic LPS in vesicles.    Narrative: Gram-negative bacteria are responsible for some of the deadliest and more widespread pandemics in the world. The proposed work focuses on the development of advanced mass spectrometry approaches for characterization of complex lipopolysaccharides, including the endotoxic lipid A domains, that comprise the outer membrane of Gram-negative bacteria. The proposed work will be applied to evaluate new antimicrobials and support development of hybrid vaccines.",UVPD-MS Characterization of Lipopolysaccharides,9174984,R01GM103655,"['Acylation', 'Address', 'Advanced Development', 'Affinity', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Architecture', 'Bacteria', 'Bacterial Infections', 'Bacterial Vaccines', 'Basic Science', 'Binding', 'Cataloging', 'Catalogs', 'Cells', 'Chemical Warfare', 'Code', 'Collaborations', 'Communicable Diseases', 'Complex', 'Complex Mixtures', 'Custom', 'Databases', 'Decision Trees', 'Development', 'Distal', 'Exhibits', 'Focus Groups', 'Glycolipids', 'Gram-Negative Bacteria', 'Housing', 'Hybrids', 'Immune', 'Immune system', 'Infection', 'Ions', 'Lipid A', 'Lipopolysaccharide Biosynthesis Pathway', 'Lipopolysaccharides', 'Mass Spectrum Analysis', 'Membrane', 'Methodology', 'Methods', 'Modification', 'Molecular', 'O Antigens', 'Oligosaccharides', 'Pathway interactions', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphorylation', 'Polysaccharides', 'Process', 'Production', 'Property', 'Publishing', 'Resistance', 'Serotyping', 'Structure', 'System', 'Tail', 'Vaccine Design', 'Vaccines', 'Variant', 'Vesicle', 'Virulence', 'Work', 'abstracting', 'acyl group', 'antimicrobial', 'base', 'cell envelope', 'combat', 'design', 'high throughput analysis', 'improved', 'innovation', 'innovative technologies', 'inorganic phosphate', 'instrument', 'mortality', 'novel', 'novel therapeutics', 'pandemic disease', 'response', 'screening', 'sugar', 'tandem mass spectrometry', 'ultraviolet']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2016,322883,91740242,-0.011252393542071502
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9050682,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2016,339750,193405667,-0.0011073338999810231
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9145647,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2016,605366,197030888,-0.005783915340385597
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9215166,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Big Data', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Immunophenotyping', 'Individual', 'Injury', 'Institution', 'Leukocyte Chemotaxis', 'Lymphocyte', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Myocardial', 'Paper', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Sampling', 'Series', 'Staining method', 'Stains', 'Standardization', 'TNF gene', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'base', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'human disease', 'improved', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2016,855992,3808719,0.01589493525220291
"An Open Source Precision Medicine Platform for Cloud Operating Systems ﻿    DESCRIPTION (provided by applicant):  Rapid improvements in DNA sequencing and synthesis have the potential to usher in a new era of precision medicine. To realize this vision, however, we must re-imagine the computational and storage infrastructure used to manage and extract actionable results from the massive data sets made possible by widely available advances in DNA sequencing and synthetic biology. In conjunction with the Global Alliance for Genomics and Health (GA4GH), we propose to build the Arvados platform so that a new ecosystem of clinical decision support applications will be able to navigate petabytes of global biomedical data and search millions of genomes in real-time (seconds). Our team has a proven track record of commercial success and high impact scientific research. Commercialization of this free and open-source software (FOSS) platform, which will be greatly accelerated by this grant, will permit organizations to seamlessly span on-premise & hosted cloud- operating systems and vastly simplify data-management & computation, all while facilitating compliance with institutional policies and regulatory requirements.         PUBLIC HEALTH RELEVANCE:  The delivery of healthcare based on molecular data specific to an individual patient (i.e. precision medicine) will require the creation of a new ecosystem of Clinical Decision Support (CDS) applications. This work will provide a platform that will make the development of such applications faster, easier, and less expensive.        ",An Open Source Precision Medicine Platform for Cloud Operating Systems,9140741,R44GM109737,"['Address', 'Adopted', 'Big Data', 'Bioinformatics', 'Businesses', 'Capital', 'Clinical', 'Clinical Decision Support Systems', 'Collaborations', 'Communities', 'Computer software', 'Contractor', 'DNA Sequence', 'DNA biosynthesis', 'Data', 'Data Set', 'Databases', 'Development', 'Distributed Systems', 'Ecosystem', 'Feedback', 'Fostering', 'Funding', 'Galaxy', 'Genome', 'Genomics', 'Grant', 'Health', 'Healthcare', 'Human', 'Industry', 'Information Technology', 'Institutional Policy', 'International', 'Internet', 'Language', 'Length', 'Letters', 'Machine Learning', 'Maintenance', 'Manuscripts', 'Measures', 'Medicine', 'Memory', 'Molecular', 'Operating System', 'Phase', 'Policies', 'Production', 'Publications', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resources', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Source Code', 'System', 'Technology', 'Time', 'Training Support', 'Vision', 'Work', 'base', 'big biomedical data', 'cloud platform', 'commercialization', 'data management', 'genome sequencing', 'genomic data', 'health care delivery', 'individual patient', 'meetings', 'new technology', 'next generation sequencing', 'open source', 'operation', 'petabyte', 'portability', 'precision medicine', 'public health relevance', 'repository', 'screening', 'success', 'symposium', 'synthetic biology', 'terabyte', 'web services', 'whole genome']",NIGMS,"CUROVERSE, INC.",R44,2016,985339,0,-0.015246154683268733
"Reproducibility Assessment for Multivariate Assays DESCRIPTION (provided by applicant): This Small Business Innovation Research project addresses the problem of assessing reproducibility in analyzing high-throughput data. In feature selection for data with large numbers of features, it is well known that some features will appear to affect an outcome by chance, and that subsequent predictions based on these features may not be as successful as initial results would seem to indicate. Similarly, there are often multiple stages, and many parameters, involved in the multivariate assays de- signed to analyze high-throughput profiles. For example, good results achieved with a particular combination of settings for an instance of cross-validation may not generalize to other instances. The objective of this proposal is to extend new statistical methods for assessing reproducibility in replicate experiments to the context of machine learning, and demonstrate effectiveness in this application. The machine-learning methods to be investigated will include random forests, supervised principal components, lasso penalization and support vector machines. We will use simulated and real data from genomic applications to show the potential of this approach for providing reproducibility assessments that are not confounded with prespecified choices, for determining biologically relevant thresholds, for improving the accuracy of signal identification, and for identifying suboptimal results. Relevance. Although today's high-throughput technologies offer the possibility of revolutionizing clinical practice, the analytical tools availble for extracting information from this amount of data are not yet sufficiently developed for targeted exploration of the underlying biology. This project directly addresses the need to make what the FDA terms IVDMIA (In-Vitro Diagnostic Multivariate Index Assays) transparent, interpretable, and reproducible, and is thus an opportunity to improve analysis products and services provided to companies that identify, characterize, and validate biomarkers for clinical diagnostics and drug development decision points. The long-term goal of the proposed project is to develop a platform for biomarker discovery and integrative genomic analysis, with reproducibility assessment incorporated into multivariate assays. This will enable evaluation and improvement of approaches to detecting the biological factors that affect a particular outcome, and lead to more efficient and more effective methods for disease diagnosis, treatment monitoring, and therapeutic drug development. PUBLIC HEALTH RELEVANCE: Statistical models play a key role in medical research in uncovering information from data that leads to new diagnostics and therapies. However, development of standards for reliability in biomedical data mining has not kept up with the rapid pace at which new data types and modeling approaches are being devised. This proposal is for new methods for quantifying reproducibility in biomedical data analyses that will have a far-reaching impact on public health by streamlining protocols, reducing costs and offering more effective clinical support systems.",Reproducibility Assessment for Multivariate Assays,8828718,R43GM109503,"['Address', 'Affect', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Biological Factors', 'Biological Markers', 'Biology', 'ChIP-seq', 'Clinical', 'Cloud Computing', 'Data', 'Data Analyses', 'Decision Trees', 'Development', 'Diagnostic', 'Dimensions', 'Effectiveness', 'Evaluation', 'Evolution', 'Genomics', 'Goals', 'Guidelines', 'Health', 'In Vitro', 'Investigation', 'Lasso', 'Lead', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Performance', 'Phase', 'Play', 'Protocols documentation', 'Public Health', 'Publishing', 'ROC Curve', 'Reproducibility', 'Research Project Grants', 'Scheme', 'Services', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Source', 'Specific qualifier value', 'Staging', 'Statistical Methods', 'Statistical Models', 'Support System', 'Techniques', 'Technology', 'Therapeutic', 'Trees', 'Validation', 'analytical tool', 'base', 'clinical practice', 'cost', 'data mining', 'design', 'disease diagnosis', 'drug development', 'follow-up', 'forest', 'high throughput technology', 'improved', 'indexing', 'novel diagnostics', 'research study']",NIGMS,INSILICOS,R43,2015,64005,0,-0.015778067427419586
"Forecasting pulmonary inflammation from in vitro assay results for nanoparticles ﻿    DESCRIPTION (provided by applicant):  The rapidly developing field of nanotechnology shows promise by allowing designers to specifically select unique combinations of material properties as needed increasing the effectiveness of applications in medicine, coatings, lubrication, semiconductors, composites, and many others. These materials with their unique combinations of properties on exposure to humans may result in unanticipated hazards, however, putting workers in nanotechnology-related industries at risk. Traditional animal testing is expensive and too slow to evaluate potential risks for the current pace of new nanomaterial development. Both technology developers and regulators need more rapid methods to evaluate new nanomaterial configurations for their risk potential. Much hope is placed in high-throughput in vitro screening assays, but the relevance of these results to the potential for human disease or even the observed toxic effects in animal exposures is unclear. Some research has proposed Quantitative Structure Activity Relationships (QSARs) to predict in vitro nanomaterial toxicity in a few specific assays, but the applicability of these models to a wider group of materials, alternative in vitro assays, or in vivo toxicity has not been explored. If the primary exposure pathway for workers in the near term is inhalation, which in vitro assays will provide the most reliable risk information for that scenario? Two recently available data sources will permit this study to investigate this question: the Environmental Protection Agency's (EPA) ToxCast data for nanomaterials and the Nanomaterial Pulmonary Toxicity Database (NTDB), a collection of published peer reviewed studies observing pulmonary inflammation in rodents upon exposures to nanomaterials. This study will pursue the following specific aims: (1.) identify combinations of in vitro assay results that can reliably forecast the results of pulmonary inflammation results in rodents; (2.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to a wider array of in vitro toxicity assays; and (3.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to in vivo pulmonary inflammation results. This study will employ machine learning methods to cluster similar nanomaterials between the various in vitro and in vivo results, and to identify combinations of in vitro assays that rank order the toxicity of nanomaterials most similarly to pulmonary inflammation results in rodents considering also how changes in specific chemical and physical particle properties exacerbate or mitigate observed toxicity. This study addresses documented research needs in the National Occupational Research Agenda (NORA) cross- sector Nanotechnology program including specific goals in the Human Health and Informatics categories. Implementation complies with the Research to Practice (r2p) Initiative in its formulation, design, and implementation plan including industry an public outreach. The insight generated by this study will improve nanomaterial risk screening capabilities and focus attention and effort on those measurements and techniques proven to be most effective and reliable enabling better management and control of the risks faced by workers.         PUBLIC HEALTH RELEVANCE:  Although toxicity risk information for nanoparticles is accumulating rapidly, the development of new nanomaterial configurations is proceeding too fast for our best risk assessment tools (i.e. animal testing) to keep up. The new availability of two large databases of in vitro assay results and pulmonary inflammation results in rodents will permit this study to investigate which in vitro assays provide the most predictive information about the results from in vivo exposures, and thus speed up the risk screening process for nanomaterials. The results of this study will have important implications for more quickly identifying new nanomaterial-related risks to workers.            ",Forecasting pulmonary inflammation from in vitro assay results for nanoparticles,8953935,R03OH010956,[' '],NIOSH,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R03,2015,66904,74382276,-0.0022077328084224948
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,8935748,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Research', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Scientist', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2015,73173,338121506,0.0021259529763443734
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,8775624,K99AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,GEORGIA INSTITUTE OF TECHNOLOGY,K99,2015,90000,45341731,-0.0030342911147281334
"Face De-Identification for Research and Clinical Use DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis. PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.",Face De-Identification for Research and Clinical Use,8908047,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Health', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'sex', 'social stigma', 'targeted imaging', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2015,193512,30434536,-0.04731404533052224
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing.         PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.                ",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8826350,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Outcome', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'neovascular', 'novel', 'programs', 'public health relevance', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2015,215393,807432003,0.0025423802601172
"A Strength Analysis Tool for Studying Healthy Aging via Exercise in C. elegans ﻿    DESCRIPTION (provided by applicant): Exercise is arguably the most potent approach we can take to defer physical decline associated with aging and to protect against late onset diseases such as diabetes, cancer, and Alzheimer's disease. Molecular understanding of how exercise benefits translate into healthy aging is thus of definitive medical interest. We study fundamental processes relevant to healthy aging in the 959-celled nematode C. elegans. Recently we made a fascinating discovery-C. elegans can exercise (swim) to exhibit training benefits, and appear to gain benefits by molecular pathways conserved in humans. Our initial model development opens up a new research area for understanding how tissue-specific and organism-wide health benefits are induced by exercise, and creates a novel paradigm for identifying exercise mimetic drugs that might promote healthy aging. To really harvest the potential of this model, we need to measure the strength of the tiny C. elegans. We collaborated to develop a strength test in which trained animals thread through a matrix of deformable pillars, and the extent of pillar deflection is used to calculate force. Our ""NemaFlex"" force detection device is the quantitative foundation with which we expect to break new ground in understanding exercise impact on healthy aging. Here we propose required development to enhance assay throughput and pursue applications that will not only anchor this technology as an essential component of C. elegans exercise evaluation but also accelerate studies on exercise biology and healthy aging in this powerful model. Aim 1 is to develop a novel high throughput tool for direct strength evaluation in C. elegans.  This aim will generate an essential tool for analysis of C. elegans strength at multiple life stages, define the exercise regimen that will become the anchor protocol in the field, and reveal features of training in this model. Aim 2 is to use NemaFlex to evaluate exercise mimetic drugs & to facilitate focused pilot genetic screens. This aim will establish critical proof-of-principle for genetic and drug discovery using the NemaFlex. Aim 3 is to initiate dissection of the functional and molecular relationship between exercise and healthy aging, grounded in NemaFlex force measures of training benefits.  To begin, we will test how optimized strength training tracks with a broad spectrum of healthspan indicators that decline with age, we will investigate impact of cessation of training on aging quality, and we will ask if exercise mimetic drugs extend healthspan in the absence of training. Our goals will create novel technology that for the first time permits facile quantitativ analysis of exercise adaptations in the powerful C. elegans genetic model. Accomplishment of our tractable aims will anchor a new subfield of genetic investigation of exercise and healthy aging that may influence design of interventions that broadly promote health and defer aging.         PUBLIC HEALTH RELEVANCE: Exercise has a profound positive impact on health of the aging population in that it protects against age-associated diseases including cancer, diabetes, and cardiovascular disease, at the same time it maintains muscle, immune system, and nervous system function in aging. We are developing the first exercise model in the simple animal C. elegans, in which training benefits appear mediated by conserved mechanisms and exercise promotes healthy aging. We will optimize a novel tool for direct strength measurement of these tiny 959-celled animals and show how our device can facilitate searches for exercise mimetic drugs and genes that are associated with training adaptations, and can also help define exercise impact on a broad range of healthy aging measures. The experimental advantages of C. elegans may yield unexpected insights that inspire development of novel interventions that protect against age-associated disease and age-associated decline.              ",A Strength Analysis Tool for Studying Healthy Aging via Exercise in C. elegans,8936078,R21AG050503,"['Address', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Animals', 'Area', 'Automation', 'Biological Assay', 'Biology', 'Biology of Aging', 'Caenorhabditis elegans', 'Cardiac', 'Cardiovascular Diseases', 'Cells', 'Collaborations', 'Computer Vision Systems', 'Detection', 'Development', 'Device Designs', 'Devices', 'Diabetes Mellitus', 'Disease', 'Dissection', 'Elderly', 'Engineering', 'Evaluation', 'Exercise', 'Exhibits', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Engineering', 'Genetic Models', 'Genetic Screening', 'Goals', 'Harvest', 'Health', 'Health Benefit', 'Human', 'Immune system', 'Intervention', 'Investigation', 'Late-Onset Disorder', 'Life', 'Longevity', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediating', 'Mediator of activation protein', 'Medical', 'Modeling', 'Molecular', 'Molecular Genetics', 'Muscle', 'Muscle function', 'Nematoda', 'Nervous System Physiology', 'Organism', 'Outcome', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Protocols documentation', 'Pump', 'Regimen', 'Reporting', 'Research', 'Staging', 'Swimming', 'System', 'Technology', 'Testing', 'Texas', 'Time', 'Tissues', 'Training', 'Translating', 'Work', 'aging population', 'anti aging', 'base', 'cognitive function', 'design', 'drug discovery', 'experience', 'fascinate', 'healthy aging', 'immune function', 'improved', 'insight', 'interest', 'mimetics', 'model development', 'new technology', 'novel', 'programs', 'public health relevance', 'strength training', 'therapy design', 'tool']",NIA,TEXAS TECH UNIVERSITY,R21,2015,235630,5488393,-0.019575228624616237
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics.         PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.            ",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9072725,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disadvantaged', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Population', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'Solutions', 'Staging', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2015,299984,7208224,0.027073322220375878
"Image analysis for high-throughput C. elegans infection and metabolism assays DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute. PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8786567,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression Profile', 'Gene Expression Profiling', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'imaging platform', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,309263,191864802,0.01645376783861411
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8922953,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2015,314327,188894159,-0.0007847043277427809
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8842639,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2015,332955,193405667,-0.0011073338999810231
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8919113,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'imaging software', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'targeted imaging', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,341788,807432003,-0.010347516878530883
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities.         PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.                ","Pathology Image Informatics Platform for visualization, analysis and management",8970326,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2015,606305,197030888,-0.005783915340385597
"The Cardiovascular Research Grid DESCRIPTION (provided by applicant):    The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinations of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotating ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and motion that can predict the early presence of developing heart disease in time for therapeutic intervention. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informatics system that allows clinical information to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG. RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8786588,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'High Performance Computing', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Ultrasonography', 'Work', 'base', 'cardiovascular imaging', 'cardiovascular visualization', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2015,2177431,807432003,0.015306918248526142
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,8774800,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Clinical Trials', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Research', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Scientist', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2014,73173,338121506,0.0021259529763443734
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through  multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,8618418,K99AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,GEORGIA INSTITUTE OF TECHNOLOGY,K99,2014,90000,45341731,-0.0030342911147281334
"Reproducibility Assessment for Multivariate Assays  Project Summary. This Small Business Innovation Research project addresses the problem of assessing reproducibility in analyzing high-throughput data. In feature selection for data with large numbers of fea- tures, it is well known that some features will appear to affect an outcome by chance, and that subsequent predictions based on these features may not be as successful as initial results would seem to indicate. Similarly, there are often multiple stages, and many parameters, involved in the multivariate assays de- signed to analyze high-throughput profiles. For example, good results achieved with a particular combina- tion of settings for an instance of cross-validation may not generalize to other instances. The objective of this proposal is to extend new statistical methods for assessing reproducibility in replicate experiments to the context of machine learning, and demonstrate effectiveness in this application. The machine-learning methods to be investigated will include random forests, supervised principal components, lasso penal- ization and support vector machines. We will use simulated and real data from genomic applications to show the potential of this approach for providing reproducibility assessments that are not confounded with prespecified choices, for determining biologically relevant thresholds, for improving the accuracy of signal identification, and for identifying suboptimal results. Relevance. Although today's high-throughput technologies offer the possibility of revolutionizing clinical practice, the analytical tools available for extracting information from this amount of data are not yet sufficiently developed for targeted exploration of the underlying biology. This project directly addresses the need to make what the FDA terms IVDMIA (In-Vitro Diagnostic Multivariate Index Assays) transparent, interpretable, and reproducible, and is thus an opportunity to improve analysis products and services provided to companies that identify, characterize, and validate biomarkers for clinical diagnostics and drug development decision points. The long-term goal of the proposed project is to develop a platform for biomarker discovery and integrative genomic analysis, with reproducibility assessment incorporated into multivariate assays. This will enable evaluation and improvement of approaches to detecting the biological factors that affect a particular outcome, and lead to more efficient and more effective methods for disease diagnosis, treatment monitoring, and therapeutic drug development. PUBLIC HEALTH RELEVANCE: Statistical models play a key role in medical research in uncovering information from data that leads to new diagnostics and therapies. However, development of standards for reliability in biomedical data mining has not kept up with the rapid pace at which new data types and modeling approaches are being devised. This proposal is for new methods for quantifying reproducibility in biomedical data analyses that will have a far-reaching impact on public health by streamlining protocols, reducing costs and offering more effective clinical support systems.            ",Reproducibility Assessment for Multivariate Assays,8647816,R43GM109503,"['Address', 'Affect', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Biological Factors', 'Biological Markers', 'Biology', 'ChIP-seq', 'Clinical', 'Cloud Computing', 'Data', 'Data Analyses', 'Decision Trees', 'Development', 'Diagnostic', 'Dimensions', 'Effectiveness', 'Evaluation', 'Evolution', 'Genomics', 'Goals', 'Guidelines', 'In Vitro', 'Investigation', 'Lasso', 'Lead', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Performance', 'Phase', 'Play', 'Protocols documentation', 'Public Health', 'Publishing', 'ROC Curve', 'Reproducibility', 'Research Project Grants', 'Scheme', 'Services', 'Signal Transduction', 'Simulate', 'Small Business Innovation Research Grant', 'Source', 'Specific qualifier value', 'Staging', 'Statistical Methods', 'Statistical Models', 'Support System', 'Techniques', 'Technology', 'Therapeutic', 'Trees', 'Validation', 'analytical tool', 'base', 'clinical practice', 'cost', 'data mining', 'design', 'disease diagnosis', 'drug development', 'follow-up', 'forest', 'high throughput technology', 'improved', 'indexing', 'novel diagnostics', 'public health relevance', 'research study']",NIGMS,INSILICOS,R43,2014,131071,0,-0.01574437916915149
"The Cardiovascular Research Grid DESCRIPTION (provided by applicant):    The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinations of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotating ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and motion that can predict the early presence of developing heart disease in time for therapeutic intervention. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informatics system that allows clinical information to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG. RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8928685,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'High Performance Computing', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Ultrasonography', 'Work', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2014,159202,807432003,0.015306918248526142
"Face De-Identification for Research and Clinical Use     DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis.         PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.            ",Face De-Identification for Research and Clinical Use,8772435,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'public health relevance', 'sex', 'social stigma', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2014,194915,30434536,-0.04731404533052224
"Automated retinopathy of prematurity classification using machine learning     DESCRIPTION (provided by applicant): The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH-funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi-disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing.         PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.",Automated retinopathy of prematurity classification using machine learning,8723225,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2014,198905,551214295,-0.020632273287181025
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence  Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.  Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8669161,R00LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'screening', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2014,212994,570146095,-0.005444004473472666
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8600293,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,310129,191864802,0.01645376783861411
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus     DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community.         PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.            ",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8761698,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'prognostic', 'public health relevance', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2014,314327,188894159,-0.0007847043277427809
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8652462,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2014,332955,193405667,-0.0011073338999810231
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8737899,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,335356,807432003,-0.010347516878530883
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.        Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8704932,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild cognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'screening', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2014,338287,507546965,-0.033983738159410505
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.       PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.            ",Integration and visualization of diverse biological data,8601095,R01GM071966,"['Address', 'Algorithms', 'Bayesian Method', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Cloud Computing', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Microvascular Dysfunction', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'public health relevance', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2014,391301,58504236,-0.009554567931707047
"A Software Platform for Sensor-based Movement Disorder Recognition     DESCRIPTION (provided by applicant): The overall objective of this SBIR project is to develop a pre-commercial prototype system capable of continuously monitoring involuntary movement disorders from a wide spectrum of neurological conditions. The impact of this innovation will enhance the availability of advanced brain and behavior research tools [PA- 11-134] by providing a continuous means of tracking the presence and severity of movement disorders during normal daily activities. This project will transform our unique movement disorder recognition algorithms into custom software that analyzes movement disorders for specific neurological conditions. The information obtained from body worn sensors will provide an accurate and objective means for assessing the complex and changeable nature of movement disorders. This goal cannot by realized using the current method of self-report questionnaires.  The research strategy for Phase I will establish the merit and feasibility of this effort by developing an Application Generation (AG) software platform using a framework of configurable signal processing modules to generate custom applications for movement disorder analysis (Aim 1). This approach reduces the effort and enhances the flexibility of designing and testing software solutions for these applications. The AG Platform will be developed using C++ software to implement signal processing and machine-learning software modules that operate within a knowledge-based framework that we have previously developed. In Aim 2 we will utilize the AG platform to generate movement disorder analysis software to evaluate a challenging test-case application: freezing-of-gait in Parkinson's disease (PD). The goal is to attain performance metrics for freezing that are comparable to those we have achieved for tremor and dyskinesia in previous efforts.  Phase II will refine the capabilities of the AG platform developed in Phase I. We will augment it with the means to automatically design and train the machine learning algorithms, improve the user-interface, and provide options for viewing and summarizing the results. The improved AG platform will be used to develop customized disorder-analysis software that encompasses the full complement of movement disorders associated with PD (e.g. dystonia, bradykinesia, Parkinsonian gait, tremor, dyskinesia), as well as for other neurological condition, such as Essential Tremor (ET). Firmware will be developed for each custom application to efficiently integrate the analytic software with our existing Trigno wireless sensor data acquisition hardware, which needs to be streamlined for this application. This combined system will be evaluated under research use-case scenarios in Neurology. Phase II will deliver an ambulatory Movement Disorder Monitoring system that not only succeeds in providing state-of-the-art monitoring solutions for PD and Essential Tremor, but has proven technology to develop monitoring solutions for a wide variety of neurological conditions. Future development will transfer this technology to a clinical version of this system.         PUBLIC HEALTH RELEVANCE: The project is intended to improve the accuracy and reduce the burden of researchers and clinicians when assessing motor outcomes for patients with involuntary movement disorders. The proposed technology will provide a means for evaluating new treatment options, and expedite the delivery of care. The attainment of these goals should increase the effectiveness of research, the time required for these research advancements to reach the consumer, and help control the rising costs of clinical care among the estimated 45 million Americans who have neurological disorders resulting in involuntary movements. The resulting improvements in motor function will ultimately lead to greater independence and productivity for this growing segment of the population.            ",A Software Platform for Sensor-based Movement Disorder Recognition,8734495,R43NS083098,"['Affect', 'Algorithms', 'American', 'Bradykinesia', 'Clinical', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Custom', 'Data', 'Development', 'Disease', 'Dyskinetic syndrome', 'Dystonia', 'Early Diagnosis', 'Essential Tremor', 'Freezing', 'Future', 'Gait', 'Generations', 'Goals', 'Health Care Sector', 'Health Professional', 'Home environment', 'Involuntary Movements', 'Lead', 'Learning Module', 'Left', 'Lower Extremity', 'Machine Learning', 'Methods', 'Metric', 'Miniaturization', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Neurologic', 'Neurology', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Process', 'Productivity', 'Quality of life', 'Questionnaires', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Severities', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Technology', 'Technology Transfer', 'Testing', 'Time', 'Training', 'Tremor', 'Video Recording', 'Wireless Technology', 'Work', 'Writing', 'advanced system', 'base', 'brain behavior', 'care delivery', 'clinical care', 'cost', 'data acquisition', 'design', 'disorder control', 'effectiveness research', 'flexibility', 'handheld mobile device', 'human subject', 'improved', 'innovation', 'knowledge base', 'motor disorder', 'nervous system disorder', 'novel therapeutics', 'prototype', 'public health relevance', 'research study', 'response', 'sensor', 'signal processing', 'software development', 'tool']",NINDS,"ALTEC, INC.",R43,2014,417876,1532918,-0.0006683971859454265
"Scalable Assays for Morphological Analysis of Mammalian Neurons    DESCRIPTION (provided by applicant): Medium and high-throughput assays (i.e., screens) have generally not been applied to mammalian neurons because of the difficulties in culturing them in large numbers and because of the low efficiency with which the genetic makeup of neurons can be altered. Furthermore, because many aspects of neuronal function can only be assayed with electrophysiological assays, follow-up analysis and validation of screening hits is difficult. We propose to use automated imaging approaches to analyze synapse number and neuronal structure in vitro in a scalable format. We have implemented tissue culture and immunostaining approaches to monitor the number and types of synapses formed onto neurons in multi-well plates. We will couple this analysis with lentivirus mediated introduction of short-hairpin RNAs to induce RNA interference against genes expressed in neurons. This will be performed in concert with transcriptional analysis of neurons to determine the key changes in gene expression that correlate with structural and synaptic changes. The proposal represents a significant collaboration between several groups with expertise in functional analysis of neurons, automated analysis of images, viral mediated manipulation of gene expression, and whole-genome transcriptional analysis. We hope that our work will lead, for the first time, to a turn-key and robust method of analysis of neuron and synapse structure suitable for scalable, whole-genome analysis. Such a system will permit the unbiased and systematic analysis of pathways involved in neuropsychiatric diseases including neurodegenerative diseases such as Alzheimer's and Parkinson's as well as neurodevelopmental disorders such as mental retardation and autism.        Massively parallel analysis of cells in many conditions has allowed the discovery of key pathways that control cell function. Unfortunately, these techniques have not been applied to neurons due to difficulties in handling, manipulating, and analyzing large numbers of brain cells. We propose to develop imaging-based techniques to analyze neurons in dishes at a high throughput in order to find pathways that control their development and susceptibility to disease.            ",Scalable Assays for Morphological Analysis of Mammalian Neurons,8657123,R01NS077907,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Antibodies', 'Autistic Disorder', 'Axon', 'Benchmarking', 'Biochemical Pathway', 'Biological Assay', 'Cell Line', 'Cell physiology', 'Cells', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Development', 'Disease', 'Ensure', 'Excitatory Synapse', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Image', 'Image Analysis', 'In Vitro', 'Inhibitory Synapse', 'Institutes', 'Label', 'Lead', 'Machine Learning', 'Measurement', 'Mediating', 'Mental Retardation', 'Methods', 'Mining', 'Mitochondria', 'Monitor', 'Morphology', 'Mus', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuroglia', 'Neurons', 'Organelles', 'Parkinson Disease', 'Pathway Analysis', 'Pathway interactions', 'Phenotype', 'Predisposition', 'Procedures', 'Process', 'Protocols documentation', 'RNA Interference', 'Relative (related person)', 'Structure', 'Subfamily lentivirinae', 'Synapses', 'System', 'Techniques', 'Time', 'Transfection', 'Validation', 'Viral', 'Work', 'base', 'bioimaging', 'brain cell', 'density', 'design', 'fluorescence imaging', 'follow-up', 'genome analysis', 'genome-wide', 'high throughput screening', 'medical schools', 'neuropsychiatry', 'open source', 'prototype', 'scale up', 'screening', 'small hairpin RNA', 'synaptogenesis', 'tissue culture', 'tool']",NINDS,HARVARD MEDICAL SCHOOL,R01,2014,419513,178569161,-0.012219618856333155
"Efficient patient-specific cell generation by image-guidance    DESCRIPTION (provided by applicant): This fast-track proposal applies advanced kinetic image pattern recognition (KIPR) technologies to predict induced pluripotent stem cell (iPSC) reprogramming colonies' differentiation outcomes for significantly improved yield and robustness of differentiation protocols. The objectives of the proposed tool are 1) Teaching: creation of scores for induced colony differentiation outcome prediction by machine learning; 2) Reprogramming: optimal reprogramming harvest time determination by continuous colony score monitoring; 3) Differentiation: selection of colonies with the highest prediction scores for differentiation at the reprogramming harvest time; 4) Differentiation: cell cluster quality control by continuous monitoring during differentiation. The specific aims of this fast-track proposal are Phase I: 1) Extend SVCell for the prediction of induced colony differentiation outcomes ; 2) Validate that prediction of colony differentiation outcomes can improve the yield of CM differentiation. Phase II: 1) Validate that the integrated system can be taught to be robust and high yielding for a diverse set of human fibroblast input samples and different reprogramming / differentiation protocols; 2) Integrate SVCell with a state-of-the-art continuous cell imaging and culture system to create a prototype patient-specific cell generation system; 3) Validate the integrated system as a patient-specific cell generation product. The ultimate goal of this fast-track proposal is to develop and validate an image-guided efficient patient-specific cardiomyocyte generation system. This will be achieved by integrating our established SVCell software containing advanced KIPR technologies with a live cell imaging technology to synthesize state-of-the-art cell fate control protocols against iPSC. Patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. Successful development of the patient-specific cell generation system of this proposal could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.        Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.         ",Efficient patient-specific cell generation by image-guidance,8697110,R44HL106863,"['Biotechnology', 'Brain Diseases', 'Cardiac Myocytes', 'Cell Culture System', 'Cell Differentiation process', 'Cell Fate Control', 'Cells', 'Cellular Morphology', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Fibroblasts', 'Generations', 'Goals', 'Government', 'Harvest', 'Health', 'Healthcare', 'Heart', 'Human', 'Image', 'Imaging technology', 'Institutes', 'Kinetics', 'Life', 'Machine Learning', 'Medicine', 'Metric', 'Monitor', 'Outcome', 'Patients', 'Pattern Recognition', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Production', 'Protocols documentation', 'Quality Control', 'Sampling', 'Staging', 'Staining method', 'Stains', 'Stem cells', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Work', 'alanine aminopeptidase', 'base', 'cell type', 'cellular imaging', 'cost', 'cost effectiveness', 'disease diagnosis', 'drug discovery', 'drug testing', 'human embryonic stem cell', 'improved', 'induced pluripotent stem cell', 'patient population', 'prototype', 'stem cell technology', 'tool', 'usability']",NHLBI,"DRVISION TECHNOLOGIES, LLC",R44,2014,976531,1296025,-0.0015183162819843604
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8668954,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'screening', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2014,1029385,673201228,-0.026964849397697277
"The Cardiovascular Research Grid DESCRIPTION (provided by applicant):    The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinations of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotating ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and motion that can predict the early presence of developing heart disease in time for therapeutic intervention. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informatics system that allows clinical information to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG.  RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8588958,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'High Performance Computing', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Ultrasonography', 'Work', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2014,2177431,807432003,0.015306918248526142
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.         PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8466969,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'public health relevance', 'screening', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2013,1,1300000,-0.002776779297646649
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence  Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.  Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8484438,R00LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'screening', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2013,202118,570146095,-0.005444004473472666
"Automated retinopathy of prematurity classification using machine learning  Project Summary/Abstract The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH- funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi- disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing. PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.                 ",Automated retinopathy of prematurity classification using machine learning,8445584,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2013,283543,551214295,-0.019340811183726766
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8402395,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,301051,191864802,0.01645376783861411
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.        Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8514601,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild cognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'screening', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2013,328871,507546965,-0.033983738159410505
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8477880,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2013,339750,193405667,-0.0011073338999810231
"Multimodal image registration by proxy image synthesis No abstract available PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8614480,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,343798,807432003,-0.00898975763918179
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.       PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.            ",Integration and visualization of diverse biological data,8403055,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diabetic Angiopathies', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'public health relevance', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2013,378540,58504236,-0.009554567931707047
"Scalable Assays for Morphological Analysis of Mammalian Neurons    DESCRIPTION (provided by applicant): Medium and high-throughput assays (i.e., screens) have generally not been applied to mammalian neurons because of the difficulties in culturing them in large numbers and because of the low efficiency with which the genetic makeup of neurons can be altered. Furthermore, because many aspects of neuronal function can only be assayed with electrophysiological assays, follow-up analysis and validation of screening hits is difficult. We propose to use automated imaging approaches to analyze synapse number and neuronal structure in vitro in a scalable format. We have implemented tissue culture and immunostaining approaches to monitor the number and types of synapses formed onto neurons in multi-well plates. We will couple this analysis with lentivirus mediated introduction of short-hairpin RNAs to induce RNA interference against genes expressed in neurons. This will be performed in concert with transcriptional analysis of neurons to determine the key changes in gene expression that correlate with structural and synaptic changes. The proposal represents a significant collaboration between several groups with expertise in functional analysis of neurons, automated analysis of images, viral mediated manipulation of gene expression, and whole-genome transcriptional analysis. We hope that our work will lead, for the first time, to a turn-key and robust method of analysis of neuron and synapse structure suitable for scalable, whole-genome analysis. Such a system will permit the unbiased and systematic analysis of pathways involved in neuropsychiatric diseases including neurodegenerative diseases such as Alzheimer's and Parkinson's as well as neurodevelopmental disorders such as mental retardation and autism.        Massively parallel analysis of cells in many conditions has allowed the discovery of key pathways that control cell function. Unfortunately, these techniques have not been applied to neurons due to difficulties in handling, manipulating, and analyzing large numbers of brain cells. We propose to develop imaging-based techniques to analyze neurons in dishes at a high throughput in order to find pathways that control their development and susceptibility to disease.            ",Scalable Assays for Morphological Analysis of Mammalian Neurons,8467069,R01NS077907,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Antibodies', 'Autistic Disorder', 'Axon', 'Benchmarking', 'Biochemical Pathway', 'Biological Assay', 'Cell Line', 'Cell physiology', 'Cells', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Development', 'Disease', 'Ensure', 'Excitatory Synapse', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Image', 'Image Analysis', 'In Vitro', 'Inhibitory Synapse', 'Institutes', 'Label', 'Lead', 'Machine Learning', 'Measurement', 'Mediating', 'Mental Retardation', 'Methods', 'Mining', 'Mitochondria', 'Monitor', 'Morphology', 'Mus', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuroglia', 'Neurons', 'Organelles', 'Parkinson Disease', 'Pathway Analysis', 'Pathway interactions', 'Phenotype', 'Predisposition', 'Procedures', 'Process', 'Protocols documentation', 'RNA Interference', 'Relative (related person)', 'Structure', 'Subfamily lentivirinae', 'Synapses', 'System', 'Techniques', 'Time', 'Transfection', 'Validation', 'Viral', 'Work', 'base', 'bioimaging', 'brain cell', 'density', 'design', 'fluorescence imaging', 'follow-up', 'genome analysis', 'genome-wide', 'high throughput screening', 'medical schools', 'neuropsychiatry', 'open source', 'prototype', 'scale up', 'screening', 'small hairpin RNA', 'synaptogenesis', 'tissue culture', 'tool']",NINDS,HARVARD MEDICAL SCHOOL,R01,2013,408818,178569161,-0.012219618856333155
"A Software Platform for Sensor-based Movement Disorder Recognition     DESCRIPTION (provided by applicant): The overall objective of this SBIR project is to develop a pre-commercial prototype system capable of continuously monitoring involuntary movement disorders from a wide spectrum of neurological conditions. The impact of this innovation will enhance the availability of advanced brain and behavior research tools [PA- 11-134] by providing a continuous means of tracking the presence and severity of movement disorders during normal daily activities. This project will transform our unique movement disorder recognition algorithms into custom software that analyzes movement disorders for specific neurological conditions. The information obtained from body worn sensors will provide an accurate and objective means for assessing the complex and changeable nature of movement disorders. This goal cannot by realized using the current method of self-report questionnaires.  The research strategy for Phase I will establish the merit and feasibility of this effort by developing an Application Generation (AG) software platform using a framework of configurable signal processing modules to generate custom applications for movement disorder analysis (Aim 1). This approach reduces the effort and enhances the flexibility of designing and testing software solutions for these applications. The AG Platform will be developed using C++ software to implement signal processing and machine-learning software modules that operate within a knowledge-based framework that we have previously developed. In Aim 2 we will utilize the AG platform to generate movement disorder analysis software to evaluate a challenging test-case application: freezing-of-gait in Parkinson's disease (PD). The goal is to attain performance metrics for freezing that are comparable to those we have achieved for tremor and dyskinesia in previous efforts.  Phase II will refine the capabilities of the AG platform developed in Phase I. We will augment it with the means to automatically design and train the machine learning algorithms, improve the user-interface, and provide options for viewing and summarizing the results. The improved AG platform will be used to develop customized disorder-analysis software that encompasses the full complement of movement disorders associated with PD (e.g. dystonia, bradykinesia, Parkinsonian gait, tremor, dyskinesia), as well as for other neurological condition, such as Essential Tremor (ET). Firmware will be developed for each custom application to efficiently integrate the analytic software with our existing Trigno wireless sensor data acquisition hardware, which needs to be streamlined for this application. This combined system will be evaluated under research use-case scenarios in Neurology. Phase II will deliver an ambulatory Movement Disorder Monitoring system that not only succeeds in providing state-of-the-art monitoring solutions for PD and Essential Tremor, but has proven technology to develop monitoring solutions for a wide variety of neurological conditions. Future development will transfer this technology to a clinical version of this system.         PUBLIC HEALTH RELEVANCE: The project is intended to improve the accuracy and reduce the burden of researchers and clinicians when assessing motor outcomes for patients with involuntary movement disorders. The proposed technology will provide a means for evaluating new treatment options, and expedite the delivery of care. The attainment of these goals should increase the effectiveness of research, the time required for these research advancements to reach the consumer, and help control the rising costs of clinical care among the estimated 45 million Americans who have neurological disorders resulting in involuntary movements. The resulting improvements in motor function will ultimately lead to greater independence and productivity for this growing segment of the population.            ",A Software Platform for Sensor-based Movement Disorder Recognition,8521782,R43NS083098,"['Affect', 'Algorithms', 'American', 'Bradykinesia', 'Clinical', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Custom', 'Data', 'Development', 'Devices', 'Disease', 'Dyskinetic syndrome', 'Dystonia', 'Early Diagnosis', 'Essential Tremor', 'Freezing', 'Future', 'Gait', 'Generations', 'Goals', 'Health Care Sector', 'Health Professional', 'Home environment', 'Involuntary Movements', 'Lead', 'Left', 'Lower Extremity', 'Machine Learning', 'Methods', 'Metric', 'Miniaturization', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Neurologic', 'Neurology', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Process', 'Productivity', 'Quality of life', 'Questionnaires', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Severities', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Technology', 'Technology Transfer', 'Testing', 'Time', 'Training', 'Tremor', 'Video Recording', 'Wireless Technology', 'Work', 'Writing', 'advanced system', 'base', 'brain behavior', 'care delivery', 'clinical care', 'computerized data processing', 'cost', 'data acquisition', 'design', 'disorder control', 'effectiveness research', 'flexibility', 'human subject', 'improved', 'innovation', 'knowledge base', 'motor disorder', 'nervous system disorder', 'novel therapeutics', 'prototype', 'public health relevance', 'research study', 'response', 'sensor', 'software development', 'tool']",NINDS,"ALTEC, INC.",R43,2013,424766,1532918,-0.0006683971859454265
"Automatic 3D Quantification of Synapse Distribution in Complex Dendritic Arbor     DESCRIPTION (provided by applicant): The subcellular distribution of synapses is critical for the assembly, function, and plasticity of the nervous system and plays a role in its disorders. Underlying molecular mechanisms, however, remain largely unknown. While advanced multidimensional images, in conjunction with single-cell genetic techniques, have afforded an unprecedented opportunity to understand synapse development at a new level, there is a knowledge gap in our capacity to effectively quantify subcellular synapses from large quantities of three-dimensional images. This is a significant problem and has hampered large-scale studies of the molecular mechanisms of synapse development, especially in neurons with complex arbor-such as Purkinje cells in mammals and lobula plate tangential cells (LPTC) in Drosophila-where existing approaches do not yield complete or robust synapse quantification for the entire dendritic tree and do not scale to efficient genetic screening. The objective of thi project is to bridge this gap by providing tools for quantitative investigation of subcellular synapse distribution and its molecular mechanisms using three-dimensional microscopy images. Specifically, our highly cross- disciplinary team will pursue two aims: (1) Develop automatic algorithms to analyze and quantify synapse distribution in the entire dendritic tree of neurons with complex arbor. Holistic and objective description of synapse density will enable automatic detection of mutant patterns. (2) Develop automatic algorithms to analyze and quantify synapse distribution in different parts of the entire dendritic tree of neurons with complex arbor. Efficient quantification at distinct subcellular locations will assist discovery of novel regulators for different subcellular parts. As a test case, we will use synapse distribution n Drosophila LPTC neurons, which are amenable to both genome-wide genetic screens and genetic manipulations with single-neuron resolution. We will develop reliable methods to characterize the density of inhibitory GABAergic and excitatory cholinergic synapses from three-dimensional fluorescence confocal images. Our algorithms will lead to the next level of mechanistic understanding that controls the subcellular distribution of inhibitory and excitatory synapses, and enable a wide range of quantitative analyses for other types of neurons with similar complexity. Powerful multichannel co-analysis and machine learning approaches will be used to improve synapse detection and subcellular compartment extraction for overcoming challenges in 3D confocal image, including staining artifacts and anisotropic resolution. Algorithms will be developed using a model-guided methodology that emphasizes efficiency for large volume 3D images during genetic screening. Pattern-recognition methods will be used to speed up proofreading of the synapse quantification results. A novel ordering strategy will be adapted for neurons of complex dendritic arbor to quantify subcellular synapses in a functionally meaningful way. The project will produce a set of open-source, extensible tools for automatic synapse quantification and proofreading, with friendly graphical-user interfaces, to serve the neuroscience community.         PUBLIC HEALTH RELEVANCE: The underlying molecular mechanisms for the subcellular distribution of synapses remain largely unknown, which hinders the discovery of novel therapies for many neurological disorders. By developing new, efficient automatic algorithms and open-source tools for quantifying synapses in neurons, this research intends to advance the capacity to effectively analyze large quantities of three-dimensional neuronal images, especially those of complex dendritic arbor. The work will impact public health by enabling a better understanding of disease mechanisms, which is the critical first step toward new treatments, and supports NIH's goal to advance understanding of fundamental biology to uncover the causes of specific diseases.            ",Automatic 3D Quantification of Synapse Distribution in Complex Dendritic Arbor,8574710,R15MH099569,"['Academic Research Enhancement Awards', 'Algorithms', 'Area', 'Biology', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Data', 'Dendrites', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Excitatory Synapse', 'Fluorescence', 'Generations', 'Genetic', 'Genetic Screening', 'Genetic Techniques', 'Goals', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'Inhibitory Synapse', 'Investigation', 'Knowledge', 'Lead', 'Location', 'Machine Learning', 'Mammals', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Nervous system structure', 'Neurons', 'Neurosciences', 'Pattern', 'Pattern Recognition', 'Play', 'Public Health', 'Purkinje Cells', 'Pyramidal Cells', 'Research', 'Resolution', 'Role', 'Speed', 'Staging', 'Staining method', 'Stains', 'Surface', 'Synapses', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Trees', 'Variant', 'Work', 'base', 'cholinergic synapse', 'density', 'falls', 'genetic manipulation', 'genome-wide', 'graduate student', 'graphical user interface', 'high throughput technology', 'improved', 'in vivo', 'innovation', 'interdisciplinary approach', 'mutant', 'nervous system disorder', 'novel', 'open source', 'public health relevance', 'tool', 'undergraduate student', 'user-friendly']",NIMH,NORTHERN ILLINOIS UNIVERSITY,R15,2013,461165,2020585,-0.011207803101121135
"Efficient patient-specific cell generation by image-guidance    DESCRIPTION (provided by applicant): This fast-track proposal applies advanced kinetic image pattern recognition (KIPR) technologies to predict induced pluripotent stem cell (iPSC) reprogramming colonies' differentiation outcomes for significantly improved yield and robustness of differentiation protocols. The objectives of the proposed tool are 1) Teaching: creation of scores for induced colony differentiation outcome prediction by machine learning; 2) Reprogramming: optimal reprogramming harvest time determination by continuous colony score monitoring; 3) Differentiation: selection of colonies with the highest prediction scores for differentiation at the reprogramming harvest time; 4) Differentiation: cell cluster quality control by continuous monitoring during differentiation. The specific aims of this fast-track proposal are Phase I: 1) Extend SVCell for the prediction of induced colony differentiation outcomes ; 2) Validate that prediction of colony differentiation outcomes can improve the yield of CM differentiation. Phase II: 1) Validate that the integrated system can be taught to be robust and high yielding for a diverse set of human fibroblast input samples and different reprogramming / differentiation protocols; 2) Integrate SVCell with a state-of-the-art continuous cell imaging and culture system to create a prototype patient-specific cell generation system; 3) Validate the integrated system as a patient-specific cell generation product. The ultimate goal of this fast-track proposal is to develop and validate an image-guided efficient patient-specific cardiomyocyte generation system. This will be achieved by integrating our established SVCell software containing advanced KIPR technologies with a live cell imaging technology to synthesize state-of-the-art cell fate control protocols against iPSC. Patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. Successful development of the patient-specific cell generation system of this proposal could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.        Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.         ",Efficient patient-specific cell generation by image-guidance,8509778,R44HL106863,"['Biotechnology', 'Brain Diseases', 'Cardiac Myocytes', 'Cell Culture System', 'Cell Differentiation process', 'Cell Fate Control', 'Cells', 'Cellular Morphology', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Fibroblasts', 'Generations', 'Goals', 'Government', 'Harvest', 'Health', 'Healthcare', 'Heart', 'Human', 'Image', 'Imaging technology', 'Institutes', 'Kinetics', 'Life', 'Machine Learning', 'Medicine', 'Metric', 'Monitor', 'Outcome', 'Patients', 'Pattern Recognition', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Production', 'Protocols documentation', 'Quality Control', 'Sampling', 'Staging', 'Staining method', 'Stains', 'Stem cells', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Work', 'alanine aminopeptidase', 'base', 'cell type', 'cellular imaging', 'cost', 'cost effectiveness', 'disease diagnosis', 'drug discovery', 'drug testing', 'human embryonic stem cell', 'improved', 'induced pluripotent stem cell', 'patient population', 'prototype', 'stem cell technology', 'tool', 'usability']",NHLBI,"DRVISION TECHNOLOGIES, LLC",R44,2013,983515,1296025,-0.0015183162819843604
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8464703,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'screening', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2013,1054947,673201228,-0.026964849397697277
"The Cardiovascular Research Grid DESCRIPTION (provided by applicant):    The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinations of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotating ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and motion that can predict the early presence of developing heart disease in time for therapeutic intervention. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informatics system that allows clinical information to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG.  RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8424997,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'High Performance Computing', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Ultrasonography', 'Work', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2013,2177404,807432003,0.015306918248526142
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8393965,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Screening procedure', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2012,75559,673201228,-0.026964849397697277
"Sensory based CNS diagnostics for the clinic    DESCRIPTION (provided by applicant): There is currently a significant gap that exists between fundamental neuroscience research and translation of the findings of that research into everyday practice. Experimental findings at the genetic, cellular, molecular and systems level often take a fairly long and frequently circuitous route to make an impact on a particular neurological disease or disorder. The goal of our work is to bridge the neuroscientific gap at the systems level of study by developing standardized sensory measures that can be not only utilized in clinical or clinical research settings, but can be directly correlated with the observations obtained directly from sensory cortex in non-human primates via high resolution imaging and extracellular recording. Successful development of an experimental model that iteratively evaluates the relationship of clinical measures and systemic CNS responses to specific mechanistic alterations will be quite significant. Such an evaluation of an individual's CNS status could be directly linked to systemic mechanistic deficiencies or alterations observed in animal experimentation.  Towards that goal, we have successfully designed and fabricated a tactile sensory diagnostic device. In parallel with that development, we designed a number of protocols - based on experimental neurophysiological findings from both our non human primate research and that of others - that could be rapidly and efficiently delivered (1-3 minutes) to a number of subject populations. The tactile diagnostic system that we have developed was conceptually designed to investigate differences in cortical information processing strategies between people with autism and people without. In this proposal we ask whether or not the strategy that we have devised for investigating a population with a neurodevelopmental disorder could be broadly applied to a number of neurological disorders. In other words, we consider the changes manifested by the neurodevelpmental disorder autism to be systemic, and if systemic cortical alterations occur in other neurological disorders, could they also be detected in the same manner?  Proof-of-concept studies in a number of clinical research areas demonstrated that these newly developed metrics were sensitive to systemic cortical alterations. One question that emerges from this data is that most of these neurological disorders result in some type of altered central sensitization, no matter what the cause - whether it be neurodevelopmental, neurodegenerative, pharmacological or trauma induced - in which there is a significant change in the balance between excitation and inhibition. This application proposes to determine if sensory perceptual metrics, similar to those that were used to successfully distinguish subjects with autism from healthy control populations (with 90% accuracy using SVM to assess the results of a 25 minute battery of 9 protocols), could be used to reliably distinguish - on an individual basis - subjects with neurological disorders that are not neurodevelopmental in nature. Towards this goal, we target subjects from one broad category of neurological disorders - chronic pain. More specifically, we will examine the differences and commonalities from observations of pain patients diagnosed with one of the following: fibromyalgia, vulvodynia, TMJD, IBS and migraine.        The overall goal of the proposed work is to investigate the utility of novel sensory-based methodologies that are currently being used in both basic and clinical research. Recently, utilizing state-of-the-art technology, we built a multi-site tactile stimulator that allows for investigation of central nervous system (CNS) health and advanced methods in sensory perceptual metrics. These metrics have been demonstrated to be sensitive to changes in centrally mediated mechanisms; and systemic alterations of cortical health (via neurodegenerational, neurodevelopmental, pharmacological or trauma induced changes) robustly change the measures. It is anticipated that clinicians will be able to utilize these measures to improve diagnostic performance and enable assessment of efficacy of treatment. The study itself will serve to validate the utility of a number of these measures in several types of pain, specifically fibromyalgia, TMJD, IBS, vulvodynia and migraine. The information from this study could aid in understanding centrally mediated mechanisms that undergo significant alterations with chronic pain.         ",Sensory based CNS diagnostics for the clinic,8293088,R21NS072811,"['Address', 'Age', 'Animal Experimentation', 'Area', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Brain Concussion', 'Caregivers', 'Categories', 'Cerebrum', 'Clinic', 'Clinical', 'Clinical Research', 'Data', 'Databases', 'Development', 'Devices', 'Dextromethorphan', 'Diagnosis', 'Diagnostic', 'Disease', 'Equilibrium', 'Evaluation', 'Experimental Models', 'Fibromyalgia', 'GABA Agonists', 'Genetic', 'Goals', 'Health', 'Image', 'Individual', 'Investigation', 'Laboratory Animals', 'Lead', 'Letters', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Metric', 'Migraine', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Nature', 'Nerve Degeneration', 'Neuraxis', 'Neurodevelopmental Disorder', 'Neurons', 'Neurosciences Research', 'Ophthalmic examination and evaluation', 'Pain', 'Patients', 'Performance', 'Physiological', 'Play', 'Population', 'Population Control', 'Primary Health Care', 'Process', 'Protocols documentation', 'Recruitment Activity', 'Research', 'Resolution', 'Role', 'Route', 'Sensory', 'Site', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Technology', 'Temporomandibular Joint Disorders', 'Testing', 'Translations', 'Trauma', 'Treatment Efficacy', 'United States National Institutes of Health', 'Vulvodynia', 'Work', 'analytical tool', 'base', 'central sensitization', 'chronic pain', 'cohort', 'cost effective', 'data mining', 'demographics', 'design', 'extracellular', 'gamma-Aminobutyric Acid', 'improved', 'in vivo', 'information processing', 'nervous system disorder', 'neurophysiology', 'neurotransmission', 'nonhuman primate', 'novel', 'process optimization', 'protocol development', 'response', 'sensory cortex', 'white matter damage']",NINDS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2012,181885,511185245,-0.10754831777528538
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.      PUBLIC HEALTH RELEVANCE: The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.           The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8227796,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2012,197444,807432003,-0.014358488093748342
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.        PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.              Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8266132,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2012,199915,1300000,-0.0032898560204132395
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.           Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8320160,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'metagenome', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2012,204974,2836411,-0.006882279075184786
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence  Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.  Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8471822,R00LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Screening procedure', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2012,224100,570146095,-0.005444004473472666
"Ontology-based Information Network to Support Vaccine Research  Project Summary (Abstract):  Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.  Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,8311060,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Semantics', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'abstracting', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2012,264994,641965656,0.007873879109053919
"Computational methods for the analysis of RNA-Seq data    DESCRIPTION (provided by applicant): Technologies for the measurement of mRNA quantities within cells are key components of a biomedical researcher<s toolbox. The characterization of gene expression is important to both the understanding of the molecular biology of the cell and the diagnosis and treatment of human disease. To be most useful to scientists, RNA measurement technologies should be as accurate and precise as possible since even small perturbations in transcript levels may be significant. A recently developed experimental method, RNA-Seq, is promising to revolutionize gene expression analysis and is enabling new discoveries about the human transcriptome. RNA-Seq data demands a significant amount of computation before it can be used and the current computational methods are still in their infancy. We propose to take RNA-Seq computational methods to the next level, increasing both the accuracy of gene expression estimates and the number of scenarios in which it may be used. Using novel probabilistic models and statistical learning techniques, we will enable the technology to precisely measure alternative splicing events and characterize the transcriptomes of non-model organisms. Our computational methods will be validated with both real and simulated RNA-Seq data and will be made freely available as an open source software package. In addition, we will use the methods we develop to explore differences between the transcriptomes of undifferentiated and differentiated cells. A first application will be the characterization of alternative splicing differences between human embryonic stem cells and differentiated fibroblast cells. A second application will be the estimation of gene expression levels in embryos of the frog Xenopus leaves using the genome sequence of a closely related frog; Xenopus (Silurana) tropical is as a reference. The results of these experiments are expected to advance our understanding of cellular differentiation in vertebrates and, ultimately, the potential for stem cells to be used in the treatment of human diseases and injuries.      PUBLIC HEALTH RELEVANCE: The proposed research aims to develop computational methods for the support of a technology that measures the quantities of RNA inside of a cell. With this technology and the developed computational methods, researchers will be able to better diagnose and understand the molecular basis of human disease.           Project Narrative The proposed research aims to develop computational methods for the support of a technology that measures the quantities of RNA inside of a cell. With this technology and the developed computational methods, researchers will be able to better diagnose and understand the molecular basis of human disease.",Computational methods for the analysis of RNA-Seq data,8293382,R01HG005232,"['Address', 'Alternative Splicing', 'Area', 'Cell physiology', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Disease', 'Embryo', 'Environment', 'Event', 'Fibroblasts', 'Frequencies', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Profiling', 'Genes', 'Genomics', 'Goals', 'Human', 'Individual', 'Injury', 'Knowledge', 'Learning', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Messenger RNA', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Organism', 'Outcome', 'Output', 'Protein Isoforms', 'Protocols documentation', 'RNA', 'RNA Sequence Analysis', 'RNA Sequences', 'RNA Splicing', 'Rana', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Simulate', 'Spliced Genes', 'Staging', 'Statistical Models', 'Stem cells', 'Structure', 'Techniques', 'Technology', 'Transcript', 'Undifferentiated', 'Vertebrates', 'Work', 'Xenopus', 'Xenopus laevis', 'base', 'blastomere structure', 'computerized data processing', 'genome sequencing', 'human RNA sequencing', 'human disease', 'human embryonic stem cell', 'infancy', 'method development', 'novel', 'open source', 'public health relevance', 'research study', 'xenopus genome']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2012,271772,338121506,-0.013522760865826619
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Public Health Relevance/Narrative Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8208036,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,311786,191864802,0.01682969523301577
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.        Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8294581,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Screening procedure', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild neurocognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2012,348750,507546965,-0.033983738159410505
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.      PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.              Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.",Integration and visualization of diverse biological data,8209212,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diabetic Angiopathies', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'public health relevance', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2012,393228,58504236,-0.007349490163019144
"Scalable Assays for Morphological Analysis of Mammalian Neurons    DESCRIPTION (provided by applicant): Medium and high-throughput assays (i.e., screens) have generally not been applied to mammalian neurons because of the difficulties in culturing them in large numbers and because of the low efficiency with which the genetic makeup of neurons can be altered. Furthermore, because many aspects of neuronal function can only be assayed with electrophysiological assays, follow-up analysis and validation of screening hits is difficult. We propose to use automated imaging approaches to analyze synapse number and neuronal structure in vitro in a scalable format. We have implemented tissue culture and immunostaining approaches to monitor the number and types of synapses formed onto neurons in multi-well plates. We will couple this analysis with lentivirus mediated introduction of short-hairpin RNAs to induce RNA interference against genes expressed in neurons. This will be performed in concert with transcriptional analysis of neurons to determine the key changes in gene expression that correlate with structural and synaptic changes. The proposal represents a significant collaboration between several groups with expertise in functional analysis of neurons, automated analysis of images, viral mediated manipulation of gene expression, and whole-genome transcriptional analysis. We hope that our work will lead, for the first time, to a turn-key and robust method of analysis of neuron and synapse structure suitable for scalable, whole-genome analysis. Such a system will permit the unbiased and systematic analysis of pathways involved in neuropsychiatric diseases including neurodegenerative diseases such as Alzheimer's and Parkinson's as well as neurodevelopmental disorders such as mental retardation and autism.        Massively parallel analysis of cells in many conditions has allowed the discovery of key pathways that control cell function. Unfortunately, these techniques have not been applied to neurons due to difficulties in handling, manipulating, and analyzing large numbers of brain cells. We propose to develop imaging-based techniques to analyze neurons in dishes at a high throughput in order to find pathways that control their development and susceptibility to disease.            ",Scalable Assays for Morphological Analysis of Mammalian Neurons,8306192,R01NS077907,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Antibodies', 'Autistic Disorder', 'Axon', 'Benchmarking', 'Biochemical Pathway', 'Biological Assay', 'Cell Line', 'Cell physiology', 'Cells', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Development', 'Disease', 'Ensure', 'Excitatory Synapse', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Image', 'Image Analysis', 'In Vitro', 'Inhibitory Synapse', 'Institutes', 'Label', 'Lead', 'Machine Learning', 'Measurement', 'Mediating', 'Mental Retardation', 'Methods', 'Mining', 'Mitochondria', 'Monitor', 'Morphology', 'Mus', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuroglia', 'Neurons', 'Organelles', 'Parkinson Disease', 'Pathway Analysis', 'Pathway interactions', 'Phenotype', 'Predisposition', 'Procedures', 'Process', 'Protocols documentation', 'RNA Interference', 'Relative (related person)', 'Screening procedure', 'Structure', 'Subfamily lentivirinae', 'Synapses', 'System', 'Techniques', 'Time', 'Transfection', 'Validation', 'Viral', 'Work', 'base', 'bioimaging', 'brain cell', 'density', 'design', 'fluorescence imaging', 'follow-up', 'genome-wide', 'high throughput screening', 'medical schools', 'neuropsychiatry', 'open source', 'prototype', 'scale up', 'small hairpin RNA', 'synaptogenesis', 'tissue culture', 'tool']",NINDS,HARVARD MEDICAL SCHOOL,R01,2012,422500,178569161,-0.012219618856333155
"Efficient patient-specific cell generation by image-guidance    DESCRIPTION (provided by applicant): This fast-track proposal applies advanced kinetic image pattern recognition (KIPR) technologies to predict induced pluripotent stem cell (iPSC) reprogramming colonies' differentiation outcomes for significantly improved yield and robustness of differentiation protocols. The objectives of the proposed tool are 1) Teaching: creation of scores for induced colony differentiation outcome prediction by machine learning; 2) Reprogramming: optimal reprogramming harvest time determination by continuous colony score monitoring; 3) Differentiation: selection of colonies with the highest prediction scores for differentiation at the reprogramming harvest time; 4) Differentiation: cell cluster quality control by continuous monitoring during differentiation. The specific aims of this fast-track proposal are Phase I: 1) Extend SVCell for the prediction of induced colony differentiation outcomes ; 2) Validate that prediction of colony differentiation outcomes can improve the yield of CM differentiation. Phase II: 1) Validate that the integrated system can be taught to be robust and high yielding for a diverse set of human fibroblast input samples and different reprogramming / differentiation protocols; 2) Integrate SVCell with a state-of-the-art continuous cell imaging and culture system to create a prototype patient-specific cell generation system; 3) Validate the integrated system as a patient-specific cell generation product. The ultimate goal of this fast-track proposal is to develop and validate an image-guided efficient patient-specific cardiomyocyte generation system. This will be achieved by integrating our established SVCell software containing advanced KIPR technologies with a live cell imaging technology to synthesize state-of-the-art cell fate control protocols against iPSC. Patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. Successful development of the patient-specific cell generation system of this proposal could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.        Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.         ",Efficient patient-specific cell generation by image-guidance,8392472,R44HL106863,"['Biotechnology', 'Brain Diseases', 'Cardiac Myocytes', 'Cell Culture System', 'Cell Differentiation process', 'Cell Fate Control', 'Cells', 'Cellular Morphology', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Fibroblasts', 'Generations', 'Goals', 'Government', 'Harvest', 'Health', 'Healthcare', 'Heart', 'Human', 'Image', 'Imaging technology', 'Institutes', 'Kinetics', 'Life', 'Machine Learning', 'Medicine', 'Metric', 'Monitor', 'Outcome', 'Patients', 'Pattern Recognition', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Production', 'Protocols documentation', 'Quality Control', 'Sampling', 'Staging', 'Staining method', 'Stains', 'Stem cells', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Work', 'alanine aminopeptidase', 'base', 'cell type', 'cellular imaging', 'cost', 'cost effectiveness', 'disease diagnosis', 'drug discovery', 'drug testing', 'human embryonic stem cell', 'improved', 'induced pluripotent stem cell', 'patient population', 'prototype', 'stem cell technology', 'tool', 'usability']",NHLBI,"DRVISION TECHNOLOGIES, LLC",R44,2012,987686,1296025,-0.0015183162819843604
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8274480,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Screening procedure', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2012,1070334,673201228,-0.026964849397697277
"The Cardiovascular Research Grid    DESCRIPTION (provided by applicant):       The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinafions of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotafing ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and mofion that can predict the early presence of developing heart disease in fime for therapeufic intervenfion. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informafics system that allows clinical informafion to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG.  RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease. (End of Abstract)          The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store,  manage, and analyze data on the structure and function of the cardiovascular system in health and disease.  The CVRG Project has developed and deployed unique technology that is now being used in a broad range  of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to  explore and analvze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8240702,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Time', 'Ultrasonography', 'Work', 'abstracting', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2012,2194299,807432003,0.016050358970658457
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence    DESCRIPTION (provided by applicant): Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.           Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8190163,K99LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Screening procedure', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2011,89802,570146095,-0.005066559709076656
"Semi-Automated Abstract Screening for Comparative Effectiveness Reviews    DESCRIPTION (provided by applicant): In this three-year project, we aim to apply state-of-the-art information analysis technologies to assist the production of systematic reviews and meta-analyses that are increasingly being used as a foundation for evidence-based medicine (EBM) and comparative effectiveness reviews. We plan to develop a human guided computerized abstract screening tool to greatly reduce the need to perform a tedious but crucial step of manually screening many thousands of abstracts generated by literature searches in order to retrieve a small fraction potentially relevant for further analysis. This tool will combine proven machine learning techniques with a new open source tool that enables management of the screening process. This new technology will enable investigators to screen abstracts in a small fraction of the time compared to the current manual process. It will reduce the time and cost of producing systematic reviews, provide clear documentation of the process and potentially perform the task more accurately. With the acceptance of EBM and increasing demands for systematic reviews, there is a great need for tools to assist in generating new systematic reviews and in updating them. This need cannot be more pressing. The recent passage of the American Recovery and Reinvestment Act and the $1.1 billion allocated for comparative effectiveness research have created an unprecedented need for systematic reviews and opportunities to improve the methodologies and efficiency of their conduct.   We herein propose the development of novel, open-source software to help systematic reviewers better   cope with these torrents of data. The research and development of this tool will be carried out by a highly experienced team of systematic review investigators with computer scientists at Tufts University who began to collaborate last year as a result of Tufts being awarded one of the NIH Clinical Translational Science Awards (CTSA). We will pursue dissemination of the new technology through numerous channels including, but not limited to publication, presentation at conferences, exploring interest in its adoption by the Agency for Healthcare Research and Quality (AHRQ) Evidence-based Practice Center (EPC) Program, Cochrane Collaboration, CTSA network, and other groups conducting systematic reviews, and production of tutorial material. Our aims are:   1. Conduct research to design and implement a semi-automated system using machine learning and   information retrieval methods to identify relevant abstracts in order to improve the accuracy and efficiency of systematic reviews.   2. Develop Abstrackr, an open-source system with a Graphical User Interface (GUI) for screening abstracts, that applies the methods developed in Aim 1 to automatically exclude irrelevant abstracts/articles.   3. Evaluate the performance of the active learning model developed in Aim 1 and the functionality of   Abstrackr developed in Aim 2 through application to a collection of manually screened datasets of   biomedical abstracts that will subsequently be made publicly available for use as a repository to spur   research in the machine learning and information retrieval communities.           Systematic reviewing is a scientific approach to objectively summarizing the effectiveness and safety of existing treatments for diseases, a prerequisite for informed healthcare decision-making. Systematic reviewers must read many thousands of medical study abstracts, the vast majority of which are completely irrelevant to the review at hand. This is hugely laborious and time consuming. We propose to build a computerized system that automatically excludes a large number of the irrelevant abstracts, thereby accelerating the process and expediting the application of the systematic review findings to patient care.",Semi-Automated Abstract Screening for Comparative Effectiveness Reviews,8115129,R01HS018494,[' '],AHRQ,TUFTS MEDICAL CENTER,R01,2011,136978,17640378,0.0057284282138516315
"PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY    DESCRIPTION (provided by applicant): Well trained, experienced gastroenterologists in academic and high volume settings can reliably recognize 97% of pathologies in Capsule Endoscopy (CE) video. However, community physicians and infrequent users may miss up to 20%. The end goal of our proposed new line of research is to develop clinical software that provides automatic decision support to physicians who are trying to declare that a patient is pathology free or has a certain disease process. The risk for the physician - and their patients - is that of a less than optimal clinical outcome due to:  1) missing a lesion/pathology in the video and putting the patient at risk of developing a more serious condition over time, or  2) mistakenly ""identifying"" a pathology that is not present and thus subjecting the patient to unnecessary further diagnostic or surgical procedures.  The research aims in this proposal will enable Ikona to create a pathology prioritization image processing module. Implementing modern machine learning techniques such as Support Vector Machines (SVM) and Adaboost methodologies together with proprietary image feature analysis, this technology will assign a probability metric to every frame in the image sequence for specific pathology (lesions, ulcers, bleeding, etc) and the major landmarks in the GI tract (ileo-cecal valve, pyloric valve etc.). Filtering and sorting endoscopy image data will be done such that the images with the highest probability of containing pathology will be presented to the reviewer first.  This pathology prioritized sequencing is not intended to replace the clinician in the workflow, but rather to allow the clinician to focus more time on frames with a higher potential of containing pathology. Often times, clinically significant pathology may only be present in a single frame. A single ""pathological"" frame in the middle of a 50,000 frame sequence can easily be overlooked by a novice reviewer or a reviewer whose attention is temporarily distracted. With our proposed pathology prioritization, that single pathological frame will be identified and sorted near the beginning of the image sequence thus greatly increasing the likelihood of detection by the reviewer.  Specifically for Phase I, we plan to investigate and develop different algorithms for classifying image frames and recognizing pathological and normal frames, and, algorithms for ranking frames by severity of pathology. Following the implementation of a working prototype, we will further test the clinical utility of these algorithms with human clinical capsule endoscopy videos.      PUBLIC HEALTH RELEVANCE: Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.           Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.         ",PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY,8057895,R43DK091083,"['Affect', 'Algorithms', 'American', 'Attention', 'Blood', 'Categories', 'Classification', 'Classification Scheme', 'Clinical', 'Community Physician', 'Computer software', 'Crohn&apos', 's disease', 'Data', 'Data Set', 'Databases', 'Deformity', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Disease', 'Endoscopy', 'Evaluation', 'Family', 'Fatigue', 'Gastroenterologist', 'Gastrointestinal tract structure', 'Goals', 'Hemorrhage', 'Hour', 'Human', 'Image', 'Imagery', 'Lesion', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Metric', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Phase', 'Physicians', 'Polyps', 'Population', 'Probability', 'Procedures', 'Process', 'Readability', 'Reader', 'Reading', 'Research', 'Risk', 'Risk Reduction', 'Severities', 'Small Intestines', 'Sorting - Cell Movement', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Training Support', 'Ulcer', 'Work', 'base', 'capsule', 'clinically relevant', 'clinically significant', 'cost', 'experience', 'gastrointestinal', 'image processing', 'improved', 'innovation', 'interest', 'prospective', 'prototype', 'tumor']",NIDDK,IKONA MEDICAL CORPORATION,R43,2011,176778,0,-0.010712109528264282
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.      PUBLIC HEALTH RELEVANCE:    Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.                 Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8192895,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2011,180669,2836411,-0.0018773915152288654
"Human-Centered Perceptual and Conceptual Classification of Biomedical Images    DESCRIPTION (provided by applicant): Biomedical images are ever increasing in quantity and importance yet effective computing solutions for managing images and understanding their content are lacking. Image understanding is a key limiting factor in advancing these endeavors. Major challenges remain in understanding the capabilities of the human visual system with respect to biomedical imaging and in extracting and utilizing tacit knowledge of domain experts. To meet these challenges, we propose an innovative, multidisciplinary approach which combines methods of user centered design, visual perception and computer imaging research to interact with domain experts and to elicit and use their extrinsic and intrinsic knowledge. We will use a novel contextual design approach to inspection of dermatology images to discover relationships between perceptually- relevant visual content of images and users' conceptual understanding as expressed through natural language. Analysis of users' eye movements and verbal descriptions, together with mapping to domain medical ontologies, will allow us to integrate visual data with a user-specified language model to define perceptual categories and inform image classification. This is a fundamental and challenging data to knowledge problem that has not been solved. This study will provide proof of concept of the value of eliciting tacit knowledge from domain experts through multiple perceptually relevant modes in order to integrate data and knowledge models for better image understanding and may help enact a paradigm shift in how we conceptualize and develop biomedical information systems, in general.             Project Narrative Biomedical images are ever increasing in quantity yet their usefulness for research, medicine, and teaching is limited by the design of current computing systems. Discoveries and concrete advances made in this study will contribute to solutions for effective use of digital images-a problem that is central to research and application across science, technology, and medicine. Advancements in our understanding of the design of useful and usable information systems will benefit society at large and contribute to the public health.  ",Human-Centered Perceptual and Conceptual Classification of Biomedical Images,8077991,R21LM010039,"['Algorithms', 'Categories', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Computer Systems', 'Conceptual Domain', 'Data', 'Data Set', 'Dermatologist', 'Dermatology', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Information Resources', 'Information Systems', 'Internet', 'Knowledge', 'Language', 'Learning', 'Link', 'Maps', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Perception', 'Phase', 'Process', 'Public Health', 'Research', 'Retrieval', 'Science', 'Semantics', 'Societies', 'Solutions', 'Specific qualifier value', 'Statistical Models', 'Structure', 'System', 'Technology', 'Training', 'Unified Medical Language System', 'Validation', 'Visual', 'Visual Perception', 'Visual system structure', 'base', 'bioimaging', 'biomedical information system', 'design', 'digital imaging', 'innovation', 'interdisciplinary approach', 'interest', 'meetings', 'natural language', 'novel', 'success', 'tool', 'user centered design', 'vector']",NLM,ROCHESTER INSTITUTE OF TECHNOLOGY,R21,2011,192348,3619659,-0.001999959248238244
"Digital image analysis for quantitative and qualitative assessment of pig islets    DESCRIPTION (provided by applicant): The demonstration by the Edmonton group that human islet transplantation can be successfully used to manage adult type 1 diabetes patients with refractory hypoglycemia has led to increased funding of clinical trials and further research to extend the scope of this therapy by using porcine islets in place of human islets. Significant advances have been made in improving immunosuppression treatment regimens so that results obtained from treating adult diabetic patients with human islet transplants are similar to those obtained after pancreas transplantation. The major hurdle to move this therapy from clinical research to routine clinical practice is to improve the yield and quality of islets recovered from human or porcine pancreas. Presently, there are no standardized methods that can accurately assess the number or quality of islets that are used in the islet transplantation procedures so that results between laboratories can be objectively evaluated. This grant is focused on developing a robust, islet image analysis software to objectively analyze the number and quality of porcine islets recovered from the pancreas. The two major aims of the project are first to develop an improved image analysis software program that will provide a standardized measurement of the number and mass of porcine islets in a cell preparation. And second, enhance the capabilities of the software program by correlating the image signatures of each porcine islet to an artificial category. Porcine islets of similar size will be handpicked and sorted into three categories based on the shape, border, integrity, or uniformity of dithizone staining. The first software enhancement will find those features in the images that can be used to distinguish the different categories of islets. The second enhancement will assess the feasibility of using machine learning methods to correlate these features with data recovered from the images but also other discrete or continuous variables that are used to characterize the porcine islet preparations. If successful, the ability to use a rapid and objective image analysis methodology will improve the assessment of the number and quality of islets within and between laboratories; correlate image features with success of transplantation as measured by graft survival and insulin independence; and improve the islet isolation methods to achieve favorable islet image scores that are determined by retrospective analysis. The ability of a commercial firm focused on improving islet yields by focusing on tissue dissociation with a leading academic laboratory that has sophisticated expertise in developing software algorithms from microscopic images provides a fresh approach to a difficult medical that needs to be resolved to realize the full potential of islet transplantation to treat adult type 1 diabetic patients.      PUBLIC HEALTH RELEVANCE: An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.           An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.         ",Digital image analysis for quantitative and qualitative assessment of pig islets,8058009,R43DK091103,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Biochemical', 'Biological', 'Biological Assay', 'Caliber', 'Categories', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computer Assisted', 'Computer software', 'Data', 'Data Collection', 'Development', 'Dissociation', 'Dithizone', 'Drops', 'Enzymes', 'Family suidae', 'Feasibility Studies', 'Funding', 'Genetic', 'Glucose', 'Graft Survival', 'Grant', 'Human', 'Hypoglycemia', 'Image', 'Image Analysis', 'Immunosuppression', 'In Vitro', 'Insulin', 'Insulin-Dependent Diabetes Mellitus', 'Islet Cell', 'Islets of Langerhans Transplantation', 'Laboratories', 'Liver', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microscope', 'Microscopic', 'Modification', 'Optics', 'Organ', 'Outcome', 'Pancreas', 'Pancreas Transplantation', 'Pathway interactions', 'Patients', 'Pattern Recognition', 'Pattern Recognition Systems', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Portal vein structure', 'Predictive Value', 'Preparation', 'Procedures', 'Proteomics', 'Protocols documentation', 'Recovery', 'Refractory', 'Reporting', 'Research', 'Sampling', 'Sampling Errors', 'Scientist', 'Screening procedure', 'Shapes', 'Sorting - Cell Movement', 'Staining method', 'Stains', 'Standardization', 'Statistical Models', 'Stress', 'Structure', 'Survival Rate', 'System', 'Techniques', 'Time', 'Tissues', 'Transplantation', 'Treatment Protocols', 'base', 'cell preparation', 'clinical practice', 'diabetic patient', 'digital', 'digital imaging', 'improved', 'indexing', 'innovation', 'islet', 'programs', 'software development', 'standardize measure', 'success', 'tool', 'type I diabetic']",NIDDK,"VITACYTE, LLC",R43,2011,232329,0,-0.001264070821826792
"Statistical Model Building for High Dimensional Biomedical Data    DESCRIPTION (provided by applicant):  Typical of current large-scale biomedical data is the feature of small number of observed samples and the widely observed sample heterogeneity. Identifying differentially expressed genes related to the sample phenotye (e.g., cancer disease development) and predicting sample phenotype based on the gene expressions are some central research questions in the microarray data analysis. Most existing statistical methods have ignored sample heterogeneity and thus loss power.       This project proposes to develop novel statistical methods that explicitly address the small sample size and sampe heterogeneity issues, and can be applied very generally. The usefulness of these methods will be shown with the large-scale biomedical data originating from the lung and kidney transplant research projects. The transplant projects aimed to improve the molecular diagnosis and therapy of lung/kidney allograft rejection by identifying molecular biomarkers to predict the allograft rejection for critical early treatment and rapid, noninvasive, and economical testing.       The specific aims are 1) Develop novel statistical methods for differential gene expression detection that explicitly model sample heterogeneity. 2) Develop novel statistical methods for classifying high-dimensional biomedical data and incorporating sample heterogeneity. 3) Develop novel statistical methods for jointly analyzing a set of genes (e.g., genes in a pathway). 4) Use the developed models and methods to answer research questions relevant to public health in the lung and kidney transplant projects; and implement and validate the proposed methods in user-friendly and well-documented software, and distribute them to the scientific community at no charge.       It is very important to identify new biomarkers of allograft rejection in lung and kidney transplant recipients. The rapid and reliable detection and prediction of rejection in easily obtainable body fluids may allow the rapid advancement of clinical interventional trials. We propose to study novel methods for analyzing the large-scale biomedical data to realize their full potential of molecular diagnosis and prognosis of transplant rejection prediction for critical early treatment.          n/a",Statistical Model Building for High Dimensional Biomedical Data,8079474,R01GM083345,"['Address', 'Adopted', 'Algorithms', 'Biological Markers', 'Body Fluids', 'Cations', 'Characteristics', 'Charge', 'Clinical', 'Collection', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early treatment', 'Effectiveness', 'Experimental Designs', 'Gene Expression', 'Genes', 'Genomics', 'Graft Rejection', 'Heterogeneity', 'Individual', 'Internet', 'Joints', 'Kidney Transplantation', 'Least-Squares Analysis', 'Literature', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Minnesota', 'Modeling', 'Molecular', 'Molecular Diagnosis', 'Oncogene Activation', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Phenotype', 'Principal Component Analysis', 'Probability', 'Procedures', 'Public Health', 'Relative (related person)', 'Research', 'Research Project Grants', 'Research Proposals', 'Resources', 'Sample Size', 'Sampling', 'Silicon Dioxide', 'Statistical Methods', 'Statistical Models', 'Technology', 'Testing', 'Tissue-Specific Gene Expression', 'Transplant Recipients', 'Transplantation', 'Universities', 'Ursidae Family', 'Work', 'allograft rejection', 'base', 'biobank', 'cancer microarray', 'cancer type', 'design', 'improved', 'interest', 'kidney allograft', 'method development', 'novel', 'outcome forecast', 'predictive modeling', 'simulation', 'software development', 'sound', 'theories', 'transplant database', 'user friendly software', 'user-friendly']",NIGMS,UNIVERSITY OF MINNESOTA,R01,2011,250488,340417756,-0.024356909617159313
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,8120230,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Semantics', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2011,264994,641965656,0.008581702223175933
"Computational methods for the analysis of RNA-Seq data    DESCRIPTION (provided by applicant): Technologies for the measurement of mRNA quantities within cells are key components of a biomedical researcher<s toolbox. The characterization of gene expression is important to both the understanding of the molecular biology of the cell and the diagnosis and treatment of human disease. To be most useful to scientists, RNA measurement technologies should be as accurate and precise as possible since even small perturbations in transcript levels may be significant. A recently developed experimental method, RNA-Seq, is promising to revolutionize gene expression analysis and is enabling new discoveries about the human transcriptome. RNA-Seq data demands a significant amount of computation before it can be used and the current computational methods are still in their infancy. We propose to take RNA-Seq computational methods to the next level, increasing both the accuracy of gene expression estimates and the number of scenarios in which it may be used. Using novel probabilistic models and statistical learning techniques, we will enable the technology to precisely measure alternative splicing events and characterize the transcriptomes of non-model organisms. Our computational methods will be validated with both real and simulated RNA-Seq data and will be made freely available as an open source software package. In addition, we will use the methods we develop to explore differences between the transcriptomes of undifferentiated and differentiated cells. A first application will be the characterization of alternative splicing differences between human embryonic stem cells and differentiated fibroblast cells. A second application will be the estimation of gene expression levels in embryos of the frog Xenopus leaves using the genome sequence of a closely related frog; Xenopus (Silurana) tropical is as a reference. The results of these experiments are expected to advance our understanding of cellular differentiation in vertebrates and, ultimately, the potential for stem cells to be used in the treatment of human diseases and injuries.      PUBLIC HEALTH RELEVANCE: The proposed research aims to develop computational methods for the support of a technology that measures the quantities of RNA inside of a cell. With this technology and the developed computational methods, researchers will be able to better diagnose and understand the molecular basis of human disease.           Project Narrative The proposed research aims to develop computational methods for the support of a technology that measures the quantities of RNA inside of a cell. With this technology and the developed computational methods, researchers will be able to better diagnose and understand the molecular basis of human disease.",Computational methods for the analysis of RNA-Seq data,8101207,R01HG005232,"['Address', 'Alternative Splicing', 'Area', 'Cell physiology', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Disease', 'Embryo', 'Environment', 'Event', 'Fibroblasts', 'Frequencies', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Profiling', 'Genes', 'Genomics', 'Goals', 'Human', 'Individual', 'Injury', 'Knowledge', 'Learning', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Messenger RNA', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Organism', 'Outcome', 'Output', 'Protein Isoforms', 'Protocols documentation', 'RNA', 'RNA Sequence Analysis', 'RNA Sequences', 'RNA Splicing', 'Rana', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Simulate', 'Spliced Genes', 'Staging', 'Statistical Models', 'Stem cells', 'Structure', 'Techniques', 'Technology', 'Transcript', 'Undifferentiated', 'Vertebrates', 'Work', 'Xenopus', 'Xenopus laevis', 'base', 'blastomere structure', 'computerized data processing', 'genome sequencing', 'human RNA sequencing', 'human disease', 'human embryonic stem cell', 'infancy', 'method development', 'novel', 'open source', 'public health relevance', 'research study', 'xenopus genome']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2011,271791,338121506,-0.013522760865826619
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8022635,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,304318,191864802,0.016970006955252033
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.      PUBLIC HEALTH RELEVANCE: Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.           Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8116342,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Screening procedure', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild neurocognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2011,324000,507546965,-0.041220430390061104
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.           Project Narrative The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.",Scalable Learning with Ensemble Techniques and Parallel Computing,8045486,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Biological Sciences', 'Biomedical Research', 'Classification', 'Communication', 'Communities', 'Community Financing', 'Companions', 'Complex', 'Computer software', 'Consult', 'Crowding', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Health', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'new technology', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2011,374673,0,0.017095416506464282
"Efficient patient-specific cell generation by image-guidance    DESCRIPTION (provided by applicant): This fast-track proposal applies advanced kinetic image pattern recognition (KIPR) technologies to predict induced pluripotent stem cell (iPSC) reprogramming colonies' differentiation outcomes for significantly improved yield and robustness of differentiation protocols. The objectives of the proposed tool are 1) Teaching: creation of scores for induced colony differentiation outcome prediction by machine learning; 2) Reprogramming: optimal reprogramming harvest time determination by continuous colony score monitoring; 3) Differentiation: selection of colonies with the highest prediction scores for differentiation at the reprogramming harvest time; 4) Differentiation: cell cluster quality control by continuous monitoring during differentiation. The specific aims of this fast-track proposal are Phase I: 1) Extend SVCell for the prediction of induced colony differentiation outcomes ; 2) Validate that prediction of colony differentiation outcomes can improve the yield of CM differentiation. Phase II: 1) Validate that the integrated system can be taught to be robust and high yielding for a diverse set of human fibroblast input samples and different reprogramming / differentiation protocols; 2) Integrate SVCell with a state-of-the-art continuous cell imaging and culture system to create a prototype patient-specific cell generation system; 3) Validate the integrated system as a patient-specific cell generation product. The ultimate goal of this fast-track proposal is to develop and validate an image-guided efficient patient-specific cardiomyocyte generation system. This will be achieved by integrating our established SVCell software containing advanced KIPR technologies with a live cell imaging technology to synthesize state-of-the-art cell fate control protocols against iPSC. Patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. Successful development of the patient-specific cell generation system of this proposal could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.      PUBLIC HEALTH RELEVANCE: Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.           Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.         ",Efficient patient-specific cell generation by image-guidance,8058635,R44HL106863,"['Biotechnology', 'Brain Diseases', 'Cardiac Myocytes', 'Cell Culture System', 'Cell Differentiation process', 'Cell Fate Control', 'Cells', 'Cellular Morphology', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Fibroblasts', 'Generations', 'Goals', 'Government', 'Harvest', 'Health', 'Healthcare', 'Heart', 'Human', 'Image', 'Imaging technology', 'Institutes', 'Kinetics', 'Life', 'Machine Learning', 'Medicine', 'Metric', 'Monitor', 'Outcome', 'Patients', 'Pattern Recognition', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Production', 'Protocols documentation', 'Quality Control', 'Sampling', 'Staging', 'Staining method', 'Stains', 'Stem cells', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Work', 'alanine aminopeptidase', 'base', 'cell type', 'cellular imaging', 'cost', 'cost effectiveness', 'disease diagnosis', 'drug discovery', 'drug testing', 'human embryonic stem cell', 'improved', 'induced pluripotent stem cell', 'patient population', 'prototype', 'stem cell technology', 'tool', 'usability']",NHLBI,"DRVISION TECHNOLOGIES, LLC",R44,2011,374865,1296025,-0.0041491904050880175
"Scalable Assays for Morphological Analysis of Mammalian Neurons    DESCRIPTION (provided by applicant): Medium and high-throughput assays (i.e., screens) have generally not been applied to mammalian neurons because of the difficulties in culturing them in large numbers and because of the low efficiency with which the genetic makeup of neurons can be altered. Furthermore, because many aspects of neuronal function can only be assayed with electrophysiological assays, follow-up analysis and validation of screening hits is difficult. We propose to use automated imaging approaches to analyze synapse number and neuronal structure in vitro in a scalable format. We have implemented tissue culture and immunostaining approaches to monitor the number and types of synapses formed onto neurons in multi-well plates. We will couple this analysis with lentivirus mediated introduction of short-hairpin RNAs to induce RNA interference against genes expressed in neurons. This will be performed in concert with transcriptional analysis of neurons to determine the key changes in gene expression that correlate with structural and synaptic changes. The proposal represents a significant collaboration between several groups with expertise in functional analysis of neurons, automated analysis of images, viral mediated manipulation of gene expression, and whole-genome transcriptional analysis. We hope that our work will lead, for the first time, to a turn-key and robust method of analysis of neuron and synapse structure suitable for scalable, whole-genome analysis. Such a system will permit the unbiased and systematic analysis of pathways involved in neuropsychiatric diseases including neurodegenerative diseases such as Alzheimer's and Parkinson's as well as neurodevelopmental disorders such as mental retardation and autism.      PUBLIC HEALTH RELEVANCE: Massively parallel analysis of cells in many conditions has allowed the discovery of key pathways that control cell function. Unfortunately, these techniques have not been applied to neurons due to difficulties in handling, manipulating, and analyzing large numbers of brain cells. We propose to develop imaging-based techniques to analyze neurons in dishes at a high throughput in order to find pathways that control their development and susceptibility to disease.              Massively parallel analysis of cells in many conditions has allowed the discovery of key pathways that control cell function. Unfortunately, these techniques have not been applied to neurons due to difficulties in handling, manipulating, and analyzing large numbers of brain cells. We propose to develop imaging-based techniques to analyze neurons in dishes at a high throughput in order to find pathways that control their development and susceptibility to disease.            ",Scalable Assays for Morphological Analysis of Mammalian Neurons,8192511,R01NS077907,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Antibodies', 'Autistic Disorder', 'Axon', 'Benchmarking', 'Biochemical Pathway', 'Biological Assay', 'Cell Line', 'Cell physiology', 'Cells', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Development', 'Disease', 'Ensure', 'Excitatory Synapse', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Image', 'Image Analysis', 'In Vitro', 'Inhibitory Synapse', 'Institutes', 'Label', 'Lead', 'Machine Learning', 'Measurement', 'Mediating', 'Mental Retardation', 'Methods', 'Mining', 'Mitochondria', 'Monitor', 'Morphology', 'Mus', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuroglia', 'Neurons', 'Organelles', 'Parkinson Disease', 'Pathway Analysis', 'Pathway interactions', 'Phenotype', 'Predisposition', 'Procedures', 'Process', 'Protocols documentation', 'RNA Interference', 'Relative (related person)', 'Screening procedure', 'Structure', 'Subfamily lentivirinae', 'Synapses', 'System', 'Techniques', 'Time', 'Transfection', 'Validation', 'Viral', 'Work', 'base', 'bioimaging', 'brain cell', 'density', 'design', 'fluorescence imaging', 'follow-up', 'genome-wide', 'high throughput screening', 'medical schools', 'neuropsychiatry', 'open source', 'prototype', 'scale up', 'small hairpin RNA', 'synaptogenesis', 'tissue culture', 'tool']",NINDS,HARVARD MEDICAL SCHOOL,R01,2011,422500,178569161,-0.008395691735961592
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.      PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.              Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.            ",Integration and visualization of diverse biological data,8041717,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diabetic Angiopathies', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2011,433016,58504236,-0.007349490163019144
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,8139155,R44RR024094,"['AIDS/HIV problem', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cell physiology', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2011,449663,0,0.003389359939664638
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8147701,U19ES019528,[' '],NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2011,1090598,673201228,-0.026964849397697277
"The Cardiovascular Research Grid    DESCRIPTION (provided by applicant):       The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinafions of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotafing ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and mofion that can predict the early presence of developing heart disease in fime for therapeufic intervenfion. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informafics system that allows clinical informafion to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG.  RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease. (End of Abstract)          The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store,  manage, and analyze data on the structure and function of the cardiovascular system in health and disease.  The CVRG Project has developed and deployed unique technology that is now being used in a broad range  of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to  explore and analvze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8017600,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Time', 'Ultrasonography', 'Work', 'abstracting', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2011,2241978,807432003,0.016050358970658457
"Development of a Research-Ready Pregnancy and Newborn Biobank in California    DESCRIPTION (provided by applicant): Development of a Research-Ready Pregnancy and Newborn Biobank in California Population-based biobanks are a critical resource for identifying disease mechanisms and developing screening tests for biomarkers associated with certain disorders. The California Department of Public Health has been banking newborn specimens statewide since 1982 (N~14 million) and maternal prenatal specimens for a portion of the state since 2000 (N~1 million), creating one of the largest, if not the largest single biological specimen banks with linked data in the world. With the fast pace of new knowledge in genetics and laboratory methods, the demand for specimens and data from researchers around the world now far surpasses the Department's ability to fill them. The goal of this infrastructure development project is to create an efficient, high throughput, low cost newborn screening and prenatal/maternal screening specimen biobank and linked data base that could be used by large numbers of researchers around the world for a wide range of studies through the following aims: (1) establishment of highly efficient protocols and procurement and integration of automated systems for pulling and processing specimens; (2) development of an integrated specimen tracking system into the Department's existing web-based Screening Information System; (3) development of a computerized system to track application requests for specimens and data; and (4) development of a linked screening program-vital records database that is organized into a life course, client based system. These aims will be accomplished through expansion of the Department's award-winning Screening Integration System to include web-based tracking of specimens and research requests, and use of an innovative machine-learning record matching application for high-performance linkages. After the 2 year grant period is completed, the California Research Ready Biospecimen Bank will be able to provide researchers with valuable biological specimens in a timely, cost-effective manner, thereby enabling a dramatic expansion of epidemiological research nationwide. The continuity of the system will be ensured by codifying human subjects-sensitive policies and procedures into Departmental regulations and by charging researchers modest fees for specimens, data and other research services.      PUBLIC HEALTH RELEVANCE: Development of a research-ready pregnancy and newborn biobank in California This proposal funds infrastructure development to create a research-ready, efficient, high- throughput, and low-cost prenatal and newborn biobank in California. Specimens spanning 28 years will be linked to existing records of fetal death, live birth, death, prenatal and newborn screening to develop a rich, client-based, cross-generational, life- course database. Specimens and linked data from the California Research-Ready Biospecimen Bank will be made available to researchers in the U.S. and around the world to enable a broad and expanded array of studies.           Program Narrative Development of a research-ready pregnancy and newborn biobank in California This proposal funds infrastructure development to create a research-ready, efficient, high- throughput, and low-cost prenatal and newborn biobank in California. Specimens spanning 28 years will be linked to existing records of fetal death, live birth, death, prenatal and newborn screening to develop a rich, client-based, cross-generational, life- course database. Specimens and linked data from the California Research-Ready Biospecimen Bank will be made available to researchers in the U.S. and around the world to enable a broad and expanded array of studies.",Development of a Research-Ready Pregnancy and Newborn Biobank in California,7945336,RC2HD065514,"['Area', 'Award', 'Biological', 'Biological Markers', 'Biological Specimen Banks', 'California', 'Case-Control Studies', 'Cessation of life', 'Charge', 'Client', 'Data', 'Data Files', 'Databases', 'Development', 'Disease', 'Ensure', 'Epidemiology', 'Family Study', 'Fees', 'Fetal Death', 'Funding', 'Future', 'Genetic', 'Goals', 'Government', 'Grant', 'Information Systems', 'Infusion procedures', 'Knowledge', 'Laboratories', 'Laws', 'Life Cycle Stages', 'Link', 'Live Birth', 'Machine Learning', 'Methods', 'Multiple Pregnancy', 'Neonatal Screening', 'Newborn Infant', 'Online Systems', 'Performance', 'Policies', 'Population', 'Pregnancy', 'Principal Investigator', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Records', 'Regulation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Screening procedure', 'Services', 'Specimen', 'Specimen Handling', 'Study Subject', 'System', 'Systems Integration', 'Testing', 'Time', 'Woman', 'abstracting', 'base', 'biobank', 'cohort', 'computerized', 'cost', 'human subject', 'infrastructure development', 'innovation', 'population based', 'prenatal', 'programs']",NICHD,SEQUOIA FOUNDATION,RC2,2010,1,0,-0.016719935255698478
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8146748,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Screening procedure', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'predictive modeling', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2010,27441,673201228,-0.026964849397697277
"Human-Centered Perceptual and Conceptual Classification of Biomedical Images    DESCRIPTION (provided by applicant): Biomedical images are ever increasing in quantity and importance yet effective computing solutions for managing images and understanding their content are lacking. Image understanding is a key limiting factor in advancing these endeavors. Major challenges remain in understanding the capabilities of the human visual system with respect to biomedical imaging and in extracting and utilizing tacit knowledge of domain experts. To meet these challenges, we propose an innovative, multidisciplinary approach which combines methods of user centered design, visual perception and computer imaging research to interact with domain experts and to elicit and use their extrinsic and intrinsic knowledge. We will use a novel contextual design approach to inspection of dermatology images to discover relationships between perceptually- relevant visual content of images and users' conceptual understanding as expressed through natural language. Analysis of users' eye movements and verbal descriptions, together with mapping to domain medical ontologies, will allow us to integrate visual data with a user-specified language model to define perceptual categories and inform image classification. This is a fundamental and challenging data to knowledge problem that has not been solved. This study will provide proof of concept of the value of eliciting tacit knowledge from domain experts through multiple perceptually relevant modes in order to integrate data and knowledge models for better image understanding and may help enact a paradigm shift in how we conceptualize and develop biomedical information systems, in general.             Project Narrative Biomedical images are ever increasing in quantity yet their usefulness for research, medicine, and teaching is limited by the design of current computing systems. Discoveries and concrete advances made in this study will contribute to solutions for effective use of digital images-a problem that is central to research and application across science, technology, and medicine. Advancements in our understanding of the design of useful and usable information systems will benefit society at large and contribute to the public health.  ",Human-Centered Perceptual and Conceptual Classification of Biomedical Images,7896281,R21LM010039,"['Algorithms', 'Categories', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Computer Systems', 'Conceptual Domain', 'Data', 'Data Set', 'Dermatologist', 'Dermatology', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Information Resources', 'Information Systems', 'Internet', 'Knowledge', 'Language', 'Learning', 'Link', 'Maps', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Perception', 'Phase', 'Process', 'Public Health', 'Research', 'Retrieval', 'Science', 'Semantics', 'Societies', 'Solutions', 'Specific qualifier value', 'Statistical Models', 'Structure', 'System', 'Technology', 'Training', 'Unified Medical Language System', 'Validation', 'Visual', 'Visual Perception', 'Visual system structure', 'base', 'bioimaging', 'biomedical information system', 'design', 'digital imaging', 'innovation', 'interdisciplinary approach', 'interest', 'meetings', 'natural language', 'novel', 'success', 'tool', 'user centered design', 'vector']",NLM,ROCHESTER INSTITUTE OF TECHNOLOGY,R21,2010,163457,3619659,-0.001999959248238244
"Statistical Model Building for High Dimensional Biomedical Data    DESCRIPTION (provided by applicant):  Typical of current large-scale biomedical data is the feature of small number of observed samples and the widely observed sample heterogeneity. Identifying differentially expressed genes related to the sample phenotye (e.g., cancer disease development) and predicting sample phenotype based on the gene expressions are some central research questions in the microarray data analysis. Most existing statistical methods have ignored sample heterogeneity and thus loss power.       This project proposes to develop novel statistical methods that explicitly address the small sample size and sampe heterogeneity issues, and can be applied very generally. The usefulness of these methods will be shown with the large-scale biomedical data originating from the lung and kidney transplant research projects. The transplant projects aimed to improve the molecular diagnosis and therapy of lung/kidney allograft rejection by identifying molecular biomarkers to predict the allograft rejection for critical early treatment and rapid, noninvasive, and economical testing.       The specific aims are 1) Develop novel statistical methods for differential gene expression detection that explicitly model sample heterogeneity. 2) Develop novel statistical methods for classifying high-dimensional biomedical data and incorporating sample heterogeneity. 3) Develop novel statistical methods for jointly analyzing a set of genes (e.g., genes in a pathway). 4) Use the developed models and methods to answer research questions relevant to public health in the lung and kidney transplant projects; and implement and validate the proposed methods in user-friendly and well-documented software, and distribute them to the scientific community at no charge.       It is very important to identify new biomarkers of allograft rejection in lung and kidney transplant recipients. The rapid and reliable detection and prediction of rejection in easily obtainable body fluids may allow the rapid advancement of clinical interventional trials. We propose to study novel methods for analyzing the large-scale biomedical data to realize their full potential of molecular diagnosis and prognosis of transplant rejection prediction for critical early treatment.          n/a",Statistical Model Building for High Dimensional Biomedical Data,7858165,R01GM083345,"['Address', 'Adopted', 'Algorithms', 'Biological Markers', 'Body Fluids', 'Cations', 'Characteristics', 'Charge', 'Clinical', 'Collection', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early treatment', 'Effectiveness', 'Experimental Designs', 'Gene Expression', 'Genes', 'Genomics', 'Graft Rejection', 'Heterogeneity', 'Individual', 'Internet', 'Joints', 'Kidney Transplantation', 'Least-Squares Analysis', 'Literature', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Minnesota', 'Modeling', 'Molecular', 'Molecular Diagnosis', 'Oncogene Activation', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Phenotype', 'Principal Component Analysis', 'Probability', 'Procedures', 'Public Health', 'Relative (related person)', 'Research', 'Research Project Grants', 'Research Proposals', 'Resources', 'Sample Size', 'Sampling', 'Silicon Dioxide', 'Statistical Methods', 'Statistical Models', 'Technology', 'Testing', 'Tissue-Specific Gene Expression', 'Transplant Recipients', 'Transplantation', 'Universities', 'Ursidae Family', 'Work', 'allograft rejection', 'base', 'biobank', 'cancer microarray', 'cancer type', 'design', 'improved', 'interest', 'kidney allograft', 'method development', 'novel', 'outcome forecast', 'predictive modeling', 'simulation', 'software development', 'sound', 'theories', 'transplant database', 'user friendly software', 'user-friendly']",NIGMS,UNIVERSITY OF MINNESOTA,R01,2010,253269,340417756,-0.024356909617159313
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,7935464,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2010,267671,641965656,0.008581702223175933
"Computational methods for the analysis of RNA-Seq data    DESCRIPTION (provided by applicant): Technologies for the measurement of mRNA quantities within cells are key components of a biomedical researcher<s toolbox. The characterization of gene expression is important to both the understanding of the molecular biology of the cell and the diagnosis and treatment of human disease. To be most useful to scientists, RNA measurement technologies should be as accurate and precise as possible since even small perturbations in transcript levels may be significant. A recently developed experimental method, RNA-Seq, is promising to revolutionize gene expression analysis and is enabling new discoveries about the human transcriptome. RNA-Seq data demands a significant amount of computation before it can be used and the current computational methods are still in their infancy. We propose to take RNA-Seq computational methods to the next level, increasing both the accuracy of gene expression estimates and the number of scenarios in which it may be used. Using novel probabilistic models and statistical learning techniques, we will enable the technology to precisely measure alternative splicing events and characterize the transcriptomes of non-model organisms. Our computational methods will be validated with both real and simulated RNA-Seq data and will be made freely available as an open source software package. In addition, we will use the methods we develop to explore differences between the transcriptomes of undifferentiated and differentiated cells. A first application will be the characterization of alternative splicing differences between human embryonic stem cells and differentiated fibroblast cells. A second application will be the estimation of gene expression levels in embryos of the frog Xenopus leaves using the genome sequence of a closely related frog; Xenopus (Silurana) tropical is as a reference. The results of these experiments are expected to advance our understanding of cellular differentiation in vertebrates and, ultimately, the potential for stem cells to be used in the treatment of human diseases and injuries.      PUBLIC HEALTH RELEVANCE: The proposed research aims to develop computational methods for the support of a technology that measures the quantities of RNA inside of a cell. With this technology and the developed computational methods, researchers will be able to better diagnose and understand the molecular basis of human disease.           Project Narrative The proposed research aims to develop computational methods for the support of a technology that measures the quantities of RNA inside of a cell. With this technology and the developed computational methods, researchers will be able to better diagnose and understand the molecular basis of human disease.",Computational methods for the analysis of RNA-Seq data,7899578,R01HG005232,"['Address', 'Alternative Splicing', 'Animal Model', 'Area', 'Cell physiology', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Disease', 'Embryo', 'Environment', 'Event', 'Fibroblasts', 'Frequencies', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Profiling', 'Genes', 'Genomics', 'Goals', 'Human', 'Individual', 'Injury', 'Knowledge', 'Learning', 'Left', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Messenger RNA', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Organism', 'Outcome', 'Output', 'Protein Isoforms', 'Protocols documentation', 'RNA', 'RNA Sequences', 'RNA Splicing', 'RNA analysis', 'Rana', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Simulate', 'Spliced Genes', 'Staging', 'Statistical Models', 'Stem cells', 'Structure', 'Techniques', 'Technology', 'Transcript', 'Undifferentiated', 'Vertebrates', 'Work', 'Xenopus', 'Xenopus laevis', 'base', 'blastomere structure', 'computerized data processing', 'genome sequencing', 'human disease', 'human embryonic stem cell', 'infancy', 'method development', 'novel', 'open source', 'public health relevance', 'research study', 'xenopus genome']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2010,281832,338121506,-0.013522760865826619
"Discovering hidden groups across tuberculosis patient and pathogen genotype data    DESCRIPTION (provided by applicant):       The principal objective of this project is to develop methods that combine pathogen genotyping and patient epidemiology data that can be used in the control, understanding, and tracking of infectious diseases. This work focuses on the modeling of large international collections of patient epidemiology and strain data for the Mycobacterium tuberculosis complex (MTC), the causative agent of tuberculosis disease (TB), because of the urgent global need and the unique data availability due to the National TB genotyping program. Specifically, the project addresses the following problem: given MTC DNA fingerprinting and TB patient data being accumulated nationally and internationally, identify hidden groups capturing MTC genetic families and TB epidemiology using machine learning, and use these hidden groups to address problems in the control, understanding, prevention, and treatment of tuberculosis at city, state, national, and international levels. To address this objective, we identify several aims. The first aim is to gather and merge large databases of MTC patient-isolate genotypes as well as associated patient information from the New York City, New York State, United States, and the rest of the world. The second aim is to identify MTC strain families based on multiple genotype methods using graphical models constrained to reflect background knowledge. The third aim is to identify hidden host-pathogen groups within TB patient demographics and MTC genotypes using a combination of probabilistic graphical models and deterministic multi-way tensor analysis methods designed to capture the temporal dynamics of TB. The fourth aim answers public health questions posed by TB experts by transforming the questions into quantifiable metrics applied to the hidden groups. The hidden group models and metrics will be embedded in analysis methods, and then evaluated by TB experts. The proposed models and analysis methods will capture and share knowledge embedded in large TB patient and MTC genotyping databases without necessarily sharing the actual data.          n/a",Discovering hidden groups across tuberculosis patient and pathogen genotype data,7805478,R01LM009731,"['Address', 'Age', 'Algorithms', 'Area', 'Biology', 'Boxing', 'Centers for Disease Control and Prevention (U.S.)', 'Cities', 'Collection', 'Communicable Diseases', 'Complex', 'Country', 'DNA Fingerprinting', 'DNA Insertion Elements', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Epidemiology', 'Exercise', 'Family', 'Fingerprint', 'Gender', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Guadeloupe', 'Healthcare', 'Individual', 'Institutes', 'International', 'Investigation', 'Joints', 'Knowledge', 'Label', 'Learning', 'Link', 'Literature', 'Location', 'Machine Learning', 'Methods', 'Metric', 'Modeling', 'Molecular Epidemiology', 'Mycobacterium tuberculosis', 'Nature', 'New York', 'New York City', 'Patients', 'Pattern', 'Phylogeny', 'Population', 'Prevention', 'Principal Investigator', 'Property', 'Protocols documentation', 'Public Health', 'Research Institute', 'Research Personnel', 'Rest', 'Restriction fragment length polymorphism', 'Single Nucleotide Polymorphism', 'Social Network', 'Source', 'Stream', 'Structure', 'Time', 'Translating', 'Trees', 'Tuberculosis', 'United States', 'Visual', 'Work', 'base', 'demographics', 'design', 'disorder control', 'family genetics', 'fight against', 'genetic analysis', 'genetic variant', 'global health', 'improved', 'mycobacterial', 'novel', 'pathogen', 'patient privacy', 'programs', 'prototype', 'public health research', 'relational database', 'success', 'theories', 'tool', 'transmission process', 'trend', 'tuberculosis treatment']",NLM,RENSSELAER POLYTECHNIC INSTITUTE,R01,2010,339537,12471676,0.026010661200439645
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,8013208,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2010,376899,0,0.017428535649473463
"COMPUTATIONAL THINKING - Combining multiple types of reasoning to infer plausible In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING - Combining multiple types of reasoning to infer plausible,8170612,76201000023C,"['Caring', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Face', 'Family', 'Funding', 'Goals', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Medical Informatics', 'Patients', 'Population', 'Process', 'Research', 'Research Personnel', 'Research Project Grants', 'System', 'Thinking', 'biomedical scientist', 'flexibility', 'innovation', 'novel strategies', 'prototype', 'rapid growth']",NLM,"CYCORP, INC.",N03,2010,377967,0,-0.004441935143176082
"COMPUTTIONAL THINKING-An Evidence-Based, Open-Database Approach to Diagnostic Dec In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a","COMPUTTIONAL THINKING-An Evidence-Based, Open-Database Approach to Diagnostic Dec",8173645,76201000026C,"['Caring', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Complement', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Face', 'Family', 'Funding', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Memory', 'Patients', 'Population', 'Prevention', 'Research', 'Research Personnel', 'Research Project Grants', 'Solutions', 'Speed', 'System', 'Thinking', 'biomedical scientist', 'cost effectiveness', 'design', 'evidence base', 'flexibility', 'improved', 'innovation', 'novel strategies', 'rapid growth']",NLM,"SIMULCONSULT, INC.",N03,2010,377991,0,-0.0023268027313866663
"Semi-Automated Abstract Screening for Comparative Effectiveness Reviews    DESCRIPTION (provided by applicant): In this three-year project, we aim to apply state-of-the-art information analysis technologies to assist the production of systematic reviews and meta-analyses that are increasingly being used as a foundation for evidence-based medicine (EBM) and comparative effectiveness reviews. We plan to develop a human guided computerized abstract screening tool to greatly reduce the need to perform a tedious but crucial step of manually screening many thousands of abstracts generated by literature searches in order to retrieve a small fraction potentially relevant for further analysis. This tool will combine proven machine learning techniques with a new open source tool that enables management of the screening process. This new technology will enable investigators to screen abstracts in a small fraction of the time compared to the current manual process. It will reduce the time and cost of producing systematic reviews, provide clear documentation of the process and potentially perform the task more accurately. With the acceptance of EBM and increasing demands for systematic reviews, there is a great need for tools to assist in generating new systematic reviews and in updating them. This need cannot be more pressing. The recent passage of the American Recovery and Reinvestment Act and the $1.1 billion allocated for comparative effectiveness research have created an unprecedented need for systematic reviews and opportunities to improve the methodologies and efficiency of their conduct.   We herein propose the development of novel, open-source software to help systematic reviewers better   cope with these torrents of data. The research and development of this tool will be carried out by a highly experienced team of systematic review investigators with computer scientists at Tufts University who began to collaborate last year as a result of Tufts being awarded one of the NIH Clinical Translational Science Awards (CTSA). We will pursue dissemination of the new technology through numerous channels including, but not limited to publication, presentation at conferences, exploring interest in its adoption by the Agency for Healthcare Research and Quality (AHRQ) Evidence-based Practice Center (EPC) Program, Cochrane Collaboration, CTSA network, and other groups conducting systematic reviews, and production of tutorial material. Our aims are:   1. Conduct research to design and implement a semi-automated system using machine learning and   information retrieval methods to identify relevant abstracts in order to improve the accuracy and efficiency of systematic reviews.   2. Develop Abstrackr, an open-source system with a Graphical User Interface (GUI) for screening abstracts, that applies the methods developed in Aim 1 to automatically exclude irrelevant abstracts/articles.   3. Evaluate the performance of the active learning model developed in Aim 1 and the functionality of   Abstrackr developed in Aim 2 through application to a collection of manually screened datasets of   biomedical abstracts that will subsequently be made publicly available for use as a repository to spur   research in the machine learning and information retrieval communities.           Systematic reviewing is a scientific approach to objectively summarizing the effectiveness and safety of existing treatments for diseases, a prerequisite for informed healthcare decision-making. Systematic reviewers must read many thousands of medical study abstracts, the vast majority of which are completely irrelevant to the review at hand. This is hugely laborious and time consuming. We propose to build a computerized system that automatically excludes a large number of the irrelevant abstracts, thereby accelerating the process and expediting the application of the systematic review findings to patient care.",Semi-Automated Abstract Screening for Comparative Effectiveness Reviews,7933715,R01HS018494,[' '],AHRQ,TUFTS MEDICAL CENTER,R01,2010,388462,17640378,0.0057284282138516315
"Accessible Handling of Misclassified or Missing Binary Variables in CER Studies    DESCRIPTION (provided by applicant): Common but often overlooked threats to the validity of comparative effectiveness research (CER) studies include the misclassification or missingness of binary variables that are crucial to the ultimate analysis of the data. These variables potentially include the outcome of interest in standard or repeated measures logistic regression models, the factor (exposure) of interest, or an important confounder of the association under study. This proposal seeks to facilitate the investigation of the resulting biases to which a given CER analysis may be subject, and to provide study design-based remedial measures via which validity can be restored. The focus is upon statistical methods for conducting sensitivity analyses, as well as methods designed to make efficient use of supplemental data sources. The latter include validation data (in the case of misclassification), and so-called reassessment data (in the case of potentially informative missingness). A primary consideration throughout includes the incorporation of subject-specific covariates into the model of interest, as well as into models for the underlying misclassification or missingness process. Another primary goal is to establish a relatively consistent likelihood-based framework for all proposed analyses incorporating supplemental data, and to provide user-friendly programs utilizing common statistical software in order to make the methods broadly and readily accessible to those conducting CER. While not limited to specific applications, the proposed research draws motivation from and lends itself to illustration via two real-world studies. The first is the HIV Epidemiology Research Study (HERS), an observational cohort study in which the binary diagnosis of bacterial vaginosis was made at repeated visits via both error-prone and sophisticated assay techniques. The second is an emergency department-based ophthalmologic study in which non-dilated ocular fundus photography will be used for diagnosing serious ocular conditions, and will be compared against existing standard diagnostic methods. Both studies involve internal validation data to facilitate corrections for misclassification based on a fallible diagnostic method, and both are also subject to missing outcome and/or predictor data.      PUBLIC HEALTH RELEVANCE: The goal of this project is to provide statistical methods to aid comparative effectiveness research (CER) investigators with common problems encountered in data analysis. The problems upon which the project focuses come about when binary (""yes/no"") data are subject to being incorrectly measured (misclassified), or when they are sometimes not observed (missing) for reasons that might relate to information about subjects in the study. The intention is to provide CER investigators with methods that are relatively easy to use, yet effective and powerful for combating these challenges to valid data analysis.           PROJECT NARRATIVE The goal of this project is to provide statistical methods to aid comparative effectiveness research (CER) investigators with common problems encountered in data analysis. The problems upon which the project focuses come about when binary (""yes/no"") data are subject to being incorrectly measured (misclassified), or when they are sometimes not observed (missing) for reasons that might relate to information about subjects in the study. The intention is to provide CER investigators with methods that are relatively easy to use, yet effective and powerful for combating these challenges to valid data analysis.",Accessible Handling of Misclassified or Missing Binary Variables in CER Studies,8037394,RC4NR012527,"['Accident and Emergency department', 'Address', 'Bacterial Vaginosis', 'Biological Assay', 'Clinical', 'Cohort Studies', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Data Sources', 'Diagnosis', 'Diagnostic Procedure', 'Epidemiologic Studies', 'Epidemiology', 'Equation', 'Fostering', 'Fundus photography', 'Goals', 'HIV', 'Intention', 'Investigation', 'Literature', 'Logistic Regressions', 'Measures', 'Methods', 'Modeling', 'Motivation', 'Outcome', 'Participant', 'Process', 'Research', 'Research Design', 'Research Personnel', 'Resource Allocation', 'Sampling', 'Series', 'Statistical Methods', 'Techniques', 'Time', 'Validation', 'Visit', 'abstracting', 'analytical method', 'base', 'case control', 'combat', 'comparative effectiveness', 'cost', 'design', 'effectiveness research', 'interest', 'programs', 'research study', 'user-friendly']",NINR,EMORY UNIVERSITY,RC4,2010,441691,507546965,-0.004637459499797224
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,7999420,R44RR024094,"['Acquired Immunodeficiency Syndrome', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'HIV', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2010,449663,0,0.003389359939664638
"Robust Classification Methods for Categorical Regression    DESCRIPTION (provided by applicant): Improving statistical methods to provide better classification performance and new analytical capabilities for categorical regression would be invaluable to the medical and health care research communities. Categorical regression models (e.g., binary logistic, multinomial logistic) are used extensively to identify patterns of alcohol-related symptoms, screen for disorders, and assess policies. In addition, such models are used extensively in other areas of research such as mental illness, cancer, traumatic injuries, and AIDS-related pathologies. However, many such models are developed with inadequate support to fully analyze and exploit the intrinsically probabilistic nature of their results. This is of critical importance as health researchers, clinicians, and administrators are often faced with classification decisions using categorical regression models to identify unacceptable risks, adequate outcomes, and acceptable guidelines for screening, diagnoses, treatment, and quality of care. Commercially available statistical software does not offer sophisticated methods for robust estimation of posterior probabilities in the presence of model misspecification, missing covariates, and nonignorable missing data generating processes. Such robust missing data handling methods provide natural mechanisms for dealing with verification bias and modeling correlated, longitudinal, or survey data with complex sampling designs. Moreover, commercially available statistical software does not provide automated methods for using estimated posterior probabilities to make optimal classification decisions with respect to different optimality criteria. In particular, automated features such as optimizing multiple decision criteria (allocation rules) that trade off specificity against sensitivity, decision threshold confidence intervals, statistical tests for evaluating correct specification of posterior probabilities, statistical tests for comparing competing classifier thresholds, and methods for multi-outcome classification and inference are not readily available. Phase II research will extend Phase I findings for binary logistic regression to develop and implement automated robust classification methods for multinomial logistic regression modeling, which also applies to the larger class of nonlinear categorical regression models that output posterior probabilities. The Phase II software prototype will provide: 1) new user-selectable robust decision threshold estimators, 2) robust confidence intervals on decision threshold estimators, 3) new classifier threshold comparison tests, 4) new outcome probability specification tests, 5) efficient missing data handling methods in the presence of nonignorable nonresponse data, and 6) second-order analytic and simulation-based Bayesian methods for improved small sample and rare event outcome probability estimation. These new methodologies will be integrated into a prototype user-friendly software package, evaluated with extensive simulation studies, and then applied to real world classification problems encountered in: alcohol, mental illness (depression, bipolar, schizophrenia), cancer (prostate), trauma (emergency room), and infectious disease (AIDS) through collaborations with domain experts in those respective fields. In summary, Phase II research will establish the essential technical foundation for Phase III commercialization with the objective of providing a suite of new classification analysis methods as an advanced statistical tool that improves epidemiologic, clinical, and public health research.                 n/a",Robust Classification Methods for Categorical Regression,7917387,R44CA139607,"['Accident and Emergency department', 'Achievement', 'Address', 'Administrator', 'Agreement', 'Alcohols', 'Algorithms', 'Area', 'Bayesian Method', 'Behavior', 'Bipolar Depression', 'Classification', 'Clinical', 'Clinical Investigator', 'Collaborations', 'Communicable Diseases', 'Communities', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Analyses', 'Data Set', 'Decision Analysis', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Empirical Research', 'Engineering', 'Epidemiologic Studies', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Foundations', 'Goals', 'Guidelines', 'Health', 'Health Services Research', 'Healthcare', 'Industry', 'Information Resources Management', 'Injury', 'Jordan', 'Journals', 'Knowledge', 'Literature', 'Logistic Regressions', 'Logistics', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Outcome', 'Output', 'Pathology', 'Pattern', 'Peer Review', 'Performance', 'Phase', 'Policies', 'Preparation', 'Probability', 'Process', 'Publishing', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Risk', 'Robin bird', 'Sampling', 'Schizophrenia', 'Screening procedure', 'Sensitivity and Specificity', 'Simulate', 'Software Tools', 'Specific qualifier value', 'Specificity', 'Statistical Methods', 'Surveys', 'Symptoms', 'Technology', 'Testing', 'Trauma', 'anticancer research', 'base', 'commercialization', 'computerized data processing', 'density', 'design', 'graphical user interface', 'improved', 'innovation', 'phase 1 study', 'phase 2 study', 'prototype', 'public health research', 'simulation', 'software development', 'theories', 'tool', 'user friendly software']",NCI,MARTINGALE RESEARCH CORPORATION,R44,2010,990520,0,0.0009636971483650964
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8016739,U19ES019528,[' '],NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2010,1144284,673201228,-0.026964849397697277
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7850408,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'discount', 'drug discovery', 'empowered', 'fluorescence imaging', 'genome-wide', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,R01,2009,26557,50305751,-0.040508061707775246
"Novel TIRF microscopy analyzing trafficking & signaling at the cell cortex In 3-month paid research experiences, over two summers, 4  talented undergraduate engineering and computer science students will be recruited to contribute in a substantial way to the progress of sub-aims of my parent New Innovator (DP2) Award;  the DP2's main specific aims are to develop novel microscopes (Aim 1) and analytical tools (Aim 2) to study membrane trafficking at the cell cortex (Aim 3).  Specifically, students will work on one of two projects: i)  Design and construct and improve electronic circuits to control the galvometric XY mirror on our multi-angle FRAP/TIRFM (Aim 1B) and/or new auto-sensing calibration devices (Aim 2) or ii) Develop models or software to visualize and track vesicles in 3D by multi-angle TIRFM (Aim 2 ). Their advances will directly benefits goals of the DP2 and the new electronics and software's performance will be benchmarked and iteratively improved. Training and oversight will come from the PI and the DP2-supported senior scientist, Dr. Polejaev.  Students will benefit from the infrastructure of the Yale 'CINEMA' lab imaging center, which is under the PI's directorship.         Two outstanding US engineering students have already been identified, Noah Pestana and Isaac Anderson, both of whom have expressed a high interest in participating this summer on projects (i) and (ii), respectively. In the second summer, a particular emphasis will be made to recruit minority undergraduate students through the Yale 'STARS' program for minorities.   All proposed activity are within the scope of the parent DP2 and capitalizes on early successes and will accelerate the tempo of two of the approved specific aims. Consistent with the recovery act's goal, this funding will provide full-time summer employment for 4 undergraduate students and accelerate scientific achievement of the parent DP2 award.  n/a",Novel TIRF microscopy analyzing trafficking & signaling at the cell cortex,7892704,DP2OD002980,"['1-Phosphatidylinositol 3-Kinase', 'Abbreviations', 'Accounting', 'Acoustics', 'Address', 'Adipocytes', 'Affect', 'Algorithms', 'Area', 'Arts', 'Attenuated', 'Automobile Driving', 'Award', 'Back', 'Binding', 'Biochemical', 'Biochemistry', 'Biological', 'Biology', 'Boxing', 'Buffers', 'Caliber', 'Calibration', 'Cell Line', 'Cell membrane', 'Cell surface', 'Cells', 'Cellular biology', 'Clathrin', 'Cluster Analysis', 'Collaborations', 'Collection', 'Collimator', 'Color', 'Coma', 'Communities', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computers', 'Conflict (Psychology)', 'Confocal Microscopy', 'Coupled', 'Coupling', 'Cues', 'Cytoskeleton', 'Data', 'Data Set', 'Defect', 'Development', 'Diabetes Mellitus', 'Diffusion', 'Dimensions', 'Dimerization', 'Disadvantaged', 'Discipline', 'Docking', 'Down-Regulation', 'Drops', 'Dyes', 'Employee Strikes', 'Endocytosis', 'Engineering', 'Ensure', 'Environment', 'Event', 'Exocytosis', 'Eye', 'Face', 'Feedback', 'Fiber', 'Figs - dietary', 'Flare', 'Fluorescein-5-isothiocyanate', 'Fluorescence', 'Fluorescence Microscopy', 'Fluorescence Recovery After Photobleaching', 'Fluorescent Dyes', 'Functional disorder', 'Funding', 'Genetic Screening', 'Germany', 'Glass', 'Glucose Transporter', 'Glycerol', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Insulin', 'Interdisciplinary Study', 'Investments', 'Joints', 'Kinetics', 'Knowledge', 'Label', 'Laboratories', 'Lasers', 'Learning', 'Legal patent', 'Length', 'Life', 'Light', 'Lighting', 'Link', 'Lipids', 'Location', 'Macromolecular Complexes', 'Malignant Neoplasms', 'Maps', 'Masks', 'Measures', 'Mediating', 'Membrane', 'Membrane Microdomains', 'Membrane Protein Traffic', 'Methodology', 'Methods', 'Microscope', 'Microscopy', 'Microtubules', 'Modeling', 'Molecular', 'Monitor', 'Morphologic artifacts', 'Motivation', 'Motor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Optics', 'Organelles', 'PTEN gene', 'Paper', 'Parasites', 'Pathway interactions', 'Penetration', 'Performance', 'Phosphatidylinositols', 'Phosphotransferases', 'Photobleaching', 'Physiologic pulse', 'Planet Mars', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Private Sector', 'Probability', 'Process', 'Proteins', 'Publications', 'Pupil', 'Quantum Dots', 'RNA Interference', 'Radial', 'Randomized', 'Reagent', 'Recruitment Activity', 'Refractive Indices', 'Regulation', 'Relative (related person)', 'Reporter', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seminal', 'Series', 'Side', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Simulate', 'Site', 'Small Interfering RNA', 'Solid', 'Solutions', 'Sorting - Cell Movement', 'Source', 'Spain', 'Spatial Distribution', 'Specific qualifier value', 'Specimen', 'Speed', 'Spottings', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Thick', 'Time', 'Total Internal Reflection Fluorescent', 'Touch sensation', 'Training', 'Transfection', 'Tubulin', 'Vesicle', 'Visual', 'Wolves', 'Work', 'analytical method', 'basal insulin', 'base', 'blood glucose regulation', 'cell cortex', 'cell motility', 'cell type', 'cellular imaging', 'density', 'design', 'extracellular', 'flexibility', 'flotillin', 'fluorescence imaging', 'fluorescence microscope', 'fluorophore', 'handbook', 'holistic approach', 'image processing', 'improved', 'innovation', 'insight', 'instrument', 'instrumentation', 'insulin signaling', 'interest', 'lens', 'medical schools', 'meetings', 'micromanipulator', 'migration', 'millisecond', 'nanometer', 'novel', 'object shape', 'photoactivation', 'prototype', 'receptor', 'research study', 'response', 'scaffold', 'simulation', 'single molecule', 'success', 'tool', 'trafficking', 'trans-Golgi Network', 'trend', 'user-friendly', 'virtual']",OD,YALE UNIVERSITY,DP2,2009,50463,550947887,-0.011267869594977012
"Discovering hidden groups across tuberculosis patient and pathogen genotype data    DESCRIPTION (provided by applicant):       The principal objective of this project is to develop methods that combine pathogen genotyping and patient epidemiology data that can be used in the control, understanding, and tracking of infectious diseases. This work focuses on the modeling of large international collections of patient epidemiology and strain data for the Mycobacterium tuberculosis complex (MTC), the causative agent of tuberculosis disease (TB), because of the urgent global need and the unique data availability due to the National TB genotyping program. Specifically, the project addresses the following problem: given MTC DNA fingerprinting and TB patient data being accumulated nationally and internationally, identify hidden groups capturing MTC genetic families and TB epidemiology using machine learning, and use these hidden groups to address problems in the control, understanding, prevention, and treatment of tuberculosis at city, state, national, and international levels. To address this objective, we identify several aims. The first aim is to gather and merge large databases of MTC patient-isolate genotypes as well as associated patient information from the New York City, New York State, United States, and the rest of the world. The second aim is to identify MTC strain families based on multiple genotype methods using graphical models constrained to reflect background knowledge. The third aim is to identify hidden host-pathogen groups within TB patient demographics and MTC genotypes using a combination of probabilistic graphical models and deterministic multi-way tensor analysis methods designed to capture the temporal dynamics of TB. The fourth aim answers public health questions posed by TB experts by transforming the questions into quantifiable metrics applied to the hidden groups. The hidden group models and metrics will be embedded in analysis methods, and then evaluated by TB experts. The proposed models and analysis methods will capture and share knowledge embedded in large TB patient and MTC genotyping databases without necessarily sharing the actual data.          n/a",Discovering hidden groups across tuberculosis patient and pathogen genotype data,7901729,R01LM009731,"['Address', 'Age', 'Algorithms', 'Area', 'Biology', 'Boxing', 'Centers for Disease Control and Prevention (U.S.)', 'Cities', 'Collection', 'Communicable Diseases', 'Complex', 'Country', 'DNA Fingerprinting', 'DNA Insertion Elements', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Epidemiology', 'Exercise', 'Family', 'Fingerprint', 'Gender', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Guadeloupe', 'Health', 'Healthcare', 'Individual', 'Institutes', 'International', 'Investigation', 'Joints', 'Knowledge', 'Label', 'Learning', 'Link', 'Literature', 'Location', 'Machine Learning', 'Methods', 'Metric', 'Modeling', 'Molecular Epidemiology', 'Mycobacterium tuberculosis', 'Nature', 'New York', 'New York City', 'Patients', 'Pattern', 'Phylogeny', 'Population', 'Prevention', 'Principal Investigator', 'Property', 'Protocols documentation', 'Public Health', 'Research Institute', 'Research Personnel', 'Rest', 'Restriction fragment length polymorphism', 'Single Nucleotide Polymorphism', 'Social Network', 'Source', 'Stream', 'Structure', 'Time', 'Translating', 'Trees', 'Tuberculosis', 'United States', 'Visual', 'Work', 'base', 'demographics', 'design', 'disorder control', 'family genetics', 'fight against', 'genetic analysis', 'genetic variant', 'improved', 'mycobacterial', 'novel', 'pathogen', 'patient privacy', 'programs', 'prototype', 'public health research', 'success', 'theories', 'tool', 'transmission process', 'trend', 'tuberculosis treatment']",NLM,RENSSELAER POLYTECHNIC INSTITUTE,R01,2009,170789,12471676,0.026010661200439645
"Discovering hidden groups across tuberculosis patient and pathogen genotype data    DESCRIPTION (provided by applicant):       The principal objective of this project is to develop methods that combine pathogen genotyping and patient epidemiology data that can be used in the control, understanding, and tracking of infectious diseases. This work focuses on the modeling of large international collections of patient epidemiology and strain data for the Mycobacterium tuberculosis complex (MTC), the causative agent of tuberculosis disease (TB), because of the urgent global need and the unique data availability due to the National TB genotyping program. Specifically, the project addresses the following problem: given MTC DNA fingerprinting and TB patient data being accumulated nationally and internationally, identify hidden groups capturing MTC genetic families and TB epidemiology using machine learning, and use these hidden groups to address problems in the control, understanding, prevention, and treatment of tuberculosis at city, state, national, and international levels. To address this objective, we identify several aims. The first aim is to gather and merge large databases of MTC patient-isolate genotypes as well as associated patient information from the New York City, New York State, United States, and the rest of the world. The second aim is to identify MTC strain families based on multiple genotype methods using graphical models constrained to reflect background knowledge. The third aim is to identify hidden host-pathogen groups within TB patient demographics and MTC genotypes using a combination of probabilistic graphical models and deterministic multi-way tensor analysis methods designed to capture the temporal dynamics of TB. The fourth aim answers public health questions posed by TB experts by transforming the questions into quantifiable metrics applied to the hidden groups. The hidden group models and metrics will be embedded in analysis methods, and then evaluated by TB experts. The proposed models and analysis methods will capture and share knowledge embedded in large TB patient and MTC genotyping databases without necessarily sharing the actual data.          n/a",Discovering hidden groups across tuberculosis patient and pathogen genotype data,7848604,R01LM009731,"['Address', 'Age', 'Algorithms', 'Area', 'Biology', 'Boxing', 'Centers for Disease Control and Prevention (U.S.)', 'Cities', 'Collection', 'Communicable Diseases', 'Complex', 'Country', 'DNA Fingerprinting', 'DNA Insertion Elements', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Epidemiology', 'Exercise', 'Family', 'Fingerprint', 'Gender', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Guadeloupe', 'Health', 'Healthcare', 'Individual', 'Institutes', 'International', 'Investigation', 'Joints', 'Knowledge', 'Label', 'Learning', 'Link', 'Literature', 'Location', 'Machine Learning', 'Methods', 'Metric', 'Modeling', 'Molecular Epidemiology', 'Mycobacterium tuberculosis', 'Nature', 'New York', 'New York City', 'Patients', 'Pattern', 'Phylogeny', 'Population', 'Prevention', 'Principal Investigator', 'Property', 'Protocols documentation', 'Public Health', 'Research Institute', 'Research Personnel', 'Rest', 'Restriction fragment length polymorphism', 'Single Nucleotide Polymorphism', 'Social Network', 'Source', 'Stream', 'Structure', 'Time', 'Translating', 'Trees', 'Tuberculosis', 'United States', 'Visual', 'Work', 'base', 'demographics', 'design', 'disorder control', 'family genetics', 'fight against', 'genetic analysis', 'genetic variant', 'improved', 'mycobacterial', 'novel', 'pathogen', 'patient privacy', 'programs', 'prototype', 'public health research', 'success', 'theories', 'tool', 'transmission process', 'trend', 'tuberculosis treatment']",NLM,RENSSELAER POLYTECHNIC INSTITUTE,R01,2009,170861,12471676,0.026010661200439645
"Statistical Model Building for High Dimensional Biomedical Data    DESCRIPTION (provided by applicant):  Typical of current large-scale biomedical data is the feature of small number of observed samples and the widely observed sample heterogeneity. Identifying differentially expressed genes related to the sample phenotye (e.g., cancer disease development) and predicting sample phenotype based on the gene expressions are some central research questions in the microarray data analysis. Most existing statistical methods have ignored sample heterogeneity and thus loss power.       This project proposes to develop novel statistical methods that explicitly address the small sample size and sampe heterogeneity issues, and can be applied very generally. The usefulness of these methods will be shown with the large-scale biomedical data originating from the lung and kidney transplant research projects. The transplant projects aimed to improve the molecular diagnosis and therapy of lung/kidney allograft rejection by identifying molecular biomarkers to predict the allograft rejection for critical early treatment and rapid, noninvasive, and economical testing.       The specific aims are 1) Develop novel statistical methods for differential gene expression detection that explicitly model sample heterogeneity. 2) Develop novel statistical methods for classifying high-dimensional biomedical data and incorporating sample heterogeneity. 3) Develop novel statistical methods for jointly analyzing a set of genes (e.g., genes in a pathway). 4) Use the developed models and methods to answer research questions relevant to public health in the lung and kidney transplant projects; and implement and validate the proposed methods in user-friendly and well-documented software, and distribute them to the scientific community at no charge.       It is very important to identify new biomarkers of allograft rejection in lung and kidney transplant recipients. The rapid and reliable detection and prediction of rejection in easily obtainable body fluids may allow the rapid advancement of clinical interventional trials. We propose to study novel methods for analyzing the large-scale biomedical data to realize their full potential of molecular diagnosis and prognosis of transplant rejection prediction for critical early treatment.          n/a",Statistical Model Building for High Dimensional Biomedical Data,7666186,R01GM083345,"['Address', 'Adopted', 'Algorithms', 'Allografting', 'Biological Markers', 'Body Fluids', 'Cations', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Collection', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early treatment', 'Effectiveness', 'Experimental Designs', 'Gene Expression', 'Genes', 'Genomics', 'Graft Rejection', 'Heterogeneity', 'Individual', 'Internet', 'Joints', 'Kidney Transplantation', 'Least-Squares Analysis', 'Literature', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Minnesota', 'Modeling', 'Molecular', 'Molecular Diagnosis', 'Oncogene Activation', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Phenotype', 'Principal Component Analysis', 'Probability', 'Procedures', 'Public Health', 'Relative (related person)', 'Research', 'Research Project Grants', 'Research Proposals', 'Resources', 'Sample Size', 'Sampling', 'Silicon Dioxide', 'Statistical Methods', 'Statistical Models', 'Technology', 'Testing', 'Tissue-Specific Gene Expression', 'Transplant Recipients', 'Transplantation', 'Universities', 'Ursidae Family', 'Work', 'base', 'biobank', 'cancer microarray', 'cancer type', 'design', 'improved', 'interest', 'kidney allograft', 'method development', 'novel', 'outcome forecast', 'predictive modeling', 'simulation', 'software development', 'sound', 'theories', 'transplant database', 'user friendly software', 'user-friendly']",NIGMS,UNIVERSITY OF MINNESOTA,R01,2009,256073,340417756,-0.024356909617159313
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,7735790,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2009,270375,641965656,0.008581702223175933
"Discovering hidden groups across tuberculosis patient and pathogen genotype data    DESCRIPTION (provided by applicant):       The principal objective of this project is to develop methods that combine pathogen genotyping and patient epidemiology data that can be used in the control, understanding, and tracking of infectious diseases. This work focuses on the modeling of large international collections of patient epidemiology and strain data for the Mycobacterium tuberculosis complex (MTC), the causative agent of tuberculosis disease (TB), because of the urgent global need and the unique data availability due to the National TB genotyping program. Specifically, the project addresses the following problem: given MTC DNA fingerprinting and TB patient data being accumulated nationally and internationally, identify hidden groups capturing MTC genetic families and TB epidemiology using machine learning, and use these hidden groups to address problems in the control, understanding, prevention, and treatment of tuberculosis at city, state, national, and international levels. To address this objective, we identify several aims. The first aim is to gather and merge large databases of MTC patient-isolate genotypes as well as associated patient information from the New York City, New York State, United States, and the rest of the world. The second aim is to identify MTC strain families based on multiple genotype methods using graphical models constrained to reflect background knowledge. The third aim is to identify hidden host-pathogen groups within TB patient demographics and MTC genotypes using a combination of probabilistic graphical models and deterministic multi-way tensor analysis methods designed to capture the temporal dynamics of TB. The fourth aim answers public health questions posed by TB experts by transforming the questions into quantifiable metrics applied to the hidden groups. The hidden group models and metrics will be embedded in analysis methods, and then evaluated by TB experts. The proposed models and analysis methods will capture and share knowledge embedded in large TB patient and MTC genotyping databases without necessarily sharing the actual data.          n/a",Discovering hidden groups across tuberculosis patient and pathogen genotype data,7612766,R01LM009731,"['Address', 'Age', 'Algorithms', 'Area', 'Biology', 'Boxing', 'Centers for Disease Control and Prevention (U.S.)', 'Cities', 'Collection', 'Communicable Diseases', 'Complex', 'Country', 'DNA Fingerprinting', 'DNA Insertion Elements', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Epidemiology', 'Exercise', 'Family', 'Fingerprint', 'Gender', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Guadeloupe', 'Health', 'Healthcare', 'Individual', 'Institutes', 'International', 'Investigation', 'Joints', 'Knowledge', 'Label', 'Learning', 'Link', 'Literature', 'Location', 'Machine Learning', 'Methods', 'Metric', 'Modeling', 'Molecular Epidemiology', 'Mycobacterium tuberculosis', 'Nature', 'New York', 'New York City', 'Patients', 'Pattern', 'Phylogeny', 'Population', 'Prevention', 'Principal Investigator', 'Property', 'Protocols documentation', 'Public Health', 'Research Institute', 'Research Personnel', 'Rest', 'Restriction fragment length polymorphism', 'Single Nucleotide Polymorphism', 'Social Network', 'Source', 'Stream', 'Structure', 'Time', 'Translating', 'Trees', 'Tuberculosis', 'United States', 'Visual', 'Work', 'base', 'demographics', 'design', 'disorder control', 'family genetics', 'fight against', 'genetic analysis', 'genetic variant', 'improved', 'mycobacterial', 'novel', 'pathogen', 'patient privacy', 'programs', 'prototype', 'public health research', 'success', 'theories', 'tool', 'transmission process', 'trend', 'tuberculosis treatment']",NLM,RENSSELAER POLYTECHNIC INSTITUTE,R01,2009,342967,12471676,0.026010661200439645
"Semi-Automated Abstract Screening for Comparative Effectiveness Reviews    DESCRIPTION (provided by applicant): In this three-year project, we aim to apply state-of-the-art information analysis technologies to assist the production of systematic reviews and meta-analyses that are increasingly being used as a foundation for evidence-based medicine (EBM) and comparative effectiveness reviews. We plan to develop a human guided computerized abstract screening tool to greatly reduce the need to perform a tedious but crucial step of manually screening many thousands of abstracts generated by literature searches in order to retrieve a small fraction potentially relevant for further analysis. This tool will combine proven machine learning techniques with a new open source tool that enables management of the screening process. This new technology will enable investigators to screen abstracts in a small fraction of the time compared to the current manual process. It will reduce the time and cost of producing systematic reviews, provide clear documentation of the process and potentially perform the task more accurately. With the acceptance of EBM and increasing demands for systematic reviews, there is a great need for tools to assist in generating new systematic reviews and in updating them. This need cannot be more pressing. The recent passage of the American Recovery and Reinvestment Act and the $1.1 billion allocated for comparative effectiveness research have created an unprecedented need for systematic reviews and opportunities to improve the methodologies and efficiency of their conduct.   We herein propose the development of novel, open-source software to help systematic reviewers better   cope with these torrents of data. The research and development of this tool will be carried out by a highly experienced team of systematic review investigators with computer scientists at Tufts University who began to collaborate last year as a result of Tufts being awarded one of the NIH Clinical Translational Science Awards (CTSA). We will pursue dissemination of the new technology through numerous channels including, but not limited to publication, presentation at conferences, exploring interest in its adoption by the Agency for Healthcare Research and Quality (AHRQ) Evidence-based Practice Center (EPC) Program, Cochrane Collaboration, CTSA network, and other groups conducting systematic reviews, and production of tutorial material. Our aims are:   1. Conduct research to design and implement a semi-automated system using machine learning and   information retrieval methods to identify relevant abstracts in order to improve the accuracy and efficiency of systematic reviews.   2. Develop Abstrackr, an open-source system with a Graphical User Interface (GUI) for screening abstracts, that applies the methods developed in Aim 1 to automatically exclude irrelevant abstracts/articles.   3. Evaluate the performance of the active learning model developed in Aim 1 and the functionality of   Abstrackr developed in Aim 2 through application to a collection of manually screened datasets of   biomedical abstracts that will subsequently be made publicly available for use as a repository to spur   research in the machine learning and information retrieval communities.           Systematic reviewing is a scientific approach to objectively summarizing the effectiveness and safety of existing treatments for diseases, a prerequisite for informed healthcare decision-making. Systematic reviewers must read many thousands of medical study abstracts, the vast majority of which are completely irrelevant to the review at hand. This is hugely laborious and time consuming. We propose to build a computerized system that automatically excludes a large number of the irrelevant abstracts, thereby accelerating the process and expediting the application of the systematic review findings to patient care.",Semi-Automated Abstract Screening for Comparative Effectiveness Reviews,7786337,R01HS018494,[' '],AHRQ,TUFTS MEDICAL CENTER,R01,2009,362692,17640378,0.0057284282138516315
"Metabolomic Assessment of Estrogenic Endocrine Disruptor    DESCRIPTION (provided by applicant)     Estrogenic endocrine disruptors (EEDs) are a group of structurally diverse compounds that include pharmaceuticals, dietary supplements, industrial chemicals and environmental contaminants.  They can elicit a number of adverse health effects such as hormone dependent cancers, reproductive tract abnormalities, compromised reproductive fitness, and impaired cognitive abilities.  In order to fully assess the potential adverse effects of synthetic and natural EEDs, a more comprehensive understanding of their molecular, metabolic, and tissue level effects is required within the context of a whole organism.  This collaborative proposal will elucidate the pathways, networks and signaling cascades perturbed by EEDs using the complementary multidisciplinary expertise of its team members in the areas of toxicology, molecular biology, endocrinology, multinuclear NMR spectroscopy, data management and advanced data analysis.  The comparative effects of ethynyl estradiol (EE), genistein (GEN), and o, p'-dichlorodiphenyltrichloroethane (DDT) on metabolite levels will be assessed in urine, serum and liver extracts by multinuclear (i. e., 1H, 13C, 31P) NMR spectroscopy, and complemented with histopathology examination and gene expression data from ongoing microarray studies in both mouse and rat models.  All data will be stored and archived in dbZach, a MIAME-compliant toxicogenomic supportive database that facilitates data analysis, the integration of disparate data sets, the exchange of data between investigators, and the deposition of data into public repositories.  Advanced statistical approaches, modeling and data integration tools such as neural networks, data fusion, and Baysean inference will be used to fuse these disparate data sets in order to elucidate the conserved biological networks that are of importance in response to endogenous estrogens.  Moreover, EED perturbed pathways associated with elicited effects will be further defined.  Results from these studies will not only further define the physiologic and toxic mechanisms of action of estrogenic compounds but will also demonstrate the synergy of fusing complementary microarray, metabolomic and histopathology data into a comprehensive integrative computational model.  This approach will also demonstrate the ability to maximize knowledge extraction from all disparate data available within the proposed innovative data management system when used with the advanced information tools that will be developed.            n/a",Metabolomic Assessment of Estrogenic Endocrine Disruptor,7625039,R01ES013927,"['Adverse effects', 'Affect', 'Apical', 'Archives', 'Area', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Cell Proliferation', 'Chemicals', 'Classification', 'Clinical Chemistry', 'Cognitive', 'Complement', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Base Management', 'Data Set', 'Databases', 'Deposition', 'Development', 'Disease Progression', 'Dose', 'Endocrine Disruptors', 'Endocrinology', 'Engineering', 'Environmental Pollution', 'Estradiol', 'Estrogens', 'Funding', 'Future', 'Gene Expression', 'Genistein', 'Health', 'Hepatic', 'Histopathology', 'Hormones', 'Knowledge Extraction', 'Lead', 'Link', 'Lipids', 'Liver Extract', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Metabolic', 'Metabolism', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Multinuclear NMR', 'Mus', 'NMR Spectroscopy', 'Organ Weight', 'Outcome', 'Pathway interactions', 'Pattern Recognition', 'Pharmacologic Substance', 'Physiological', 'Principal Investigator', 'Process', 'Rattus', 'Reporting', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Assessment', 'Rodent', 'Sampling', 'Screening procedure', 'Serum', 'Signal Transduction', 'System', 'Techniques', 'Time', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Urine', 'Whole Organism', 'aqueous', 'comparative', 'data exchange', 'data format', 'data integration', 'data management', 'dichlorodiphenyltrichloroethane', 'dietary supplements', 'estrogenic endocrine disruptor', 'experience', 'fitness', 'innovation', 'member', 'metabolic abnormality assessment', 'metabolomics', 'multidisciplinary', 'programs', 'repository', 'reproductive', 'research study', 'response', 'tool']",NIEHS,MICHIGAN STATE UNIVERSITY,R01,2009,536571,89938253,-0.01727768537112088
"Robust Classification Methods for Categorical Regression    DESCRIPTION (provided by applicant): Improving statistical methods to provide better classification performance and new analytical capabilities for categorical regression would be invaluable to the medical and health care research communities. Categorical regression models (e.g., binary logistic, multinomial logistic) are used extensively to identify patterns of alcohol-related symptoms, screen for disorders, and assess policies. In addition, such models are used extensively in other areas of research such as mental illness, cancer, traumatic injuries, and AIDS-related pathologies. However, many such models are developed with inadequate support to fully analyze and exploit the intrinsically probabilistic nature of their results. This is of critical importance as health researchers, clinicians, and administrators are often faced with classification decisions using categorical regression models to identify unacceptable risks, adequate outcomes, and acceptable guidelines for screening, diagnoses, treatment, and quality of care. Commercially available statistical software does not offer sophisticated methods for robust estimation of posterior probabilities in the presence of model misspecification, missing covariates, and nonignorable missing data generating processes. Such robust missing data handling methods provide natural mechanisms for dealing with verification bias and modeling correlated, longitudinal, or survey data with complex sampling designs. Moreover, commercially available statistical software does not provide automated methods for using estimated posterior probabilities to make optimal classification decisions with respect to different optimality criteria. In particular, automated features such as optimizing multiple decision criteria (allocation rules) that trade off specificity against sensitivity, decision threshold confidence intervals, statistical tests for evaluating correct specification of posterior probabilities, statistical tests for comparing competing classifier thresholds, and methods for multi-outcome classification and inference are not readily available. Phase II research will extend Phase I findings for binary logistic regression to develop and implement automated robust classification methods for multinomial logistic regression modeling, which also applies to the larger class of nonlinear categorical regression models that output posterior probabilities. The Phase II software prototype will provide: 1) new user-selectable robust decision threshold estimators, 2) robust confidence intervals on decision threshold estimators, 3) new classifier threshold comparison tests, 4) new outcome probability specification tests, 5) efficient missing data handling methods in the presence of nonignorable nonresponse data, and 6) second-order analytic and simulation-based Bayesian methods for improved small sample and rare event outcome probability estimation. These new methodologies will be integrated into a prototype user-friendly software package, evaluated with extensive simulation studies, and then applied to real world classification problems encountered in: alcohol, mental illness (depression, bipolar, schizophrenia), cancer (prostate), trauma (emergency room), and infectious disease (AIDS) through collaborations with domain experts in those respective fields. In summary, Phase II research will establish the essential technical foundation for Phase III commercialization with the objective of providing a suite of new classification analysis methods as an advanced statistical tool that improves epidemiologic, clinical, and public health research.                 n/a",Robust Classification Methods for Categorical Regression,7686932,R44CA139607,"['Accident and Emergency department', 'Achievement', 'Address', 'Administrator', 'Agreement', 'Alcohols', 'Algorithms', 'Area', 'Bayesian Method', 'Behavior', 'Bipolar Depression', 'Classification', 'Clinical', 'Clinical Investigator', 'Collaborations', 'Communicable Diseases', 'Communities', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Analyses', 'Data Set', 'Decision Analysis', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Empirical Research', 'Engineering', 'Epidemiologic Studies', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Foundations', 'Goals', 'Guidelines', 'Health', 'Health Services Research', 'Healthcare', 'Industry', 'Information Resources Management', 'Injury', 'Jordan', 'Journals', 'Knowledge', 'Literature', 'Logistic Regressions', 'Logistics', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Outcome', 'Output', 'Pathology', 'Pattern', 'Peer Review', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Policies', 'Preparation', 'Probability', 'Process', 'Publishing', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Risk', 'Robin bird', 'Sampling', 'Schizophrenia', 'Screening procedure', 'Sensitivity and Specificity', 'Simulate', 'Software Tools', 'Specific qualifier value', 'Specificity', 'Statistical Methods', 'Surveys', 'Symptoms', 'Technology', 'Testing', 'Trauma', 'anticancer research', 'base', 'commercialization', 'computerized data processing', 'density', 'design', 'graphical user interface', 'improved', 'innovation', 'prototype', 'public health research', 'simulation', 'software development', 'theories', 'tool', 'user friendly software']",NCI,MARTINGALE RESEARCH CORPORATION,R44,2009,957937,0,0.0009636971483650964
"Development of a Research-Ready Pregnancy and Newborn Biobank in California    DESCRIPTION (provided by applicant): Development of a Research-Ready Pregnancy and Newborn Biobank in California Population-based biobanks are a critical resource for identifying disease mechanisms and developing screening tests for biomarkers associated with certain disorders. The California Department of Public Health has been banking newborn specimens statewide since 1982 (N~14 million) and maternal prenatal specimens for a portion of the state since 2000 (N~1 million), creating one of the largest, if not the largest single biological specimen banks with linked data in the world. With the fast pace of new knowledge in genetics and laboratory methods, the demand for specimens and data from researchers around the world now far surpasses the Department's ability to fill them. The goal of this infrastructure development project is to create an efficient, high throughput, low cost newborn screening and prenatal/maternal screening specimen biobank and linked data base that could be used by large numbers of researchers around the world for a wide range of studies through the following aims: (1) establishment of highly efficient protocols and procurement and integration of automated systems for pulling and processing specimens; (2) development of an integrated specimen tracking system into the Department's existing web-based Screening Information System; (3) development of a computerized system to track application requests for specimens and data; and (4) development of a linked screening program-vital records database that is organized into a life course, client based system. These aims will be accomplished through expansion of the Department's award-winning Screening Integration System to include web-based tracking of specimens and research requests, and use of an innovative machine-learning record matching application for high-performance linkages. After the 2 year grant period is completed, the California Research Ready Biospecimen Bank will be able to provide researchers with valuable biological specimens in a timely, cost-effective manner, thereby enabling a dramatic expansion of epidemiological research nationwide. The continuity of the system will be ensured by codifying human subjects-sensitive policies and procedures into Departmental regulations and by charging researchers modest fees for specimens, data and other research services.      PUBLIC HEALTH RELEVANCE: Development of a research-ready pregnancy and newborn biobank in California This proposal funds infrastructure development to create a research-ready, efficient, high- throughput, and low-cost prenatal and newborn biobank in California. Specimens spanning 28 years will be linked to existing records of fetal death, live birth, death, prenatal and newborn screening to develop a rich, client-based, cross-generational, life- course database. Specimens and linked data from the California Research-Ready Biospecimen Bank will be made available to researchers in the U.S. and around the world to enable a broad and expanded array of studies.           Program Narrative Development of a research-ready pregnancy and newborn biobank in California This proposal funds infrastructure development to create a research-ready, efficient, high- throughput, and low-cost prenatal and newborn biobank in California. Specimens spanning 28 years will be linked to existing records of fetal death, live birth, death, prenatal and newborn screening to develop a rich, client-based, cross-generational, life- course database. Specimens and linked data from the California Research-Ready Biospecimen Bank will be made available to researchers in the U.S. and around the world to enable a broad and expanded array of studies.",Development of a Research-Ready Pregnancy and Newborn Biobank in California,7853378,RC2HD065514,"['Area', 'Award', 'Biological', 'Biological Markers', 'Biological Specimen Banks', 'California', 'Case-Control Studies', 'Cessation of life', 'Charge', 'Client', 'Data', 'Data Files', 'Databases', 'Development', 'Disease', 'Ensure', 'Epidemiology', 'Family Study', 'Fees', 'Fetal Death', 'Funding', 'Future', 'Genetic', 'Goals', 'Government', 'Grant', 'Information Systems', 'Infusion procedures', 'Knowledge', 'Laboratories', 'Laws', 'Life Cycle Stages', 'Link', 'Live Birth', 'Machine Learning', 'Methods', 'Multiple Pregnancy', 'Neonatal Screening', 'Newborn Infant', 'Online Systems', 'Performance', 'Policies', 'Population', 'Pregnancy', 'Principal Investigator', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Records', 'Regulation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Screening procedure', 'Services', 'Specimen', 'Specimen Handling', 'Study Subject', 'System', 'Systems Integration', 'Testing', 'Time', 'Woman', 'base', 'biobank', 'cohort', 'computerized', 'cost', 'human subject', 'infrastructure development', 'innovation', 'population based', 'prenatal', 'programs', 'public health relevance']",NICHD,SEQUOIA FOUNDATION,RC2,2009,2003191,0,-0.016719935255698478
"Causal Discovery Algorithms for Translational Research with High-Throughput Data Project Summary Causal Discovery Algorithms for Translational Research with High-Throughput Data The long-term goal of this project is to provide to the biomedical community next-generation causal algorithms to facilitate discovery of disease molecular pathways and causative as well as predictive biomarkers and molecular signatures from high-throughput data. Such knowledge and methods are necessary toward earlier and more accurate diagnosis and prognosis, personalized medicine, and rational drug design. If successful, the proposed research will have significant and wide methodological and practical implications spanning several areas of biomedicine with a primary focus and immediate benefits in high-throughput diagnostics and personalized medicine. It will provide significantly improved computational methods and deeper theoretical understanding related to producing molecular signatures and understanding mechanisms of disease and concomitant leads for new drugs. It will provide evidence about applicability of novel causal methods in other types of data. It will generate insights in specific pathways of lung cancer in humans. It will deepen our understanding and solutions to the Rashomon effect in ¿omics¿ data. The proposed research will also shed light on the operational value of the stability heuristic. Finally the research will engage the international research community to address open computational causal discovery problems relevant to high-throughput and other biomedical data. ¿ Aim 1. Evaluate and characterize several novel causal algorithms for biomarker selection, molecular signature creation and reverse network engineering using real, simulated, resimulated, and experimental datasets. Study generality of the methods by means of applicability to non-¿omics¿ datasets. ¿ Aim 2. Evaluate and characterize, novel and state of the art causal algorithms against state-of-the-art non-causal and quasi-causal algorithms. ¿ Aim 3. Systematically investigate the Rashomon effect as it applies to biomarker and signature multiplicity. ¿ Aim 4. Systematically investigate the utility of applying the stability heuristic for causal discovery. ¿ Aim 5. Derive novel biomarkers, pathways and hypotheses for lung cancer. ¿ Aim 6. Induce novel solutions through an international causal discovery competition. ¿ Aim 7. Disseminate findings. n/a",Causal Discovery Algorithms for Translational Research with High-Throughput Data,7643514,R56LM007948,"['AKT1 gene', 'AKT2 gene', 'AKT3 gene', 'Address', 'Affect', 'Algorithms', 'Area', 'Arts', 'Benchmarking', 'Bioinformatics', 'Biologic Characteristic', 'Biological Markers', 'Biology', 'Biometry', 'Book Chapters', 'Books', 'Cancer cell line', 'Causations', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'Consultations', 'Data', 'Data Set', 'Depth', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discipline', 'Disease', 'Drug Design', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Ensure', 'Epidermal Growth Factor Receptor', 'European', 'Evaluation', 'Event', 'Excision', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Goals', 'Gold', 'Healthcare', 'Hereditary Disease', 'Home environment', 'Human', 'Human Cell Line', 'Inferior', 'Information Retrieval', 'Institution', 'International', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Light', 'Localized', 'Machine Learning', 'Malignant neoplasm of lung', 'Marker Discovery', 'Medicine', 'Methods', 'Modality', 'Molecular', 'Molecular Profiling', 'Neighborhoods', 'Noise', 'Numbers', 'Online Systems', 'Outcome', 'Output', 'Paper', 'Pathway interactions', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Proteomics', 'Protocols documentation', 'Public Domains', 'Publishing', 'Quality Control', 'Random Allocation', 'Randomized', 'Rate', 'Research', 'Research Personnel', 'Research Proposals', 'Role', 'Sample Size', 'Sampling', 'Schedule', 'Score', 'Services', 'Simulate', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Testing', 'Text', 'Thinking', 'Tissues', 'Translational Research', 'Variant', 'Work', 'base', 'c-erbB-1 Proto-Oncogenes', 'clinically relevant', 'computer based statistical methods', 'computer science', 'contextual factors', 'coping', 'data mining', 'design', 'drug development', 'heuristics', 'human data', 'human tissue', 'improved', 'innovation', 'insight', 'journal article', 'member', 'new technology', 'next generation', 'novel', 'novel diagnostics', 'outcome forecast', 'reconstruction', 'research study', 'software systems', 'symposium', 'theories', 'tool']",NLM,VANDERBILT UNIVERSITY,R56,2008,2949,117374875,-0.04503297092824201
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7433144,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Class', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Computers', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Numbers', 'Performance', 'Personal Satisfaction', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Public Health', 'Randomized', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Today', 'Training', 'Voting', 'Work', 'base', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSIGHTFUL CORPORATION,R44,2008,25548,0,0.017428535649473463
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7688793,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2008,58299,570146095,0.006167634549374861
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7480255,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2008,89733,807432003,-0.02113923764159205
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): The proposed Clinical Cytometry Analysis Software Project described in this grant application is designed to create a new, more efficient and effective way of analyzing cells for the presence of cancer, HIV/AIDS and other disease, using a fully automated software system. Using modern data mining techniques (pattern recognition, feature recognition, image analysis) we will design software which will analyze data (the cell samples from patients) at a much faster rate and with fewer false positives and negatives than the manual method now in use. Objectives: Assemble and validate algorithms in software that can automatically classify regions of interest in flow cytometry data. We will demonstrate that the particular populations required by our use cases can be validly, rigorously and repeatably identified automatically. Develop and validate graphical and statistical results that satisfy FDA requirements for medical device software, simplify regulatory compliance by the clinical user, and automatically deliver analysis results to diagnostic expert systems and/or LIMS systems. Satisfy the  translational medicine  goals outlined in the NIH Roadmap. This software will bring the clinician streamlined testing currently only available in research labs. Methods: Four use cases have been selected, one employing synthetic data and three clinical data; Leukemia/Lymphoma test, Analysis of longitudinal Graft vs. Host Disease (GvHD) in bone marrow transplant specimens for predictive markers and HIV/AIDS - Gag-specific T cell cytokine response profile assay. For each we have access to a substantial body of existing data, analyzed by experts. Beginning with the autogating routines in our own FlowJo software, we will test and expand the application of Magnetic gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural and Support Vector Machines (SVM). Using a sampling of human operators to establish a control range, we will test each of these five techniques against the four use cases in cooperation with our collaborators. Events in the manually classified samples are given a weighted score based on the frequency with which they are included by all the operators. A single operator's score or the gating algorithm's score is compared with the cumulative score of the expert group and a match rating is computed. Additional validation techniques include combinatory validation on internal measures with respect to Pareto optimality, and Predictive Power/Stability self consistency checks using resampled or perturbed data measured with external indices such as the adjusted Rand index and the Variation of Information index.  PUBLIC HEALTH RELEVANCE: By eliminating the operator's time, we estimate that the cost of clinical flow cytometry analysis can be reduced to half the current figure while delivering the results much faster. By eliminating the subjectivity and human error of manually created regions and reducing the range of variability of the so created, there would result fewer false positives and false negatives, improving the clinical outcome for those patients needing therapy but undetected by current methods. An order of magnitude increase in speed means faster therapeutic intervention.  A less expensive test improves outcome by making the test accessible to more patients.          n/a",Clinical Cytometry Analysis Software with Automated Gating,7482923,R43RR024094,"['AIDS/HIV problem', 'Algorithms', 'Applications Grants', 'B-Lymphocytes', 'Biological Assay', 'Biological Neural Networks', 'Bone Marrow Transplantation', 'Cells', 'Characteristics', 'Class', 'Classification', 'Clinical', 'Clinical Data', 'Cluster Analysis', 'Complex', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cytometry', 'Data', 'Data Analyses', 'Data Files', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Educational process of instructing', 'Environment', 'Evaluation', 'Event', 'Expert Systems', 'Facility Construction Funding Category', 'Flow Cytometry', 'Frequencies', 'Funding', 'Future', 'Gagging', 'Generations', 'Goals', 'Grant', 'Graph', 'Human', 'Image Analysis', 'Individual', 'Instruction', 'Knowledge', 'Legal patent', 'Life Cycle Stages', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Noise', 'Numbers', 'Outcome', 'Output', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Population', 'Probability', 'Process', 'Public Health', 'Publishing', 'Range', 'Rate', 'Regulation', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Scientist', 'Score', 'Software Design', 'Software Engineering', 'Software Tools', 'Solutions', 'Specific qualifier value', 'Specimen', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'T-Lymphocyte', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tube', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Voting', 'Weight', 'base', 'clinical Diagnosis', 'commercialization', 'cost', 'cytokine', 'data mining', 'design', 'improved', 'indexing', 'innovation', 'interest', 'leukemia/lymphoma', 'novel', 'predictive modeling', 'relating to nervous system', 'research study', 'response', 'software systems', 'statistics', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R43,2008,100854,0,-0.017025272410818124
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7748401,R44GM083965,"['Learning', 'Techniques', 'parallel computing']",NIGMS,INSILICOS,R44,2008,143361,0,0.017428535649473463
"Statistical Model Building for High Dimensional Biomedical Data    DESCRIPTION (provided by applicant):  Typical of current large-scale biomedical data is the feature of small number of observed samples and the widely observed sample heterogeneity. Identifying differentially expressed genes related to the sample phenotye (e.g., cancer disease development) and predicting sample phenotype based on the gene expressions are some central research questions in the microarray data analysis. Most existing statistical methods have ignored sample heterogeneity and thus loss power.       This project proposes to develop novel statistical methods that explicitly address the small sample size and sampe heterogeneity issues, and can be applied very generally. The usefulness of these methods will be shown with the large-scale biomedical data originating from the lung and kidney transplant research projects. The transplant projects aimed to improve the molecular diagnosis and therapy of lung/kidney allograft rejection by identifying molecular biomarkers to predict the allograft rejection for critical early treatment and rapid, noninvasive, and economical testing.       The specific aims are 1) Develop novel statistical methods for differential gene expression detection that explicitly model sample heterogeneity. 2) Develop novel statistical methods for classifying high-dimensional biomedical data and incorporating sample heterogeneity. 3) Develop novel statistical methods for jointly analyzing a set of genes (e.g., genes in a pathway). 4) Use the developed models and methods to answer research questions relevant to public health in the lung and kidney transplant projects; and implement and validate the proposed methods in user-friendly and well-documented software, and distribute them to the scientific community at no charge.       It is very important to identify new biomarkers of allograft rejection in lung and kidney transplant recipients. The rapid and reliable detection and prediction of rejection in easily obtainable body fluids may allow the rapid advancement of clinical interventional trials. We propose to study novel methods for analyzing the large-scale biomedical data to realize their full potential of molecular diagnosis and prognosis of transplant rejection prediction for critical early treatment.          n/a",Statistical Model Building for High Dimensional Biomedical Data,7386333,R01GM083345,"['Address', 'Adopted', 'Algorithms', 'Allografting', 'Biological Markers', 'Body Fluids', 'Cations', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Collection', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early treatment', 'Effectiveness', 'Experimental Designs', 'Gene Expression', 'Genes', 'Genomics', 'Graft Rejection', 'Heterogeneity', 'Individual', 'Internet', 'Joints', 'Kidney Transplantation', 'Least-Squares Analysis', 'Literature', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Minnesota', 'Modeling', 'Molecular', 'Molecular Diagnosis', 'None or Not Applicable', 'Numbers', 'Oncogene Activation', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Principal Component Analysis', 'Probability', 'Procedures', 'Public Health', 'Purpose', 'Relative (related person)', 'Research', 'Research Project Grants', 'Research Proposals', 'Resources', 'Sample Size', 'Sampling', 'Silicon Dioxide', 'Statistical Methods', 'Statistical Models', 'Technology', 'Testing', 'Tissue-Specific Gene Expression', 'Transplant Recipients', 'Transplantation', 'Universities', 'Ursidae Family', 'Work', 'base', 'cancer microarray', 'cancer type', 'design', 'desire', 'improved', 'interest', 'kidney allograft', 'method development', 'novel', 'outcome forecast', 'predictive modeling', 'simulation', 'software development', 'sound', 'theories', 'user friendly software', 'user-friendly']",NIGMS,UNIVERSITY OF MINNESOTA,R01,2008,255036,340417756,-0.024356909617159313
"Robust computational framework for predictive ADME-Tox modeling    DESCRIPTION (provided by applicant):    This proposal seeks to establish a universally applicable and robust predictive ADME-Tox modeling framework based on rigorous Quantitative Structure Activity/Property Relationships (QSAR/QSPR) modeling. The framework has been refined in the course of many years of our research in the areas of QSPR methodology development and application to experimental datasets that led to novel analytical approaches, descriptors, model validation schemes, overall QSPR workflow design, and multiple end-point studies. This proposal focuses on the design of optimized QSPR protocols for the development of reliable predictors of critically important ADME-Tox properties. The ADME properties will include, but not limited to, water solubility, membrane permeability, P450 metabolism inhibition and induction, metabolic stability, human intestinal absorption, bioavailability, transporters and PK data; a variety of toxicological end-points vital to human health will be explored; they are available from recent initiatives on development and standardization of toxicity data, such as the US FDA, NIEHS, and EPA DSS-Tox and other database projects. The ultimate goal of this project is sharing both modeling software and specialized predictors with the research community via a web-based Predictive ADME-Tox Portal. The project objectives will be achieved via concurrent development of QSPR methodology (Specific Aim 1), building highly predictive, robust QSPR models of known ADME-Tox properties (Specific Aim 2), and the deployment of both modeling software and individual predictors via a specialized web-portal (Specific Aim 3). To achieve the goals of this project focusing on the development and delivery of specialized tools and rigorous predictors, we have assembled a research team of mostly senior investigators with complimentary skills and track records of accomplishment in the areas of computational drug discovery, experimental toxicology, statistical modeling, and software development and integration; two of the team members have had recent industrial experience before transitioning to academia. To the best of our knowledge, the results of this proposal will lead to the first publicly available in silico ADME-Tox modeling framework and predictors that can be used by the research community to analyze any set of chemicals (i.e., virtual and real compound sets). The framework will have a significant impact on compound prioritization, chemical library design, and candidate selection for preclinical and clinical development.            n/a",Robust computational framework for predictive ADME-Tox modeling,7433931,R21GM076059,"['Academia', 'Acute', 'Address', 'Area', 'Biological Availability', 'Cardiotoxicity', 'Cell Membrane Permeability', 'Chemicals', 'Chronic', 'Clinical', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Consensus', 'Cytochrome P450', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Drug Kinetics', 'End Point', 'Ensure', 'Environment', 'Goals', 'Health', 'Hepatotoxicity', 'Human', 'Individual', 'Internet', 'Intestinal Absorption', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Letters', 'Lung', 'Machine Learning', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Organ', 'Pharmacologic Substance', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Scheme', 'Scientist', 'Screening procedure', 'Secure', 'Source', 'Specialist', 'Standardization', 'Standards of Weights and Measures', 'Statistical Models', 'Statistically Significant', 'Structure', 'Students', 'Techniques', 'Technology', 'Testing', 'Toxic effect', 'Toxicology', 'Training', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'carcinogenicity', 'career', 'cluster computing', 'combinatorial', 'computer framework', 'data mining', 'design', 'drug discovery', 'experience', 'genotoxicity', 'innovation', 'knowledge of results', 'member', 'method development', 'neurotoxicity', 'novel', 'open source', 'pre-clinical', 'programs', 'protocol development', 'reproductive', 'skills', 'small molecule libraries', 'software development', 'tool', 'virtual', 'water solubility']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2008,322087,511185245,-0.00976633214131901
"CRCNS: Info. Process. & Neuronal Coordination: Neocortex DESCRIPTION (provided by applicant): The brain dysfunctions underlying schizophrenia are poorly understood. Nevertheless, it is likely that a critical aspect of this disease is a breakdown of the normal information processing functions of the neuronal assemblies. This project would study the activity of neuronal populations in sensory neocortex and investigate how neuronal assembly activity is disrupted in the dissociative anesthetic (PCP) model of schizophrenia.      Experimental investigation of this question will require recording large numbers of cells in functioning neural circuits. However, obtaining this data is only the beginning: the computational and statistical machinery to draw meaningful conclusions from such data must also be developed. Here we propose a collaborative research project between a mathematician (Kenneth Harris) and an electrophysiologist (Gyorgy Buzsaki), with the aim of recording, analyzing, and modeling the activity of large neuronal populations in primary sensory cortex and its disruption by psychotomimetic drugs. The project will rely on two techniques we have developed over the last years: large-scale neuronal recordings using silicon microelectrodes; and the data analysis method of peer prediction. The use of silicon probes will allow for estimation of the location of recorded cells, identification of monosynaptic connections between cell pairs, and characterization of neurons as pyramidal cells or interneurons. Experimentally identified assembly structure will be interpreted in the context of this circuit-level information.      We will investigate the hypothesis that psychotomimetic effects of low doses of dissociative anesthetics are caused by a partial distortion in assembly organization, whereas larger doses cause a more complete distortion resulting anesthesia. If reliable signatures of psychotomimetic doses on assembly structure are found, this will suggest a novel method of drug screening for antipsychotics, whereby candidate drugs are evaluated by their ability to reverse these signatures. n/a",CRCNS: Info. Process. & Neuronal Coordination: Neocortex,7429713,R01MH073245,"['Address', 'Algorithms', 'Anesthesia procedures', 'Anesthetics', 'Animals', 'Antipsychotic Agents', 'Area', 'Auditory', 'Auditory area', 'Biology', 'Brain', 'Cell Count', 'Cells', 'Cognitive', 'Collaborations', 'Complex', 'Computer information processing', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Disease', 'Disruption', 'Dissociative Anesthetics', 'Dose', 'Fire - disasters', 'Floods', 'Functional disorder', 'Hallucinogens', 'Interneurons', 'Investigation', 'Ketamine', 'Location', 'Machine Learning', 'Mathematics', 'Methods', 'Microelectrodes', 'Modality', 'Modeling', 'Monitor', 'Neocortex', 'Neurons', 'Neurosciences', 'Numbers', 'Pattern', 'Pharmaceutical Preparations', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Probability', 'Process', 'Psychotropic Drugs', 'Pyramidal Cells', 'Rattus', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Role playing therapy', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Silicon', 'Site', 'Stimulus', 'Structure', 'Sum', 'Techniques', 'Testing', 'Time', 'Training', 'Vibrissae', 'Work', 'awake', 'barrel cortex', 'computerized data processing', 'in vivo', 'neocortical', 'neural circuit', 'novel', 'peer', 'programs', 'response', 'sensory cortex', 'somatosensory', 'sound', 'statistics', 'theories']",NIMH,RUTGERS THE STATE UNIV OF NJ NEWARK,R01,2008,322599,10097598,-0.02157607833530068
"Discovering hidden groups across tuberculosis patient and pathogen genotype data    DESCRIPTION (provided by applicant):       The principal objective of this project is to develop methods that combine pathogen genotyping and patient epidemiology data that can be used in the control, understanding, and tracking of infectious diseases. This work focuses on the modeling of large international collections of patient epidemiology and strain data for the Mycobacterium tuberculosis complex (MTC), the causative agent of tuberculosis disease (TB), because of the urgent global need and the unique data availability due to the National TB genotyping program. Specifically, the project addresses the following problem: given MTC DNA fingerprinting and TB patient data being accumulated nationally and internationally, identify hidden groups capturing MTC genetic families and TB epidemiology using machine learning, and use these hidden groups to address problems in the control, understanding, prevention, and treatment of tuberculosis at city, state, national, and international levels. To address this objective, we identify several aims. The first aim is to gather and merge large databases of MTC patient-isolate genotypes as well as associated patient information from the New York City, New York State, United States, and the rest of the world. The second aim is to identify MTC strain families based on multiple genotype methods using graphical models constrained to reflect background knowledge. The third aim is to identify hidden host-pathogen groups within TB patient demographics and MTC genotypes using a combination of probabilistic graphical models and deterministic multi-way tensor analysis methods designed to capture the temporal dynamics of TB. The fourth aim answers public health questions posed by TB experts by transforming the questions into quantifiable metrics applied to the hidden groups. The hidden group models and metrics will be embedded in analysis methods, and then evaluated by TB experts. The proposed models and analysis methods will capture and share knowledge embedded in large TB patient and MTC genotyping databases without necessarily sharing the actual data.          n/a",Discovering hidden groups across tuberculosis patient and pathogen genotype data,7354450,R01LM009731,"['Address', 'Age', 'Algorithms', 'Area', 'Biology', 'Boxing', 'Centers for Disease Control and Prevention (U.S.)', 'Cities', 'Class', 'Collection', 'Communicable Diseases', 'Complex', 'Country', 'DNA Fingerprinting', 'DNA Insertion Elements', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Epidemiology', 'Epidemiology, Other', 'Exercise', 'Family', 'Fingerprint', 'Gender', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Guadeloupe', 'Health', 'Healthcare', 'Individual', 'Infectious Disease Epidemiology', 'Institutes', 'International', 'Investigation', 'Joints', 'Knowledge', 'Label', 'Learning', 'Link', 'Literature', 'Location', 'Machine Learning', 'Methods', 'Metric', 'Modeling', 'Molecular', 'Molecular Epidemiology', 'Mycobacterium tuberculosis', 'Nature', 'New York', 'New York City', 'Patients', 'Pattern', 'Phylogeny', 'Population', 'Prevention', 'Principal Investigator', 'Property', 'Protocols documentation', 'Public Health', 'Research Institute', 'Research Personnel', 'Rest', 'Restriction fragment length polymorphism', 'Single Nucleotide Polymorphism', 'Social Network', 'Source', 'Stream', 'Structure', 'Time', 'Translating', 'Trees', 'Tuberculosis', 'United States', 'Visual', 'Work', 'base', 'demographics', 'design', 'disorder control', 'family genetics', 'fight against', 'genetic analysis', 'genetic variant', 'improved', 'mycobacterial', 'novel', 'pathogen', 'patient privacy', 'programs', 'prototype', 'success', 'theories', 'tool', 'transmission process', 'transposon/insertion element', 'trend', 'tuberculosis treatment']",NLM,RENSSELAER POLYTECHNIC INSTITUTE,R01,2008,342967,12471676,0.026010661200439645
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7471355,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genome', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Numbers', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Rate', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'day', 'discount', 'drug discovery', 'fluorescence imaging', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,R01,2008,411777,50305751,-0.040508061707775246
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7458835,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2008,503603,570146095,0.006167634549374861
"Metabolomic Assessment of Estrogenic Endocrine Disruptor    DESCRIPTION (provided by applicant)     Estrogenic endocrine disruptors (EEDs) are a group of structurally diverse compounds that include pharmaceuticals, dietary supplements, industrial chemicals and environmental contaminants.  They can elicit a number of adverse health effects such as hormone dependent cancers, reproductive tract abnormalities, compromised reproductive fitness, and impaired cognitive abilities.  In order to fully assess the potential adverse effects of synthetic and natural EEDs, a more comprehensive understanding of their molecular, metabolic, and tissue level effects is required within the context of a whole organism.  This collaborative proposal will elucidate the pathways, networks and signaling cascades perturbed by EEDs using the complementary multidisciplinary expertise of its team members in the areas of toxicology, molecular biology, endocrinology, multinuclear NMR spectroscopy, data management and advanced data analysis.  The comparative effects of ethynyl estradiol (EE), genistein (GEN), and o, p'-dichlorodiphenyltrichloroethane (DDT) on metabolite levels will be assessed in urine, serum and liver extracts by multinuclear (i. e., 1H, 13C, 31P) NMR spectroscopy, and complemented with histopathology examination and gene expression data from ongoing microarray studies in both mouse and rat models.  All data will be stored and archived in dbZach, a MIAME-compliant toxicogenomic supportive database that facilitates data analysis, the integration of disparate data sets, the exchange of data between investigators, and the deposition of data into public repositories.  Advanced statistical approaches, modeling and data integration tools such as neural networks, data fusion, and Baysean inference will be used to fuse these disparate data sets in order to elucidate the conserved biological networks that are of importance in response to endogenous estrogens.  Moreover, EED perturbed pathways associated with elicited effects will be further defined.  Results from these studies will not only further define the physiologic and toxic mechanisms of action of estrogenic compounds but will also demonstrate the synergy of fusing complementary microarray, metabolomic and histopathology data into a comprehensive integrative computational model.  This approach will also demonstrate the ability to maximize knowledge extraction from all disparate data available within the proposed innovative data management system when used with the advanced information tools that will be developed.            n/a",Metabolomic Assessment of Estrogenic Endocrine Disruptor,7440169,R01ES013927,"['Adverse effects', 'Affect', 'Apical', 'Archives', 'Area', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Cell Proliferation', 'Chemicals', 'Class', 'Classification', 'Clinical Chemistry', 'Cognitive', 'Complement', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Deposition', 'Development', 'Disease Progression', 'Dose', 'Endocrine Disruptors', 'Endocrinology', 'Engineering', 'Environmental Pollution', 'Estradiol', 'Estrogens', 'Funding', 'Future', 'Gene Expression', 'Genistein', 'Health', 'Hepatic', 'Histopathology', 'Hormones', 'Knowledge Extraction', 'Lead', 'Link', 'Lipids', 'Liver Extract', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Metabolic', 'Metabolism', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Multinuclear NMR', 'Mus', 'NMR Spectroscopy', 'Numbers', 'Organ Weight', 'Outcome', 'Pathway interactions', 'Pattern Recognition', 'Pharmacologic Substance', 'Physiological', 'Principal Investigator', 'Process', 'Rattus', 'Reporting', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Assessment', 'Rodent', 'Sampling', 'Screening procedure', 'Serum', 'Signal Transduction', 'Spectrum Analysis', 'System', 'Techniques', 'Time', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Urine', 'Whole Organism', 'aqueous', 'comparative', 'data integration', 'data management', 'dichlorodiphenyltrichloroethane', 'dietary supplements', 'estrogenic endocrine disruptor', 'experience', 'fitness', 'innovation', 'member', 'metabolic abnormality assessment', 'metabolomics', 'multidisciplinary', 'programs', 'repository', 'reproductive', 'research study', 'response', 'tool']",NIEHS,MICHIGAN STATE UNIVERSITY,R01,2008,535031,89938253,-0.01727768537112088
"Robust Classification Methods for Categorical Regression    DESCRIPTION (provided by applicant): Improving statistical methods to provide better classification performance and new analytical capabilities for categorical regression would be invaluable to the medical and health care research communities. Categorical regression models (e.g., binary logistic, multinomial logistic) are used extensively to identify patterns of alcohol-related symptoms, screen for disorders, and assess policies. In addition, such models are used extensively in other areas of research such as mental illness, cancer, traumatic injuries, and AIDS-related pathologies. However, many such models are developed with inadequate support to fully analyze and exploit the intrinsically probabilistic nature of their results. This is of critical importance as health researchers, clinicians, and administrators are often faced with classification decisions using categorical regression models to identify unacceptable risks, adequate outcomes, and acceptable guidelines for screening, diagnoses, treatment, and quality of care. Commercially available statistical software does not offer sophisticated methods for robust estimation of posterior probabilities in the presence of model misspecification, missing covariates, and nonignorable missing data generating processes. Such robust missing data handling methods provide natural mechanisms for dealing with verification bias and modeling correlated, longitudinal, or survey data with complex sampling designs. Moreover, commercially available statistical software does not provide automated methods for using estimated posterior probabilities to make optimal classification decisions with respect to different optimality criteria. In particular, automated features such as optimizing multiple decision criteria (allocation rules) that trade off specificity against sensitivity, decision threshold confidence intervals, statistical tests for evaluating correct specification of posterior probabilities, statistical tests for comparing competing classifier thresholds, and methods for multi-outcome classification and inference are not readily available. Phase II research will extend Phase I findings for binary logistic regression to develop and implement automated robust classification methods for multinomial logistic regression modeling, which also applies to the larger class of nonlinear categorical regression models that output posterior probabilities. The Phase II software prototype will provide: 1) new user-selectable robust decision threshold estimators, 2) robust confidence intervals on decision threshold estimators, 3) new classifier threshold comparison tests, 4) new outcome probability specification tests, 5) efficient missing data handling methods in the presence of nonignorable nonresponse data, and 6) second-order analytic and simulation-based Bayesian methods for improved small sample and rare event outcome probability estimation. These new methodologies will be integrated into a prototype user-friendly software package, evaluated with extensive simulation studies, and then applied to real world classification problems encountered in: alcohol, mental illness (depression, bipolar, schizophrenia), cancer (prostate), trauma (emergency room), and infectious disease (AIDS) through collaborations with domain experts in those respective fields. In summary, Phase II research will establish the essential technical foundation for Phase III commercialization with the objective of providing a suite of new classification analysis methods as an advanced statistical tool that improves epidemiologic, clinical, and public health research.                 n/a",Robust Classification Methods for Categorical Regression,7395177,R44CA139607,"['Accident and Emergency department', 'Achievement', 'Address', 'Administrator', 'Agreement', 'Alcohols', 'Algorithms', 'Area', 'Bayesian Method', 'Behavior', 'Bipolar Depression', 'Class', 'Classification', 'Clinical', 'Clinical Investigator', 'Collaborations', 'Communicable Diseases', 'Communities', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Analyses', 'Data Set', 'Decision Analysis', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Disease regression', 'Empirical Research', 'Engineering', 'Epidemiologic Studies', 'Epidemiologist', 'Evaluation', 'Event', 'Foundations', 'Goals', 'Guidelines', 'Health', 'Health Services Research', 'Healthcare', 'Industry', 'Information Resources Management', 'Injury', 'Jordan', 'Journals', 'Knowledge', 'Literature', 'Logistic Regressions', 'Logistics', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Outcome', 'Output', 'Pathology', 'Pattern', 'Peer Review', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Policies', 'Preparation', 'Probability', 'Process', 'Public Health', 'Publishing', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Risk', 'Robin bird', 'Sampling', 'Schizophrenia', 'Screening procedure', 'Sensitivity and Specificity', 'Simulate', 'Software Tools', 'Specific qualifier value', 'Specificity', 'Standards of Weights and Measures', 'Statistical Methods', 'Surveys', 'Symptoms', 'Technology', 'Testing', 'Trauma', 'anticancer research', 'base', 'commercialization', 'computerized data processing', 'density', 'design', 'graphical user interface', 'improved', 'innovation', 'prototype', 'simulation', 'software development', 'theories', 'tool', 'user friendly software']",NCI,MARTINGALE RESEARCH CORPORATION,R44,2008,857168,0,0.0009636971483650964
"Machine Learning Applied to Automated Planar Patch Clamps    DESCRIPTION (provided by applicant): The introduction of automated planar patch clamp instruments over the past two years has increased the throughput of voltage clamp ion channel assays by a factor of at least ten. This is possible because the automated systems can perform assays in parallel using16 and 384-well plates. While the drug discovery industry has embraced this new technology, the enthusiasm has been tempered by the modest success rates of the assays and by the high cost of the consumable patch substrate. Currently, typical success rates for a standard ion channel assay, using, for example, the Q-Patch from Sophion Biosciences, the Port-a-Patch system from Nanion Biosciences, or the PatchXpress from Molecular Devices Corp., is around 50%. In other words, for every16 channel chip used in these systems, only eight will produce useable data. This effectively doubles the price of each data point over what is ideally possible. In order for a planar patch clamp experiment to succeed, several events need to occur (assuming that the cell expresses the appropriate ion channels in functional states): the cell of interest must form a high-resistance seal with the planar substrate, the whole-cell configuration must be achieved, and fluidic pathways must be intact so that compounds of interest maybe applied to the cell. A failure of anyone of these steps will result in no data collected from that well. We propose to optimize the first two steps in this process, namely, seal formation and entry into whole-cell recording configuration. We will use machine learning approaches to examine how a human patch clamp expert interacts with the patch clamp system in order to develop a model that will provide parameters that can be used to more efficiently and successfully provide useable whole-cell recording configuration. It is important to note that the model that we derive from our approach will not actually copy what the expert does, but will attempt to optimize the process based on cues that mayor may not be consciously monitored by the expert. The Specific Aims of the Phase I component will be to: (1) integrate recording capabilities into existing automated patch clamp software from Nanion, (2) evaluate the success rate of the procedure specified by our machine learning analysis, and (3) develop stand-alone software for use specifically with manual patch clamp setups and for exploration of the potential benefits of using machine learning via expert training in other applications. In Phase II we propose to develop the proof-of-concept software into a user-friendly commercial software module which we will offer to existing and potential automated patch clamp companies. We will also simplify and streamline the user interface of this software as a stand-alone component for manual patch clamp systems. Developing drugs that target ion channels has been hindered by the expense of the consumables used in automated patch clamp screening devices. We propose to develop a method, using machine learning techniques which may increase the success rate of these instruments and therefore lower the overall cost of ion channel drug discovery.          n/a",Machine Learning Applied to Automated Planar Patch Clamps,7220448,R43EB007148,"['Biological Assay', 'Cells', 'Chemistry', 'Computer software', 'Condition', 'Cues', 'Data', 'Devices', 'Drug Delivery Systems', 'Employee Strikes', 'Event', 'Failure', 'Goals', 'Housing', 'Human', 'Industry', 'Ion Channel', 'Learning', 'Licensing', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Monitor', 'Pathway interactions', 'Performance', 'Phase', 'Price', 'Procedures', 'Process', 'Programmed Learning', 'Protocols documentation', 'Rate', 'Relative (related person)', 'Research', 'Research Personnel', 'Resistance', 'Running', 'Sales', 'Scientist', 'Screening procedure', 'Software Engineering', 'Solutions', 'Specific qualifier value', 'Spottings', 'Standards of Weights and Measures', 'Suction', 'Surface', 'System', 'Techniques', 'Testing', 'Training', 'Visual', 'Whole-Cell Recordings', 'Work', 'Writing', 'base', 'cell type', 'concept', 'cost', 'drug discovery', 'improved', 'instrument', 'interest', 'new technology', 'patch clamp', 'programs', 'research study', 'seal', 'success', 'tool', 'user-friendly', 'voltage', 'voltage clamp']",NIBIB,BLATZ SCIENTIFIC,R43,2007,1,0,-0.026469333382600317
"Systems analysis of oxygen regulation in Halobacterium    DESCRIPTION (provided by applicant): To withstand environmental onslaught, biological systems mount global programs to coordinate the induction of protection and repair mechanisms. This proposal poses the hypothesis that the transcriptional networks underlying such responses to diverse stressors are interrelated. Halobacterium, a halophilic archaeon, has been chosen as a model for this study because it routinely negotiates an array of adverse conditions in its extreme environment, including anoxia, metal stress, and radiation damage. This proposal will investigate the inter-relationship of these responses using global approaches. Given that basal genetic information processing pathways in Halobacterium are mediated by eukaryotic-like proteins, findings from this study will have a direct impact on understanding how complex eukaryotic organisms elicit orthogonal responses in disease-perturbed or infection states. Specifically, I will (1) Characterize key transcriptional regulators responsible for mediating responses to fluctuating oxygen concentrations and identify regulons under their direct and indirect control; (2) Through statistical analysis of integrated datasets, evaluate the extent of cross-regulation of the anoxic response with other environmental perturbations; (3) Experimentally test new hypotheses generated by statistical analysis. These proposed experiments are expected to result in a transcriptional network model that addresses how organisms maintain homeostasis despite stress.           n/a",Systems analysis of oxygen regulation in Halobacterium,7261251,F32GM078980,"['Address', 'Aerobic', 'Algorithms', 'Anoxia', 'Archaea', 'Behavioral', 'Binding Sites', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Phenomena', 'Cells', 'Collection', 'Complex', 'Computer software', 'Condition', 'Couples', 'Data', 'Data Set', 'Defect', 'Disease', 'Electrophoretic Mobility Shift Assay', 'Environment', 'Equilibrium', 'Experimental Designs', 'Face', 'Facility Construction Funding Category', 'Fellowship', 'Gene Targeting', 'Genes', 'Genetic Information Processing Pathway', 'Genome', 'Goals', 'Growth', 'Halobacterium', 'Homeostasis', 'Hydrogen Peroxide', 'Individual', 'Infection', 'Information Systems', 'Knock-out', 'Laboratories', 'Learning', 'Light', 'Localized', 'Machine Learning', 'Manuscripts', 'Maps', 'Mediating', 'Mediation', 'Metals', 'Modeling', 'Molecular Biology', 'Mutate', 'Names', 'Organism', 'Oxidation-Reduction', 'Oxidative Stress', 'Oxygen', 'Oxygen measurement, partial pressure, arterial', 'Play', 'Preparation', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Radiation', 'Regulation', 'Regulator Genes', 'Regulon', 'Relative (related person)', 'Role', 'Stress', 'Study models', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Testing', 'Time', 'TimeLine', 'Training', 'Transcription Initiation Site', 'Transcriptional Regulation', 'Work', 'biological adaptation to stress', 'cell injury', 'chromatin immunoprecipitation', 'halobacteria', 'high throughput screening', 'in vivo', 'insight', 'metal poisoning', 'mutant', 'network models', 'novel', 'programs', 'repaired', 'research study', 'response', 'stressor', 'transcription factor']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,F32,2007,48796,10159852,-0.011953498939427057
"Developing computerized tools for cryosurgery planning    DESCRIPTION (provided by applicant):    Cryosurgery has been known as an invasive surgical technique since 1961, when Cooper and Lee invented the first cryoprobe. In the 1990s, new developments in Joule-Thomson cooling (the cooling effect associated with a sudden relief of a pressurized gas) led to a dramatic decrease in the size of cryoprobes and an increase in the number of cryoprobes that could be used simultaneously. A dozen or more cryoprobes operating simultaneously in a single prostate cryosurgery is already common practice. If localized effectively, one of the primary benefits of using a large number of miniaturized cryoprobes is superior control over the freezing process.   Currently, the process of selecting the correct placement of the cryoprobes for a specific procedure is an art held by the cryosurgeon, based on the surgeon's own experience and rules of thumb. Cryoprobes are typically operated in a trial-and-error fashion, until the entire target volume is thought to be frozen. Currently, there are no means to determine the optimal locations for the cryoprobes. Suboptimal cryoprobe localization may leave regions in the target volume unfrozen, may lead to cryoinjury of healthy surrounding tissues, may require an unnecessarily large number of cryoprobes, may increase the duration of the surgical procedure, and may increase the likelihood of post cryosurgery complications, all of which affect the quality and cost of the medical treatment. Computerized planning tools would help to alleviate these difficulties.   The ""cryoheater,"" a new device for cryosurgery control has recently been presented by the research team. The cryoheater is a temperature controlled electrical heater. In broad terms, cryoheaters can dramatically increase the ability to control the shape and size of the frozen region, however, to achieve the full benefits of cryoheaters, computerized planning tools for cryoheater localization are necessary.   Our goal is to develop computerized planning tools for cryosurgery that are suitable for all available cooling techniques. The proposed research includes: (1) Development of an efficient numerical scheme for bioheat transfer simulations of cyroprocedures, (2) Development of an efficient optimization technique based on a force-field analogy. (3) Development of knowledge-based optimization techniques. (4) Experimental verification of the planning tool.       Besides planning, another important application of the proposed tool is the training of cryosurgeons. The proposed tool will provide cryosurgeons with the ability to visualize the 3D volumetric nature of the freezing process.   Likewise, it will allow the surgeon to explore the performance of various configurations of cryoprobes and cryoheaters, and observe the defects that would result from each. Such visualization capabilities will provide surgeons with insights into the physics of cryosurgery that are difficult to obtain from physical experiments or surgical practice.         n/a",Developing computerized tools for cryosurgery planning,7210691,R01EB003563,"['Affect', 'Arts', 'Biological', 'Catheters', 'Computational Technique', 'Condition', 'Cool-X-A', 'Cryosurgery', 'Defect', 'Depth', 'Development', 'Devices', 'Europe', 'Feasibility Studies', 'Freezing', 'Frequencies', 'Furuncles', 'Gases', 'Goals', 'Heating', 'Imagery', 'Imaging Device', 'Invasive', 'Lasers', 'Lead', 'Learning', 'Left', 'Liquid substance', 'Localized', 'Location', 'Machine Learning', 'Medical', 'Methods', 'Modems', 'Nature', 'Nitrogen', 'Numbers', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Performance', 'Physics', 'Placement', 'Procedures', 'Process', 'Prostate', 'Publishing', 'Purpose', 'Radio', 'Reporting', 'Research', 'Research Proposals', 'Scheme', 'Shapes', 'Simulate', 'Solutions', 'Source', 'Surgeon', 'Techniques', 'Temperature', 'Thermal Ablation Therapy', 'Thinking', 'Thumb structure', 'Time', 'Tissues', 'Training', 'Ultrasonography', 'Urethra', 'base', 'clinical application', 'computerized', 'computerized tools', 'cost', 'experience', 'insight', 'knowledge base', 'miniaturize', 'research study', 'simulation', 'size', 'thermal seeds', 'three-dimensional modeling', 'tool']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2007,87443,30434536,-0.01340156168405763
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7298516,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2007,88539,807432003,-0.02113923764159205
"Least Angle Regression    DESCRIPTION (provided by applicant): This SBIR project aims to produce superior methods and software for classification and regression when there are many potential predictor variables to choose from. The methods should (1) produce stable results, where small changes in the data do not produce major changes in the variables selected or in model predictions; (2) produce accurate predictions; (3) facilitate scientific interpretation, by selecting a smaller subset of predictors which provide the best predictions; (4) allow continuous and categorical variables; and (5) support linear regression, logistic regression (predicting a binary outcome), survival analysis, and other types of regression. This project is based on least angle regression, which unifies and provides a fast implementation for a number of modern regression techniques. Least angle regression has great potential, but currently available software is limited in scope and robustness. The outcome of this project should be software which is more robust and widely applicable. This software would apply broadly, including to medical diagnosis, detecting cancer, feature selection in microarrays, and modeling patient characteristics like blood pressure. Phase I work demonstrates feasibility by extending least angle work in three key directions-categorical predictors, logistic regression, and a numerically-accurate implementation. Phase II goals include extensions to other types of explanatory variables (e.g. polynomial or spline functions, and interactions between variables), to survival and other additional regression models, and to handle missing data and massive data sets. This proposed software will enable medical researchers to obtain high prediction accuracy, and obtain stable and interpretable results, in high-dimensional situations. Predicting outcomes based on covariates, determining which covariates most affect outcomes, and adjusting treatment effects estimates for covariates, are among the most important problems in biostatistics. Prediction and feature selection are particularly difficult when there are more possible features than samples; gene microarrays and protein mass spectrometry are extreme examples of this, producing thousands to millions of measurements per sample. LARS excels at feature selection; the proposed software should enable medical researchers to obtain stable and interpretable models with better prediction accuracy in high-dimensional situations.             n/a",Least Angle Regression,7293630,R44GM074313,"['Affect', 'Algorithms', 'Biometry', 'Blood Pressure', 'Case Study', 'Cations', 'Characteristics', 'Classification', 'Computer software', 'Consult', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease regression', 'Future', 'Genes', 'Goals', 'Healthcare', 'Lasso', 'Libraries', 'Linear Models', 'Logistic Regressions', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measurement', 'Medical', 'Methods', 'Microarray Analysis', 'Mind', 'Modeling', 'Non-linear Models', 'Numbers', 'Outcome', 'Output', 'Patients', 'Personal Satisfaction', 'Phase', 'Procedures', 'Process', 'Protein Microchips', 'Proteome', 'Proteomics', 'Research Personnel', 'Sampling', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Survival Analysis', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Work', 'base', 'design', 'falls', 'graphical user interface', 'improved', 'interest', 'prototype', 'statistics', 'tool', 'treatment effect', 'ward']",NIGMS,INSIGHTFUL CORPORATION,R44,2007,158481,0,-0.003513287753495822
"Least Angle Regression    DESCRIPTION (provided by applicant): This SBIR project aims to produce superior methods and software for classification and regression when there are many potential predictor variables to choose from. The methods should (1) produce stable results, where small changes in the data do not produce major changes in the variables selected or in model predictions; (2) produce accurate predictions; (3) facilitate scientific interpretation, by selecting a smaller subset of predictors which provide the best predictions; (4) allow continuous and categorical variables; and (5) support linear regression, logistic regression (predicting a binary outcome), survival analysis, and other types of regression. This project is based on least angle regression, which unifies and provides a fast implementation for a number of modern regression techniques. Least angle regression has great potential, but currently available software is limited in scope and robustness. The outcome of this project should be software which is more robust and widely applicable. This software would apply broadly, including to medical diagnosis, detecting cancer, feature selection in microarrays, and modeling patient characteristics like blood pressure. Phase I work demonstrates feasibility by extending least angle work in three key directions-categorical predictors, logistic regression, and a numerically-accurate implementation. Phase II goals include extensions to other types of explanatory variables (e.g. polynomial or spline functions, and interactions between variables), to survival and other additional regression models, and to handle missing data and massive data sets. This proposed software will enable medical researchers to obtain high prediction accuracy, and obtain stable and interpretable results, in high-dimensional situations. Predicting outcomes based on covariates, determining which covariates most affect outcomes, and adjusting treatment effects estimates for covariates, are among the most important problems in biostatistics. Prediction and feature selection are particularly difficult when there are more possible features than samples; gene microarrays and protein mass spectrometry are extreme examples of this, producing thousands to millions of measurements per sample. LARS excels at feature selection; the proposed software should enable medical researchers to obtain stable and interpretable models with better prediction accuracy in high-dimensional situations.             n/a",Least Angle Regression,7748342,R44GM074313,"['Affect', 'Algorithms', 'Biometry', 'Blood Pressure', 'Case Study', 'Characteristics', 'Classification', 'Computer software', 'Consult', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease regression', 'Future', 'Genes', 'Goals', 'Healthcare', 'Lasso', 'Libraries', 'Linear Models', 'Logistic Regressions', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measurement', 'Medical', 'Methods', 'Microarray Analysis', 'Mind', 'Modeling', 'Non-linear Models', 'Numbers', 'Outcome', 'Output', 'Patients', 'Personal Satisfaction', 'Phase', 'Procedures', 'Process', 'Protein Microchips', 'Proteome', 'Proteomics', 'Research Personnel', 'Sampling', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Survival Analysis', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Work', 'base', 'design', 'falls', 'graphical user interface', 'improved', 'interest', 'prototype', 'statistics', 'tool', 'treatment effect', 'ward']",NIGMS,INSILICOS,R44,2007,168203,0,-0.003513287753495822
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7214118,R42ES013321,"['Accounting', 'Animals', 'Architecture', 'Biological Assay', 'Biological Neural Networks', 'Chemicals', 'Clinical', 'Clinical Trials', 'Computer Simulation', 'Computer software', 'Contracts', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Drug Formulations', 'Drug Industry', 'Drug toxicity', 'End Point', 'Expert Systems', 'Funding', 'Future', 'Fuzzy Logic', 'Gene Expression', 'Guidelines', 'Health Care Costs', 'Hepatotoxicity', 'Investments', 'Learning', 'Liver', 'Marketing', 'Methods', 'Network-based', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Process', 'Proteomics', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Rate', 'Relative (related person)', 'Reliance', 'Research', 'Research Personnel', 'Screening procedure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Training', 'Validation', 'base', 'computational chemistry', 'cost', 'data acquisition', 'design', 'highly advanced system', 'improved', 'innovation', 'knowledge base', 'metabolomics', 'quantum', 'serial analysis of gene expression', 'subtraction hybridization', 'tool']",NIEHS,"YAHSGS, LLC",R42,2007,257269,0,-0.016260051630189256
MACE - Michigan Alliance for Cheminformatic Exploration No abstract available n/a,MACE - Michigan Alliance for Cheminformatic Exploration,7472717,P20HG003890,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Michigan', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,UNIVERSITY OF MICHIGAN,P20,2007,271370,0,0.014458332442745801
"Development of rapid detection tests for Brucella species    DESCRIPTION (provided by applicant): Brucellosis is a re-emerging zoonotic disease that affects humans and a variety of farm animals. As well as a threat to public health it has considerable economic importance. The etiologic agent responsible for human infection, Brucella melitensis, is classified by both NIAID and CDC as a Category B biothreat pathogen. Antibiotics are only partially effective at controlling the disease and there is no vaccine approved for use in humans. Thus, prompt and accurate diagnosis is the key to containing infection. Currently, the most common diagnostic tests for Brucella are based on indirect serology which are lacking in specificity and sensitivity as well as speed of execution. Thus, there is a pressing need to develop improved diagnostics, especially technologies that may be used at field level. This investigation proposes to address this issue and develop a superior and robust technique for diagnosing Brucella infection with highly specific, non-cross reactive antibody reactions. We will achieve this goal by screening the Brucella genome using novel proteomic chip technology to identify unique antigens that will yield highly specific and accurate diagnoses. This work will be undertaken in Phase 1 of the application. In Phase 2, when antigens have been selected, we anticipate that we will proceed to develop ELISA and immunoblot assays. In parallel, both ELISA and lateral flow ""dipstick"" tests for Brucella antigen will be constructed. We envisage that the antigen assays will have particular utility in detecting Brucella disseminated in the context of the bioterrorism event. The diagnostic tools developed within this application will be rigorously evaluated for sensitivity and specificity using large and diverse panels of human and animal Brucella-positive sera available through our collaborators. The project proposes to develop a highly sensitive and robust diagnostic test for brucellosis, also known as ""undulant fever"", an infectious disease that causes serious illness in farm animals and humans. The current techniques for diagnosing infection are somewhat unreliable and based on outmoded methods. This investigation will use state- of-the-art technology to identify new structures or antigens on Brucella bacteria that may be used to develop a test with superior diagnostic performance.          n/a",Development of rapid detection tests for Brucella species,7278655,R43AI068166,"['Acute', 'Address', 'Affect', 'Algorithms', 'Animals', 'Antibiotics', 'Antibodies', 'Antigen Targeting', 'Antigens', 'Area', 'Artificial Intelligence', 'Arts', 'Bacteria', 'Bioinformatics', 'Biological Assay', 'Bioterrorism', 'Brucella', 'Brucella abortus', 'Brucella melitensis', 'Brucellosis', 'Categories', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Clinical', 'Communicable Diseases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Economics', 'Enzyme-Linked Immunosorbent Assay', 'Event', 'Fluorescence', 'Genes', 'Genome', 'Goals', 'Human', 'Immune Sera', 'Immunoassay', 'Immunoblotting', 'Immunodominant Antigens', 'Infection', 'Investigation', 'Lateral', 'Livestock', 'Methods', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Peptides', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Printing', 'Proteomics', 'Public Health', 'Reaction', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Serologic tests', 'Serum', 'Speed', 'Structure', 'Study of serum', 'System', 'Techniques', 'Technology', 'Testing', 'Vaccines', 'Work', 'Yersinia enterocolitica', 'base', 'biothreat', 'disorder control', 'improved', 'novel', 'pathogen', 'prototype', 'rapid detection', 'response', 'tool']",NIAID,"INBIOS INTERNATIONAL, INC.",R43,2007,278818,299112,-0.01190655432474585
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7186695,R01NS051826,"['Accounting', 'Adult', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Anatomic structures', 'Anatomy', 'Area', 'Atlases', 'Back', 'Biomechanics', 'Boston', 'Brain', 'Caring', 'Class', 'Classification', 'Clinical assessments', 'Clutterings', 'Collaborations', 'Competence', 'Computer Simulation', 'Computer Vision Systems', 'Computing Methodologies', 'Corpus Callosum', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diffuse Pattern', 'Discipline of obstetrics', 'Disease', 'Disease Progression', 'Effectiveness', 'Effectiveness of Interventions', 'Electroencephalography', 'Elements', 'Ensure', 'Evaluation', 'Evolution', 'Fetal Growth Retardation', 'General Hospitals', 'Genetic Markers', 'Goals', 'Gold', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Incidence', 'Individual', 'Infant', 'Intervention', 'Intuition', 'Invasive', 'Knowledge', 'Label', 'Learning', 'Learning Disabilities', 'Link', 'Localized', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphologic artifacts', 'Morphology', 'Motivation', 'Neonatal', 'Neuroanatomy', 'Neurosciences', 'Neurosurgeon', 'Noise', 'Normal Range', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Pediatric Hospitals', 'Population', 'Population Characteristics', 'Population Study', 'Positioning Attribute', 'Premature Infant', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Property', 'Psyche structure', 'Range', 'Rate', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Resolution', 'Rest', 'Role', 'Scanning', 'Schizophrenia', 'Shapes', 'Site', 'Specificity', 'Staging', 'Standards of Weights and Measures', 'Statistical Distributions', 'Statistical Models', 'Statistical Study', 'Statistically Significant', 'Structure', 'Surface', 'Surgeon', 'Surgical Instruments', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Tweens', 'Universities', 'Validation', 'Variant', 'Washington', 'Woman', 'base', 'cohort', 'computer studies', 'computerized tools', 'desire', 'deviant', 'disease classification', 'expectation', 'feeding', 'healthy aging', 'imaging Segmentation', 'improved', 'instrument', 'interest', 'mortality', 'neonate', 'nervous system disorder', 'neuroimaging', 'neurosurgery', 'normal aging', 'novel', 'programs', 'radiologist', 'reconstruction', 'relating to nervous system', 'research clinical testing', 'response', 'shape analysis', 'statistics', 'tool', 'tumor']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2007,282619,113554200,-0.0054951450601741425
"Robust computational framework for predictive ADME-Tox modeling    DESCRIPTION (provided by applicant):    This proposal seeks to establish a universally applicable and robust predictive ADME-Tox modeling framework based on rigorous Quantitative Structure Activity/Property Relationships (QSAR/QSPR) modeling. The framework has been refined in the course of many years of our research in the areas of QSPR methodology development and application to experimental datasets that led to novel analytical approaches, descriptors, model validation schemes, overall QSPR workflow design, and multiple end-point studies. This proposal focuses on the design of optimized QSPR protocols for the development of reliable predictors of critically important ADME-Tox properties. The ADME properties will include, but not limited to, water solubility, membrane permeability, P450 metabolism inhibition and induction, metabolic stability, human intestinal absorption, bioavailability, transporters and PK data; a variety of toxicological end-points vital to human health will be explored; they are available from recent initiatives on development and standardization of toxicity data, such as the US FDA, NIEHS, and EPA DSS-Tox and other database projects. The ultimate goal of this project is sharing both modeling software and specialized predictors with the research community via a web-based Predictive ADME-Tox Portal. The project objectives will be achieved via concurrent development of QSPR methodology (Specific Aim 1), building highly predictive, robust QSPR models of known ADME-Tox properties (Specific Aim 2), and the deployment of both modeling software and individual predictors via a specialized web-portal (Specific Aim 3). To achieve the goals of this project focusing on the development and delivery of specialized tools and rigorous predictors, we have assembled a research team of mostly senior investigators with complimentary skills and track records of accomplishment in the areas of computational drug discovery, experimental toxicology, statistical modeling, and software development and integration; two of the team members have had recent industrial experience before transitioning to academia. To the best of our knowledge, the results of this proposal will lead to the first publicly available in silico ADME-Tox modeling framework and predictors that can be used by the research community to analyze any set of chemicals (i.e., virtual and real compound sets). The framework will have a significant impact on compound prioritization, chemical library design, and candidate selection for preclinical and clinical development.            n/a",Robust computational framework for predictive ADME-Tox modeling,7244058,R21GM076059,"['Academia', 'Acute', 'Address', 'Area', 'Biological Availability', 'Cardiotoxicity', 'Cell Membrane Permeability', 'Chemicals', 'Chronic', 'Clinical', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Consensus', 'Cytochrome P450', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Drug Kinetics', 'End Point', 'Ensure', 'Environment', 'Goals', 'Health', 'Hepatotoxicity', 'Human', 'Individual', 'Internet', 'Intestinal Absorption', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Letters', 'Lung', 'Machine Learning', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Organ', 'Pharmacologic Substance', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Scheme', 'Scientist', 'Screening procedure', 'Secure', 'Source', 'Specialist', 'Standardization', 'Standards of Weights and Measures', 'Statistical Models', 'Statistically Significant', 'Structure', 'Students', 'Techniques', 'Technology', 'Testing', 'Toxic effect', 'Toxicology', 'Training', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'carcinogenicity', 'career', 'cluster computing', 'combinatorial', 'computer framework', 'data mining', 'design', 'drug discovery', 'experience', 'genotoxicity', 'innovation', 'knowledge of results', 'member', 'method development', 'neurotoxicity', 'novel', 'open source', 'pre-clinical', 'programs', 'protocol development', 'reproductive', 'skills', 'small molecule libraries', 'software development', 'tool', 'virtual', 'water solubility']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2007,328325,511185245,-0.00976633214131901
Comparative and Web-Enabled Virtual Screening No abstract available n/a,Comparative and Web-Enabled Virtual Screening,7472716,P20HG003900,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'comparative', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project', 'virtual', 'web-enabled']",NHGRI,NORTH CAROLINA STATE UNIVERSITY RALEIGH,P20,2007,363833,32532200,-0.02278244715535293
The RPI Exploratory Center for Cheminformatics (RMI) No abstract available n/a,The RPI Exploratory Center for Cheminformatics (RMI),7472067,P20HG003899,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,RENSSELAER POLYTECHNIC INSTITUTE,P20,2007,364010,12471676,0.012313504590920923
Carolina Exploratory Center for Cheminformatics Research No abstract available n/a,Carolina Exploratory Center for Cheminformatics Research,7472715,P20HG003898,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,P20,2007,373960,511185245,0.012313504590920923
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7264516,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genome', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Numbers', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Rate', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'day', 'discount', 'drug discovery', 'fluorescence imaging', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2007,387827,0,-0.040508061707775246
"CRCNS: Info. Process. & Neuronal Coordination: Neocortex DESCRIPTION (provided by applicant): The brain dysfunctions underlying schizophrenia are poorly understood. Nevertheless, it is likely that a critical aspect of this disease is a breakdown of the normal information processing functions of the neuronal assemblies. This project would study the activity of neuronal populations in sensory neocortex and investigate how neuronal assembly activity is disrupted in the dissociative anesthetic (PCP) model of schizophrenia.      Experimental investigation of this question will require recording large numbers of cells in functioning neural circuits. However, obtaining this data is only the beginning: the computational and statistical machinery to draw meaningful conclusions from such data must also be developed. Here we propose a collaborative research project between a mathematician (Kenneth Harris) and an electrophysiologist (Gyorgy Buzsaki), with the aim of recording, analyzing, and modeling the activity of large neuronal populations in primary sensory cortex and its disruption by psychotomimetic drugs. The project will rely on two techniques we have developed over the last years: large-scale neuronal recordings using silicon microelectrodes; and the data analysis method of peer prediction. The use of silicon probes will allow for estimation of the location of recorded cells, identification of monosynaptic connections between cell pairs, and characterization of neurons as pyramidal cells or interneurons. Experimentally identified assembly structure will be interpreted in the context of this circuit-level information.      We will investigate the hypothesis that psychotomimetic effects of low doses of dissociative anesthetics are caused by a partial distortion in assembly organization, whereas larger doses cause a more complete distortion resulting anesthesia. If reliable signatures of psychotomimetic doses on assembly structure are found, this will suggest a novel method of drug screening for antipsychotics, whereby candidate drugs are evaluated by their ability to reverse these signatures. n/a",CRCNS: Info. Process. & Neuronal Coordination: Neocortex,7235675,R01MH073245,"['Address', 'Algorithms', 'Anesthesia procedures', 'Anesthetics', 'Animals', 'Antipsychotic Agents', 'Area', 'Auditory', 'Auditory area', 'Biology', 'Brain', 'Cell Count', 'Cells', 'Cognitive', 'Collaborations', 'Complex', 'Computer information processing', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Disease', 'Disruption', 'Dissociative Anesthetics', 'Dose', 'Fire - disasters', 'Floods', 'Functional disorder', 'Hallucinogens', 'Interneurons', 'Investigation', 'Ketamine', 'Location', 'Machine Learning', 'Mathematics', 'Methods', 'Microelectrodes', 'Modality', 'Modeling', 'Monitor', 'Neocortex', 'Neurons', 'Neurosciences', 'Numbers', 'Pattern', 'Pharmaceutical Preparations', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Probability', 'Process', 'Psychotropic Drugs', 'Pyramidal Cells', 'Rattus', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Role playing therapy', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Silicon', 'Site', 'Stimulus', 'Structure', 'Sum', 'Techniques', 'Testing', 'Time', 'Training', 'Vibrissae', 'Work', 'awake', 'barrel cortex', 'computerized data processing', 'in vivo', 'neocortical', 'neural circuit', 'novel', 'peer', 'programs', 'response', 'sensory cortex', 'somatosensory', 'sound', 'statistics', 'theories']",NIMH,RUTGERS THE STATE UNIV OF NJ NEWARK,R01,2007,405312,10097598,-0.02157607833530068
"Metabolomic Assessment of Estrogenic Endocrine Disruptor    DESCRIPTION (provided by applicant)     Estrogenic endocrine disruptors (EEDs) are a group of structurally diverse compounds that include pharmaceuticals, dietary supplements, industrial chemicals and environmental contaminants.  They can elicit a number of adverse health effects such as hormone dependent cancers, reproductive tract abnormalities, compromised reproductive fitness, and impaired cognitive abilities.  In order to fully assess the potential adverse effects of synthetic and natural EEDs, a more comprehensive understanding of their molecular, metabolic, and tissue level effects is required within the context of a whole organism.  This collaborative proposal will elucidate the pathways, networks and signaling cascades perturbed by EEDs using the complementary multidisciplinary expertise of its team members in the areas of toxicology, molecular biology, endocrinology, multinuclear NMR spectroscopy, data management and advanced data analysis.  The comparative effects of ethynyl estradiol (EE), genistein (GEN), and o, p'-dichlorodiphenyltrichloroethane (DDT) on metabolite levels will be assessed in urine, serum and liver extracts by multinuclear (i. e., 1H, 13C, 31P) NMR spectroscopy, and complemented with histopathology examination and gene expression data from ongoing microarray studies in both mouse and rat models.  All data will be stored and archived in dbZach, a MIAME-compliant toxicogenomic supportive database that facilitates data analysis, the integration of disparate data sets, the exchange of data between investigators, and the deposition of data into public repositories.  Advanced statistical approaches, modeling and data integration tools such as neural networks, data fusion, and Baysean inference will be used to fuse these disparate data sets in order to elucidate the conserved biological networks that are of importance in response to endogenous estrogens.  Moreover, EED perturbed pathways associated with elicited effects will be further defined.  Results from these studies will not only further define the physiologic and toxic mechanisms of action of estrogenic compounds but will also demonstrate the synergy of fusing complementary microarray, metabolomic and histopathology data into a comprehensive integrative computational model.  This approach will also demonstrate the ability to maximize knowledge extraction from all disparate data available within the proposed innovative data management system when used with the advanced information tools that will be developed.            n/a",Metabolomic Assessment of Estrogenic Endocrine Disruptor,7240459,R01ES013927,"['Adverse effects', 'Affect', 'Apical', 'Archives', 'Area', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Cell Proliferation', 'Chemicals', 'Class', 'Classification', 'Clinical Chemistry', 'Cognitive', 'Complement', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Deposition', 'Development', 'Disease Progression', 'Dose', 'Endocrine Disruptors', 'Endocrinology', 'Engineering', 'Environmental Pollution', 'Estradiol', 'Estrogens', 'Funding', 'Future', 'Gene Expression', 'Genistein', 'Health', 'Hepatic', 'Histopathology', 'Hormones', 'Knowledge Extraction', 'Lead', 'Link', 'Lipids', 'Liver Extract', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Metabolic', 'Metabolism', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Multinuclear NMR', 'Mus', 'NMR Spectroscopy', 'Numbers', 'Organ Weight', 'Outcome', 'Pathway interactions', 'Pattern Recognition', 'Pharmacologic Substance', 'Physiological', 'Principal Investigator', 'Process', 'Rattus', 'Reporting', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Assessment', 'Rodent', 'Sampling', 'Screening procedure', 'Serum', 'Signal Transduction', 'Spectrum Analysis', 'System', 'Techniques', 'Time', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Urine', 'Whole Organism', 'aqueous', 'comparative', 'data integration', 'data management', 'dichlorodiphenyltrichloroethane', 'dietary supplements', 'estrogenic endocrine disruptor', 'experience', 'fitness', 'innovation', 'member', 'metabolic abnormality assessment', 'metabolomics', 'multidisciplinary', 'programs', 'repository', 'reproductive', 'research study', 'response', 'tool']",NIEHS,MICHIGAN STATE UNIVERSITY,R01,2007,543226,89938253,-0.01727768537112088
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7284239,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2007,588968,570146095,0.006167634549374861
"Novel TIRF microscopy analyzing trafficking & signaling at the cell cortex My major goal is to advance knowledge about events on or near the plasma membrane. This region directly controls membrane traffic to and from the cell surface (exo- and endocytosis) and is where extracellular signals are amplified and modulated by assembly of signaling scaffolds. The introduction of total internal reflection fluorescence (TIRF) microscopy, a technique that allows unprecedented axial resolution, has revolutionized studies of dynamic processes at the cell cortex. I propose 1) to develop two highly innovative multi-angle TIRF microscopes and 2) to apply these instruments towards the elucidation of mechanisms that regulate exo- and endocytosis. These microscopes will allow the penetration depth of the light beam to be varied rapidly and avoid traditional imaging artifacts. Together with new analytical methods, they will permit high-resolution 3D imaging of a ~50- 1000 nanometer cortical region of living cells. Additionally, a highly innovative FRAP implementation will allow us to `pulse' photoactivate single vesicles and track their fate. I will use this novel instrumentation to expand our ongoing studies on exo- and endocytic traffic. A main new goal will be to elucidate mechanisms in the vesicular trafficking pathways that regulate levels of glucose transporters (Glut4) at the cell surface, a process whose dysfunction leads to type 2 diabetes. I will test the hypothesis that the exocyst complex participates in the spatial regulation of the insulin responsiveness of Glut4 vesicle exocytosis. Using photoactivatable Glut4-Dendra I will determine whether insulin signaling triggers a switch from lipid raft to clathrin-mediated endocytic pathways. To address where PI3K signaling acts, I will implement inducible dimerization technology to rapidly turn on/off PI(3,4,5)P3 at the plasma membrane. The innovative approaches of this proposal capitalize on my unique expertise in interdisciplinary research spanning instrumentation, cell biology, and quantitative biology and will fundamentally impact biology and a medically important field. n/a",Novel TIRF microscopy analyzing trafficking & signaling at the cell cortex,7432044,DP2OD002980,"['1-Phosphatidylinositol 3-Kinase', 'Abbreviations', 'Accounting', 'Acoustics', 'Address', 'Adipocytes', 'Affect', 'Algorithms', 'Area', 'Arts', 'Attenuated', 'Automobile Driving', 'Award', 'Back', 'Binding', 'Biochemical', 'Biochemistry', 'Biological', 'Biology', 'Boxing', 'Buffers', 'Caliber', 'Calibration', 'Cell Line', 'Cell membrane', 'Cell surface', 'Cells', 'Cellular biology', 'Clathrin', 'Cluster Analysis', 'Collaborations', 'Collection', 'Collimator', 'Color', 'Coma', 'Communities', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computers', 'Conflict (Psychology)', 'Confocal Microscopy', 'Coupled', 'Coupling', 'Cues', 'Cytoskeleton', 'Data', 'Data Set', 'Defect', 'Depth', 'Development', 'Diabetes Mellitus', 'Diffusion', 'Dimensions', 'Dimerization', 'Disadvantaged', 'Discipline', 'Docking', 'Down-Regulation', 'Drops', 'Dyes', 'Employee Strikes', 'Endocytosis', 'Engineering', 'Ensure', 'Environment', 'Event', 'Exocytosis', 'Eye', 'Face', 'Feedback', 'Fiber', 'Figs - dietary', 'Flare', 'Fluorescein-5-isothiocyanate', 'Fluorescence', 'Fluorescence Microscopy', 'Fluorescence Recovery After Photobleaching', 'Fluorescent Dyes', 'Functional disorder', 'Funding', 'Genetic Screening', 'Germany', 'Glass', 'Glucose Transporter', 'Glycerol', 'Goals', 'Grant', 'Green Fluorescent Proteins', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Insulin', 'Interdisciplinary Study', 'Investments', 'Joints', 'Kinetics', 'Knowledge', 'Label', 'Laboratories', 'Lasers', 'Learning', 'Legal patent', 'Length', 'Life', 'Light', 'Lighting', 'Link', 'Lipids', 'Localized', 'Location', 'Macromolecular Complexes', 'Malignant Neoplasms', 'Maps', 'Masks', 'Measures', 'Mediating', 'Membrane', 'Membrane Microdomains', 'Membrane Protein Traffic', 'Methodology', 'Methods', 'Microscope', 'Microscopy', 'Microtubules', 'Modeling', 'Molecular', 'Monitor', 'Morphologic artifacts', 'Motivation', 'Motor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Optics', 'Organelles', 'PTEN gene', 'Paper', 'Parasites', 'Pathway interactions', 'Penetration', 'Performance', 'Personal Satisfaction', 'Phosphatidylinositols', 'Phosphoinositide-3-Kinase, Catalytic, Gamma Polypeptide', 'Phosphotransferases', 'Photobleaching', 'Physiologic pulse', 'Planet Mars', 'Play', 'Pliability', 'Positioning Attribute', 'Postdoctoral Fellow', 'Private Sector', 'Probability', 'Process', 'Proteins', 'Publications', 'Pulse taking', 'Pupil', 'Quantum Dots', 'RNA Interference', 'Radial', 'Randomized', 'Range', 'Reagent', 'Recruitment Activity', 'Refractive Indices', 'Regulation', 'Relative (related person)', 'Reporter', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Risk', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seminal', 'Series', 'Side', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Simulate', 'Site', 'Small Interfering RNA', 'Solid', 'Solutions', 'Sorting - Cell Movement', 'Source', 'Spain', 'Spatial Distribution', 'Specific qualifier value', 'Specimen', 'Speed', 'Spottings', 'Standards of Weights and Measures', 'Structure', 'Support of Research', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Thick', 'Time', 'Total Internal Reflection Fluorescent', 'Touch sensation', 'Training', 'Transfection', 'Tubulin', 'Vesicle', 'Visual', 'Wolves', 'Work', 'analytical method', 'basal insulin', 'base', 'blood glucose regulation', 'cell cortex', 'cell motility', 'cell type', 'cellular imaging', 'concept', 'day', 'density', 'design', 'desire', 'extracellular', 'flotillin', 'fluorescence imaging', 'fluorescence microscope', 'fluorophore', 'handbook', 'human wyatt protein', 'image processing', 'improved', 'innovation', 'insight', 'instrument', 'instrumentation', 'insulin signaling', 'interest', 'lens', 'medical schools', 'micromanipulator', 'migration', 'millisecond', 'mouse wyatt protein', 'nanometer', 'novel', 'object shape', 'photoactivation', 'prototype', 'radius bone structure', 'receptor', 'research study', 'response', 'scaffold', 'simulation', 'single molecule', 'success', 'tool', 'trafficking', 'trans-Golgi Network', 'trend', 'user-friendly', 'virtual']",OD,YALE UNIVERSITY,DP2,2007,2481250,550947887,-0.0012201994030366318
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,7287568,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2006,38558,0,-0.011343975215237792
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,7243612,R33RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R33,2006,350636,22951068,0.0058432115826896735
"Least Angle Regression    DESCRIPTION (provided by applicant): This SBIR project aims to produce superior methods and software for classification and regression when there are many potential predictor variables to choose from. The methods should (1) produce stable results, where small changes in the data do not produce major changes in the variables selected or in model predictions; (2) produce accurate predictions; (3) facilitate scientific interpretation, by selecting a smaller subset of predictors which provide the best predictions; (4) allow continuous and categorical variables; and (5) support linear regression, logistic regression (predicting a binary outcome), survival analysis, and other types of regression. This project is based on least angle regression, which unifies and provides a fast implementation for a number of modern regression techniques. Least angle regression has great potential, but currently available software is limited in scope and robustness. The outcome of this project should be software which is more robust and widely applicable. This software would apply broadly, including to medical diagnosis, detecting cancer, feature selection in microarrays, and modeling patient characteristics like blood pressure. Phase I work demonstrates feasibility by extending least angle work in three key directions-categorical predictors, logistic regression, and a numerically-accurate implementation. Phase II goals include extensions to other types of explanatory variables (e.g. polynomial or spline functions, and interactions between variables), to survival and other additional regression models, and to handle missing data and massive data sets. This proposed software will enable medical researchers to obtain high prediction accuracy, and obtain stable and interpretable results, in high-dimensional situations. Predicting outcomes based on covariates, determining which covariates most affect outcomes, and adjusting treatment effects estimates for covariates, are among the most important problems in biostatistics. Prediction and feature selection are particularly difficult when there are more possible features than samples; gene microarrays and protein mass spectrometry are extreme examples of this, producing thousands to millions of measurements per sample. LARS excels at feature selection; the proposed software should enable medical researchers to obtain stable and interpretable models with better prediction accuracy in high-dimensional situations.             n/a",Least Angle Regression,7219604,R44GM074313,"['computer human interaction', 'computer program /software', 'data management', 'handbook', 'mathematical model', 'mathematics', 'method development', 'microarray technology', 'model design /development', 'statistics /biometry']",NIGMS,INSIGHTFUL CORPORATION,R44,2006,374846,0,-0.003513287753495822
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7125135,R42ES013321,"['artificial intelligence', 'chemical structure function', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug discovery /isolation', 'drug screening /evaluation', 'functional /structural genomics', 'hepatotoxin', 'microarray technology', 'toxicant screening']",NIEHS,"YAHSGS, LLC",R42,2006,387181,0,-0.016260051630189256
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7125565,R01EB006200,"['NIH Roadmap Initiative tag', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'biotechnology', 'charge coupled device camera', 'computer program /software', 'computer system hardware', 'high throughput technology', 'image enhancement', 'robotics']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2006,399410,0,-0.040508061707775246
"Least Angle Regression DESCRIPTION (provided by applicant): This SBIR project aims to produce superior methods and software for classification and regression when there are many potential predictor variables to choose from. The methods should (1) produce stable results, where small changes in the data do to produce major changes in the variables selected or in model predictions, (2) produce accurate predictions, (3) facilitate scientific interpretation, by selecting a smaller subset of predictors which provide the best predictions, (4) allow continuous and categorical variables, and (5) support linear regression, logistic regression (predicting a binary outcome), survival analysis, and other types of regression. This project is based on least angle regression, which unifies and provides a fast implementation for a number of modern regression techniques. Least angle regression has great potential, but the state of the art is limited to linear regression with continuous or binary variables, and uses numerically-unstable calculations. The outcome of this project should be software which is more robust and widely applicable. This software would apply broadly, including to medical diagnosis, detecting cancer, feature selection in microarrays, and modeling patient characteristics like blood pressure.  Phase I work will demonstrate feasibility by extending least angle work in three key directions-categorical predictors, logistic regression, and a numerically-accurate implementation. Phase II will extend the work to other types of explanatory variables (e.g. polynomial or spline functions, and interactions between variables), and to survival and other additional regression models. This proposed software will enable medical researchers to obtain high prediction accuracy, and obtain stable and interpretable results, in high-dimensional situations. n/a",Least Angle Regression,6933500,R43GM074313,"['clinical research', 'computational biology', 'computer graphics /printing', 'computer human interaction', 'computer program /software', 'data collection methodology /evaluation', 'data quality /integrity', 'human data', 'mathematical model', 'model design /development', 'statistics /biometry', 'technology /technique development']",NIGMS,INSIGHTFUL CORPORATION,R43,2005,99685,0,0.0030951959971517473
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,6914863,R21RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R21,2005,167918,22951068,0.0058432115826896735
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7052491,R42ES013321,"['artificial intelligence', 'chemical structure function', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug discovery /isolation', 'drug screening /evaluation', 'functional /structural genomics', 'hepatotoxin', 'microarray technology', 'toxicant screening']",NIEHS,"YAHSGS, LLC",R42,2005,180862,0,-0.016260051630189256
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6910621,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2005,245768,0,-0.011343975215237792
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6850134,R01AR042739,"['artificial intelligence', 'bone density', 'bone fracture', 'clinical research', 'computer assisted diagnosis', 'densitometry', 'diagnosis design /evaluation', 'disease /disorder proneness /risk', 'hip', 'human subject', 'information systems', 'limbs', 'mathematical model', 'noninvasive diagnosis', 'osteoporosis', 'photon absorptiometry', 'radiography', 'spine', 'women&apos', 's health']",NIAMS,UNIVERSITY OF CHICAGO,R01,2005,297104,246330700,0.008429482073862253
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7012638,R01EB006200,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biotechnology', 'charge coupled device camera', 'computer program /software', 'computer system hardware', 'high throughput technology', 'image enhancement', 'robotics']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2005,363523,0,-0.040508061707775246
"Tree Ensemble Regression and Classification Methods    DESCRIPTION (provided by applicant):    This SBIR aims to produce next generation classification and regression software based upon ensembles of decision trees: bagging, random forests, and boosting. The prediction accuracy of these methods has caused much excitement in the machine learning community, and both challenges and complements the data modeling culture prevalent among biostatisticians. Recent research extends the methodology to likelihood based methods used in biostatistics, leading to models for survival data and generalized forest models. Generalized forest models extend regression forests in the same way that generalized linear models extend linear models.      This software would apply broadly, including to medical diagnosis, prognostic modeling, and detecting cancer; and for modeling patient characteristics like blood pressure, discrete responses in clinical trials, and count data.      Phase I work will prototype software for survival data, and investigate the performance of ensemble methods on simulated and real data. For survival applications, we will assess out-of-bag estimates of performance, and investigate measures of variable importance and graphics that help clinicians understand the results. Experience writing prototypes and using them on data will lead to a preliminary software design that serves as the foundation of Phase II work.      Phase II will expand upon this work to create commercial software. We will research and implement algorithms for a wider range of applications including generalized forest models, classification, and least squares regression. We will also implement robust loss criteria that enable good performance on noisy data, and make adaptations to handle large data sets.      This proposed software will enable medical researchers to obtain high prediction accuracy, and complement traditional tools like discriminant analysis, linear and logistic regression models, and the Cox model.         n/a",Tree Ensemble Regression and Classification Methods,6832086,R43CA105724,"['clinical research', 'computer assisted medical decision making', 'computer graphics /printing', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'human data', 'mathematical model', 'method development', 'model design /development', 'neoplasm /cancer classification /staging', 'neoplasm /cancer diagnosis', 'neoplasm /cancer remission /regression', 'prognosis', 'statistics /biometry']",NCI,INSIGHTFUL CORPORATION,R43,2004,99937,0,0.005069160863747063
"Validating and Translating Array Signatures    DESCRIPTION (provided by applicant)   In the area of cancer, microarray analysis is being used to identify specific differences between normal and disease tissues. Such efforts are leading to the identification of small gene sets, or signatures, that can provide key information for classifying cancer types. We propose here a mechanism for translating these discoveries into cost-effective, quantitative assays based on the use of highly multiplexed, universal-primer-driven rtPCR (UP-rtPCR). In this proposal we will demonstrate and validate the combined use of artificial neural network analysis for identification of small gene signatures and UP-rtPCR technology for translating these signatures into high throughput assays for use in research and clinical settings. Success will be measured by the ability of this approach to differentiate 4 types of small, round, blue-cell tumors. This work will be performed in collaboration with Drs. Javed Khan and Gary Fogel.            n/a",Validating and Translating Array Signatures,6836381,R43CA110542,"['RNA', 'artificial intelligence', 'bioengineering /biomedical engineering', 'bioinformatics', 'computational biology', 'gene expression', 'high throughput technology', 'human genetic material tag', 'microarray technology', 'neoplasm /cancer classification /staging', 'neoplasm /cancer diagnosis', 'neoplasm /cancer genetics', 'polymerase chain reaction', 'technology /technique development']",NCI,"ALTHEA TECHNOLOGIES, INC.",R43,2004,99999,0,-0.021930623924490706
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6849505,R01AR042739,"['artificial intelligence', 'bone density', 'bone fracture', 'clinical research', 'computer assisted diagnosis', 'densitometry', 'diagnosis design /evaluation', 'disease /disorder proneness /risk', 'hip', 'human subject', 'information systems', 'limbs', 'mathematical model', 'noninvasive diagnosis', 'osteoporosis', 'photon absorptiometry', 'radiography', 'spine', 'women&apos', 's health']",NIAMS,UNIVERSITY OF CHICAGO,R01,2004,105415,246330700,0.008429482073862253
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,6810083,R21RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R21,2004,178840,22951068,0.0058432115826896735
"Epileptic Seizures in the Neonatal EEG   DESCRIPTION: (provided by applicant) The identification of electrographic            seizures during long-term EEG monitoring in the neonate is currently based upon      visual interpretation of the graphic record, a process that is very                  time-consuming. While significant progress has been made in the automated            detection of seizures in the adult population, relatively little work has been       done in the neonatal area. Therefore, the major objective of this project is         the development of techniques for the reliable automated detection of                electrographic seizures in the neonatal EEG. We propose a multi-stage, hybrid        approach to detection that will employ a combination of signal processing,           pattern recognition, neural networks, and expert rules. Through the successive       stages of the detection process, multichannel neonatal EEG data containing all       types of background activity and artifacts will be analyzed to detect and            classify electrographic seizures. We postulate that the varied types and             morphologies of seizures in the neonatal EEG, as compared to seizures in the         adult EEG, can best be detected and classified using this hybrid approach. We        will test the methods we develop on data recorded from infants in the Clinical       Research Center for Neonatal Seizures, The Methodist Hospital, in Houston,           Texas. We expect that the information we gain from the research will lead to         the development of a practical seizure detection system and further our              long-term goals of reduced expense in the reading and interpretation of              neonatal EEGs, and also facilitate the efficient collection of seizure               parameters for possible use in future research studies.                                                                                                                   n/a",Epileptic Seizures in the Neonatal EEG,6780874,R01NS040577,"['adult human (21+)', 'age difference', 'artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'brain electrical activity', 'computer assisted diagnosis', 'electroencephalography', 'epilepsy', 'human subject', 'newborn human (0-6 weeks)', 'patient monitoring device', 'patient oriented research']",NINDS,UNIVERSITY OF HOUSTON,R01,2004,194888,31980265,-0.01168898367197629
"Use of Microarray Test Data for Toxicogenomic Prediction    DESCRIPTION (provided by applicant):    This project bridges the understanding between physical and chemical principles and genomic/proteomic response by integrating three independent parallel toxicity prediction tools. Each uses computational neural networks (CNNs) and wavelets to rapidly and accurately make pharmaceutical/chemical toxicity predictions. A CNN-based Quantitative Structure-Activity Relationship (QSAR) module makes toxicological predictions based only on structure-activity analyses; a second CNN/wavelet module makes independent toxicogenomic predictions using microarray data; and a third CNN/wavelet module makes toxicogenomic predictions using Massively Parallel Signature Sequencing (MPSS) data. This multi-intelligent, three-module approach provides crosschecks to reduce false positives and false negatives while substantially increasing confidence in predictions relative to current computer-based toxicity prediction techniques. The resulting product could potentially become a primary tool used by (a) human health researchers, b) pharmaceutical companies for screening drugs early during development, c) companies designing/developing new chemicals and chemically treated materials, and (d) government organizations (e.g., military) for mission-related chemical deployments. Public benefits include reduced health and environmental risks (e.g., 4 out of 5 chemicals in use today have inadequate testing); reduced reliance on animal testing; and reduced time and cost required to bring new pharmaceuticals and chemicals into beneficial medical and commercial use.            n/a",Use of Microarray Test Data for Toxicogenomic Prediction,6743871,R41ES013321,"['computational neuroscience', 'computer data analysis', 'evaluation /testing', 'method development', 'microarray technology', 'polymerase chain reaction', 'toxicant screening', 'toxicology']",NIEHS,"YAHSGS, LLC",R41,2004,211770,0,-0.01870061837797888
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6774688,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2004,242058,0,-0.011343975215237792
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6701378,R01AR042739,"['artificial intelligence', 'bone density', 'bone fracture', 'clinical research', 'computer assisted diagnosis', 'densitometry', 'diagnosis design /evaluation', 'disease /disorder proneness /risk', 'hip', 'human subject', 'information systems', 'limbs', 'mathematical model', 'noninvasive diagnosis', 'osteoporosis', 'photon absorptiometry', 'radiography', 'spine', 'women&apos', 's health']",NIAMS,UNIVERSITY OF CHICAGO,R01,2004,297104,246330700,0.008429482073862253
"Integrated SNP, gene expression and proteomic analysis DESCRIPTION (provided by applicant): This project will see development of a software suite (Genetrix) comprised of tools for data management, visualization, machine learning, statistical analysis and biologic interpretation of data from the large-scale biological platforms (gene expression, SNP and proteomics), in conjunction with ancillary clinical, demographic, epidemiological, laboratory and outcome data.       The bioinformatics challenges of the new large-scale biotechnologies and formidable: efficient mining of biologically- and clinically-relevant information requires coordinated contributions from computer scientists, statisticians, mathematicians, biologists and clinicians. The potential benefits however, are also substantial as evidenced by the rapidly growing use of gene expression rnicroarrays. The complexities, and payoffs, will increase dramatically as scientists begin to integrate SNP/proteomic data and gene expression data, and there will be demand for a new generation of software to meet this challenge.       Genetrix will include algorithms to pre-process and normalize raw data to reduce noise, will provide a flexible, interactive and intuitive graphical interface, will support unsupervised and supervised for classification, and for dichotomous or survival outcome prediction, using appropriate statistic methods as well as proven machine learning heuristics, and will have extensive biological information integrated into the software, and available directly from Web resources. n/a","Integrated SNP, gene expression and proteomic analysis",6689832,R43HG002696,"['artificial intelligence', ' computer program /software', ' computer system design /evaluation', ' data management', ' gene expression', ' genetic polymorphism', ' genetic screening', ' human data', ' informatics', ' information systems', ' mathematics', ' proteomics']",NHGRI,EPICENTER SOFTWARE,R43,2003,68876,0,-0.020090936441007193
"Epileptic Seizures in the Neonatal EEG   DESCRIPTION: (provided by applicant) The identification of electrographic            seizures during long-term EEG monitoring in the neonate is currently based upon      visual interpretation of the graphic record, a process that is very                  time-consuming. While significant progress has been made in the automated            detection of seizures in the adult population, relatively little work has been       done in the neonatal area. Therefore, the major objective of this project is         the development of techniques for the reliable automated detection of                electrographic seizures in the neonatal EEG. We propose a multi-stage, hybrid        approach to detection that will employ a combination of signal processing,           pattern recognition, neural networks, and expert rules. Through the successive       stages of the detection process, multichannel neonatal EEG data containing all       types of background activity and artifacts will be analyzed to detect and            classify electrographic seizures. We postulate that the varied types and             morphologies of seizures in the neonatal EEG, as compared to seizures in the         adult EEG, can best be detected and classified using this hybrid approach. We        will test the methods we develop on data recorded from infants in the Clinical       Research Center for Neonatal Seizures, The Methodist Hospital, in Houston,           Texas. We expect that the information we gain from the research will lead to         the development of a practical seizure detection system and further our              long-term goals of reduced expense in the reading and interpretation of              neonatal EEGs, and also facilitate the efficient collection of seizure               parameters for possible use in future research studies.                                                                                                                   n/a",Epileptic Seizures in the Neonatal EEG,6642804,R01NS040577,"['adult human (21+)', ' age difference', ' artificial intelligence', ' bioengineering /biomedical engineering', ' biomedical equipment development', ' brain electrical activity', ' computer assisted diagnosis', ' electroencephalography', ' epilepsy', ' human subject', ' newborn human (0-6 weeks)', ' patient monitoring device', ' patient oriented research']",NINDS,UNIVERSITY OF HOUSTON,R01,2003,193637,31980265,-0.01168898367197629
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6702676,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2003,205127,246330700,0.008429482073862253
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6617187,R01EY014162,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' diagnosis design /evaluation', ' eye disorder diagnosis', ' eye refractometry', ' human data', ' image processing', ' ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2003,241570,0,-0.011343975215237792
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6628097,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2003,297104,246330700,0.008429482073862253
"KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY  The proposed work extends previous research performed by this                                                                     investigator in the field of knowledge-based systems for the analysis of             histopathologic material, mainly neoplastic tissue; and mostly focusing on           adenocarcinoma of the prostate. The present application concerns the creation        of methods for the definition and analysis of novel histopathologic features         predominantly derived from nuclear image data, with the objective of defining        ""prototype identities."" According to the investigator, these are fundamental         complexes of histologic features unique to individual tissue samples, or small       groups of such samples, that should convey useful predictive value for               individual patients. Many of these features are not normally discernable to the      eye, even to the experienced observer. They encompass a large number of primary      and derived nuclear morphometric measures, including what are referred to as         ""weak features,"" that is those that have not in the past shown strong                correlative utility by standard statistical measures. Derived measures include       feature and heterogeneity profiles. These data will form the inputs to a logic       network (""inference network"") designed to perform an identification process and      ultimately to generate the prototype identities.                                                                                                                          n/a",KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6626641,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' human tissue', ' hyperplasia', ' image processing', ' information system analysis', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2003,482862,161094826,-0.02244558054271813
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6558149,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2002,10000,246330700,0.008429482073862253
"Automated PCR Pathogen Detection and Quantification  DESCRIPTION (provided by applicant):  We will develop software for automated pathogen detection and quantification using data from PCR experiments. Automated pathogen detection using data from a PCR experiment requires software to determine whether DNA from the pathogen is present or absent in a sample. We will develop a pattern-matching algorithm to mathematically analyze PCR amplification data. We will optimize the algorithm against a data set of at least 5000 PCR reactions (including a significant set of data gathered during the anthrax attack) to determine its efficacy and limitations. We expect the pathogen detection algorithms to distinguish positives samples from negative samples in more than 98% of the samples, to find inconclusive results in less than 1% of the samples, and to incorrectly classify less than 1% of the samples. We will also develop software to perform automated melting curve analysis of samples that our detection algorithm has determined to be positive or inconclusive. The melting profile of the probes is a property of the assay, and it can be used for secondary confirmation of a pathogen by comparing the profile of the unknown samples to the profile of the assay's positive controls. We will develop algorithms to automatically determine whether the melting profile of the sample and controls match. With melting analysis confirmation, the failure rate of the final detection algorithm should be less than 0.5%.   Automated pathogen quantification requires software to determine the number of copies of a pathogen's DNA in a sample. We will develop discrete dynamical models of PCR for quantification. We will optimize these methods against a large data set of PCR reactions with dilution series. We will systematically determine the features of the models that provide information and the features that can be ignored. We will measure efficacy by comparing computed DNA copy numbers against the known concentrations (as specified by experimenters), and against each other. We will use the most effective model (or models) in the software we produce.   n/a",Automated PCR Pathogen Detection and Quantification,6555484,R43AI052944,"['artificial intelligence', ' bioterrorism /chemical warfare', ' communicable disease diagnosis', ' computer program /software', ' computer system design /evaluation', ' microorganism', ' nucleic acid denaturation', ' nucleic acid quantitation /detection', ' phase change', ' polymerase chain reaction']",NIAID,IDAHO TECHNOLOGY,R43,2002,100000,0,-0.0036857876966906087
"Deployment Framework for Medical Imaging Applications DESCRIPTION (provided by applicant): There are many reasons for the relatively slow proliferation of advanced medical image processing methods but a significant reason is the present paradigm for providing access: most applications are still tied to proprietary software and hardware environments that carry significant up-front costs. The ultimate intent of this work is leverage commodity computing technologies to develop an open, extensible framework for deploying medical image processing applications in the heterogeneous, networked computing environment of today. The framework will provide clinicians and researchers access to state-of-the-art image processing applications regardless of their particular computing platform or locally available computing resources connecting them with federated database resources, with high-end computing resources, or even with their colleagues in a peer-to-peer computing environment. The aims for Phase I of this project are: (1) Demonstrate that the framework provides access to image processing applications to an extent that is largely independent of local computing resources. (2) Demonstrate that the framework is general in that the same components can be reused for deploying a wide variety of medical imaging applications. (3) Demonstrate that the framework is customizable both by third-party developers and by end-users allowing power-users to both create and deploy new applications. Work in Phase II will extend the framework and develop two-demonstration applications--computer aided diagnosis (CAD) for mammography and multimodality image fusion. The ultimate goal is to obtain key partnerships and the private equity investment necessary for commercialization, which will proceed by launching revenue-generating versions of the CAD and image fusion applications. n/a",Deployment Framework for Medical Imaging Applications,6494576,R44EB000149,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computed axial tomography', ' computer assisted diagnosis', ' computer human interaction', ' computer network', ' computer program /software', ' computer system design /evaluation', ' human data', ' image processing', ' mammography', ' mathematics', ' positron emission tomography', ' telemedicine']",NIBIB,"FRONTIER MEDICAL, LLC",R44,2002,143577,0,-0.03537692318046933
"Epileptic Seizures in the Neonatal EEG   DESCRIPTION: (provided by applicant) The identification of electrographic            seizures during long-term EEG monitoring in the neonate is currently based upon      visual interpretation of the graphic record, a process that is very                  time-consuming. While significant progress has been made in the automated            detection of seizures in the adult population, relatively little work has been       done in the neonatal area. Therefore, the major objective of this project is         the development of techniques for the reliable automated detection of                electrographic seizures in the neonatal EEG. We propose a multi-stage, hybrid        approach to detection that will employ a combination of signal processing,           pattern recognition, neural networks, and expert rules. Through the successive       stages of the detection process, multichannel neonatal EEG data containing all       types of background activity and artifacts will be analyzed to detect and            classify electrographic seizures. We postulate that the varied types and             morphologies of seizures in the neonatal EEG, as compared to seizures in the         adult EEG, can best be detected and classified using this hybrid approach. We        will test the methods we develop on data recorded from infants in the Clinical       Research Center for Neonatal Seizures, The Methodist Hospital, in Houston,           Texas. We expect that the information we gain from the research will lead to         the development of a practical seizure detection system and further our              long-term goals of reduced expense in the reading and interpretation of              neonatal EEGs, and also facilitate the efficient collection of seizure               parameters for possible use in future research studies.                                                                                                                   n/a",Epileptic Seizures in the Neonatal EEG,6529026,R01NS040577,"['adult human (21+)', ' age difference', ' artificial intelligence', ' bioengineering /biomedical engineering', ' biomedical equipment development', ' brain electrical activity', ' computer assisted diagnosis', ' electroencephalography', ' epilepsy', ' human subject', ' newborn human (0-6 weeks)', ' patient monitoring device', ' patient oriented research']",NINDS,UNIVERSITY OF HOUSTON,R01,2002,193637,31980265,-0.01168898367197629
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6497411,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2002,297104,246330700,0.008429482073862253
"KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY  The proposed work extends previous research performed by this                                                                     investigator in the field of knowledge-based systems for the analysis of             histopathologic material, mainly neoplastic tissue; and mostly focusing on           adenocarcinoma of the prostate. The present application concerns the creation        of methods for the definition and analysis of novel histopathologic features         predominantly derived from nuclear image data, with the objective of defining        ""prototype identities."" According to the investigator, these are fundamental         complexes of histologic features unique to individual tissue samples, or small       groups of such samples, that should convey useful predictive value for               individual patients. Many of these features are not normally discernable to the      eye, even to the experienced observer. They encompass a large number of primary      and derived nuclear morphometric measures, including what are referred to as         ""weak features,"" that is those that have not in the past shown strong                correlative utility by standard statistical measures. Derived measures include       feature and heterogeneity profiles. These data will form the inputs to a logic       network (""inference network"") designed to perform an identification process and      ultimately to generate the prototype identities.                                                                                                                          n/a",KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6489213,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' human tissue', ' hyperplasia', ' image processing', ' information system analysis', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2002,474210,161094826,-0.02244558054271813
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6487190,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2001,10000,246330700,0.008429482073862253
"Educational Tools for Neuroscience   DESCRIPTION (provided by applicant): SHAI proposes to bring two instructional        technologies together to compliment neuroscience lectures and distance               learning. Specifically we want to embed Computer Simulations of experiments and      the chemical, genetic, and physiological systems that underlie them within an        Intelligent Tutoring System. Simulations are excellent tools for revealing the       structure and dynamics of systems to students. They can also serve as a basis        of interactive experiments where students can ""discover"" the answers to              questions. Intelligent Tutoring Systems (ITS) are an emerging educational            technology based on artificial intelligence research. They play the role of          tutor, in that they guide students with appropriate information or                   demonstrations when they are having difficulty with a lesson. They also              adaptively plan the presentation of new lessons based on evaluations of a            student's past performance and knowledge level. The objective of this phase I        proposal is to develop a prototype of NeuroTutor, a simulation-based ITS to          provide students with individualized instruction in a simulation centered            environment. Steps to reaching this objective include designing a curriculum,        developing instructional, presentations and support, developing appropriate          methods for Student Modeling and Diagnosis, and implementing a limited               prototype.                                                                           PROPOSED COMMERCIAL APPLICATION:  This project has a sizeable commercialization potential.  Medical schools and university  neuroscience courses from a significant market.  Moreover the technologies to be   developed are transferable to other domains in the natural and social sciences, business  and medicine.  The technologies used are appropriate for use in distance learning programs,  and can be used by individuals to educate themselves.                                                                                     n/a",Educational Tools for Neuroscience,6403961,R43MH065842,"['computer assisted instruction', ' computer simulation', ' educational resource design /development', ' interactive multimedia', ' neurobiology', ' science education']",NIMH,"STOTTLER HENKE ASSOCIATES, INC.",R43,2001,100000,0,-0.003956886178538765
"Epileptic Seizures in the Neonatal EEG   DESCRIPTION: (provided by applicant) The identification of electrographic            seizures during long-term EEG monitoring in the neonate is currently based upon      visual interpretation of the graphic record, a process that is very                  time-consuming. While significant progress has been made in the automated            detection of seizures in the adult population, relatively little work has been       done in the neonatal area. Therefore, the major objective of this project is         the development of techniques for the reliable automated detection of                electrographic seizures in the neonatal EEG. We propose a multi-stage, hybrid        approach to detection that will employ a combination of signal processing,           pattern recognition, neural networks, and expert rules. Through the successive       stages of the detection process, multichannel neonatal EEG data containing all       types of background activity and artifacts will be analyzed to detect and            classify electrographic seizures. We postulate that the varied types and             morphologies of seizures in the neonatal EEG, as compared to seizures in the         adult EEG, can best be detected and classified using this hybrid approach. We        will test the methods we develop on data recorded from infants in the Clinical       Research Center for Neonatal Seizures, The Methodist Hospital, in Houston,           Texas. We expect that the information we gain from the research will lead to         the development of a practical seizure detection system and further our              long-term goals of reduced expense in the reading and interpretation of              neonatal EEGs, and also facilitate the efficient collection of seizure               parameters for possible use in future research studies.                                                                                                                   n/a",Epileptic Seizures in the Neonatal EEG,6383999,R01NS040577,"['adult human (21+)', ' age difference', ' artificial intelligence', ' bioengineering /biomedical engineering', ' biomedical equipment development', ' brain electrical activity', ' computer assisted diagnosis', ' electroencephalography', ' epilepsy', ' human subject', ' newborn human (0-6 weeks)', ' patient monitoring device', ' patient oriented research']",NINDS,UNIVERSITY OF HOUSTON,R01,2001,200999,31980265,-0.01168898367197629
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6333620,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2001,297104,246330700,0.008429482073862253
"KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY  The proposed work extends previous research performed by this                                                                     investigator in the field of knowledge-based systems for the analysis of             histopathologic material, mainly neoplastic tissue; and mostly focusing on           adenocarcinoma of the prostate. The present application concerns the creation        of methods for the definition and analysis of novel histopathologic features         predominantly derived from nuclear image data, with the objective of defining        ""prototype identities."" According to the investigator, these are fundamental         complexes of histologic features unique to individual tissue samples, or small       groups of such samples, that should convey useful predictive value for               individual patients. Many of these features are not normally discernable to the      eye, even to the experienced observer. They encompass a large number of primary      and derived nuclear morphometric measures, including what are referred to as         ""weak features,"" that is those that have not in the past shown strong                correlative utility by standard statistical measures. Derived measures include       feature and heterogeneity profiles. These data will form the inputs to a logic       network (""inference network"") designed to perform an identification process and      ultimately to generate the prototype identities.                                                                                                                          n/a",KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6286183,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' human tissue', ' hyperplasia', ' image processing', ' information system analysis', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2001,465813,161094826,-0.02244558054271813
"MODEL BASED INTERPRETATION OF INTRACARDIAC ELECTROGRAMS Catheter ablation is a medical procedure that involves the destruction of        small volumes of heart tissue with radiofrequency energy.  To be                 successful, catheter ablation requires precise localization of the tissue        to be destroyed. To accomplish this in a typical ablation procedure, five        catheters containing a total of 19 electrode pairs are utilized to record        potentials (called electrograms) from spatially distinct locations within        the heart throughout the cardiac cycle. Experienced cardiologists                interpret the electrograms to locate the conduction pathways responsible         for the arrhythmia. The pathways are destroyed by applications of                radiofrequency energy, thus treating the arrhythmia.                                                                                                              Ablation procedures are performed by highly trained and experienced              cardiology sub-specialists yet the massive amount of data produced during        these procedures creates a data overload problem that can impede the             performance of even the best practitioners. This may be evidenced by (1)         overlooking important signal features, (2) misinterpreting the signals,          and (3) misinterpreting catheter locations in the heart, all of which may        lead to increased procedure duration and/or applications of radiofrequency       energy to the wrong part of the heart.                                                                                                                            The purpose of this project is to develop a model-based system for               interpreting intracardiac electrograms in near real-time. The system is          intended to assist physicians in ""making sense"" of the enormous amounts of       data recorded during a cardiac electrophysiology study. New computer             algorithms for reasoning about the time- and space-varying nature of             intracardiac electrograms from underlying causal models of the heart will        be developed. The models can be represented as a graph of nodes connected        by arcs. The nodes represent specific an atomic regions of the heart while       the arcs represent the connections between the regions.                                                                                                           The analytic approach will be a variation of the hypothesize-and-test            paradigm. The control loop will be based on the ""tracking"" concept whereby       models will be tracked as long as the data supports the model. Rule-based        knowledge will be utilized to generate models based on the observed data.        The output of the system will be a series of ladder diagrams describing          the data. In the event that the data admits more than a single explanatory       model, ladder diagrams will be generated for all created models.                                                                                                  This proposal is an extension of the applicant's graduate and post-              doctoral project, which used the same approach to the simpler domain of          the interpretation of the body-surface electrocardiogram. The domain of          this proposal is more complex because it adds reasoning with a more              detailed three dimensional cardiac model to the temporal reasoning               required for previous work. Also, this domain requires the ability to            account for simultaneous activation of the heart at multiple locations,          which was performed at a rudimentary level in the previous work.                                                                                                  This project is important for three reasons: (1) it offers new knowledge-        based algorithms for reasoning about time- and space-varying data, (2) a         comprehensive and extensible model of the cardiac conduction will be             created that incorporates the spatial resolution necessary for                   interpreting intracardiac electrograms, and (3) a software tool such the         one proposed may help clinicians improve the quality of health care.              n/a",MODEL BASED INTERPRETATION OF INTRACARDIAC ELECTROGRAMS,6126011,R29LM006004,"['arrhythmia', ' artificial intelligence', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' electrocardiography', ' heart catheterization', ' heart conduction system', ' human data', ' interactive multimedia', ' mathematical model', ' model design /development']",NLM,SOUTHWEST RESEARCH INSTITUTE,R29,2000,149839,0,-0.008326970110523607
"CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI DESCRIPTION (Adapted from the Investigator's Abstract): Bold steps must be       taken to advance our understanding of the genetic and associated co-             variates affecting the inheritance of complex diseases. To that end, this        proposal will develop improved quantitative methods to detect genetic            factors contributing to increased susceptibility to complex disorders and        implement these methods in software for distribution to the research             community.                                                                                                                                                        The methods will concentrate on the use of classification techniques             applied to allele sharing data and other risk factors which affect the           trait. Allele sharing methods for mapping genes will be extended to              include the classification methods known as latent class models, cluster         analysis, and artificial neural networks, as well as a novel use of              logistic regression Co-variates such as gender, parental diagnosis, or           other concomitant factors will be systematically studied through                 applications to both stimulated and existing data sets. An additional goal       is to determine the optimal distribution of relative pairs (e.g. siblings,       first cousins) for these methods. Of great importance to this proposal is        the development of well-documented, user-friendly software and                   documentation which will be distributed to the scientific community via          the Internet. Existing software developed by the PI will be extensively          expanded for latent class models. Existing cluster analysis software will        be modified and combined for ease of use.                                                                                                                         This proposal consists of theoretical exploration, computer simulation,          data analysis, and software development. First, solutions of theoretical         questions relating to classification techniques will be pursued; second,         adaptation of computer programs to implement the analytic methods, and           investigation into alternative research strategies will be accomplished.         The new strategies will be applied to stimulated data, and finally, to           existing data sets of pedigrees in which a complex trait has been                diagnosed. Findings from this research may contribute to the ability to          locate susceptibility loci in complex traits and to the clarification of         those etiological mechanisms responsible for susceptibility.                      n/a",CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI,6168495,R01AA012239,"['alleles', ' analytical method', ' artificial intelligence', ' biomedical resource', ' computer program /software', ' computer simulation', ' data collection methodology /evaluation', ' disease /disorder classification', ' disease /disorder etiology', ' family genetics', ' gene environment interaction', ' gene expression', ' genetic disorder', ' genetic disorder diagnosis', ' genetic mapping', ' genetic markers', ' genetic susceptibility', ' human data', ' mathematical model', ' model design /development', ' quantitative trait loci', ' statistics /biometry']",NIAAA,WASHINGTON UNIVERSITY,R01,2000,180260,533594881,-0.011557325106968707
"NEW ROC METHODOLOGY TO ASSESS DIAGNOSTIC ACCURACY DESCRIPTION (Adapted from Applicant's Abstract):  Receiver Operating             Characteristic (ROC) analysis is recognized widely as the best way of            measuring and specifying the accuracies of diagnostic procedures, because it     is able to distinguish between actual differences in discrimination              capacity, on one hand, and apparent differences that are due only to             decision-threshold effects, on the other.  Key methodological needs remain       to be satisfied before ROC analysis can address all of the practically           important situations that arise in diagnostic applications, however.  This       project employs signal detection theory and computer simulation to address       several of those needs, by:  (1) refining and continuing distribution of         software developed previously by the applicants for fitting ROC curves and       for testing the statistical significance of differences between ROC curve        estimates; (2) developing and evaluating new algorithms for ROC                  curve-Fitting and statistical testing, based on their recently-developed         ""proper"" binormal model, that should provide more meaningful results in          experimental situations that involve small samples of cases; (3)                 investigating the usefulness of a form of ROC methodology that is based on       mixture distributions in order to rduce the need for diagnostic truth in ROC     experiments; (4) investigating the effect of case-saple difficulty on the        statistical power tests for differences between ROC curves, in order to          determine the optimal difficulty of cases that shouldbe studied on rank          diagnostic systems; and (5) developing methods for training artificial           neural networks (ANNs) to maximize diagnostic accuracy in terms of ROC           analysis and signal detection theory.                                             n/a",NEW ROC METHODOLOGY TO ASSESS DIAGNOSTIC ACCURACY,6181168,R01GM057622,"['artificial intelligence', ' computer assisted diagnosis', ' computer system design /evaluation', ' method development', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R01,2000,218176,246330700,-0.01058130776521924
