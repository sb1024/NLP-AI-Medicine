text,title,id,project_number,terms,administration,organization,mechanism,year,cost,funding,score
"Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics Abstract Support is requested for a Keystone Symposia conference entitled Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics, organized by Drs. Jose M. Lora and Timothy K. Lu. The conference will be held in Breckenridge, Colorado from March 29- April 1, 2019. Synthetic Biology tools and principles have matured tremendously over the last decade and have reached extraordinary levels of sophistication, both in eukaryotic and prokaryotic systems. Synthetic biology as a therapeutic modality is starting to enter multiple clinical studies and has the potential to have a significant impact on medicine across a wide range of diseases (e.g., metabolic, immune-mediated, cancer, and neurologic diseases). This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine. While there are conferences that capture synthetic biology in only a few talks mixed in among other various topics, there is a paucity of conferences focused on synthetic biology as drugs to treat disease. However, due to the rapid pace of fundamental scientific advances along with an expanding number of biotechnology companies and emerging clinical studies with synthetic biology at their core, this conference will be highly relevant for a wide audience of scientists both from academia and industry. In addition, other meetings in this field have a highly technology-driven focus on synthetic biology techniques with relatively little attention given to biological and medical context. Ultimately, this Keystone Symposia conference should inspire researchers from diverse backgrounds to discuss synthetic biology via many new angles. PROJECT NARRATIVE Over the past two decades, tremendous advances have been made in the use of biological parts to engineer systems that can effectively direct living cells for a vast variety of purposes (a.k.a. synthetic biology). Synthetic biology is being used to construct more effective therapies in diseases such as cancer, but there are remaining obstacles to the clinical translation of these therapies. This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine.",Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics,9913772,R13EB029305,"['Academia', 'Address', 'Area', 'Attention', 'Biological', 'Biomedical Research', 'Biotechnology', 'Cells', 'Clinical Research', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Colorado', 'Computers', 'Disease', 'Educational workshop', 'Engineering', 'Future', 'Genetic Engineering', 'Genetic Screening', 'Human', 'Immune', 'Industrialization', 'Industry', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medical', 'Medicine', 'Metabolic', 'Methodology', 'Modality', 'Neurologic', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Preventive', 'Process', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Scientific Advances and Accomplishments', 'Scientist', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Work', 'clinical application', 'clinical practice', 'clinical translation', 'combinatorial', 'design', 'effective therapy', 'graduate student', 'meetings', 'nervous system disorder', 'next generation', 'novel diagnostics', 'posters', 'symposium', 'synthetic biology', 'targeted treatment', 'tool']",NIBIB,KEYSTONE SYMPOSIA,R13,2020,10000,559385,-0.017982028523584846
"Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients Failure to rescue (FTR), a nurse-sensitive national metric of health care quality, refers to death of a hospitalized patient from a treatable complication, and is potentiated by failure to recognize and appropriately respond to early signs of complications. There is a paucity of research examining patient features predictive of FTR complications. Such information could shift the current paradigm of nursing surveillance to earlier recognition, prevention and treatment of FTR complications, thereby saving lives. New-onset venous thromboembolism (VTE), an FTR complication occurring as either a deep vein thrombosis (DVT) or a pulmonary embolism (PE), is the leading cause of preventable hospital death, carrying a high risk of mortality and a national cost burden of $7 billion annually. VTE is a complex disease process involving interactions between clinical risk factors and acquired and/or inherited susceptibilities to thrombosis. Although biomarkers and clinical factors associated with VTE have been identified, clinical manifestations are subtle, presenting gradually over hours to days. Current VTE risk assessment models (RAM), the cornerstone of prevention, have limited utility due to their complexity and lack of reliability, generalizability and external validation. A critical gap in VTE risk modeling research is that while new-onset VTE pathology evolves over the course of hospitalization, no current models incorporate the progressive accrual of dynamic patient data and pattern evolution over time in their modeling approaches. The totality of routinely collected electronic health record (EHR) data is massive in terms of volume, variety, and production at a rapid velocity in real-time. Such big data could be used in machine learning (ML) analytic approaches to process time series clinical data to identify subtle, evolving feature patterns predictive of new-onset VTE and address this gap. This study proposes to assemble a large scale, multi-source, multi-dimensional VTE study dataset, and in tandem, systematically define the EHR data elements associated with a new-onset VTE diagnosis for computable phenotype algorithm development. We will then apply machine learning analytic approaches to baseline and accruing intensive time series clinical data in the curated dataset to develop models identifying data patterns and features predictive of dynamically evolving new-onset VTE in adult hospitalized patients. This proposal aligns with NINR’s strategic vision for nurse scientists to employ new strategies for collecting and analyzing complex big data sets to permit better understanding of the biological underpinnings of health, and improve ways nurses prevent and manage illness. This innovative study and individualized training plan under a strong and well- established team, represents initial steps in the applicant’s research trajectory focused on data science approaches to predict FTR complication risk, and develop, implement and test dynamic RAMs to inform targeted prevention and treatment decisions. Discovering new knowledge informing real-time decision making, nursing surveillance practices and care delivery systems can improve nurse sensitive patient outcomes. PROJECT NARRATIVE Venous thromboembolism (VTE) is the leading cause of preventable hospital death. This study first proposes to develop a reproducible computable phenotype definition for new-onset VTE cohort ascertainment from the electronic health record, and then develop dynamic models for VTE risk assessment through the application of machine learning algorithms to massive electronic health record clinical data repositories. Such models can inform the mechanisms underlying this complex disease and identify subtle pattern changes in a patient’s condition forecasting a VTE event, enabling earlier nurse identification and intervention, and decreasing the development of complications and failure to rescue in hospitalized patients.",Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients,10219195,F31NR018102,"['Address', 'Adult', 'Adverse event', 'Big Data', 'Biological', 'Biological Markers', 'Censuses', 'Cessation of life', 'Clinical', 'Clinical Data', 'Code', 'Cohort Studies', 'Complex', 'Complication', 'Data', 'Data Element', 'Data Science', 'Data Set', 'Decision Making', 'Deep Vein Thrombosis', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Electronic Health Record', 'Event', 'Evolution', 'Failure', 'Frequencies', 'Future', 'Genetic Predisposition to Disease', 'Gold', 'Health', 'Hospitalization', 'Hospitals', 'Hour', 'Human', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Link', 'Logic', 'Machine Learning', 'Manuals', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Pathology', 'Patient Triage', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Prevention', 'Process', 'Production', 'Pulmonary Embolism', 'Quality of Care', 'Readability', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Savings', 'Scientist', 'Selection for Treatments', 'Sensitivity and Specificity', 'Series', 'Signs and Symptoms', 'Source', 'Standardization', 'System', 'Testing', 'Thrombosis', 'Time', 'Training', 'Treatment Failure', 'Validation', 'Venous', 'Vision', 'algorithm development', 'base', 'care delivery', 'classification algorithm', 'clinical data warehouse', 'clinical decision-making', 'clinical risk', 'cohort', 'computable phenotypes', 'cost', 'disease phenotype', 'health care quality', 'high risk', 'improved', 'innovation', 'interest', 'machine learning algorithm', 'mortality risk', 'multidimensional data', 'prevent', 'venous thromboembolism']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F31,2020,17002,570146095,-0.005670731667408527
"Leveraging Artificial Intelligence Solutions to Develop Digital Biomarkers for Precision Trauma Resuscitation PROJECT SUMMARY / ABSTRACT  In the U.S., trauma is the leading cause of death for those 1-45 years old and hemorrhage remains the largest contributing factor to preventable death. Providers must rapidly identify those suffering from hemorrhage to optimize outcome, but internal bleeding remains difficult to diagnose even for experienced clinicians. Little is known on presentation about those suffering from occult hemorrhage and providers must quickly make treatment decisions in these time-pressured, time-sensitive clinical scenarios. This proposal seeks to develop through artificial intelligence, a type of advanced machine learning, prediction algorithms that could be deployed at the bedside of patients to assist clinicians with more timely recognition of hemorrhage. By doing so, we hypothesize that this approach (integrating diverse data sources that have not previously been combined to one another) could identify patterns in our patients that far surpass current capabilities to quickly detect and act on the critical components contributing to outcome. The ability to rapidly pinpoint these patterns and display them to the bedside clinician could allow more timely intervention and precise therapeutic approaches for hemorrhage control.  Beyond the challenges in rapidly identifying bleeding, current treatment of hemorrhage is rudimentary with a standard resuscitation approach for all patients. This reflects attempts to optimize outcome based upon the average treatment effect, rather than being adaptable for unique patient phenotypes. Hemorrhage is believed to initiate a complex chain of events involving crosstalk between the coagulation and inflammatory systems that are hypothesized to play a key role in outcome. Trauma has a known time zero of onset, making it an ideal model to study the immediate pathophysiologic changes associated with hemorrhage. This complex, individual patient biology is believed to explain why those suffering similar injury have differing outcomes. However, to date, these individual characteristics are poorly understood and not factored into initial treatment approaches. Through this proposal, I also seek to define novel digital biomarkers representing patient phenotypes that require precision resuscitation approaches to maximize outcome. Fundamental to reducing hemorrhagic deaths is the need to elucidate a deeper understanding of these mechanistic models of patient states. Strategies that help to identify novel patient phenotypes that could benefit from more tailored treatment pathways may provide important advances in decreasing preventable death.  The net result of this proposal will be a deeper insight into the mechanistic models contributing to evolving patient states following hemorrhage, and identify the key phenotypes or digital biomarkers associated with mortality, complications, and occult hemorrhage. Finding solutions to advance our resuscitation approaches following hemorrhage has potential to decrease complications, save lives, and reduce health care costs. PROJECT NARRATIVE In the US, traumatic injury is the number one cause of death for those under 45 years old and these deaths include many patients dying from the consequences of bleeding. Through leveraging the power of artificial intelligence (a scientific analysis approach similarly used in non-medical fields to help answer questions from large amounts of complex information), an integrated approach to measuring outcome will be developed utilizing biologic, clinical, and electronic medical record (EMR) data. The goal of this project is to lay the ground work for developing early warning detection systems that could identify those at risk of complications early and assist care providers in selecting the best treatment to minimize complications and death from hemorrhage.",Leveraging Artificial Intelligence Solutions to Develop Digital Biomarkers for Precision Trauma Resuscitation,9858108,R01HL149670,"['Abdomen', 'Abdominal Cavity', 'Address', 'Area', 'Artificial Intelligence', 'Bedside Technology', 'Biological', 'Biological Markers', 'Biology', 'Blood', 'Caring', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical', 'Coagulation Process', 'Complex', 'Computational Science', 'Computational algorithm', 'Computerized Medical Record', 'Computers', 'Coupled', 'Coupling', 'Data', 'Data Sources', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early Intervention', 'Event', 'Foundations', 'Goals', 'Health Care Costs', 'Hemorrhage', 'Image', 'Individual', 'Inflammatory', 'Injury', 'Intervention', 'Knowledge', 'Lead', 'Life', 'Liquid substance', 'Machine Learning', 'Mentored Research Scientist Development Award', 'Modeling', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Physiologic Monitoring', 'Physiology', 'Play', 'Provider', 'Resuscitation', 'Risk', 'Stream', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Time', 'Trauma', 'Trauma patient', 'Traumatic injury', 'Triage', 'Ultrasonography', 'United States National Institutes of Health', 'Work', 'advanced analytics', 'base', 'care providers', 'clinical decision-making', 'clinical predictors', 'clinically significant', 'deep learning', 'digital', 'diverse data', 'experience', 'improved', 'individual patient', 'individualized medicine', 'insight', 'mortality', 'multimodal data', 'novel', 'point of care', 'prediction algorithm', 'predictive modeling', 'pressure', 'preventable death', 'profiles in patients', 'relating to nervous system', 'sensor', 'severe injury', 'treatment effect']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,17591,685608202,-0.011465206095323557
"Automated Decision Support System for Traumatic Brain Injury through Image Processing and Machine Learning Approaches Summary: There is an urgent need for an automated decision support system for diagnosis and prognosis of traumatic brain injuries (TBI). TBI is one of the leading causes of death in the modern world, and substantially contributes to disability and impairment. The early detection of TBI and its proper management presents an unfilled need. We therefore aim to supplement clinicians' decisions by developing a decision support system for monitoring and integrating available information of a TBI patient for accurate and quantitative diagnosis and prognosis. This project is the main component of a long-term goal of building a system that creates personalized treatment plans. Specifically, we intend to automatically detect and accurately quantify two critical abnormalities including shift in the brain's middle structure (Aim 1) and intracranial hemorrhage (Aim 2) from computed tomography (CT) head scans. In Aim 1, we develop a model for delineating the spatial shift in brain structure and its predictive power. We employ anatomical landmarks to detect a 3D deformed surface of the brain midline after TBI. Such an approach allows us to quantify the shifted volume, a measurement that is not currently achievable. Additionally, it provides accurate and timely access to conventional midline shift in a 2D CT slice. In Aim 2, we build a model for delineating intracranial hemorrhage and its predictive power. We implement a 3D convolutional neural network model to detect hemorrhagic regions and quantify and localize their volume. Currently, these measurements are inaccurate and not readily available due to the cumbersome manual process; instead a lesion's thickness in a 2D CT slice is used to assess its severity. In both Aim 1 and 2, we automatically calculate conventional and proposed volumetric and locational measurements and compare them to suggest the best diagnostic metric for each abnormality. Finally, in Aim 3, we build an automated pipeline for TBI severity assessment and outcome prediction. To this end, manual CT scan reads will be integrated with patient-level information available from electronic health records to achieve accurate data-driven diagnosis and prognosis. We implement machine learning approaches to build models capable of predicting short and long-term clinical outcomes. Our prediction models will be developed independently of our image processing algorithms. Upon achievement of Aims 1 and 2, automatically calculated information from CT scans will be incorporated into machine learning models. The proposed research is significant, because it is expected to advance TBI care, specifically within the “golden hour"" post-injury. Ultimately, such a system has the potential to reduce delayed and missed diagnosis, thereby reducing TBI morbidity and mortality. Additionally, by preventing permanent and/or secondary injuries, and minimizing the time of hospitalization and rehabilitation, our system will contribute to reducing the annual $76 billion burden of TBI care in the U.S. In addition to innovation in the proposed approaches and their quantitative outputs, we aggregate four existing datasets to incorporate heterogeneity in both phenotypes and therapies, so the resulted model will be generalizable and applicable to real clinical settings. Project Narrative: Traumatic brain injury, frequently referred to as a silent epidemic, involves about 1.7 million people in the U.S, among whom 50,000 will die, while 152,000 will suffer from long-term disability and impairment. The proposed research will automatically diagnose and assess the severity of critical abnormalities from computed tomography head scan, and integrate all available sources of clinical data using data science methods to make a personalized data-driven prognosis. It is expected that this technology will provide caregivers with critical information for early and proper management of injuries, thus saving lives and improving the quality of life of survivors by reducing second/permanent injuries; importantly, this system would enable people living in outlying and deprived regions lacking skilled clinicians benefit from more accurate diagnostics, and as a result, a better care.",Automated Decision Support System for Traumatic Brain Injury through Image Processing and Machine Learning Approaches,9989634,F31LM012946,"['3-Dimensional', 'Achievement', 'Admission activity', 'Algorithms', 'American', 'Anatomy', 'Area', 'Brain', 'Caregivers', 'Caring', 'Cause of Death', 'Characteristics', 'Clinical', 'Clinical Data', 'Computed Tomography Scanners', 'Consumption', 'Data', 'Data Science', 'Data Set', 'Decision Making', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Electronic Health Record', 'Epidemic', 'Glasgow Outcome Scale', 'Goals', 'Head', 'Hemorrhage', 'Heterogeneity', 'Hospitalization', 'Hour', 'Image', 'Impairment', 'Injury', 'Intracranial Hemorrhages', 'Investigation', 'Lead', 'Length', 'Length of Stay', 'Lesion', 'Link', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical center', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Morbidity - disease rate', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Population Heterogeneity', 'Positioning Attribute', 'Process', 'Quality of life', 'Radiology Specialty', 'Reading', 'Rehabilitation therapy', 'Research', 'Resources', 'Savings', 'Scanning', 'Severities', 'Slice', 'Software Tools', 'Source', 'Specific qualifier value', 'Structure', 'Surface', 'Survivors', 'System', 'Technology', 'Testing', 'Thick', 'Time', 'Trauma', 'Traumatic Brain Injury', 'Triage', 'Visual', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'care costs', 'convolutional neural network', 'cost', 'design', 'diagnostic accuracy', 'disability', 'functional outcomes', 'human error', 'image processing', 'improved', 'injured', 'innovation', 'machine learning algorithm', 'machine learning method', 'mortality', 'neural network algorithm', 'outcome forecast', 'outcome prediction', 'personalized medicine', 'predictive modeling', 'prevent', 'three-dimensional modeling', 'treatment planning']",NLM,UNIVERSITY OF MICHIGAN AT ANN ARBOR,F31,2020,38064,641965656,-0.01031837747095482
"CoAI: Cost-Aware Artificial Intelligence for Efficient Prehospital Diagnosis of Trauma Patients Project Summary/Abstract While artificial intelligence (AI) and machine learning (ML) are becoming widely used throughout medicine, the analysis of the cost of an ML model’s predictions has been very limited. For example, an ML model may accurately predict that a trauma patient will have acute traumatic coagulopathy (ATC), a bleeding disorder; however, it may heavily rely on hard-to-measure patient features, like blood pressure or Glasgow Coma Score, to do so. Standard ML techniques do not prioritize timely diagnosis, which is key to minimize death and injury. This idea, which we refer to as cost-aware prediction, is a topic of recent interest in machine learning. However, existing methods have substantial limitations, and their clinical impact has not been demonstrated. This proposal will adopt recent advances in ML and explainable AI to 1) develop improved cost-aware prediction techniques. 2) demonstrate their value using clinical data and 3) integrate them into the electronic medical record. These methods will be applicable in many areas of science and medicine. Aim 1. Develop a novel feature importance-based approach for cost-aware prediction. No existing approach for cost-aware prediction consistently outperforms the others, and each has its own strengths and weaknesses. This proposal uses recent discoveries in machine learning to design a new algorithm, CoAI, with new strengths and fewer weaknesses. CoAI will substantially improve predictive performance, enable analysis on large datasets, and flexibly work with any ML model. Preliminary results show that CoAI can outperform existing methods. A new public benchmark for cost-aware prediction will be created and used to compare CoAI to existing methods, and CoAI will be published as easy-to-use open-source software. Aim 2. Evaluate CoAI’s potential for clinical time savings. CoAI’s ability to predict bleeding disorders will be tested on an unprecedentedly detailed dataset that combines trauma hospital data with surveys of doctors and paramedics. Comparing CoAI to the risk scores used in clinical practice will provide explicit estimates of how much time CoAI can save and how many misdiagnoses it can prevent. In preliminary analysis with trauma registry data, CoAI reduces prediction time and increases accuracy relative to an existing risk score. Aim 3. Incorporate an interactive ML method into the medical record. CoAI will be integrated into the electronic medical record (EMR), using feedback from professional paramedics. Quantitative estimates of time and cost savings and subjective impressions will be gathered from paramedics, and open-ended interviews will be conducted to assess their feelings about interactive machine learning methods like CoAI. These insights will guide future research in interactive machine learning methods, as well as possible clinical work to study CoAI’s impact on decision making in simulated trauma scenarios.  Successful completion of this project will allow faster, more accurate diagnosis of acute illness and advance the state of the art in machine learning and artificial intelligence. Project Narrative Artificial intelligence (AI) is rapidly becoming an integral part of healthcare, from automatic radiology reading and triage to early-warning systems that detect adverse events during surgery. Until recently, AI systems have not been optimized to rely on data that can be gathered quickly or easily. We believe developing AI systems that can intelligently minimize the cost their use imposes on health care providers will lead to more efficient patient risk prediction and diagnosis, and will ultimately save lives.",CoAI: Cost-Aware Artificial Intelligence for Efficient Prehospital Diagnosis of Trauma Patients,9907467,F30HL151074,"['Acute', 'Adopted', 'Adverse event', 'Algorithms', 'Area', 'Artificial Intelligence', 'Awareness', 'Benchmarking', 'Blood Coagulation Disorders', 'Blood Pressure', 'Budgets', 'Categories', 'Cessation of life', 'Clinical', 'Clinical Data', 'Coma', 'Computer software', 'Computerized Medical Record', 'Consensus', 'Cost Analysis', 'Cost Savings', 'Data', 'Data Set', 'Decision Making', 'Decision Trees', 'Diagnosis', 'Evaluation', 'Expert Systems', 'Feedback', 'Feeling', 'Future', 'Health Personnel', 'Healthcare', 'Hospitals', 'Injury', 'Intelligence', 'Interview', 'Learning', 'Literature', 'Machine Learning', 'Measures', 'Medical Records', 'Medicine', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Paramedical Personnel', 'Patient risk', 'Patients', 'Performance', 'Process', 'Psychological reinforcement', 'Publishing', 'Radiology Specialty', 'Reading', 'Research', 'Risk', 'Running', 'Savings', 'Science', 'Surveys', 'System', 'Techniques', 'Testing', 'Time', 'Trauma', 'Trauma patient', 'Triage', 'Work', 'accurate diagnosis', 'base', 'clinical decision-making', 'clinical practice', 'computer science', 'cost', 'data registry', 'design', 'falls', 'flexibility', 'impression', 'improved', 'insight', 'interest', 'large datasets', 'machine learning method', 'medical specialties', 'novel', 'open source', 'patient registry', 'prediction algorithm', 'predictive modeling', 'prevent', 'prototype', 'theories', 'time use', 'usability']",NHLBI,UNIVERSITY OF WASHINGTON,F30,2020,41178,533302350,0.006197120634842419
"Abiotic-Biotic Interfaces for Ophthalmology Symposium ABSTRACT This proposal seeks funding to support a symposium, Abiotic-Biotic Interfaces for Ophthalmology (ABI), which will bring together recognized world experts in clinical, research, vision science, engineering, industrial and pharmaceutical communities as well as junior investigators (i.e., young faculty and those in training) to discuss the current state of ABI, ranging from bioelectronic implantable and wearable devices, to nanoscale scaffolds for stem cell and gene therapies. Given the multidisciplinary nature of this field, it is essential to bring together researchers and clinicians with varying levels of expertise across many domains related to ABI to advance the progress of this novel field, identify challenges of advancement, and develop a strategic action plan to overcome these challenges. The timing to have such a symposium to further the application of implantable and/or wearable bioengineered systems in ophthalmology is now as we focus on precision and personalized medicine and leverage the revolution in deep learning artificial intelligence algorithms. Through symposium talks, sessions, and discussions we will cover the fundamentals and also identify innovative and cutting-edge strategies and methodologies to accelerate the rate of major discoveries and development of novel therapeutics. The specific aims of this symposium are: Specific Aim 1. To bring together both established and junior investigators representing a broad range of disciplines to discuss cutting edge research in this novel field, catalyze the development of cross-disciplinary and translational approaches to advance abiotic-biotic interfaces for ophthalmology, and identify gaps in knowledge and barriers to advancement. We will identify research questions and develop an agenda to guide future research that is consistent with the objectives and interests of NEI. Specific Aim 2. Develop a junior investigator program to motivate a diverse group of students and junior investigators to pursue research careers in vision science and ophthalmologic therapeutic development, who will ultimately submit grant proposals to NEI solicitations and contribute to the scientific literature. Specific Aim 3. Develop a strategic action plan to set priorities for future studies that will encourage inter-agency collaborations (e.g., NEI, NSF, DARPA, etc.). This is critical because often certain engineering tasks are best suited to be supported by NSF or DARPA whereas the biological testing of the engineered systems lends itself to funding from NEI. Hence such inter-agency or cross-agency efforts can help leverage the funding to develop sophisticated abiotic-biotic systems NARRATIVE This meeting is the first on this topic dedicated to the broad use of implantable and/or wearable bioelectronics for ophthalmological applications. It is anticipated that the strategic action plan will significantly impact the field by greatly accelerating the translation of basic science and engineering research findings to stimulate the development of novel treatments and improve clinical practice. Key topics include visual restoration, drug and gene delivery, and sensing intraocular pressure. This meeting will foster training and development of future leaders in this emerging field and promote collaboration and exchange of knowledge and ideas among junior and established investigators.",Abiotic-Biotic Interfaces for Ophthalmology Symposium,10070800,R13EY031988,"['Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Basic Science', 'Biological Testing', 'Biomedical Engineering', 'Cellular Phone', 'Clinical Research', 'Collaborations', 'Communities', 'Computer software', 'Contact Lenses', 'Custom', 'Data', 'Development', 'Devices', 'Diagnosis', 'Discipline', 'Disease', 'Drug Delivery Systems', 'Electronics', 'Engineering', 'Eye', 'Faculty', 'Fostering', 'Funding', 'Future', 'Gene Delivery', 'Glass', 'Industrialization', 'Intraocular lens implant device', 'Knowledge', 'Literature', 'Medicine', 'Methodology', 'Nature', 'Neural Retina', 'Ophthalmology', 'Optics', 'Pharmacologic Substance', 'Physiologic Intraocular Pressure', 'Physiological', 'Research', 'Research Personnel', 'Route', 'Scientific Inquiry', 'Scientist', 'Senior Scientist', 'Students', 'System', 'Time', 'Training', 'Translations', 'Virtual and Augmented reality', 'Visual', 'base', 'career', 'clinical practice', 'deep learning', 'gene therapy', 'implantable device', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'meetings', 'multidisciplinary', 'nanoscale', 'neural network', 'novel', 'novel therapeutics', 'personalized medicine', 'portability', 'precision medicine', 'programs', 'restoration', 'scaffold', 'stem cell therapy', 'symposium', 'therapeutic development', 'translational approach', 'vision science', 'wearable device']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R13,2020,42465,324592664,-0.013833510000426893
"Health Inequality and a Machine Learning-Based Tool for Emergency Department Triage: A Mixed Methods Approach Project Summary There is growing evidence that artificial intelligence (AI) technologies like machine learning (ML) can perpetuate or even worsen social inequalities when deployed into real-world settings. This has been demonstrated in many realms, including policing, the court system, banking, social services provision, and there is growing concern the same is true in medicine. At the same time, there has been an outpouring of new AI-based interventions, with a ten-fold increase in the number of Food and Drug Administration (FDA) approvals for AI-based technologies since 2017. However, little research empirically examines the health equity implications of ML-based clinical decision-making tools. One clinical arena in which ML-based tools are already in use is emergency department (ED) triage, as an alternative to the common Emergency Severity Index (ESI) system. Despite its widespread popularity, evidence has shown that ESI-based triage has many problems, including poor acuity discrimination, with up to 50% of patients triaged at the midpoint of the scale, and is associated with racial inequalities, with African-American patients experiencing longer wait-times and lower triage levels controlling for illness severity. This study will use an ML-based ED triage tool that is already in use at a major academic medical center in the United States to explore the extent to which several factors are associated with inequality in predictive performance across patient racial/ethnic groups. This research will take a mixed methods approach to concurrently examine both human and ‘machine’ elements that affect the triage tool’s final impact on patients. Aim 1 will be a qualitative study involving ethnographic observation and semi-structured interviewing of triage nurses, to develop a conceptual framework for clinicians’ understanding of and interaction with an ML-based tool. Aim 2 will examine ‘label bias’, a type of measurement bias. The Applicant will use synthetic and real electronic health record (EHR) data and simulate different levels of label bias, then examine predictive performance of the triage tool across patient racial/ethnic groups. Aim 3 will explore different methods for imputing missing EHR data. The Applicant will deploy common, simplistic deletion-based methods as well as a promising new ML-based imputation method called an autoencoder, apply the triage model to generate predictions and examine performance across patient racial/ethnic groups. This project is innovative because it contributes to the development of a ‘life cycle’ model of ML-based tools and their health equity implications using a mixed methods approach that integrates both human and computational elements, while also providing a rigorous training plan for the Applicant, an MD-PhD student in epidemiology. This training plan is rigorous, synergistic yet diverse, and will include advanced coursework, dedicated 1-on-1 and group mentoring with experts in the field, attendance at seminars and targeted conferences, integration with clinical education and professional development. This project will be an essential step toward the Applicant’s maturation into an independent physician-scientist. Project Narrative This proposal represents a significant contribution to public health in that it seeks to improve upon current emergency department (ED) triage processes, which are associated with racial inequalities in wait time and triage severity. Specifically, this research will evaluate the performance of an alternative machine learning (ML) -based tool for ED triage across racial/ethnic groups, contributing to a more accurate and equitable triaging of patients and directly improving patient health outcomes. More broadly, this project will enhance the ability of many stakeholders, including data scientists, clinicians, researchers and health policy-makers to evaluate the health equity impacts of any proposed ML-based interventions for health.",Health Inequality and a Machine Learning-Based Tool for Emergency Department Triage: A Mixed Methods Approach,9992378,F31LM013403,"['Academic Medical Centers', 'Accident and Emergency department', 'Address', 'Adjuvant', 'Affect', 'African American', 'Algorithms', 'Artificial Intelligence', 'Characteristics', 'Clinical', 'Collaborations', 'Critiques', 'Data', 'Data Science', 'Data Scientist', 'Data Set', 'Data Sources', 'Decision Making', 'Demographic Factors', 'Development', 'Diagnosis', 'Discrimination', 'Education', 'Electronic Health Record', 'Elements', 'Emergency Medicine', 'Emergency Situation', 'Emergency department visit', 'Empirical Research', 'Epidemiology', 'Ethnic Origin', 'Ethnic group', 'Ethnography', 'Generations', 'Health', 'Health Policy', 'Healthcare', 'Human', 'Inequality', 'Intervention', 'Interview', 'Label', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Measurement', 'Medicine', 'Mentors', 'Methods', 'Minority Groups', 'Modeling', 'Nurses', 'Outcome', 'Patient Triage', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Police', 'Policy Maker', 'Process', 'Provider', 'Public Health', 'Qualitative Methods', 'Race', 'Research', 'Research Personnel', 'Scientist', 'Service provision', 'Severities', 'Severity of illness', 'Social Work', 'Socioeconomic Status', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Treatment outcome', 'Triage', 'United States', 'United States Food and Drug Administration', 'Universities', 'University Hospitals', 'Variant', 'Wait Time', 'Work', 'algorithm training', 'artificial neural network', 'autoencoder', 'base', 'clinical decision-making', 'computer science', 'court', 'deep learning', 'doctoral student', 'ethnic minority population', 'experience', 'health care settings', 'health equity', 'health inequalities', 'improved', 'indexing', 'innovation', 'learning strategy', 'machine learning algorithm', 'racial and ethnic', 'racial bias', 'social', 'social bias', 'social inequality', 'symposium', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,F31,2020,50520,593605914,-0.007798858946207835
"Novel Non-Invasive Coronary Flow Patterning to Predict Early Coronary Microvascular Disease PROJECT SUMMARY  Coronary microvascular disease (CMD) is notoriously difficult to diagnose non-invasively, and current methods of assessing CMD utilize only the peak velocity of the coronary flow pattern. While new imaging techniques such as cardiac magnetic resonance imaging (MRI) have improved the assessment coronary perfusion, there are currently no non-invasive methods that incorporate the coronary flow pattern over a complete cardiac cycle to definitively assess and predict the development of CMD.  Coronary blood flow (CBF) reflects the summation of flow in the coronary microcirculation, and our lab has begun to harness the full CBF pattern under varying flow and disease conditions (e.g. type 2 diabetes) to determine whether it might harbor novel clues leading to the early detection of CMD. Our past and preliminary data indicate an early onset of CMD in both type 2 diabetes mellitus (T2DM) and metabolic syndrome (MetS) that occurs prior to the onset of macrovascular complications and that are characterized by blood flow impairments and alterations in coronary resistance microvessel (CRM) structure, function, and biomechanics. Our data also uncovered innovative correlations between CRM structure/biomechanics and our newly-defined features of the coronary flow pattern, some of which were unique to normal or diabetic mice. We have initially utilized these CBF features, in the presence and absence of other factors such as cardiac function, to develop a mathematical model in collaboration with Drs. Christopher Bartlett and William Ray that to date demonstrated that 6 simple factors can predict a normal vs. diabetic coronary flow pattern with 85% predictive accuracy. Utilizing a multidisciplinary approach, these preliminary data strongly suggest that the coronary flow pattern and physiological modulators of it (e.g. coronary micovascular structure/function/biomechanics, cardiac function, etc), may be useful in directly diagnosing early CMD. Therefore, we hypothesize that dissecting the elements that influence coronary flow patterning will be critical determinants in the direct assessment of coronary microvascular disease using computational modeling. Using our previous publications and our preliminary data as guides, the hypothesis will be tested by addressing two specific aims: 1) Determine whether unique time-dependent CBF patterning in normal and T2DM is dictated by a combination of CRM remodeling and biomechanics, coronary flow pattern dynamics, and cardiac function, permitting the development of a computational model to accurately predict CMD; 2) Determine the reproducibility and robustness of the machine learning model in predicting CMD in a diet-induced obesity/diabetes mouse model. If successful, these studies will be the first to simultaneously examine the influence of CRMs, CBF, and cardiac structure/function on the distinct pattern of coronary flow, and it will determine whether a mathematical model may be useful in establishing a direct assessment of CMD to eventually enable clinicians to conduct a more direct non-invasive diagnosis of CMD for the prevention and/or treatment of heart disease. PROJECT NARRATIVE Coronary Artery Disease (CAD) is the leading cause of heart disease and is associated with hypertension, diabetes, and metabolic syndrome. Coronary Microvascular Disease (CMD) is comprised of structural and functional deficits of the tiny coronary arteries that may be an earlier indicator of disease prior to the onset of overt CAD. The proposed multidisciplinary research aims to develop a computational artificial intelligence model that will accurately predict CMD based on a non-invasive coronary flow pattern obtained by Doppler echocardiography.",Novel Non-Invasive Coronary Flow Patterning to Predict Early Coronary Microvascular Disease,10163298,R21EB026518,"['Address', 'Age', 'Artificial Intelligence', 'Biomechanics', 'Blood flow', 'Cardiac', 'Collaborations', 'Computer Models', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Development', 'Diabetes Mellitus', 'Diabetic mouse', 'Diet', 'Disease', 'Doppler Echocardiography', 'Early Diagnosis', 'Echocardiography', 'Elements', 'Heart Diseases', 'Hyperemia', 'Hypertension', 'Imaging Techniques', 'Impairment', 'Interdisciplinary Study', 'Laboratories', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Metabolic syndrome', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Pattern', 'Physiological', 'Publications', 'Reproducibility', 'Resistance', 'Structure', 'Testing', 'Time', 'base', 'coronary perfusion', 'db/db mouse', 'diabetic', 'disorder prevention', 'early onset', 'experimental study', 'heart function', 'improved', 'innovation', 'interdisciplinary approach', 'macrovascular disease', 'mathematical model', 'noninvasive diagnosis', 'novel', 'pressure', 'prevent']",NIBIB,RESEARCH INST NATIONWIDE CHILDREN'S HOSP,R21,2020,75521,43994644,-0.008426095312759714
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,9979523,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2020,77243,2966077,-0.001405558029681049
"Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records Project Summary/Abstract This project proposes new methods for representing data in electronic health records (EHR) to improve pre- dictive modeling and interpretation of patient outcomes. EHR data offer a promising opportunity for advancing the understanding of how clinical decisions and patient conditions interact over time to inﬂuence patient health. However, EHR data are difﬁcult to use for predictive modeling due to the various data types they contain (con- tinuous, categorical, text, etc.), their longitudinal nature, the high amount of non-random missingness for certain measurements, and other concerns. Furthermore, patient outcomes often have heterogenous causes and re- quire information to be synthesized from several clinical lab measures and patient visits. The core challenge at hand is overcoming the mismatch between data representations in the EHR and the assumptions underly- ing commonly used statistical and machine learning (ML) methods. To this end, this project proposes novel wrapper-based methods for learning informative features from EHR data. Both methods propose specialized operators to handle sequential data, time delays, and variable interactions, and have the capacity to discover underlying clinical rules/decisions that affect patient outcomes. Importantly, both methods also produce archives of possible models that represent the best trade-offs between complexity and accuracy, which assists in model interpretation. These method advances are made possible by encoding a rich set of data operations as nodes in a directed acyclic graph, and optimizing the graph structures using multi-objective optimization. The central hypothesis of this research is that multi-objective optimization can learn effective data representations from the EHR to produce accurate, explanatory models of patient outcomes. Preliminary work has shown that these methods can effectively learn low-order data representations that improve the predictive ability of several state- of-the-art ML methods. This technique demonstrates good scaling properties with high-dimensional biomedical data. Aim 1 (K99) is to develop a multi-objective feature engineering method that pairs with existing ML methods to iteratively improve their performance by constructing new features from the raw data and using feedback from the trained model to guide feature construction. In Aim 2 (K99), this method is applied to form predictive models of the risk of heart disease and heart failure using longitudinal EHR data. The resultant models will be inter- preted with the help of mentors in order to translate predictions into clinical recommendations. For Aim 3 (R00), a second method is proposed that uses a similar framework to optimize existing neural network approaches in order to simplify their structure as much as possible while maintaining accuracy. The goal of Aim 4 (R00) is to identify hospital patients who are at risk of readmission and propose point-of-care strategies to mitigate that risk. This goal is facilitated through the application of the proposed methods to patient data collected from the Hospital of the University of Pennsylvania, the Geisinger Health System, and publicly available EHR databases. Project Narrative  Understanding how clinical decisions interact with a patient's health and environmental over time to inﬂuence patient outcomes is central to the goals of enhancing health, reducing illness and improving quality of life. The proposed research provides important methodological advances for extracting these insights from widely available patient health records.",Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records,9936444,K99LM012926,"['Address', 'Affect', 'Archives', 'Area', 'Automobile Driving', 'Cardiovascular Diseases', 'Categories', 'Clinical', 'Communities', 'Complex', 'Couples', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Disease', 'Electronic Health Record', 'Engineering', 'Feedback', 'Goals', 'Graph', 'Hand', 'Health', 'Health Sciences', 'Health system', 'Heart Diseases', 'Heart failure', 'Hospitals', 'Inpatients', 'Knowledge', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Mentors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nature', 'Outcome', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pennsylvania', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Process', 'Property', 'Protocols documentation', 'Quality of life', 'Recommendation', 'Replacement Arthroplasty', 'Research', 'Research Personnel', 'Risk', 'Structure', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'University Hospitals', 'Visit', 'Work', 'base', 'care costs', 'cluster computing', 'data archive', 'deep learning', 'deep neural network', 'design', 'disease diagnosis', 'disorder subtype', 'heart disease risk', 'high dimensionality', 'hospital readmission', 'improved', 'insight', 'learning strategy', 'machine learning method', 'network architecture', 'neural network', 'novel', 'open source', 'operation', 'patient health information', 'point of care', 'predictive modeling', 'readmission rates', 'readmission risk', 'statistical and machine learning', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,K99,2020,89401,593605914,-0.027539781301773283
"DUET: Rapid dual-mode microscopy for quantitative slide-based renal fibrosis evaluation Contact PD/PI: Fereidouni, Farzad Abstract Kidneys, like other organs, have an inherent capacity to recover from acute injury; however, severe or recurrent injury can result in chronic kidney disease (CKD), the sequelae of which result in 82,000 deaths annually in the US alone. Regardless of the etiology of the initial injury, the common final pathway leading to- end stage renal disease is closely connected to fibrosis(excess or aberrant collagen distribution), one of the most important determinants of renal disease severity and prognosis. Histology is the gold standard for evaluation, typically through the use of histochemical stains such as trichrome and PAS that highlight the presence of collagens and basement membrane, respectively. Nevertheless, these stains are not completely specific, can be technically challenging to perform well and reproducibly, and thus contribute to interobserver variability and a concomitant decrease in diagnostic precision. Moreover, they also require the preparation of extra slides and additional staining procedures, and thus increase cost and can prolong the diagnostic process. We propose to optimize, deploy and test a new kind of microscope, DUET (DUal mode Emission and Transmission microscopy), developed at UC Davis, that will be a low-cost and very rapid solution for detection and digital characterization of the presence and distribution of collagen and other macromolecules, directly from standard formalin-fixed, paraffin-embedded hematoxylin and eosin-stained slides. Specifically, we will finalize the design of the hardware and software components of the instrument itself, validate imaging performance against standard histology and immunohistochemical stains for collagen and other components, and with the assistance of scientists at our partnering institutions (John Hopkins University and University of Buffalo) develop robust tools for analysis and quantitation of fibrosis. DUET instrument hardware will be shared with JHU to ensure that the methods are technically reproducible across multiple sites. The application leverages the expertise across three institutions in optics, biomedical engineering, renal pathology and novel artificial intelligence approaches. The goal of the project is development and validation of DUET, which promises to be a robust, inexpensive and practical approach for the rapid and accurate evaluation of fibrosis, extensible to other renal pathologies, and indeed across other organs systems, with significant positive impact on disease research, clinical practice, and patient outcomes. Page 6 Project Summary/Abstract Project Narrative Evaluation of fibrosis and tubular atrophy from chemically stained kidney biopsies are essential for diagnosis and disease-severity assessment, but current techniques are time-consuming, somewhat non-specific and contribute to interobserver variability and imprecision, affecting care. We propose to optimize and test a new kind of microscope (“DUET”) that can visualize fibrosis (scarring) and other tissue abnormalities directly from standard slides to enable high-quality reproducible fibrosis scoring and evaluation. This multi-site project will also provide a unique opportunity to perform a retrospective study from hundreds of existing H&E slides with associated months to years of clinical follow-up data, and to create a method with demonstrated utility in more than one institution.",DUET: Rapid dual-mode microscopy for quantitative slide-based renal fibrosis evaluation,10261643,R56DK124873,"['Acute', 'Affect', 'Agreement', 'Algorithms', 'Allografting', 'Archives', 'Artificial Intelligence', 'Atrophic', 'Basement membrane', 'Biomedical Engineering', 'Biopsy', 'Buffaloes', 'Caring', 'Cessation of life', 'Chemicals', 'Chronic Kidney Failure', 'Cicatrix', 'Clinical', 'Collagen', 'Computer software', 'Computers', 'Consumption', 'Data', 'Data Science', 'Data Sources', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'End stage renal failure', 'Ensure', 'Etiology', 'Evaluation', 'Fibrillar Collagen', 'Fibrosis', 'Fluorescence', 'Formalin', 'Goals', 'Gold', 'Hematoxylin and Eosin Staining Method', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Injury', 'Institution', 'Interobserver Variability', 'Kidney', 'Kidney Diseases', 'Kidney Failure', 'Laboratories', 'Link', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Natural History', 'Optics', 'Organ', 'Paraffin Embedding', 'Pathologist', 'Pathology', 'Pathway interactions', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Preparation', 'Procedures', 'Process', 'Property', 'Quantitative Microscopy', 'Recurrence', 'Renal Replacement Therapy', 'Renal function', 'Reproducibility', 'Research', 'Retrospective Studies', 'Running', 'Scientist', 'Severity of illness', 'Signal Transduction', 'Sirius Red F3B', 'Site', 'Slide', 'Staging', 'Stains', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissue Embedding', 'Tissues', 'Trichrome stain method', 'Tubular formation', 'Universities', 'Validation', 'base', 'body system', 'clinical care', 'clinical practice', 'clinically significant', 'cohort', 'cost', 'cost effective', 'design', 'digital', 'digital pathology', 'follow-up', 'histological stains', 'instrument', 'instrumentation', 'kidney biopsy', 'kidney fibrosis', 'macromolecule', 'novel', 'outcome forecast', 'personalized diagnostics', 'predict clinical outcome', 'predictive modeling', 'prognostic', 'prognostic value', 'software development', 'stem', 'tool', 'transmission process']",NIDDK,UNIVERSITY OF CALIFORNIA AT DAVIS,R56,2020,91725,254622553,-0.00817755487534103
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,9952803,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2020,92359,570146095,0.0020742913872426882
"Investigating how mechanical connectivity yields developmental robustness ABSTRACT  It is essential for the fate of an organism that key morphogenetic processes occur reproducibly even under tissue damage or environmental perturbations. While much is known about how genetic redundancy and regulation achieves robust development, less is understood about how a tissue mechanically ensures reproducible shape change when perturbed. This project uncovers how populations of physically interacting cells mechanically respond to challenging conditions and modify their collective behavior to still sculpt the correct final shape.  One way for cells to coordinate tissue-scale forces and movements is through direct mechanical connections. In fact, many developing tissues exhibit supracellular networks of actomyosin connections that link hundreds of cells. A large roadblock has been with the challenges of imaging and quantifying subcellular protein at the tissue scale. I adapted a topological smoothing algorithm originally used to trace high-noise filamentous structure of galaxies in the Universe to data to trace high-noise filamentous myosin structure in confocal images. This allowed for the first quantification of a supracellular myosin network across an entire tissue over developmental time. Subsequent analysis adopting techniques from network theory allowed me to identify that the robust folding of the Drosophila fruit fly embryo during ventral furrow formation is mechanically ensured by patterns in the supracellular network spanning its ventral cells.  This newly discovered importance of supracellular networks in coordinating robust shape change highlights the need for a comprehensive understanding of how supracellular networks form, and how their patterns impact the function and robustness of a population of cells. Deciphering robustness at the tissue-level, where the displacement and fate of hundreds of cells must be considered, requires techniques at the interface of cell and developmental biology, biophysics and computer science. The proposed project will take a highly interdisciplinary approach to identify how supracellular network patterns are controlled molecularly, at the cell level, and via tissue constraints. As well, how heterogeneity in tissue-level patterns impacts morphogenetic robustness will be addressed. Together this comprehensive study of the structure and function of supracellular networks will represent a new way to interpret mechanical robustness across diverse developing tissues. As well, a generalized description of mechanical robustness has the potential to uncover new paths to predict and control tissue malformation, which would represent a significant advance for both developmental biology and fetal medicine. PROJECT NARRATIVE The robust establishment of correct shape is essential for proper tissue function. Tissue shape change is a mechanical process that necessitates the coordinated force generation and motion of thousands of cells. Identifying how physically interacting cells mechanically respond to challenging conditions and modify their behavior to still sculpt the correct final shape will shed light onto many congenital disorders that result from morphogenetic dysregulation.",Investigating how mechanical connectivity yields developmental robustness,9950519,K99GM136915,"['Actomyosin', 'Address', 'Adopted', 'Affect', 'Algorithms', 'Architecture', 'Behavior', 'Biophysics', 'Cell Culture Techniques', 'Cell Size', 'Cells', 'Cellular biology', 'Congenital Abnormality', 'Congenital Disorders', 'Data', 'Development', 'Developmental Biology', 'Disease', 'Drosophila genus', 'Early Diagnosis', 'Embryo', 'Engineering', 'Ensure', 'Exhibits', 'Galaxy', 'Generations', 'Genetic', 'Heterogeneity', 'Image', 'In Vitro', 'Light', 'Link', 'Location', 'Machine Learning', 'Maternal-fetal medicine', 'Mechanics', 'Molecular', 'Morphogenesis', 'Morphology', 'Motion', 'Movement', 'Myosin ATPase', 'Neural Tube Defects', 'Noise', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Process', 'Property', 'Proteins', 'Regulation', 'Reproducibility', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Transportation', 'Work', 'cohesion', 'computer science', 'confocal imaging', 'congenital heart disorder', 'fetal', 'fetal medicine', 'fly', 'in vivo', 'interdisciplinary approach', 'malformation', 'mechanical force', 'mechanical properties', 'novel', 'optogenetics', 'theories', 'tissue-level behavior', 'transmission process']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,K99,2020,98836,113554200,-0.023722598617646543
"The Effects of Insurance Benefit Design Innovation on Patient Health Abstract My research in health economics has focused on how information and targeted consumer cost-sharing influences how patients choose providers and the financial savings of incentivizing patients to choose low-price providers. I have also examined the opposite side of the market, how patient use of information and targeted consumer incentives spurs provider price competition. These topics provided the framework for my research as a PhD student in Health Economics at the University of California, Berkeley and I continue to build on these topics while a policy researcher at the RAND Corporation. A natural next step for my career is to expand this line of research but in a more in-depth manner and using more advanced statistical methods. Performing mentored research in these areas will help me successfully make the transition from directed to independent research. The proposed study will help me to (1) contribute to a deeper understanding of patient health effects of an innovative insurance benefit design that is particularly relevant for the aging population; (2) continue to build capabilities working with large medical claims data sets and develop expertise in innovative statistical methods from different disciplines; (3) gain training in aging-related health-services research; (4) expand my exposure to the aging, health economics, and health services research communities; and (5) develop my abilities as an independent health services researcher and build the foundations to successfully compete for R01-level grants.  In this project, I propose to examine whether reference pricing for colonoscopies and pharmaceuticals decreases adherence to recommended colorectal cancer screening and medication therapies among the near- elderly population. I will also examine the impact of reference pricing on patient health outcomes and the aging process. To do so, I intend to apply novel machine-learning statistical methods that have been recently developed in the computer science and statistics fields. As part of this proposal, I have built a formal training plan to develop expertise in these methods. This project will provide me with the flexibility and support to develop a long-term research agenda that focuses on using innovative statistical methods to evaluate the comprehensive effects of consumer cost- sharing programs. Although this study focuses on a single cost- sharing program, reference pricing, the skills I gain through this award will allow me to independently lead evaluations of future benefit designs. The application of machine-learning methods to the setting of reference pricing will provide a framework that I or other researchers can use to evaluate other insurance benefit designs or alternative patient populations. ! Narrative An increasingly popular insurance benefit design, reference pricing, provides targeted financial incentives for consumers to receive care at low-cost providers. While the financial savings from reference pricing programs are well-known, the health impacts have yet to be studied. The proposed career grant will apply machine learning techniques to develop a long-term research agenda focused on understanding the patient health effects of reference pricing for colonoscopies and medication therapies, which are services that are especially relevant for the aging population. !",The Effects of Insurance Benefit Design Innovation on Patient Health,9891936,K01AG061274,"['Accident and Emergency department', 'Adherence', 'Admission activity', 'Adult', 'Advisory Committees', 'Age', 'Aging', 'Area', 'Award', 'Behavior', 'Big Data', 'California', 'Caring', 'Chronic', 'Chronic Disease', 'Colonoscopy', 'Communities', 'Cost Sharing', 'Data Set', 'Deductibles', 'Development', 'Diabetes Mellitus', 'Discipline', 'Elderly', 'Employee', 'Evaluation', 'Exposure to', 'Foundations', 'Future', 'Grant', 'Health', 'Health Benefit', 'Health Care Costs', 'Health Services', 'Health Services Research', 'Healthcare', 'Heart Diseases', 'Heart Rate', 'Heterogeneity', 'Hospitals', 'Incentives', 'Individual', 'Inpatients', 'Insurance', 'Insurance Benefits', 'Insurance Carriers', 'Internal Medicine', 'Journals', 'Lead', 'Link', 'Machine Learning', 'Medical', 'Medicine', 'Mentors', 'Methodology', 'Methods', 'New England', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Policies', 'Population', 'Preventive service', 'Price', 'Process', 'Provider', 'Publications', 'Publishing', 'Quality of life', 'Research', 'Research Methodology', 'Research Personnel', 'Retirement', 'Savings', 'Screening for cancer', 'Services', 'Side', 'Statistical Methods', 'System', 'Techniques', 'Testing', 'Training', 'Universities', 'Work', 'aging population', 'asthmatic patient', 'career', 'colorectal cancer screening', 'comorbidity', 'compliance behavior', 'computer science', 'cost', 'design', 'doctoral student', 'financial incentive', 'flexibility', 'health data', 'health economics', 'health plan', 'improved', 'innovation', 'machine learning method', 'mortality', 'novel', 'patient population', 'programs', 'response', 'semiparametric', 'skills', 'statistical and machine learning', 'statistics', 'treatment effect']",NIA,RAND CORPORATION,K01,2020,130228,37281765,-0.013050578288146228
"Obesity Prevention in Early Life (OPEL): Risk Screening and Targeted Intervention Given the difficulty of reversing obesity once present, there has been increasing focus on the primary prevention of obesity early in the lifecourse. Few attempts have been made to prevent obesity during the first years of life. This proposal summarizes a 5-year program of mentored professional development tied to a multi-method research project intended to improve the identification and potential treatment of infants and toddlers with high risk for obesity. My long-term goal is to prevent obesity by identifying infants at greatest risk and providing for them an effective, family-centered intervention that targets modifiable, life course factors. My central hypothesis, based on my prior research, is that identifying infants at risk for obesity prior to the onset of unhealthy weight gain will enable early intervention. My research plan aims to: (1) create risk prediction models for obesity at age 24 months by linking three existing data systems that combine birth certificate, contextual- level, and health outcome data; (2) test the feasibility of linking these data prospectively to validate the Aim 1 obesity risk prediction models over a 24-month period within a contemporary, clinical cohort; and (3) identify best approaches for family-focused risk communication regarding the prevention of excessive weight gain and obesity in infants and toddlers using a human-centered design approach. Through my career development plan and guidance from my mentors, I will expand upon a foundation in epidemiology and pediatric health services research to develop expertise in machine learning, health informatics, data integration, qualitative methods, human-centered design, and behavior change. Together, the research and educational aims of this proposal will provide me with the necessary groundwork to compete for additional funding as an independent investigator. Specifically, I will seek R03-level grant funding from the NIDDK in year 4 of my K01 award to test the communication strategy developed in Aim 3 and to partner with families to modify an existing behavioral change intervention for use in infancy. By the end of this award, I will be well positioned to apply for funding from the NIDDK to conduct a robust R01-level study that combines the validated prediction models, family- focused communication strategy, and modified intervention to determine whether we can effectively prevent obesity in those infants and toddlers identified as being at the highest risk. This line of research will help ensure that prevention efforts are deployed in an efficient, cost-effective manner and accepted by those who need them. I will accomplish this work under the mentorship of Dr. Aaron E. Carroll, a child health services researcher, and a multidisciplinary team of faculty with expertise machine learning, health informatics, data integration and surveillance, qualitative research, human-centered design approaches, behavior change, and childhood obesity. I am ideally suited to complete this research due to my past research productivity, current mentorship team, open access to health care data, and the established clinical decision support infrastructure at the Indiana University School of Medicine. Project Narrative Increasing evidence suggests that the infancy and toddler periods represent the best opportunity for obesity prevention, but few attempts have been made to prevent obesity during the first years of life. The current proposal seeks to develop practical methods to assess the risk of future obesity in infants and toddlers in the clinical setting, and to partner with families to explore new ways to communicate early life obesity risk in ways that account for their perceptions, concerns and beliefs. This proposal has the promise to lead to targeted, tailored interventions for infants most at-risk for obesity, ensuring that prevention efforts are deployed in an efficient, cost-effective manner and accepted by those who need them.",Obesity Prevention in Early Life (OPEL): Risk Screening and Targeted Intervention,9912764,K01DK114383,"['Address', 'Age', 'Age-Months', 'Award', 'Behavioral', 'Belief', 'Birth Certificates', 'Child', 'Child Health Services', 'Childhood', 'Clinical', 'Communication', 'Communities', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Support Systems', 'Development', 'Development Plans', 'Early Intervention', 'Early identification', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Faculty', 'Family', 'Foundations', 'Funding', 'Future', 'Geographic Information Systems', 'Goals', 'Grant', 'Health Services Research', 'Health Status', 'Human', 'Indiana', 'Infant', 'Information Systems', 'Infrastructure', 'Intervention', 'K-Series Research Career Programs', 'Lead', 'Life', 'Life Cycle Stages', 'Link', 'Machine Learning', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'National Institute of Child Health and Human Development', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Parents', 'Perception', 'Positioning Attribute', 'Pregnancy Histories', 'Prevention', 'Preventive Intervention', 'Primary Prevention', 'Process', 'Productivity', 'Public Health Informatics', 'Publishing', 'Qualitative Methods', 'Qualitative Research', 'Records', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Risk', 'Risk Factors', 'Source', 'Testing', 'Toddler', 'Universities', 'Weight', 'Weight Gain', 'Work', 'approach behavior', 'base', 'behavior change', 'career development', 'clinical decision support', 'cohort', 'cost effective', 'data access', 'data integration', 'data warehouse', 'design', 'epidemiologic data', 'health care availability', 'health data', 'healthy weight', 'high risk', 'improved', 'infancy', 'innovation', 'machine learning method', 'medical schools', 'multidisciplinary', 'obesity in children', 'obesity prevention', 'obesity risk', 'predictive modeling', 'prevent', 'programs', 'prospective', 'risk prediction model', 'screening', 'sociodemographics', 'tool']",NIDDK,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,K01,2020,139614,232986943,-0.009631771070182872
"Great Lakes Node of the Drug Abuse Clinical Trials Network PROJECT SUMMARY  Individuals with substance use disorders are disproportionately experiencing homelessness, poverty, and chronic medical conditions (diabetes and hypertension), which are emerging risk factors for contracting SARS-CoV-2 (official name for the virus that causes COVID-19). Different types of substance use have been associated with development of respiratory infections and progression to severe respiratory failure, also known as Acute Respiratory Distress Syndrome (ARDS). However, complex syndromes like ARDS and behavioral conditions like substance misuse are difficult to identify from the electronic health record. Clinical notes and radiology reports provide a rich source of information that may be used to identify cases of substance misuse and ARDS. This information is routinely recorded during hospital care, and automated, data-driven solutions with natural language processing (NLP) can extract semantics and important risk factors from the unstructured data of clinical notes. The computational methods of NLP derive meaning from clinical notes, from which machine learning can predict risk factors for patients leaving AMA or progressing to respiratory failure. Our team developed tools with >80% sensitivity/specificity to identify individual types of substance misuse using NLP with machine learning (ML). Our single-center models delineated risk factors embedded in the notes (e.g., mental health conditions, socioeconomic indicators). Further, we have developed and externally validated a machine learning tool to identify cases of ARDS with high accuracy for early treatment. We aim to expand this work by pooling data across health systems and build a generalizable and comprehensive classifier that captures multiple types of substance misuse for use in risk stratification and prognostication during the COVID pandemic.  We hypothesize that a single-model NLP substance misuse classifier will provide a standardized, interoperable, and accurate approach for universal analysis of hospitalized patients, and that such information can be used to identify those at risk for disrupted care and those at risk for respiratory failure. We aim to train and test our substance misuse classifiers at Rush in a retrospective dataset of over 60,000 hospitalizations that have been manually screened with the universal screen, AUDIT, and DAST. This Administrative Supplement will allow us to examine the correlations between substances of misuse and risk for COVID-19 as well as development of Acute Respiratory Distress Syndrome (ARDS) in the context of these phenomena. PROJECT NARRATIVE We anticipate that the research proposed will provide novel and critically important tools in artificial intelligence for the detection of substance misuse and COVID-19 from the electronic health record (EHR). Development and validation of a digital classifier would enable a standardized approach to perform screening on all patient encounters on a daily basis in health systems. We will rigorously develop and test the classifier retrospectively on an existing dataset of 60,000 patients. This will serve as the first step towards a comprehensive universal screener that leverages available data in the EHR.",Great Lakes Node of the Drug Abuse Clinical Trials Network,10173503,UG1DA049467,"['2019-nCoV', 'Accident and Emergency department', 'Administrative Supplement', 'Adult', 'Adult Respiratory Distress Syndrome', 'Affect', 'Alcohol or Other Drugs use', 'Artificial Intelligence', 'Behavioral', 'COVID-19', 'COVID-19 pandemic', 'Caring', 'Chronic', 'Cities', 'Clinical', 'Clinical Data', 'Clinical Trials Network', 'Communities', 'Complex', 'Computing Methodologies', 'Consumption', 'Contracts', 'Data', 'Data Pooling', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Disasters', 'Drug abuse', 'Drug usage', 'Early treatment', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Equipment', 'Felis catus', 'General Population', 'Health', 'Health Services', 'Health Status', 'Health system', 'Heart Diseases', 'Home environment', 'Homelessness', 'Hospitalization', 'Hospitals', 'Hurricane', 'Hypertension', 'Illicit Drugs', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Medical', 'Mental Health', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Outcome', 'Overdose', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Poverty', 'Prevention', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resources', 'Respiratory Failure', 'Respiratory Tract Infections', 'Risk', 'Risk Factors', 'Risk stratification', 'Semantics', 'Sensitivity and Specificity', 'Social support', 'Source', 'Standardization', 'Sterility', 'Substance Use Disorder', 'Syndrome', 'Testing', 'Training', 'Treatment outcome', 'Triage', 'Validation', 'Virus', 'Visit', 'Vulnerable Populations', 'Withdrawal', 'Work', 'behavioral health', 'cohort', 'comorbidity', 'coronavirus disease', 'digital', 'drug market', 'experience', 'high risk', 'improved', 'individual patient', 'interoperability', 'machine learning method', 'marijuana use', 'mortality risk', 'non-opioid analgesic', 'novel', 'opioid misuse', 'overdose death', 'pandemic disease', 'predictive modeling', 'prognostic', 'screening', 'social', 'social exclusion', 'social stigma', 'socioeconomics', 'substance misuse', 'success', 'tool', 'transmission process', 'unstructured data']",NIDA,RUSH UNIVERSITY MEDICAL CENTER,UG1,2020,139752,55098220,-0.015464521332258313
"A computer vision toolbox for computational analysis of nonverbal social communication PROJECT SUMMARY We will develop novel computer vision tools to reliably and precisely measure nonverbal social communication through quantifying communicative facial and bodily expressions. Our tools will be designed and developed in order to maximize their usability by non-engineer behavioral scientists, filling the enormous gap between engineering advances and their clinical accessibility. Significance: Social interaction inherently relies on perception and production of coordinated face and body expressions. Indeed, atypical face and body movements are observed in many disorders, impacting social interaction and communication. Traditional systems for quantifying nonverbal communication (e.g., FACS, BAP) require extensive training and coding time. Their tedious coding requirements drastically limits their scalability and reproducibility. While an extensive literature exists on advanced computer vision and machine learning techniques for face and body analysis, there is no well-established method commonly used in mental health community to quantify production of facial and bodily expressions or efficiently capture individual differences in nonverbal communication in general. As a part of this proposal, we will develop a computer vision toolbox including tools that are both highly granular and highly scalable, to allow for measurement of complex social behavior in large and heterogeneous populations. Approach: Our team will develop tools that provide granular metrics of nonverbal social behavior, including localized face and body kinematics, characteristics of elicited expressions, and imitation performance. Our tools will facilitate measurement of social communication both within a person and between people, to allow for assessment of individual social communication cues as well as those that occur within bidirectional social contexts. Preliminary Data: We have developed and applied novel computer vision tools to assess: (1) diversity of mouth motion during conversational speech (effect size d=1.0 in differentiating young adults with and without autism during a brief natural conversation), (2) interpersonal facial coordination (91% accuracy in classifying autism diagnosis in young adults during a brief natural conversation, replicated in an independent child sample), and (3) body action imitation (85% accuracy in classifying autism diagnosis based on body imitation performance). As apart of current proposal, we will develop more generic methods that can be used in normative and clinical samples. Aims. In Aim 1, we will develop tools to automatically quantify fine-grained face movements and their coordination during facial expression production; in Aim 2, we will develop tools to quantify body joint kinematics and their coordination during bodily expression production; in Aim 3, we will demonstrate the tools’ ability to yield dimensional metrics using machine learning. Impact: Our approach is designed for fast and rigorous assessment of nonverbal social communication, providing a scalable solution to measure individual variability, within a dimensional and transdiagnostic framework. PROJECT NARRATIVE This project develops novel tools for measuring nonverbal social communication as manifested through facial and bodily expressions. Using advanced computer vision and machine learning methodologies, we will quantify humans’ communicative social behavior. The results of this project will impact public health by facilitating a rich characterization of normative development of social functioning, providing access to precise phenotypic information for neuroscience and genetics studies, and by measuring subtle individual differences to determine whether some interventions or treatments work better than others.",A computer vision toolbox for computational analysis of nonverbal social communication,9946780,R01MH122599,"['Adolescent', 'Age', 'Area', 'Behavior', 'Behavioral', 'Behavioral Research', 'Behavioral Sciences', 'Characteristics', 'Child', 'Clinical', 'Code', 'Communication', 'Community Health', 'Complex', 'Computational Technique', 'Computer Analysis', 'Computer Vision Systems', 'Cues', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Educational Materials', 'Engineering', 'Expression Profiling', 'Face', 'Facial Expression', 'Genetic study', 'Goals', 'Gold', 'Grain', 'Grant', 'Human', 'Individual', 'Individual Differences', 'Intervention', 'Joints', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Motion', 'Movement', 'Nature', 'Neurologic', 'Neurosciences', 'Nonverbal Communication', 'Oral cavity', 'Participant', 'Perception', 'Performance', 'Persons', 'Phenotype', 'Population Heterogeneity', 'Production', 'Public Health', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Sampling', 'Science', 'Scientist', 'Sex Differences', 'Social Behavior', 'Social Development', 'Social Environment', 'Social Functioning', 'Social Interaction', 'Speech', 'System', 'Techniques', 'Teenagers', 'Time', 'Training', 'Translations', 'Validation', 'Work', 'analysis pipeline', 'autism spectrum disorder', 'automated algorithm', 'base', 'behavior measurement', 'behavioral health', 'clinical application', 'computerized tools', 'design', 'individual variation', 'interest', 'kinematics', 'novel', 'open source', 'sex', 'social', 'social communication', 'tool', 'usability', 'young adult']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2020,150000,178185562,-0.02647878952903767
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,10258317,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data warehouse', 'database design', 'deep learning', 'heuristics', 'improved', 'in silico', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'personalized diagnostics', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2020,157500,254622553,-0.00664237795077796
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9969443,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data standards', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'large datasets', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'public repository', 'repository', 'research and development', 'software development', 'software infrastructure', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2020,158388,758431960,0.0017582756261319292
"Classifying addictions using machine learning analysis of multidimensional data ABSTRACT This Independent Scientist Award will significantly enhance my research capabilities, enabling me to become a leading quantitative investigator in the field of substance use disorders (SUDs). Specifically, it will allow me to increase my knowledge in the areas of SUD phenotypes, treatment and genetics. SUDs are clinically and etiologically heterogeneous and their classification has been difficult. This application reflects my ongoing commitment to developing an innovative and interdisciplinary research program on the classification of SUDs through quantitative analysis of multidimensional data. My extensive training in computational science and prior research on biomedical informatics have provided me with the skills to design, implement and evaluate advanced algorithms and sophisticated analyses to solve challenging problems in classifying SUDs. My ongoing NIDA-funded R01 employs a large (n=~12,000) sample aggregated from multiple genetic studies of cocaine, opioid, and alcohol dependence to develop and evaluate novel statistical models to generate clinical SUD subtypes that are optimized for gene finding. This K02 proposal extends that work to evaluate treatment outcome in refined subgroups of SUD populations using data from treatment studies for cocaine, opioid, alcohol and multiple substance dependence. This project will integrate data from diagnostic behavioral variables and genotypes, as well as biological/neurobiological features of the disorders and repeated measures of treatment outcome. The primary career development goals of this application are to: (1) understand the reliability, validity and functional mechanisms of various phenotyping methods; (2) to continue training in the genetics of addictions; and (3) to gain greater knowledge of different treatment approaches and their efficacy. A solid foundation in these areas will enhance my ability to realize the full potential of the data collected and aggregated from multiple dimensions, and to use the data to design the most clinically useful analysis and generate innovative solutions to diagnostic and predictive challenges in SUD research. Through formal coursework, directed readings, individual tutoring and intensive multidisciplinary collaboration with a diverse team of world-renowned researchers, I will receive training and collect pilot data for future R01 projects by examining (Aim I): whether clinically-defined highly heritable subtypes derived in my current R01 project predict differential treatment response; (Aim II) whether new statistical models that directly combine treatment data with behavioral, biological, and genomic data identify refined subtypes with confirmatory multilevel evidence; and (Aim III) whether there are genetic and social moderators of treatment outcome by subtype. The overall goal of this proposal is to further my independent and multidisciplinary research program in the development of statistical methods for refined classification of SUDs. The K02 award will provide me with the protected time necessary to fully engage in the training activities described that will enhance my knowledge and skills to enable me to make important, novel contributions to the genetics and treatment of SUD. PROJECT NARRATIVE This project will develop novel statistical and quantitative tools to identify homogeneous subtypes of substance use disorders (SUDs) and other complex diseases to enhance gene finding and treatment matching. The proposed project will perform secondary analyses of existing data from treatment studies of cocaine, opioid, alcohol, and mixed SUDs. The proposed novel approaches are expected to advance precision medicine approaches to SUDs by enabling treatment matching and a more refined SUD classification to gene finding.",Classifying addictions using machine learning analysis of multidimensional data,9851853,K02DA043063,"['Adherence', 'Aftercare', 'Alcohol dependence', 'Alcohols', 'Algorithms', 'Area', 'Behavioral', 'Biological', 'Biological Markers', 'Biosensor', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Cocaine', 'Cocaine Dependence', 'Collaborations', 'Combined Modality Therapy', 'Complex', 'Computational Science', 'DSM-IV', 'DSM-V', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic and Statistical Manual of Mental Disorders', 'Dimensions', 'Disease', 'Drug Use Disorder', 'Electroencephalography', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'Heterogeneity', 'Independent Scientist Award', 'Individual', 'Interdisciplinary Study', 'Investigation', 'Joints', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Neurobiology', 'Opiate Addiction', 'Opioid', 'Patients', 'Pattern', 'Pharmacogenetics', 'Pharmacotherapy', 'Phenotype', 'Population', 'Reading', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk Factors', 'Sampling', 'Scientist', 'Signs and Symptoms', 'Solid', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'Substance Addiction', 'Substance Use Disorder', 'Surveys', 'Symptoms', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Work', 'addiction', 'alcohol use disorder', 'biomarker performance', 'biomedical informatics', 'career development', 'cocaine use', 'contingency management', 'design', 'disease classification', 'disorder subtype', 'endophenotype', 'genetic association', 'genomic data', 'imaging genetics', 'improved', 'innovation', 'multidimensional data', 'neural correlate', 'novel', 'novel strategies', 'opioid use disorder', 'outcome prediction', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'secondary analysis', 'skills', 'social', 'tool', 'treatment planning', 'treatment response', 'tutoring']",NIDA,UNIVERSITY OF CONNECTICUT STORRS,K02,2020,161422,36067938,-0.03151929317783194
"Evaluation of multiple medication exposures concurrently using a novel algorithm PROJECT SUMMARY The development of large observational health databases (OHD) has expanded the data available for analysis by pharmacoepidemiology research. The efficiency of these studies may be improved by simultaneously studying the association of multiple medications with a disease of interest. Unfortunately, prior research has demonstrated that it is difficult to distinguish true-positive from false-positive results when studying multiple exposures simultaneously, thus limiting the conclusions drawn from these types of studies and representing a major gap in the field. The objective of this proposal, which is the first step in achieving the applicant's long- term goal of improving the diagnosis and treatment of gastrointestinal diseases using insights derived from OHD, is to evaluate and validate medication class enrichment analysis (MCEA), a novel set-based signal-to- noise enrichment algorithm developed by the applicant to analyze multiple exposures from OHD with high sensitivity and specificity. The central hypothesis of this proposal is that MCEA has equal sensitivity and greater specificity compared to logistic regression, the most widely used analytic method for OHD, for identifying true associations between medications and clinical outcomes. The applicant will complete the following two interrelated specific aims to test the hypothesis: Aim 1 – to calculate the sensitivity and specificity of medication class enrichment analysis (MCEA) and logistic regression (LR) for identifying medication associations with Clostridium difficile infection (CDI) and Aim 2 – to calculate the sensitivity and specificity of MCEA and LR for identifying medication associations with gastrointestinal hemorrhage (GIH). The rationale for these aims is that by reproducing known medication-disease associations without false positives, MCEA can be used to identify novel pharmacologic associations with gastrointestinal diseases in future studies. The expected outcome for the proposed research is that it will demonstrate MCEA as a valid method for pharmacoepidemiology research, opening new research opportunities for the study of multi-exposure OHD. These new research opportunities may lead to more rapid identification of potential pharmacologic causes of emerging diseases and discovery of unanticipated beneficial medication effects, allowing such medications to be repurposed for new indications. To attain the expected outcome, the applicant will complete additional coursework that builds on his Master of Science in Clinical Epidemiology to learn computational biology, machine learning, and econometrics techniques. With the support of this grant and his institution, he will also directly apply these techniques to pharmacoepidemiology applications under the close mentorship of a carefully selected team of faculty with extensive experience in gastroenterology, pharmacoepidemiology, medical informatics, and mentoring prior K-award grant recipients. Through these activities, the applicant will develop the skills necessary to obtain NIH R01-level funding and become a leader in developing novel techniques for application to the epidemiologic study of gastrointestinal diseases. PROJECT NARRATIVE Traditionally, research studying medications associated with diseases are limited to analyzing one medication at a time. This novel proposal will validate medication class enrichment analysis, a recently developed algorithm to study multiple medications simultaneously for association with a disease of interest. Validation of this method will allow researchers to use existing medical databases to more rapidly identify potential medication causes of emerging diseases and identify medications with unanticipated beneficial effects, allowing such medications to be repurposed for new indications.",Evaluation of multiple medication exposures concurrently using a novel algorithm,9853783,K08DK119475,"['Address', 'Algorithms', 'Aminoglycosides', 'Antibiotics', 'Anticoagulants', 'Antiplatelet Drugs', 'Big Data to Knowledge', 'Biological', 'Carbapenems', 'Case-Control Studies', 'Cephalosporins', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Computational Biology', 'Computer software', 'Data', 'Databases', 'Development', 'Development Plans', 'Diagnosis', 'Digestive System Disorders', 'Disease', 'Electronic Health Record', 'Epidemiologic Methods', 'Evaluation', 'Faculty', 'Fluoroquinolones', 'Funding', 'Future', 'Gastroenterology', 'Gastrointestinal Diseases', 'Gastrointestinal Hemorrhage', 'Generations', 'Genomics', 'Goals', 'Grant', 'Health', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'K-Series Research Career Programs', 'Lead', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Master of Science', 'Medical', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Noise', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Penicillins', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacology', 'Research', 'Research Design', 'Research Personnel', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Techniques', 'Testing', 'Time', 'United Kingdom', 'United States National Institutes of Health', 'Validation', 'Veterans', 'analytical method', 'base', 'beta-Lactams', 'career development', 'clinical epidemiology', 'econometrics', 'epidemiology study', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'interest', 'novel', 'research study', 'simulation', 'skills', 'usability']",NIDDK,UNIVERSITY OF PENNSYLVANIA,K08,2020,167900,593605914,-0.0014031538144971178
"Improving cancer family history collection through social networking and artificial intelligence PROJECT SUMMARY  The  activities  proposed  in  this  NCI  K07  application  are  designed  to  advance  the  career  development  and  research  independence  of  Dr.  Brandon  M.  Welch.  Family  health  history  (FHx)  is  one  of  the most important  resources available to help clinicians identify disease risks. By knowing a patient's FHx, clinicians can quickly  identify  disease risks and initiate risk-reducing strategies such as increased screening, prophylactic surgery,  risk-reducing  therapeutics,  and  lifestyle  changes.  FHx  is  also  the  foundation  of  genomic  medicine.  Unfortunately,  the  collection  and  use  of  FHx  by  patients  and  clinicians  is  suboptimal.  To  improve  the  collection and use of FHx among the general population, a better FHx tool that is easier and more convenient  to  use  than  current  FHx  tools  is  needed.  A  new  FHx  web  tool,  called  ​ItRunsInMyFamily.com,​  incorporates  artificial intelligence and social networking to improve user engagement with FHx collection.Utilizing artificial  intelligence  based  chat  entity  can  improve  the  collection  of  FHx  information  by  making  it  easier  and  more  engaging to record FHx information, likewise social networking allows users to tap into the collective wisdom  and  knowledge  of  the  family  to  correct  inaccuracies  and  overcome  gaps  in  FHx  knowledge.  This research  study  will  first  identify  enhancements  to  ​ItRunsInMyFamily.com  ​that  will  further  promote  user  engagement,  with  particular  focus  on  rural and underserved patients (Aim 1). We will then evaluate whether this new FHx  tool can improve collection of cancer FHx in comparison with current FHx tools (Aim 2). Finally, we will assess  the impact of ​ItRunsInMyFamily.com ​on the clinical settings (Aim 3). To implement the research plan, it will be  critical  to  apply,  skills  obtained  through  K  award  learning  objectives,  namely  clinical  oncology  (learning  objective  1),  iterative  patient-centered  design  (learning  objective  2),  and  health  technology  assessment  (learning  objective  3).  To  fulfill  these  learning  objectives,  an  interdisciplinary  group  of  mentors  will  direct  a  comprehensive training plan. The training plan includes coursework, seminars, workshops, journal clubs, and  conferences,  covering clinical oncology, patient engagement, health disparities, user-centered development,  human-computer  interaction,  clinical  research  methodologies,  health  technology  assessment,  and  ethical  conduct  of  research.  The  strong  support  of  an  excellent  team  of  mentors,  and  the  vast  resources  of  the  Medical  University  of  South  Carolina,  create  an  optimal  training  environment.  Collectively,  the  integrated  learning  objectives  and  research  plan  are  critical  to  establishing  a  successful,  innovative,  and  meaningful  academic career focused on developing patient-centric informatics tools for oncology.   PROJECT NARRATIVE Family health history (FHx) is one of the most important risk factors for cancer and the foundation of genomic medicine, but is under-utilized by patients and clinicians. By incorporating artificial intelligence and social networking into a FHx tool, it will lead to greater engagement with FHx collection. This research study will identify and incorporate features that promote user adoption, and evaluate its impact on FHx collection.  ",Improving cancer family history collection through social networking and artificial intelligence,10008996,K07CA211786,"['Adoption', 'Area', 'Artificial Intelligence', 'Breast Cancer Patient', 'Cancer Control', 'Cancer Family', 'Cellular Phone', 'Client satisfaction', 'Clinical', 'Clinical Oncology', 'Clinical Research', 'Collection', 'Data', 'Development', 'Educational workshop', 'Environment', 'Ethics', 'Family', 'Family Cancer History', 'Family health status', 'Foundations', 'General Population', 'Genomic medicine', 'Goals', 'Health Technology', 'Human', 'Internet', 'Journals', 'K-Series Research Career Programs', 'Knowledge', 'Learning', 'Life', 'Malignant Neoplasms', 'Measures', 'Medical', 'Mentors', 'Methodology', 'Minority', 'Oncology', 'Outcome', 'Patient Care', 'Patients', 'Provider', 'Qualitative Research', 'Randomized Controlled Trials', 'Recording of previous events', 'Reporting', 'Research', 'Research Design', 'Research Methodology', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Rural Population', 'Social Network', 'South Carolina', 'Technology Assessment', 'Time', 'Training', 'Underserved Population', 'Universities', 'Workload', 'base', 'cancer care', 'cancer risk', 'career', 'career development', 'clinical care', 'computer human interaction', 'design', 'disorder risk', 'genetic testing', 'health disparity', 'improved', 'informatics tool', 'innovation', 'next generation', 'patient engagement', 'patient oriented', 'personalized care', 'prevent', 'prophylactic', 'research and development', 'research study', 'rural underserved', 'satisfaction', 'screening', 'skills', 'surgical risk', 'symposium', 'therapeutic lifestyle change', 'tool', 'user centered design']",NCI,MEDICAL UNIVERSITY OF SOUTH CAROLINA,K07,2020,173453,136810522,-0.0013209338302383627
"Identifying primary care patients at increased risk of atrial fibrillation for screening interventions Project Summary/Abstract Atrial Fibrillation (AF) increases the risk of stroke 5-fold and accounts for roughly 15% of all strokes in the United States. Many individuals may have undiagnosed AF whose arrhythmia does not prompt evaluation either because of minimal symptoms or brief episodes. Oral anticoagulation (OAC) is highly effective at reducing stroke risk in patients with AF, but is only prescribed to individuals with recognized disease. Identifying subjects with undiagnosed AF is important so they may be treated with OAC and prevent strokes from occurring. This project will help advance our knowledge of screening patients for undiagnosed AF in the primary care setting by identifying patients at high risk of developing AF for targeted clinic and home-based screening strategies. Fundamental questions of who to target and how to implement a screening program in the United States remain unanswered. To address these gaps in knowledge, the principal investigator (PI) proposes a career development program that blends rigorous methodologic and content area training with an innovative research agenda. This plan has three scientific objectives: 1) To identify predictors of AF incidence from electronic health record structured and free-text data, 2) To develop and implement an electronic algorithm that improves upon existing models to identify patients at increased risk for AF in a primary care population, and 3) To implement and evaluate feasibility, acceptability, appropriateness, and usability of a clinic and home-based screening program to identify undiagnosed AF. This project aligns with several objectives of the National Heart, Lung, and Blood Institute’s Strategic Vision by implementing novel diagnostic tools to diagnose AF and prevent strokes, by optimizing clinical and implementation research to improve health and reduce disease, and leveraging emerging opportunities in data science, through the use of natural language processing of text data in the electronic health record, to improve identification of patients at high risk for AF. The long-term goal of this career development award is to establish the PI as an independent researcher with expertise in cardiovascular disease and targeting populations for prevention of cardiovascular disease events. Career development activities include training in biomedical informatics, data mining and risk prediction, survey research design, implementation research, and cardiovascular disease pathophysiology and clinical management through formal coursework, clinical shadowing, as well as mentorship by an exceptionally qualified team of senior scientists. Successful completion of this career development proposal will improve prediction of which patients are at the highest risk of developing AF, and evaluate how to use this risk information to implement an effective screening strategy in primary care. Pilot data from this award will lay the groundwork for a highly competitive application for NIH R01 funding. Project Narrative Atrial fibrillation increases the risk of ischemic stroke and the prevalence is estimated to increase from 5.2 million adults in the United States to more than 12 million by 2030, however, many additional individuals have undiagnosed disease. The proposed research program will significantly advance our understanding of screening for undiagnosed atrial fibrillation, by 1) improving identification of patients at high risk of developing atrial fibrillation, and 2) targeting patients at high risk of developing atrial fibrillation in the primary care setting with an efficient strategy for clinic and home-based screening. This program will significantly increase knowledge of how to overcome the real-world issue of how to effectively and efficiently screen for atrial fibrillation in clinical practice.",Identifying primary care patients at increased risk of atrial fibrillation for screening interventions,9982695,K01HL148506,"['Address', 'Adhesives', 'Adult', 'Affect', 'Algorithms', 'Anticoagulation', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Award', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Research', 'Data', 'Data Science', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Evaluation', 'Event', 'Functional disorder', 'Funding', 'General Hospitals', 'Goals', 'Health', 'Health Technology', 'Home environment', 'Incidence', 'Individual', 'Intervention', 'Ischemic Stroke', 'K-Series Research Career Programs', 'Knowledge', 'Massachusetts', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Oral', 'Patient Care', 'Patients', 'Physicians', 'Population', 'Prevalence', 'Primary Health Care', 'Principal Investigator', 'Program Development', 'Research', 'Research Design', 'Research Personnel', 'Risk', 'Risk Factors', 'Senior Scientist', 'Stroke', 'Stroke prevention', 'Structure', 'Survey Methodology', 'Surveys', 'Symptoms', 'Target Populations', 'Techniques', 'Text', 'Training', 'United States', 'United States National Institutes of Health', 'Vision', 'Work', 'base', 'biomedical informatics', 'cardiovascular disorder prevention', 'career development', 'clinical practice', 'cohort', 'data mining', 'data registry', 'follow-up', 'high risk', 'implementation research', 'implementation science', 'improved', 'innovation', 'mHealth', 'medical specialties', 'mobile computing', 'novel', 'novel diagnostics', 'patient screening', 'population based', 'practice setting', 'primary care setting', 'programs', 'prospective', 'randomized trial', 'risk minimization', 'screening', 'screening program', 'stroke risk', 'structured data', 'tool', 'usability']",NHLBI,MASSACHUSETTS GENERAL HOSPITAL,K01,2020,177770,551214295,-0.06311405962845576
"Leveraging modern analytic approaches to improve diabetes outcomes ABSTRACT Diabetic patients are at risk of developing diabetic heart disease, which may lead to complications in care. Diabetic heart disease patients not only have exceptionally high healthcare expenditures and resource utilization but also are likely to have poor patient outcomes. Studies have shown that early intervention of patients likely to develop diabetic heart disease is cost-effective and yields favorable health outcomes. Therefore, early identiﬁcation of diabetic patients at high-risk of developing diabetic heart disease is crucial to provide effective interventions. The commonly accepted methodology for diabetic heart disease risk prediction is the use of one or more risk scoring systems. However, these risk functions may not generalize well for the diabetes patient and may suffer from poor calibration when used on different cohorts. Moreover, the scoring systems have only been studied on coronary heart disease, one variant of diabetic heart disease while heart failure and diabetic cardiomyopathy remain important, yet insufﬁciently studied problems. Machine learning offers the ability to perform accurate predictive analytics and has been proposed as a way to identify and manage high-risk patients. The primary goal of this proposal is to develop a high-impact and practical risk prediction model that can be used to per- form early identiﬁcation of high-risk diabetic heart disease patients. Given the heterogeneity and complexity of patient information in electronic health records, the model needs to capitalize on the multi-dimensional temporal nature of pa- tient records to extract identifying characteristics of patients that will develop diabetic heart disease. To accomplish this, we will leverage modern machine learning approaches such as tensor factorization and natural language processing to model complex patient characteristics, provide a more complete representation of the patient, and uncover excellent predictors of diabetic heart disease risk. An existing dataset that contains the de-identiﬁed electronic health records of approximately 4,100 diabetic patients from the Emory Healthcare System to compare the predictive power of machine learning-based algorithms with the standard risk scoring systems. These algorithms will be evaluated on calibration, discrimination, and ease of interpretability. The results of this work will provide insight as to how to develop a machine learning–based prediction system that can identify high-risk diabetic heart disease patients. The study may also shed light on the best approaches for fusing data from multiple heterogeneous sources to build a better predictive model and potentially identify novel indicators of high- risk diabetic heart disease factors. Moreover, the work will help inform a larger multi-site study of diabetic heart disease risk prediction and develop methods to generalize the results to a broader spectrum of comorbidities. This project is consistent with the National Library of Medicine's mission to translate biomedical research into practice. PROJECT NARRATIVE Diabetic patients are risk of developing diabetic heart disease which can lead to high healthcare expenditure, high resource utilization, and poor patient outcomes. Existing diabetic risk prediction models can suffer from poor calibration and predictive accuracy. This project develops a novel and practical analytic tool to identify patients at high-risk of developing diabetic heart disease.",Leveraging modern analytic approaches to improve diabetes outcomes,9939687,K01LM012924,"['Adopted', 'Age', 'Algorithms', 'Biomedical Research', 'Calibration', 'Caring', 'Characteristics', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Complex', 'Complications of Diabetes Mellitus', 'Computer software', 'Congestive', 'Coronary', 'Coronary heart disease', 'Data', 'Data Set', 'Data Sources', 'Diabetes Mellitus', 'Diagnosis', 'Discrimination', 'Disease', 'Early Intervention', 'Early identification', 'Economic Burden', 'Elderly', 'Electronic Health Record', 'Epidemic', 'Evaluation', 'Future', 'Goals', 'Health', 'Health Expenditures', 'Healthcare', 'Healthcare Systems', 'Heart Diseases', 'Heart failure', 'Heterogeneity', 'Institution', 'Intervention', 'Lead', 'Light', 'Machine Learning', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Natural Language Processing', 'Nature', 'Outcome', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Predictive Analytics', 'Predictive Value', 'Prevalence', 'Prevention', 'Procedures', 'Records', 'Research Personnel', 'Resources', 'Risk', 'Site', 'Source', 'Structure', 'System', 'Translating', 'United States', 'United States National Library of Medicine', 'Variant', 'Work', 'advanced analytics', 'analytical tool', 'base', 'clinical practice', 'cohort', 'comorbidity', 'computer science', 'cost effective', 'design', 'diabetic', 'diabetic cardiomyopathy', 'diabetic patient', 'effective intervention', 'electronic structure', 'epidemiologic data', 'heart disease risk', 'heterogenous data', 'high risk', 'improved', 'insight', 'novel', 'open source', 'predictive modeling', 'prospective', 'prototype', 'research to practice', 'risk prediction model', 'secondary analysis', 'structured data']",NLM,EMORY UNIVERSITY,K01,2020,179604,507546965,-0.004209328970045529
"Data Science Applications in Communication andSwallowing Disorders PROJECT SUMMARY/ABSTRACT The emergence of electronic medical records, large data registries and readily accessible, protected servers have resulted in an explosion of digital information with potentially high clinical impact for improving patient management and outcomes. Big data warehouses that capture standardized information within the scope of clinical practices allow trained scientists to not only engage in traditional hypothesis testing, but to also uncover new hypotheses, refine existing theories and apply new discoveries to health assessments and interventions. Despite the accessibility and potential impact of these data platforms, clinician scientists have traditionally directed experiments that incorporate relatively small sample sizes and data from individual laboratories, and have not been trained in big data analytics or in engaging appropriate team scientists who work in this space, such as computer scientists, biostatisticians and engineers. The overarching goal of this proposal is to mentor early patient oriented communication and swallowing scientists in big data analytics and to mentor and involve early data science scholars in communication and swallowing research. The PI proposes four primary mentorship and research goals in this K24 renewal proposal: 1. Train a cadre of early stage communication and swallowing scientists in data science methods, including machine learning, by an expert, interdisciplinary, collaborative data science team, 2. Engage and introduce early career data scientists from fields of biostatistics, computer science and engineering to communication and swallowing sciences, and respective data sets, toward facilitating interdisciplinary data science teams and research productivity, 3. Apply novel data science methods to identify phenotypes of swallowing impairment and severity classifications in patient groups known to be at high risk for nutritional and health complications related to dysphagia, and 4. Develop a new area of research in machine learning applications toward improving reliability of physiologic swallowing assessment. The data science theme of the career development and research plan directly align with NIDCD's Strategic Plan for Data Science which lists as its mission: Storing, managing, standardizing and publishing the vast amounts of data produced by biomedical research. NIDCD recognizes that accessible, well-organized, secure and efficiently operated data resources are critical to modern scientific inquiry…and by maximizing the value of data generated through NIH-funded efforts, the pace of biomedical discoveries and medical breakthroughs for better health outcomes can be accelerated. PROJECT NARRATIVE The emergence of electronic health records exposes clinicians to massive amounts of information about the millions of patients who suffer from communication and swallowing disorders, yet most clinical scientists do not have the training or skill to apply meaning to the data toward improving patient care. The overarching mentorship goal of this proposal is to train early, patient-oriented communication and swallowing scientists in big data analyses, including computer machine learning approaches. The research project will uncover distinct patterns and severity of swallowing impairments in large groups of patients with high risk medical diagnoses, which will have high impact on patient care planning and identification of treatments that directly target these impairments for improved outcomes.",Data Science Applications in Communication andSwallowing Disorders,9892671,K24DC012801,"['Algorithms', 'Area', 'Award', 'Barium swallow', 'Big Data', 'Big Data Methods', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Chronic Obstructive Airway Disease', 'Classification', 'Clinical', 'Communication', 'Communication impairment', 'Computer Vision Systems', 'Computerized Medical Record', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Data Scientist', 'Data Set', 'Deglutition', 'Deglutition Disorders', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Economics', 'Electronic Health Record', 'Engineering', 'Explosion', 'Funding', 'Geography', 'Goals', 'Grant', 'Head and Neck Cancer', 'Health', 'Hearing', 'Impairment', 'Individual', 'Instruction', 'Intervention', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Records', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Mission', 'Modernization', 'National Institute on Deafness and Other Communication Disorders', 'Nutritional', 'Outcome', 'Parkinson Disease', 'Patient Care', 'Patient Care Planning', 'Patients', 'Pattern', 'Phenotype', 'Physiological', 'Productivity', 'Publishing', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Sample Size', 'Science', 'Scientific Inquiry', 'Scientist', 'Secure', 'Severities', 'Speech', 'Standardization', 'Statistical Models', 'Strategic Planning', 'Stroke', 'Supervision', 'Techniques', 'Testing', 'Training', 'United States National Institutes of Health', 'Work', 'base', 'career', 'career development', 'clinical practice', 'clinically relevant', 'computer science', 'computerized', 'data registry', 'data resource', 'data warehouse', 'digital', 'experimental study', 'health assessment', 'high risk', 'human error', 'impression', 'improved', 'improved outcome', 'learning algorithm', 'novel', 'patient oriented', 'programs', 'research and development', 'skills', 'statistical learning', 'theories', 'uptake']",NIDCD,NORTHWESTERN UNIVERSITY,K24,2020,183209,66720547,-0.013253673203691986
"Machine learning to inform health services and policy for traumatic brain injury Project Summary Traumatic brain injury (TBI) is recognized as the leading cause of death and disability in all parts of the world and costs the international economy approximately US$400 billion annually, which, given an estimated standardized gross world product of US $73.7 trillion, is a striking 0.5% of the entire annual global output. To address the profound issues related to a drastic increase in emergency department visits and hospitalizations for TBI over the past decades, the United States Congress highlighted injury surveillance as a federal priority. The Centers for Disease Control and Prevention defines surveillance as “use of health-related data that precede diagnosis and signal a sufficient probability of a case or an outbreak to warrant further public health response”. To prevent TBI, it is essential to understand its distribution and patterns, in addition to having strong knowledge of clinical disorders, characteristic, or other definable entity, that differentiates TBI from other clinical populations. A critical barrier to the progress of the NIH-funded program “Comorbidity in traumatic brain injury and risk of all-cause mortality, functional and financial burden: a decade-long population based cohort study” was the presence of complex and multifaceted comorbidities in a patient with TBI before and at the time of the injury, and their links to patients’ frailty, injury circumstances, severity, and outcomes. This resulted in a shift in the research paradigm, and development of a novel data mining approach used in genomics to sequence more than 70,000 clinical diagnosis codes in a TBI population, and compare them to a matched population. The developed data mining approach allowed not only the validation of previously known risk factors of TBI, but also the identification of associations previously unknown, without any preconceived human biases. This project will continue advancement of a non-hypothesis driven scientific approach, which will: (1) Characterize patients with TBI at three different time periods in relation to the TBI event – before, at the time of, and after the injury; (2) Develop individual and population level models to study the transitions between the different time states; and (3) Construct and validate predictive models of susceptibility to TBI events, adverse outcomes, and high healthcare resource use at the individual and population level. Decades- long population-based health administrative data from the publicly-funded healthcare system in Ontario, Canada is ready to be further analysed for clinical and technological advancement, to support human thinking in categorizing personal, clinical, and environmental exposure data preceding TBI. Project Narrative To detect, manage, and prevent traumatic brain injury (TBI), a complex and often lifelong disabling injury, it is essential to understand its distribution and patterns and have a comprehensive knowledge of the clinical disorder, characteristic, or other definable entity that differentiates between and within persons at risk of TBI of varying mechanisms, injury presentation, and its course. This research proposal expands an ongoing NIH-funded project that started to categorize clinical comorbidities and personal and environmental exposure data into clinically meaningful factors that increase the risk of injury and its severity at the population and individual levels. With the support of data mining and big data, this proposed program will advance research methods with a goal-directed learning process and the fields of injury surveillance and precision medicine, covering a variety of interests in public health, brain injury medicine, and behavioural and social sciences.",Machine learning to inform health services and policy for traumatic brain injury,10030705,R01NS117921,"['Acute', 'Address', 'Affect', 'Ambulances', 'Americas', 'Amnesia', 'Area', 'Behavioral', 'Big Data', 'Biological', 'Brain', 'Brain Injuries', 'Brain Pathology', 'Canada', 'Cardiovascular Diseases', 'Categories', 'Cause of Death', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Classification', 'Clinical', 'Code', 'Cohort Studies', 'Complex', 'Congresses', 'Data', 'Decision Support Systems', 'Development', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Elements', 'Emergency department visit', 'Environmental Exposure', 'Evaluation', 'Event', 'Explosion', 'Exposure to', 'Financial Hardship', 'Funding', 'Gender', 'Genomics', 'Goals', 'Head', 'Health', 'Health Policy', 'Health Services', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Human', 'Human Resources', 'Individual', 'Individual Differences', 'Injury', 'International', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investments', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Medicine', 'Metabolic', 'Modeling', 'Musculoskeletal System', 'Natural regeneration', 'Ontario', 'Outcome', 'Output', 'Patients', 'Pattern', 'Persons', 'Phenotype', 'Population', 'Populations at Risk', 'Predisposition', 'Prevalence', 'Preventive', 'Probability', 'Process', 'Province', 'Public Health', 'Recovery', 'Research', 'Research Methodology', 'Research Proposals', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Role', 'Secondary to', 'Services', 'Severities', 'Signal Transduction', 'Standardization', 'Stratification', 'Symptoms', 'System', 'TBI Patients', 'Thinking', 'Time', 'Training', 'Translating', 'Traumatic Brain Injury', 'Unconscious State', 'United States', 'United States National Institutes of Health', 'Validation', 'Woman', 'adverse outcome', 'assault', 'behavioral/social science', 'clinical Diagnosis', 'comorbidity', 'cost', 'data mining', 'disability', 'expectation', 'falls', 'frailty', 'functional outcomes', 'gender disparity', 'improved', 'informatics tool', 'injury recovery', 'injury surveillance', 'interest', 'medically necessary care', 'men', 'mortality', 'mortality risk', 'novel', 'outcome forecast', 'personalized medicine', 'population based', 'precision medicine', 'predictive modeling', 'prevent', 'prognostic', 'programs', 'response', 'sex', 'social', 'survivorship', 'vehicular accident', 'virtual']",NINDS,UNIVERSITY OF TORONTO,R01,2020,185878,2238991,-0.007237835891483731
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10056062,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data warehouse', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,188198,570146095,-0.016632513126952783
"Novel Non-Invasive Coronary Flow Patterning to Predict Early Coronary Microvascular Disease PROJECT SUMMARY  Coronary microvascular disease (CMD) is notoriously difficult to diagnose non-invasively, and current methods of assessing CMD utilize only the peak velocity of the coronary flow pattern. While new imaging techniques such as cardiac magnetic resonance imaging (MRI) have improved the assessment coronary perfusion, there are currently no non-invasive methods that incorporate the coronary flow pattern over a complete cardiac cycle to definitively assess and predict the development of CMD.  Coronary blood flow (CBF) reflects the summation of flow in the coronary microcirculation, and our lab has begun to harness the full CBF pattern under varying flow and disease conditions (e.g. type 2 diabetes) to determine whether it might harbor novel clues leading to the early detection of CMD. Our past and preliminary data indicate an early onset of CMD in both type 2 diabetes mellitus (T2DM) and metabolic syndrome (MetS) that occurs prior to the onset of macrovascular complications and that are characterized by blood flow impairments and alterations in coronary resistance microvessel (CRM) structure, function, and biomechanics. Our data also uncovered innovative correlations between CRM structure/biomechanics and our newly-defined features of the coronary flow pattern, some of which were unique to normal or diabetic mice. We have initially utilized these CBF features, in the presence and absence of other factors such as cardiac function, to develop a mathematical model in collaboration with Drs. Christopher Bartlett and William Ray that to date demonstrated that 6 simple factors can predict a normal vs. diabetic coronary flow pattern with 85% predictive accuracy. Utilizing a multidisciplinary approach, these preliminary data strongly suggest that the coronary flow pattern and physiological modulators of it (e.g. coronary micovascular structure/function/biomechanics, cardiac function, etc), may be useful in directly diagnosing early CMD. Therefore, we hypothesize that dissecting the elements that influence coronary flow patterning will be critical determinants in the direct assessment of coronary microvascular disease using computational modeling. Using our previous publications and our preliminary data as guides, the hypothesis will be tested by addressing two specific aims: 1) Determine whether unique time-dependent CBF patterning in normal and T2DM is dictated by a combination of CRM remodeling and biomechanics, coronary flow pattern dynamics, and cardiac function, permitting the development of a computational model to accurately predict CMD; 2) Determine the reproducibility and robustness of the machine learning model in predicting CMD in a diet-induced obesity/diabetes mouse model. If successful, these studies will be the first to simultaneously examine the influence of CRMs, CBF, and cardiac structure/function on the distinct pattern of coronary flow, and it will determine whether a mathematical model may be useful in establishing a direct assessment of CMD to eventually enable clinicians to conduct a more direct non-invasive diagnosis of CMD for the prevention and/or treatment of heart disease. PROJECT NARRATIVE Coronary Artery Disease (CAD) is the leading cause of heart disease and is associated with hypertension, diabetes, and metabolic syndrome. Coronary Microvascular Disease (CMD) is comprised of structural and functional deficits of the tiny coronary arteries that may be an earlier indicator of disease prior to the onset of overt CAD. The proposed multidisciplinary research aims to develop a computational artificial intelligence model that will accurately predict CMD based on a non-invasive coronary flow pattern obtained by Doppler echocardiography.",Novel Non-Invasive Coronary Flow Patterning to Predict Early Coronary Microvascular Disease,9999582,R21EB026518,"['Address', 'Age', 'Artificial Intelligence', 'Biomechanics', 'Blood flow', 'Cardiac', 'Collaborations', 'Computer Models', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Development', 'Diabetes Mellitus', 'Diabetic mouse', 'Diet', 'Disease', 'Doppler Echocardiography', 'Early Diagnosis', 'Echocardiography', 'Elements', 'Heart Diseases', 'Hyperemia', 'Hypertension', 'Imaging Techniques', 'Impairment', 'Interdisciplinary Study', 'Laboratories', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Metabolic syndrome', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Pattern', 'Physiological', 'Publications', 'Reproducibility', 'Resistance', 'Structure', 'Testing', 'Time', 'base', 'coronary perfusion', 'db/db mouse', 'diabetic', 'disorder prevention', 'early onset', 'experimental study', 'heart function', 'improved', 'innovation', 'interdisciplinary approach', 'macrovascular disease', 'mathematical model', 'noninvasive diagnosis', 'novel', 'pressure', 'prevent']",NIBIB,RESEARCH INST NATIONWIDE CHILDREN'S HOSP,R21,2020,190000,43994644,-0.008426095312759714
"Improving Critical Congenital Heart Disease Screening and Detection of ""Secondary"" Targets PROJECT SUMMARY/ABSTRACT  We propose to develop an automated critical congenital heart disease (CCHD) screening algorithm using machine learning techniques to combine non-invasive measurements of perfusion and oxygenation. Oxygen saturation (SpO2)-based screening is the current standard for CCHD screening, however it fails to detect up to 50% of asymptomatic newborns with CCHD or nearly 900 newborns in the United States annually. The majority of newborns missed by SpO2 screening have defects with aortic obstruction, such as coarctation of the aorta (CoA), that do not result in deoxygenated blood entering circulation. Non-invasive measurements of perfusion such as perfusion index (PIx) and pulse oximetry waveform analysis is expected to improve the detection of newborns with defects such as CoA, which is currently the most commonly missed CCHD by SpO2 screening. Both PIx and pulse oximetry waveforms can be measured non-invasively and with the same equipment used for SpO2 screening.  Members of our team recently showed that the addition of PIx, a non-invasive measurement of pulsatile blood flow, has the potential to improve CCHD detection otherwise missed by SpO2 screening. However, variability of PIx over brief time periods (seconds) and human error in its interpretation limit its clinical capabilities. Additionally, human error in interpretation of the current SpO2 screening algorithm leads to missed diagnoses and inappropriate testing in healthy newborns. Therefore, an automated SpO2-PIx screening algorithm is needed to both simplify the screening process, and improve detection of defects that are missed with SpO2 screening. In order to achieve that, we will identify the optimal PIx waveforms to create a metric that discriminates between newborns with and without CCHD. We will perform pulse oximetry waveform analysis to identify other non-invasive components with discriminatory capacity for newborns with CCHD. Additionally, we will apply supervised machine learning techniques to automate the algorithm interpretation.  The proposed research is significant because an automated SpO2-PIx screening algorithm could save the lives of hundreds of newborns with CCHD that are not diagnosed by SpO2 screening. Additionally, this is innovative as it will be the first automatic interpretation of PIx measurement among newborns with CCHD and merging of automated PIx and SpO2, which will allow for easy implementation at later steps. Through collaboration with four pediatric cardiac centers, we will establish the infrastructure and necessary multidisciplinary relationships to conduct future multicenter studies to evaluate this novel combined SpO2-PIx algorithm on a large scale involving thousands of newborns. Improving the detection of CCHD will require a multidisciplinary approach among all the individuals involved in the care and screening of newborns with CCHD. Additionally, collaboration with engineering and computer sciences will be necessary to automate the SpO2-PIx CCHD screening algorithm. PROJECT NARRATIVE A screening approach that improves earlier detection of critical congenital heart defects with systemic obstruction is critically necessary. This application seeks to develop a screening algorithm that will combine the current screening standard, oxygen saturation, with non-invasive measurements of perfusion. This high risk, high reward approach is fundamentally different from other approaches as it will use machine learning techniques, and is expected to improve the detection of critical congenital heart defects with systemic obstruction and automate the interpretation of the screening results.","Improving Critical Congenital Heart Disease Screening and Detection of ""Secondary"" Targets",10018507,R21HD099239,"['Affect', 'Algorithms', 'American Heart Association', 'Aortic coarctation', 'Automatic Data Processing', 'Blood', 'Blood Circulation', 'Blood Pressure', 'Blood flow', 'California', 'Cardiac', 'Caring', 'Cessation of life', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Congenital Abnormality', 'Critical Congenital Heart Defects', 'Critical Illness', 'Data', 'Defect', 'Detection', 'Diagnosis', 'Early Diagnosis', 'Engineering', 'Equipment', 'Evaluation', 'Funding', 'Future', 'Goals', 'Individual', 'Infant', 'Infrastructure', 'Interruption', 'Intervention', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Morbidity - disease rate', 'Multicenter Studies', 'National Heart, Lung, and Blood Institute', 'National Institute of Child Health and Human Development', 'Neonatal Screening', 'New York', 'Newborn Infant', 'Obstruction', 'Oxygen', 'Perfusion', 'Physiologic pulse', 'Population', 'Process', 'Pulsatile Flow', 'Pulse Oximetry', 'Research', 'Savings', 'Screening Result', 'Screening procedure', 'Sensitivity and Specificity', 'Specificity', 'Techniques', 'Testing', 'Time', 'Ultrasonography', 'United States', 'Upper Extremity', 'Validation', 'aortic arch', 'automated algorithm', 'base', 'clinical application', 'cohort', 'computer science', 'congenital heart disorder', 'high reward', 'high risk', 'human error', 'improved', 'indexing', 'infant death', 'innovation', 'interdisciplinary approach', 'member', 'mortality', 'multidisciplinary', 'neonatal period', 'novel', 'prenatal', 'prevent', 'screening', 'supervised learning']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2020,192195,254622553,-0.044914813728500175
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this ﬁeld typically produce an “all-cause” risk estimate which, even if accurate, overlooks the actionable mechanisms behind admis- sion risk and therefore fails to identify a prescribed response. This limitation may explain the only modest – at best – reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modiﬁable risks and their associated phenotypes driving hospital ad- missions; (2) using natural language processing techniques (NLP) to build classiﬁcation models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to signiﬁcantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close men- toring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a support- ive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identiﬁcation and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,9906933,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Preventive Intervention', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'clinical center', 'clinical encounter', 'comorbidity', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'randomized trial', 'response', 'risk prediction model', 'skills', 'social', 'statistical learning', 'structured data', 'supportive environment', 'trend', 'trial design', 'unstructured data']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2020,194806,593605914,-0.019472450344397478
"Identifying Protective and Risk Factors for Non-infectious Uveitis Project Summary/Abstract Background Information and Relevance: Uveitis is an important cause of permanent vision loss that affects younger patients. Despite the human and economic impact of this disease, the risk factors for non-infectious uveitis are poorly understood. This is in part because epidemiologic studies of uveitis have been limited by insufficient numbers of participants. Newly available large health care claims databases provide an opportunity to increase the ability to detect uveitis risk factors. Hypotheses: Metformin, statin, angiotensin converting enzyme inhibitors are associated with a lower incidence of non-infectious uveitis, while female hormonal therapies are associated with a higher incidence of non-infectious uveitis. Specific Objectives: 1. To determine if non-infectious uveitis incidence varies in relation to putative protective medications, including metformin, statins and angiotensin converting enzyme inhibitors. 2. To determine if non-infectious uveitis incidence varies in relation the modifiable risk factor of female hormonal therapy, including hormonal replacement therapy and hormonal contraceptive therapy. Methods: The Clinformatics™ Data Mart Database contains medical claims on over 60 million beneficiaries from a large insurer in the United States. We will define non-infectious uveitis based on validated diagnosis codes recorded by an eye care provider twice within a 120-day period and exclusion of infectious or surgical causes of uveitis with diagnosis and procedural codes. Potential confounders including demographic (age, gender, race/ethnicity, education level, financial net worth) and clinical (smoking exposure) covariate information will be extracted from the database. Medication exposure will be rigorously captured based on the filling of outpatient prescriptions or coding of clinic-administered therapies. The cohort not exposed to the medication will be matched on age (±3 years), race/ethnicity, sex and date of plan entry and exit (±3 months) to the medication-exposed cohort. Propensity scores for each medication exposure will be estimated using multivariable logistic regression and the rich information on comorbid conditions and treatments available in the database. With multivariable Cox proportional hazards regression, we will calculate the hazard ratios for incident non-infectious uveitis based on exposure to each of the medications listed above. To account for the possibility of systematic differences between individuals with and without the exposures of interest, the Cox proportional hazards models will be weighted by the inverse of the predicted probability of their observed exposures using the propensity scores. We will interpret the results taking into the account the multiple comparisons being tested. Implications: The well-powered, rigorous analyses proposed here offer a unique opportunity to identify novel modifiable protective and risk factors for non-infectious uveitis, guide practice patterns for discontinuation of medications that increase uveitis risk, and inform the development of clinical trials for medications for secondary uveitis prevention. Project Narrative Uveitis is an eye disease that causes blindness disproportionately in young and working-age Americans, and we do not completely understand the risk factors for developing uveitis. Our study aims to uncover the risk factors for uveitis, including whether some medications may play a role in uveitis risk. The insights gained could improve the treatment and prevention of uveitis recurrence.",Identifying Protective and Risk Factors for Non-infectious Uveitis,9850573,R21EY029851,"['Adrenal Cortex Hormones', 'Affect', 'Age', 'American', 'Angiotensin-Converting Enzyme Inhibitors', 'Animals', 'Benefits and Risks', 'Blindness', 'Caring', 'Characteristics', 'Chronic', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Cohort Studies', 'Cox Proportional Hazards Models', 'Data', 'Data Mart', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease remission', 'Drug usage', 'Educational Background', 'Enrollment', 'Ethnic Origin', 'Exclusion', 'Exposure to', 'Eye', 'Eye diseases', 'Female', 'Gender', 'Health', 'Healthcare', 'Hormonal', 'Human', 'Immune', 'Immunosuppression', 'Incidence', 'Individual', 'Inflammation', 'Inflammatory', 'Insurance Carriers', 'Investigation', 'Logistic Regressions', 'Measurement', 'Mediating', 'Medical', 'Metformin', 'Methods', 'Modification', 'Nature', 'Office Visits', 'Operative Surgical Procedures', 'Outpatients', 'Panuveitis', 'Participant', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Play', 'Population Study', 'Prevention', 'Prevention strategy', 'Privatization', 'Probability', 'Procedures', 'Race', 'Recurrence', 'Relapse', 'Replacement Therapy', 'Research', 'Risk', 'Risk Factors', 'Role', 'Secondary Prevention', 'Smoking', 'Societies', 'Source', 'Testing', 'Time', 'United Kingdom', 'United States', 'Uveitis', 'Weight', 'age related', 'base', 'beneficiary', 'care providers', 'clinical development', 'cohort', 'comorbidity', 'cost', 'cost effective', 'disorder risk', 'economic impact', 'epidemiology study', 'hazard', 'high risk population', 'hormonal contraception', 'hormone therapy', 'improved', 'insight', 'interest', 'modifiable risk', 'novel', 'patient population', 'prevent', 'prevention clinical trial', 'protective factors', 'sex']",NEI,MASSACHUSETTS EYE AND EAR INFIRMARY,R21,2020,205802,32639530,-0.013052316396362408
"Identifying False HPV-Vaccine Information and Modeling Its Impact on Risk Perceptions PROJECT SUMMARY/ABSTRACT Human papillomavirus (HPV) is the most common sexually transmitted infection in the United States, with over 30,000 new HPV-related-cancers are diagnosed annually. Although HPV vaccines have been approved by the Food and Drug Administration (FDA) since 2006 and recommended for routine vaccination for school-age girls and boys, vaccination rates remain low. One reason that has contributed to low vaccination rates is incorrect “risk perceptions” around HPV vaccines such as the high perceived risks of adverse events or side effects from the HPV vaccine. Incorrect risk perceptions are often rooted in the false information about HPV vaccines that people are exposed to in their daily life, including social media. The impact of social media on health information is substantial. Negative social-media HPV-vaccine information has been found to have an association with low vaccination coverage. Given the negative consequences of false information, there is a need to develop a robust and scalable way to detect false HPV-vaccine information before it propagates and negatively impacts behavior. The overarching goal of the proposed research is to build a model to identify false HPV-vaccine information on Twitter, demonstrate its impact on individual risk perceptions and measure its underlying mechanisms on risk perception formation. We propose a novel approach to leverage machine learning, natural language processing, network analysis, crowdsourcing/expert data annotation, psycholinguistic analysis and statistical modeling to investigate the false HPV-vaccine information collectively (in terms of its detection and propagation patterns) and individually (in terms of its impact and underlying cognitive mechanisms). Our study will first build a computational model to detect false HPV-vaccine information on Twitter. By modeling the domain-specific HPV- vaccine related text content, information-veracity related linguistic features, individual and collective user behaviors, and dissemination patterns, our model will be able to detect false HPV-vaccine information before it gets verified and spreads widely. We will then investigate the impact of false HPV-vaccine information on risk perceptions around HPV vaccination operationalized by natural language processing methods and a developed HPV-vaccine Risk Lexicon. We will further conduct psycholinguistic analysis on the false HPV-vaccine information and use statistical modeling to uncover the underlying mechanism of risk perceptions. Our study will make a critical and timely contribution to identifying the false HPV-vaccine information and its impact, which has the potential to be applied to other health topics. This proposed project will also address the National Cancer Institute priorities in promoting HPV vaccines and combating misinformation in cancer prevention and control. PROJECT NARRATIVE The uptake of human papillomavirus (HPV) vaccine remains low in part because of incorrect perceptions of vaccination risks, which has been linked to the spread of false HPV-vaccine information. The proposed study seeks to build a computational model to detect false HPV-vaccine information on social media (Twitter) and determine its impact on risk perceptions of the HPV vaccine. The findings will provide important contributions to understand the impact of false health information on HPV vaccination behavior and could be expanded to other health topics.",Identifying False HPV-Vaccine Information and Modeling Its Impact on Risk Perceptions,9954963,R21CA237483,"['Address', 'Affect', 'Age', 'Anxiety', 'Attitude', 'Behavior', 'Cancer Control', 'Categories', 'Cognitive', 'Communication', 'Comprehension', 'Computer Models', 'Data', 'Decision Making', 'Detection', 'Diagnosis', 'Electronic cigarette', 'Event', 'Exposure to', 'Fright', 'Goals', 'Harm Reduction', 'Health', 'Human Papilloma Virus Vaccination', 'Human Papilloma Virus Vaccine', 'Human Papilloma Virus-Related Malignant Neoplasm', 'Human Papillomavirus', 'Human papilloma virus infection', 'Individual', 'Information Dissemination', 'Knowledge', 'Lesion', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methods', 'Misinformation', 'Modeling', 'National Cancer Institute', 'Natural Language Processing', 'Neural Network Simulation', 'Participant', 'Pathway Analysis', 'Patients', 'Pattern', 'Perception', 'Plant Roots', 'Politics', 'Property', 'Psycholinguistics', 'Psychological reinforcement', 'Research', 'Risk', 'Safety', 'School-Age Population', 'Semantics', 'Sexually Transmitted Diseases', 'Source', 'Statistical Models', 'Text', 'Time', 'Twitter', 'United States', 'United States Food and Drug Administration', 'Vaccination', 'Vaccines', 'Work', 'adverse event risk', 'boys', 'cancer diagnosis', 'cancer prevention', 'combat', 'crowdsourcing', 'deep learning', 'girls', 'high risk', 'information model', 'information processing', 'multilevel analysis', 'news', 'novel strategies', 'premalignant', 'prevent', 'recurrent neural network', 'response', 'risk perception', 'side effect', 'social media', 'theories', 'uptake']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,211659,76545728,-0.0050019736086428105
"Real time optimization of electron-based fragmentation for middle and top-down proteomics in mass spectrometry The identification and quantification of biological macromolecules remains challenging despite major advances in the speed, resolution and mass accuracy of modern mass spectrometers. A key weakness with current instrumentation lies in the methods used to induce fragmentation. The reliance in particular on collision-induced dissociation (CID) has limited such analyses to bottom-up workflows of trypsin-digested peptides of 10-30 residues. At e-MSion, we have developed an efficient electron-fragmentation technology called ExD for large proteins and are now co-marketed our ExD Option with Agilent, and soon will be with Thermo and Waters instruments. What has really captured the interest of the biopharma and top-down communities in the past year is the exceptional sequence coverage of native proteins we obtain with the same ExD cell. The resulting spectra are less congested than those obtained with currently available ETD/UVPD/CID fragmentation methodologies. We have shown that our technology works faster and gives cleaner spectra with more complete dissociation with larger macromolecular protein complexes than has ever been possible before, while still preserving labile post translational modifications. In addition, fragmentation with higher energy electrons can be used to provide complementary data to improve protein and glycan identification. The challenge now has become how to optimally collect and process these data to maximize the utility of ExD fragmentation. Last summer, Xilinx released its Versal Adaptive Compute Acceleration Platform (ACAP), a massively parallel processor with 50 billion transistors targeted to transform digital signal processing, handling of big data and artificial intelligence. This ACAP technology has already accelerated Illumina DNA sequence assembly by 90-fold. Our feasibility question asks how to effectively harness this new highly parallelized technology to preprocess complex top-down mass spectra on- the-fly. This will allow us to actively optimize data acquisition by enabling adaptive operation of the ExD cell and mass spectrometer. The objective is to maximize both fragmentation and dissociation of native proteins, enabling faster and comprehensive characterization of challenging proteoforms important to the biopharmaceutical industry and biomedical researchers.  Success will offer an extremely fast, cost-effective solution to characterize complexes of macromolecules under native conditions with increased accuracy, speed, and fewer misidentifications. Our ExD technology with the Versal ACAP can be both retrofitted into existing mass spectrometers as well as being available in new generations of mass spectrometers at a price below other less-effective alternative fragmentation technologies like ETD and UVPD. Thus, it will provide new abilities for many NIH investigators to advance basic research, probe disease mechanisms and permit more sophisticated searches for both diagnostic and therapeutic biomarkers. Even with all of the scientific progress made to date, the complexity of disease-affected tissues still challenges our ability to probe what makes people sick. The goal of this Phase I SBIR project is to develop a powerful computer technology to aid in characterizing biological molecules that will improve the diagnosis and treatment of diseases ranging from arthritis, cancer, diabetes to heart disease and neurodegeneration.",Real time optimization of electron-based fragmentation for middle and top-down proteomics in mass spectrometry,10081127,R43GM139467,"['Acceleration', 'Affect', 'Arthritis', 'Artificial Intelligence', 'Automobile Driving', 'Basic Science', 'Big Data', 'Biological', 'Biological Products', 'Biological Response Modifier Therapy', 'Businesses', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computers', 'Continuous Infusion', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Collection', 'Diabetes Mellitus', 'Diagnosis', 'Digital Signal Processing', 'Disease', 'Dissociation', 'Electronics', 'Electrons', 'Engineering', 'Face', 'Family', 'Feasibility Studies', 'Generations', 'Goals', 'Grant', 'Health', 'Heart Diseases', 'Individual', 'Industrialization', 'Industry', 'Ions', 'Isoleucine', 'Laboratories', 'Leucine', 'Macromolecular Complexes', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Methodology', 'Methods', 'Modernization', 'Multiprotein Complexes', 'Nerve Degeneration', 'Noise', 'Optics', 'Peptides', 'Periodicity', 'Phase', 'Polysaccharides', 'Post-Translational Protein Processing', 'Price', 'Process', 'Protein Analysis', 'Protein Fragment', 'Proteins', 'Proteomics', 'Reading', 'Research Personnel', 'Resolution', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'Techniques', 'Technology', 'Time', 'Tissues', 'Transistors', 'Trypsin', 'United States National Institutes of Health', 'Vendor', 'Water', 'Work', 'base', 'blind', 'computational platform', 'computerized data processing', 'cost effective', 'data acquisition', 'diagnostic biomarker', 'disulfide bond', 'electron energy', 'encryption', 'experience', 'fragment X', 'improved', 'instrument', 'instrumentation', 'interest', 'macromolecule', 'mass spectrometer', 'meetings', 'operation', 'preservation', 'programs', 'protein complex', 'signal processing', 'success', 'therapeutic biomarker']",NIGMS,"E-MSION, INC.",R43,2020,212830,959155,-0.051298170461913505
"An interactive, digital platform to transform physical science learning Abstract: The next generation of science and health care professionals will need to understand the foundational concepts of physics. While textbooks play a critical role in science learning, these books are not designed to meet the diverse learning needs of students in today’s classrooms. Unfortunately, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current physical science textbooks and to revolutionize reading with interactive texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned force and motion (NGSS PS2A) content into Spanish (Aim 1); designing and developing science learning games (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content in both English and Spanish to address 9 additional NGSS standards (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive learning technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning disabilities. This Fast-Track project will produce a bilingual, digital platform to support students’ understanding of Physical Science, which will allow students to seamlessly move between different reading levels and languages, play science learning games, and receive personalized content. This project will also solicit feedback from teachers and students, develop teacher support materials, and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform physical science learning",10006915,R44GM137622,"['Address', 'Adoption', 'Books', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Drops', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Health Professional', 'Healthcare', 'Home environment', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Motion', 'Phase', 'Physics', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Rewards', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Students', 'Techniques', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'adaptive learning', 'base', 'bilingualism', 'design', 'digital', 'education resources', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'physical science', 'reading ability', 'response', 'science teacher', 'scientific literacy', 'skills', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2020,231500,981500,-0.0037727907687160546
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10224492,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,233900,641965656,-0.0026337488343054372
"Sarcopenia: computable phenotypes and clinical outcomes. PROJECT SUMMARY  Sarcopenia is a generalized muscle condition that develops with aging and complicates many common chronic diseases, resulting in low muscle mass, weakness, and impaired physical function. Sarcopenia contributes to disability, increased hospitalizations, healthcare costs, and risk of death. Despite being under- recognized clinically, sarcopenia is a major public health concern, with the worldwide prevalence projected to increase by up to 72% in the next 30 years. However, limited knowledge of sarcopenia among clinicians, combined with time pressures in clinical encounters delay its detection, and limit opportunity for intervention or recruitment into clinical trials. To overcome this barrier to detecting sarcopenia, we propose to use advanced big data and machine learning methods to identify additional component variables predicting sarcopenia among the rich electronic health record (EHR) data and develop a validated and portable sarcopenia computable phenotype (which uses a computer algorithm to detect patient characteristics or outcomes from the EHR). This innovative proposal takes advantage of key resources at Indiana University and its affiliation with the Regenstrief Institute and the Indiana Network for Patient Care (INPC), a statewide multi-health system clinical data warehouse including >100 healthcare entities and >18 million unique patients with both coded and text-based data, combined with the ability to perform comprehensive musculoskeletal measurements in the Musculoskeletal Function Imaging and Tissue (MSK-FIT) Core funded through a NIAMS Core Center for Clinical Research grant (P30AR072581). Our long-term goal is to accurately identify patients with, or at risk for, sarcopenia and its consequences in order to provide targeted interventions. We hypothesize that by using medical informatics and machine learning innovations, computable phenotypes can identify patients with sarcopenia from the EHR, predict deficits in measured muscle strength and physical function, and prospectively predict risk of hospitalization and death. In Aim 1, we will categorize >2000 adult participants in the MSK-FIT Core with accessible EHR data, as either sarcopenic or nonsarcopenic according to measurements of muscle strength, muscle mass and physical performance. We will then use 75% of the MSK- FIT Core cohort to train machine deep learning algorithms to detect combinations of variables from these subjects’ EHR predicting whether the patient is sarcopenic or not sarcopenic. The performance of the resulting computable phenotype will then be tested in the remaining 25% of the MSK-FIT Core participants. In Aim 2, we will test the performance of the sarcopenia computable phenotype to detect a clinically meaningful phenotype in the entire INPC adult population (>18 million), by evaluating the ability to predict the rate of hospitalizations and death among patients rated as sarcopenic versus matched controls. Such a computable phenotype will then enable large scale targeted recruitment, pragmatic clinical trials, clinical evaluation and intervention. PROJECT NARRATIVE Sarcopenia is a generalized muscle condition that develops with aging and complicates many common chronic diseases, resulting in low muscle mass, weakness, and impaired physical function, and contributing to disability, increased hospitalizations and risk of death. Despite being underrecognized clinically, sarcopenia is a major public health concern, with projected large increases in its prevalence worldwide. The overall goal of this grant is to use advanced, state-of-the art biomedical informatics and big data methods to generate a tool using electronic health record data to detect patients with sarcopenia early and facilitate patient recruitment, engagement and clinical interventions to treat sarcopenia.",Sarcopenia: computable phenotypes and clinical outcomes.,9970930,R01AR077273,"['Adult', 'Aging', 'Algorithms', 'Automated Clinical Decision Support', 'Awareness', 'Big Data', 'Big Data Methods', 'Birth', 'Cessation of life', 'Characteristics', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Computational algorithm', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Detection', 'Diagnosis', 'Diet', 'Disease', 'Electronic Health Record', 'Exercise', 'Funding', 'Goals', 'Grant', 'Hand Strength', 'Health Care Costs', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Image', 'Impairment', 'Indiana', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical Informatics', 'Methods', 'Muscle', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Outcome', 'Participant', 'Patient Care', 'Patient Recruitments', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmacology', 'Phenotype', 'Physical Function', 'Physical Performance', 'Physicians', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Process', 'Provider', 'Public Health', 'Public Health Informatics', 'Publishing', 'Race', 'Reporting', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Supervision', 'Testing', 'Text', 'Time', 'Tissues', 'Training', 'Universities', 'age group', 'base', 'biomedical informatics', 'clinical center', 'clinical data warehouse', 'clinical encounter', 'cohort', 'comorbidity', 'computable phenotypes', 'deep learning algorithm', 'disability', 'electronic data', 'experience', 'hospitalization rates', 'improved', 'improved outcome', 'innovation', 'machine learning method', 'mortality risk', 'muscle form', 'muscle strength', 'performance tests', 'physical conditioning', 'population health', 'portability', 'pressure', 'prevent', 'prospective', 'ranpirnase', 'recruit', 'reduced muscle mass', 'research clinical testing', 'sarcopenia', 'sex', 'text searching', 'tool']",NIAMS,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2020,235788,232986943,-0.03374423806422784
"Photoplethysmography Analysis to Assess Cardio-Cerebrovascular Impact of Sleep Project Summary Obstructive sleep apnea (OSA) is common in the aging population and is associated with increased risk of cardiovascular (CV) disease, including cerebrovascular injury. Repetitive exposure to acute CV response, such as sympathetic surge and blood pressure (BP) rise following obstructive respiratory events, is an important mediating mechanism linking OSA to CV disease and cerebrovascular injury. However, such acute CV responses are not effectively captured by conventional polysomnography metrics, such as the apnea hypopnea index (AHI) commonly used in OSA evaluation. This results in imprecise classification of patients in terms of their CV risk and may be responsible for inconsistent results in epidemiologic and clinical studies. More importantly, the uncertainty of the effectiveness of continuous positive airway pressure (CPAP) therapy in reducing the CV risk poses a significant challenge in therapeutic decision-making in older individuals. Therefore, the identification of additional phenotypic markers that better quantify the unfavorable CV effects of OSA and provide improved prediction of CV outcomes is crucial to improving risk stratification and clinical therapeutic decision-making. Herein, we propose to study novel physiologic measurements that can readily be retrieved from a single photoplethysmography (PPG) sensor and investigate whether PPG features are associated with markers of subclinical, clinical CV disease, and cerebrovascular injury. We will extract PPG features from polysomnography obtained in the Multi-Ethnic Study of Atherosclerosis (MESA) Sleep study and examine whether PPG features are associated with CV outcomes, including left ventricular mass, aortic stiffness, and incident cardiovascular events, as well as markers of cerebrovascular injury, including brain structural abnormalities by MRI and cognitive impairment by Cognitive Abilities Screening Instrument in the older men and women. We will compare the association of PPG features with these outcomes with that of conventional OSA assessment metrics (such as apnea hypopnea index). The main PPG feature of interest is slope transit time. To assess the utility of the various PPG features for use in estimating and classifying outcomes, we will use novel machine learning methods, such as are based on the GNOSIS (Generalized Networks for the Optimal Synthesis of Information Systems) information-theory-based modeling tool. Subsequently, we will determine how PPG features predict BP treatment response to CPAP and O2 therapy using data from the HeartBEAT randomized controlled trial. This study attempts to identify novel PSG metrics that are cardiovascular-centric and to assess their clinical utility in the older adults. The findings of the study will provide a basis for further development of a simpler method by which to assess and monitor OSA. Considering the high prevalence of OSA in older populations, coupled with its impact on adverse health outcomes, the proposal has significant public health implications. Project Narrative Currently used conventional metrics for sleep apnea assessment has many limitations including insufficient consideration of acute cardiovascular response to sleep apnea event. We propose to study a novel physiologic measurements that can be readily retrieved from a single photoplethysmography (PPG) sensor and investigate whether they are associated with markers of subclinical, clinical CVD and neurocognitive outcomes. We will use data from the Multi-Ethnic Study of Atherosclerosis (MESA) Sleep study to evaluate PPG features in their associations with outcomes and examine whether these features help identify people who respond better to CPAP therapy in terms of blood pressure in the Heart Biomarker Evaluation in Apnea Treatment (HeartBEAT) randomized controlled trial data.",Photoplethysmography Analysis to Assess Cardio-Cerebrovascular Impact of Sleep,10107688,R21AG070576,"['Acute', 'Apnea', 'Biomedical Engineering', 'Biomedical Research', 'Blood Pressure', 'Brain', 'Cardiovascular Diseases', 'Cardiovascular Physiology', 'Cardiovascular system', 'Caring', 'Classification', 'Clinical', 'Clinical Research', 'Continuous Positive Airway Pressure', 'Coupled', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Effectiveness', 'Elderly', 'Electrocardiogram', 'Evaluation', 'Event', 'Exposure to', 'Frequencies', 'Health', 'Heart', 'High Prevalence', 'Hour', 'Impaired cognition', 'Individual', 'Information Systems', 'Information Theory', 'Injury', 'Investigation', 'Left Ventricular Mass', 'Lesion', 'Link', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mediating', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Multi-Ethnic Study of Atherosclerosis', 'Neurocognitive', 'Obstructive Sleep Apnea', 'Older Population', 'Optics', 'Outcome', 'Oxygen', 'Patients', 'Personal Satisfaction', 'Photoplethysmography', 'Physiologic Monitoring', 'Physiologic pulse', 'Physiological', 'Polysomnography', 'Public Health', 'Pulse Oximetry', 'Randomized Controlled Trials', 'Risk', 'Risk stratification', 'Shapes', 'Signal Transduction', 'Sleep', 'Sleep Apnea Syndromes', 'Structural defect', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Uncertainty', 'Work', 'aging population', 'arm', 'base', 'biomarker evaluation', 'cardiovascular disorder risk', 'cardiovascular risk factor', 'cerebrovascular', 'clinical practice', 'cognitive ability', 'cognitive function', 'cognitive testing', 'cohort', 'epidemiology study', 'improved', 'indexing', 'instrument', 'interest', 'machine learning method', 'novel', 'older men', 'older women', 'phenotypic biomarker', 'predicting response', 'prospective', 'respiratory', 'response', 'screening', 'sensor', 'tool', 'treatment response', 'white matter']",NIA,UNIVERSITY OF WASHINGTON,R21,2020,256550,533302350,-0.009097614839463003
"Infrared Eyes(iREyes) Infrared Eyes Abstract Eden Medical, Inc. is pleased to resubmit this Phase 2 SBIR proposal to develop the “Infrared Eyes” (iREyes) imager system, an affordable and powerful mobile health (mHealth) tool for healthcare. The hand-held iREyes system will acquire both thermal and visible spectrum imagery to quantify healing via thermal indexing methodology. The iREyes will offer a user-friendly product with automated categorization. Diabetic foot wounds are common, complex and costly. Foot areas that are likely to ulcerate are associated with increased local skin temperature due to inflammation and enzymatic autolysis of tissue. Inflammation is characterized by the cardinal signs including redness, swelling, and heat. In addition to identifying inflammation associated with healing, the iREyes will also identify hot spots associated with repetitive stress to reduce ulceration and re-ulceration risk for people in diabetic foot remission. The iREyes will directly quantify inflammation pathophysiology implementing a powerful revised two-part strategy: wound healing via regional foot index analysis and ulcer reoccurrence risk through temperature asymmetry threshold analysis. The combined thermal indexing for healing existing wounds and asymmetry predictive analysis represents a significant breakthrough over current practice. Infrared Eyes Narrative To develop a low-cost mobile health (mHealth) infrared imaging system that acquires both thermal and visible spectrum imagery to quantify diabetic foot ulcer healing via thermal indexing and risk prediction with temperature asymmetry methodology.",Infrared Eyes(iREyes),9996341,R44DK102244,"['Agreement', 'Algorithms', 'Amputation', 'Area', 'Autolysis', 'Automation', 'Blood flow', 'California', 'Catalogs', 'Chronic', 'Clinical', 'Clinics and Hospitals', 'Collaborations', 'Complex', 'Consult', 'Data Analyses', 'Data Analytics', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Foot', 'Diabetic Foot Ulcer', 'Diagnosis', 'Discipline of Nursing', 'Disease remission', 'Electronic Health Record', 'Electronics', 'Evaluation', 'Eye', 'Functional disorder', 'Funding', 'Gifts', 'Grant', 'Hand', 'Hawaii', 'Health', 'Healthcare', 'Hospitals', 'Hot Spot', 'Image', 'Imagery', 'Impairment', 'Inflammation', 'Inflammatory', 'Lead', 'Legal patent', 'Length', 'Licensing', 'Limb structure', 'Los Angeles', 'Lower Extremity', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Methodology', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Outpatients', 'Pain', 'Patients', 'Pattern', 'Phase', 'Physicians', 'Redness', 'Risk', 'Sales', 'Services', 'Shapes', 'Skin Temperature', 'Small Business Innovation Research Grant', 'Spottings', 'Stress', 'Swelling', 'System', 'Tablets', 'Technology', 'Temperature', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'Ulcer', 'United States', 'United States National Institutes of Health', 'Universities', 'Width', 'Work', 'base', 'commercialization', 'computerized data processing', 'cost', 'design', 'diabetic patient', 'foot', 'healing', 'human subject', 'imager', 'imaging system', 'improved', 'indexing', 'mHealth', 'medical schools', 'portability', 'programs', 'prototype', 'spectrograph', 'tool', 'user-friendly', 'web portal', 'wound', 'wound care', 'wound healing']",NIDDK,"EDEN MEDICAL, INC.",R44,2020,267476,467010,-0.001634573261634572
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9911975,R01AR068456,"['3-Dimensional', 'Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Bone structure', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Screening procedure', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Visualization', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cortical bone', 'cost', 'density', 'experience', 'fracture risk', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'osteoporosis with pathological fracture', 'patient response', 'population based', 'public health relevance', 'response', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'treatment response']",NIAMS,UNIVERSITY OF COLORADO DENVER,R01,2020,276227,292134808,0.003524713545440312
"Automated Molecular Identity Disambiguator (AutoMID) PROJECT SUMMARY Small molecules are one of the most important classes of therapeutics alleviating suffering and in many cases death for hundreds of millions of people worldwide. Small molecules also serve as invaluable tools to study biology, often with the goal to validate novel targets for the development of future therapeutic drugs. Reproducibility of experimental results and the interoperability and reusability of resulting datasets depend on accurate descriptions of associated research objects, and most critically on correct representations of small molecules that are tested in biological assays. For example, it is not possible to develop predictive models of protein target - small molecule interactions if their chemical structure representations are not correct. Many factors contribute to errors in reported chemical structures in small molecule screening and omics reference databases, scientific publications, and many other web-based resources and documents. Because of the complexity of representing small molecules chemical structure graphs and the lack of thorough curation, errors are frequently introduced by non-experts and error propagation across different digital research assets is a pervasive problem. To address this challenging problem via a scalable approach, we propose the Automated Molecular Identity Disambiguator (AutoMID). AutoMID will be usable in batch mode at scale via an API, for example to assist chemical structure standardization and registration by maintainers of digital research assets, and also via interactive (UI) mode for everyday researchers to quickly and easily validate or correct their small molecule representations. AutoMID will leverage extensive highly standardized linked databases of chemical structures and associated information including names, synonyms, biological activity and physical properties and their sources / provenance and leverage expert rules and AI to enable reliable disambiguation of chemical structure identities at scale. PROJECT NARRATIVE Small molecules are one of the most important types of drugs. They also serve as invaluable tools to study biology. The complexity of representing chemical graphs and the lack of thorough curation leads to frequent small molecule structure errors, which propagate across digital research assets, impeding their interoperability and reusability. To address this challenging problem, we propose the Automated Molecular Identity Disambiguator (AutoMID). Built on expert knowledge and AI, AutoMID will enable researchers and maintainers of data repositories to reliably identify and resolve ambiguities in chemical structures at scale.",Automated Molecular Identity Disambiguator (AutoMID),9987129,R01LM013391,"['Address', 'Adoption', 'Biological', 'Biological Assay', 'Biology', 'Categories', 'Cessation of life', 'Chemical Structure', 'Chemicals', 'Classification', 'Complex', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Deposition', 'Detection', 'Development', 'FAIR principles', 'Future', 'Goals', 'Graph', 'Hand', 'Hybrids', 'In Vitro', 'Individual', 'Knowledge', 'Legal patent', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Metadata', 'Modeling', 'Molecular', 'Molecular Structure', 'Names', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Privatization', 'Property', 'Proteins', 'Publications', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Semantics', 'Source', 'Standardization', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Training', 'base', 'cheminformatics', 'data harmonization', 'data modeling', 'data warehouse', 'design', 'digital', 'high throughput screening', 'improved', 'in silico', 'in vivo', 'interoperability', 'knowledge curation', 'novel', 'online resource', 'physical property', 'predictive modeling', 'relational database', 'screening', 'small molecule', 'software systems', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2020,293345,157845771,-0.04204413773255345
New Approaches to Dementia Heterogeneity  ,New Approaches to Dementia Heterogeneity,10053649,P30AG062422,"['Aging', 'Area', 'Artificial Intelligence', 'Astrocytes', 'Behavior', 'Big Data', 'Biological Markers', 'Blood', 'Blood Vessels', 'Brain', 'Brain imaging', 'Cells', 'Cognition', 'Cognitive', 'Data', 'Data Analytics', 'Data Collection', 'Degenerative Disorder', 'Dementia', 'Disease', 'Disease Progression', 'Dissection', 'Early Diagnosis', 'Emotional', 'Endothelium', 'Etiology', 'Failure', 'Fibrosis', 'Functional disorder', 'Funding', 'Goals', 'Heterogeneity', 'Homeostasis', 'Image', 'Impaired cognition', 'Impairment', 'Inflammation', 'Injury', 'Intervention', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mediating', 'Mediation', 'Mentors', 'Mentorship', 'Modeling', 'Molecular', 'National Institute of Neurological Disorders and Stroke', 'Natural regeneration', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuroglia', 'Neurons', 'Outcome', 'Pathologic Neovascularization', 'Pathway interactions', 'Patients', 'Pattern', 'Perfusion', 'Phase', 'Phenotype', 'Play', 'Population', 'Proteomics', 'Research Personnel', 'Risk', 'Role', 'Scientist', 'Site', 'Synapses', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Training', 'Vascular Dementia', 'Vascular Diseases', 'Veterans', 'angiogenesis', 'base', 'biomedical informatics', 'cerebrovascular biology', 'clinical phenotype', 'cognitive testing', 'cohort', 'disorder subtype', 'drug development', 'endophenotype', 'exosome', 'hypoperfusion', 'molecular marker', 'multidimensional data', 'neuroinflammation', 'neurovascular', 'novel', 'novel strategies', 'phenotypic biomarker', 'precision medicine', 'predictive signature', 'prospective', 'proteostasis', 'resilience', 'retinal imaging', 'tau Proteins', 'tool', 'unsupervised learning', 'vascular cognitive impairment and dementia']",NIA,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",P30,2020,298759,685608202,-0.026424919252544476
"Inferential methods for functional data from wearable devices Project Summary/Abstract This is a project to develop new statistical methods for comparing groups of subjects in terms of health outcomes that are assessed using data from wearable devices. Inexpensive wearable sensors for health monitoring are now capable of generating massive amounts of data collected longitudinally, up to months at a time. The project will develop inferential methods that can deal with the complexity of such data. A serious challenge is the presence of unmeasured time-dependent confounders (e.g., circadian and dietary patterns), making direct comparisons or borrowing strength across subjects untenable unless the studies are carried out in controlled experimental con- ditions. Generic data mining and machine learning tools have been widely used to provide predictions of health status from such data. However, such tools cannot be used for signiﬁcance testing of covariate effects, which is necessary for designing precision medicine interventions, for example, without taking the inherent model selection or the presence of the unmeasured confounders into account. To overcome these difﬁculties, a systematic de- velopment of inferential methods for functional outcome data obtained from wearable devices will be carried out. There are three speciﬁc aims: 1) Develop metrics for functional outcome data from wearable devices, 2) Develop nonparametric estimation and testing methods for activity proﬁles and a screening method for predictors of activity proﬁles, 3) Implement the methods in an R package and carry out two case studies using accelerometer data. For Aim 1, the approach is to reduce the sensor data to occupation time proﬁles (e.g., as a function of activity level), and formulate the statistical modeling in terms of these proﬁles using survival and functional data analytic meth- ods. This will have a number of advantages, the principal one being that time-dependent confounders become less problematic because the effect of differences in temporal alignment across subjects is mitigated. In addition, survival analysis methods can be applied by viewing the occupation time as a time-to-event outcome indexed by activity level. For Aim 2, nonparametric methods will be used to compare and order occupation time distributions between groups of subjects that are speciﬁed in terms of baseline covariate levels or treatment groups. Further, a new method of post-selection inference based on marginal screening for function-on-scalar regression will be developed to identify and formally test whether covariates are signiﬁcantly associated with activity proﬁles. Aim 3 will develop an R-package implementation, and as a test-bed for the proposed methods they will be applied to two Columbia-based clinical studies: to the study of physical activity in children enrolled in New York City Head Start, and to the study of experimental drugs for the treatment of mitochondrial depletion syndrome. Project Narrative The relevance of the project to public health is that it will develop statistical methods for the physiological eval- uation of patients on the basis of data collected by inexpensive wearable sensors (e.g., accelerometers). By introducing methods for the rigorous comparison of healthcare status among groups of patients observed longi- tudinally over time using such devices, treatment decisions that can beneﬁt targeted populations of patients in terms of continuously-assessed health outcomes will become possible.",Inferential methods for functional data from wearable devices,9924432,R01AG062401,"['Acceleration', 'Accelerometer', 'Beds', 'Bypass', 'Case Study', 'Characteristics', 'Child', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Development', 'Devices', 'Dietary Practices', 'Drug Combinations', 'Enrollment', 'Evaluation', 'Event', 'Grant', 'Head Start Program', 'Health', 'Health Status', 'Healthcare', 'Intervention', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Monitor', 'Motivation', 'Nature', 'New York City', 'Obesity', 'Occupations', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmacotherapy', 'Physical activity', 'Physiological', 'Preschool Child', 'Process', 'Proxy', 'Public Health', 'Recording of previous events', 'Regimen', 'Signal Transduction', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Stochastic Processes', 'Survival Analysis', 'Syndrome', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Work', 'analytical method', 'base', 'circadian', 'data mining', 'design', 'experimental study', 'functional outcomes', 'indexing', 'interest', 'lower income families', 'novel', 'patient population', 'precision medicine', 'screening', 'sensor', 'theories', 'time use', 'tool', 'treatment group', 'wearable device', 'wearable sensor technology']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,298890,558628098,0.001391474849009756
"Instrumental screening for dysphagia by combining high-resolution cervical auscultation with advanced data analysis tools to identify silent dysphagia and silent aspiration ABSTRACT Dysphagia (disordered swallowing) causes nearly 150,000 annual hospitalizations and over 220,000 additional hospital days, and prolongs hospital lengths of stay by 40%. Dysphagia risk is typically identified through subjective screening methods and those identified through screening undergo gold standard imaging testing such as videofluoroscopy (VF). However, screening methods over- or underestimate risk, and completely fail to identify patients with silent dysphagia (e.g., silent aspiration) that can cause pneumonia and other adverse events. Pre-emptive detection of silent or near-silent aspiration is essential. The long term goal is to develop an instrumental dysphagia screening approach based on high-resolution cervical auscultation (HRCA) in order to early predict dysphagia-related adverse events, and initiate intervention measures to mitigate them. The overall objective here is to develop accurate, advanced data analysis approaches to translate HRCA signals to swallowing events observed in VF images. Our strong preliminary data has led us to our central hypothesis: advanced data analytics tools are suitable approaches for the analysis of HRCA in order to automate dysphagia screening. The rationale is that a reliable, robust early-warning instrumental dysphagia screening approach will reduce adverse events in patients with silent aspiration/dysphagia, shorten length of stay and improve overall clinical outcomes. Guided by strong preliminary data, we will pursue the following three specific aims: (1) develop machine learning algorithms to differentiate HRCA signals produced by swallowing physiologic events from similar, non-swallow related signals produced during swallowing; (2) translate HRCA swallowing-signal signatures to actual swallow physiologic events to detect abnormal swallowing physiology; and (3) discriminate normal from abnormal airway protection and swallow physiology via machine-learning analysis of HRCA signals with similar accuracy as VF. Under the first aim, a machine learning approach will be used to detect pharyngeal swallowing events and differentiate them from speech, cough and other non- swallow events, with 90% accuracy, when compared to a human expert’s interpretation of our VF data sets. Under the second aim, objective swallowing physiology observations from VF will be matched to swallowing events observed with HRCA in order to show that abnormal swallow physiology and airway protection will produce distinctive HRCA signal signatures that predict the same events identified with VF. Under the third aim, analytical algorithms will be used to detect signs of disordered airway protection in HRCA signal signatures with 90% accuracy when compared to a human expert’s airway protection ratings from VF images. The approach is innovative, as it will produce analysis tools that will infer about dysphagia and aspiration based on the analysis of HRCA with unprecedented accuracy, before patients are placed in harm’s way. Our work is significant, because it will translate to an early-warning HRCA screening tool that predicts dysphagia- related adverse events in asymptomatic patients reducing medical adverse events, and length of stay. The proposed research is relevant to public health because dysphagia is related to nearly 150,000 annual hospitalizations and over 220,000 additional hospital days, it increases pneumonia incidence, prolongs hospital stays by 40% for patients with many diseases, and is prevalent in acute care hospitals and nursing homes. Choking (airway obstruction) and pneumonia due to aspiration (inhalation of swallowed food and liquids), are common results of dysphagia, and both are preventable when dysphagia is identified before patients are offered oral food, liquids or medications. The proposed research is relevant to the part of NIH’s mission that pertains to enhancing health, lengthening life and reducing illnesses, as we will develop new data analytics tools to be used along with high-resolution cervical auscultation in order to instrumentally screen for dysphagia and predict dysphagia-related adverse events before they can harm patients with dysphagia.",Instrumental screening for dysphagia by combining high-resolution cervical auscultation with advanced data analysis tools to identify silent dysphagia and silent aspiration,9935103,R01HD092239,"['Address', 'Adult', 'Adverse event', 'Algorithmic Analysis', 'Algorithms', 'Aspirate substance', 'Aspiration Pneumonia', 'Auscultation', 'Biomechanics', 'Cervical', 'Choking', 'Clinical', 'Coughing', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Deglutition', 'Deglutition Disorders', 'Dehydration', 'Dementia', 'Detection', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Disabled Persons', 'Disease', 'Equipment', 'Event', 'Food', 'Goals', 'Gold', 'Group Homes', 'Head and Neck Cancer', 'Health', 'Hospital Nursing', 'Hospitalization', 'Human', 'Image', 'Impairment', 'Incidence', 'Inhalation', 'Intervention', 'Lead', 'Learning', 'Length of Stay', 'Life', 'Liquid substance', 'Machine Learning', 'Malnutrition', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monte Carlo Method', 'Morbidity - disease rate', 'Nature', 'Neurodegenerative Disorders', 'Nursing Homes', 'Oral', 'Outcome', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Physiological', 'Physiology', 'Pneumonia', 'Positioning Attribute', 'Public Health', 'Research', 'Resolution', 'Risk', 'Screening procedure', 'Severities', 'Signal Transduction', 'Speech', 'Stroke', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Water', 'Work', 'acute care', 'airway obstruction', 'analytical tool', 'base', 'cancer therapy', 'clinical practice', 'clinically significant', 'image processing', 'improved', 'innovation', 'instrument', 'kinematics', 'machine learning algorithm', 'mortality', 'patient safety', 'post stroke', 'predictive signature', 'predictive tools', 'screening', 'tool', 'translational impact', 'vibration']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,302394,570146095,0.003078883493247137
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,9855035,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'disease phenotype', 'driver mutation', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'machine learning method', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistical learning', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,305167,511185245,-0.019332391758118028
"Sample-specific Models for Molecular Portraits of Diseases in Precision Medicine A fundamental challenge in precision medicine is to understand the patterns of differentiation between individuals. To address this challenge, we propose to go beyond the traditional `one disease--one model' view of bioinformatics and pursue a new view built upon personalized patient models that facilitates precision medicine by leveraging both commonalities within a patient cohort as well as signatures unique to every individual patient. With the emergence of large-scale databases such as The Cancer Genome Atlas (TCGA), the International Cancer Genome Consortium (ICGC), and the Gene Expression Omnibus (GEO), which collect multi-omic data on many different diseases, a new “pan-omics” and “pan-disease” paradigm has emerged to jointly analyze all patients in a disease cohort while accounting for patient-specific effects. An example of this is the recently released Pan-Cancer Atlas. At the same time, next generation statistical tools to accurately and rigorously draw the necessary inferences are lacking. In this project we propose a series of mathematically rigorous, statistically sound, and computationally feasible approaches to infer sample-specific models, providing a more complete view of heterogeneous datasets. By bringing together ideas from the machine learning, statistics, and mathematical optimization communities, we provide a rigorous framework for precision medicine via sample-specific statistical models. Crucially, we propose to analyze this framework and prove strong theoretical guarantees under weak assumptions--this dramatically distinguishes our framework from much of the existing literature. Towards these goals, we propose the following aims: Aim 1: Discovery of new molecular profiles with sample-specific statistical models. We propose a general framework for inferring sample-specific models with low-rank structure based on the novel concept of distance-matching. This allows us to infer statistical models at the level of a single patient without overfitting, and is general enough to be applied for prediction, classification, and network inference as well as a variety of diseases and phenotypes. Aim 2: Multimodal approaches to personalized diagnosis--contextually interpretable models for actionable clinical decision support. In order to translate these models into practice, we propose a novel interpretable predictive model that supports complex, multimodal data types such as images and text combined with high-level interpretable features such as SNP data, gender, age, etc. This framework simultaneously boosts the accuracy of clinical predictions by exploiting sample heterogeneity while providing human-digestable explanations for the predictions being made. Aim 3: Next-generation precision medicine--algorithms and software for personalized estimation. To put our models into practical use, we will develop new algorithms for interpretable prediction of personalized clinical outcomes and visualization of personalized statistical models. All of our tools will be combined into a user-friendly software package called PrecisionX that will be freely available to researchers and clinicians everywhere. RELEVANCE (See instructions): Personalization with data is a critical challenge whenever decisions must be made at scale, and has applications that go beyond precision medicine; businesses, educational institutions, and financial institutions are among the many players that have acknowledged a stake in this complex problem. We expect the proposed work to provide a rigorous foundation for personalization with large and high-dimensional datasets, finding use throughout the broader scientific community as well as with industry and educational institutions. Alongside our collaboration with Pitt/UPMC, we will work with physicians and data scientists for practical feedback as well as provide training in the methods developed. n/a",Sample-specific Models for Molecular Portraits of Diseases in Precision Medicine,10133782,R01GM140467,"['Accounting', 'Address', 'Age', 'Algorithmic Software', 'Algorithms', 'Atlases', 'Bioinformatics', 'Businesses', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Scientist', 'Data Set', 'Disease', 'Feedback', 'Foundations', 'Gender', 'Gene Expression', 'Goals', 'Heterogeneity', 'Human', 'Image', 'Individual', 'Industry', 'Institution', 'Instruction', 'International', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Methods', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Outcome', 'Patients', 'Pattern', 'Physicians', 'Portraits', 'Research Personnel', 'Sampling', 'Series', 'Statistical Models', 'Structure', 'Text', 'The Cancer Genome Atlas', 'Time', 'Training', 'Translating', 'Visualization', 'Work', 'base', 'cancer genome', 'clinical decision support', 'clinically actionable', 'cohort', 'disease phenotype', 'heterogenous data', 'high dimensionality', 'individual patient', 'large-scale database', 'molecular modeling', 'multimodal data', 'multimodality', 'next generation', 'novel', 'personalized diagnostics', 'personalized predictions', 'precision medicine', 'predictive modeling', 'sound', 'statistics', 'tool', 'user friendly software']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2020,305566,30434536,-0.00816082512875912
"Image-guided Biocuration of Disease Pathways From Scientific Literature Realization of precision medicine ideas requires an unprecedented rapid pace of translation of biomedical discoveries into clinical practice. However, while many non-canonical disease pathways and uncommon drug actions, which are of vital importance for understanding individual patient-specific disease pathways, are accumulated in the literature, most are not organized in databases. Currently, such knowledge is curated manually or semi-automatically in a very limited scope. Meanwhile, the volume of biomedical information in PubMed (currently 28 million publications) keeps growing by more than a million articles per year, which demands more efficient and effective biocuration approaches.  To address this challenge, a novel biocuration method for automatic extraction of disease pathways from figures and text of biomedical articles will be developed.  Specific Aim 1: To develop focused benchmark sets of articles to assess the performance of the biocuration pipeline.  Specific Aim 2: To develop a method for extraction of components of disease pathways from articles’ figures based on deep-learning techniques.  Specific Aim 3: To develop a method for reconstruction of disease-specific pathways through enrichment and through graph neural network (GNN) approaches.  Specific Aim 4: To conduct a comprehensive evaluation of the pipeline.  The overarching goal of this project is to develop a computer-based automatic biocuration ecosystem for rapid transformation of free-text biomedical literature into a machine-processable format for medical applications.  The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. It will especially benefit cancer patients for which up-to-date knowledge of newly discovered molecular mechanisms and drug actions is critical. The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. In this project, a novel biocuration method for an automatic extraction of disease mechanisms from figures and text in scientific literature will be developed. These mechanisms will be stored in a database for further querying to assist in medical diagnosis and treatment.",Image-guided Biocuration of Disease Pathways From Scientific Literature,9987133,R01LM013392,"['Address', 'Architecture', 'Benchmarking', 'Biological', 'Cancer Patient', 'Communities', 'Computers', 'Databases', 'Deposition', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Pathway', 'Ecosystem', 'Elements', 'Evaluation', 'Feedback', 'Genes', 'Goals', 'Graph', 'Health', 'Image', 'Informatics', 'Knowledge', 'Label', 'Language', 'Link', 'Literature', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Medical', 'Methods', 'Molecular', 'Molecular Analysis', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'PubMed', 'Publications', 'Regulation', 'Reporting', 'Research', 'Retrieval', 'Selection Criteria', 'Signal Pathway', 'Source', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'Translations', 'Visual', 'Work', 'base', 'clinical practice', 'deep learning', 'design', 'detector', 'drug action', 'image guided', 'improved', 'individual patient', 'knowledge base', 'knowledge curation', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'precision medicine', 'reconstruction', 'success', 'text searching', 'tool', 'usability']",NLM,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2020,313495,63611576,-0.010154377182079857
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9872178,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'data analysis pipeline', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'programmed cell death protein 1', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2020,314000,560644462,-0.021444199248779924
"CAPER: Computerized Assessment of Psychosis Risk Project Summary/Abstract Research suggests that early identification of individuals at clinical high risk (CHR) for psychosis may be able to improve illness course. Studies suggest that early identification of CHR using specialized interviews with help-seeking individuals (with attenuated psychosis symptoms) is a useful approach. This work has two major limitations: 1) interview methods have limited specificity as only 20% of CHR individuals convert to psychosis, and 2) the expertise needed to make CHR diagnosis is only accessible in a few academic centers. We propose to develop a new psychosis symptom domain sensitive (PSDS) battery, prioritizing tasks that show correlations with the symptoms that define psychosis and are tied to the neurobiological systems and computational mechanisms implicated in these symptoms. To promote accessibility, we utilize behavioral tasks that could be administered over the internet; this will set the stage for later research testing widespread screening that would identify those most in need of in-depth assessment. To reach that goal we first need determine which tasks are effective for predicting illness course and how this strategy compares to published prediction methods. We propose to recruit 500 CHR participants, 500 help-seeking individuals, and 500 healthy controls across 5 sites with the following Aims: Aim 1A) To develop a psychosis risk calculator through the application of machine learning (ML) methods to the measures from the PSDS battery. In determine an exploratory ML analysis, we will the added value of combining the PSDS with self-report measures and historical predicators; Aim 1B) We will evaluate group differences on the risk calculator score and hypothesize that the risk calculator score of the CHR group will differ from help-seeking and healthy controls. We further hypothesize that the risk calculator score of the CHR converters will differ significantly from groups of CHR nonconverters, help-seeking and healthy controls. The inclusion of a help-seeking group is critical for translating the risk-calculator into clinical practice, where the goal is to differentiate those at greatest risk for psychosis from those with other forms of psychopathology; Aim 1C): Evaluate how baseline PSDS performance relates to symptomatic outcome 2 years later examining: 1) symptomatic worsening treated as a continuous variable, and 2) conversion to psychosis. We hypothesize that the PSDS calculator: 1) will predict symptom course and, 2) that the differences observed between converters and nonconverters will be larger on the PSDS calculator than on the NAPLS calculator. Aim 2) Use ML methods, as above, to develop calculators that predict: 2A) social, and, 2B) role function deterioration, both observed over two years. Because negative symptoms are strongly linked t o functional outcome than positive symptoms, we predict that negative symptom tasks will be the strongest predictor of functional decline in both domains.This project will provide a next-generation CHR battery, tied to illness mechanisms and powered by cutting-edge computational methods that can be used to facilitate the earliest possible detection of psychosis risk. Narrative Early detection of young people at clinical high risk for psychosis offers a critical opportunity for early intervention to improve the course of illness, and perhaps even prevent onset entirely. Current interview-based methods for psychosis risk detection lack specificity, and are only available in a handful of research centers in the United States. The proposed study aims to improve accessibility and broaden impact of high risk screening by testing brief computerized measures, ultimately able to be administered on the internet, and to improve prediction by focusing on tasks specific to underlying mechanisms driving emerging psychotic symptoms.",CAPER: Computerized Assessment of Psychosis Risk,9980111,R01MH120091,"['Address', 'American', 'Attenuated', 'Automobile Driving', 'Behavioral', 'Biological Markers', 'Classification', 'Clinical', 'Collaborations', 'Computing Methodologies', 'Detection', 'Deterioration', 'Diagnosis', 'Dimensions', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Foundations', 'Frequencies', 'Functional disorder', 'Generations', 'Goals', 'Human Resources', 'Individual', 'Internet', 'Intervention Trial', 'Interview', 'Joints', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Outcome', 'Participant', 'Patient Self-Report', 'Performance', 'Population', 'Predictive Value', 'Preventive Intervention', 'Primary Prevention', 'Psychopathology', 'Psychotic Disorders', 'Public Health', 'Publishing', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk', 'Role', 'Sample Size', 'Secondary Prevention', 'Sensitivity and Specificity', 'Severities', 'Site', 'Specificity', 'Symptoms', 'System', 'Techniques', 'Test Result', 'Testing', 'Training', 'Translating', 'United States', 'Work', 'Youth', 'base', 'clinical practice', 'cognitive testing', 'computerized', 'design', 'follow-up', 'functional decline', 'functional outcomes', 'help-seeking behavior', 'high risk', 'high risk population', 'improved', 'machine learning method', 'new therapeutic target', 'next generation', 'prevent', 'psychotic symptoms', 'recruit', 'relating to nervous system', 'screening', 'social', 'trait']",NIMH,TEMPLE UNIV OF THE COMMONWEALTH,R01,2020,317000,83544663,0.0020345611421913375
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10016840,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2020,330502,560644462,0.001701353435848688
"Assessment of ultrasound features of knee osteoarthritis in a population-based community cohort Project summary Our long-term goal is to demonstrate the utility of ultrasound for OA assessment, standardize its acquisition and scoring, and promote increased uptake of US for use in clinical, research, and trial settings. Knee osteoarthritis (KOA) is highly prevalent and frequently debilitating. Development of potential treatments has been hampered by the heterogenous nature of this common chronic condition, which is characterized by a number of subgroups, or phenotypes, with different underlying pathophysiological mechanisms. Imaging, genetics, biochemical biomarkers, and other features can be used to characterize phenotypes, but variations in data types can make it difficult to harmonize definitions. While radiography is widely used in KOA imaging, it is limited in its ability to assess early disease (when interventions are most likely to succeed) and is insensitive to change. Ultrasound (US) is a widely accessible, time-efficient and cost-effective imaging modality that can provide detailed and reliable information about all joint tissues (e.g., cartilage, meniscus, synovium, bone), and could therefore inform phenotypes in KOA (e.g., by presence of synovitis, effusion, cartilage damage, calcium crystal deposition, and popliteal cysts). Use of US is currently limited by the lack of systematically performed studies in well-characterized non-clinical populations. To address this gap and further the use of this advantageous imaging modality for KOA, we will obtain standardized US and radiography in the population- based Johnston County Health Study (JoCoHS), the new enrollment phase of the 25+ year Johnston County OA Project which includes white, African American, and Hispanic men and women aged 35-70, to achieve three aims. In Aim 1, we will determine the population prevalence (n~3000) of knee US features including cartilage and meniscal damage, synovitis/effusion, calcium crystal deposition, popliteal cysts and osteophytes overall and in key subgroups by age, sex, race/ethnicity, and symptom status. Aim 2 will allow quantification of the associations between these US features and radiographic findings and symptom scores overall and in key subgroups (e.g., those with and without radiographic KOA, by sex, by race/ethnicity). For Aim 3, we will apply novel machine learning methodologies (e.g., Direction-projection-permutation [DiProPerm] hypothesis testing, Joint and Individual Variation [JIVE], and Distance-Weighted Discrimination [DWD]) to a) develop an overall US score for symptomatic KOA and b) identify the contribution of US variables to phenotypes relevant to KOA based on general health, physical activity, and functional assessments. This study is a crucial step to establish the foundation for US as an assessment tool for clinical use, research, and clinical trials in KOA, providing unique population-based cross-sectional data regarding the utility of US and forming the basis for future longitudinal work evaluating its value and performance characteristics related to incident and progressive KOA. Project narrative Osteoarthritis is an enormous and increasing public health problem that, like many other chronic conditions, is not a single disease but a heterogeneous condition consisting of multiple subgroups, or phenotypes, with differing underlying mechanisms. Ultrasound is an accessible, time-efficient, and cost-effective imaging modality that provides invaluable data about all joint tissues involved in osteoarthritis and has the potential to identify important phenotypes. The proposed work is relevant to the NIAMS mission and represents a crucial step to establish the foundation for ultrasound as an assessment tool for use in clinics, research, and clinical trials in osteoarthritis.",Assessment of ultrasound features of knee osteoarthritis in a population-based community cohort,9944803,R01AR077060,"['Address', 'African American', 'Age', 'Area', 'Assessment tool', 'Bilateral', 'Biochemical', 'Biological Markers', 'Bone Spur', 'Calcium', 'Cartilage', 'Categories', 'Characteristics', 'Chronic', 'Claustrophobias', 'Clinic', 'Clinical', 'Clinical Assessment Tool', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Communities', 'County', 'Crystal Formation', 'Crystallization', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Discrimination', 'Disease', 'Enrollment', 'Ethnic Origin', 'Etiology', 'Foundations', 'Future', 'General Population', 'Goals', 'Health', 'Hispanics', 'Image', 'Implant', 'Individual', 'Infrastructure', 'Intervention', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Meniscus structure of joint', 'Methodology', 'Mission', 'Modality', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Nature', 'Outcome', 'Pain', 'Participant', 'Pathology', 'Performance', 'Phase', 'Phenotype', 'Physical activity', 'Popliteal Cyst', 'Population', 'Population Study', 'Prevalence', 'Public Health', 'Race', 'Receiver Operating Characteristics', 'Research', 'Risk Factors', 'Sex Differences', 'Specialist', 'Standardization', 'Subgroup', 'Symptoms', 'Syndrome', 'Synovial Membrane', 'Synovitis', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Variant', 'Woman', 'Work', 'aged', 'base', 'bone', 'cohort', 'cost', 'cost effective', 'effusion', 'follow-up', 'imaging genetics', 'imaging modality', 'individual variation', 'interest', 'men', 'novel', 'point of care', 'population based', 'recruit', 'rheumatologist', 'sex', 'uptake']",NIAMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,342100,511185245,-0.007705851505307187
"N3C & All of Us Research Program Collaborative Project Project Summary/Abstract The COVID-19 pandemic presents unprecedented clinical and public health challenges. Though institutions collect large amounts of clinical data about COVID-19 cases, these datasets individually might not be diverse enough to draw population level conclusions. Also, statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. To tackle this problem, NCATS introduced the National COVID Cohort Collaborative (N3C), an open science, community-based initiative to share patient level data for analysis. The initiative requires participating institutions to share information about their COVID-19 patients in a standard-driven way, including demographics, vital signs, diagnoses, laboratory results, medications, and other treatments. The data from multiple institutions will be merged and consolidated, and access will be provided to investigators through a centralized analytical platform. The COVID-19 data sharing collaboration with the N3C initiative offers a mechanism to initiate collaborations with other NIH sponsored data sharing programs, such as the All of Us Research Program (AoURP). This administrative supplement will support efforts to clean and standardize data at VCU, and to transfer it to the N3C data repository. The supplement will also assist in introducing new services at the Wright Center to support our investigators to use the N3C resources. It will also enable collaboration with the AoURP by establishing a pipeline to collect and transmit consented patients' EHR data and by building on existing community outreach pathways to recruit additional participants for the AoURP. The project will be overseen by the PI/Executive Committee and supervised by the Director of Research Informatics. Procedures and services developed at our local CTSA hub will be shared and disseminated to the CTSA network. Project Narrative NIH/NCATS has been working on the National COVID Cohort Collaborative (N3C), which aims to build a centralized national data resource to be used by the research community to study the COVID-19 pandemic and identify potential treatments as the pandemic continues to evolve. The COVID-19 data sharing collaboration with the N3C initiative also offers a mechanism to initiate collaborations with the All of Us Research Program (AoURP). This administrative supplement will support the creation and management of a data extraction and transfer pipeline to the N3C and AoURP data repositories from VCU.",N3C & All of Us Research Program Collaborative Project,10217339,UL1TR002649,"['Administrative Supplement', 'All of Us Research Program', 'COVID-19', 'COVID-19 pandemic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communities', 'Community Outreach', 'Consent', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Effectiveness', 'Funding Opportunities', 'Goals', 'Health', 'Health Status', 'Individual', 'Informatics', 'Infrastructure', 'Institution', 'Laboratories', 'Outcomes Research', 'Participant', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Procedures', 'Public Health', 'Research', 'Research Personnel', 'Resource Informatics', 'Resources', 'Services', 'Supervision', 'Testing', 'Translational Research', 'United States National Institutes of Health', 'base', 'biomedical informatics', 'clinical center', 'cohort', 'coronavirus disease', 'data resource', 'data sharing', 'data standards', 'data warehouse', 'demographics', 'design', 'improved', 'informatics infrastructure', 'innovation', 'large scale data', 'multi-site trial', 'network informatics', 'open data', 'pandemic disease', 'parent grant', 'programs', 'recruit', 'response', 'statistical and machine learning', 'tool']",NCATS,VIRGINIA COMMONWEALTH UNIVERSITY,UL1,2020,346608,90243698,-0.026634070953607755
"Modeling the Incompleteness and Biases of Health Data Modeling the Incompleteness and Biases of Health Data Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. Existing efforts for missing health data imputation often focus on only cross-sectional correlation (e.g., correlation across subjects or across variables) but neglect autocorrelation (e.g., correlation across time points). Moreover, they often focus on modeling incompleteness but neglect the biases in health data. Modeling both the incompleteness and bias may contribute to better understanding of health data and better support clinical decision making. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets. Aim 1 introduces the MICA framework to jointly consider cross-sectional correlation and auto-correlation. In Aim 2, we will augment MICA to be bias-aware (hence BAMICA) to account for biases stemmed from multiple roots such as healthcare process and use them as features in imputing missing health data. This augmentation is achieved by a novel recurrent neural network architecture that keeps track of both evolution of health data variables and bias factors. In Aim 3, we will supplement unstructured clinical notes to structured health data for modeling incompleteness and biases using a novel architecture of graph neural network on top of memory network. We will apply graph neural networks to process clinical notes in order to learn proper representations as input to the memory networks for imputation and downstream predictive modeling tasks. Depending on the clinical problem and data availability, not all modules may be needed. Thus our proposed BAMICA framework is designed to be flexible and consists of selectable modules to meet some or all of the above needs. In summary, our proposal bridges a key knowledge gap in jointly modeling incompleteness and biases in health data and utilizes unstructured clinical notes to supplement and augment such modeling in order to better support predictive modeling and clinical decision making. We will demonstrate generalizability by experimenting on four large clinical and cohort study datasets, and by scaling up to the eMERGE network spanning 11 institutions nationwide. We will disseminate the open-source framework. The principled and flexible framework generated by this project will bring significant methodological advancement and have a direct impact on enhancing discovery from health data. Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets.",Modeling the Incompleteness and Biases of Health Data,9941499,R01LM013337,"['Adoption', 'Algorithms', 'Architecture', 'Awareness', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Collection', 'Communities', 'Computer software', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Diagnostic tests', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Evolution', 'Functional disorder', 'General Hospitals', 'Goals', 'Graph', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Hour', 'Individual', 'Inpatients', 'Institution', 'Intuition', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Learning', 'Measurement', 'Medical', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Regimen', 'Research', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Structure', 'Symptoms', 'System', 'Test Result', 'Testing', 'Time', 'Training', 'Validation', 'clinical decision support', 'clinical decision-making', 'data mining', 'data quality', 'design', 'experimental study', 'flexibility', 'health care service utilization', 'health data', 'improved', 'lifetime risk', 'machine learning algorithm', 'neglect', 'neural network', 'neural network architecture', 'novel', 'open source', 'patient population', 'personalized diagnostics', 'personalized therapeutic', 'predictive modeling', 'recurrent neural network', 'scale up', 'social health determinants', 'stem', 'structured data', 'text searching', 'tool', 'trait']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2020,348397,367414121,-0.00879852513830949
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9889134,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'machine learning method', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,356625,323604360,-0.0013986293307253622
"Center for Machine Learning in Urology PROJECT SUMMARY We propose to establish an Exploratory Center for Interdisciplinary Research in Benign Urology at the Children’s Hospital of Philadelphia (CHOP) and the University of Pennsylvania (Penn), the central mission of which is to apply machine learning to improve the understanding of the pathophysiology, diagnosis, risk stratification, and prediction of treatment responses of benign urological disease among children and adults. The proposed CHOP/Penn Center for Machine Learning in Urology (CMLU) addresses critical structural and scientific barriers that impede the development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. Structurally, urologic research occurs in silos, with little interaction among investigators that study different diseases or different populations (e.g. pediatric and adult). Scientifically, analysis of imaging and other types complex data is limited by inter-observer variability, and incomplete utilization of available information. This proposal overcomes these barriers by applying cutting-edge approaches in machine learning to analyze CT images that are routinely obtained for evaluation of individuals with kidney stone disease. Central to the CHOP/Penn CMLU is the partnership of urologists and experts in machine learning, which will bring a new approach to generating knowledge that advances research and clinical care. In addition, the CMLU will expand the urologic research community by providing a research platform and standalone machine learning executables that could be applied to other datasets. The Center’s mission will be achieved through the following Aims, with progress assessed through systematic evaluation: Aim 1. To expand the research base investigating benign urological disease. We will establish a community with the research base, particularly with the KURe, UroEpi programs, other P20 Centers, and O’Brien Centers. We will build this community by providing mini-coaching clinics to facilitate application of machine learning to individual projects, developing an educational hub for synchronous and asynchronous engagement with the research base, and making freely available all source codes and standalone executables for all machine learning tools. Aim 2. To improve prediction of ureteral stone passage using machine learning of CT images. The CMLU has developed deep learning methods that segment and automate measurement of urinary stones and adjacent renal anatomy. In the Research Project, we will compare these methods to existing segmentation methods and the current gold standard of manual measurement. We will then extract informative features from thousands of CT scans to predict the probability of spontaneous passage of ureteral stones for children and adults evaluated in the CHOP and Penn healthcare systems. Aim 3. To foster collaboration in benign urological disease research across levels of training and centers through an Educational Enrichment Program. We will amplify interactions across institutions and engage investigators locally and nationally by providing summer research internships, and interinstitutional exchange program, and an annual research symposium. PROJECT NARRATIVE The proposed CHOP/Penn O’Brien Center for Machine Learning in Urology addresses critical structural and scientific barriers that impede development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. This application overcomes these barriers by applying cutting- edge approaches in machine learning to analyze complex imaging data for individuals with kidney stone disease.The Center’s strategic vision of using machine learning to generate knowledge that improves diagnosis, risk stratification strategies, and prediction of outcomes among children and adults will be achieved through the implementation of a Educational Enrichment Program and a Research Project.",Center for Machine Learning in Urology,10133362,P20DK127488,"['Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Benign', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Investigator', 'Code', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Educational Status', 'Evaluation', 'Fostering', 'Functional disorder', 'Funding', 'Future', 'Gold', 'Healthcare Systems', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internships', 'Interobserver Variability', 'Investigation', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Lead', 'Longevity', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Mission', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pediatric Hospitals', 'Pennsylvania', 'Philadelphia', 'Population', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Probability', 'Publishing', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk stratification', 'Site', 'Source Code', 'Structure', 'Students', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Urinary Calculi', 'Urologic Diseases', 'Urologist', 'Urology', 'Vision', 'Visit', 'X-Ray Computed Tomography', 'base', 'clinical care', 'complex data ', 'deep learning', 'deep neural network', 'design', 'experience', 'feature selection', 'human error', 'improved', 'interdisciplinary collaboration', 'interest', 'learning strategy', 'novel strategies', 'outcome prediction', 'peer', 'programs', 'routine imaging', 'senior faculty', 'skills', 'summer research', 'symposium', 'tool', 'urologic', 'web page']",NIDDK,CHILDREN'S HOSP OF PHILADELPHIA,P20,2020,358890,178185562,-0.003712987215767308
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,9874005,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2020,360227,169622494,-0.007735453983947732
"Addressing racial disparities in monoclonal gammopathy of undetermined significance and progression to multiple myeloma from a prevention perspective PROJECT SUMMARY/ABSTRACT Multiple myeloma (MM) is a lethal neoplasm and a common hematologic malignancy. MM is uniformly preceded by monoclonal gammopathy of undetermined significance (MGUS). Unlike MM, patients with MGUS are asymptomatic. The current management for MGUS is watchful waiting for disease progression. A marked racial disparity in this disease area is long-established with a 2 to 3-fold increased risk in African Americans (AAs) compared to Caucasians. Moreover, obesity is a risk factor for MM independent of race. Obesity is prevalent in U.S. adults, and particularly more prevalent among AAs than Caucasians. As a result, without any intervention, racial disparities in this disease will continue to worsen. Metformin, a widely-used, safe, well- tolerated, and inexpensive medication, induces weight loss and has been found to be more effective in glycemic control in AAs compared to Caucasians. It has also been used in prospective trials for non-diabetes indications and solid tumor malignancies. We therefore hypothesize that metformin use in MGUS patients will prevent MM and reduce MM disparities. This project plans to focus on the precursor condition of MM – MGUS. The findings from the proposed project will inform biological mechanism studies and MGUS/MM prevention trials. The long-term goal is to identify intervention strategies to prevent the progression of MGUS to MM, reduce the overall burden of MM, and reduce MM disparities. We plan to identify whether high body mass index (BMI) and/or significant change in BMI over the life course are risk factors for MGUS by race (Aim 1), utilizing linked databases with nearly lifelong follow-up of BMI and other health measures ,as well as utilizing artificial intelligence, i.e., machine learning approaches, to perform big data analyses. We will then assess racial differences in the M-protein trajectory after MGUS diagnosis in metformin versus non-metformin users in a subgroup of MGUS patients diagnosed with diabetes mellitus (Aim 2.1) and the association of metformin use with the progression of MGUS to MM (Aim 2.2). Last, we will assess racial differences in the M-protein trajectory in the subgroup of MGUS patients without diabetes mellitus (Aim 3). This project is significant in its capability to 1) identify perhaps the only modifiable risk factor (high BMI) to inform interventions to prevent MM; 2) identify a dynamic marker for disease progression by race (M-protein concentration), where these biomarkers can be a surrogate for MM diagnosis in future prevention trials; and 3) reduce MM health disparities by a) identifying race-specific biomarkers for MGUS and MGUS progression, available through clinical encounters (as opposed to expensive genetic testing); and b) exploring metformin use as a chemopreventive measure. It is innovative in its 1) focus on MM prevention rather than treatment and 2) utilization of artificial intelligence to analyze big data. Successful completion of this study will provide evidence for a paradigm shift in current clinical practice of MGUS management and help prevent MM, an incurable and costly disease. More importantly, it will provide evidence to guide interventions to reduce MM disparities. PROJECT NARRATIVE RELEVANCE: Racial disparities in multiple myeloma (MM), a common and incurable malignancy whose management is extremely costly, are long-established. Although MM is preceded by monoclonal gammopathy of undetermined significance (MGUS) by many years, no established prevention strategies exist and current clinical practice does not treat patients with MGUS; thus, racial disparities for this disease are expected to persist or even worsen due to the disproportionate burden of obesity – a known risk factor for MM – in the African American population. This project plans to study racial differences in risk factors/biomarkers for MGUS and the progression of MGUS to MM to inform future biological mechanism studies and MGUS/MM prevention trials with the goal of reducing MM health disparities.",Addressing racial disparities in monoclonal gammopathy of undetermined significance and progression to multiple myeloma from a prevention perspective,10055834,R01CA253475,"['Address', 'Adult', 'African American', 'Age', 'Area', 'Artificial Intelligence', 'Big Data', 'Biological', 'Biological Markers', 'Body Weight decreased', 'Body mass index', 'Caucasians', 'Chemoprevention', 'Chemopreventive Agent', 'Clinical', 'Cost of Illness', 'Data', 'Data Analyses', 'Databases', 'Department of Defense', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Disease Marker', 'Disease Progression', 'Economic Burden', 'Event', 'Future', 'General Population', 'Goals', 'Growth', 'Health', 'Hematologic Neoplasms', 'Incidence', 'Individual', 'International Agency for Research on Cancer', 'Intervention', 'Life', 'Life Cycle Stages', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medicare/Medicaid', 'Metformin', 'Monoclonal gammopathy of uncertain significance', 'Multiple Myeloma', 'Neoplasms', 'Obesity', 'Patient observation', 'Patients', 'Pharmaceutical Preparations', 'Play', 'Population', 'Predisposition', 'Prevalence', 'Prevention', 'Prevention strategy', 'Prevention trial', 'Process', 'Proteins', 'Race', 'Rare Diseases', 'Risk', 'Risk Factors', 'Role', 'Serum', 'Solid Neoplasm', 'Subgroup', 'Variant', 'Veterans', 'base', 'carcinogenicity', 'clinical encounter', 'clinical practice', 'cost', 'diabetic', 'follow-up', 'genetic testing', 'glycemic control', 'health disparity', 'health economics', 'innovation', 'modifiable risk', 'multiple myeloma M Protein', 'preclinical study', 'premalignant', 'prevent', 'progression marker', 'prospective', 'racial difference', 'racial disparity', 'specific biomarkers', 'working group']",NCI,WASHINGTON UNIVERSITY,R01,2020,360281,533594881,-0.005399692898883679
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9970217,R01DE027027,"['3-Dimensional', 'Accounting', 'Affect', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'feature extraction', 'feature selection', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'segmentation algorithm', 'statistical learning', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2020,371369,135644722,-0.007480241397047244
"Automating Delirium Identification and Risk Prediction in Electronic Health Records Abstract. Delirium, or acute confusional state, affects 30-40% of hospitalized older adults, with the added cost of care estimated to be up to $7 billion. Although originally conceptualized as a transient disorder, delirium is now recognized to have significant consequences, including increased risk of death, functional decline, and long-term cognitive impairment. As up to 75% cases are not recognized by providers, there is an urgent need for additional methods to identify delirium for clinical and research purposes, and to stratify patients based on delirium risk. In this proposal, we present a novel approach to the identification of delirium based on large-scale data mining (i.e., pattern recognition) algorithms using machine learning and natural language processing applied to electronic health record (EHR) data, which will automate chart-based determination of delirium status and risk prediction. We will combine these algorithms with data collected through our recently implemented Virtual Acute Care for Elders (ACE) quality improvement project, which institutes delirium screening once per shift by nursing staff for all individuals over age 65 admitted to the University of Alabama at Birmingham (UAB) Hospital. This unprece- dented volume of data will allow us to achieve the necessary sample sizes for effective training and validation of our data mining algorithms. Data mining algorithms that discover patterns of associations in data, rather than testing predetermined hypotheses, are well suited to application in large-scale algorithms for identification of delirium. Using our Virtual ACE and hospital EHR data, we will be able to evaluate more than 10,000 individual features (e.g., text words and phrases, laboratory and other diagnostic tests, concurrent medical conditions) as- sociated with delirium, which will be classified as risk factors for delirium, as signs, symptoms, and descriptors of delirium itself, and as complications and consequences of delirium, based on expert consensus. We will then use these features to develop rules for identification of delirium in the EHR, as well as risk prediction models that can be integrated into the EHR to provide individualized assessments of delirium risk. This study will lay the foundation for methods of automated delirium identification and risk prediction in healthcare settings that are unable to implement the screening by providers done in our Virtual ACE, as well as for large-scale epidemiological investigations of delirium using EHR data, expanding the current armamentarium for studying this common and debilitating disorder. Project Narrative. Delirium, or acute confusional state, affects up to 7 million hospitalized older adults annu- ally and is associated with long-term declines in cognition and function, but is not recognized by providers in up to 75% of cases. The growth of electronic health records offers a unique opportunity to improve recognition of delir- ium, as methods for identifying delirium based on chart review by clinicians have been developed but are time- and resource-intensive. In this secondary data analysis, we will examine methods for automating delirium recog- nition and risk prediction in electronic health records using machine learning and natural language processing computer algorithms, which in turn will lead to improved care for this serious but often overlooked disorder.",Automating Delirium Identification and Risk Prediction in Electronic Health Records,9873880,R01AG060993,"['Acute', 'Address', 'Adult', 'Affect', 'Agreement', 'Alabama', 'Algorithms', 'Ally', 'Assessment tool', 'Automation', 'Caring', 'Characteristics', 'Clinical Research', 'Cognition', 'Cognitive', 'Computational algorithm', 'Confusion', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Delirium', 'Descriptor', 'Detection', 'Development', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Foundations', 'Growth', 'Health system', 'Hospitals', 'Impaired cognition', 'Individual', 'Inpatients', 'Institutes', 'Institutionalization', 'Laboratories', 'Link', 'Logistics', 'Long-Term Care for Elderly', 'Machine Learning', 'Measurable', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Nursing Staff', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pattern Recognition', 'Persons', 'Prevention', 'Property', 'Provider', 'ROC Curve', 'Reference Standards', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Signs and Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'acute care', 'adverse outcome', 'base', 'care costs', 'confusion assessment method', 'data mining', 'epidemiology study', 'functional decline', 'functional disability', 'health care settings', 'high dimensionality', 'human old age (65+)', 'improved', 'instrument', 'interest', 'large scale data', 'model development', 'mortality risk', 'novel', 'novel strategies', 'patient stratification', 'phrases', 'prediction algorithm', 'programs', 'risk prediction model', 'screening', 'validation studies', 'virtual', 'ward']",NIA,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2020,376860,325573502,-0.023943473848882117
"2/5 CAPER Computerized assessment of psychosis risk Summary  Research suggests that early identification of individuals at clinical high risk (CHR) for psychosis may be able to improve illness course. Studies suggest that early identification of CHR using specialized interviews with help-seeking individuals (with attenuated psychosis symptoms) is a useful approach. This work has two major limitations: 1) interview methods have limited specificity as only 20% of CHR individuals convert to psychosis, and 2) the expertise needed to make CHR diagnosis is only accessible in a few academic centers. We propose to develop a new psychosis symptom domain sensitive (PSDS) battery, prioritizing tasks that show correlations with the symptoms that define psychosis and are tied to the neurobiological systems and computational mechanisms implicated in these symptoms. To promote accessibility, we utilize behavioral tasks that could be administered over the internet; this will set the stage for later research testing widespread screening that would identify those most in need of in-depth assessment. To reach that goal we first need determine which tasks are effective for predicting illness course and how this strategy compares to published prediction methods. We propose to recruit 500 CHR participants, 500 help-seeking individuals, and 500 healthy controls across 5 sites with the following Aims: Aim 1A) To develop a psychosis risk calculator through the application of machine learning (ML) methods to the measures from the PSDS battery. In an exploratory ML historical analysis, we will determine the added value of combining the PSDS with self-report measures and predicators;Aim 1B) We will evaluate group differences on the risk calculator score and hypothesize that the risk calculator score of the CHR group will differ from help-seeking and healthy controls. We further hypothesize that the risk calculator score of the CHR converters will differ significantly from groups of CHR nonconverters, help-seeking and healthy controls. The inclusion of a help-seeking group is critical for translating the risk-calculator into clinical practice, where the goal is to differentiate those at greatest risk for psychosis from those with other forms of psychopathology; Aim 1C): Evaluate how baseline PSDS performance relates to symptomatic outcome 2 years later examining: 1) symptomatic worsening treated as a continuous variable, and 2) conversion to psychosis. We hypothesize that the PSDS calculator: 1) will predict symptom course and, 2) that the differences observed between converters and nonconverters will be larger on the PSDS calculator than on the NAPLS calculator. Aim 2) Use ML methods, as above, to develop calculators that predict: 2A) social, and, 2B) role function deterioration, both observed over two years. Because negative are more strongly linked to functional outcome than positive symptoms, we predict that negative mechanism tasks will be the strongest predictor of functional decline in both domains.This project will provide a next-generation CHR battery, tied to illness mechanisms and powered by cutting-edge computational methods that can be used to facilitate the earliest possible detection of psychosis risk. Narrative  Early detection of young people at clinical high risk for psychosis offers a critical opportunity for early intervention to improve the course of illness, and perhaps even prevent onset entirely. Current interview-based methods for psychosis risk detection lack specificity, and are only available in a handful of research centers in the United States. The proposed study aims to improve accessibility and broaden impact of high risk screening by testing brief computerized measures, ultimately able to be administered on the internet, and to improve prediction by focusing on tasks specific to underlying mechanisms driving emerging psychotic symptoms.",2/5 CAPER Computerized assessment of psychosis risk,9978241,R01MH120088,"['Address', 'American', 'Attenuated', 'Automobile Driving', 'Behavioral', 'Biological Markers', 'Classification', 'Clinical', 'Collaborations', 'Computing Methodologies', 'Detection', 'Deterioration', 'Diagnosis', 'Dimensions', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Foundations', 'Frequencies', 'Functional disorder', 'Generations', 'Goals', 'Human Resources', 'Individual', 'Internet', 'Intervention Trial', 'Interview', 'Joints', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Outcome', 'Participant', 'Patient Self-Report', 'Performance', 'Population', 'Predictive Value', 'Preventive Intervention', 'Primary Prevention', 'Psychopathology', 'Psychotic Disorders', 'Public Health', 'Publishing', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk', 'Role', 'Sample Size', 'Secondary Prevention', 'Sensitivity and Specificity', 'Severities', 'Site', 'Specificity', 'Symptoms', 'System', 'Techniques', 'Test Result', 'Testing', 'Training', 'Translating', 'United States', 'Work', 'Youth', 'base', 'clinical practice', 'cognitive testing', 'computerized', 'design', 'follow-up', 'functional decline', 'functional outcomes', 'help-seeking behavior', 'high risk', 'high risk population', 'improved', 'machine learning method', 'new therapeutic target', 'next generation', 'prevent', 'psychotic symptoms', 'recruit', 'relating to nervous system', 'screening', 'social', 'trait']",NIMH,NORTHWESTERN UNIVERSITY,R01,2020,377685,66720547,0.0031692893881603633
"A Quantitative Risk Model for Predicting Outcome and Identifying Structural Biomarkers of Treatment Targets in Oral Cancer on a Large Multi-Center Patient Cohort Post-resection prognostication for oral cavity cancers (OCC) is qualitative and potentially ambiguous. A significant subset (25-37%) of Stage I/II patients still develop local recurrence after treatment with surgery alone. The long-term goal of this proposal will be to create a Quantitative Risk Model (QRM) using machine learning and artificial intelligence to predict recurrence risk for Stage I/II patients using image-based biomarkers of aggression. The objective is to develop and validate state-of-the-art systems for biomarker imaging, quantification, and modeling to accurately predict risk of recurrence in cancer patients based on image analytics. The central hypothesis is that a quantitative, artificial intelligence approach to pathology will result in significantly greater prognostic value compared with manual microscope-based analysis. The rationale for this work is that tumor aggression can be predicted from patterns present in pathology images, given the existence of histological risk models that have been clinically validated in the past; however, these risk models are not in widespread use because they are less accurate, robust, and transportable to the larger community of pathologists. This proposal will test the central hypothesis through three specific aims: (1) Develop an analysis pipeline that can accurately predict recurrence risk for Stage I/II OCC patients and identify treatment targets (e.g. adaptive local immune response and angiogenesis); (2) Demonstrate robust performance across a multi-site data cohort collected from seven national and international centers; and (3) Distil the results of QRM analysis to synoptic pathology reporting, demonstrating the ability of QRM to interface with standard clinical reporting tools. The innovation for addressing these aims comes from a unique application of active learning for training artificial intelligence to recognize tissue structures, new features for quantifying tissue architecture based on the interface between tumor and host, and a novel approach for large cross-site validation. Moreover, this proposal develops a unique mapping between computational pathology and commonly-used synoptic reporting variables, enabling rapid uptake of this work into existing clinical workflows. This research is significant because it provides personalized outcome predictions for a niche group of undertreated patients with limited options and can serve as the foundation for designing future clinical trials through identification of treatment targets. Multi-site training and evaluation, combined with AI-to-report mapping, will be broadly applicable to a large group of computational approaches, bridging the gap between engineering research labs and clinical application. The expected outcome of this work is a trained model for predicting Stage I/II OCC recurrence, identification of treatment targets, and mapping to synoptic reports, as well as a broadly-applicable workflow for the broader computational pathology community. This project will have a large positive impact on patients and surgical pathologists by enabling rapid, accurate prognosis and directed treatment plans in an easy-to-use pipeline that integrates seamlessly into existing clinical workflows. We aim to develop a quantitative risk model for oral cavity cancer patients, 25-37% of whom will experience debilitating post-treatment recurrence. Using state-of-the-art machine learning and artificial intelligence methods, we will develop and validate our risk model on a large multi-site cohort of patients, and develop an AI-assisted synoptic report-filling tool for integrating into clinical practice. A computational pathology approach to characterizing disease will help identify patients for whom aggressive multimodality therapy will improve outcomes and post-treatment quality of life.",A Quantitative Risk Model for Predicting Outcome and Identifying Structural Biomarkers of Treatment Targets in Oral Cancer on a Large Multi-Center Patient Cohort,9974099,R01DE028741,"['Active Learning', 'Address', 'Aftercare', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'Biological Markers', 'Blinded', 'Cancer Patient', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Collection', 'Combined Modality Therapy', 'Communities', 'Companions', 'Consensus', 'Country', 'Data', 'Databases', 'Disease', 'Elements', 'Engineering', 'Evaluation', 'Excision', 'Foundations', 'Future', 'Goals', 'Head and Neck Surgery', 'Head and neck structure', 'Histologic', 'Image', 'Immune response', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical Economics', 'Methods', 'Microscope', 'Modeling', 'Operative Surgical Procedures', 'Oral Stage', 'Outcome', 'Pathologist', 'Pathology', 'Pathology Report', 'Patients', 'Pattern', 'Performance', 'Play', 'Postoperative Period', 'Productivity', 'Quality of life', 'Radiation therapy', 'Randomized', 'Recurrence', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Risk', 'Salvage Therapy', 'Screening procedure', 'Semantics', 'Site', 'Slide', 'Specimen', 'Standardization', 'Structure', 'Surgical Pathology', 'System', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Work', 'Workload', 'analysis pipeline', 'angiogenesis', 'base', 'cancer recurrence', 'cancer type', 'clinical application', 'clinical practice', 'cohort', 'computational pipelines', 'deep learning', 'design', 'digital', 'digital pathology', 'expectation', 'experience', 'experimental study', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'improved outcome', 'innovation', 'international center', 'malignant mouth neoplasm', 'novel strategies', 'outcome forecast', 'outcome prediction', 'pathology imaging', 'patient oriented', 'predictive modeling', 'pressure', 'prognostic', 'prognostic value', 'quality assurance', 'quantitative imaging', 'screening', 'segmentation algorithm', 'tool', 'treatment planning', 'tumor', 'uptake']",NIDCR,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2020,382900,73424103,-0.03245166695807907
"Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data ABSTRACT Since early January 2020, our interdisciplinary research team has conducted several studies to elucidate the emerging threat of COVID-19 and support public health responses throughout the United States, resulting in peer-reviewed publications, online COVID-19 forecasting tools, and extensive engagement with city, state and national decision makers. In our collaboration with the CDC to develop a national modeling resource for pandemic preparedness, we had recently developed a national model for evaluating multi-layered intervention strategies to contain and mitigate outbreaks in US cities. We adapted the model to COVID-19 by incorporating the latest estimates for age- and risk-group specific rates of transmission, disease progression, asymptomatic infections, and severity (including risks of hospitalization, critical care, ventilation and death). The model is designed to flexibly incorporate combinations of social distancing, contact tracing-isolation, antiviral prophylaxis and treatment, as well as vaccination strategies. Our Supplementary Aims propose to build a more granular and data-driven model of COVID-19 to elucidate the transmission, identify high-risk populations, surveillance targets and effective control of this and future epidemics within US cities. Aim S1: Focusing initially on the Austin-Round Rock metropolitan area in Texas, we will apply these models to improve real-time risk assessments and optimize the timing and extent of layered social distancing measures. Aim S2: We will rapidly evaluate strategies for rolling out antiviral prophylaxis and therapy based on clinical trial data. Aim S3: We will develop user interfaces for our Austin and national models to support both scientific research and public health efforts to mitigate COVID-19 and plan for future pandemic threats. These Aims are synergistic with Specific Aim 2 of our parent grant (R01 AI151176-01), in which we are developing high-resolution models of viral transmission to improve the early detection and control of anomalous respiratory viruses, particularly in at risk populations. NARRATIVE Our Supplementary Aims will accelerate the development of a flexible and granular model of COVID-19 emergence, transmission and control within US cities. Leveraging unprecedented data and a high level engagement with city and state leadership in the Austin-Round Rock MSA and Texas, we will rapidly improve our existing models to evaluate strategies for real-time surveillance and multifaceted interventions including non-pharmaceutical measures (eg, adaptive social distancing and cocooning of high risk populations) as well as future antiviral drugs to mitigate COVID-19. Finally, we will develop user-friendly interfaces for our models to support research and public health decision making for COVID-19 and future pandemic threats.","Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data",10150283,R01AI151176,"['Age', 'Antiviral Agents', 'Area', 'COVID-19', 'Categories', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Cities', 'Clinical Trials', 'Collaborations', 'Contact Tracing', 'Critical Care', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Disease Progression', 'Dose', 'Early Diagnosis', 'Economics', 'Epidemic', 'Epidemiology', 'Funding', 'Future', 'Health Care Costs', 'Hospitalization', 'Human', 'Individual', 'Infection', 'Influenza', 'Interdisciplinary Study', 'Intervention', 'Leadership', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Neighborhoods', 'Peer Review', 'Pharmacologic Substance', 'Policy Maker', 'Population Surveillance', 'Populations at Risk', 'Prophylactic treatment', 'Public Health', 'Publications', 'Readiness', 'Research', 'Research Support', 'Resolution', 'Resources', 'Risk', 'Risk Assessment', 'Science', 'Scientist', 'Severities', 'Social Distance', 'Testing', 'Texas', 'Time', 'United States', 'Update', 'Vaccines', 'Viral', 'Visualization', 'austin', 'base', 'cost', 'design', 'evidence base', 'flexibility', 'high risk', 'high risk population', 'improved', 'metropolitan', 'mortality', 'multi-component intervention', 'pandemic disease', 'pandemic preparedness', 'parent grant', 'prevent', 'respiratory virus', 'response', 'social', 'socioeconomics', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy', 'ventilation', 'viral transmission']",NIAID,YALE UNIVERSITY,R01,2020,387199,550947887,-0.0030564764277807533
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,9942461,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Models', 'Cornea', 'Corneal Diseases', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Structure', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2020,391938,197030888,-0.007934041793089102
"Genomic and Phenomic Architecture of Heart Failure The overarching goal of this project is to improve care for patients with heart failure (HF). HF, whether with reduced (HFrEF) or preserved (HFpEF) ejection fraction, is associated with significant morbidity, mortality, and cost. In the U.S. alone, HF affects over 5 million adults, and the prevalence is projected to exceed 8 million by 2030. HF is the most frequent cause of hospitalization among Medicare recipients and results in over $30 billion in health care expenditures each year. Advances in management, especially for HFrEF, have modestly reduced death rates over time, but mortality continues to be high, with approximately half of patients dying within 5 years of diagnosis. Moreover, the pace of drug discovery has been slow, and there are no proven therapies for patients suffering with HFpEF. Among patients with established HF there is substantial variation in illness severity, degree of cardiac remodeling, disease progression, and response to therapy. These observations highlight the heterogeneity of the HF syndrome and suggest existence of subtypes with differing clinical and potentially genetic profiles, with subsequent differences in downstream disease mechanisms, overall risk, and therapeutic response. However, the understanding of the phenotypic, genetic, and pathophysiological heterogeneity of HF is incomplete. This project investigates the phenotypic substructure and genetic architecture of HF by leveraging a unique collection of interrelated datasets from Vanderbilt University Medical Center (VUMC), including the de- identified electronic health record (EHR) and BioVU, a linked DNA biobank. The EHR contains ~2.6 million patients, including ~35,000 with HF, and BioVU currently houses >225,000 DNA samples. Dense genotype data are available in >28,000 subjects and an institutional genotyping project will increase this to >125,000 by mid- 2017; this includes >13,000 subjects with HF. The proposed research will: 1) identify HF subtypes from dense clinical data alone using advanced, unbiased, deep learning algorithms (Aim 1), 2) define the genetic architecture of HF and HF subtypes by using inferred gene expression, general linear mixed models, genetic risk scores, and traditional association testing to quantify heritability of and genetic correlations among HF subtypes, define the contribution of established risk factors to HF subtypes, and 3) discover subtype-specific genetic risk factors (Aim 2), and discover HF subtype-specific clinical outcomes, disease associations, and drug response phenotypes using advanced phenome scanning and network analysis (Aim 3). Heart failure (HF) is a complex, debilitating syndrome associated with significant morbidity and mortality. The heterogeneity of HF has limited success of prior efforts to understand HF pathobiology and develop effective interventions. By defining clinical and genetic modifiers of HF risk, disease course, and treatment response for clinically recognized and novel, data-driven HF subtypes, results from this work could result in a more sophisticated HF classification system based on underlying biology, and ultimately facilitate precision risk stratification, tailoring of therapeutic strategies, and rational HF clinical trials.",Genomic and Phenomic Architecture of Heart Failure,9841436,R01HL140074,"['Academic Medical Centers', 'Adult', 'Affect', 'Architecture', 'Biological', 'Biology', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular Diseases', 'Cardiovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collection', 'Complex', 'Consensus', 'DNA', 'Data', 'Data Set', 'Death Rate', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'EFRAC', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Etiology', 'Failure', 'Gene Expression', 'Genetic', 'Genetic Heterogeneity', 'Genetic Risk', 'Genetic Transcription', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health Expenditures', 'Heart failure', 'Heritability', 'Heterogeneity', 'Hospitalization', 'Human', 'Link', 'Measures', 'Mediator of activation protein', 'Medical', 'Medical Genetics', 'Medicare', 'Modeling', 'Morbidity - disease rate', 'Myocardial dysfunction', 'Natural History', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Prevalence', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Sampling', 'Scanning', 'Severity of illness', 'Subgroup', 'Syndrome', 'System', 'Testing', 'Therapeutic', 'Time', 'Variant', 'Work', 'base', 'biobank', 'cohort', 'comorbidity', 'cost', 'deep learning', 'deep learning algorithm', 'defined contribution', 'disease phenotype', 'drug discovery', 'effective intervention', 'genetic architecture', 'genetic association', 'genetic profiling', 'genetic risk factor', 'genome wide association study', 'genomic data', 'improved', 'learning strategy', 'mortality', 'novel', 'phenome', 'phenomics', 'preservation', 'response', 'risk variant', 'success', 'treatment response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,395000,377931988,-0.005287641018704864
"Modeling Homeostasis of Human Blood Metabolites PROJECT SUMMARY  Metabolite levels in human blood are regulated by a relatively strict system of homeostatic control. Previous investigations of homeostasis have taken a number of approaches, and models of glucose and a few other metabolites have been developed, typically focused on a single organ. However, while potentially extremely useful, an accurate and quantitative model of blood metabolite levels under homeostasis does not currently exist.  It is well known that numerous demographic and clinical factors such as gender, age, BMI, smoking, etc., as well as pre-analytical factors and many diseases, significantly affect the levels of blood metabolites. Numerous studies in the field of metabolomics have attempted to account for the effects of many such factors. However, efforts to quantify these effects and validate them across different studies have so far been challenging, and resulted in consistent failures to validate discovered putative biomarkers. The challenges to integrate metabolite profiles with clinical and demographic factors are complicated by the high dimensionality of the data and the numerous correlations among the metabolites. Traditional statistical methods are incapable of accounting for these factors, and hence, investigations suffer from a high false discovery rate (FDR).  To overcome these challenges, we propose to develop quantitative statistical models of blood metabolite levels in healthy adults, and thereby produce a predictive model of homeostasis. Our preliminary work indicates that we can predict metabolite levels with much reduced variance using the reproducibly measured levels of a large pool of blood metabolites and clinical and demographic variables. We propose to develop sophisticated models of homeostasis based on advanced statistical methods and evaluate their predictive performance across different sample sets and metabolite classes.  The proposed project has four main Aims: (1) Obtain broad-based metabolomics data on blood samples collected from geographically distinct sites to explore the effects of a range of confounding effects on metabolite levels. (2) Model individual or biologically related groups of metabolite levels using multivariate statistical approaches to determine the contribution of clinical/demographic and pre-analytical variables and their predictability across collection site. (3) Investigate the interactions between metabolites and clinical/demographic variables using machine learning approaches to identify stable metabolites and key interactions. (4) Provide the community with user-friendly software packages for the prediction of blood metabolite levels under homeostasis.  An overall model of the metabolite concentrations in blood will be highly useful for a number of applications that include a better understanding of systems biology at the whole organism level, and ultimately improved risk prediction, disease diagnosis, treatment monitoring and outcomes analysis. PROJECT NARRATIVE A quantitative model of blood homeostasis based on predicting the normal levels of small molecules in the blood can help identify diseases or other stresses that cause changes to those levels. The proposed statistical methods that will be used to develop this homeostasis model have the potential to efficiently identify more reliable disease markers and to more accurately predict disease risk.",Modeling Homeostasis of Human Blood Metabolites,9995722,R01GM131491,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biometry', 'Blood', 'Blood specimen', 'Clinical', 'Collection', 'Communities', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Demographic Factors', 'Development', 'Dimensions', 'Disease', 'Disease Marker', 'Evaluation', 'Failure', 'Gases', 'Gender', 'Geographic Locations', 'Geography', 'Glucose', 'Homeostasis', 'Human', 'Individual', 'Investigation', 'Ions', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolite Interaction', 'Modeling', 'Monitor', 'NMR Spectroscopy', 'Organ', 'Outcome', 'Performance', 'Risk', 'Sampling', 'Site', 'Smoking', 'Source', 'Statistical Methods', 'Statistical Models', 'Stress', 'Supervision', 'System', 'Systems Biology', 'Technology', 'Temperature', 'Time', 'Training', 'Validation', 'Whole Organism', 'Work', 'base', 'clinical effect', 'cohort', 'computerized tools', 'data quality', 'disease diagnosis', 'disorder risk', 'improved', 'interoperability', 'metabolome', 'metabolomics', 'multidimensional data', 'predictive modeling', 'sample collection', 'small molecule', 'software development', 'user friendly software', 'user-friendly', 'validation studies']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,395738,533302350,-0.0017460768591577797
"Advanced Risk Adjusters and Predictive Formulas for ICD-10 Based Risk Adjustment Diagnosis-based risk adjustment is widely used in the US and abroad for health plan payment, notably for Medicare Parts C and D, for commercial contracting and quality assessment, and in numerous state Medicaid programs. Yet the risk adjustment technology used for payments has not kept up with improved classification systems, larger patient datasets, improved estimation algorithms or recent theoretical and clinical developments. Our work will take advantage of the richer ICD-10-CM classification system, in use since October 2015, with over 5 times as many diagnoses as ICD-9-CM Codes. ICD-10 codes now recognize: left vs. right side for thousands of conditions, distinguish between initial, subsequent and sequela diagnoses, and incorporate hundreds of new clinical, demographic and biometric variables. Based on the ICD-10, more exact models can leverage increased diagnostic coding accuracy to reduce opportunities for gaming or discriminating against patients with conditions who are predicted to be unprofitable. Led by two of the three developers of the Centers for Medicare and Medicaid Services Hierarchical Condition Category (CMS-HCC) existing classification system, our team of physicians, public policy experts, statisticians and economists will comprehensively improve the accuracy of risk adjustment and predictive models using larger sample sizes, clinical judgment and state-of-art economic and statistical modeling. We will also expand the conventional regression methods explored, to include machine learning algorithms, constrained regression, and LASSO estimation. We will calculate a new “appropriateness to include” (ATI) score that captures diagnostic vagueness, discretion and suitability for use in risk adjustment models, and use this score to inform which variables are included in plan payment formulas. Selection incentives remain of concern in public US health plan payments formulas and may be costing Medicare over $5 billion per year (NBER 2017). Prediction and payment models from this project can reduce overpayment and offset plan incentives to skimp on services that attract sick people. To ensure that these models and formulas are useful for enrollees of all ages, they will initially be calibrated and tested on large commercially-insured claims data, covering ages 0 to 64. They will then be validated and refined for Medicare, Medicaid, and state employees using data from All-Payer Claims Data from five states and a second large commercial dataset. We will make development steps, statistical programs, and full details of the classification system and prediction formulas publicly available for comment, refinement, and use by health care delivery system researchers, payers and providers. Project Narrative This project will develop new classification systems and new prediction and payment models that take advantage of the fivefold increase in diagnostic codes available with the October 2015 change from ICD- 9-CM to ICD-10-CM. Using data from two national claims datasets and five state all-payer claims datasets that collectively cover over 75 million enrollees, we will identify new, underutilized ICD-10 capabilities, create new clusters of diagnoses useful for prediction, develop new algorithms for using these clusters, and estimate formulas that predict spending, utilization and diverse health care outcomes for all ages. Methods and results will be publicly described and software posted on the web for use in risk adjustment and diverse clinical, financial, policy evaluation, and quality assessment outcomes by health care delivery system researchers, payers and providers.",Advanced Risk Adjusters and Predictive Formulas for ICD-10 Based Risk Adjustment,9965911,R01HS026485,[' '],AHRQ,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2020,399950,61050884,0.0072826792958493505
"SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring This project aims to develop an interpretable, physician-in-the-loop AI-aided software that accurately delineates glioma boundaries in MRIs, computes volumetric curves, and statistically quantifies the tumor growth in longitudinal studies. The current clinical practice of visually analyzing and manually contouring tumors is subjective, time-consuming, and often inconsistent. The novelty of MRIMath's explainable, trustworthy, and physician-in-the-loop AI system is multi-fold. First, we introduce a multi-scale feature extraction framework using the inception modules in contracting and expanding paths of the U-Net image segmentation neural network architecture. Second, we propose a new loss function based on the modified Dice similarity coefficient. Third, we train and test the AI system using two learning regimes: learning to segment intra-tumoral structures and learning to segment glioma sub-regions. Finally, we produce heat maps to visualize the features extracted by the AI, thus offering physicians a view of AI's attention patterns and activation maps that were triggered during AI's decision-making. An intuitive and interactive User Interface will allow the physician to review contouring results, make adjustments and approve contours, visualize AI's explanations and volumetric measurements, and finally review the results of the statistical analysis. Any modifications made by the physician will be used later to re-train AI. n/a","SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10269837,5N91020C00049,"['Artificial Intelligence', 'Attention', 'Computer software', 'Consumption', 'Contracts', 'Data', 'Data Sources', 'Decision Making', 'Diagnosis', 'Glioma', 'Human', 'Intuition', 'Learning', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measurement', 'Modality', 'Modification', 'Monitor', 'Pattern', 'Phase', 'Physicians', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'System', 'Testing', 'Time', 'TimeLine', 'Training', 'base', 'cancer imaging', 'cancer prevention', 'clinical practice', 'design', 'feature extraction', 'imaging Segmentation', 'imaging software', 'imaging system', 'loss of function', 'neural network architecture', 'prototype', 'tumor', 'tumor growth', 'usability']",NCI,"MRIMATH, LLC",N43,2020,400000,400000,-0.030123854429294106
"4/5 CAPER: Computerized assessment of psychosis risk Summary  Research suggests that early identification of individuals at clinical high risk (CHR) for psychosis may be able to improve illness course. Studies suggest that early identification of CHR using specialized interviews with help-seeking individuals (with attenuated psychosis symptoms) is a useful approach. This work has two major limitations: 1) interview methods have limited specificity as only 20% of CHR individuals convert to psychosis, and 2) the expertise needed to make CHR diagnosis is only accessible in a few academic centers. We propose to develop a new psychosis symptom domain sensitive (PSDS) battery, prioritizing tasks that show correlations with the symptoms that define psychosis and are tied to the neurobiological systems and computational mechanisms implicated in these symptoms. To promote accessibility, we utilize behavioral tasks that could be administered over the internet; this will set the stage for later research testing widespread screening that would identify those most in need of in-depth assessment. To reach that goal we first need determine which tasks are effective for predicting illness course and how this strategy compares to published prediction methods. We propose to recruit 500 CHR participants, 500 help-seeking individuals, and 500 healthy controls across 5 sites with the following Aims: Aim 1A) To develop a psychosis risk calculator through the application of machine learning (ML) methods to the measures from the PSDS battery. In an exploratory ML analysis, we will determine the added value of combining the PSDS with self-report measures and historical predicators; Aim 1B) We will evaluate group differences on the risk calculator score and hypothesize that the risk calculator score of the CHR group will differ from help-seeking and healthy controls. We further hypothesize that the risk calculator score of the CHR converters will differ significantly from groups of CHR nonconverters, help-seeking and healthy controls. The inclusion of a help-seeking group is critical for translating the risk-calculator into clinical practice, where the goal is to differentiate those at greatest risk for psychosis from those with other forms of psychopathology; Aim 1C): Evaluate how baseline PSDS performance relates to symptomatic outcome 2 years later examining: 1) symptomatic worsening treated as a continuous variable, and 2) conversion to psychosis. We hypothesize that the PSDS calculator: 1) will predict symptom course and, 2) that the differences observed between converters and nonconverters will be larger on the PSDS calculator than on the NAPLS calculator. Aim 2) Use ML methods, as above, to develop calculators that predict: 2A) social, and, 2B) role function deterioration, both observed over two years. Because negative symptoms are more strongly linked to functional outcome than positive symptoms, we predict that negative symptom mechanism tasks will be the strongest predictor of functional decline in both domains. This project will provide a next-generation CHR battery, tied to illness mechanisms and powered by cutting-edge computational methods that can be used to facilitate the earliest possible detection of psychosis risk. Narrative  Early detection of young people at clinical high risk for psychosis offers a critical opportunity for early intervention to improve the course of illness, and perhaps even prevent onset entirely. Current interview-based methods for psychosis risk detection lack specificity, and are only available in a handful of research centers in the United States. The proposed study aims to improve accessibility and broaden impact of high risk screening by testing brief computerized measures, ultimately able to be administered on the internet, and to improve prediction by focusing on tasks specific to underlying mechanisms driving emerging psychotic symptoms.",4/5 CAPER: Computerized assessment of psychosis risk,9983971,R01MH120092,"['Address', 'American', 'Attenuated', 'Automobile Driving', 'Behavioral', 'Biological Markers', 'Classification', 'Clinical', 'Collaborations', 'Computing Methodologies', 'Detection', 'Deterioration', 'Diagnosis', 'Dimensions', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Foundations', 'Frequencies', 'Functional disorder', 'Generations', 'Goals', 'Human Resources', 'Individual', 'Internet', 'Intervention Trial', 'Interview', 'Joints', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Outcome', 'Participant', 'Patient Self-Report', 'Performance', 'Population', 'Predictive Value', 'Preventive Intervention', 'Primary Prevention', 'Psychopathology', 'Psychotic Disorders', 'Public Health', 'Publishing', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk', 'Role', 'Sample Size', 'Secondary Prevention', 'Sensitivity and Specificity', 'Severities', 'Site', 'Specificity', 'Symptoms', 'System', 'Techniques', 'Test Result', 'Testing', 'Training', 'Translating', 'United States', 'Work', 'Youth', 'base', 'clinical practice', 'cognitive testing', 'computerized', 'design', 'follow-up', 'functional decline', 'functional outcomes', 'help-seeking behavior', 'high risk', 'high risk population', 'improved', 'machine learning method', 'new therapeutic target', 'next generation', 'prevent', 'psychotic symptoms', 'recruit', 'relating to nervous system', 'screening', 'social', 'trait']",NIMH,UNIVERSITY OF GEORGIA,R01,2020,401699,80786674,0.0019004158948692567
"Big Data Methods for Comprehensive Similarity based Risk Prediction Project Summary Electronic health records (EHR) provide rich source of data about representative populations and are yet to be fully utilized to enhance clinical decision-making. Conventional approaches in clinical decision-making start with the identification of relevant biomarkers based on subject-matter knowledge, followed by detailed but limited analysis using these biomarkers exclusively. As the current scientific literature indicates, many human disorders share a complex etiological basis and exhibit correlated disease progression. Therefore, it is desirable to use comprehensive patient data for patient similarity. This proposal focuses on deriving a comprehensive and integrated score of patient similarity from complete patient characteristics currently available, including but not limited to 1) demographic similarity; 2) genetic similarity; 3) clinical phenotype similarity; 4) treatment similarity; and 5) exposome similarity (here exposome defined as all available attributes of the living environment an individual is exposed to), when some of the aspects may overlap and interact. We will optimize information fusion and task-dependent feature selection for assessing patient similarity for clinical risk prediction. Since currently there does not exist a pipeline that is able to extract executable complete patient determinant data, to achieve the research goal described above, we propose first deliver an open- source data preparation pipeline that is based on a widely used clinical data standard, the OMOP (Observational Medical Outcomes Partnership) Common Data Model (CMD) version 5.2. Moreover, to mitigate common missingness and sparsity challenges in clinical data, we describe the first attempt to represent patients' sparse clinical information with missingness, including diagnosis information, medication data, treatment intervention, with a fixed-length feature vector (i.e. the Patient2Vec). This project has four specific aims. Aim 1 is to develop a clinical data processing pipeline for harmonizing patient information from multiple sources into a standards-based uniformed data representation and to evaluate its efficiency, interoperability, and accuracy. Aim 2 is to leverage a powerful machine learning technique, Document2Vec, from the natural language processing literature, to create an open-source Patient2Vec framework for the derivation of informative numerical representations of patients. Aim 3 is to develop a unified machine learning clinical- outcome-prediction framework for Optimized Patient Similarity Fusion (OptPSF) that integrates traditional medical covariates with the derived numerical patient representations from Patient2Vec (Aim 2) for improved clinical risk prediction. Aim 4 is to evaluate our similarity framework for predicting 1) the risk of end-stage kidney disease (ESKD) in general EHR patient population and 2) the risk of death among patients with chronic kidney disease (CKD). The project focus on developing a novel data science pipeline which includes a clinical data processing pipeline to format comprehensive patient health determinants from a variety of sources of clinical, genomic, socioenvironmental data, and a clinical-outcome-prediction framework that optimally fuses relevant patient health determinants to define patient similarity for improved clinical risk predictions.",Big Data Methods for Comprehensive Similarity based Risk Prediction,9870948,R01LM013061,"['Address', 'Automation', 'Big Data', 'Big Data Methods', 'Biological Markers', 'Biological Process', 'Biometry', 'Case Study', 'Characteristics', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complex', 'Data', 'Data Reporting', 'Data Science', 'Derivation procedure', 'Diagnosis', 'Disease', 'Disease Progression', 'Electronic Health Record', 'End stage renal failure', 'Environment', 'Etiology', 'Exhibits', 'Exposure to', 'Genetic', 'Genomics', 'Goals', 'Health', 'Health Professional', 'Healthcare', 'Heterogeneity', 'Human', 'Individual', 'Informatics', 'Interdisciplinary Study', 'Intervention', 'Knowledge', 'Length', 'Life', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Preparation', 'Reporting', 'Reproducibility', 'Research', 'Risk', 'Social Environment', 'Source', 'Surveys', 'Techniques', 'base', 'biomedical informatics', 'clinical decision support', 'clinical decision-making', 'clinical phenotype', 'clinical risk', 'data analysis pipeline', 'data modeling', 'data standards', 'design', 'disease diagnosis', 'feature selection', 'health data', 'improved', 'interoperability', 'mortality risk', 'novel', 'open data', 'open source', 'outcome prediction', 'patient health information', 'patient population', 'precision medicine', 'predict clinical outcome', 'socioeconomics', 'support tools', 'vector']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,420434,558628098,-0.01769055191253724
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,10024094,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'behavioral phenotyping', 'comorbidity', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2020,422740,560644462,-0.004162850399398118
"Stakeholder Guidance to Anticipate and Address Ethical Challenges in Applications of Machine Learning and Artificial Intelligence in Algorithmic Medicine: a Novel Empirical Approach PROJECT ABSTRACT The potential for artificial intelligence applications, specifically machine learning, to prevent, predict, and help manage disease sparks immense hope not only for the individuals affected, but also for the overall health of populations. Particularly exciting examples of these novel computing strategies are increasingly found in the development of deep learning algorithms for medical use. Already embedded in our daily lives, algorithms have begun to impact human-decision making, from recruitment and hiring of employees to criminal sentencing. Outside of medicine, recognition of the ways algorithms may reflect, reproduce, and perpetuate bias has led to an explosion of theoretical and empirical research on the subject. There is an increasing awareness of potential algorithmic weaknesses, including some that raise concerns about fundamental issues of fairness, justice, and bias. The need to anticipate and address emerging ethical issues in algorithmic medicine is time- sensitive. As health care systems increasingly utilize algorithms for patient identification, diagnosis, and treatment direction, the consequences of algorithmic bias yield real and significant costs. Numerous stakeholders are responsible for the development, application and interpretation of algorithms in medicine, and yet there has been very little engagement of stakeholders most affected by these learning systems and tools. The overarching goal of this empirical and hypothesis driven project is to articulate the landscape of ethical concerns and the issues emerging in the context of the development, refinement, and application of machine learning in algorithmic medicine. First, we determine the distinct ethical issues and problems encountered in the development, refinement, and application of machine learning, by querying the perspectives of a diverse array of stakeholders involved—machine learning researchers, clinicians, ethicists, and patients. Using the new insights generated from the first half, we will conduct an evidence-based, information-sharing vignette survey to understand the impact of the contexts of algorithms on the ethically salient perspectives of physicians—those poised to implement such innovation in their own decision-making for the care of patients. Maximizing our established record of expertise in empirical ethics investigations, this sequence of projects leverages access to the exceptional machine learning research conducted at Stanford University, including work by NIH-funded investigators, and provides extensive, systematically collected data on ethical issues encountered and anticipated throughout the development and implementation of algorithms. Finally, the project develops and refines an evidence-informed information-sharing survey for use in better understanding how physicians react to intelligent systems. PROJECT NARRATIVE  Machine learning-driven algorithmic medicine now faces an urgent need to anticipate and address emerging ethical issues. For machine learning applications in algorithmic medicine, the failure to examine ethical issues from the perspective of stakeholders will inevitably limit the ecological validity and utility of the algorithms and threaten society's future embrace of these innovations. A hypothesis-driven, empirical study is needed to anticipate and address ethical concerns, and provide clinicians, machine learning researchers, policymakers, and the public with evidence to better enable ethical application and translation of algorithms in medicine.",Stakeholder Guidance to Anticipate and Address Ethical Challenges in Applications of Machine Learning and Artificial Intelligence in Algorithmic Medicine: a Novel Empirical Approach,10099785,R01TR003505,"['Address', 'Adoption', 'Affect', 'Agreement', 'Algorithm Design', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Attitude', 'Awareness', 'Clinical', 'Clinical Investigator', 'Complex', 'Data', 'Decision Making', 'Development', 'Diagnosis', 'Dimensions', 'Disclosure', 'Disease Management', 'Effectiveness', 'Empirical Research', 'Employee', 'Ensure', 'Ethical Issues', 'Ethicists', 'Ethics', 'Evaluation', 'Expert Systems', 'Explosion', 'Face', 'Failure', 'Familiarity', 'Funding', 'Future', 'Goals', 'Health', 'Healthcare Systems', 'Human', 'Human Resources', 'Individual', 'Interview', 'Investigation', 'Judgment', 'Justice', 'Knowledge', 'Learning', 'Machine Learning', 'Medical', 'Medicine', 'Methodology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Perception', 'Persons', 'Physicians', 'Play', 'Randomized', 'Research', 'Research Personnel', 'Role', 'Science', 'Shapes', 'Societies', 'Structure', 'Surveys', 'System', 'Time', 'Training', 'Translations', 'Trust', 'United States National Institutes of Health', 'Universities', 'Work', 'clinical decision-making', 'clinical risk', 'cost', 'court', 'deep learning algorithm', 'evidence base', 'experience', 'improved', 'innovation', 'insight', 'meetings', 'multidisciplinary', 'novel', 'patient population', 'population health', 'precision medicine', 'prevent', 'recruit', 'response', 'tool']",NCATS,STANFORD UNIVERSITY,R01,2020,429327,560644462,-0.0065110678473314625
"Clinical Evaluation of Burns using Spatial Frequency Domain Imaging Program Director/Principal Investigator (Last, First, Middle): Durkin, Anthony J. Abstract The central aim of this 3 year competing R01 renewal is to characterize and apply a new, compact, clinic- friendly Spatial Frequency Domain Imaging (SFDI) device to objectively and non-invasively classify burn severity (burn grade) over a large areas of skin. Delays in determining burn severity directly impacts patient treatment plans (including decisions whether to graft), rates of infection and scarring, duration of hospitalization and ultimately cost of care. Currently, the primary method of determining burn severity continues to be clinical assessment, which is highly subjective. While both superficial thickness and full-thickness burns are typically readily diagnosed based on visual clinical impression, partial thickness burns are difficult to classify and carry with them considerable potential for complications. Burn severity classification accuracy, even by experts, is only 60–80%. Our research in animal models demonstrates that SFDI data can successfully be used to classify different regions of burn severities. Typically, these differences are not apparent to the unaided eye and a great deal of training and experience is required in order for clinicians to accurately differentiate them Our work using a research grade, hybrid-SFDI device suggests that objective parameters provided by SFDI can be used within 24 hours after injury, to accurately classify burn severity. Specifically, we have demonstrated in a porcine burn model that the research grade SFDI outperforms laser speckle imaging and thermal imaging at 24 hours post-burn, in terms of predicting whether a burn will require a graft or not. However, translating these results to the clinic has been difficult due to several device limitations. The research grade SFDI device has slow acquisition times that can result in motion artifacts. It is also sensitive to ambient light which is often an issue in a clinical setting. Additionally, the SFDI device generates so much diverse data (oxygenated and deoxygenated hemoglobin, water fraction, reduced scattering coefficients at multiple wavelengths), there is no obvious way to present it to a clinical user to make a quick decision. To this end, we propose to methodically investigate an improved next generation SFDI device that addresses these issues by using brighter LEDs and fewer wavelengths to rapidly collect data in a way that reduces motion artifacts and is independent of clinical lighting conditions. In addition, we will develop a machine learning based classification framework that will provide the clinical with actionalble diagnostic information. The central aim of this 3 year competing R01 renewal is to characterize and then modify a new clinic-friendly SFDI device (Clarifi) to objectively classify in- vivo regions of different burn severity over large areas. The proposed research seeks to investigate this via the following Specific Aims: 1) Test & Validate Clinical SFDI Instrument, 2) Compare Clinical SFDI Instrument to other Modalities on a Long Term Swine Model of Graded Burns, 3) Develop Spatially Resolved Classification Maps of Burn Severity based on SFDI Data, 4) Conduct Clinical Measurements of Burn Severity using the new SFDI device and Spatially Resolved Burn Severity Classification Maps based on SFDI data. Program Director (Last, first, middle): Durkin, Anthony J. PROJECT NARRATIVE Burn injuries rank in the top 15 causes of global burden of disease. Burn severity assessment, which is a critical step in treatment planning, is subjective, depending on the experience of the treating physician. This leads to misdiagnosis and increased days of hospitalization and cost. In order to address this, we propose to test, validate and apply a novel optical imaging device in order to provide noninvasive objective assessment of burn wound severity. This has the potential to improve management of burn patients and reduce rates of complications.",Clinical Evaluation of Burns using Spatial Frequency Domain Imaging,10052657,R01GM108634,"['Address', 'Animal Model', 'Area', 'Biometry', 'Blood Vessels', 'Burn Centers', 'Burn injury', 'Cicatrix', 'Classification', 'Clinic', 'Clinical', 'Clinical assessments', 'Collaborations', 'Custom', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Enrollment', 'Eye', 'Family suidae', 'Female', 'Hemoglobin', 'Hospital Costs', 'Hospitalization', 'Hour', 'Hybrids', 'Image', 'Imaging Device', 'Injury', 'Laser Speckle Imaging', 'Lasers', 'Light', 'Lighting', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical center', 'Methods', 'Modality', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Optics', 'Output', 'Patients', 'Physicians', 'Principal Investigator', 'Property', 'Reporting', 'Research', 'Severities', 'Side', 'Signal Transduction', 'Skin', 'Spatial Frequency Domain Imaging', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translating', 'Ulcer', 'Variant', 'Visual', 'Water', 'Work', 'base', 'burden of illness', 'burn model', 'burn wound', 'care costs', 'clinical imaging', 'cost', 'data acquisition', 'data integrity', 'data modeling', 'diverse data', 'experience', 'healing', 'human data', 'imaging system', 'impression', 'improved', 'in vivo', 'infection rate', 'male', 'next generation', 'novel', 'optical imaging', 'pre-clinical', 'programs', 'research clinical testing', 'stability testing', 'treatment planning']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2020,430325,167717872,-0.006194160315471857
"Machine Learning to Optimize Management of Acute Hydrocephalus Patients 37,000 patients a year receive an external ventricular drain (EVD) in the setting of acute hydrocephalus in the US, generating in-hospital charges of $151,672 per patient, or $5.6 billion dollars a year. There is great motivation in the neurointensive care unit for the optimization of EVD management to reduce infection rates, accurately determine need for permanent shunting, and to do so efficiently in order to minimize duration of drainage and length of stay (LOS). Risk factors for ventriculitis include EVD duration, cerebrospinal fluid (CSF) sampling frequency, presence of intraventricular hemorrhage (IVH), and insertion technique. Severe CSF disturbances in patients with IVH and EVDs limit the value of routine CSF analysis for ventriculitis prediction. And ventriculitis diagnosis is imprecise, with only a minority declaring culture positivity while all still demanding antibiotic treatment and delay of permanent shunt. This leads to unnecessary empiric antibiotic treatment and increased LOS (30.8 vs 22.6 days), with the associated cost ($30,335 more) and morbidity (e.g. Clostridium difficile infection, emergence of drug-resistant pathology). The process of determining permanent shunt dependence is variable between institutions, particularly around the decision of when to begin weaning the EVD or predicting delayed resolution. These decisions in the subacute period determine LOS and associated adverse events, exposure to radiography, and commitment to potentially unnecessary permanent foreign materials in the CNS, which then carry lifelong risks for infection and blockage. There is no accurate noninvasive test (that does not further introduce infection) to diagnose ventriculitis nor is there a timely method to predict need for permanent shunt after acute hydrocephalus. To fill this gap, we propose developing a quantitative model from intracranial pressure (ICP) waveform analysis to increase precision in the diagnosis of ventriculitis and accurately predict need for permanent shunt. In previous work, we were able to predict with good accuracy who would need permanent shunt placement using ICP waveform analysis collected during a 24 hour clamp trial. However, a complex model can only be justified if it achieves a diagnosis earlier or more accurately than traditional clinical methods. In preliminary work, we clustered raw ICP waveforms and found a pattern of waveforms specific for ventriculitis that appears 1 day before diagnostic cultures are sent. Our central hypothesis is that there is a temporal quantitative signal in ICP waveform reflective of intracranial dynamics that can be harvested to optimize acute hydrocephalus management. Impact and Significance: Noninvasive quantitative models based on ICP waveform analysis that diagnose ventriculitis and accurately predict need for permanent shunt would decrease the duration of EVD and the frequency of CSF sampling, two of the risk factors for ventriculitis, while also decreasing LOS, associated adverse events of ICU stay, and empiric antibiotics. There is no accurate noninvasive test to diagnose ventriculitis nor is there a timely method to predict need for permanent shunt after acute hydrocephalus. To fill this gap, we propose developing a quantitative model from intracranial pressure waveform analysis to increase precision in the diagnosis of ventriculitis and accurately predict need for permanent shunt. Accurate noninvasive sequential machine learning models could decrease external ventricular drain duration and cerebrospinal fluid sampling frequency, two of the risk factors for ventriculitis, while also decreasing length of stay and empiric systemic antibiotics.",Machine Learning to Optimize Management of Acute Hydrocephalus Patients,10057040,R21NS113055,"['Acute', 'Adverse event', 'Antibiotic Therapy', 'Antibiotics', 'Caring', 'Cerebral hemisphere hemorrhage', 'Cerebrospinal Fluid', 'Cerebrospinal Fluid Proteins', 'Clinical', 'Clostridium difficile', 'Closure by clamp', 'Complex', 'Data', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Drainage procedure', 'Drug resistance', 'Early Diagnosis', 'Exposure to', 'Frequencies', 'Harvest', 'Healthcare', 'Hospital Charges', 'Hour', 'Hydrocephalus', 'Infection', 'Inflammatory', 'Information Retrieval', 'Institution', 'Intracranial Pressure', 'Learning', 'Length of Stay', 'Machine Learning', 'Methods', 'Minority', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Motivation', 'Natural Language Processing', 'Neuraxis', 'Neurosurgeon', 'Output', 'Pathology', 'Patients', 'Pattern', 'Process', 'Resolution', 'Risk', 'Risk Factors', 'Sampling', 'Shunt Device', 'Signal Transduction', 'Subarachnoid Hemorrhage', 'Techniques', 'Testing', 'Time', 'Translating', 'Ventricular', 'Weaning', 'Work', 'base', 'cost', 'improved', 'infection rate', 'infection risk', 'intraventricular hemorrhage', 'long short term memory', 'recurrent neural network', 'vector']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R21,2020,445500,558628098,-0.0019417860944634727
"Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models Project Summary Amyotrophic lateral sclerosis (ALS) and Frontotemporal Dementia FTD are devastating neurodegenerative disorders that lie on a genetic and mechanistic continuum. ALS is a disease of motor neurons that that is almost uniformly lethal within only 3-5 years of diagnosis. FTD is a heterogeneous, rapidly progressing syndrome that is among the top three causes of presenile dementia. About 10% of ALS cases are caused by dominantly transmitted gene defects. SOD1 and FUS mutations cause aggressive motor neuron pathology while TDP43 mutations cause ALS-FTD. Further, wild type FUS and TDP43 are components of abnormal inclusions in many FTD cases, suggesting a mechanistic link between these disorders. Early phenotypes are of particular interest because these could lead to targeted interventions aimed at the root cause of the disorder that could stem the currently inexorable disease progression. Elucidating such early, potentially shared characteristics of these disorders should be greatly aided by: 1) knock-in animal models expressing familial ALS-FTD genes; 2) sensitive, rigorous and objective behavioral phenotyping methods to analyze and compare models generated in different laboratories. In published work the co-PIs applied their first-generation, machine vision-based automated phenotyping method, ACBM ‘1.0’ (automated continuous behavioral monitoring) to detect and quantify the earliest-observed phenotypes in Tdp43Q331K knock-in mice. This method entails continuous video recording for 5 days to generate >14 million frames/mouse. These videos are then scored by a trained computer vision system. In addition to its sensitivity, objectivity and reproducibility, a major advantage of this method is the ability to acquire and archive video recordings and to analyze the data at sites, including the Cloud, remote from those of acquisition. We will use Google Cloud TPUs supercomputers that have been designed from the ground up to accelerate cutting-edge machine learning workloads, with a special focus on deep learning. We will analyze this data using Bayesian hierarchical spline models that describe the different mouse behaviors along the circadian rhythm. The current proposal has two main goals: 1) Use deep learning to refine and apply a Next Generation ACBM - ‘2.0’ - that will allow for more sensitive, expansive and robust automated behavioral phenotyping of four novel knock-in models along with the well characterized SOD1G93A transgenic mouse. 2) To establish and validate procedures to enable remote acquisition of video recording data with cloud-based analysis. Our vision is to establish sensitive, robust, objective, and open-source machine vision-based behavioral analysis tools that will be widely available to researchers in the field. Since all the computer-annotated video data is standardized in ACBM 2.0 and will be archived, we envision a searchable ‘behavioral database’, that can be freely mined and analyzed. Such tools are critical to accelerate the development of novel and effective therapeutics for ALS-FTD. Narrative ALS and Frontotemporal Dementia (FTD) are devastating, rapidly progressing diseases and current treatments are of limited value. In this proposal a neuroscientist and a computer scientist have teamed up to develop a new machine vision-based method for behavioral analysis novel mouse models of ALS-FTD. The ultimate goal is to reveal early phenotypes in ALS-FTD models that can be used in understanding disease pathology and in the development of new therapeutic targets.",Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models,9979408,R21NS112743,"['Amyotrophic Lateral Sclerosis', 'Animal Model', 'Archives', 'Behavior', 'Behavior monitoring', 'Behavioral', 'Characteristics', 'Circadian Rhythms', 'Computer Vision Systems', 'Computers', 'Data', 'Data Set', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Expression Profiling', 'Familial Amyotrophic Lateral Sclerosis', 'Frontotemporal Dementia', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Goals', 'Hour', 'Human', 'Intervention', 'Knock-in', 'Knock-in Mouse', 'Laboratories', 'Lead', 'Link', 'Machine Learning', 'Methods', 'Modeling', 'Motor Neuron Disease', 'Motor Neurons', 'Mus', 'Mutation', 'Neurodegenerative Disorders', 'Paralysed', 'Pathology', 'Phenotype', 'Plant Roots', 'Presenile Dementia', 'Procedures', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Respiratory Paralysis', 'Scientist', 'Site', 'Standardization', 'Syndrome', 'TensorFlow', 'Time', 'Training', 'Transgenic Mice', 'Transgenic Organisms', 'Treatment Efficacy', 'Video Recording', 'Vision', 'Work', 'Workload', 'base', 'behavioral phenotyping', 'cloud based', 'data archive', 'deep learning', 'design', 'frontotemporal lobar dementia-amyotrophic lateral sclerosis', 'interest', 'knockin animal', 'machine vision', 'mouse model', 'new therapeutic target', 'next generation', 'novel', 'open source', 'programs', 'protein TDP-43', 'stem', 'supercomputer', 'superoxide dismutase 1', 'tool']",NINDS,BROWN UNIVERSITY,R21,2020,446875,127562714,-0.008581008550313898
"Novel Statistical Inference for Biomedical Big Data Project Summary This project develops novel statistical inference procedures for biomedical big data (BBD), including data from diverse omics platforms, various medical imaging technologies and electronic health records. Statistical inference, i.e., assess- ing uncertainty, statistical signiﬁcance and conﬁdence, is a key step in computational pipelines that aim to discover new disease mechanisms and develop effective treatments using BBD. However, the development of statistical inference procedures for BBD has lagged behind technological advances. In fact, while point estimation and variable selection procedures for BBD have matured over the past two decades, existing inference procedures are either limited to simple methods for marginal inference and/or lack the ability to integrate biomedical data across multiple studies and plat- forms. This paucity is, in large part, due to the challenges of statistical inference in high-dimensional models, where the number of features is considerably larger than the number of subjects in the study. Motivated by our team's extensive and complementary expertise in analyzing multi-omics data from heterogenous studies, including the TOPMed project on which multiple team members currently collaborate, the current proposal aims to address these challenges. The ﬁrst aim of the project develops a novel inference procedure for conditional parameters in high-dimensional models based on dimension reduction, which facilitates seamless integration of external biological information, as well as biomedical data across multiple studies and platforms. To expand the application of this method to very high-dimensional models that arise in BBD applications, the second aim develops a data-adaptive screening procedure for selecting an optimal subset of relevant variables. The third aim develops a novel inference procedure for high-dimensional mixed linear models. This method expands the application domain of high-dimensional inference procedures to studies with longitu- dinal data and repeated measures, which arise commonly in biomedical applications. The fourth aim develops a novel data-driven procedure for controlling the false discovery rate (FDR), which facilitates the integration of evidence from multiple BBD sources, while minimizing the false negative rate (FNR) for optimal discovery. Upon evaluation using ex- tensive simulation experiments and application to multi-omics data from the TOPMed project, the last aim implements the proposed methods into easy-to-use open-source software tools leveraging the R programming language and the capabilities of the Galaxy workﬂow system, thus providing an expandable platform for further developments for BBD methods and tools. Public Health Relevance Biomedical big data (BBD), including large collections of omics data, medical imaging data, and electronic health records, offer unprecedented opportunities for discovering disease mechanisms and developing effective treatments. However, despite their tremendous potential, discovery using BBD has been hindered by computational challenges, including limited advances in statistical inference procedures that allow biomedical researchers to investigate uncon- founded associations among biomarkers of interest and various biological phenotypes, while integrating data from multiple BBD sources. The current proposal bridges this gap by developing novel statistical machine learning methods and easy-to-use open-source software for statistical inference in BBD, which are designed to facilitate the integration of data from multiple studies and platforms.",Novel Statistical Inference for Biomedical Big Data,9969887,R01GM133848,"['Address', 'Adoption', 'Behavioral', 'Big Data Methods', 'Biological', 'Biological Assay', 'Biological Markers', 'Code', 'Collection', 'Communities', 'Computer software', 'Data', 'Data Sources', 'Development', 'Dimensions', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Galaxy', 'Genetic study', 'Goals', 'Heart', 'Imaging technology', 'Individual', 'Linear Models', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular', 'Multiomic Data', 'Outcome', 'Phenotype', 'Procedures', 'R programming language ', 'Research Personnel', 'Sample Size', 'Scientist', 'Screening procedure', 'Software Tools', 'Structure', 'System', 'Testing', 'Trans-Omics for Precision Medicine', 'Uncertainty', 'Work', 'base', 'big biomedical data', 'computational pipelines', 'data integration', 'design', 'diverse data', 'effective therapy', 'experimental study', 'heterogenous data', 'high dimensionality', 'interest', 'machine learning method', 'member', 'novel', 'open source', 'public health relevance', 'screening', 'simulation', 'statistical and machine learning', 'structured data', 'tool', 'treatment strategy', 'user friendly software']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,456980,533302350,-0.004027163679404361
"Scientific Questions: A New Target for Biomedical NLP Project Summary  Natural language processing (NLP) technology is now widespread (e.g. Google Translate) and has several important applications in biomedical research. We propose a new target for NLP: extraction of scientific questions stated in publications. A system that automatically captures and organizes scientific questions from across the biomedical literature could have a wide range of significant impacts, as attested to in our diverse collection of support letters from researchers, journal editors, educators and scientific foundations. Prior work focused on making binary (or probabilistic) assessments of whether a text is hedged or uncertain, with the goal of downgrading such statements in information extraction tasks—not computationally capturing what the uncertainty is about. In contrast, we propose an ambitious plan to identify, represent, integrate and reason about the content of scientific questions, and to demonstrate how this approach can be used to address two important new use cases in biomedical research: contextualizing experimental results and enhancing literature awareness. Contextualizing results is the task of linking elements of genome-scale results to open questions across all of biomedical research. Literature awareness is the ability to understand important characteristics of large, dynamic collections of research publications as a whole. We propose to produce rich computational representations of the dynamic evolution of research questions, and to prototype textual and visual interfaces to help students and researchers explore and develop a detailed understanding of key open scientific questions in any area of biomedical research. Project Narrative The scientific literature is full of statements of important unsolved questions. By using artificial intelligence systems to identify and categorize these questions, the proposed work would help other researchers discover when their findings might address an important question in another scientific area. This work would also make it easier for students, journal editors, conference organizers and others understand where science is headed by tracking the evolution of scientific questions.",Scientific Questions: A New Target for Biomedical NLP,10069773,R01LM013400,"['Address', 'Area', 'Artificial Intelligence', 'Awareness', 'Biomedical Research', 'Characteristics', 'Collection', 'Computerized Patient Records', 'Cues', 'Data', 'Elements', 'Environment', 'Evolution', 'Expert Systems', 'Foundations', 'Genes', 'Goals', 'Gold', 'Information Retrieval', 'Journals', 'Letters', 'Link', 'Literature', 'Manuals', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Phenotype', 'Proteomics', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Semantics', 'Services', 'Signal Transduction', 'Source', 'Students', 'System', 'Taxonomy', 'Technology', 'Text', 'Time', 'Translating', 'Uncertainty', 'Update', 'Visual', 'Work', 'design', 'dynamical evolution', 'experimental study', 'genome wide association study', 'genome-wide', 'graduate student', 'high throughput screening', 'innovation', 'journal article', 'news', 'novel', 'pharmacovigilance', 'prototype', 'symposium', 'text searching', 'tool', 'transcriptome sequencing', 'trend']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2020,462393,292134808,-0.007864518042269706
"A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities DESCRIPTION (provided by applicant): Our ultimate goal is to improve our ability to create and measure 3D models derived from cone-beam computed tomography (CBCT). Our main motivation is to improve quality and reduce costs in care of patients with craniomaxillofacial (CMF) deformities. The resulted innovations will also impact other fields. CMF deformities involve congenital and acquired deformities of the jaws and face. A large number of patients in the US and around the world suffered from CMF deformities. The evaluation of these patients includes an assessment of CMF form on 3D models that are traditionally generated from segmented spiral multi-slice CTs (MSCTs). These models are also used to plan their treatment. The purpose of segmentation is to separate different anatomical structures and to remove the artifacts on the CTs. Once 3D models are generated from the segmented CTs, anatomical and teeth landmarks are manually digitized for measurements. Finally, diagnosis and treatment planning are performed based on measurements. Although MSCT provides high- quality images and thus allows relatively fast and easy post processing, many concerns have been raised on excessive radiation exposure to patients. Therefore, more doctors are now using CBCT scanners in their offices. CBCT has less radiation and is inexpensive compared to the MSCT, but their use in generating 3D models is greatly limited by the poor image quality, i.e., low contrast / signal-to-noise ratio and artifacts. Thus, the existing automated segmentation algorithms developed for MSCT are incapable of practically segmenting CBCTs. The current solution to CBCT segmentation entails an arduous and lengthy process that involves labor-intensive manual editing of hundreds of slices. Besides, another arduous and inaccurate task in the assessment of CMF deformities is the digitization of anatomical landmarks on 3D models - the first step to quantify the deformities. Currently a typical 3D cephalometric and teeth analysis requires the manual digitization of more than 200 landmarks, which is time consuming and has limited accuracy. We hypothesize that the creation and measurement of high-quality 3D models can be significantly improved by developing innovative CBCT-friendly post processing tools. Therefore, in this renewal project, we propose to develop and validate a novel CBCT analysis platform to automate the process of CBCT segmentation and landmark digitization. The feasibility of our approaches has already been proven by our preliminary studies. Our innovative CBCT analysis platform will significantly improve the quality and reduce the cost of care to the individuals with CMF conditions. It will change our dental/CMF fields in effectively utilizing CBCT as a guide for on-the-fly diagnosis and treatment planning. With minimal user intervention, the computer will accurately and effectively do the work, which is currently artistically done by the labor-intensive human operators. The resulted innovations may also impact other fields in the future, e.g., orthopedic surgery and cardiovascular surgery where intraoperative whole-body CBCT is acquired for image-guided surgery and intervention. PUBLIC HEALTH RELEVANCE: Cone-beam computed tomography (CBCT) is widely used in physician's offices for orthodontics, craniomaxillofacial (CMF) surgery, facial plastic surgery and dentistry, but its segmentation and landmark digitization have to be completed artistically by human operators, which is labor-intensive and with limited accuracy.  We propose to develop and validate an innovative CBCT post processing system to automate the processes of CBCT segmentation and landmark digitization with minimal user intervention.  The proposed system will significantly improve the quality and reduce the cost of care to the individuals  with CMF conditions, and also change 1) the fields of orthodontics, CMF surgery and general dentistry in  effectively utilizing CBCT as a guide for diagnosis and treatment planning, and 2) the fields of orthopedic  surgery, general surgery, and cardiovascular surgery where the quality and the speed of intraoperative imaging is critical.",A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities,9840832,R01DE022676,"['3-Dimensional', 'American', 'Anatomy', 'Atlases', 'Back', 'Cardiovascular Surgical Procedures', 'Cephalometry', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computed Tomography Scanners', 'Computer Assisted', 'Computer software', 'Computers', 'Consultations', 'Consumption', 'Deformity', 'Dental Care', 'Dentistry', 'Detection', 'Diagnosis', 'Diagnostic', 'Ensure', 'Evaluation', 'Exposure to', 'Face', 'Future', 'Goals', 'Head', 'Hour', 'Human', 'Image', 'Image-Guided Surgery', 'Individual', 'Intervention', 'Jaw', 'Label', 'Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motivation', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Oral', 'Orthodontics', 'Orthopedic Surgery procedures', 'Patient Care', 'Patients', 'Phase', 'Physicians&apos', ' Offices', 'Plastic Surgical Procedures', 'Process', 'Quality of Care', 'Quantitative Evaluations', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Running', 'Scanning', 'Services', 'Shapes', 'Signal Transduction', 'Slice', 'Speed', 'Syncope', 'System', 'Technology', 'Three-Dimensional Image', 'Time', 'Tooth structure', 'Training', 'Validation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'automated segmentation', 'base', 'care costs', 'cone-beam computed tomography', 'cost', 'craniofacial', 'craniomaxillofacial', 'design', 'detector', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'psychologic', 'public health relevance', 'random forest', 'segmentation algorithm', 'three-dimensional modeling', 'tool', 'treatment planning', 'usability', 'user-friendly', 'virtual surgery']",NIDCR,METHODIST HOSPITAL RESEARCH INSTITUTE,R01,2020,495143,27487788,-0.015174673220665144
"Utility of Predictive Systems to identify Inpatient Diagnostic Errors: The UPSIDE Study PROJECT SUMMARY/ABSTRACT  While much research has been conducted on patient safety since the Institute of Medicine published “To Err is Human” in 2000, there is a comparative dearth of research on diagnostic errors in the hospital setting. The broad, long-term objectives of the proposed research is to better understand the incidence, causes, and risk factors for diagnostic errors in the inpatient setting. This work will provide foundational research for the development of interventions to reduce these errors, including predictive tools, targets for intervention, and a methodology for outcome assessment in future trials of interventions. To achieve this overall goal, we will carry out the following specific aims: 1) To determine the incidence of diagnostic errors among patients who die in hospital or are transferred to the ICU two days or more after admission to a general medicine service through a structured, standardized adjudication process of patient records, 2) To combine adjudication data with data from Vizient to determine which specific factors contribute to risks for diagnostic errors, and to use risk estimates to calculate incidence and impact of factors contributing to those errors, and 3)To create machine- learning models that can be used to retrospectively identify patients in whom a diagnostic error was likely to have taken place. The research will involve a retrospective evaluation of 2000 patients admitted to general medicine units at 20 US hospitals participating in a national research collaborative and which also contribute data to a benchmarking and purchasing organization (Vizient). Using the Safer-Diagnosis (Safer-Dx) and Diagnostic Error Evaluation and Research (DEER) taxonomy tools, both adapted for the inpatient setting, adjudicators will review electronic medical record data and determine the presence or absence of diagnostic errors using a rigorous training and continuous review process to ensure reliability across sites, adjudicators, and time. Standard modelling techniques will be used to understand the population-attributable risk of each of the DEER process failure points to diagnostic error as well as the contributions of several patient, provider, and system-level risk factors. Lastly, advanced machine-learning methods will be used to create models that can identify patients in whom diagnostic error occurred, with superior performance to standard approaches such as logistic regression. Together, these approaches will provide a broad and representative picture of the incidence of diagnostic errors among hospitalized patients who have suffered harm, develop models of patient and system-based factors that make a diagnostic error more or less likely, and build advanced, efficient, and scalable tools needed to support future surveillance and improvement programs for a variety of institutions. This research will establish a foundation from which healthcare systems can assess and achieve excellence in diagnosis in the inpatient setting. PROJECT NARRATIVE  This study seeks to accurately define the incidence of diagnostic errors among patients suffering serious inpatient events in a large network of US hospitals. Without a reliable method for determining the presence of diagnostic errors across many organizations, it is not otherwise possible to understand the incidence, impact, predictors, and underlying causes of these errors, to create and optimize future solutions to reduce diagnostic errors, to directly test the effects of these solutions, or to teach physicians how to avoid diagnostic pitfalls in the future. Our study addresses these issues while being responsive to the RFA’s goals of developing robust estimates of incidence and risk and using approaches that leverage electronic data, and our approach represents a novel application of rigorous outcome adjudication and advanced modeling techniques to the problem of inpatient diagnostic errors.",Utility of Predictive Systems to identify Inpatient Diagnostic Errors: The UPSIDE Study,10020962,R01HS027369,[' '],AHRQ,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,496734,685608202,-0.001900233800602064
"Predicting Human Olfactory Perception from Molecular Structure PROJECT SUMMARY Modern technology makes it possible to capture a visual scene as a photograph, alter it, send it to another country nearly instantaneously, and store it without concern for degradation. None of this is currently possible in olfaction. Although perfumers and flavorists are adept at mixing odorous molecules to produce a desired perceptual effect, the rules underlying this process are poorly understood at a quantitative level. Current methods for displaying odors to a subject are akin to requiring a Polaroid of every visual stimulus of interest. A more efficient method for probing the olfactory system would be to use a set of 'primary odors'—some limited number of odors from which all other complex odors could be reproduced by appropriate mixtures. Both auditory and visual stimuli have been digitized, and this will eventually be possible in olfaction as well. Predicting odor from chemical structure has been a problem in the field since its inception, but recent advances in machine learning algorithms have made great progress in analogous problems, such as facial recognition. The research proposed here will combine these machine learning techniques with high quality human psychophysics to understand how to predict the smell of a molecule or mixture of odorants, which will ultimately help improve our understanding of disease diagnosis using odors as well as eating-related health and illness. HEALTH RELEVANCE The sense of smell plays a critical role in preferences and aversions for specific foods. The proposed research will combine machine learning techniques with high quality human psychophysics to create a model that can predict the smell of odorous molecules. This model will allow us to describe and control odors, which will increase our understanding of food preference and eating-related health and wellness.",Predicting Human Olfactory Perception from Molecular Structure,9887973,R01DC017757,"['Algorithms', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Code', 'Collection', 'Color', 'Communities', 'Complex', 'Complex Mixtures', 'Country', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Eating', 'Enrollment', 'Face', 'Food', 'Food Preferences', 'Frequencies', 'Health', 'Human', 'Ligands', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Molecular Structure', 'Neurosciences', 'Non-linear Models', 'Numerical value', 'Odors', 'Olfactory Pathways', 'Perception', 'Play', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Role', 'Smell Perception', 'Stimulus', 'Techniques', 'Technology', 'Training', 'Translating', 'Vision', 'Visual', 'Vocabulary', 'Work', 'auditory stimulus', 'base', 'computer monitor', 'disease diagnosis', 'experience', 'high dimensionality', 'improved', 'in silico', 'interest', 'machine learning algorithm', 'member', 'novel', 'physical property', 'predictive modeling', 'predictive test', 'preference', 'receptor', 'relating to nervous system', 'single molecule', 'visual stimulus']",NIDCD,MONELL CHEMICAL SENSES CENTER,R01,2020,496911,6406933,-0.020981938644714003
"Identifying Personalized Risk of Acute Kidney Injury with Machine Learning PROJECT SUMMARY/ABSTRACT Acute Kidney Injury (AKI) is a common and highly lethal health problem, affecting 10-15% of all hospitalized patients and >50% of patients in intensive care units (ICUs). It has been shown that a small increase in serum creatinine (SCr) of ≥0.5 mg/dl was associated with a 6.5-fold increase in the odds of death, a 3.5-day increase in length of stay, and nearly $7,500 in excess hospital costs. Unfortunately, no specific treatment exists to cure AKI once it has developed. The ability to predict AKI in hospitalized patients would provide clinicians the opportunity to modify care pathways and implement interventions, which could in turn prevent AKI and yield better outcomes. Although electronic medical record (EMR) based monitoring systems for AKI have led to expedited interventions and may increase the percentage of patients returning to baseline kidney function, most of these systems are reactive rather than proactive, with little or no contribution to AKI prevention. Moreover, our current knowledge of AKI risk factors is far from complete, especially in the ICU and general inpatient populations, characterized by numerous deficiencies and systematic failings that may be avoidable To transform the reactive AKI care to proactive and personalized care, early identification of high risk patients and better understanding of individual modifiable risk factors for AKI is the key. In Aim 1, to discover novel risk factors predictive of AKI, we propose to develop an ensemble multi-view feature selection framework to simultaneously consider the differences and interrelations between feature spaces and obtain robust knowledge by synthesizing findings from diverse patient populations across multiple institutions in nine US states. In Aim 2, to discover general modifiable causes of AKI to help physicians design more effective AKI prevention policies, we propose to develop a novel multi-cause inference method to identify causal relationships between modifiable factors and AKI for susceptible patient subgroups. In Aim 3, to explain what caused AKI in individual patients to support physicians in designing personalized AKI intervention, we propose to develop a new causal explanation method by integrating causal inference and case based reasoning to quantify patient-level causal significance of modifiable factors. The proposed study will have a significant clinical impact by not only expanding the capacity of clinicians to identify high risk patients for AKI early and advancing the general knowledge on causal and modifiable risk factors for AKI but also supporting personalized AKI intervention with suggestions on potential patient-specific actionable items. The work will not only advance AKI but also the machine learning and clinical research informatics community and the methodology developed is generalizable to other clinical domains. PROJECT NARRATIVE The proposed research is to identify clinical risk factors of acute kidney injury (AKI) in hospitalized patients from electronic medical records (EMRs) with machine learning. AKI risk factors discovered from EMR of diverse populations from multiple institutions across nine US states will be reliable and robust and can assist clinicians in providing proactive and personalized care to high-risk patients.",Identifying Personalized Risk of Acute Kidney Injury with Machine Learning,10003227,R01DK116986,"['Acute Renal Failure with Renal Papillary Necrosis', 'Affect', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Computerized Medical Record', 'Creatinine', 'Data', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Early identification', 'Elderly', 'Event', 'Exposure to', 'Geographic Locations', 'Geographic state', 'Health', 'Health system', 'Hospital Costs', 'Hospital Mortality', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Injury to Kidney', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'Kidney', 'Knowledge', 'Learning', 'Length of Stay', 'Life', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Monitor', 'Myocardial', 'Outcome', 'Outcomes Research', 'Pathway interactions', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Physiology', 'Policies', 'Population', 'Population Heterogeneity', 'Predictive Factor', 'Renal function', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Role', 'Sepsis', 'Series', 'Serum', 'Suggestion', 'System', 'Time', 'Work', 'adjudication', 'base', 'case-based', 'clinical predictors', 'clinical risk', 'design', 'feature selection', 'heterogenous data', 'high dimensionality', 'high risk', 'improved', 'individual patient', 'inhibitor/antagonist', 'injury prevention', 'machine learning algorithm', 'modifiable risk', 'mortality risk', 'nephrotoxicity', 'novel', 'patient population', 'patient subsets', 'personalized care', 'prevent']",NIDDK,UNIVERSITY OF KANSAS MEDICAL CENTER,R01,2020,506170,77014486,-0.013154737282539583
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10017950,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,513041,641965656,-0.0026337488343054372
"Optical Body Composition and Health Assessment ﻿    DESCRIPTION (provided by applicant):1 Of all markers of human health, the most intuitive is body shape but based on quantitative evidence.  2 Anthropometry and regional composition measures such as waist circumference (WC), waist to hip ratio  3 (WHR), and visceral adipose tissue area (VAT) are better predictors of obesity-related diseases and mortality  4 risk than body mass index (BMI). Dual-energy X-ray absorptiometry (DXA) can quantify regional adiposity in  5 more detail than the above measures but is underutilized for many reasons including potential harm from  6 ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments  7 in the ""quantified self movement"" to better describe phenotypes of body shape and its relation to metabolic  8 risks. The candidate developed in this proposal is 3D optical whole body scanning. If successful, sophisticated  9 obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with 10 disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment 11 technology. Whole body 3D imaging technology is already so accessible that it can be done with video games 12 such as the Microsoft Xbox Kinect, and consumer cameras. 13 The long term goal of the Optical Body Shape and Health Assessment Study is 1) to provide phenotype 14 descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in 15 research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive 16 models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, 17 muscle mass, lean mass, and percent fat), and then show how our 3DO body composition estimates are 18 associated to important metabolic risk factors. Our central hypothesis is that 3DO measures of body 19 composition with shape classification better predict metabolic risk factors than anthropometry or DXA body 20 composition alone. Our specific aims are: 1. Identify the unique associations of body shape to body 21 composition indices in a population that represents the variance of sex, age, BMI, and ethnicity found 22 in the US population; 2. Describe the precision and accuracy of 3DO scans to monitor change in body 23 composition and metabolic health interventions; and 3. Estimate the level of association of 3DO to 24 common health indicators including metabolic risk factors by gender, race, age, and BMI. In an 25 exploratory aim, we investigate holistic, high-resolution descriptors of 3D body shape as direct 26 predictors of body composition and metabolic risk using statistical shape models and Latent Class 27 Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self- 28 assessment technologies that are capable of representing over 95% of the shape variance in the US 29 population, and how these models relate to important metabolic status and body composition. The positive 30 impact will be the immediate applicability to clinicians and individuals for personalized risk assessment. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because they have the potential to provide a better understanding of who is at high risk of metabolic diseases because of a poor metabolic profile. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Optical Body Composition and Health Assessment,9971509,R01DK109008,"['3-Dimensional', 'Adipose tissue', 'Adult', 'Age', 'Animals', 'Anorexia Nervosa', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Classification', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Devices', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Ethnic Origin', 'Fatty acid glycerol esters', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Individual', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Personal Satisfaction', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Video Games', 'Visceral', 'Visceral fat', 'Waist-Hip Ratio', 'bariatric surgery', 'base', 'clinical practice', 'cost', 'disorder prevention', 'disorder risk', 'health assessment', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolic profile', 'metabolomics', 'mortality', 'mortality risk', 'muscle form', 'optical imaging', 'predictive modeling', 'public health relevance', 'sensor', 'sex', 'subcutaneous', 'tool', 'waist circumference', 'whole body imaging']",NIDDK,UNIVERSITY OF HAWAII AT MANOA,R01,2020,514103,45734163,0.017842522954837608
"Using a Natural Experiment to Evaluate the Long-Term Effects of Neighborhood Deprivation on Alzheimer's Disease and Vascular Risk Factors ABSTRACT  The NIA has called for social science and community-based studies to clarify risk and protective factors for Alzheimer's disease and related dementias (ADRD), particularly among racial minorities who are disproportionately affected. Place, including both neighborhood of residence and region/state of birth, has consistently been correlated with ADRD, stroke, and impaired cognitive function. Yet it is unclear whether modifiable mechanisms explain this association, or whether the association is merely due to the selection of unhealthy individuals into poor regions. The goal of this study is to produce the first quasi-experimental evidence to understand the influence of neighborhood socioeconomic deprivation on ADRD and its vascular risk factors. We take advantage of a unique natural experiment, overcoming methodological challenges in the previous literature on neighborhood effects on ADRD. From 1986 to 1998, the Danish government actively dispersed roughly 76,000 incoming refugees across the country in a nearly randomized (“quasi-random”) fashion to avoid over-crowding in major cities. This cohort includes nearly 12,000 individuals who lived until at least age 60 in Denmark during the 30-year follow-up. Over 90% of families agreed to participate in the program, creating a natural experiment in which these individuals were quasi-randomly assigned to neighborhoods with different levels of deprivation. We will employ unique data spanning over 30 years from Denmark's population and clinical registers, which provide data on sociodemographics, clinical encounters, and prescriptions for all Danish residents. We identify cases of ADRD and its vascular risk factors among this racially diverse cohort via validated techniques using ICD codes and prescription data in clinical registers. We have successfully linked these registers to detailed geocoded data sources on eight measures of neighborhood socioeconomic deprivation. In Aim 1, our goal is to test the hypothesis that neighborhood deprivation increases the incidence of ADRD later in life. In Aim 2, we will examine the effects of neighborhood deprivation on vascular risk factors for ADRD, including highly prevalent conditions that occur across the life course. In Aim 3, we will identify vulnerable subgroups whose development of ADRD and vascular risk factors differs in response to neighborhood deprivation, taking advantage of the large sample size and complete register data available on all subjects. We will employ both hypothesis-driven and hypothesis-generating statistical techniques, including innovative machine learning methods that allow for more complex and robust subgroup identification. This will enable future interventions to be tailored to the most vulnerable individuals. Overall, the expected outcome of this research is to produce rigorous evidence on the effects of neighborhood characteristics on ADRD and vascular risk factors, overcoming the methodological challenges in previous work. This will directly inform the development of clinical, community, and policy strategies to address the neighborhood determinants of ADRD among vulnerable populations who are most at-risk. PROJECT NARRATIVE  The goal of this research is to examine the effects of neighborhood deprivation on Alzheimer's dementia and its vascular risk factors. We will examine the association of specific neighborhood characteristics with Alzheimer's and its risk factors, and we will assess whether specific subgroups may be more vulnerable to neighborhood deprivation. This will inform the development of interventions to address the neighborhood factors that affect Alzheimer's disease.",Using a Natural Experiment to Evaluate the Long-Term Effects of Neighborhood Deprivation on Alzheimer's Disease and Vascular Risk Factors,9922214,R01AG063385,"['Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Alzheimer&apos', 's disease risk', 'Attention', 'Biological Factors', 'Birth', 'Blood Vessels', 'Characteristics', 'Cities', 'Clinical', 'Communities', 'Community Developments', 'Complex', 'Country', 'Crowding', 'Data', 'Data Sources', 'Denmark', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disadvantaged', 'Discrimination', 'Environmental Risk Factor', 'Exposure to', 'Family', 'Future', 'Gender', 'Goals', 'Government', 'Health', 'Hyperlipidemia', 'Hypertension', 'Immigrant', 'Impaired cognition', 'Incidence', 'Individual', 'International Classification of Disease Codes', 'Intervention', 'Life', 'Life Cycle Stages', 'Life Experience', 'Link', 'Literature', 'Logistics', 'Long-Term Effects', 'Measures', 'Methodology', 'Minority Groups', 'Natural experiment', 'Neighborhoods', 'Observational Study', 'Outcome', 'Outcomes Research', 'Pathway interactions', 'Pattern', 'Policies', 'Population', 'Poverty', 'Race', 'Randomized', 'Refugees', 'Research', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Schools', 'Social Sciences', 'Socialization', 'Stroke', 'Subgroup', 'Techniques', 'Testing', 'Time', 'Violence', 'Vulnerable Populations', 'Work', 'base', 'clinical development', 'clinical encounter', 'cognitive function', 'cohort', 'dementia risk', 'deprivation', 'diabetes risk', 'environmental enrichment for laboratory animals', 'ethnic minority population', 'evidence base', 'experimental study', 'follow-up', 'forest', 'high risk', 'indexing', 'innovation', 'machine learning method', 'member', 'prevent', 'programs', 'protective factors', 'racial and ethnic', 'racial diversity', 'racial minority', 'residence', 'response', 'social', 'social factors', 'sociodemographics', 'socioeconomic disadvantage', 'socioeconomics', 'stressor', 'theories', 'therapy development', 'treatment effect', 'vascular risk factor', 'young adult']",NIA,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,522652,685608202,-0.028297930523655368
"An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics Immune-repertoire sequence, which consists of an individual's millions of unique antibody and T-cell receptor (TCR) genes, encodes a dynamic and highly personalized record of an individual's state of health. Our long- term goal is to develop the computational models and tools necessary to read this record, to one day be able diagnose diverse infections, autoimmune diseases, cancers, and other conditions directly from repertoire se- quence. The key problem is how to find patterns of specific diseases in repertoire sequence, when repertoires are so complex. Our hypothesis is that a combination of bottom-up (sequence-level) and top-down (systems- level) modeling can reveal these patterns, by encoding repertoires as simple but highly informative models that can be used to build highly sensitive and specific disease classifiers. In preliminary studies, we introduced two new modeling approaches for this purpose: (i) statistical biophysics (bottom-up) and (ii) functional diversity (top-down), and showed their ability to elucidate patterns related to vaccination status (97% accuracy), viral infection, and aging. Building on these studies, we will test our hypothesis through two specific aims: (1) We will develop models and classifiers based on the bottom-up approach, statistical biophysics; and (2) we will de- velop the top-down approach, functional diversity, to improve these classifiers. To achieve these aims, we will use our extensive collection of public immune-repertoire datasets, beginning with 391 antibody and TCR da- tasets we have characterized previously. Our team has deep and complementary expertise in developing computational tools for finding patterns in immune repertoires (Dr. Arnaout) and in the mathematics that under- lie these tools (Dr. Altschul), with additional advice available as needed regarding machine learning (Dr. AlQuraishi). This proposal is highly innovative for how our two new approaches address previous issues in the field. (i) Statistical biophysics uses a powerful machine-learning method called maximum-entropy modeling (MaxEnt), improving on past work by tailoring MaxEnt to learn patterns encoded in the biophysical properties (e.g. size and charge) of the amino acids that make up antibodies/TCRs; these properties ultimately determine what targets antibodies/TCRs can bind, and therefore which sequences are present in different diseases. (ii) Functional diversity fills a key gap in how immunological diversity has been measured thus far, by factoring in whether different antibodies/TCRs are likely to bind the same target. This proposal is highly significant for (i) developing an efficient, accurate, generative, and interpretable machine-learning method for finding diagnostic patterns in repertoire sequence; (ii) applying a robust mathematical framework to the measurement of immuno- logical diversity; (iii) impacting clinical diagnostics; and (iv) adding a valuable new tool for integrative/big-data medicine. The expected outcome of this proposal is an integrated pair of robust and well validated new tools/models for classifying specific disease exposures directly from repertoire sequence. This proposal in- cludes plans to make these tools widely available, to maximize their positive impact across medicine. The proposed research is relevant to public health because B cells/antibodies and T cells play vital roles across such a vast range of health conditions, from infection, to autoimmunity, to cancer, that the ability to de- code what they are doing would be an important step forward for diagnosing these conditions. The proposed research is relevant to the NIH's mission of fostering fundamental creative discoveries, innovative research strategies, and their applications as a basis for ultimately protecting and improving health, specifically relating to the diagnosis of human diseases.",An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics,10050030,R01AI148747,"['Address', 'Affect', 'Aging', 'Amino Acid Motifs', 'Amino Acids', 'Antibodies', 'Autoimmune Diseases', 'Autoimmunity', 'B-Lymphocytes', 'Base Sequence', 'Big Data', 'Binding', 'Biophysics', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Code', 'Collection', 'Complex', 'Computer Models', 'Data Set', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Entropy', 'Fostering', 'Gene Frequency', 'Genes', 'Goals', 'Health', 'Human', 'Immune', 'Immunology', 'Individual', 'Infection', 'Influenza vaccination', 'Intuition', 'Learning', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mission', 'Modeling', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Physics', 'Play', 'Population Heterogeneity', 'Privatization', 'Property', 'Public Health', 'Reading', 'Reporting', 'Research', 'Role', 'Sample Size', 'Sampling', 'Sampling Errors', 'Signs and Symptoms', 'Speed', 'Statistical Study', 'System', 'T-Cell Receptor', 'T-Cell Receptor Genes', 'T-Lymphocyte', 'Testing', 'United States National Institutes of Health', 'Vaccination', 'Virus Diseases', 'Work', 'base', 'biophysical properties', 'clinical diagnostics', 'computerized tools', 'diagnostic accuracy', 'human disease', 'immunological diversity', 'improved', 'information model', 'innovation', 'machine learning method', 'multidisciplinary', 'multilevel analysis', 'novel', 'novel strategies', 'tool']",NIAID,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2020,535171,135941803,-0.006322770679039831
"A Transfer Learning Framework for Creating Subject-Specific Musculoskeletal Models of the Hand PROJECT SUMMARY Restoring hand function remains an elusive goal for many clinical conditions, including stroke, osteoarthritis, tetraplegia, amputation, and traumatic injury. The hand’s anatomical complexity makes restoring hand function particularly challenging because altering any one parameter in the hand can have cascading effects that are difficult to predict, but essential to control. In this proposal, as a critical step toward informing personalized treatments for the hand, we will study how subject-specific differences influence hand function. Completion of this proposal will rely on collection of three datasets that are designed to provide varying levels of biomechanical detail and require varying levels of effort to collect. Briefly, these datasets include (1) a simulation dataset containing 500,000 simulations fully describing all musculoskeletal parameters involved in hand force production, (2) a dense, biomechanical datasets that describes the kinematics, kinetics, and muscle activity required for hand force production in 30 adults, and (3) a sparse, clinically-inspired dataset that describes demographics, anthropometrics, and clinical metrics of hand function in 1000 adults. In Aim 1, we will leverage the first two datasets to design a data-driven analysis framework that identifies the most important biomechanical parameter(s) and maps how those parameters influence hand force production. Completion of this aim will elucidate the biomechanical mechanisms that modulate hand force production and evaluate the ability to use simulation data, instead of experimental data, to identify these mechanisms. In Aim 2, we will leverage all three datasets to create a transfer learning framework capable of efficiently and accurately predicting subject-specific muscle force-generating parameters from easy to collect clinical data. We specifically focus on muscle force- generating parameters because these parameters remain challenging to quickly and accurately estimate, are known to vary across the population, and are highly related to functional metrics like strength. Completion of this aim will provide a new approach for rapidly estimating subject-specific musculoskeletal parameters, thereby enabling efficient creation of subject-specific models and potentially catalyzing use of such models in a clinical setting. Overall, the results from this study could enhance our ability to provide personalized diagnoses and prognoses for individuals suffering from hand impairments. PROJECT NARRATIVE The proposed project aims to understand the biomechanical mechanisms underlying force production in the hand. Specifically, we utilize machine learning methods to examine how subject-specific differences influence hand force production and create subject-specific computer models from easy to obtain clinical data. The results, which integrate modeling with an individual’s clinical data, could enhance our ability to provide personalized diagnoses and prognoses for individuals suffering from hand impairments.",A Transfer Learning Framework for Creating Subject-Specific Musculoskeletal Models of the Hand,10040078,R21EB030068,"['Address', 'Adult', 'Amputation', 'Anatomy', 'Biomechanics', 'Clinical', 'Clinical Data', 'Code', 'Collection', 'Complex', 'Computer Models', 'Computer Simulation', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Diagnostic', 'Floor', 'Future', 'Goals', 'Hand', 'Hand Strength', 'Hand functions', 'Individual', 'Joints', 'Kinetics', 'Learning', 'Maps', 'Methods', 'Modeling', 'Muscle', 'Musculoskeletal', 'Musculoskeletal System', 'Outcome', 'Patients', 'Perception', 'Physics', 'Population', 'Production', 'Psychological Transfer', 'Quadriplegia', 'Research', 'Sensory', 'Stroke', 'Study Subject', 'System', 'Testing', 'Traumatic injury', 'Work', 'Wrist', 'base', 'bone', 'computational platform', 'computerized tools', 'deep neural network', 'demographics', 'design', 'experimental study', 'grasp', 'hand dysfunction', 'hand rehabilitation', 'individual patient', 'kinematics', 'machine learning method', 'motor control', 'neural network', 'neuromuscular', 'novel strategies', 'open-access repositories', 'personalized diagnostics', 'personalized medicine', 'prognostic', 'random forest', 'simulation', 'tool']",NIBIB,UNIVERSITY OF FLORIDA,R21,2020,560939,188894159,-0.008538628578640312
"Computational and Statistical Framework to Model Tissue Shape and Mechanics PROJECT SUMMARY  The morphologic and mechanical characteristics of a tissue are fundamental to understanding the development, homeostasis, and pathology of the human body. During the previous period of funding, we developed statistical shape modeling (SSM) methods and applied these to the study of structural hip disease. We also developed the initial framework to integrate SSM with finite element (FE) analysis to enable the study of shape and mechanics together. If incorporated into clinical practice, SSM and FE analysis could identify features of the anatomy likely responsible for injury, remodeling, or repair. Geometry needed for SSM and FE models is typically generated by segmentation of volumetric imaging data. This step can be painstakingly slow, error prone, and cost prohibitive, which hampers clinical application of these computational techniques. We have created a deep machine learning algorithm ‘DeepSSM’ that uses a convolutional neural network to establish the correspondence model directly from unsegmented images. In Aim 1 we will apply DepSSM to improve clinical understanding of structural hip disease by characterizing differences in anatomy between symptomatic and asymptomatic individuals; these morphometric comparisons will identify anatomic features most telling of disease, thereby guiding improvements in diagnosis. Computational advancements have simplified the process to generate patient-specific FE models, enabling clinically focused research. However, there is no framework to collectively visualize, compare, and interpret (i.e., post-process) results from multiple FE models. Currently, inter-subject comparisons require oversimplifications such as averaging results over subjectively defined regions. In Aim 2 we will develop new post-processing methods to collectively visualize, interpret and statistically analyze FE results across multiple subjects and study groups. We will map FE results to synthetic anatomies representing statistically meaningful distributions using the correspondence model. Statistical parametric mapping will be applied to preserve anatomic detail through statistical testing. We will use our published FE models of hip joint mechanics as the test system. Finally, volumetric images provide a wealth of information that is delivered to physicians in a familiar format. Yet, tools are not available to interpret model data with clinical findings from volumetric images. In Aim 3, we will develop methods that evaluate relationships between shape, mechanics, and clinical findings gleaned from imaging through integrated statistical tests and semi-automatic medical image annotation tools that utilize standard ontologies. Quantitative CT and MRI images of the hip, which estimate bone density and cartilage ultrastructure, respectively, will be evaluated as test datasets. To impart broad impact, we will disseminate our methods to the community as open source software that will call core functionality provided by existing, open source software that has a large user base (FEBio, ShapeWorks). PROJECT NARRATIVE The proposed technology will provide the methodologies necessary to increase the clinical acceptance and applicability of computer models. These models measure three-dimensional tissue shape and estimate tissue mechanics, providing information that cannot be measured conventionally. We will implement these methods into software that can be used by the public free-of-charge.",Computational and Statistical Framework to Model Tissue Shape and Mechanics,9972694,R01EB016701,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anatomy', 'Architecture', 'Bone Density', 'Cardiology', 'Cartilage', 'Characteristics', 'Charge', 'Clinical', 'Communities', 'Computational Technique', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Finite Element Analysis', 'Foundations', 'Funding', 'Geometry', 'Glean', 'Grooming', 'Hip Joint', 'Hip region structure', 'Homeostasis', 'Human Pathology', 'Human body', 'Image', 'Individual', 'Injury', 'Intuition', 'Libraries', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Mechanics', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Neurology', 'Ontology', 'Orthopedics', 'Pathology', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Procedures', 'Process', 'Publishing', 'Quantitative Evaluations', 'Research', 'Resources', 'Scheme', 'Shapes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Model', 'Tissues', 'Training', 'Validation', 'X-Ray Computed Tomography', 'annotation  system', 'base', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data modeling', 'disease diagnosis', 'improved', 'in vivo', 'machine learning algorithm', 'novel', 'open source', 'predictive modeling', 'preservation', 'relating to nervous system', 'repaired', 'shape analysis', 'simulation', 'three-dimensional modeling', 'tool']",NIBIB,UNIVERSITY OF UTAH,R01,2020,563658,228951281,-0.006930550612512447
"A Pragmatic Latent Variable Learning Approach Aligned with Clinical Practice Abstract With growing interest in personalized medicine and the rise of machine learning, constructing good risk prediction and prognostic models has been drawing renewed attention. In this development, much effort is concentrated in identifying good predictors of patient outcomes, although the same level of rigor is often absent in improving the outcome side of prediction. The majority of popular supervised techniques (e.g., regularized logistic regression and its variations), which can be readily applied in risk model development, assumes that the prediction target is a clear single outcome measured at a single time point. In clinical reality, patient outcomes are often complex, multivariate, and measured with errors. Even when a target is a relatively clear univariate outcome (e.g., death, cancer, diabetes, etc), the process that leads to this ultimate outcome often involves complex intermediate outcomes, where predicting and understanding this intermediate process can be crucial in providing effective care and preventing negative ultimate outcomes. The situation calls for a ﬂexible learning framework that can easily incorporate this important but neglected aspect in model development - better characterizing and constructing prediction targets before building prediction models.  Focusing on risk labels as prediction targets, we propose a pragmatic 3-stage learning approach, where we sequentially 1) generate latent labels, 2) validate them using explicit validators, and 3) go on with supervised learning with labeled data. Latent variable (LV) strategies used in Satge 1 have great potentials in handling complex outcome information. The unsupervised nature of LV strategies makes highly ﬂexible data synthesis and organization possible. The same nature, however, can also be seen as esoteric and subjective, which is not desirable in situations where transparency and reproducibility are of great concern such as in risk prediction. As a practical solution to this problem, we propose the use of explicit clinical validators, which not only makes LV-based labels closely aligned with contemporary science and clinical practice, but also makes it possible to automatically validate and narrow a large pool of candidate labels. With the goal of developing a practical and transparent system of learning and inference for clinical research and practice, we formed a highly interdisciplinary team of researchers with expertise in latent variable modeling, machine learning, psychometrics and causal inference along with clinical/substantive expertise. Our streamlined learning framework focuses on direct and transparent validation of latent variable solutions to ensure clear communication across risk model developers, clinical researchers and practitioners. The project ultimately aims to improve personalized treatment and care by improving risk prediction. Narrative This project intends to develop a pragmatic learning and risk predction framework that will facilitate utilization of multivariate data collected from research and health care services, which otherwise is underutilized in developing methods to improve personalized care of future patients. The project ultimately aims to improve personalized treatment and care by improving risk prediction, and therefore will have positive impact on public health.",A Pragmatic Latent Variable Learning Approach Aligned with Clinical Practice,10033908,R01MH123443,"['Address', 'Anxiety', 'Anxiety Disorders', 'Attention', 'Attention deficit hyperactivity disorder', 'Brain', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'Data', 'Decision Making', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Ensure', 'Future', 'Goals', 'Health', 'Heart', 'Hybrids', 'Hyperglycemia', 'Intention', 'Label', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Manic', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Motivation', 'Nature', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Process', 'Psychometrics', 'Public Health', 'Reproducibility', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Science', 'Side', 'Structure', 'Supervision', 'Symptoms', 'System', 'Techniques', 'Time', 'Validation', 'Variant', 'base', 'clinical practice', 'clinical risk', 'comorbidity', 'data exploration', 'flexibility', 'health care service', 'high dimensionality', 'improved', 'improved outcome', 'interest', 'model development', 'neglect', 'personalized care', 'personalized medicine', 'predictive modeling', 'prevent', 'prognostic', 'risk prediction model', 'simulation', 'supervised learning', 'tool', 'treatment planning', 'unsupervised learning']",NIMH,STANFORD UNIVERSITY,R01,2020,565519,560644462,0.00669087819194398
"5/5 CAPER: Computerized Assessment of Psychosis Risk Summary Research suggests that if we can identify individuals at-risk for these disorders early, we may be able to improve the course of illness and hopefully prevent illness onset all together. A first generation of studies suggest that the approach of identifying those at clinical high-risk (CHR), through the use of specialized interviews with help-seeking individuals (with attenuated psychosis symptoms) is a promising strategy for exploring mechanisms associated with illness progression, understanding etiology, and identifying new treatment targets. This work has two major limitations: 1) interview methods have limited specificity as only 15-20% of CHR individuals convert to psychosis, and 2) the expertise needed to make CHR diagnosis is only accessible in a handful of metropolitan centers, and requires extensively trained staff. Here, we aim to lay the foundation for a new approach to CHR assessment that will increase accessibility, and positive predictive value. We propose to develop a new psychosis symptom domain sensitive (PSDS) battery, prioritizing tasks that show correlations with the symptoms that define psychosis (actively tapping into psychotic disorder-specific processes, rather than to trait vulnerability signs) and relatedly, that are tied to the neurobiological systems and computational mechanisms implicated in these symptoms. To promote accessibility, we utilize inexpensive behavioral tasks that could be administered over the internet; this will set the stage for later research testing widespread screening in help-seeking as well as non-help seeking populations, that would identify those most in need of in-depth assessment. Before this can be accomplished however, it is necessary to determine which tasks are effective for predicting illness course and how this strategy compares to the first-generation prediction methods. We propose to recruit 500 CHR participants, 500 help-seeking individuals, and 500 healthy controls across 5 sites and in Aim 1, develop a PSDS battery risk calculator based on measures that prove to be most sensitive to imminent conversion. Further, the inclusion of a help-seeking comparison group is critical for translating the PSDS calculator into clinical practice, where the goal is to differentiate those at greatest risk for developing a psychotic disorder from others forms of psychopathology. In Aim 2, we will compare the sensitivity and specificity of the PSDS risk-calculator to the North American Prodromal Study (NAPLS) risk-calculator (a gold-standard first-generation tool) in the prediction of psychosis conversion over a 2 year- period. Last, in Aim 3, the study will determine if the PSDS predicts functional outcomes over the course of 2 years. Predicting diagnosis is important but being able to provide early intervention to limit the disability characteristic of psychosis is a priority. This project will answer the preliminary questions necessary for a next-generation CHR battery, tied to illness mechanisms and powered by cutting-edge computational methods, that can be used to facilitate the earliest possible detection of psychosis risk. Narrative Early detection of young people at clinical high risk for psychosis offers a critical opportunity for early intervention to improve the course of illness, and perhaps even prevent onset entirely. Current interview- based methods for psychosis risk detection lack specificity, and are only available in a handful of research centers in the United States. The proposed study aims to improve accessibility and broaden impact of high risk screening by testing brief computerized measures, ultimately able to be administered on the internet, and to improve prediction by focusing on tasks specific to underlying mechanisms driving emerging psychotic symptoms.",5/5 CAPER: Computerized Assessment of Psychosis Risk,9984613,R01MH120089,"['Address', 'American', 'Attenuated', 'Automobile Driving', 'Behavioral', 'Biological Markers', 'Characteristics', 'Classification', 'Clinical', 'Collaborations', 'Computing Methodologies', 'Detection', 'Diagnosis', 'Dimensions', 'Early Diagnosis', 'Early Intervention', 'Etiology', 'Foundations', 'Frequencies', 'Functional disorder', 'Generations', 'Goals', 'Gold', 'Human Resources', 'Individual', 'Internet', 'Intervention Trial', 'Interview', 'Joints', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Onset of illness', 'Outcome', 'Participant', 'Patient Self-Report', 'Performance', 'Population', 'Predictive Value', 'Preventive Intervention', 'Primary Prevention', 'Process', 'Psychopathology', 'Psychotic Disorders', 'Public Health', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk', 'Risk Assessment', 'Role', 'Sample Size', 'Secondary Prevention', 'Sensitivity and Specificity', 'Severities', 'Site', 'Specificity', 'Symptoms', 'System', 'Techniques', 'Test Result', 'Testing', 'Training', 'Translating', 'United States', 'Work', 'Youth', 'base', 'clinical practice', 'cognitive testing', 'comparison group', 'computerized', 'design', 'disability', 'disorder risk', 'follow-up', 'functional decline', 'functional outcomes', 'help-seeking behavior', 'high risk', 'high risk population', 'improved', 'machine learning method', 'metropolitan', 'new therapeutic target', 'next generation', 'novel strategies', 'prevent', 'psychotic symptoms', 'recruit', 'relating to nervous system', 'screening', 'social', 'tool', 'trait']",NIMH,YALE UNIVERSITY,R01,2020,572946,550947887,0.0011112892375051689
"Factors associated with hospitalization, ICU use and death among vulnerable populations diagnosed with COVID-19 Project Summary. As of April 30, 2020, over 1 million individuals in the U.S. have been diagnosed with coronavirus disease 2019 (COVID-19). Patients with COVID-19 may develop various symptoms – while the majority of patients have mild symptoms, some require hospitalization, admissions to intensive care unit (ICU), and may die. To date, there is only limited knowledge on risk factors associated with the severity of COVID-19. First, older adults have been found to have higher risks of developing severe symptoms of COVID-19 and are more likely to be hospitalized or die. Studies have suggested that some underlying conditions, such as hypertension, diabetes, or obesity, are associated with the severity of COVID-19. However, it is unknown to what extent these comorbidities explain the variation in the severity of COVID-19, whether older age is independently associated with the severity of COVID-19; and whether and how older age modifies the relationship between comorbidities and the severity of COVID-19. Second, it has been reported that black Americans experienced a higher rate of COVID-related hospitalization and were more likely to die of COVID- 19, compared to white Americans. However, it is unknown what may contribute to such racial difference – whether it is due to the differences in health conditions between blacks and whites, or due to the characteristics of the community where they reside in, or due to some other factors that are also associated with race. The objective of this study is to identify individual risk factors that are associated with the severity of COVID-19 (i.e. hospitalizations, ICU use and death), especially among older adults, and to understand reasons that may contribute to racial differences in COVID-19 severity. To achieve these goals, we will use the daily- updated national Veterans Affairs (VA) data, which contain rich individual-level information on veterans diagnosed with COVID-19. As of April 30, 2020, almost 9,000 veterans have been diagnosed with COVID-19, and about 500 had died, thus providing a large study cohort. This proposed study has two Specific Aims:1) To identify individual risk factors that are associated with COVID-19 related hospitalizations, ICU use and mortality, to understand the role of older age in COVID-19 severity, and to build a predictive model for COVID- 19 severity by machine learning; and 2) To examine reasons for racial differences in illness severity among veterans diagnosed with COVID-19: whether and how such difference is related to individual factors and community characteristics, especially socio-economic status. This study is innovative because it will be the first study to examine the role of multiple risk factors in the severity of COVID-19 by using national data with detailed individual-level information and machine learning algorithm; and it will be the first to examine the reasons, including the role of social determinants, for racial differences in COVID-19 severity. This proposed research is significant as it will help to identify patients with the highest-risk phenotypes, thus providing insights into disease prevention and resource allocation. Project Narrative: This proposed research aims to understand risks factors associated with the severity of COVID-19 (i.e. hospitalization, ICU use and death) and the role of older age in the severity of COVID-19; and to examine reasons leading to racial differences in the severity of COVID-19. This proposed research is highly relevant to public health because the findings from this study will help target prevention strategies and allocation of resources to high-risk populations and help fight this novel infectious disease.","Factors associated with hospitalization, ICU use and death among vulnerable populations diagnosed with COVID-19",10159581,RF1AG063811,"['Address', 'Admission activity', 'African American', 'Age', 'COVID-19', 'Caring', 'Cessation of life', 'Characteristics', 'Cohort Studies', 'Communicable Diseases', 'Communities', 'Data', 'Death Rate', 'Diabetes Mellitus', 'Diagnosis', 'Elderly', 'Ensure', 'Goals', 'Grant', 'Health', 'Hospitalization', 'Hypertension', 'Individual', 'Intensive Care Units', 'Knowledge', 'Machine Learning', 'Obesity', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population', 'Prevention strategy', 'Public Health', 'Race', 'Recording of previous events', 'Reporting', 'Research', 'Resource Allocation', 'Risk Factors', 'Role', 'Severities', 'Severity of illness', 'Socioeconomic Status', 'Symptoms', 'Time', 'Update', 'Variant', 'Veterans', 'Virus', 'Vulnerable Populations', 'caucasian American', 'comorbidity', 'coronavirus disease', 'disorder prevention', 'experience', 'fighting', 'health administration', 'health difference', 'health service use', 'high risk', 'high risk population', 'innovation', 'insight', 'machine learning algorithm', 'male', 'mortality', 'novel', 'novel virus', 'parent grant', 'predictive modeling', 'racial difference', 'racial health disparity', 'social determinants', 'sociodemographics', 'socioeconomics', 'study population', 'success']",NIA,UNIVERSITY OF ROCHESTER,RF1,2020,578879,179705973,-0.010383603343206193
"1/5 CAPER: Computerized Assessment of ProdromE Risk Summary  Research suggests that early identification of individuals at clinical high risk (CHR) for psychosis may be able to improve illness course. Studies suggest that early identification of CHR using specialized interviews with help-seeking individuals (with attenuated psychosis symptoms) is a useful approach. This work has two major limitations: 1) interview methods have limited specificity as only 20% of CHR individuals convert to psychosis, and 2) the expertise needed to make CHR diagnosis is only accessible in a few academic centers. We propose to develop a new psychosis symptom domain sensitive (PSDS) battery, prioritizing tasks that show correlations with the symptoms that define psychosis and are tied to the neurobiological systems and computational mechanisms implicated in these symptoms. To promote accessibility, we utilize behavioral tasks that could be administered over the internet; this will set the stage for later research testing widespread screening that would identify those most in need of in-depth assessment. To reach that goal we first need determine which tasks are effective for predicting illness course and how this strategy compares to published prediction methods. We propose to recruit 500 CHR participants, 500 help-seeking individuals, and 500 healthy controls across 5 sites with the following Aims: Aim 1A) To develop a psychosis risk calculator through the application of machine learning (ML) methods to the measures from the PSDS battery. In an exploratory ML analysis, we will determine the added value of combining the PSDS with self-report measures and historical predicators; Aim 1B) We will evaluate group differences on the risk calculator score and hypothesize that the risk calculator score of the CHR group will differ from help-seeking and healthy controls. We further hypothesize that the risk calculator score of the CHR converters will differ significantly from groups of CHR nonconverters, help-seeking and healthy controls. The inclusion of a help-seeking group is critical for translating the risk-calculator into clinical practice, where the goal is to differentiate those at greatest risk for psychosis from those with other forms of psychopathology; Aim 1C): Evaluate how baseline PSDS performance relates to symptomatic outcome 2 years later examining: 1) symptomatic worsening treated as a continuous variable, and 2) conversion to psychosis. We hypothesize that the PSDS calculator: 1) will predict symptom course and, 2) that the differences observed between converters and nonconverters will be larger on the PSDS calculator than on the NAPLS calculator. Aim 2) Use ML methods, as above, to develop calculators that predict: 2A) social, and, 2B) role function deterioration, both observed over two years. Because negative symptoms are more strongly linked to functional outcome than positive symptoms, we predict that negative symptom mechanism tasks will be the strongest predictor of functional decline in both domains. This project will provide a next-generation CHR battery, tied to illness mechanisms and powered by cutting-edge computational methods that can be used to facilitate the earliest possible detection of psychosis risk. Narrative  Early detection of young people at clinical high risk for psychosis offers a critical opportunity for early intervention to improve the course of illness, and perhaps even prevent onset entirely. Current interview-based methods for psychosis risk detection lack specificity, and are only available in a handful of research centers in the United States. The proposed study aims to improve accessibility and broaden impact of high risk screening by testing brief computerized measures, ultimately able to be administered on the internet, and to improve prediction by focusing on tasks specific to underlying mechanisms driving emerging psychotic symptoms.",1/5 CAPER: Computerized Assessment of ProdromE Risk,9975396,R01MH120090,"['Address', 'American', 'Attenuated', 'Automobile Driving', 'Behavioral', 'Biological Markers', 'Classification', 'Clinical', 'Collaborations', 'Computing Methodologies', 'Detection', 'Deterioration', 'Diagnosis', 'Dimensions', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Foundations', 'Frequencies', 'Functional disorder', 'Generations', 'Goals', 'Human Resources', 'Individual', 'Internet', 'Intervention Trial', 'Interview', 'Joints', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Outcome', 'Participant', 'Patient Self-Report', 'Performance', 'Population', 'Predictive Value', 'Preventive Intervention', 'Primary Prevention', 'Psychopathology', 'Psychotic Disorders', 'Public Health', 'Publishing', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk', 'Role', 'Sample Size', 'Secondary Prevention', 'Sensitivity and Specificity', 'Severities', 'Site', 'Specificity', 'Symptoms', 'System', 'Techniques', 'Test Result', 'Testing', 'Training', 'Translating', 'United States', 'Work', 'Youth', 'base', 'clinical practice', 'cognitive testing', 'computerized', 'design', 'follow-up', 'functional decline', 'functional outcomes', 'help-seeking behavior', 'high risk', 'high risk population', 'improved', 'machine learning method', 'new therapeutic target', 'next generation', 'prevent', 'psychotic symptoms', 'recruit', 'relating to nervous system', 'screening', 'social', 'trait']",NIMH,UNIVERSITY OF MARYLAND BALTIMORE,R01,2020,589572,230060143,0.0014000257970971754
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,9935719,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Asses', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2020,599090,340417756,-0.0037496865387155257
"Multimodality imaging-driven multifidelity modeling of aortic dissection PROJECT SUMMARY. Aortic dissections are responsible for significant morbidity and mortality in young and old individuals alike. Whereas type A (ascending aorta) dissections are treated aggressively via surgery, type B (descending thoracic aorta) dissections are often monitored for long periods to determine the best treatment. These lesions can cease to propagate (i.e., stabilize or heal) or they can propagate further and either turn inward and connect again with the true lumen to form a re-entry tear or turn outward and result in rupture in the case of an compromised adventitia. Notwithstanding the importance of these later events, there is a pressing need to understand better the early processes that initiate the dissection and drive its initial propagation as well as to determine whether the presence of intramural thrombus is protective or not against early or continued propagation. Over the past 5 years our collaborative team has developed numerous new multimodality imaging techniques, biomechanical testing methods, and computational modeling approaches across multiple scales that uniquely positions us to understand better the process of early aortic dissection and the possible roles played by early intramural thrombus development. In this project, we propose to use nine complementary mouse models to gain broad understanding of the bio-chemo-mechanical processes that lead to aortic dissection and to introduce a new machine learning based multifidelity modeling approach to develop predictive probabilistic multiscale models of dissection. These models will be informed, trained, and validated via data obtained from a combination of unique in vitro biomechanical phenotyping experiments (wherein we can, for the first time, quantify the initial delamination process under well-controlled conditions and regional material properties thereafter) and novel multimodality imaging of delamination / dissection both in vitro and in vivo. We will consider, for example, the roles of different elastic lamellar geometries; we will assess separate roles of focal proteolytic activation and pooling of highly negatively charged mucoid material, which can degrade or swell the wall respectively; and we will model and assess the effects of early thrombus deposition within a false lumen. We submit that our new probabilistic paradigm, based on statistical autoregressive schemes and enabled by machine learning tools, could be transformative and lead to a paradigm shift in disease prediction where historical data, animal experiments, and limited clinical input (e.g., multiomics) can be used synergistically for robust prognosis and thus interventional planning. Our work is also expected to lead naturally to an eventual better understanding of the chronic processes associated with dissection via predictive models that are aided by the expected “revolution of resolution” in diagnostic imaging. PUBLIC HEALTH RELEVANCE Mounting evidence reveals that thoracic aortic dissections – which afflict young and old individuals alike – are responsible for even greater disability and death than long thought. We will use a unique combination of multiple mouse models, advanced medical imaging, and novel computational models to elucidate the mechanisms responsible for the initiation of a dissection and reasons for the extreme biological variability that characterizes these lethal lesions.",Multimodality imaging-driven multifidelity modeling of aortic dissection,9981804,U01HL142518,"['Acute', 'Address', 'Animal Experiments', 'Animal Model', 'Aorta', 'Aortic Rupture', 'Arteries', 'Attention', 'Biological', 'Biomechanics', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blunt Trauma', 'Carotid Arteries', 'Categories', 'Cervical', 'Cessation of life', 'Charge', 'Chest', 'Child', 'Chronic', 'Clinical', 'Coagulation Process', 'Collaborations', 'Communities', 'Computer Models', 'Coupling', 'Data', 'Defect', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dilatation - action', 'Disease', 'Dissection', 'Elderly', 'Event', 'Foundations', 'Geometry', 'Glycosaminoglycans', 'Goals', 'Heritability', 'Human', 'Hypertension', 'Image', 'Imaging Techniques', 'In Vitro', 'Individual', 'Infusion procedures', 'Intervention', 'Knowledge', 'Lead', 'Lesion', 'Long-Term Effects', 'Machine Learning', 'Mechanics', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Motivation', 'Multimodal Imaging', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Phase', 'Phenotype', 'Platelet aggregation', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Property', 'Research', 'Resolution', 'Risk Factors', 'Role', 'Rupture', 'Scheme', 'Site', 'Solid', 'Statistical Models', 'Testing', 'Thoracic aorta', 'Thrombus', 'Time', 'Training', 'Tunica Adventitia', 'Ultrasonography', 'Uncertainty', 'Video Microscopy', 'Work', 'ascending aorta', 'base', 'digital imaging', 'disability', 'experimental study', 'healing', 'hemodynamics', 'improved', 'in silico', 'in vivo', 'insight', 'intracranial artery', 'microSPECT', 'mortality', 'mouse model', 'mucoid', 'multi-scale modeling', 'multiple omics', 'normotensive', 'novel', 'novel strategies', 'outcome forecast', 'particle', 'predictive modeling', 'public health relevance', 'spatiotemporal', 'supervised learning', 'tool', 'virtual', 'young adult']",NHLBI,YALE UNIVERSITY,U01,2020,601275,550947887,-0.0021930255808257255
"Development and Deployment of Artificial Intelligence (AI) Driven Methods to Enable Chest X-ray Radiography as an Alternative Diagnostic Method for COVID-19 Pneumonia ABSTRACT In this competitive revision, within the same scope of developing and deploying algorithms to make a quantum leap in clinical diagnosis as that in our current U01EB021183, we would like to revise the original aims to add a new Aim to leverage our expertise in the areas of algorithm development and clinical translation to make immediate contributions to combat the COVID-19 pandemic. Specifically, we propose to develop and deploy artificial intelligence (AI) methods to enable chest x-ray radiography (CXR) as an alternative diagnostic tool to diagnose COVID-19 pneumonia, to rapidly triage patients for appropriate treatment, to monitor the treatment response in a contained environment, and to optimize the distribution of the limited medical resources during the current COVID-19 crisis. PROJECT NARRATIVE In this project, our overarching objective is to develop automated artificial intelligence (AI)-based algorithms to help radiologists to differentiate COVID-19 related pneumonia from other non-COVID-19 related pneumonia using CXR images. The advantages of the proposed AI equipped CXR technique include: i) widely available, ii) inexpensive, iii) excellent coronavirus exposure profile for patient, technologist, and equipment, and iv) rapid and automated DL interpretation, which is effectively instantaneous.",Development and Deployment of Artificial Intelligence (AI) Driven Methods to Enable Chest X-ray Radiography as an Alternative Diagnostic Method for COVID-19 Pneumonia,10156179,U01EB021183,"['Accident and Emergency department', 'Air', 'Algorithms', 'American College of Radiology', 'Anosmia', 'Appearance', 'Area', 'Artificial Intelligence', 'Bilateral', 'COVID-19', 'COVID-19 pandemic', 'Case Study', 'Cessation of life', 'China', 'Clinic', 'Clinical', 'Communities', 'Containment', 'Coronavirus', 'Coughing', 'Country', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic Sensitivity', 'Diagnostic radiologic examination', 'Diarrhea', 'Disease', 'Disease Outbreaks', 'Dyspnea', 'Environment', 'Equipment', 'European', 'Exposure to', 'Fatigue', 'Fever', 'Glass', 'Gold', 'Health Personnel', 'Health care facility', 'Hospitals', 'Human', 'Image', 'Individual', 'Investigation', 'Lung', 'Lung diseases', 'Medical', 'Medical Imaging', 'Methods', 'Monitor', 'North America', 'Parents', 'Pathway interactions', 'Patient Triage', 'Patients', 'Performance', 'Persons', 'Pleural effusion disorder', 'Pneumonia', 'Process', 'Radiology Specialty', 'Reading', 'Reporting', 'Resources', 'Reverse Transcriptase Polymerase Chain Reaction', 'Rural', 'Sensitivity and Specificity', 'Societies', 'Symptoms', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Triage', 'United States', 'Viral Pneumonia', 'War', 'World Health Organization', 'X-Ray Computed Tomography', 'accurate diagnosis', 'algorithm development', 'base', 'chest computed tomography', 'clinical Diagnosis', 'clinical translation', 'combat', 'deep learning', 'high risk', 'high risk population', 'imaging facilities', 'imaging modality', 'improved', 'intelligent algorithm', 'neural network architecture', 'pandemic disease', 'prevent', 'profiles in patients', 'quantum', 'radiologist', 'screening', 'success', 'tool', 'treatment response', 'urgent care']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,U01,2020,605070,338121506,-0.0043037748638297775
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,9941090,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Catalogs', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2020,605875,560644462,0.004180472926484033
"Learning to Predict Delayed Cerebral Ischemia with Novel Continuous Cerebral Arterial State Index Project Summary  Delayed cerebral ischemia (DCI) is the most devastating complication after aneurysmal subarachnoid hemorrhage (aSAH) and has an incidence rate of 30%. Current practice relies on intermittent assessment of neurological status and daily cerebral blood flow velocity (CBFV) by Transcranial Doppler ultrasound (TCD) to guide medical management to prevent DCI. Only after medical management fails, is endovascular treatment (EVT) including intraarterial vasodilator infusion and/or intracranial angioplasty initiated. This reactive practice does not account for early predictors of DCI and may miss the optimal EVT window at an early stage of DCI development before symptoms or severe deviations from normal hemodynamics. The goal of this project is to develop algorithms to predict DCI and related targets at an early stage in their development. An accurate prediction of DCI will enable a more proactive strategy to prevent and treat the underlying cause of DCI.  The following three aims will be pursued towards the goal of the project: 1) Develop aSAH-specific intracranial pressure (ICP) pulse-based cerebral arterial state index; 2) Develop and validate predictive models of targets related to delayed cerebral ischemia after aSAH; 3) Conduct a prospective institution- specific adaption and validation of the developed models.  Our DCI predictive algorithms only need data available in current clinical practice hence they can be readily adopted. If validated, these algorithms will enable clinicians to monitor risk of DCI continuously and to proactively deliver appropriate treatment. The proposed prospective study of algorithm implementation and adaptation will well prepare future clinical trials to test the efficacy of algorithm-informed interventions. Project Narrative  Delayed cerebral ischemia (DCI) is a devastating complication after aneurysmal subarachnoid hemorrhage (aSAH) and has an incidence rate of 30%. Current practice relies on intermittent assessment of neurological status and daily cerebral blood flow velocity (CBFV) by Transcranial Doppler ultrasound (TCD) to guide medical management to prevent DCI. The goal of this project is to develop algorithms to predict DCI and other related targets at an early stage in their development to enable a more proactive strategy to prevent and treat the underlying cause of DCI.",Learning to Predict Delayed Cerebral Ischemia with Novel Continuous Cerebral Arterial State Index,10070930,R01NS113541,"['Acute', 'Adopted', 'Algorithms', 'Aneurysmal Subarachnoid Hemorrhages', 'Angioplasty', 'Appearance', 'Area', 'Blood Flow Velocity', 'Cerebral Ischemia', 'Cerebral perfusion pressure', 'Cerebrovascular Circulation', 'Cerebrum', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Complication', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Diagnosis', 'Dilatation - action', 'Distal', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Event', 'Future', 'Goals', 'Hydrocephalus', 'Incidence', 'Individual', 'Infusion procedures', 'Injury', 'Institution', 'Intervention', 'Intracranial Pressure', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Modeling', 'Monitor', 'Morphology', 'Nature', 'Neurologic', 'Neurological status', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Procedures', 'Process', 'Prospective Studies', 'Pulse Pressure', 'Recurrence', 'Reproducibility', 'Research', 'Risk', 'Shapes', 'Signal Transduction', 'Source', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Training', 'Transcranial Doppler Ultrasonography', 'Validation', 'Vasodilator Agents', 'base', 'clinical practice', 'constriction', 'data streams', 'diagnostic accuracy', 'efficacy testing', 'electronic data', 'hemodynamics', 'improved', 'indexing', 'machine learning algorithm', 'novel', 'prediction algorithm', 'predictive modeling', 'prevent', 'prospective', 'recurrent neural network', 'relating to nervous system', 'temporal measurement', 'vector']",NINDS,DUKE UNIVERSITY,R01,2020,612984,607172798,0.0009404186129034091
"Leveraging Social Media Data and Machine Learning to Optimize Treatment Paradigms for Youth with Schizophrenia Abstract Schizophrenia constitutes a chronic and disabling illness. While patients show high rates of response to treatment after a ﬁrst-episode of schizophrenia, the long-term course of the illness is typically characterized by frequent re- lapses, persistence of symptoms, and enduring cognitive and functional deﬁcits. Despite the prioritization of relapse prevention as a treatment goal, about four out of ﬁve patients experience a relapse within the ﬁrst ﬁve years of treatment. Relapses are known to have serious psychosocial, educational, or vocational implications in young adults—a population at high risk of psychosis. However, current psychiatric ability to recognize indicators of relapse in order to prevent escalation of psychotic symptoms is markedly limited. Challenges stem from a lack of availability of comprehensive information about early warning signs, and reliance on ﬁxed time point sampling of cross-sectional data as well as patient or family reported observations, that is subject to recall bias, or on clin- ician sought information, that needs frequent and timely contact. The present proposal seeks to address these gaps in early psychosis treatment, by leveraging patient-generated and patient-volunteered social media data, and developing and validating machine learning approaches for “digital phenotyping” and relapse prediction. Our proposed work is founded on the observation that social media sites have emerged as prominent platforms of emotional and linguistic expression—young adults are among the heaviest users of social media. The work signif- icantly advances the research agenda and extensive pilot investigations of the team, who a) have demonstrated that social media data of individuals can serve as a powerful “lens” toward understanding and inferring mental health state, illness course, and likelihood of relapse, including among young adults with early psychosis; and b) have been involved in examining the role of emergent technologies, like social media, in improving access to and delivery of psychiatric care. Aim 1 will provide theoretically-grounded and clinically meaningful methods for extracting and modeling digital phenotypes and symptoms from social media data of young adult early psychosis patients. Then in Aim 2, we will develop and evaluate machine learning methods that will utilize the extracted social media digital phenotypes to infer patient-speciﬁc personalized risk of relapse, and identify its antecedents. Finally, Aim 3 will develop a two-faceted validation framework, to assess the statistical and clinical efﬁcacy and utility of the social media derived inferences of psychosis and relapse in inﬂuencing clinical outcomes and in facilitating evidence-based treatment. To accomplish these aims, the project brings together a strong multidisci- plinary team, combining expertise in social media analytics, psychiatry, psychology, natural language analysis, machine learning, information privacy, and research ethics. Our novel approach offers unprecedented opportuni- ties to initiate the adoption of personalized, responsive, and preemptive evidence-based strategies in treatment of psychosis. The knowledge will set the stage for future research on launching large-scale trials aimed to develop interventions that diminish the severity of relapses, or prevent their occurrence altogether. Project Narrative Timely monitoring of symptoms and preventing relapse after an initial psychotic episode are essential component of early intervention programs and have a critical impact on long term outcome in individuals with psychotic dis- orders. Employing patient-contributed social media data as a viable source of collateral information, this proposal provides a suite of robust, scalable, and ﬁeld evaluated machine learning methods to facilitate early and precise identiﬁcation of digital phenotypes, symptomatic exacerbation, and risk of psychotic relapse in early psychosis patients. The knowledge would provide the necessary opportunity to initiate personalized, adaptive, and proac- tive illness management strategies, inform better nosology, and assist the adoption of improved evidence-based care approaches to diminish the severity of relapses, or prevent their occurrence altogether.",Leveraging Social Media Data and Machine Learning to Optimize Treatment Paradigms for Youth with Schizophrenia,9914128,R01MH117172,"['Address', 'Adolescent and Young Adult', 'Adopted', 'Adoption', 'Affect', 'Aftercare', 'Behavior', 'Behavioral', 'Big Data', 'Biometry', 'Caring', 'Chronic', 'Circadian Rhythms', 'Clinical', 'Clinical Data', 'Clinical Psychology', 'Clinical Research', 'Clinical Trials', 'Cognition', 'Cognitive', 'Computational Technique', 'Computers', 'Computing Methodologies', 'Data', 'Data Collection', 'Deterioration', 'Development', 'Disorientation', 'Doctor of Philosophy', 'Early Diagnosis', 'Early Intervention', 'Emerging Technologies', 'Emotional', 'Evaluation', 'Evidence based treatment', 'Family', 'Feedback', 'Foundations', 'Goals', 'Health', 'Hospitalization', 'Improve Access', 'Individual', 'Intervention', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methods', 'Monitor', 'Moods', 'National Institute of Mental Health', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Phenotype', 'Population', 'Privacy', 'Psychiatric therapeutic procedure', 'Psychiatry', 'Psychology', 'Psychotic Disorders', 'Relapse', 'Reporting', 'Research', 'Research Ethics', 'Research Methodology', 'Risk', 'Role', 'Sampling', 'Schizophrenia', 'Scientist', 'Severities', 'Site', 'Social Functioning', 'Social Psychology', 'Source', 'Stigmatization', 'Strategic Planning', 'Suicide', 'Surface', 'Symptoms', 'Techniques', 'Testing', 'Texas', 'Theoretical model', 'Time', 'Universities', 'Validation', 'Violence', 'Work', 'Youth', 'base', 'biological research', 'biomarker development', 'clinical decision support', 'clinical efficacy', 'clinical heterogeneity', 'cohort', 'computational basis', 'deep learning', 'digital', 'digital media', 'digital models', 'disability', 'disease classification', 'disorder later incidence prevention', 'evidence base', 'experience', 'family burden', 'first episode schizophrenia', 'high risk', 'improved', 'innovative technologies', 'intervention program', 'lens', 'machine learning method', 'medical complication', 'multidisciplinary', 'natural language', 'novel', 'novel strategies', 'peer', 'personalized intervention', 'prevent', 'prospective', 'psychosocial', 'psychotic symptoms', 'recruit', 'relapse patients', 'relapse prediction', 'relapse risk', 'response', 'social', 'social media', 'social observations', 'stem', 'support tools', 'treatment optimization', 'treatment response', 'treatment strategy', 'volunteer', 'willingness', 'young adult']",NIMH,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2020,640014,45341731,-0.006612492035219154
"Clinical Biomechanics of Hip Fracture Over 300,000 hip fractures occur each year in the U.S. and up to 25% of hip-fracture patients die within a year of their injury. Despite the importance of this clinical problem, the diagnostic screening rate for osteoporosis is only 5% of the eligible population, and the sensitivity of measuring bone mineral density (BMD) by DXA, the clinical standard test for diagnosis, is only 50%. Therefore, most patients are not being screened diagnostically for osteoporosis, and for those who are, about half who will experience a hip fracture are missed. Given that the current empirical approach is inadequate, we propose to pursue a more mechanistic approach, combining state-of-the-art biomechanics and machine learning approaches. Biomechanically, the three etiological elements of hip fracture are fall risk, femoral strength, and femoral impact force. In this project, our overall goal is to provide a deeper understanding of how all three biomechanical etiological elements interact in the event of a hip fracture and from that, directly improve clinical fracture risk assessment through the use of a single predictive “Integral Biomechanical Risk (IBR)” parameter. In addition, we will also address the problem of low DXA screening rates by further developing our Biomechanical Computed Tomography (BCT) technology. This test estimates the breaking strength of the femur using finite element analysis of routine clinical CT scans previously acquired for any medical reason, and represents an improvement compared to the use of BMD alone. Since millions of patients are scanned with CT each year, this approach could double screening rates if offered as an alternative to DXA. The proposed study will investigate this biomechanical approach in a large incident hip fracture, case-cohort study (3,000 patients with hip fracture, 6,000 without). This retrospective study will include patients seen at Kaiser Permanente who had an abdominal CT scan as part of medical care prior to any hip fracture; and have standard geriatric measurements in their electronic medical records, which we will use to estimate fall risk. Specifically, our aims are to: 1) utilize electronic medical record data and CT scans to obtain patient-specific measurements related to fall risk, femoral strength, and fall severity, and 2) combine the different elements of hip fracture etiology into the IBR parameter to test the hypothesis that this metric predicts hip fracture independent of age, sex, BMI, race/ethnicity, and history of prior fracture and improves hip fracture prediction compared to the clinical standard (BMD with FRAX). Scientifically, a major novelty of this work is its use of contemporary machine learning algorithms to inform construction of a mechanistic model of the three etiological elements of hip fracture, which should better capture any interactions between these elements compared to a purely statistical-regression approach. In addition, the study cohort will be the largest and most diverse CT-based hip fracture cohort ever assembled. Importantly, positive results from this project would provide a compelling “second front” to DXA that could be quickly translated to widespread clinical practice, profoundly impacting osteoporosis care. STATEMENT OF RELEVANCE More than half of individuals who experience hip fracture do not have osteoporosis as assessed by DXA. This project draws together the latest technological advances in CT-based finite element modeling and combines it into a probabilistic model of fracture risk that uses as inputs, data typically available in medical records. By going beyond BMD, the fracture risk prediction tool developed by this work aims to significantly improve clinical fracture risk assessment and substantially impact the preventative care and treatment of osteoporosis.",Clinical Biomechanics of Hip Fracture,9886227,R01AR074958,"['Accounting', 'Address', 'Age', 'Algorithms', 'Archives', 'Biomechanics', 'Blinded', 'Bone Density', 'Calibration', 'Caring', 'Clinical', 'Clinical Data', 'Clinical assessments', 'Cohort Studies', 'Complex', 'Computerized Medical Record', 'Data', 'Diagnosis', 'Discrimination', 'Dual-Energy X-Ray Absorptiometry', 'Economics', 'Elderly', 'Elements', 'Ensure', 'Equilibrium', 'Ethnic Origin', 'Etiology', 'Evaluation', 'Event', 'Fatty acid glycerol esters', 'Femur', 'Finite Element Analysis', 'Fracture', 'Goals', 'Health', 'Hip Fractures', 'Individual', 'Injury', 'Intramuscular', 'Investigation', 'Logistics', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Modeling', 'Muscle', 'Osteoporosis', 'Pathway interactions', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Preventive care', 'Preventive treatment', 'Probability', 'Race', 'Recording of previous events', 'Regression Analysis', 'Retrospective Studies', 'Risk', 'Risk Assessment', 'Risk Factors', 'Scanning', 'Severities', 'Shapes', 'Spatial Distribution', 'Statistical Models', 'Technology', 'Testing', 'Thick', 'Tissues', 'Training', 'Translating', 'Validation', 'Weight', 'Work', 'X-Ray Computed Tomography', 'abdominal CT', 'base', 'biomechanical model', 'bone', 'bone strength', 'clinical practice', 'clinical risk', 'clinical translation', 'cohort', 'diagnostic screening', 'ductile', 'electronic data', 'experience', 'fall risk', 'falls', 'fracture risk', 'high risk', 'hip bone', 'improved', 'indexing', 'insight', 'kinematics', 'machine learning algorithm', 'neuromuscular', 'older patient', 'patient health information', 'screening', 'sex', 'soft tissue', 'standing height', 'theories', 'tool']",NIAMS,"O. N. DIAGNOSTICS, LLC",R01,2020,647058,647058,-0.005085811990800441
"Shape up! Kids Project Summary/Abstract Of all markers of pediatric health, the most intuitive is body shape. Human and animal studies indicate that weight loss/gain correlates closely with increasing/decreasing insulin sensitivity, respectively. Anthropometry and regional composition measures such as waist circumference, waist to hip ratio (WHR), and visceral adipose tissue area are better predictors of obesity-related diseases and mortality risk than pediatric body mass index Z-score. Dual-energy X-ray absorptiometry can quantify regional adiposity in more detail than these measures but is underutilized for many reasons including the sensitivity to children to ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments in optical technology to better describe phenotypes of pediatric body shape and its relation to metabolic risks (obesity, “failure to thrive”) and bone density and size. If successful, sophisticated obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment technology. The long term goal of the Shape Up! Kids Study is 1) to provide pediatric phenotype descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, muscle mass, lean mass, and percent fat) and bone mineral density (BMD) over a wide range of ages (5 to 18 years), weights and heights, stratified by sex, and ethnicity. Our central hypothesis is that optical estimates with shape classification of soft tissue composition and bone density better predict fracture and metabolic risk factors than anthropometry (WC, WHR, and BM) alone. The Investigators will highly leverage existing data from the National Health and Nutrition Examination Survey and Bone Mineral Density in Children Study. Our specific aims are: 1) Identify the unique associations of body shape to body composition and bone density indices in a pediatric population that represents the variance found in the US population, 2) Describe the precision and accuracy of optical scans to monitor change in body composition, bone density, 3) Estimate the level of association of optical scans to common health indicators including metabolic risk factors. Our exploratory aim is to investigate holistic, high-resolution descriptors of 3D body shape as direct predictors of body composition and metabolic risk using statistical shape models and Latent Class Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self-assessment technologies that are capable of representing over 95% of the shape variance in the US pediatric population, and to define how these models relate to important metabolic status indicators. The positive impact of these outcomes will be the immediate applicability to other researcher studies and clinicians using the automated tools and models developed here for 3D optical images. PROJECT NARRATIVE  The proposed research is relevant to public health because they have the potential to provide a better understanding of what children are at high risk of metabolic consequences of obesity. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults, and are becoming epidemic in children as well. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Shape up! Kids,9850234,R01DK111698,"['3-Dimensional', 'Adipose tissue', 'Adult', 'Age', 'Algorithms', 'Animals', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Surface', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Bone Density', 'Child', 'Childhood', 'Classification', 'Clinical', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Epidemiology', 'Ethnic Origin', 'Failure to Thrive', 'Fatty acid glycerol esters', 'Fracture', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Liver', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'Muscle', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Pediatric Radiology', 'Personal Satisfaction', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Factors', 'Safety', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Visceral', 'Visceral fat', 'Waist-Hip Ratio', 'Weight', 'bone', 'clinical practice', 'cost', 'disorder prevention', 'disorder risk', 'handheld mobile device', 'health assessment', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolomics', 'mortality', 'mortality risk', 'muscle form', 'optical imaging', 'predictive modeling', 'sensor', 'sex', 'soft tissue', 'subcutaneous', 'tool', 'waist circumference']",NIDDK,UNIVERSITY OF HAWAII AT MANOA,R01,2020,647631,45734163,0.021316360644854374
"Multi-site External Validation and Improvement of a Clinical Screening Tool for Future Firearm Violence ABSTRACT  Interventions in clinical settings, such as the emergency department (ED), are an opportunity for interpersonal firearm violence prevention, particularly among youth, whom interpersonal firearm violence disproportionately affects. A crucial prerequisite to successful clinical interventions is an accurate gauge of risk, to ensure the judicious allocation of scarce resources; providing that missing prerequisite is the primary goal of the proposed work. Machine learning methods, in contrast to traditional inferential statistical models, are distinguished by their emphasis on prospective prediction, and have enhanced clinical prediction in several fields, including heart disease, cancer diagnosis and outcomes, PTSD, suicide risk, and substance use, among others. Yet, with the exception of the SAFETY score—developed by the current investigative team—machine learning methods have not been leveraged to prospectively predict firearm violence. In this proposed work our research objectives are two-fold: 1) Externally validate the SAFETY score by determining its ability to predict firearm violence involvement within the next year on a new data set; and 2) Improve the SAFETY score by conducting a comparative analysis of four powerful machine learning methods: elastic net penalized logistic regression, random forests, support vector machines, and boosting (ensemble) methods. In this way, we are responding to Objective One: Research to help inform the development of innovative and promising opportunities to enhance safety and prevent firearm-related injuries, deaths, and crime. This approach is innovative because it builds upon the only work to apply machine learning methods to firearm violence prediction, and it is a promising opportunity to prevent firearm injuries because it will a) provide an explicit gauge of future firearm violence risk; and b) characterize risk factor effects in terms of their prospective prediction ability, unlike any prior research. Thus this research will both identify individuals in most need of intervention, and also point to potentially modifiable predictive factors. Properly addressing this research question in a generalizable way requires a contemporary data set with 1) a focus on a high-need, yet broad, study population; 2) comprehensive baseline measures that provide a broad basis for prediction; and 3) geographic variability (Midwest, West Coast, and East Coast) that enhances generalizability. Thus, we will recruit 1,500 youth age 18-24 from urban EDs in three broadly different locales—Flint, Philadelphia, and Seattle—and administer a baseline survey covering several domains of potential risk factors for future violence, and follow up with those youth at 6- and 12-months to ascertain the primary outcome—firearm violence involvement (as victim or perpetrator)—as well as the secondary outcomes: high-risk firearm behaviors, non-firearm violence, and violent injury. Because this work requires a prospective longitudinal study, we are applying for Option B. This work will lay the ground for future research involving the development and testing of interventions for interpersonal firearm violence both by identifying potential high- leverage modifiable predictive factors, and by identifying youth most in need of intervention. PROJECT NARRATIVE  The purpose of the proposed work is to harness cutting-edge machine learning methods to optimize prediction of future firearm violence so that prevention resources can be allocated efficiently. In service to that goal, we will recruit participants age 18-24 from three urban emergency departments, administer a comprehensive assessment, and use the measurements taken there to predict firearm violence over the following year. The proposed work will provide generalizable knowledge on what factors are most predictive of future firearm violence, which will contribute to future intervention strategies both in terms of content and in terms of optimally determining which people require intervention.",Multi-site External Validation and Improvement of a Clinical Screening Tool for Future Firearm Violence,10162695,R01CE003294,[' '],NCIPC,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,649991,641965656,-0.04072335552383943
"Rapid Low-Cost Quantitative 3D MRI and Gait Assessment of the Knee Project Abstract Motivation: Osteoarthritis (OA) is a painful disease that affects tens of millions of Americans, but is poorly understood, resulting in a lack of treatments. Enabling low-cost approaches for widespread study of risk factors, onset and early progression of OA will enable better understanding of OA mechanisms, treatment development, and triage of patients to different treatments based on speciﬁc disease phenotypes. Multiple systemic factors, biochemical factors, and other risk factors are associated with OA, but causes are difﬁ- cult to isolate and study during slow progression. Currently OA is diagnosed as joint-space narrowing using X-ray radiography, at a stage well beyond when interventions can be effective. Magnetic resonance imaging (MRI) of- fers sensitivity to morphologic and biochemical changes, but most methods are impractical for widespread clinical or research use. Usually MRI exams study only one knee, precluding the opportunity to compare knees. Sim- ilarly, biomechanics assessment typically requires numerous tests using advanced and rarely-available equip- ment and time-intensive analysis by skilled personnel, making this a challenge for widespread use. We have shown rapid, simultaneous 3D scanning of both knees with quantitative relaxometry and diffusion map- ping of connective tissues, combined with novel visualization of longitudinal change validated in a population with anterior cruciate ligament (ACL) tears. We have developed fully-automated cartilage and meniscus seg- mentation to simplify post-processing. (Our automated cartilage segmentation variability approaches that of reader-to-reader variability.) We now propose to combine MRI acquisition, reconstruction and analysis tech- niques with simple measures of kinematics into a widely applicable low-cost imaging and biomechanical test, which we will validate in subjects with ACL-injury and subjects with varying Kellgren-Lawrence grades of OA. Approach: We will begin by developing a robust 5-to-8-minute bilateral knee MRI exam, using an efﬁcient 3D isotropic acquisition and novel deep-learning based image reconstructions. This will be followed with automated cartilage segmentation and quantitative analysis (thickness, T2, diffusion) of all 3 knee plates and automated semiquantitative scoring approaches for synovitis, bone marrow and cartilage lesions. Inertial measurement units (IMUs) will be used to measure kinematics, and gait asymmetries. We will continue our studies in ACL pa- tients to validate techniques and to develop asymmetry analyses for both imaging and biomechanical measures. Finally, in subjects with varying OA grade, we will evaluate the potential of the overall low-cost approach to relate asymmetry and longitudinal change measures to progression and OA grade. Signiﬁcance: This project will develop an acquisition and analysis pipeline to quantify knee changes and left/right asymmetries that precede OA. We will characterize methods in idiopathic OA subjects and ACL- injured subjects at risk of post-traumatic OA. The very low target cost, under $120/subject, will ultimately enable widespread study of early onset and progression of different OA types, leading to earlier and better treatments. Project Narrative Osteoarthritis remains the leading cause of disability, and effective treatment will require efﬁcient assessment of disease risk-factors, onset, and progression, both for development and personalization of minimally invasive interventions. We propose a 5-minute 3D MRI exam of both knees without radiation or contrast injection, that will be combined with low-cost measures of knee motion and fully automated analysis methods to provide quan- titative measurements of cartilage, tendon, ligament, bone and ﬁbrocartilage health and asymmetries between knees. This low-cost, rapid, bilateral assessment will enable research studies in large populations, as well as adding quantitative bilateral information to clinical scans to dramatically improve understanding of onset of dif- ferent types of osteoarthritis.",Rapid Low-Cost Quantitative 3D MRI and Gait Assessment of the Knee,10032904,R01AR077604,"['3-Dimensional', 'Affect', 'American', 'Anterior Cruciate Ligament', 'Articulation', 'Bilateral', 'Biochemical', 'Biomechanics', 'Body mass index', 'Bone Marrow', 'Bone Spur', 'Cartilage', 'Chronic', 'Clinical', 'Cluster Analysis', 'Connective Tissue', 'Cost Measures', 'Coupled', 'Data', 'Data Pooling', 'Degenerative polyarthritis', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Enrollment', 'Environment', 'Equipment', 'Etiology', 'Evaluation', 'Female', 'Fibrocartilages', 'Future', 'Gait', 'Gait abnormality', 'Goals', 'Health', 'Human Resources', 'Image', 'Imaging Techniques', 'Inflammatory', 'Injections', 'Injury', 'Intervention', 'Joints', 'Kellgren-Lawrence grade', 'Knee', 'Knee Osteoarthritis', 'Left', 'Length', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Meniscus structure of joint', 'Methods', 'Morphology', 'Motion', 'Motivation', 'Output', 'Pain', 'Patient Triage', 'Patients', 'Population', 'Protocols documentation', 'Protons', 'Quality of life', 'Quantitative Evaluations', 'Radiation', 'Reader', 'Replacement Arthroplasty', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Risk Factors', 'Roentgen Rays', 'Sampling', 'Scanning', 'Sex Differences', 'Slice', 'Surface', 'Synovitis', 'Techniques', 'Tendon structure', 'Testing', 'Thick', 'Time', 'Tissues', 'Visualization', 'analysis pipeline', 'anterior cruciate ligament injury', 'anterior cruciate ligament rupture', 'automated analysis', 'base', 'bone', 'cohort', 'cost', 'deep learning', 'density', 'disability', 'disease phenotype', 'disorder risk', 'early onset', 'effective therapy', 'gait examination', 'image reconstruction', 'improved', 'kinematics', 'learning classifier', 'meniscus injury', 'minimally invasive', 'novel', 'predictive test', 'primary outcome', 'quantitative imaging', 'reconstruction', 'research study', 'sensor', 'societal costs', 'therapy development', 'tissue biomarkers']",NIAMS,STANFORD UNIVERSITY,R01,2020,658342,560644462,-0.015885747012373497
"Leveraging machine learning to improve risk prediction for chemotherapy induced neuropathy Project Summary/Abstract Chemotherapy-induced peripheral neuropathy (CIPN) affects more than two-thirds of adults with invasive cancer who receive select adjuvant chemotherapies (e.g., taxanes, platinum analogs). Severe CIPN symptoms can lead to chemotherapy dose reductions, treatment delays, or changes in treatment regimens; thereby affecting the potential curative effects of chemotherapy. For some patients, CIPN symptoms can persist over time, contributing to lower quality of life.  Little is known about risk factors for CIPN. Chemotoxicity risk scores have been developed and evaluated for use among elderly patients receiving chemotherapy. However, these tools generally report moderate predictive accuracy (60%-70%), small sample sizes, and short-term follow up. We are aware of no publicly available, validated risk models to assess risk of severe and chronic CIPN among diverse patients at risk for this potentially disabling side effect.  The goal of this proposal is to identify patients at risk for CIPN and to understand how patients and provider interpret and use CIPN risk information in clinical decision-making. Focusing on more than 8,500 insured adults (18+) diagnosed with invasive, stage I-III breast and II-IIIA colorectal cancers (2013-2021) who received adjuvant chemotherapy treatment with known risk for CIPN, we will develop and validate predictive models to quantify the risk of severe CIPN and incident chronic CIPN and assess how CIPN risk information might be used to inform clinical decision-making about cancer treatment and survivorship care planning.  We hypothesize that CIPN risk is a high priority for patients in thinking about treatment choice and survivorship care planning. In addition, we hypothesize that the relative importance of CIPN risk for patient and provider decision-making will vary by patient characteristics (e.g., age, cancer stage). We anticipate that the risk of severe and chronic CIPN can be predicted with a high degree of accuracy using electronic health records and machine learning methods.  The study team has significant and complementary expertise in health services research, biostatistics and predictive modeling, oncology practice, cancer epidemiology, pharmacotherapy, drug safety and the patient care experience. To our knowledge, this will be one of the first studies to develop and validate a CIPN predictive model that can be used by oncology teams to inform treatment and care planning decisions and improve patient-valued outcomes. Translation and replication of the findings will be catalyzed through publication in peer-reviewed journals and the development and distribution of free software to facilitate testing and adaptation of the resulting risk models across diverse systems of care. Narrative Two out of three people treated with select types of chemotherapy experience a side effect known as peripheral neuropathy that causes pain, discomfort and numbness in the extremities and contributes to poor quality of life. We do not know who is at greatest risk for this side effect or how patients and providers weigh the risks of neuropathy against the potentially life-saving benefits of cancer treatment. The proposed study will help identify patients at high risk for chemotherapy induced neuropathy and assess how patients and clinicians might use information about neuropathy risk to make better informed decisions about cancer care.",Leveraging machine learning to improve risk prediction for chemotherapy induced neuropathy,9955985,R01CA249127,"['Address', 'Adjuvant Chemotherapy', 'Adult', 'Affect', 'Age', 'Awareness', 'Biometry', 'Breast', 'Cancer Survivorship', 'Caring', 'Characteristics', 'Chemotherapy-induced peripheral neuropathy', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Colorectal Cancer', 'Communities', 'Complex', 'Computer software', 'Decision Making', 'Development', 'Diagnosis', 'Dose', 'Dose-Limiting', 'Electronic Health Record', 'Goals', 'Health Services Research', 'Impairment', 'Individual', 'Interview', 'Journals', 'Lead', 'Life', 'Limb structure', 'Machine Learning', 'Malignant Neoplasms', 'Mental Depression', 'Methods', 'Modeling', 'Motor', 'Nature', 'Neuropathy', 'Numbness', 'Obesity', 'Oncology', 'Outcome', 'Pain', 'Patient Care', 'Patient Preferences', 'Patients', 'Peer Review', 'Peripheral Nervous System Diseases', 'Pharmacotherapy', 'Platinum', 'Prevention', 'Provider', 'Publications', 'Quality of life', 'Race', 'Reporting', 'Risk', 'Risk Estimate', 'Risk Factors', 'Sample Size', 'Savings', 'Statistical Models', 'Symptoms', 'Testing', 'Thinking', 'Time', 'Translations', 'Treatment Protocols', 'Vinca Alkaloids', 'analog', 'associated symptom', 'base', 'cancer care', 'cancer epidemiology', 'cancer invasiveness', 'cancer therapy', 'cancer type', 'care systems', 'chemotherapy', 'chemotherapy induced neuropathy', 'clinical decision-making', 'community based practice', 'comorbidity', 'disability', 'experience', 'experimental study', 'fall risk', 'follow-up', 'health care settings', 'high risk', 'improved', 'machine learning method', 'mathematical ability', 'medication safety', 'neurotoxicity', 'older patient', 'predictive modeling', 'side effect', 'survivorship', 'taxane', 'tool', 'treatment choice', 'treatment duration']",NCI,KAISER FOUNDATION RESEARCH INSTITUTE,R01,2020,663447,111231681,-0.030886162790763453
"PREMIERE: A PREdictive Model Index and Exchange REpository The confluence of new machine learning (ML) data-driven approaches; increased computational power; and access to the wealth of electronic health records (EHRs) and other emergent types of data (e.g., omics, imaging, mHealth) are accelerating the development of biomedical predictive models. Such models range from traditional statistical approaches (e.g., regression) through to more advanced deep learning techniques (e.g., convolutional neural networks, CNNs), and span different tasks (e.g., biomarker/pathway discovery, diagnostic, prognostic). Two issues have become evident: 1) as there are no comprehensive standards to support the dissemination of these models, scientific reproducibility is problematic, given challenges in interpretation and implementation; and 2) as new models are put forth, methods to assess differences in performance, as well as insights into external validity (i.e., transportability), are necessary. Tools moving beyond the sharing of data and model “executables” are needed, capturing the (meta)data necessary to fully reproduce a model and its evaluation. The objective of this R01 is the development of an informatics standard supporting the requisite information for scientific reproducibility for statistical and ML-based biomedical predictive models; from this foundation, we then develop new computational approaches to compare models' performance. We begin by extending the current Predictive Model Markup Language (PMML) standard to fully characterize biomedical datasets and harmonize variable definitions; to elucidate the algorithms involved in model creation (e.g., data preprocessing, parameter estimation); and to explain the validation methodology. Importantly, models in this PMML format will become findable, accessible, interoperable, and reusable (i.e., following FAIR principles). We then propose novel meth- ods to compare and contrast predictive models, assessing transportability across datasets. While metrics exist for comparing models (e.g., c-statistics, calibration), often the required case-level information is not available to calculate these measures. We thus introduce an approach to simulate cases based on a model's reported da- taset statistics, enabling such calculations. Different levels of transportability are then assigned to the metrics, determining the extent to which a selected model is applicable to a given population/cohort (i.e., helping answer the question, can I use this published model with my own data?). We tie these efforts together in our proposed framework, the PREdictive Model Index & Exchange REpository (PREMIERE). We will develop an online portal and repository for model sharing around PREMIERE, and our efforts will include fostering a community of users to guide its development through workshops, model-thons, and other activities. To demonstrate these efforts, we will bootstrap PREMIERE with predictive models from a targeted domain (risk assessment in imaging-based lung cancer screening). Our efforts to evaluate these developments will engage a range of stakeholders (model developers, users) to inform the completeness of our standard; and biostatisticians and clinical experts to guide assessment of model transportability. PROGRAM NARRATIVE With growing access to information contained in the electronic health record and other data sources, the appli- cation of statistical and machine learning methods are generating more biomedical predictive models. However, there are significant challenges to reproducing these models for purposes of comparison and application in new environments/populations. This project develops informatics standards to facilitate the sharing and reproducibil- ity of these models, enabling a suite of comparative methods to evaluate model transportability.",PREMIERE: A PREdictive Model Index and Exchange REpository,10016297,R01EB027650,"['Access to Information', 'Address', 'Algorithms', 'Area', 'Attention', 'Bayesian Network', 'Big Data', 'Biological Markers', 'Calibration', 'Characteristics', 'Clinical', 'Communities', 'Computational Biology', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Decision Making', 'Decision Trees', 'Dermatology', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Ecosystem', 'Educational workshop', 'Electronic Health Record', 'Environment', 'Evaluation', 'FAIR principles', 'Fostering', 'Foundations', 'Goals', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Language', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Medical', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Ophthalmology', 'Pathway interactions', 'Performance', 'Population', 'Publications', 'Publishing', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Reporting', 'Reproducibility', 'Reproduction', 'Research Personnel', 'Risk Assessment', 'Source', 'Techniques', 'Testing', 'Training', 'Validation', 'Variant', 'Work', 'base', 'bioimaging', 'biomarker discovery', 'case-based', 'cohort', 'collaborative environment', 'comparative', 'computer aided detection', 'convolutional neural network', 'data sharing', 'deep learning', 'design', 'experience', 'feature selection', 'indexing', 'innovation', 'insight', 'interest', 'interoperability', 'learning network', 'lung basal segment', 'lung cancer screening', 'mHealth', 'machine learning method', 'model development', 'novel', 'novel strategies', 'online repository', 'predictive modeling', 'prognostic', 'repository', 'software repository', 'statistical and machine learning', 'statistics', 'stem', 'tool', 'web portal']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,673491,673201228,-0.004955055395781981
"Contextualized daily prediction of lapse risk in opioid use disorder by digital phenotyping PROJECT SUMMARY Opioid use disorder is increasingly widespread, leading to devastating consequences and costs for patients and their families, friends, and communities. Available treatments for opioid and other substance use disorders (SUD) are not successful at sustaining sobriety. The vast majority of people with SUD relapse within a year. Critically, they often fail to detect dynamic, day-by-day changes in their risk for relapse and do not adequately employ skills they developed or take advantage of support available through continuing care. The broad goals of this project are to develop and deliver a highly contextualized, lapse risk prediction models for forecasting day-by-day probability of opioid and other drug use lapse among people pursuing drug abstinence. This lapse risk prediction model will be delivered within the Addiction-Comprehensive Health Enhancement Support System (A-CHESS) mobile app, which has been established by RCT as a state-of-the-art mHealth system for providing continuing care services for alcohol and substance use disorders. To accomplish these broad goals, a diverse sample of 480 participants with opioid use disorder who are pursing abstinence will be recruited. These participants will be followed for 12 months of their recovery, with observations occurring as early as one week post-abstinence and as late as 18 months post-abstinence across participants in the sample. Well-established distal, static relapse risk signals (e.g., addiction severity, comorbid psychopathology) will be measured on intake. A range of more proximal, time-varying opioid (and other drug use) lapse risk signals will also be collected via participants’ smartphones. These signals include self-report surveys every two months, daily ecological momentary assessments, daily video recovery “check-ins”, voice phone call and text message logs, text message content, moment-by-moment location (via smartphone GPS and location services), physical activity (via smartphone sensors), and usage of the mobile A-CHESS Recovery Support app. The predictive power of these risk signals will be further increased by anchoring them within an inter-personal context of known people, locations, dates, and times that support or detract from participants’ abstinence efforts. Machine learning methods will be used to train, validate, and test opioid (and other drug) lapse risk prediction models based on these contextualized static and dynamic risk signals. These lapse risk prediction models will provide participant specific, day-by-day probabilistic forecast of a lapse to opioid (or other drug) use among opioid abstinent individuals. These lapse risk prediction models will be formally added to the A-CHESS continuing care mobile app at the completion of the project for use in clinical care. These project goals position A-CHESS to make relapse prevention and recovery support, information, and risk monitoring available to patients continuously. Compared to conventional continuing care, A-CHESS will provide personalized care and be available and implemented during moments of greatest need. Integrated real-time risk prediction holds substantial promise to encourage sustained recovery through adaptive use of these continuing care services. PROJECT NARRATIVE The project’s goals are to develop and deliver a real-time model for forecasting day-by-day opioid use lapse among abstinent patients with opioid use disorder. This lapse prediction model will be integrated into an existing, validated mHealth app to encourage sustained recovery through adaptive use of continuing care services.",Contextualized daily prediction of lapse risk in opioid use disorder by digital phenotyping,9980350,R01DA047315,"['Abstinence', 'Acoustics', 'Advertising', 'Affect', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Behavior', 'Caring', 'Cellular Phone', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Data Sources', 'Diagnosis', 'Distal', 'Drug usage', 'Ecological momentary assessment', 'Enrollment', 'Equilibrium', 'Face', 'Facebook', 'Family', 'Foundations', 'Frequencies', 'Friends', 'Gender', 'Goals', 'Health', 'Home environment', 'Individual', 'Intake', 'Location', 'Measures', 'Medical', 'Mental disorders', 'Methods', 'Mobile Health Application', 'Modeling', 'Monitor', 'Narcotics', 'Natural Language Processing', 'Opioid', 'Paper', 'Participant', 'Patient Recruitments', 'Patient Self-Report', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physical activity', 'Positioning Attribute', 'Predictive Analytics', 'Probability', 'Psychopathology', 'Publishing', 'Race', 'Recovery', 'Relapse', 'Risk', 'Risk Factors', 'Sampling', 'Services', 'Severities', 'Signal Transduction', 'Social Environment', 'Social Network', 'Substance Use Disorder', 'Support System', 'Surveys', 'System', 'Telephone', 'Testing', 'Text Messaging', 'Theoretical model', 'Time', 'Training', 'Visual', 'Voice', 'addiction', 'alcohol testing', 'base', 'care providers', 'care systems', 'chronic pain', 'clinical care', 'comorbidity', 'cost', 'craving', 'digital', 'disorder later incidence prevention', 'drug abstinence', 'experience', 'information gathering', 'innovation', 'mHealth', 'machine learning method', 'meetings', 'microphone', 'mobile application', 'opioid use', 'opioid use disorder', 'overdose death', 'peer', 'personalized care', 'predictive modeling', 'prevent', 'real time model', 'recruit', 'relapse risk', 'risk prediction model', 'rural setting', 'sensor', 'signal processing', 'skills', 'sleep quality', 'sobriety', 'social media', 'stressor', 'suburb']",NIDA,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,681159,338121506,-0.0079482884275895
"Machine learning for the automated identification and tracking of rare myocardial diseases PROJECT SUMMARY Although cardiac amyloidosis and hypertrophic cardiomyopathy (HCM) are relatively rare causes of heart failure (HF), they are particularly challenging to detect and treat for several shared reasons: (1) on routine clinical imaging (i.e., echocardiography [echo]), they can be difficult to distinguish from superficially similar, more common forms of cardiac disease that cause left ventricular (LV) hypertrophy; (2) the diagnoses are often missed and thus patients can present late in the course of disease at a time when treatment is difficult; (3) objective, noninvasive metrics that reliably reflect disease progression have not been identified; and (4) the small number of known patients with these diseases can make epidemiology studies and clinical trials difficult to organize and conduct. For both cardiac amyloidosis and HCM, echo plays a critical role in both diagnosis and longitudinal monitoring given its ubiquitous clinical availability, safety, and low cost. More broadly, echo dominates the current landscape of routine cardiac imaging, with tens of millions of echos performed in the United States each year. However, the clinical challenges described above highlight several shortcomings of echo: it is limited in its ability to (1) diagnose disease at its early stages; (2) discriminate between morphologically similar diseases; and (3) quantify disease progression. This proposal seeks to address deficiencies in the current echo reading workflow, which is subjective and captures only a small fraction of the data available in each study. The overall objective of this application is to use advances in machine learning to develop and validate fully-automated echo image analytic approaches to diagnose and track rare cardiomyopathies, focusing on cardiac amyloidosis and HCM. Our proposal is centered on the hypothesis that highly scalable computer vision methods can be applied to echo studies to overcome limitations of the standard clinical echo reading workflow. Accordingly our aims are: (1) Apply an automated method for echo quantification and disease identification to detect and differentiate cardiac diseases that cause increased LV wall thickness; and (2) Characterize quantifiable echo measures of disease progression in cardiac amyloidosis and HCM and associate these with clinical outcomes. Our multidisciplinary team, which is composed of experts in cardiomyopathies, echocardiography, computer vision, and machine learning, will analyze echos and patient data from 2 large patient registries: the Multicenter Amyloid Phenotyping Study (MAPS) and the Sarcomeric Human Cardiomyopathy Registry (SHaRe) HCM Network, with validation using a repository of nearly 400,000 echos. The successful completion of our aims will result in an innovative tool for early diagnosis of myocardial diseases and tracking of disease progression. Importantly, our project will set the stage for conducting larger epidemiology studies of rare myocardial diseases by automating the identification of these patients, and thereby developing previously unattainable broad-based cohorts for these conditions. PROJECT NARRATIVE Rare heart diseases such as amyloidosis (due to abnormal deposition of a protein into the heart muscle) and hypertrophic cardiomyopathy (due to a genetic mutation) are important causes of heart failure and sudden death in the general population. These heart diseases are difficult to diagnose, monitor, and treat because: (1) they appear superficially similar to more common forms of heart disease (e.g., high blood pressure) on imaging tests; (2) the optimal monitoring of disease progression over time has not been established; and (3) there is a lack of large-scale studies of patients with these diseases given their rarity. This project aims to use machine learning (artificial intelligence) of digital echocardiographic images to create a completely automated method for diagnosing and tracking these rare heart diseases with the ultimate goal of broad deployment of artificial intelligence algorithms in hospitals and clinics to help identify patients with these rare heart diseases earlier, better predict adverse outcomes, and increase the size and scope of patient registries to enhance research of these conditions.",Machine learning for the automated identification and tracking of rare myocardial diseases,9739345,R01HL140731,"['Address', 'Affect', 'Algorithm Design', 'Amyloid', 'Amyloidosis', 'Arrhythmia', 'Artificial Intelligence', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular system', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Clinics and Hospitals', 'Cohort Studies', 'Communities', 'Computer Vision Systems', 'Coronary heart disease', 'DNA Sequence Alteration', 'Data', 'Deposition', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Echocardiography', 'Face', 'General Population', 'Goals', 'Heart Diseases', 'Heart failure', 'Hospitalization', 'Human', 'Hypertension', 'Hypertrophic Cardiomyopathy', 'Image', 'Image Analysis', 'Individual', 'Information Retrieval', 'Inherited', 'Left', 'Left Ventricular Hypertrophy', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Monitor', 'Morphology', 'Myocardium', 'Outcome', 'Output', 'Patients', 'Phenotype', 'Play', 'Process', 'Proteins', 'Reader', 'Reading', 'Registries', 'Research', 'Research Personnel', 'Role', 'Safety', 'Standardization', 'Structure', 'Sudden Death', 'Symptoms', 'Testing', 'Thick', 'Time', 'Two-Dimensional Echocardiography', 'United States', 'Validation', 'Ventricular', 'adverse outcome', 'automated image analysis', 'base', 'career', 'clinical care', 'clinical imaging', 'cohort', 'comorbidity', 'cost', 'digital', 'disease diagnosis', 'epidemiology study', 'heart imaging', 'hypertensive heart disease', 'image processing', 'innovation', 'intelligent algorithm', 'interest', 'multidisciplinary', 'novel therapeutics', 'particle', 'patient registry', 'repository', 'response', 'statistical learning', 'tool']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2020,687210,327644200,-0.009600534532977562
"Safety Promotion through Early Event Detection in the Elderly (SPEEDe) ABSTRACT Adverse events (AEs) – harm to patients that results from medical care – affect as many as 13.5% of hospitalized patients; half of these AEs are preventable and AEs particularly affect the elderly. AEs are notoriously difficult to measure accurately. A variety of paper and electronic trigger tools have been developed to identify AEs; however, their positive predictive value (PPV) is low, requiting subsequent, time-intensive manual chart review to accurately measure AEs. In the proposed project, we will use innovative, state-of-the-art machine interactive learning (IML) techniques to refine existing AE triggers, improving their accuracy substantially. We will also develop a novel AE Explorer to speed review of possible AEs, as well as an innovative package of predictive analytics tools and methods to measure and detect them. Our approach combines and compares expert-driven improvement with the most recent IML techniques to make triggers more accurate, with the ultimate goal of creating triggers that are accurate enough to stand in as proxies for actual measurement of harm. We call our approach Safety Promotion through Early Event Detection in the Elderly, or SPEEDe. Our team of accomplished machine learning, patient safety, risk management, AE detection, geriatric medicine and trigger tool experts will work together to carry out the specific aims of this project: (1) prototype and rapidly iterate a trigger review dashboard (the Adverse Event Explorer) using a user-centered design process, (2) develop and evaluate novel Interactive Machine Learning approaches for more efficient and accurate adverse event chart review and trigger refinement, and (3) Integrate Interactive Machine Learning into the Adverse Event Explorer and evaluate it prospectively in a clinical setting. PROJECT NARRATIVE Adverse events – harm to patients that results from medical care – are common and difficult to identify and measure using existing tools. Accurate real-time measures of adverse events would enable organizations to track harm over time, identify and prioritize areas for safety improvements, evaluate whether patient safety programs are effective, and communicate risks of harm to patients and caregivers. Through SPEEDe, we will develop an innovative machine- learning approach for accurately detecting adverse events in the elderly in real-time.",Safety Promotion through Early Event Detection in the Elderly (SPEEDe),10093288,R01AG062499,"['Active Learning', 'Adopted', 'Adverse event', 'Affect', 'Area', 'Benchmarking', 'Caregivers', 'Caring', 'Cessation of life', 'Clinical', 'Computer software', 'Detection', 'Elderly', 'Environment', 'Event', 'Feedback', 'Foundations', 'Frequencies', 'Geriatrics', 'Goals', 'Gold', 'Grant', 'Hospitals', 'Human', 'Human Resources', 'Incentives', 'Intuition', 'Learning', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Memory', 'Minority', 'Modeling', 'Paper', 'Patients', 'Performance', 'Personal Satisfaction', 'Policies', 'Predictive Analytics', 'Predictive Value', 'Process', 'Proxy', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Management', 'Safety', 'Sampling', 'Screening procedure', 'Speed', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Woman', 'Work', 'advanced analytics', 'analytical method', 'analytical tool', 'base', 'biomedical informatics', 'cost', 'dashboard', 'detector', 'forging', 'hands-on learning', 'health information technology', 'improved', 'innovation', 'iterative design', 'machine learning method', 'novel', 'open source', 'patient safety', 'prevent', 'programs', 'prospective', 'prototype', 'supervised learning', 'tool', 'user centered design']",NIA,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,705459,377931988,-0.013889371710414157
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,9920211,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'data quality', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2020,709525,593605914,-0.008123160752214382
"Integrated prediction of cardiovascular events by automated coronary plaque and pericoronary adipose tissue quantification from CT Angiography PROJECT SUMMARY Coronary artery disease remains the leading cause of death worldwide, and more than half of the individuals suffering myocardial infarction (heart attacks) have no premonitory symptoms. Studies of patients with coronary artery disease have traditionally focused only on the severity of narrowing (stenosis) of the coronary arteries by atherosclerotic plaques, rather than the adverse features of coronary plaques which are predisposed to rupture and precipitate myocardial infarction. Coronary CT Angiography (CTA) is a noninvasive test that allows assessment of both coronary stenosis and plaque characteristics. Currently, however, CTA is interpreted visually for stenosis. Quantitative measurements of CTA stenosis severity and plaque features are not part of current clinical routine.  We propose to develop novel image processing algorithms for fully automated, robust quantification of coronary plaque features from CTA. We also propose to automatically quantify the characteristics of adipose tissue around the coronary arteries (pericoronary adipose tissue, PCAT), which have been shown to differentiate rupture-prone, high-risk coronary plaques from stable ones. We propose to apply machine learning methods to efficiently combine stenosis, plaque and PCAT features, along with patient clinical data, into a new integrated risk score for the prediction of future adverse cardiovascular events. We will evaluate this risk score in the real-world, prospective, landmark SCOT-HEART trial (including all 2073 patients in the CTA arm of the trial), with added external validation in large multicenter patient registries, with available CTA scans, clinical data, and followup for cardiovascular events (fatal and non-fatal myocardial infarction and cardiovascular death in a grand total of 7844 patients). We propose three specific aims: 1) To refine, expand and automate measurements of coronary plaque and lumen for the entire coronary artery tree, and to standardize measurement of plaque changes in serial CTA; 2) To evaluate the prognostic value of automatically-quantified plaque features and PCAT characteristics for the prediction of future MACE in the prospective SCOT-HEART trial and multicenter CTA registries; 3) To develop and evaluate with full external validation a new automated patient risk score—combining patient clinical data, CTA-measured quantitative plaque features and PCAT characteristics, using machine learning—for the prediction of future MACE events in the prospective SCOT-HEART trial and multicenter CTA registries.  The proposed work will enable automated, multi-faceted and reproducible analysis of plaque, stenosis and PCAT from CTA, combined with objective risk scores reflecting likelihood of adverse cardiovascular events. This work will provide a novel, personalized, real-world paradigm that objectively and accurately identifies individual patients at risk of future cardiovascular events, from routine CTA imaging. PROJECT NARRATIVE (lay language) In patients who are at risk of developing a heart attack, imaging of the heart with coronary Computed Tomography Angiography (CTA) allows doctors to noninvasively assess the narrowing of the coronary arteries caused by coronary plaque deposits, as well as the coronary plaques themselves. The researchers propose to develop and validate novel computerized scores derived from real-world CTA and clinical patient data using artificial intelligence, that will automatically identify the patients who are at highest risk of suffering a heart attack or cardiovascular death. This new research will allow physicians to more precisely identify patients for whom appropriate treatment could be prescribed, to reduce their risk of future adverse cardiovascular events.",Integrated prediction of cardiovascular events by automated coronary plaque and pericoronary adipose tissue quantification from CT Angiography,9981397,R01HL148787,"['Adipose tissue', 'Algorithms', 'American', 'Angiography', 'Arterial Fatty Streak', 'Arteries', 'Artificial Intelligence', 'Atherosclerosis', 'Cardiac Death', 'Cardiovascular system', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Clinical assessments', 'Complex', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary artery', 'Data', 'Deposition', 'Event', 'Future', 'Hospitals', 'Hour', 'Image', 'Imaging Techniques', 'Individual', 'Language', 'Longterm Follow-up', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical center', 'Myocardial Infarction', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Risk', 'Rupture', 'Scanning', 'Severities', 'Site', 'Standardization', 'Stenosis', 'Symptoms', 'Testing', 'Time', 'Trees', 'Validation', 'Visual', 'Work', 'acute coronary syndrome', 'arm', 'cardiovascular risk factor', 'clinically significant', 'computerized', 'coronary calcium scoring', 'coronary computed tomography angiography', 'coronary event', 'coronary plaque', 'density', 'experience', 'follow-up', 'heart imaging', 'high risk', 'image processing', 'improved', 'indexing', 'individual patient', 'machine learning method', 'mortality', 'noninvasive diagnosis', 'novel', 'outcome forecast', 'patient registry', 'prognostic significance', 'prognostic value', 'prospective']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2020,714763,90419233,-0.0038033409540662406
"Improving predictive capacity of models for universal influenza vaccine development The need for improved and more universally protective influenza vaccines is well recognized. Central to efforts towards improvements is the development of animal models more predictive of the human response to immunization and/or infection. Indeed, this need has been highlighted by the NIAID Strategic Plan for a Universal Influenza Vaccine. While animal models may never be able to fully predict the human response, understanding their full strengths and weaknesses and identifying the optimal models for different purposes is a significant public health need and is the scientific premise behind our proposed objectives. These objectives, which are built upon our extensive use of influenza animal models, are to optimize animal modeling of immunologic imprinting, to improve vaccine efficacy testing, and to identify immune correlates of protection and boosting immune responses. Our overall goal is to provide superior preclinical models to support universal influenza vaccine development. We will achieve this goal through three complementary and interrelated specific aims, 1) optimal modeling of human serologic responses to repeat influenza antigen exposure in animal models; 2) improving the quantitative nature of the ferret influenza challenge model; and 3) defining serologic correlates of influenza virus induced clinical symptoms. Our ability to conduct these aims is supported through our participation in, and collaboration with, a recently NIAID-funded human infant cohort, the DIVINCI study. We will mirror the influenza antigen exposures of a selection of these infants in three animal models and compare immunologic data sets to identify which most accurately reflects the human response (Aim 1). This marriage of human and animal data sets and samples offers an innovative way forward and will provide a unique set of differentially primed animals with which to determine immune correlates of novel physiologic parameters of infection and immune responses (Aim 2) using original machine learning algorithms (Aim 3). Current models for influenza vaccine development suffer from poor predictability of the human response. Through an innovative combination of approaches that use data from longitudinal human cohorts, we intend to greatly enhance the reliability and value of these models in universal influenza vaccine testing.",Improving predictive capacity of models for universal influenza vaccine development,9950635,R01AI150745,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Antigens', 'Antiviral Agents', 'Area', 'Cavia', 'Clinical', 'Clinical Research', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Ensure', 'Exposure to', 'Family suidae', 'Ferrets', 'Funding', 'Future', 'Goals', 'Hamsters', 'Human', 'Immune', 'Immune response', 'Immunity', 'Immunization', 'Immunological Models', 'Immunologics', 'Individual', 'Infant', 'Infection', 'Influenza', 'Influenza A Virus, H3N2 Subtype', 'Information Systems', 'Lasso', 'Lung', 'Marriage', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Mus', 'National Institute of Allergy and Infectious Disease', 'Natural History', 'Nature', 'Organ', 'Outcome', 'Output', 'Pathogenesis', 'Performance', 'Physiological', 'Population', 'Pre-Clinical Model', 'Predictive Value', 'Primates', 'Property', 'Public Health', 'Reagent', 'Recording of previous events', 'Research', 'Sampling', 'Seasons', 'Serological', 'Strategic Planning', 'Symptoms', 'System', 'Telemetry', 'Time', 'United States', 'Upper respiratory tract', 'Vaccinated', 'Vaccine Production', 'Vaccines', 'Virulence', 'Virus Replication', 'Whole Body Plethysmography', 'animal data', 'animal model development', 'cohort', 'efficacy testing', 'flexibility', 'human data', 'human model', 'imprint', 'improved', 'influenza virus vaccine', 'influenzavirus', 'innovation', 'machine learning algorithm', 'mouse development', 'multitask', 'next generation', 'novel', 'preclinical evaluation', 'product development', 'research and development', 'response', 'safety study', 'tool', 'transmission process', 'universal influenza vaccine', 'universal vaccine', 'vaccine candidate', 'vaccine development', 'vaccine effectiveness', 'vaccine efficacy', 'vaccine evaluation']",NIAID,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,R01,2020,723996,114256597,-0.01298268456929715
"Olfactory and facial markers of developmental risk for psychosis in 22q11 deletion syndrome Project Summary: 22q11.2 deletion syndrome (22q11DS) is associated with an increased risk for psychiatric disorders, including psychosis with similar symptoms to individuals with idiopathic schizophrenia (SZ), and about 1-2% of cases of idiopathic SZ have 22q11.2 deletions. Thus, targeted approaches detailing specific brain dysfunction in 22q11DS may elucidate critical neural mechanisms in psychosis. Specifically, approaches that capture abnormalities common to individuals at-risk for psychosis and with a genetic risk to psychosis, such as 22q11DS, may help explain risk and resilience for psychosis. Minor physical anomalies (MPAs) are phenotypic abnormalities of aberrant development. MPAs include subtle abnormalities of morphological structures encompassing numerous body parts including eyes, ears, mouth and head. Abnormalities of the face and head likely represent a disruption of early embryologic development, including the olfactory system and facial morphology, making these promising entry points for understanding neurodevelopmental neuropathology associated with 22q11DS and psychosis In this study, we seek to compare 1) measures of olfactory function; 2) structural abnormalities of the olfactory system and 3) structural abnormalities of the face in a large cohort of patients with 22q11DS (n=100), including those with and without psychosis, to typically developing (TD) individual. Finally, we will employ machine learning algorithms to select features that best differentiate 22q11DS+ from 22q11DS- and use those features to classify individual with idiopathic risk for psychosis (PS). In addition, analyses will leverage recent advances in machine learning to predict salient features associated with dimensional measures of psychosis. We believe this innovative approach can significantly advance our understanding of the etiology of psychosis and provide advances to precision medicine in psychiatry. Through the proposed multi-level analysis, this innovative research will provide a substantial advance in our understanding of the neurodevelopmental substrates of psychosis. RELEVANCE: Psychosis is a debilitating psychiatric condition. Greater understanding of how abnormalities in neural development lead to dysfunction during youth and produce symptoms of psychosis or psychosis risk may be critical for the conceptualization of earlier and more effective treatments. This would benefit public health by reducing the great costs of psychosis to individuals and society at large.",Olfactory and facial markers of developmental risk for psychosis in 22q11 deletion syndrome,10023944,R01MH119185,"['22q11.2', '3-Dimensional', 'Acoustic Rhinometry', 'Behavioral', 'Biometry', 'Body part', 'Brain region', 'Characteristics', 'Classification', 'Clinical', 'Craniofacial Abnormalities', 'Data', 'Development', 'DiGeorge Syndrome', 'Diffuse', 'Dimensions', 'Distress', 'Dysmorphology', 'Ear', 'Etiology', 'Event', 'Exhibits', 'Eye', 'Face', 'Functional disorder', 'Genetic Diseases', 'Genetic Risk', 'Geometry', 'Head', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mandible', 'Measures', 'Medial', 'Mental disorders', 'Minor', 'Modeling', 'Morphology', 'Nasal cavity', 'Neurobiology', 'Nose', 'Odors', 'Olfactory Cortex', 'Olfactory Pathways', 'Oral cavity', 'Patients', 'Performance', 'Peripheral', 'Phenotype', 'Process', 'Psychiatry', 'Psychophysics', 'Psychotic Disorders', 'Public Health', 'Research', 'Risk', 'Sampling', 'Schizophrenia', 'Severities', 'Smell Perception', 'Societies', 'Structural defect', 'Structure', 'Symptoms', 'Syndrome', 'Techniques', 'Temporal Lobe', 'Testing', 'Three-Dimensional Imaging', 'Work', 'Youth', 'associated symptom', 'base', 'behavior measurement', 'brain dysfunction', 'clinically relevant', 'cohort', 'cost', 'effective therapy', 'functional outcomes', 'genetic disorder diagnosis', 'high risk', 'improved', 'innovation', 'machine learning algorithm', 'microdeletion', 'multilevel analysis', 'neurodevelopment', 'neuromechanism', 'neuropathology', 'olfactory bulb', 'olfactory sulcus', 'precision medicine', 'psychotic symptoms', 'resilience', 'trait']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2020,740401,593605914,-0.013476451689977034
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,9965720,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Streptococcus pyogenes', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2020,741796,46216755,-0.030429162375384178
"Risk Factors for Psychosis and Mania with Prescription Amphetamine Use ABSTRACT: The use of prescription amphetamines for the treatment of attention-deficit hyperactivity disorder (ADHD) has markedly increased in the last fifteen years, with the greatest increase in adolescents and young adults. In 2007, the FDA mandated changes to stimulant labels to warn of increases in psychosis and mania in patients without pre-existing conditions. Our multidisciplinary research team from Brigham and Women's Hospital and McLean Hospital recently published a landmark cohort study demonstrating an increased risk of psychotic episodes in new users of amphetamine compared to methylphenidate in adolescents and young adults with ADHD. Alarmingly, the use of amphetamines increased four-fold over the study period (2004 – 2015). In addition, our data show that prescription amphetamine use has dramatically increased in patients with pre-existing bipolar disorder. Thus, there is an urgent need to accelerate knowledge about prescriber-level factors, patient-level factors and disease states that potentiate the risk of psychosis and mania with prescription amphetamines. Large-scale studies using real-world data are the only option to study the risk of infrequent and serious adverse outcomes. In Aim 1, using incident-user cohort study designs, we will utilize data from two national administrative claims databases to identify prescriber dosing strategies that increase the risk of first-episode psychosis in ~220,000 adolescents and adults with ADHD initiating amphetamines. We hypothesize that there will be a dose-dependent increase in the risk of psychosis. The goal of Aim 2 is to identify patient subgroups at heightened risk of psychosis/mania with prescription amphetamine use. To accomplish this goal, we will perform a case control study using electronic medical records (EMR) from McLean Hospital in ~1,650 patients hospitalized for an initial episode of psychosis or mania compared to ~3,300 controls with a first psychiatric hospitalization for reasons other than psychosis or mania. We will apply natural language processing to unstructured narrative notes to capture detailed patient data not available in claims data. We hypothesize that patients with a family history of psychiatric illness will have an increased risk of psychosis/mania with amphetamines compared to patients without a family history. We also hypothesize that patients with concurrent cannabis use will have an increased risk of psychosis/mania with amphetamines compared to patients without cannabis use. Aim 3 compares the risk of treatment-emergent mania in ~52,000 new users of amphetamine versus methylphenidate in a cohort study of patients with pre-existing bipolar disorder, an urgent issue given the known risk of mania with stimulant use. Combined, these studies will provide actionable evidence to be incorporated into clinical practice guidelines with the goal of mitigating the risk of psychosis and mania with prescription stimulants. The proposed research agenda aligns with NIMH Strategic Objective 3.3 “Striving for Prevention and Cure” on testing interventions in real-world practice settings to evaluate the impact of patient- and provider-level factors on clinical outcomes. PROJECT NARRATIVE: In recent years, 6.1 million U.S. children and adolescents were diagnosed with attention deficit hyperactivity disorder (ADHD) and 16 million adults reported past-year use of prescription stimulants. The research team recently found an increased risk of psychosis in new users of prescription amphetamines compared to new users of prescription methylphenidate in adolescents and young adults with ADHD, translating to potentially increased risk of psychosis for thousands of U.S. patients. Therefore, identifying patient subgroups and prescribing practices that increase the risk of psychosis and mania with prescription amphetamines has enormous public health significance and will guide providers to avoid amphetamines in patients at highest risk, preventing future cases of psychosis and mania.",Risk Factors for Psychosis and Mania with Prescription Amphetamine Use,9939094,R01MH122427,"['Address', 'Adolescent', 'Adolescent and Young Adult', 'Adult', 'Affective', 'Age', 'Amphetamine Users', 'Amphetamines', 'Antipsychotic Agents', 'Area', 'Attention deficit hyperactivity disorder', 'Big Data', 'Bipolar Disorder', 'Boston', 'Case-Control Studies', 'Child', 'Clinical', 'Clinical Practice Guideline', 'Clinical Practice Patterns', 'Cohort Studies', 'Complement', 'Computerized Medical Record', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Diagnosis', 'Disease', 'Dose', 'Ethnic Origin', 'Family', 'Family history of', 'First Degree Relative', 'Future', 'Goals', 'Gold', 'Healthcare', 'Hospitalization', 'Hospitals', 'Immigration', 'Interdisciplinary Study', 'Intervention', 'Journals', 'Knowledge', 'Label', 'Lead', 'Manic', 'Measurement', 'Medicine', 'Mental disorders', 'Modification', 'Mood stabilizers', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacy facility', 'Positioning Attribute', 'Practice Guidelines', 'Prevention', 'Principal Investigator', 'Provider', 'Psychiatric Hospitals', 'Psychotic Disorders', 'Public Health', 'Publishing', 'Race', 'Recording of previous events', 'Relative Risks', 'Reporting', 'Research', 'Research Design', 'Risk', 'Risk Factors', 'Ritalin', 'Sampling', 'Socioeconomic Status', 'Symptoms', 'Testing', 'Translating', 'Woman', 'adverse outcome', 'amphetamine use', 'base', 'comorbidity', 'comparative', 'cost effective', 'data warehouse', 'first episode psychosis', 'high risk', 'innovation', 'marijuana use', 'patient subsets', 'practice setting', 'prevent', 'stimulant use', 'treatment risk', 'university student']",NIMH,MCLEAN HOSPITAL,R01,2020,746678,44711126,-0.007871167156834275
"An interactive, digital platform to transform biological learning Abstract: The next generation of health care professionals will need to understand the foundational principles of biology. Science textbooks play a critical role in supporting biological understanding in school, yet these books are not designed to meet the diverse learning needs of students in today’s classrooms. By their nature, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current Life Science textbooks and to revolutionize reading with adaptable texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned inheritance (NGSS LS3A) content into Spanish (Aim 1); designing, developing, and testing the application to function through a web browser (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content to address 12 additional NGSS standards in English and Spanish (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive reading technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning needs. This Fast-Track project will produce an interactive, digital textbook to support students’ understanding of Life Science by giving them the ability to seamlessly move between different reading levels and languages and to play games that enhance their understanding of scientific language and concepts. This project will also solicit feedback from teachers and students to develop teacher support materials and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform biological learning",9970958,R44GM133245,"['Address', 'Adoption', 'Biological', 'Biological Sciences', 'Biology', 'Books', 'Brain', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Gametogenesis', 'Health Professional', 'Healthcare', 'Home environment', 'Individual', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Nature', 'Phase', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Spinal Cord', 'Students', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'Vocabulary', 'base', 'concept mapping', 'design', 'digital', 'education resources', 'egg', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'reading ability', 'resource guides', 'response', 'science teacher', 'scientific literacy', 'skills', 'sperm cell', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2020,750000,981500,-0.006531479321024144
"Mobilize Center: Models for Mobile Sensing and Precision Rehabilitation Limited mobility due to conditions like osteoarthritis (OA), cerebral palsy, and Parkinson’s disease affects millions of individuals, at enormous personal and societal cost. Rehabilitation can dramatically improve mobility and function, but current rehabilitation practice requires in-person guidance by a skilled clinician, increasing expense and limiting access. Mobile sensing technologies are now ubiquitous and have the potential to measure patient function and guide treatment outside the clinic, but they currently fail to capture the characteristics of motion required to accurately monitor function and customize treatment. Millions of low-cost mobile sensors are generating terabytes of data that could be analyzed in combination with other data, such as images, clinical records, and video, to enable studies of unprecedented scale, but machine learning models for analyzing these large-scale, heterogeneous, time-varying data are lacking.  To address these challenges, we will establish a Biomedical Technology Resource Center —The Mobilize Center. Through the leadership of an experienced scientific team, we will create and disseminate innovative tools to quantify movement biomechanics with mobile sensors.  Specifically, we will:  1. Push the bounds of what we can measure via wearable sensors using models that compute muscle  and joint forces and metabolic cost of locomotion. These models, based on biomechanical and machine  learning models, will be disseminated via our newly created OpenSense software, which will be used  by thousands of researchers to gain new insights into patient biomechanics using mobile sensors.  2. Meet the need for tools that analyze data about movement dynamics and develop machine learning  models to analyze and generate insights from unstructured, high-dimensional data, including time-  series (e.g., from mobile sensors), images (e.g., MRI), and video (e.g., smartphone video of a patient’s gait).  3. Provide tools needed to intervene in the real-world. We will develop algorithms to accurately quantify  kinematics outside the lab for long durations using data from inertial measurement units (IMUs). We will  also build behavioral models to adapt and personalize goal setting, drawing on movement records from  6 million individuals, as well as health goals and exercise for 1.7 million people.  Through intensive interactions with our Collaborative Projects, we will focus on improving rehabilitation outcomes for individuals with limited mobility due to osteoarthritis, obesity, Parkinson’s disease, and cerebral palsy. The Center’s tools and services will enable researchers to revolutionize how we diagnose, monitor, and treat mobility disorders, providing tools needed to deliver precision rehabilitation at low cost and on a massive scale in the future. Limited mobility due to conditions like osteoarthritis, cerebral palsy, and Parkinson’s affects millions of individuals, at a great cost to public health and personal well-being. Rehabilitation can dramatically improve mobility and function, but current rehabilitation practice requires in- person guidance by a skilled clinician, increasing expense and limiting access. This project will revolutionize how we diagnose, monitor, and treat mobility limitations and enable personalized rehabilitation at low cost and on a massive scale using wearable sensing technology in the future.",Mobilize Center: Models for Mobile Sensing and Precision Rehabilitation,9855893,P41EB027060,"['Address', 'Affect', 'Algorithms', 'Behavioral Model', 'Biomechanics', 'Biomedical Engineering', 'Biomedical Technology', 'Cellular Phone', 'Cerebral Palsy', 'Characteristics', 'Clinic', 'Clinical', 'Communities', 'Computer software', 'Custom', 'Data', 'Data Science', 'Degenerative polyarthritis', 'Diagnosis', 'Disease', 'Documentation', 'Educational workshop', 'Engineering', 'Exercise', 'Exposure to', 'Feedback', 'Foundations', 'Freezing', 'Future', 'Gait', 'Goals', 'Guidelines', 'Home environment', 'Human', 'Image', 'Individual', 'Joints', 'Leadership', 'Literature', 'Locomotion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Metabolic', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Muscle', 'Obesity', 'Parkinson Disease', 'Pathologic', 'Patients', 'Personal Satisfaction', 'Persons', 'Public Health', 'Records', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Resources', 'Series', 'Services', 'Software Tools', 'Time', 'Training', 'Vision', 'base', 'biomechanical model', 'biomedical informatics', 'cohesion', 'coral', 'cost', 'evidence base', 'experience', 'handheld mobile device', 'health goals', 'improved', 'improved functioning', 'improved mobility', 'individualized medicine', 'industry partner', 'innovation', 'insight', 'joint loading', 'kinematics', 'large scale data', 'mHealth', 'mobile computing', 'multidimensional data', 'open source', 'programs', 'sensor', 'sensor technology', 'smart watch', 'societal costs', 'symposium', 'terabyte', 'tool', 'tool development', 'wearable sensor technology']",NIBIB,STANFORD UNIVERSITY,P41,2020,752316,560644462,0.00307471611873572
"Clinical and genetic analysis of retinopathy of prematurity Project Summary The long-term goal of this project is to establish a quantitative framework for retinopathy of prematurity (ROP) care based on clinical, imaging, genetic, and informatics principles. In the previous grant period, we have developed artificial intelligence methods for ROP diagnosis, but real-world adoption has been limited by lack of prospective validation and by perception of these systems as “black boxes” that do not explain their rationale for diagnosis. Furthermore, although biomedical research data are being generated at an enormous pace, much less work has been done to integrate disparate scientific findings across the spectrum from genomics to imaging to clinical medicine. This renewal will address current gaps in knowledge in these areas. Our overall hypotheses are that developing a quantitative framework for ROP care using artificial intelligence and analytics will improve clinical disease management, that building “explainable” artificial intelligence systems will enhance clinical acceptance and educational opportunities, and that analysis of relationships among clinical, imaging, environmental, and genetic findings, in ROP will improve understanding of disease pathogenesis and risk. These hypotheses will be tested using three Specific Aims: (1) Evaluation performance of an artificial intelligence system for ROP diagnosis and screening prospectively. This will include: (a) recruit a target of over 2000 eye exams including wide-angle retinal images from 375 subjects at 5 centers, (b) optimize an image quality detection algorithm we have recently developed, and (c) analyze system accuracy for ROP diagnosis and screening (using a novel quantitative vascular severity scale). (2) Improve the interpretability of our existing artificial intelligence methods for ROP diagnosis. This will include: (a) increase “explainability” of systems by combining deep learning with traditional feature extraction methods, (b) develop neural networks to identify changes between serial images, and (c) evaluate these methods through systematic feedback by experts. (3) Develop integrated models for ROP pathogenesis and risk. This will include: (a) build and improve ROP risk prediction models based on clinical, image, and demographic features, and (b) integrate genetic, imaging, clinical, and environmental variables through genetic risk prediction by machine learning, by investigating casual relationships with genetic variants and genetic risk scores, and by incorporating SNP associations with gene expression measurements to identify functional genes of ROP. Ultimately, these studies will significantly reduce barriers to adoption of technologies such as artificial intelligence for clinicians, and will demonstrate a prototype for health information management which combines genotypic and phenotypic data. This project will be performed by a multi-disciplinary team of investigators who have worked successfully together for nearly 10 years, and who have expertise in ophthalmology, biomedical informatics, computer science, computational biology, ophthalmic genetics, genetic analysis, and statistical genetics. Project Narrative ROP is a leading cause of childhood blindness in the US and throughout the world, and the number of infants at risk for disease is increasing as the rate of premature birth rises. Rapidly-progressive changes associated with retinal vascular development may be visualized by clinical examination, captured by wide-angle imaging, and analyzed genetically. This project will develop, enhance, and validate artificial intelligence and analytic tools to help clinicians identify infants at risk for severe ROP using image analysis, genetic analysis, and integrative informatics that combines these factors – while also providing insight about disease pathogenesis.",Clinical and genetic analysis of retinopathy of prematurity,9974137,R01EY019474,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Bioinformatics', 'Biomedical Research', 'Blindness', 'Blood Vessels', 'Caring', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Research', 'Cohort Studies', 'Computational Biology', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Environment', 'Evaluation', 'Expert Systems', 'Feedback', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Infant', 'Informatics', 'Information Management', 'International', 'Knowledge', 'Longitudinal Studies', 'Machine Learning', 'Macular degeneration', 'Measurement', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular Genetics', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Other Genetics', 'Oxygen', 'Paper', 'Pathogenesis', 'Peer Review', 'Perception', 'Performance', 'Phenotype', 'Predisposition', 'Premature Birth', 'Premature Infant', 'Publishing', 'Randomized', 'Reference Standards', 'Research', 'Research Personnel', 'Retina', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Severities', 'System', 'Technology', 'Testing', 'United States', 'Validation', 'Work', 'analytical tool', 'base', 'biomedical informatics', 'care delivery', 'clinical Diagnosis', 'clinical examination', 'clinical phenotype', 'clinical risk', 'clinically significant', 'computer science', 'data access', 'data integration', 'deep learning', 'diagnosis standard', 'disorder risk', 'feature extraction', 'genetic analysis', 'genetic variant', 'high risk', 'imaging genetics', 'improved', 'insight', 'multidisciplinary', 'multiple data types', 'neovascular', 'neural network', 'novel', 'phenotypic data', 'prospective', 'prototype', 'real world application', 'recruit', 'retinal imaging', 'risk prediction model', 'screening', 'serial imaging']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,764279,304670088,-0.013550816828049476
"Leveraging Artificial Intelligence Solutions to Develop Digital Biomarkers for Precision Trauma Resuscitation PROJECT SUMMARY / ABSTRACT  In the U.S., trauma is the leading cause of death for those 1-45 years old and hemorrhage remains the largest contributing factor to preventable death. Providers must rapidly identify those suffering from hemorrhage to optimize outcome, but internal bleeding remains difficult to diagnose even for experienced clinicians. Little is known on presentation about those suffering from occult hemorrhage and providers must quickly make treatment decisions in these time-pressured, time-sensitive clinical scenarios. This proposal seeks to develop through artificial intelligence, a type of advanced machine learning, prediction algorithms that could be deployed at the bedside of patients to assist clinicians with more timely recognition of hemorrhage. By doing so, we hypothesize that this approach (integrating diverse data sources that have not previously been combined to one another) could identify patterns in our patients that far surpass current capabilities to quickly detect and act on the critical components contributing to outcome. The ability to rapidly pinpoint these patterns and display them to the bedside clinician could allow more timely intervention and precise therapeutic approaches for hemorrhage control.  Beyond the challenges in rapidly identifying bleeding, current treatment of hemorrhage is rudimentary with a standard resuscitation approach for all patients. This reflects attempts to optimize outcome based upon the average treatment effect, rather than being adaptable for unique patient phenotypes. Hemorrhage is believed to initiate a complex chain of events involving crosstalk between the coagulation and inflammatory systems that are hypothesized to play a key role in outcome. Trauma has a known time zero of onset, making it an ideal model to study the immediate pathophysiologic changes associated with hemorrhage. This complex, individual patient biology is believed to explain why those suffering similar injury have differing outcomes. However, to date, these individual characteristics are poorly understood and not factored into initial treatment approaches. Through this proposal, I also seek to define novel digital biomarkers representing patient phenotypes that require precision resuscitation approaches to maximize outcome. Fundamental to reducing hemorrhagic deaths is the need to elucidate a deeper understanding of these mechanistic models of patient states. Strategies that help to identify novel patient phenotypes that could benefit from more tailored treatment pathways may provide important advances in decreasing preventable death.  The net result of this proposal will be a deeper insight into the mechanistic models contributing to evolving patient states following hemorrhage, and identify the key phenotypes or digital biomarkers associated with mortality, complications, and occult hemorrhage. Finding solutions to advance our resuscitation approaches following hemorrhage has potential to decrease complications, save lives, and reduce health care costs. PROJECT NARRATIVE In the US, traumatic injury is the number one cause of death for those under 45 years old and these deaths include many patients dying from the consequences of bleeding. Through leveraging the power of artificial intelligence (a scientific analysis approach similarly used in non-medical fields to help answer questions from large amounts of complex information), an integrated approach to measuring outcome will be developed utilizing biologic, clinical, and electronic medical record (EMR) data. The goal of this project is to lay the ground work for developing early warning detection systems that could identify those at risk of complications early and assist care providers in selecting the best treatment to minimize complications and death from hemorrhage.",Leveraging Artificial Intelligence Solutions to Develop Digital Biomarkers for Precision Trauma Resuscitation,10133378,R01HL149670,"['Abdomen', 'Abdominal Cavity', 'Address', 'Area', 'Artificial Intelligence', 'Bedside Technology', 'Biological', 'Biological Markers', 'Biology', 'Blood', 'Caring', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical', 'Coagulation Process', 'Complex', 'Computational Science', 'Computational algorithm', 'Computerized Medical Record', 'Computers', 'Coupled', 'Coupling', 'Data', 'Data Sources', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early Intervention', 'Event', 'Foundations', 'Goals', 'Health Care Costs', 'Hemorrhage', 'Image', 'Individual', 'Inflammatory', 'Injury', 'Intervention', 'Knowledge', 'Lead', 'Life', 'Liquid substance', 'Machine Learning', 'Mentored Research Scientist Development Award', 'Modeling', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Physiologic Monitoring', 'Physiology', 'Play', 'Provider', 'Resuscitation', 'Risk', 'Stream', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Time', 'Trauma', 'Trauma patient', 'Traumatic injury', 'Triage', 'Ultrasonography', 'United States National Institutes of Health', 'Work', 'advanced analytics', 'base', 'care providers', 'clinical decision-making', 'clinical predictors', 'clinically significant', 'deep learning', 'digital', 'diverse data', 'experience', 'improved', 'individual patient', 'individualized medicine', 'insight', 'mortality', 'multimodal data', 'novel', 'point of care', 'prediction algorithm', 'predictive modeling', 'pressure', 'preventable death', 'profiles in patients', 'relating to nervous system', 'sensor', 'treatment effect']",NHLBI,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2020,772462,254622553,-0.011465206095323557
"Machine Learning in Atrial Fibrillation Project Summary  Atrial fibrillation (AF) is the most common heart rhythm disorder, affecting 2 million Americans in whom it may cause skipped heart beats, dizziness or stroke. Unfortunately, therapy for AF has limited success, likely because AF represents heterogenous and poorly characterized disease entities between individuals. A central challenge is that it is not clear why a specific therapy works in a given AF patient. This uncertainty makes it challenging to develop a patient-specific approach to tailor therapy for personalized medicine.  The premise of this project is that mechanistic data is increasingly available in AF patients at scales spanning tissue, whole heart and patient levels, yet rarely integrated. We set out to use machine learning (ML), a powerful approach proven to classify complex datasets, to integrate data to address 3 clinical unmet needs. First, electrograms are rarely used to guide therapy in AF, unlike organized rhythms, because they are difficult to interpret. Second, it is difficult to understand how arrhythmia is affected by any specific ablation strategy in AF, unlike organized rhythms. This makes it difficult to improve therapy. Third, it is difficult to identify whether an individual patient will or will not have success from AF ablation. We applied machine learning and novel objective analyses to these questions to develop strategies for personalized AF therapy.  We have 3 specific aims: (1) To identify components of AF electrograms using ML trained to monophasic action potentials (MAP); (2) To identify electrical and structural features of the acute response of AF to ablation near and remote from PVs; (3) To identify patients in whom ablation is unsuccessful or successful long-term, who are poorly separated at present. Each Aim will compare ML to traditional biostatistics, and use objective explainability analysis of ML to provide mechanistic insights.  This study has potential to deliver immediate clinical and translational impact. We will apply specific ML approaches, biostatistics, and computer modeling to our rich multiscale registry. We will develop practical and shareable tools, which we will prospectively test clinically, to deliver meaningful outcomes at tissue, whole heart and patient scales. Our team is experienced in electrophysiology, computer science, signal processing and biological physics. This project is likely to reveal novel multiscale AF phenotypes to enable personalized therapy. Machine Learning in Atrial Fibrillation Narrative Atrial fibrillation (AF) is an enormous public health problem that affects 2-5 million Americans, causing stroke, rapid heart beats, heart failure and even death. In this project, the applicant will apply numerical analysis and machine learning to detailed data acquired from patients undergoing therapy, to better define individual biological types of AF, which may provide a foundation for personalized patient-tailored diagnosis and therapy.",Machine Learning in Atrial Fibrillation,9995302,R01HL149134,"['Ablation', 'Action Potentials', 'Acute', 'Address', 'Affect', 'Algorithms', 'American', 'Anatomy', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological', 'Biometry', 'Biostatistical Methods', 'Cessation of life', 'Clinical', 'Clinical Data', 'Complex', 'Computer Models', 'Data', 'Data Element', 'Data Set', 'Diagnosis', 'Disease', 'Dizziness', 'Drug Controls', 'Electrophysiology (science)', 'Foundations', 'Funding', 'Genetic', 'Heart', 'Heart Atrium', 'Heart failure', 'Hospitalization', 'Human', 'Image Analysis', 'Individual', 'Label', 'Lesion', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Methods', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Phenotype', 'Physics', 'Physiological', 'Play', 'Public Health', 'Recovery', 'Registries', 'Science', 'Signal Transduction', 'Site', 'Stroke', 'Structure', 'Test Result', 'Testing', 'Tissues', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Work', 'base', 'computer science', 'convolutional neural network', 'demographics', 'digital', 'experience', 'heart rhythm', 'improved', 'individual patient', 'individualized medicine', 'insight', 'learning classifier', 'machine learning method', 'mortality', 'novel', 'personalized medicine', 'personalized strategies', 'prospective', 'prospective test', 'response', 'signal processing', 'success', 'tool', 'translational impact', 'voice recognition', 'voltage']",NHLBI,STANFORD UNIVERSITY,R01,2020,785591,560644462,-0.04663666527406007
"Evolution of Psychosis in Youth: Multimodal Risk and Resilience Markers PROJECT SUMMARY Efforts at early identification of individuals at risk for psychosis are propelled by the realization that psychosis is neurodevelopmental, with brain and behavioral abnormalities anteceding diagnosis of schizophrenia (SZ) by years. As longer duration of untreated psychosis portends poor outcome, early identification is important to bend the developmental trajectory in a favorable direction. Since most current studies of psychosis risk are based on help-seeking samples, there is a gap in knowledge on how psychosis unfolds in diverse community samples. While it is generally recognized that genomic and environmental factors (GxE) contribute to risk for psychosis, there is a paucity of complementary integrative studies that can chart causal pathways. Genomic “case-control” GWAS studies of SZ identified multiple common alleles permitting calculation of a polygenic risk score (PRS). Recently, increased attention has been given to childhood adversity related to SZ. The goal of the proposed R01 is to build on our genotyped ~10,000 Philadelphia Neurodevelopmental Cohort (PNC) of 8 to 21 years old youths studied in 2009-2011, where we are following those who meet criteria or are at risk for psychosis (PS) and typically developing (TD) participants, whose current age range is 15-30 years. Available multi-level “deep phenotyping” includes clinical, neurocognition and multi-modal neuroimaging on a subsample of ~1600. We have developed a preliminary environmental risk score (ERS) and will use it to dissect GxE. The proposed followup design will recruit PS and TD participants with the highest and lowest scorers (quartile) on the ERS, and within each of these four cells we will examine 120 individuals, 60 males and 60 females (total N=480). This sample will be examined clinically, neurocognitively and with multimodal neuroimaging. We will test the hypothesis that genomic vulnerabilities, based on PRS and family history, and environmental adversity, based on ERS, updated longitudinally, affect onset and course of PS by altering brain development in temporolimbic regions affecting fronto-limbic connectivity that underlies social functioning. We will augment current data with information on risk and resilience and multimodal brain-behavior parameters to establish developmental trajectories during this critical period of brain maturation when psychosis emerges. Our aims are: 1. Examine effects of ERS on PS clinical features and progression in relation to PRS. 2. Investigate brain- behavior parameters that bridge from genetic and environmental factors to clinical manifestations. 3. Establish developmental trajectories for PS features, associated brain parameters and neurocognitive deficits, and apply novel computational models to enable an adaptive “risk and resilience calculator”. The proposed study will produce the data absent for a diverse US community sample but needed to move psychiatry into the precision medicine era. The project will inform on genomic and environmental risk and resilience indicators, offering an essential rung in the ladder toward individualized prediction, a part of implementation science. As with the PNC, data and associated algorithms will be a resource shared with the scientific community. PROJECT NARRATIVE The proposed R01 aims to bridge genomic, environment and phenotypic brain-behavior measures to advance the understanding of risk and resilience to psychosis. We will build on informative samples of the Philadelphia Neurodevelopmental Cohort and integrate multidimensional behavioral measures of psychosis and cognition, multimodal neuroimaging parameters of brain structure, function and connectivity, environmental parameters, and genomic variations in risk for schizophrenia. Computational modeling will aim at developing risk and resilience predictors, essential for early identification and intervention during a dynamic period of brain maturation.",Evolution of Psychosis in Youth: Multimodal Risk and Resilience Markers,9978131,R01MH119219,"['21 year old', 'Address', 'Affect', 'African American', 'Age', 'Algorithms', 'Alleles', 'Attention', 'Behavioral', 'Benign', 'Brain', 'Cells', 'Childhood', 'Clinical', 'Clinical assessments', 'Cognition', 'Cognitive', 'Communities', 'Computer Models', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early Intervention', 'Early identification', 'Environment', 'Environmental Risk Factor', 'Epigenetic Process', 'Evaluation', 'Evolution', 'Family', 'Family history of', 'Female', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Heterogeneity', 'Image', 'Individual', 'Knowledge', 'Language', 'Lead', 'Linear Regressions', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Neurocognition', 'Neurocognitive', 'Neurocognitive Deficit', 'Neurosciences', 'Outcome', 'Participant', 'Pathway interactions', 'Performance', 'Phenotype', 'Philadelphia', 'Positioning Attribute', 'Process', 'Psychiatry', 'Psychotic Disorders', 'Public Domains', 'Race', 'Recording of previous events', 'Resource Sharing', 'Resources', 'Risk', 'Sampling', 'Schizophrenia', 'Severities', 'Sex Differences', 'Social Functioning', 'Structure', 'Symptoms', 'System', 'Testing', 'Update', 'Work', 'Youth', 'aged', 'base', 'behavior measurement', 'behavioral phenotyping', 'brain behavior', 'case control', 'childhood adversity', 'cohort', 'critical period', 'data anonymization', 'design', 'early adolescence', 'emerging adult', 'follow-up', 'genome wide association study', 'genomic variation', 'help-seeking behavior', 'high risk', 'implementation science', 'improved', 'innovation', 'machine learning algorithm', 'machine learning method', 'male', 'multidisciplinary', 'multimodality', 'neuroimaging', 'novel', 'personalized predictions', 'polygenic risk score', 'precision medicine', 'predictive modeling', 'predictive test', 'psychiatric genomics', 'recruit', 'resilience', 'sex', 'social']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2020,787558,593605914,-0.028098614996700095
"Genotype First: Actionable Genetic Risk through Genotype-to-Phenotype Prediction Project Summary Early disease prevention, detection, and intervention are fundamental goals for advancing human health. Meanwhile, genetic risk is, for all intents and purposes, the earliest significant contributor to common, heritable, disease risk. Thus, in theory, genetic profiling should be the ideal tool for early disease prevention. Yet, genetic factors are rarely used directly to predict future disease risk. Rather, genetic information is typically relegated to phenotype-first scenarios: providing or confirming diagnoses for individuals with overt disease or clarifying the genetic risk for individuals with a strong family history of disease. For modern genomics to make a significant impact on disease prevention the use of genomic information must transition to a genotype-first approach; prediction of genetic disease risk in otherwise healthy individuals. A major barrier to this transition includes our limited ability to predict the precise array of risks and likely phenotypic expression of disease in an individual from genetic and other risk factors. The degree of disease risk and phenotypic expression conveyed to any single individual by genetic factors is a result of a complex interplay between direct and indirect genetic effects, other unmodifiable risk factors (age, gender, ancestry, family history), and intermediate modifiable risk factors (environment, behavior, laboratory values, health status, therapy status, etc.) many of which have their own direct genetic mediators. New approaches are required to dissect this interplay in order to personalize and contextualize preventative actions that most effectively reduce overall disease risk. The overarching goal of this proposal is the development of innovative Deep learning and machine-learning approaches to integrate baseline genetic risk predictions with the measurement of traditional risk factors in order to provide more accurate and actionable predictions of disease risk. By tying genetic risk to traditional risk factors, especially modifiable risk factors, we will enable actionability by allowing both a determination of preventative actions that may be especially effective because they offset genetic risk, as well as the identification of modifiable risk factors that should be monitored and controlled proactively given increased genetic predisposition. To accomplish this goal, we propose to develop methods to: (1) infer the likely phenotypic expressivity of monogenic risk variants via a spatial covariance machine learning approach, (2) predict prevalent disease cases and the expected value of intermediate modifiable risk factors from polygenic and other unmodifiable risk factors, and finally (3) predict prevalent disease cases through interactions between baseline genetic expectations and observed (measured) intermediate modifiable risk factors in a deep learning framework. Adjusting age and modifiable risk factors in these trained models would then allow for the interactive projection of future disease risk and the identification of modifiable risk factors that, when manipulated, lead to the greatest change in future disease risk. We focus on the development of methods for coronary artery disease given its public health importance, the known utility of polygenic risk estimation, and the current evidence for polygene-by-environment interactions. In addition, the approach we propose integrates directly with current clinical decision support tools for coronary artery disease management. However, we will build a general framework that can be extended to any common heritable adult-onset condition, especially those with known heritable, traditional risk factors Project Narrative Significant investment has been placed in the identification of genetic risk factors for common diseases. Yet, outside of family history, genetic risk is almost never included in routine clinical risk assessments. The goal of this proposal is to develop deep learning methods for the integration of genetic and traditional risk factors into comprehensive disease risk prediction.",Genotype First: Actionable Genetic Risk through Genotype-to-Phenotype Prediction,10051655,R01HG010881,"['Adult', 'Age', 'Area', 'Behavior', 'Blood Pressure', 'Cholesterol', 'Clinical', 'Complex', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Management', 'Elements', 'Environment', 'Environmental Exposure', 'Family', 'Family history of', 'Future', 'Gender', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Health Status', 'Heritability', 'Human', 'Incidence', 'Individual', 'Intervention', 'Investments', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Machine Learning', 'Measurement', 'Measures', 'Mediator of activation protein', 'Medical Genetics', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Myocardial Infarction', 'Non-Insulin-Dependent Diabetes Mellitus', 'Onset of illness', 'Output', 'Pathogenicity', 'Performance', 'Phenotype', 'Prevention', 'Public Health', 'Recording of previous events', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sample Size', 'Training', 'Variant', 'base', 'clinical decision support', 'clinical practice', 'clinical risk', 'data standards', 'deep learning', 'disease phenotype', 'disorder prevention', 'disorder risk', 'expectation', 'feature extraction', 'feedforward neural network', 'genetic information', 'genetic predictors', 'genetic profiling', 'genetic risk factor', 'genome-wide', 'genome-wide analysis', 'improved', 'innovation', 'learning strategy', 'method development', 'modifiable risk', 'multitask', 'novel strategies', 'personalized intervention', 'rare variant', 'risk variant', 'supervised learning', 'support tools', 'theories', 'tool', 'unsupervised learning', 'variant of unknown significance']",NHGRI,SCRIPPS RESEARCH INSTITUTE,R01,2020,790452,176988430,-0.025650838333367253
"Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease PROJECT SUMMARY / ABSTRACT Cardiovascular disease (CVD) is the single largest killer in the United States for both men and women in every racial/ethnic group. Thus, accurate and systematic evaluation of CVD risk represents an aspect of Precision Medicine that will touch every patient. CVD risk scores that are currently the standard of care are derived from research cohorts and are particularly inaccurate in women, older patients, and those with missing data. The goal of this Precision Medicine based application is to capitalize on the depth and breadth of clinical data within electronic health record (EHR) systems to revolutionize CVD risk prediction, thereby optimizing personalized care for every patient. Our proposed approach is innovative in that we have identified and addressed the most significant barriers to development of an EHR-based risk score. Novel aspects of this research include: 1) use of complete EHR data to develop and validate algorithms to define a variety of risk factors (e.g., reproductive history), thus building a comprehensive risk profile for each patient that incorporates diagnosis and procedure codes, laboratory values, clinical test results, patient provided information (e.g., alcohol use), and natural language processing of unstructured clinical text; 2) incorporation of age at onset of risk factors; 3) use of highly flexible machine learning techniques in the form of generalized boosted regression modeling; 4) exploration of a new deep learning model for censored EHR data; and 5) determination of the extent of risk reclassification in multiple geographically-defined populations, including an underserved minority population. Furthermore, genetic studies demonstrate that incorporating variants into current risk models improves risk prediction and use of an individual's genetic risk could further enhance our ability to deliver precision medicine to every patient. Therefore, we seek to develop a sex-specific next-generation CVD risk prediction score using EHR data in combination with genetic variants. This paradigm is a significant departure from the current one that relies on scores derived from relatively small research cohorts that use only a restricted set of clinical parameters that differentially misclassify an individual's risk, especially in women. Our access to empirical clinical EHR data for hundreds of thousands of patients uniquely positions us to 1) develop a sex-specific risk prediction model for incident CVD using data from the EHR; 2) assess the performance of the sex-specific EHR risk score in an independent non-urban and rural population; and 3) identify and characterize patients for whom genetic information improves CVD prediction beyond the clinical risk score. Successful completion of these aims has the potential to impact all adult patients, drive clinical practice changes to systematically collect sex-specific risk factors, and inform attempts to embed the next-generation CVD risk score into EHR systems for automated use in clinical care. PROJECT NARRATIVE Cardiovascular disease (CVD) is the single largest killer in the United States. We propose to use electronic health record data to improve our ability to accurately classify risk and identify those who would benefit from preventive therapies. Improved risk prediction will shed light on the mechanisms of CVD and potentially reduce incidence, save lives, and lower health care costs.",Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease,9838270,R01HL136659,"['Address', 'Adult', 'Age', 'Alcohol consumption', 'Algorithms', 'Cardiovascular Diseases', 'Clinical', 'Clinical Data', 'Clinics and Hospitals', 'Code', 'Communities', 'Community Hospitals', 'County', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Ethnic group', 'Evaluation', 'Event', 'Genetic Risk', 'Genetic study', 'Geography', 'Goals', 'Health', 'Health Care Costs', 'Hybrids', 'Incidence', 'Individual', 'Laboratories', 'Latino', 'Light', 'Machine Learning', 'Minnesota', 'Modeling', 'Natural Language Processing', 'Not Hispanic or Latino', 'Patients', 'Performance', 'Population', 'Positioning Attribute', 'Prevention strategy', 'Preventive', 'Preventive therapy', 'Procedures', 'Reproducibility', 'Reproductive History', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Rural', 'Rural Population', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Touch sensation', 'United States', 'Variant', 'Wisconsin', 'Woman', 'base', 'biobank', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'clinical care', 'clinical practice', 'clinical risk', 'cohort', 'deep learning', 'electronic data', 'feature extraction', 'flexibility', 'genetic information', 'genetic panel test', 'genetic variant', 'improved', 'innovation', 'men', 'multiple data types', 'next generation', 'novel', 'older patient', 'personalized care', 'phenotyping algorithm', 'precision genetics', 'precision medicine', 'prospective', 'racial and ethnic', 'research clinical testing', 'risk prediction model', 'sex', 'standard of care', 'time use', 'underserved minority']",NHLBI,MAYO CLINIC ROCHESTER,R01,2020,794994,276703803,-0.03352772916320478
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9975252,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Anti-Tumor Necrosis Factor Therapy', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Individual', 'Institution', 'Intuition', 'Leukocyte Chemotaxis', 'Lymphocyte Immunophenotypings', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Sampling', 'Series', 'Stains', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'analysis pipeline', 'base', 'big-data science', 'clinical diagnostics', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'education resources', 'human disease', 'improved', 'inquiry-based learning', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'myocardial injury', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2020,801165,3808719,-0.0007807124647791958
"Familial hypercholesterolemia screening in children: population impact of phenotype, genotype, and cascade approaches Project Summary  Familial hypercholesterolemia (FH) is a common genetic disorder, affecting every 200-1000 people, depending on the population and diagnostic criteria. FH leads to lifetime raised low-density lipoprotein (LDL) cholesterol, a high risk for premature atherosclerosis and downstream coronary heart disease. FH is designated as Tier 1 disease by the Center for Disease Control and Prevention, notably one of only three such diseases, because it is common, is associated with a high risk of premature illness, and is treatable with lifestyle or medications. Great uncertainty exists about the optimal approach to FH screening, which is reflected in conflicting recommendations in national screening guidelines.  We propose to synthesize high quality data from national surveys and population-based cohort studies in a health policy computer simulation model comparing the health and economic value of different FH screening strategies. This study will prioritize the optimal approaches to FH screening in the U.S. population, identifying optimal initial screening age and defining the role of genetic testing in screening.  We have assembled a team of experts in pediatric preventive cardiology, decision analysis, cardiovascular disease epidemiology, population genetics, biostatistics, health economic evaluation, and computer simulation modeling in order to evaluate and compare different FH screening strategies in children and adults. We aim to use this expertise and these methods in order to:   Quantify diagnostic yield, clinical effectiveness, and economic value of universal FH phenotype  screening in childhood or adulthood, and the added value of FH genotype screening   Compare universal FH screening to the alternatives of using family history or a Big Data-based  algorithm to direct targeted screening limited to children and adults with possible FH diagnosis   Quantify the health and economic value of cascade screening families of FH cases  We hypothesize that FH screening in childhood will be the highest value screening strategy in the U.S. population, and that genetic testing will improve diagnosis and treatment decisions most in cases of diagnostic uncertainty (e.g., borderline high cholesterol or absent family history). We hypothesize that a machine-learning algorithm will avoid the costs and complexity of universal screening, while yielding a similar case yield, as long as cholesterol testing is sufficiently common in children.  This study will identify the optimal approach to FH screening in the U.S. population and the most influential data based on current knowledge and set the stage for efficiently designed clinical trials of FH screening. This study will be a test case for the concept of a “precision” population health approach to screening for genetically-determined diseases in the general population. Familial hypercholesterolemia (FH) is a common genetic disorder characterized by lifetime elevated cholesterol, which, if uncontrolled, is associated with premature atherosclerotic cardiovascular disease. Conflicting current national guidelines highlight that the optimal approach to FH screening in the U.S. population is controversial: it is unclear if screening should start in childhood or adulthood, or if it should include genetic testing. We propose to synthesize data from national surveys, high quality cohort studies, and clinical trials of cholesterol lowering interventions in a lifetime cardiovascular disease risk computer simulation model to project the life time health impact of different FH screening approaches and identify optimal screening strategies in children and adults.","Familial hypercholesterolemia screening in children: population impact of phenotype, genotype, and cascade approaches",9883835,R01HL141823,"['Adult', 'Adverse effects', 'Advisory Committees', 'Affect', 'Age', 'Algorithms', 'Atherosclerosis', 'Big Data', 'Biometry', 'Cardiology', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Childhood', 'Cholesterol', 'Clinical Trials', 'Clinical Trials Design', 'Clinical effectiveness', 'Cohort Studies', 'Computer Simulation', 'Conflict (Psychology)', 'Coronary heart disease', 'County', 'Data', 'Decision Analysis', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Event', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Future', 'General Population', 'Genetic Diseases', 'Genetic Screening', 'Genotype', 'Guidelines', 'Health', 'Health Benefit', 'Health Policy', 'Hepatocyte', 'Influentials', 'Intervention', 'Knowledge', 'LDL Cholesterol Lipoproteins', 'Laboratories', 'Life', 'Life Style', 'Low Prevalence', 'Low-Density Lipoproteins', 'Medical Care Costs', 'Methods', 'Mutation', 'Parents', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Population Genetics', 'Prevalence', 'Preventive', 'Preventive service', 'Preventive treatment', 'Proxy', 'Puberty', 'Public Health', 'Randomized Controlled Trials', 'Recommendation', 'Recording of previous events', 'Role', 'Serum', 'Surveys', 'Testing', 'Time', 'Uncertainty', 'Visit', 'Youth', 'base', 'cardiovascular disorder epidemiology', 'cardiovascular disorder risk', 'clinical practice', 'cost', 'cost effective', 'cost effectiveness', 'diagnostic accuracy', 'economic evaluation', 'economic value', 'genetic testing', 'health economics', 'high risk', 'improved', 'improved outcome', 'lifestyle intervention', 'machine learning algorithm', 'machine learning method', 'models and simulation', 'pediatric patients', 'population based', 'population health', 'premature', 'premature atherosclerosis', 'prevent', 'screening', 'screening guidelines', 'screening program', 'treatment strategy', 'uptake']",NHLBI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,804498,558628098,-0.0667717198593419
"International Consortium for Multimodality Phenotyping in Adults with Non-compaction Summary Non-compaction cardiomyopathy (NCCM) is a heterogeneous, poorly understood disorder characterized by a prominent inner layer of loose myocardial tissue. Patients with NCCM are at increased risk of heart failure, stroke, severe rhythm irregularities and death. Current imaging techniques cannot differentiate pathological from benign hypertrabeculation. In addition, current echo/MRI-based criteria of NCCM lead to over-diagnosis of NCCM, provide no prognostic value, and lead to implantation of defibrillators (ICD) and the use of anticoagulation without a positive benefit in many otherwise healthy individuals with non-compacted myocardium. For a growing population diagnosed with NCCM there is an urgent need for better risk stratification to appropriately allocate (or safely withhold) these impactful preventive measures. Our international consortium combines expertise in myocardial disease, cardiac imaging and advanced computer analytics from 5 centers dedicated to the care of patients with cardiomyopathies, and has the ultimate goal to improve care of patients with non-compaction cardiomyopathy. We hypothesize that comprehensive analysis of clinical, genetic, structural and functional information will improve risk stratification. In addition, we hypothesize that detailed structural analysis will allow for differentiation of pathological and benign patterns of non-compaction. In a large cohort of adult patients with suspected NCCM we will perform in-depth phenotyping, including clinical information, pedigree data, genetics, echocardiography and MRI, and follow patients for up to 3 years. We will apply machine-learning based analytics to develop predictive models and compare their performance to currently used models and treatment criteria. Secondly, in a subset of patients we will perform high-resolution cardiac CT for detailed structural characterization of the myocardial wall. Novel analytical methods will be developed to characterize the 3D architectural complexity based on pathophysiological hypothesis, but also using hypothesis-free analyses of raw images using deep learning techniques. In addition, we will investigate associations between myocardial structure and regional contractile function, as assessed by echo and MRI. The aim of this proposal is to identify a structural signature associated with pathological non-compaction and improve developed risk prediction models. This international consortium dedicated to NCCM will be the first to collect genetic and multi-modality imaging data. Discovery of pathological structural signatures through innovative imaging techniques, in relation to myocardial contractility, will advance our understanding of NCCM. There is an urgent clinical need for diagnostic techniques that detect pathological non-compaction and identify patients at risk of devastating complications. This study is clinically relevant because the developed predictive models may permit more effective, personalized preventive care in a growing number of individuals diagnosed with non-compaction cardiomyopathy. Project Narrative The proposed research is relevant to the public health because recognition of pathological myocardial non- compaction and identification of patients at risk for embolic stroke, ventricular arrhythmia and sudden cardiac death will allow for more effective use of life-saving measures, but also avoid unnecessary ICD implantations and anticoagulation in healthy individuals with benign hypertrabeculation. Thus, the proposed research is relevant to the NIH's mission that pertains to the discovery of fundamental knowledge about the nature and behavior of living systems and the application of that knowledge to enhance health, lengthen life, and reduce illness and disability.",International Consortium for Multimodality Phenotyping in Adults with Non-compaction,9977674,R01HL146754,"['3-Dimensional', 'Adult', 'Adverse event', 'Anticoagulation', 'Architecture', 'Arrhythmia', 'Artificial Intelligence', 'Awareness', 'Behavior', 'Benign', 'Cardiac', 'Cardiomyopathies', 'Cessation of life', 'Clinic', 'Clinical', 'Complex', 'Computers', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Defibrillators', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Disease', 'Echocardiography', 'Event', 'Family member', 'Foundations', 'Fractals', 'Genetic', 'Genetic Structures', 'Goals', 'Guidelines', 'Health', 'Heart failure', 'Histologic', 'Image', 'Image Analysis', 'Imaging Techniques', 'Individual', 'International', 'Intervention', 'Joints', 'Knowledge', 'Lead', 'Left ventricular non-compaction', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical Genetics', 'Mission', 'Modeling', 'Multimodal Imaging', 'Mutation', 'Myocardial', 'Myocardial tissue', 'Myocardium', 'Nature', 'Non-compaction cardiomyopathy', 'Organism', 'Outcome', 'Pathologic', 'Patient Care', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phenotype', 'Physiological', 'Population', 'Predictive Value', 'Preventive Intervention', 'Preventive care', 'Preventive measure', 'Preventive therapy', 'Public Health', 'Research', 'Resolution', 'Risk', 'Risk Factors', 'Risk stratification', 'Savings', 'Stroke', 'Structure', 'Sudden Death', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Ventricular Arrhythmia', 'accurate diagnosis', 'adjudicate', 'adjudication', 'adverse event risk', 'analytical method', 'base', 'clinically relevant', 'cohort', 'deep learning', 'density', 'disability', 'embolic stroke', 'genetic pedigree', 'heart imaging', 'high risk', 'imaging genetics', 'implantation', 'improved', 'improved outcome', 'innovation', 'multimodality', 'novel', 'outcome prediction', 'patient subsets', 'predictive modeling', 'prognostic value', 'prospective', 'radiomics', 'research clinical testing', 'risk prediction model', 'sudden cardiac death', 'thrombogenesis', 'young adult']",NHLBI,STANFORD UNIVERSITY,R01,2020,805761,560644462,-0.04821009618590552
"Prospective sudden cardiac death risk stratification using CMR and echocardiography machine learning in mitral valve prolapse PROJECT SUMMARY Mitral valve prolapse (MVP) is a common valvulopathy affecting over 170 million worldwide. Every year, 0.4- 1.9% of individuals with MVP will develop sudden cardiac arrest (SCA) or sudden cardiac death (SCD), and 7% of SCDs in the young are caused by MVP. However, predictors of this devastating outcome are not readily available, and indications for a primary prevention implantable cardioverter defibrillator (ICD) in MVP are lacking. Severe mitral regurgitation explains only 50% of SCA cases in MVP. SCD/SCA risk has also been linked to a bileaflet phenotype with mild MR, mitral annular disjunction (MAD), and left ventricular focal fibrosis on cardiac magnetic resonance (CMR)-late gadolinium enhancement (LGE) images. Such imaging parameters (including LGE) have not been evaluated prospectively. Moreover, they are not consistently found in SCA survivors, and diffuse fibrosis has been proposed as an alternative arrhythmic substrate by our group and others based on CMR/T1 mapping, strain echocardiography, and post-mortem data. Overall, it is challenging to pinpoint a unique imaging phenotype, and uncertainty exists about which MVP patients should undergo CMR. Regardless of arrhythmic phenotype, complex ventricular ectopy (ComVE - defined as frequent polymorphic PVCs, bigeminy or non-sustained ventricular tachycardia) is detected in 80-100% of MVP cases prior to SCA or SCD. ComVE, commonly associated with left ventricular fibrosis on CMR, is linked to higher all-cause mortality and SCA rates (20% versus 12% if no ComVE, p < 0.05) based on preliminary cross-sectional data. Our central hypothesis is that MVP patients with ComVE, because of the higher prevalence of either LGE or abnormal T1 mapping, represent ideal CMR candidates regardless of leaflet involvement or MAD, and can be rapidly identified by an automated “surveillance” tool within a large echocardiographic database. Moreover, we hypothesize that fibrosis is the strongest predictor of SCD/SCA in an unprecedented, multi-center effort to longitudinally assess clinical and CMR parameters of arrhythmic risk in MVP. Specifically, we aim to 1) Assess the role of CMR as a screening tool for fibrosis in MVP with ComVE incorporating T1 mapping in addition to LGE in an unselected MVP sample; 2) Develop an echo-based machine-learning algorithm to detect MVP with ComVE, test its association with myocardial fibrosis on CMR and longitudinal SCD/SCA risk; and 3) Build a novel prospective SCD/SCA risk prediction model in MVP. Better selection of CMR candidates and development of a SCD/SCA risk prediction tool inclusive of fibrosis by CMR are expected to dramatically improve risk stratification in MVP and establish future criteria for primary prevention ICD trials. PROJECT NARRATIVE Every year, 0.4-1.9% of individuals with mitral valve prolapse (MVP) will develop sudden cardiac death or arrest. In this application we propose to better identify those at risk by using cardiac magnetic resonance and echocardiography-based artificial intelligence, with the long-term goal of selecting those that may benefit most from a defibrillator. .",Prospective sudden cardiac death risk stratification using CMR and echocardiography machine learning in mitral valve prolapse,10034460,R01HL153447,"['Affect', 'Artificial Intelligence', 'Autopsy', 'California', 'Cardiac', 'Clinical', 'Clinical Markers', 'Complex', 'Data', 'Databases', 'Defibrillators', 'Development', 'Diffuse', 'Echocardiography', 'Fibrosis', 'Future', 'Gadolinium', 'Goals', 'Heart Arrest', 'High Prevalence', 'Holter Electrocardiography', 'Hybrids', 'Image', 'Image Enhancement', 'Implantable Defibrillators', 'Individual', 'Lead', 'Left', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Mission', 'Mitral Valve Insufficiency', 'Mitral Valve Prolapse', 'Myocardial', 'Outcome', 'Patients', 'Phenotype', 'Population', 'Prevalence', 'Primary Prevention', 'Registries', 'Retrospective Studies', 'Risk', 'Risk stratification', 'Role', 'Sampling', 'San Francisco', 'Screening procedure', 'Survivors', 'Testing', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Universities', 'Validation', 'Ventricular', 'Ventricular Tachycardia', 'base', 'cardiovascular risk factor', 'coronary fibrosis', 'cost', 'extracellular', 'hemodynamics', 'high risk', 'improved', 'machine learning algorithm', 'mortality', 'neural network architecture', 'novel', 'prognostic significance', 'prospective', 'recurrent neural network', 'risk prediction model', 'secondary analysis', 'stem', 'sudden cardiac death', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,810751,685608202,-0.004978995594722417
"Incorporating Learning Effects into Medical Device Active Safety Surveillance Methods Implantable medical devices have revolutionized contemporary cardiovascular care, and are used in a wide spectrum of acute and chronic cardiovascular conditions. However, medical device design fault or incorrect use may lead to significant risk of patient injury and represents an important preventable public health risk in the United States. To help identify device-related safety issues, a strategy of active, prospective, post-market safety surveillance has been recommended by the FDA, and evaluated methodologically. This type of surveillance offers significant advantages over traditional adverse event reporting strategies. However, all such approaches are challenged by the need to incorporate learning effects into expectations regarding safety. These learning impacts been repeatedly shown to have dramatic impacts on outcomes during early device experience. Quantifying learning effects on the outcomes associated with high-risk cardiovascular devices will improve our understanding of intrinsic device performance, thereby identifying patient populations best treated with such devices while simultaneously providing necessary feedback to device manufacturers to support iterative improvement in device design. Separately, understanding the impacts of learning may identify opportunities for targeted training as well as help to tease apart institutional and operator characteristics that may accelerate the achievement of optimal outcomes in the use of the specific cardiovascular device.  This proposal seeks to extend the previously validated, open-source, active, prospective device safety surveillance tool, by developing and validating robust learning curve (LC) detection and quantification algorithms, designed to simultaneously account for the effects at the operator and institutional levels. We propose a “blinded” development strategy, in which one team will generate robust synthetic clinical data simulator with LC impacts, and the other team develops and applies LC detection and quantification algorithms, without knowledge of the underlying relationships, determine performance and accuracy through sequential refinement and validation steps. We propose to formally validate the optimized LC tools in real-world data through re-analysis of previously published LC effects on transcatheter valves and vascular closure devices using national cardiovascular registries. In addition, the LC tools will be incorporated into two active, prospective device safety surveillance studies of novel implantable cardiovascular devices using large clinical registries. This proposal seeks to understand the impact of institutional and physician learning on the safety of newly approved cardiovascular devices, and to use this knowledge to support and improve effective medical device safety surveillance. We propose a “blinded” strategy of separating simulated dataset generation from the learning effects detection and quantification algorithm development. Incorporating learning effects adjustment into a validated, prospective, near-real-time safety surveillance system, this research will improve public health by identifying poorer performing cardiovascular devices, and provide physicians, device manufacturers and public health officials with better information to optimize the use of medical devices, iteratively improve their design, and identify opportunities for enhanced training that will result in improved patient outcomes.",Incorporating Learning Effects into Medical Device Active Safety Surveillance Methods,9863048,R01HL149948,"['Achievement', 'Acute', 'Address', 'Adverse event', 'Algorithm Design', 'Algorithms', 'Blinded', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Set', 'Detection', 'Development', 'Device Designs', 'Device Safety', 'Devices', 'Early Diagnosis', 'Elements', 'Environment', 'Etiology', 'Evaluation', 'Event', 'Feedback', 'Generations', 'Implant', 'Injections', 'Injury', 'Institution', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Manufacturer Name', 'Medical Device', 'Medical Device Designs', 'Medical Device Safety', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Process', 'Provider', 'Public Health', 'Publishing', 'Registries', 'Reporting', 'Risk', 'Safety', 'Signal Transduction', 'Specific qualifier value', 'Statistical Models', 'Structure', 'Surveillance Methods', 'Time', 'Training', 'United States', 'Validation', 'Variant', 'adverse outcome', 'algorithm development', 'cardiovascular risk factor', 'clinical heterogeneity', 'design', 'expectation', 'experience', 'high risk', 'implantable device', 'improved', 'novel', 'open source', 'patient population', 'post-market', 'prospective', 'safety outcomes', 'simulation', 'surveillance strategy', 'surveillance study', 'systems research', 'tool']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,828534,377931988,-0.015496475373046124
"Development and validation of an electronic health record prediction tool for first-episode psychosis Psychosis is a major public health challenge, with approximately 100,000 adolescents and young adults in the US experiencing a first episode of psychosis (FEP) every year. Early intervention following FEP is critical for achieving improved outcomes, yet treatment of FEP is often delayed between 1 and 3 years in the US due to delays in detection and referral. The World Health Organization has advocated shortening the duration of untreated psychosis (DUP) to three months or less. The goal of this study is to develop and validate a universal EHR-based screening tool for early detection of FEP across large clinical populations in diverse healthcare settings. In order to maximize the impact and generalizability of the tool across a wide range of healthcare settings, we will rely only on coded medical information collected in the course of care and thus widely available in EHRs. The tool will be developed and validated with data from three diverse health systems that cover over 8 million patients spanning a wide range of demographic, socioeconomic and ethnic backgrounds: Partners Healthcare System, Boston Children's Hospital, and Boston Medical Center. The study will be conducted by a closely collaborating interdisciplinary team of clinical specialists, psychosis researchers, and risk modeling experts based at these health systems and Harvard Medical School, with extensive experience in treating psychosis patients, and developing strategies for detecting FEP and EHR-based risk screening tools for early detection of various clinical conditions. Our preliminary studies show that EHR-based risk models can be used to sensitively and specifically detect FEP cases, on average 2 years before the first psychosis diagnosis appears in their EHR. Our specific aims include: 1. Define a robust cross-site case definition for FEP that relies only on information commonly available in EHRs and validate it through expert chart review; 2. Train and validate a predictive model for early detection of FEP based on large samples of patient data from the three sites; 3. Develop and validate FEP early detection models for key subpopulations, including patients receiving care at mental health clinics, adolescent medicine outpatient programs, and substance abuse treatment programs; and 4. Engage clinical stakeholders in the process of developing a prototype clinician-facing EHR-based risk screening tool for FEP, and release it as an open source SMART App, enabling further validation and clinical integration across a wide range of healthcare settings. Completion of these aims would provide a novel, clinically deployable, and potentially transformative tool for improving the trajectory of those affected with psychosis and reducing the burden and costs of untreated illness. Psychosis is a major public health challenge, with difficulties and delays in detecting its onset that can lead to worse clinical outcomes. The proposed research will develop a clinician-facing electronic-health-record-based automated screening tool for early detection of the first episode of psychosis, with implications for reducing the duration of untreated psychosis as recommended by the NIMH and World Health Organization. The tool will be validated across three large and diverse health systems and released as an open source application (SMART App), increasing its potential for rapid implementation in health systems and clinical care.",Development and validation of an electronic health record prediction tool for first-episode psychosis,9864102,R01MH116042,"['Accident and Emergency department', 'Adolescent Medicine', 'Adolescent and Young Adult', 'Advocate', 'Affect', 'Boston', 'Calibration', 'Caring', 'Clinic', 'Clinical', 'Code', 'Communities', 'Data', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Early Intervention', 'Electronic Health Record', 'General Population', 'Goals', 'Health system', 'Healthcare Systems', 'Inpatients', 'Intervention', 'Laboratories', 'Lead', 'Manuals', 'Measures', 'Medical', 'Medical center', 'Mental Health', 'Modeling', 'National Institute of Mental Health', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Primary Health Care', 'Procedures', 'Process', 'Psychotic Disorders', 'Public Health', 'Research', 'Research Personnel', 'Research Support', 'Risk', 'Risk Factors', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Specialist', 'Suicide', 'Testing', 'Time', 'Training', 'Validation', 'Work', 'World Health Organization', 'base', 'clinical care', 'cost', 'data resource', 'design', 'experience', 'first episode psychosis', 'health care settings', 'improved', 'improved outcome', 'individual patient', 'interest', 'medical schools', 'medical specialties', 'novel', 'open source', 'outpatient programs', 'predictive modeling', 'prototype', 'random forest', 'socioeconomics', 'substance abuse treatment', 'support vector machine', 'tool', 'treatment program']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,847935,551214295,-0.009323110597292877
"An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis Project Summary  Improved methods for the bedside diagnosis and evaluation of neuromuscular disorders are needed. One technology that is finding increasing use for this purpose is electrical impedance myography (EIM). In EIM, a very weak, high frequency electrical current is passed through a muscle of interest and the resulting surface voltages are measured. Disease associated alterations in the composition and microstructural features of the muscle produce characteristic changes that can be used to help classify specific conditions and grade disease severity. To date, most studies using EIM analysis have utilized a fairly limited data set for disease assessment. While effective, this approach ignores a great deal of information locked within the impedance data, including those values that can assist in predicting specific muscle features (such as myofiber diameter) and the presence of pathological change (e.g., fat or connective tissue deposition). In addition, as it stands, the data set is challenging for the clinician to understand without a detailed knowledge of impedance theory. Myolex, Inc is a small business concern located in Boston, MA has as its main focus the development of EIM technologies for clinical use. Myolex recently completed a Phase 1 SBIR that demonstrated the potential capability of machine learning based classification algorithms to effectively discriminate healthy muscle from diseased and to discriminate one disease from another. In this proposed work, we will greatly advance this concept by embodying classification algorithms into a powerful new software suite for Myolex’s current EIM system, the mView. Our underlying hypothesis is that EIM data analysis can be automated to the point that classification systems can provide data on disease diagnosis as well as disease severity for improved ease-of-use. We propose to study this hypothesis via 2 specific aims. In Specific Aim 1, we will design a software suite capable of assisting with artifact-free data collection to be incorporated into our current EIM system, the mViewTM. Then using classification paradigms based on a prodigious amount of previous collected data, we will develop an automated data analysis tool to help provide data on disease category as well as microscopic features, muscle based on the impedance data alone using Microsoft’s Azure Cloud platform. In Specific Aim 2, we will test this developed software suite in a total of180 adult and pediatric neuromuscular disease patients and healthy participants evaluated at Ohio State University Wexner Medical Center (adults) and Boston Children’s Hospital (children). During this data collection period, the Ohio State and Boston Children’s researchers will have real- time access to Myolex staff to provide feedback and have questions/problems answered and addressed. The user interface will continue to be refined and classification algorithms improved. At the conclusion of this work, a new diagnostic tool will be developed for potential 510(k) FDA approval. It will serve as the basis for a continuously self-refining system as additional data sets are collected by end-users employing them in regular clinical use. Project Narrative  Electrical impedance myography (EIM) is a valuable technique to assist with the evaluation of a variety of conditions affecting nerve and muscle. However, to date, only simplistic EIM outcomes have been utilized to assess muscle condition. In this proposed work, we will develop a software platform using machine learning to be incorporated into current EIM technology to allow for automated diseased classification and characterization using the entire large EIM data set collected with each muscle measurement. This will serve as the basis for a new, powerful and convenient tool for neuromuscular diagnosis that will continue to advance over time.",An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis,10002324,R44NS113756,"['Address', 'Adult', 'Affect', 'Algorithmic Software', 'Amyotrophic Lateral Sclerosis', 'Area', 'Back Pain', 'Boston', 'Businesses', 'Caliber', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Classification', 'Clinical', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Set', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Duchenne muscular dystrophy', 'Effectiveness', 'Electrodes', 'Ensure', 'Evaluation', 'Fatty acid glycerol esters', 'Feedback', 'Fiber', 'Frequencies', 'Functional disorder', 'Health', 'Inclusion Body Myositis', 'Individual', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Medical Technology', 'Medical center', 'Methods', 'Microscopic', 'Morphologic artifacts', 'Muscle', 'Muscular Dystrophies', 'Myography', 'Myopathy', 'Myositis', 'Nerve', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Ohio', 'Outcome', 'Participant', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Provider', 'Radiculopathy', 'Research Personnel', 'Role', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Work', 'advanced analytics', 'base', 'classification algorithm', 'cloud based', 'cloud platform', 'commercialization', 'complex data ', 'data acquisition', 'design', 'diagnosis evaluation', 'disease classification', 'disease diagnosis', 'electric impedance', 'feature extraction', 'improved', 'indexing', 'interest', 'machine learning algorithm', 'method development', 'nerve injury', 'neuromuscular', 'novel diagnostics', 'pediatric patients', 'physical therapist', 'prototype', 'sarcopenia', 'software development', 'success', 'theories', 'tool', 'usability', 'user friendly software', 'user-friendly', 'voltage']",NINDS,"MYOLEX, INC.",R44,2020,869698,869698,0.0026180114810748565
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,9965942,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data warehouse', 'database design', 'deep learning', 'heuristics', 'improved', 'in silico', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'personalized diagnostics', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2020,989602,254622553,-0.00664237795077796
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,9970170,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'automated algorithm', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'machine learning algorithm', 'multidisciplinary', 'pathogen', 'point of care', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2020,991540,51931732,-0.011617114570477842
"THE SEARCH FOR COVID-19 PREVENTION AND CURE: ADDRESSING THE CRITICAL ROLE OF INNATE/ADAPTIVE IMMUNITY BY INTEGRATING NOVEL INFORMATICS, TRANSLATIONAL TECHNOLOGIES, AND ONGOING CLINICAL TRIAL RESEARCH Individual CTSA hubs are leading the national clinical and translational research efforts in developing new approaches to address the COVID-19 pandemic. This crucial role was natural. Long before the current crisis, CTSA hubs were committed to translation, building multidisciplinary teams of investigators and community partners, overcoming regulatory burdens, ensuring quality in clinical and human research, developing transformative informatics, and disruptive technologies for diagnostics and therapeutics. In this proposal, we build on our center’s active participation in meaningful clinical trials (e.g., the NIH Remdesivir RCT), the early creation of a biospecimen repository from COVID-19 patients, institutional commitment and fundraising that led to a $3.5 million pilot fund distribution, a robust and accessible clinical database repository, and the ongoing work of an NCATS-supported CTSA Collaboration Innovation Award (a coalition of the J. Craig Venter Institute, UCSD, UCI, and Stanford) focused on artificial intelligence approaches for the analysis of flow cytometry data. Using the emerging informatics framework of supervised generalized canonical correlation for integrative data analysis, we will link clinical data from COVID-19 patients enrolled in a variety of trials and at various stages of disease with innovative in vitro evaluation of innate and adaptive immunity, an area still poorly understood in SARS-CoV-2 pathology, obtained from patient biospecimens to obtain mechanistic insights of COVID-19 pathogenesis at a systems level. Innate and adaptive immunity are particularly relevant to COVID-19 disease pathogenesis because they play key, but distinct, roles at all phases of the illness (initial tissue-virus interaction; systemic responses; the cell-mediated cytokine storm leading to multi- organ failure and death, likely long after levels of viremia have fallen; and, ultimately, protective immunity). The current CCIA novel flow cytometry informatics research permits elucidation of dynamic cellular immune responses related to the COVID-19 pandemic that were heretofore unobservable. Using Hi-DAFi for mass cytometry analysis, validated informatics pipelines for single cell transcriptomics analysis, and cutting-edge statistical data integration and machine learning strategies tied back to the available clinical data we will be able to discover novel associations between cellular biomarkers and disease state, a particular therapy, and disease mediating factors such as age, health disparities, and the presence of other diseases or conditions like obesity. This information will aid in critical efforts to target new therapies and possibly identify idiosyncratic individual physiologic variables that render certain patients who seem to have no known comorbidities more vulnerable to severe COVID-19 disease. Finally, the robust connection between the UCI hub and both regional and national networks (e.g., BRAID, the coalition of the 5 UC CTSAs, and NCATS Trial Innovation Network) will provide an unprecedented opportunity to rapidly disseminate clinically relevant discoveries and engage the talent and insight of the many clinicians and scientists working tirelessly to end this pandemic. BLANK PER PA-18-591","THE SEARCH FOR COVID-19 PREVENTION AND CURE: ADDRESSING THE CRITICAL ROLE OF INNATE/ADAPTIVE IMMUNITY BY INTEGRATING NOVEL INFORMATICS, TRANSLATIONAL TECHNOLOGIES, AND ONGOING CLINICAL TRIAL RESEARCH",10158982,UL1TR001414,"['2019-nCoV', 'Acceleration', 'Address', 'Age', 'Antibody titer measurement', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Award', 'B-Lymphocytes', 'Back', 'Biological Assay', 'Biological Markers', 'Biological Specimen Banks', 'Biomedical Research', 'Blood Circulation', 'Blood specimen', 'COVID-19', 'COVID-19 pandemic', 'Cardiovascular system', 'Cells', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communities', 'Controlled Clinical Trials', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Enrollment', 'Ensure', 'Evaluation', 'Failure', 'Flow Cytometry', 'Foundations', 'Funding', 'Future', 'Genetic Determinism', 'Genetic Transcription', 'Goals', 'Health', 'Human', 'IL6 gene', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Immunologics', 'Immunology', 'Immunology procedure', 'In Vitro', 'Incidence', 'Individual', 'Industry', 'Infection', 'Inflammatory', 'Informatics', 'Institutes', 'Institution', 'Interleukin-10', 'Leadership', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Molecular', 'Monitor', 'Multiomic Data', 'Natural Immunity', 'Nucleic Acids', 'Obesity', 'Paper', 'Participant', 'Pathogenesis', 'Pathology', 'Patients', 'Phase', 'Physiological', 'Placebos', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Research', 'Research Personnel', 'Resources', 'Respiratory distress', 'Role', 'Sampling', 'Schedule', 'Scientist', 'Serologic tests', 'Severity of illness', 'Signal Transduction', 'Supervision', 'Symptoms', 'System', 'T-Lymphocyte', 'TNF gene', 'Talents', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Trials', 'Therapy Clinical Trials', 'Tissues', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Vaccines', 'Validation', 'Viral Load result', 'Viremia', 'Virus', 'Work', 'adaptive immunity', 'clinical database', 'clinically relevant', 'comorbidity', 'computer framework', 'computing resources', 'cytokine', 'cytokine release syndrome', 'data integration', 'data warehouse', 'dissemination research', 'early detection biomarkers', 'enzyme linked immunospot assay', 'experience', 'feature selection', 'health disparity', 'innovation', 'insight', 'interest', 'learning strategy', 'meetings', 'multidisciplinary', 'multiple omics', 'new therapeutic target', 'novel', 'novel strategies', 'pandemic disease', 'predictive marker', 'remdesivir', 'repository', 'respiratory', 'response', 'statistical and machine learning', 'transcriptome sequencing', 'transcriptomics', 'treatment response', 'virus genetics']",NCATS,UNIVERSITY OF CALIFORNIA-IRVINE,UL1,2020,1088735,167717872,-0.00593035442773237
"DIGITAL HEALTH SOLUTIONS FOR COVID-19: PERSONALIZED ANALYTICS WEARABLE BIOSENSOR PLATFORM FOR EARLY DETECTION OF COVID-19 DECOMPENSATION The goal of this project is to develop an artificial intelligence-based data analytics and cloud computing platform, paired with U.S. Food and Drug Administration (FDA)-cleared wearable devices, to create a personalized baseline index that could indicate a change in health status for patients who have tested COVID-19 positive.  The project involves the development and validation of a COVID-19 Decompensation Index (CDI) that builds off physIQ’s existing wearable biosensor-derived analytics platform.  Data will be collected from 400 human subjects that are both pre-hospitalization subjects (found to be positive for COVID-19) and subjects that have been hospitalized and treated for COVID and then discharged.  This combined population will consist of COVID-19 decompensation cases (event cases) and cases for which COVID-19 did not result in any kind of decompensation (non-event cases).  The 400-patient dataset will be partitioned into a training subset and a testing subset.  Performance will be assessed using receiver operator characteristics (ROC) area under the curve (AUC) as the metric of performance.  Data collected under this project will be deidentified and securely transmitted to an NIH data hub. n/a",DIGITAL HEALTH SOLUTIONS FOR COVID-19: PERSONALIZED ANALYTICS WEARABLE BIOSENSOR PLATFORM FOR EARLY DETECTION OF COVID-19 DECOMPENSATION,10274152,5N91020C00040,"['Area Under Curve', 'Artificial Intelligence', 'Biosensor', 'COVID-19', 'Cloud Computing', 'Data', 'Data Analytics', 'Data Set', 'Development', 'Early Diagnosis', 'Event', 'Goals', 'Health', 'Health Status', 'Hospitalization', 'Patients', 'Performance', 'Population', 'Receiver Operating Characteristics', 'Secure', 'Testing', 'Training', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'computational platform', 'coronavirus disease', 'data hub', 'digital', 'human subject', 'indexing', 'wearable device']",NCI,"VGBIO, INC.",N01,2020,2305814,2305814,-0.014343348980641369
"Eavesdropping on heart-brain conversations during sleep for early detection and prevention of fatal cardiovascular disease ABSTRACT  The intimate link between the heart, brain and sleep is central to our well-being and ability to meet the demands of life. A majority of cardiovascular (CV) deaths occur in the early waking hours from sleep. For example, sudden cardiac arrest (SCA), an extremely prevalent and devastating condition, claims more lives (>350,000/year) in the USA than all disease-related causes of death combined. A defibrillator can prevent SCA, but current clinical strategies are grossly inadequate, both in terms of identifying people at risk and importantly, monitoring and controlling the CV risk. To address this major gap, we are proposing an entirely novel approach for studying heart-brain interactions during sleep. To our knowledge, our compelling new preliminary data and innovative strategy are unprecedented.  In robust preliminary studies of animals and humans, we have identified unique signatures of evolving, potentially fatal, CV disease within electrocardiogram (ECG) and electroencephalogram (EEG) waveforms that otherwise cannot be detected by current clinical methods and conventional statistics. Our powerful new tools reveal these “hidden” signatures during sleep (i.e., as conscious activity decreases and autonomic control of the heart becomes prominent). This missing link we have identified between the heart, brain, spontaneous intrinsic arousals, and critical CV disease is independent (in multivariate analyses) of sleep disordered breathing (e.g., apnea) and established risk factors. Our novel and highly promising findings may account for the high incidence of CV deaths associated with sleep and have potential for broad application, ranging from animal models to improved reclassification of individuals currently consid- ered “low”, “moderate” or “high” risk in contemporary clinical practice. This is important because asymptomatic individ- uals without advanced CV disease comprise the majority of SCA victims. They also are the ones “missed” by current risk stratification methods and the most challenging to identify. Further, our fundamental new approach to EEG and ECG analysis will add new, clinically valuable, prognostic insight for patients with advanced CV disease (e.g., heart failure). This robust, inexpensive, personalized strategy for identifying who will and will not need lifesaving therapy will also avoid unnecessary procedures and complications, and thus, will provide substantial socioeconomic benefits.  This paradigm-shifting application for a NIH Director’s New Innovator Award incorporates clinical cardiac electro- physiology, critical care and sleep medicine with engineering, mathematics, artificial intelligence, statistical dynamical systems, and molecular, cellular and clinical research to enable early diagnosis and therapy of critical CV disease. Our unique approach for gaining novel mechanistic insight into CV pathology and risk during sleep is likely to spawn new avenues in collaborative multidisciplinary research. Because our new paradigm can be seamlessly incorporated into existing technology readily available in hospitals and clinics, we expect our findings to rapidly transform contem- porary clinical practice in multiple fields. Importantly, the ability to identify and decode “hidden” EEG and ECG signa- tures of early onset of fatal, subclinical CV illness, including SCA, the leading cause of death in the industrialized world, has extraordinary implications for human health and the potential for broad worldwide application. NARRATIVE  The treatment of heart disease after clinical presentation has limited success. Irreversible organ system damage often initiates by the time the patient presents clinically. We seek to introduce, understand and validate a completely new approach for analyzing heart and brain signals to reveal information about evolving critical disease in an individual that otherwise would remain undetected by current clinical methods until catastrophic clinical presentation. If validated, this new paradigm will have extraordinary implications for human health and the potential to open new avenues in research and therapy.",Eavesdropping on heart-brain conversations during sleep for early detection and prevention of fatal cardiovascular disease,10002962,DP2HL157941,"['Address', 'Animal Model', 'Animals', 'Apnea', 'Arousal', 'Artificial Intelligence', 'Award', 'Brain', 'Cardiac Electrophysiologic Techniques', 'Cardiovascular Diseases', 'Cardiovascular Pathology', 'Cardiovascular system', 'Cause of Death', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinics and Hospitals', 'Conscious', 'Critical Care', 'Data', 'Defibrillators', 'Disease', 'Early Diagnosis', 'Early treatment', 'Electrocardiogram', 'Electroencephalogram', 'Engineering', 'Health', 'Heart', 'Heart Arrest', 'Heart Diseases', 'Heart failure', 'Hour', 'Human', 'Incidence', 'Individual', 'Industrialization', 'Interdisciplinary Study', 'Life', 'Link', 'Mathematics', 'Medicine', 'Methods', 'Molecular', 'Monitor', 'Multivariate Analysis', 'Patients', 'Personal Satisfaction', 'Prevention', 'Research', 'Risk', 'Risk Factors', 'Risk stratification', 'Signal Transduction', 'Sleep', 'Sleep Apnea Syndromes', 'Technology', 'Time', 'United States National Institutes of Health', 'Unnecessary Procedures', 'body system', 'cardiovascular risk factor', 'clinical practice', 'dynamic system', 'early onset', 'high risk', 'improved', 'innovation', 'insight', 'novel', 'novel strategies', 'personalized strategies', 'prevent', 'prognostic', 'socioeconomics', 'statistics', 'success', 'tool']",NHLBI,UNIVERSITY OF CINCINNATI,DP2,2020,2407500,88720000,-0.006111813943273904
"Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)? PROJECT SUMMARY The North Coast Conference on Precision Medicine is a national annual mid-sized conference series held in Cleveland, Ohio. The conference series aims to serve as a venue for the continuing education and exchange of scientific ideas related to the rapidly evolving and highly interdisciplinary landscape that is precision medicine research. The topics for each conference coincide with the national conversation and research agenda set by national research programs focused on precision medicine. The 2018 conference is a symposium that will focus on issues related to return of genomic results both in clinical and research settings with an emphasis on diverse populations. The conference will be organized as a traditional format with invited speakers from among national experts for topics ranging from issues returning research results to culturally diverse participants and family members, inclusion of diverse patient and participant populations in the Clinical Sequencing Evidence- Generating Research (CSER) consortium and the Trans-Omics for Precision Medicine (TOPMed) Program, pharmacogenomics-guided dosing and race/ethnicity, strategies used to return results, among others. 2019 and beyond conference topics are being considered from previous symposia attendees and trends in precision medicine research. Odd-numbered year conferences include a workshop component that has previously covered outcome and exposure variable extraction from electronic health records. Future workshop topics being considered include integration of multiple ‘omics, drug response in different populations, pharmacogenomics clinical implementation, precision medicine in cancer, data sharing and informed consent, and the use of apps for recruitment, diagnosis, follow-up, and treatment. Our second major objective of this conference series is the promotion of diversity in the biomedical workforce. It is well-known that the pipeline from training to full professor for women in biomedical research is leaky whereas the pipeline for under-represented minorities is practically non-existent. Drawing from national and local sources, we vet women and under-represented minorities for every invited speaker opportunity, thereby providing valuable career currency and networking opportunities. We will also encourage women and under-represented minorities, particularly at the trainee level, to attend and participate in this conference series to spur interest in pursuing precision medicine research as a career. Overall, the North Coast Conference on Precision Medicine series is a valuable addition to the national conference landscape, and with its unique location and low cost to participants, will serve as an important educational opportunity as precision medicine research accelerates in earnest. PROJECT NARRATIVE The North Coast Conference on Precision Medicine is a yearly fall conference series in Cleveland, Ohio designed as a continuing education forum in the burgeoning area of precision medicine research. The conference brings together national experts on a host of topics ranging from bioethics to bioinformatics to biomedical informatics to speak and lead workshops on timely challenges posed in translating complex genomic and health data into clinical practice. The conference series also serves to promote diversity in the biomedical workforce. This year’s symposium will focus issues related to return of genomic results in both clinical and research settings with an emphasis on diverse populations.",Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)?,9762963,R13HG010286,"['Academic Medical Centers', 'Acceleration', 'African American', 'Area', 'Back', 'Big Data', 'Bioethics', 'Bioinformatics', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Computational Biology', 'Computer Simulation', 'Continuing Education', 'Custom', 'Data', 'Databases', 'Diagnosis', 'Dose', 'Educational workshop', 'Electronic Health Record', 'Ensure', 'Ethnic Origin', 'Family member', 'Funding', 'Future', 'Generations', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidental Findings', 'Informed Consent', 'Infrastructure', 'Institution', 'Knowledge', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mining', 'Names', 'Ohio', 'Outcome', 'PMI cohort', 'Participant', 'Pathogenicity', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Population Heterogeneity', 'Prevention', 'Process', 'Race', 'Research', 'Research Personnel', 'Resources', 'Schedule', 'Science', 'Series', 'Source', 'Surveys', 'Technology', 'Time', 'Training', 'Trans-Omics for Precision Medicine', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Minority', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'Woman', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'clinical care', 'clinical implementation', 'clinical practice', 'clinical sequencing', 'clinically relevant', 'cost', 'cost effective', 'data sharing', 'design', 'falls', 'follow-up', 'forging', 'frontier', 'genome-wide', 'genomic data', 'health data', 'health disparity', 'health information technology', 'incentive program', 'individual patient', 'interest', 'medical specialties', 'multiple omics', 'patient population', 'point of care', 'posters', 'precision medicine', 'programs', 'recruit', 'response', 'science education', 'senior faculty', 'symposium', 'trend']",NHGRI,CASE WESTERN RESERVE UNIVERSITY,R13,2019,10000,197030888,-0.028841216358092326
"Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment PROJECT SUMMARY We propose a study of radiomic texture analysis in terms of robustness assessment and classification utility. We will introduce novel robustness metrics geared towards assessment of radiomic features in comparison across two image conditions, and apply these metrics to study feature robustness across imaging parameters and patient biology. In addressing the utility of radiomic features in cancer risk assessment, we will identify and evaluate texture signatures from mammography and tomosynthesis datasets. The field of radiomics is evolving fast, and quantitative texture analysis is being applied to a growing number of applications in medical imaging. By performing a thorough investigation of the robustness of these radiomic features to dataset heterogeneities we aim to identify the strengths and weaknesses of commonly used features to guide their implementations on future applications.  Two clinical tasks will be studied under the proposed research: 1) risk assessment and cancer prediction and 2) malignancy evaluation. Multiple modalities including tomosynthesis, mammography and MRI will be involved in studies geared towards addressing these clinical questions. An evaluation of the robustness of commonly employed radiomic features will help guide the field of medical texture analysis and contribute to meaningful conclusions in future studies throughout the field of quantitative image analysis. The first aim of the proposed research involves the proposition and evaluation of novel robustness metrics for investigations lacking a classification task. The second aim will extend the study of radiomics to investigate the utility of robust features in classification tasks and identification of texture signatures relate to biomedical characteristics. The third aim will build upon the two previous aims and culminate in the application of cutting-edge technologies in machine learning and deep learning in further promoting image processing in the field of medical physics. PROJECT NARRATIVE The goal of the proposed research is to evaluate and improve the application of radiomic texture features in cancer risk assessment. We will accomplish this by evaluating the robustness of various radiomic metrics, testing the classification utility of texture features in clinical tasks, and extending current classification methods to include cutting-edge developments in machine learning technology. Careful preliminary studies have demonstrated methods for selection of robust texture features and improvement in classification tasks by emphasizing feature robustness in feature selection methodology and we therefore believe that a meticulous evaluation of the impact of imaging parameters on feature calculations will lead to overall improvement of computer-aided diagnosis and clinical translation to progress in cancer screening protocols.",Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment,9683697,F31CA228247,"['Address', 'Benign', 'Biological', 'Biology', 'Breast', 'Breast Cancer Risk Factor', 'Characteristics', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Effectiveness', 'Eligibility Determination', 'Emerging Technologies', 'Evaluation', 'Family', 'Future', 'Goals', 'Heterogeneity', 'Image', 'Image Analysis', 'Impact evaluation', 'Incidence', 'Intuition', 'Investigation', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Mammography', 'Maps', 'Mathematics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Output', 'Patients', 'Pattern', 'Performance', 'Physics', 'Protocols documentation', 'Psychological Transfer', 'Recording of previous events', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Screening for cancer', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Imaging', 'Time', 'Translations', 'Variant', 'Work', 'base', 'breast imaging', 'cancer risk', 'clinical translation', 'deep learning', 'expectation', 'high risk', 'image processing', 'image registration', 'imaging modality', 'imaging system', 'improved', 'innovation', 'molecular subtypes', 'multimodality', 'novel', 'outcome forecast', 'patient population', 'quantitative imaging', 'radiomics', 'response', 'tomosynthesis', 'tumor']",NCI,UNIVERSITY OF CHICAGO,F31,2019,24304,246330700,-0.03816229133893557
"Automated Decision Support System for Traumatic Brain Injury through Image Processing and Machine Learning Approaches Summary: There is an urgent need for an automated decision support system for diagnosis and prognosis of traumatic brain injuries (TBI). TBI is one of the leading causes of death in the modern world, and substantially contributes to disability and impairment. The early detection of TBI and its proper management presents an unfilled need. We therefore aim to supplement clinicians' decisions by developing a decision support system for monitoring and integrating available information of a TBI patient for accurate and quantitative diagnosis and prognosis. This project is the main component of a long-term goal of building a system that creates personalized treatment plans. Specifically, we intend to automatically detect and accurately quantify two critical abnormalities including shift in the brain's middle structure (Aim 1) and intracranial hemorrhage (Aim 2) from computed tomography (CT) head scans. In Aim 1, we develop a model for delineating the spatial shift in brain structure and its predictive power. We employ anatomical landmarks to detect a 3D deformed surface of the brain midline after TBI. Such an approach allows us to quantify the shifted volume, a measurement that is not currently achievable. Additionally, it provides accurate and timely access to conventional midline shift in a 2D CT slice. In Aim 2, we build a model for delineating intracranial hemorrhage and its predictive power. We implement a 3D convolutional neural network model to detect hemorrhagic regions and quantify and localize their volume. Currently, these measurements are inaccurate and not readily available due to the cumbersome manual process; instead a lesion's thickness in a 2D CT slice is used to assess its severity. In both Aim 1 and 2, we automatically calculate conventional and proposed volumetric and locational measurements and compare them to suggest the best diagnostic metric for each abnormality. Finally, in Aim 3, we build an automated pipeline for TBI severity assessment and outcome prediction. To this end, manual CT scan reads will be integrated with patient-level information available from electronic health records to achieve accurate data-driven diagnosis and prognosis. We implement machine learning approaches to build models capable of predicting short and long-term clinical outcomes. Our prediction models will be developed independently of our image processing algorithms. Upon achievement of Aims 1 and 2, automatically calculated information from CT scans will be incorporated into machine learning models. The proposed research is significant, because it is expected to advance TBI care, specifically within the “golden hour"" post-injury. Ultimately, such a system has the potential to reduce delayed and missed diagnosis, thereby reducing TBI morbidity and mortality. Additionally, by preventing permanent and/or secondary injuries, and minimizing the time of hospitalization and rehabilitation, our system will contribute to reducing the annual $76 billion burden of TBI care in the U.S. In addition to innovation in the proposed approaches and their quantitative outputs, we aggregate four existing datasets to incorporate heterogeneity in both phenotypes and therapies, so the resulted model will be generalizable and applicable to real clinical settings. Project Narrative: Traumatic brain injury, frequently referred to as a silent epidemic, involves about 1.7 million people in the U.S, among whom 50,000 will die, while 152,000 will suffer from long-term disability and impairment. The proposed research will automatically diagnose and assess the severity of critical abnormalities from computed tomography head scan, and integrate all available sources of clinical data using data science methods to make a personalized data-driven prognosis. It is expected that this technology will provide caregivers with critical information for early and proper management of injuries, thus saving lives and improving the quality of life of survivors by reducing second/permanent injuries; importantly, this system would enable people living in outlying and deprived regions lacking skilled clinicians benefit from more accurate diagnostics, and as a result, a better care.",Automated Decision Support System for Traumatic Brain Injury through Image Processing and Machine Learning Approaches,9757500,F31LM012946,"['3-Dimensional', 'Achievement', 'Admission activity', 'Algorithms', 'American', 'Anatomy', 'Area', 'Brain', 'Caregivers', 'Caring', 'Cause of Death', 'Characteristics', 'Clinical', 'Clinical Data', 'Consumption', 'Data', 'Data Science', 'Data Set', 'Decision Making', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Electronic Health Record', 'Epidemic', 'Glasgow Outcome Scale', 'Goals', 'Head', 'Hemorrhage', 'Heterogeneity', 'Hospitalization', 'Hour', 'Image', 'Impairment', 'Injury', 'Intracranial Hemorrhages', 'Investigation', 'Lead', 'Length', 'Length of Stay', 'Lesion', 'Link', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical center', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Morbidity - disease rate', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Population Heterogeneity', 'Positioning Attribute', 'Process', 'Quality of life', 'Radiology Specialty', 'Reading', 'Rehabilitation therapy', 'Research', 'Resources', 'Savings', 'Scanning', 'Severities', 'Slice', 'Software Tools', 'Source', 'Specific qualifier value', 'Structure', 'Surface', 'Survivors', 'System', 'Technology', 'Testing', 'Thick', 'Time', 'Tomography, Computed, Scanners', 'Trauma', 'Traumatic Brain Injury', 'Triage', 'Visual', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'care costs', 'convolutional neural network', 'cost', 'design', 'diagnostic accuracy', 'disability', 'functional outcomes', 'human error', 'image processing', 'improved', 'injured', 'innovation', 'learning strategy', 'machine learning algorithm', 'mortality', 'neural network algorithm', 'outcome forecast', 'outcome prediction', 'personalized medicine', 'predictive modeling', 'prevent', 'three-dimensional modeling', 'treatment planning']",NLM,UNIVERSITY OF MICHIGAN AT ANN ARBOR,F31,2019,37153,641965656,-0.01031837747095482
"Identifying Children and Teens at Risk for Early Onset Alcohol Use: An Innovative Application of Machine Learning Algorithms to Prevention PROJECT SUMMARY Early onset of alcohol use during adolescence is associated with increased probability of later alcohol dependence, polydrug abuse, victimization, conduct problems, psychiatric comorbidities, and delayed achievement of adult milestones. Methods that yield rapid, accurate, and reliable predictions of which children and teens are at risk for early onset can improve the targeting of prevention interventions and enable the concentration of resources on the most debilitating and costly cases. One promising and untapped approach to this prediction problem is machine learning (also called “statistical learning,” “data mining,” or “predictive modeling”), a class of techniques arising from statistics, computer science, and engineering that seeks to build data-driven predictive algorithms. These techniques are most noticeably distinguished from “traditional” statistical methods (e.g., ordinary least squares regression) by their extreme emphasis on prediction of future cases, rather than explanation of the current data, and thus they may offer dramatic advantages over traditional approaches to identifying which children and teens will develop early onset alcohol use. This proposal will explore the potential contribution of machine learning methods by directly comparing their predictive performance to that of the traditional approach in a large-scale, multisite longitudinal study of the development of early onset alcohol use (N = 731). If machine learning methods do significantly outperform the traditional approach, future directions might include the development and implementation of machine-learning- based screening methods for real-world use. On the other hand, if machine learning methods do not outperform the traditional approach, this will suggest that at least in the context of the present study (i.e., these predictors, timeline, and outcome), machine learning does not improve the prediction of early onset alcohol use. Analyses will investigate whether the performance of machine learning methods varies across the nature of predictor variables use, the age span covered, and the outcome to be predicted. Thus, the current proposal uses an extant longitudinal dataset to carry out two specific aims: (1) Train five different machine learning algorithms and one traditional algorithm (ordinary logistic regression) for predicting later early onset alcohol use in a subset (70%) of the data. (2) Test these six predictive algorithms on the rest (30%) of the data and directly compare their predictive performance in multiple contexts. PROJECT NARRATIVE Prospectively predicting which children and teens are at risk for early onset alcohol use enables targeted implementation of preventive interventions. Machine learning is a promising yet untapped approach that may be well-suited to this task. This study investigates the potential of several machine learning algorithms to contribute to the rapid, accurate, and reliable identification of individuals at risk for early onset alcohol use.",Identifying Children and Teens at Risk for Early Onset Alcohol Use: An Innovative Application of Machine Learning Algorithms to Prevention,9753696,F31AA026768,"['Achievement', 'Address', 'Adolescent', 'Adult', 'Advertising', 'Age', 'Alcohol abuse', 'Alcohol consumption', 'Alcohol dependence', 'Algorithms', 'American', 'Attention', 'Behavioral', 'Child', 'Childhood', 'Cocaine Dependence', 'Comorbidity', 'Data', 'Data Set', 'Dependence', 'Development', 'Engineering', 'Fraud', 'Future', 'Goals', 'Impulsivity', 'Individual', 'Lasso', 'Least-Squares Analysis', 'Logistic Regressions', 'Longitudinal Studies', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Noise', 'Outcome', 'Performance', 'Prevention', 'Preventive Intervention', 'Probability', 'Procedures', 'Public Health', 'Recommendation', 'Research', 'Resources', 'Rest', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Services', 'Statistical Methods', 'Structure', 'Substance abuse problem', 'Techniques', 'Teenagers', 'Testing', 'TimeLine', 'Training', 'Victimization', 'Work', 'addiction', 'alcohol screening', 'base', 'classification trees', 'computer science', 'conduct problem', 'cost', 'data mining', 'early alcohol use', 'early onset', 'field study', 'improved', 'innovation', 'learning strategy', 'longitudinal dataset', 'machine learning algorithm', 'multidrug abuse', 'outcome prediction', 'prediction algorithm', 'predictive modeling', 'prevent', 'prospective', 'psychologic', 'random forest', 'screening', 'search engine', 'spam', 'speech recognition', 'statistics', 'success', 'underage drinking', 'vector']",NIAAA,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,F31,2019,43749,51931732,-0.08846070337748821
"Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients Failure to rescue (FTR), a nurse-sensitive national metric of health care quality, refers to death of a hospitalized patient from a treatable complication, and is potentiated by failure to recognize and appropriately respond to early signs of complications. There is a paucity of research examining patient features predictive of FTR complications. Such information could shift the current paradigm of nursing surveillance to earlier recognition, prevention and treatment of FTR complications, thereby saving lives. New-onset venous thromboembolism (VTE), an FTR complication occurring as either a deep vein thrombosis (DVT) or a pulmonary embolism (PE), is the leading cause of preventable hospital death, carrying a high risk of mortality and a national cost burden of $7 billion annually. VTE is a complex disease process involving interactions between clinical risk factors and acquired and/or inherited susceptibilities to thrombosis. Although biomarkers and clinical factors associated with VTE have been identified, clinical manifestations are subtle, presenting gradually over hours to days. Current VTE risk assessment models (RAM), the cornerstone of prevention, have limited utility due to their complexity and lack of reliability, generalizability and external validation. A critical gap in VTE risk modeling research is that while new-onset VTE pathology evolves over the course of hospitalization, no current models incorporate the progressive accrual of dynamic patient data and pattern evolution over time in their modeling approaches. The totality of routinely collected electronic health record (EHR) data is massive in terms of volume, variety, and production at a rapid velocity in real-time. Such big data could be used in machine learning (ML) analytic approaches to process time series clinical data to identify subtle, evolving feature patterns predictive of new-onset VTE and address this gap. This study proposes to assemble a large scale, multi-source, multi-dimensional VTE study dataset, and in tandem, systematically define the EHR data elements associated with a new-onset VTE diagnosis for computable phenotype algorithm development. We will then apply machine learning analytic approaches to baseline and accruing intensive time series clinical data in the curated dataset to develop models identifying data patterns and features predictive of dynamically evolving new-onset VTE in adult hospitalized patients. This proposal aligns with NINR’s strategic vision for nurse scientists to employ new strategies for collecting and analyzing complex big data sets to permit better understanding of the biological underpinnings of health, and improve ways nurses prevent and manage illness. This innovative study and individualized training plan under a strong and well- established team, represents initial steps in the applicant’s research trajectory focused on data science approaches to predict FTR complication risk, and develop, implement and test dynamic RAMs to inform targeted prevention and treatment decisions. Discovering new knowledge informing real-time decision making, nursing surveillance practices and care delivery systems can improve nurse sensitive patient outcomes. PROJECT NARRATIVE Venous thromboembolism (VTE) is the leading cause of preventable hospital death. This study first proposes to develop a reproducible computable phenotype definition for new-onset VTE cohort ascertainment from the electronic health record, and then develop dynamic models for VTE risk assessment through the application of machine learning algorithms to massive electronic health record clinical data repositories. Such models can inform the mechanisms underlying this complex disease and identify subtle pattern changes in a patient’s condition forecasting a VTE event, enabling earlier nurse identification and intervention, and decreasing the development of complications and failure to rescue in hospitalized patients.",Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients,9794015,F31NR018102,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Big Data', 'Biological', 'Biological Markers', 'Censuses', 'Cessation of life', 'Clinical', 'Clinical Data', 'Code', 'Cohort Studies', 'Complex', 'Complication', 'Data', 'Data Element', 'Data Science', 'Data Set', 'Decision Making', 'Deep Vein Thrombosis', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Electronic Health Record', 'Event', 'Evolution', 'Failure', 'Frequencies', 'Future', 'Genetic Predisposition to Disease', 'Gold', 'Health', 'Hospitalization', 'Hospitals', 'Hour', 'Human', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Link', 'Logic', 'Machine Learning', 'Manuals', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Pathology', 'Patient Triage', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Prevention', 'Process', 'Production', 'Pulmonary Embolism', 'Quality of Care', 'Readability', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Savings', 'Scientist', 'Selection for Treatments', 'Sensitivity and Specificity', 'Series', 'Signs and Symptoms', 'Source', 'Standardization', 'System', 'Testing', 'Thromboembolism', 'Thrombosis', 'Time', 'Training', 'Treatment Failure', 'Validation', 'Venous', 'Vision', 'base', 'care delivery', 'classification algorithm', 'clinical data warehouse', 'clinical decision-making', 'clinical risk', 'cohort', 'cost', 'disease phenotype', 'health care quality', 'high risk', 'improved', 'innovation', 'interest', 'machine learning algorithm', 'mortality risk', 'multidimensional data', 'prevent']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F31,2019,45016,570146095,-0.005670731667408527
"Automatic quantification of myocardial motion in older adults Abstract  Heart failure (HF) is a common condition that represents the end stage of cardiovascular diseases (CVDs) subsequent to progressing myocardial damage or ischemia. In populations at ages 65 and older, coronary artery disease (CAD) serves as the leading cause of HF. Although low left ventricular (LV) ejection fraction (EF) is a major evidence for the diagnosis of HF in clinical practice, impaired regional myocardial dysfunction is expected to present the existence of CAD in its early stage.  Heart deformation analysis (HDA) is a cutting-edge myocardial motion analysis technique that is able to automatically track the myocardium borders on time frames and calculate global and regional cardiac functional and motional indices on existing cine images without extra scans. In the present study, we will use the HDA tool to analyze existing cine images of CHARISMA study. From 2009 to 2012, cardiac MRI exams (including coronary wall imaging and cine MRI at two-chamber, four-chamber and short-axis views) and concurrent tests for traditional cardiovascular risk factors were performed on 440 older participants (age: 65 - 84 years old at the time of MRI scans) without documented history of CVDs. During the present R03 project (2019-2021), CHARISMA participants would have been followed-up for 10 - 12 years. We plan to relate newly- acquired regional myocardial motion indices (displacement, velocity, strain and strain rate) to clinical outcomes, existing coronary wall measures and results of lab tests in CHARISMA datasets. We will test the overall hypothesis that regional myocardial motion indices have the potential to present cardiovascular risk in asymptomatic elderly. Three specific aims are: 1) Predict cardiovascular events using baseline regional myocardial motion indices; 2) Relate regional myocardial motion indices to MRI-derived features of coronary remodeling; and 3) Determine correlations between regional myocardial motion indices and traditional cardiovascular risk biomarkers/conditions collected in CHARISMA study.  No new MRI scans or lab tests are required in this project. Through a cost-effective approach, the immediate objective of the proposed project is to evaluate the clinical value of regional myocardial motion for cardiovascular risk stratification in asymptomatic older adults, a major target population of cardiovascular prevention. This study will also help us better understand the correlations between impaired myocardial function/motion and subclinical CAD burden. Furthermore, the results will facilitate the selection of quantitative imaging biomarkers and their optimal cut-off points for predicting cardiovascular events in future clinical studies. Project Narrative  In the present study, we will use heart deformation analysis (HDA) to reanalyze existing cardiac MRI data of CHARISMA study. The goal of the present study was to test the hypothesis that regional myocardial motion indices have the potential to predict cardiovascular risk in older adults.",Automatic quantification of myocardial motion in older adults,9789927,R03HL144891,"['Adopted', 'Age', 'Area', 'Artificial Intelligence', 'Biological Markers', 'Biomechanics', 'C-reactive protein', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chicago', 'Cine Magnetic Resonance Imaging', 'Clinical', 'Clinical Research', 'Comorbidity', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Echocardiography', 'Elderly', 'Event', 'Functional disorder', 'Funding', 'Future', 'Gelatinase B', 'Goals', 'Heart', 'Heart failure', 'Hypertension', 'Image', 'Impairment', 'Incidence', 'Individual', 'LDL Cholesterol Lipoproteins', 'Left', 'Left Ventricular Ejection Fraction', 'Left Ventricular Mass', 'Left ventricular structure', 'Longitudinal observational study', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Angiography', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Medicine', 'Methods', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial dysfunction', 'Myocardium', 'National Heart, Lung, and Blood Institute', 'Older Population', 'Outcome', 'Participant', 'Patients', 'Pattern', 'Peroxidases', 'Population', 'Prevention', 'Prospective Studies', 'Protocols documentation', 'Radial', 'Recording of previous events', 'Research Project Grants', 'Risk', 'Risk stratification', 'Scanning', 'Series', 'Smoking', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Ventricular', 'base', 'burden of illness', 'cardiovascular risk factor', 'clinical practice', 'coronary plaque', 'cost', 'cost effective', 'design', 'diabetic patient', 'follow-up', 'healthy aging', 'heart damage', 'human old age (65+)', 'human subject', 'imaging biomarker', 'improved', 'indexing', 'myocardial damage', 'quantitative imaging', 'tool']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R03,2019,79000,367414121,-0.023931384571718048
"Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records Project Summary/Abstract This project proposes new methods for representing data in electronic health records (EHR) to improve pre- dictive modeling and interpretation of patient outcomes. EHR data offer a promising opportunity for advancing the understanding of how clinical decisions and patient conditions interact over time to inﬂuence patient health. However, EHR data are difﬁcult to use for predictive modeling due to the various data types they contain (con- tinuous, categorical, text, etc.), their longitudinal nature, the high amount of non-random missingness for certain measurements, and other concerns. Furthermore, patient outcomes often have heterogenous causes and re- quire information to be synthesized from several clinical lab measures and patient visits. The core challenge at hand is overcoming the mismatch between data representations in the EHR and the assumptions underly- ing commonly used statistical and machine learning (ML) methods. To this end, this project proposes novel wrapper-based methods for learning informative features from EHR data. Both methods propose specialized operators to handle sequential data, time delays, and variable interactions, and have the capacity to discover underlying clinical rules/decisions that affect patient outcomes. Importantly, both methods also produce archives of possible models that represent the best trade-offs between complexity and accuracy, which assists in model interpretation. These method advances are made possible by encoding a rich set of data operations as nodes in a directed acyclic graph, and optimizing the graph structures using multi-objective optimization. The central hypothesis of this research is that multi-objective optimization can learn effective data representations from the EHR to produce accurate, explanatory models of patient outcomes. Preliminary work has shown that these methods can effectively learn low-order data representations that improve the predictive ability of several state- of-the-art ML methods. This technique demonstrates good scaling properties with high-dimensional biomedical data. Aim 1 (K99) is to develop a multi-objective feature engineering method that pairs with existing ML methods to iteratively improve their performance by constructing new features from the raw data and using feedback from the trained model to guide feature construction. In Aim 2 (K99), this method is applied to form predictive models of the risk of heart disease and heart failure using longitudinal EHR data. The resultant models will be inter- preted with the help of mentors in order to translate predictions into clinical recommendations. For Aim 3 (R00), a second method is proposed that uses a similar framework to optimize existing neural network approaches in order to simplify their structure as much as possible while maintaining accuracy. The goal of Aim 4 (R00) is to identify hospital patients who are at risk of readmission and propose point-of-care strategies to mitigate that risk. This goal is facilitated through the application of the proposed methods to patient data collected from the Hospital of the University of Pennsylvania, the Geisinger Health System, and publicly available EHR databases. Project Narrative  Understanding how clinical decisions interact with a patient's health and environmental over time to inﬂuence patient outcomes is central to the goals of enhancing health, reducing illness and improving quality of life. The proposed research provides important methodological advances for extracting these insights from widely available patient health records.",Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records,9744166,K99LM012926,"['Address', 'Affect', 'Archives', 'Area', 'Automobile Driving', 'Cardiovascular Diseases', 'Categories', 'Clinical', 'Communities', 'Complex', 'Couples', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Disease', 'Electronic Health Record', 'Engineering', 'Feedback', 'Goals', 'Graph', 'Hand', 'Health', 'Health Sciences', 'Health system', 'Heart Diseases', 'Heart failure', 'Hospitals', 'Inpatients', 'Knowledge', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical Records', 'Mentors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nature', 'Outcome', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pennsylvania', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Process', 'Property', 'Protocols documentation', 'Quality of life', 'Recommendation', 'Replacement Arthroplasty', 'Research', 'Research Personnel', 'Risk', 'Structure', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'University Hospitals', 'Visit', 'Work', 'base', 'care costs', 'cluster computing', 'data archive', 'deep learning', 'deep neural network', 'design', 'disease diagnosis', 'disorder subtype', 'health record', 'heart disease risk', 'high dimensionality', 'hospital readmission', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network', 'novel', 'open source', 'operation', 'point of care', 'predictive modeling', 'readmission rates', 'readmission risk', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,K99,2019,89260,593605914,-0.027539781301773283
"Developing Classification Criteria for the Uveitides ﻿    DESCRIPTION (provided by applicant): The uveitides are a collection of ~30 distinct diseases characterized by intraocular infection. Each disease has its own features, course, treatment, and prognosis. Traditionally, the uveitides have been grouped by the primary anatomic site of inflammation as anterior uveitis, intermediate uveitis, posterior uveitis, and panuveitis. However, there are substantial limitations to this ""lumping"" of diseases. For example, among the posterior uveitides, some (e.g. toxoplasmic retinitis and cytomegalovirus retinitis) are infectious and require treatment with antimicrobial/antiviral agents, some are chronic, presumed immune-mediated diseases that require immunosuppression (e.g. birdshot chorioretinitis, multifocal choroiditis, serpiginous choroiditis), and a few are self-limited, spontaneously-remitting diseases with a good prognosis (e.g. acute posterior multifocal placoid pigment epitheliopathy and multiple evanescent white dot syndrome). As such precise diagnosis is critical for research, including epidemiology, translational pathogenesis research, outcomes research, and disease specific clinical trials. Classification criteria are a type of ""diagnostic"" criteria used for reserch purposes. Although classification criteria seek to optimize sensitivity and specificity, when a trade-off is required, they emphasize specificity in order to ensure that a homogeneous group of patients is being studied. A precise phenotype is required particularly for genomic risk factor studies of complex disorders and translational pathogenesis research, as inclusion of other diseases with different risk factors and disease mechanisms would confound the results. Currently there are no widely-accepted and validated classification criteria for any of the uveitides. Preliminary data indicate ""fair to moderate"" agreement at best on the independent diagnosis of any one case by uveitis experts (κ's 0.27-0.40), but the ability of committees to reach agreement on the diagnosis of >98% of cases. The goal of the ""Developing Classification Criteria for the Uveitides"" project is for the Standardization of Uveitis Nomenclature (SUN) Working Group to develop classification criteria for the 25 leading uveitides using a formal, rigorous approach. There are 4 phases to the project: 1) informatics, to develop a standardized terminology; 2) case collection, to develop a preliminary database of ~250 cases of each disease; 3) case selection, to select at least 150-200 cases of each disease that are generally accepted to be the disease (using formal consensus techniques) from the preliminary database into a final database; and 4) data analysis, using machine learning approaches, of the final database to develop a parsimonious set of criteria for each disease that minimizes misclassification. The informatics and case collection phases of the Project are complete. The case selection phase is well underway and uses online voting and consensus conference calls to achieve supermajority acceptance on all cases included in the final database. The goals of this application are to complete case selection and data analysis and develop classification criteria for the 25 of the major uveitides. These results are crucial to future clinical research i the field of uveitis. PUBLIC HEALTH RELEVANCE:  Collectively, the uveitides are the 5th leading cause of blindness in the U.S., and the cost of treating them is estimated to be similar to that of treating diabetic retinopathy. Because uveitis occurs in all age groups, including children and working-age adults, there is a greater potential for years of vision lost than with age- related diseases. Clinical research in the field of uveitis has been hampered by diagnostic imprecision and a lack of widely-accepted and validated classification criteria, the development of which is the goal of this application; these criteria are needed urgently to advance epidemiology, genomic research, translational pathogenesis research, outcomes research, and disease-specific clinical trials.",Developing Classification Criteria for the Uveitides,9663961,R01EY026593,"['Acute', 'Adult', 'Affect', 'Age', 'Agreement', 'Anatomy', 'Anterior uveitis', 'Antiviral Agents', 'Blindness', 'Child', 'Choroiditis', 'Chronic', 'Classification', 'Clinical Research', 'Clinical Trials', 'Collection', 'Complex', 'Consensus', 'Cytomegalovirus Retinitis', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Enrollment', 'Ensure', 'Epidemiology', 'Future', 'Genomics', 'Goals', 'Immune', 'Immunosuppression', 'Infection', 'Inflammation', 'Informatics', 'Intermediate Uveitis', 'Machine Learning', 'Mediating', 'Nomenclature', 'Outcomes Research', 'Panuveitis', 'Pathogenesis', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Pigments', 'Posterior Uveitis', 'Publications', 'Research', 'Retinitis', 'Risk Factors', 'Sensitivity and Specificity', 'Specificity', 'Standardization', 'Syndrome', 'Techniques', 'Terminology', 'United States', 'Uveitis', 'Vision', 'Visual impairment', 'Voting', 'age group', 'age related', 'aging population', 'antimicrobial', 'birdshot chorioretinitis', 'cost', 'outcome forecast', 'public health relevance', 'symposium', 'tool', 'web page', 'working group']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2019,127308,415711940,-0.0021712629364851704
"The Effects of Insurance Benefit Design Innovation on Patient Health Abstract My research in health economics has focused on how information and targeted consumer cost-sharing influences how patients choose providers and the financial savings of incentivizing patients to choose low-price providers. I have also examined the opposite side of the market, how patient use of information and targeted consumer incentives spurs provider price competition. These topics provided the framework for my research as a PhD student in Health Economics at the University of California, Berkeley and I continue to build on these topics while a policy researcher at the RAND Corporation. A natural next step for my career is to expand this line of research but in a more in-depth manner and using more advanced statistical methods. Performing mentored research in these areas will help me successfully make the transition from directed to independent research. The proposed study will help me to (1) contribute to a deeper understanding of patient health effects of an innovative insurance benefit design that is particularly relevant for the aging population; (2) continue to build capabilities working with large medical claims data sets and develop expertise in innovative statistical methods from different disciplines; (3) gain training in aging-related health-services research; (4) expand my exposure to the aging, health economics, and health services research communities; and (5) develop my abilities as an independent health services researcher and build the foundations to successfully compete for R01-level grants.  In this project, I propose to examine whether reference pricing for colonoscopies and pharmaceuticals decreases adherence to recommended colorectal cancer screening and medication therapies among the near- elderly population. I will also examine the impact of reference pricing on patient health outcomes and the aging process. To do so, I intend to apply novel machine-learning statistical methods that have been recently developed in the computer science and statistics fields. As part of this proposal, I have built a formal training plan to develop expertise in these methods. This project will provide me with the flexibility and support to develop a long-term research agenda that focuses on using innovative statistical methods to evaluate the comprehensive effects of consumer cost- sharing programs. Although this study focuses on a single cost- sharing program, reference pricing, the skills I gain through this award will allow me to independently lead evaluations of future benefit designs. The application of machine-learning methods to the setting of reference pricing will provide a framework that I or other researchers can use to evaluate other insurance benefit designs or alternative patient populations. ! Narrative An increasingly popular insurance benefit design, reference pricing, provides targeted financial incentives for consumers to receive care at low-cost providers. While the financial savings from reference pricing programs are well-known, the health impacts have yet to be studied. The proposed career grant will apply machine learning techniques to develop a long-term research agenda focused on understanding the patient health effects of reference pricing for colonoscopies and medication therapies, which are services that are especially relevant for the aging population. !",The Effects of Insurance Benefit Design Innovation on Patient Health,9646811,K01AG061274,"['Accident and Emergency department', 'Adherence', 'Admission activity', 'Adult', 'Advisory Committees', 'Age', 'Aging', 'Area', 'Award', 'Behavior', 'Big Data', 'California', 'Caring', 'Chronic', 'Chronic Disease', 'Colonoscopy', 'Communities', 'Comorbidity', 'Cost Sharing', 'Data Set', 'Deductibles', 'Development', 'Diabetes Mellitus', 'Discipline', 'Elderly', 'Employee', 'Evaluation', 'Exposure to', 'Foundations', 'Future', 'Grant', 'Health', 'Health Benefit', 'Health Care Costs', 'Health Services', 'Health Services Research', 'Healthcare', 'Heart Diseases', 'Heart Rate', 'Heterogeneity', 'Hospitals', 'Incentives', 'Individual', 'Inpatients', 'Insurance', 'Insurance Benefits', 'Insurance Carriers', 'Internal Medicine', 'Journals', 'Lead', 'Link', 'Machine Learning', 'Medical', 'Medicine', 'Mentors', 'Methodology', 'Methods', 'New England', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Policies', 'Population', 'Preventive service', 'Price', 'Process', 'Provider', 'Publications', 'Publishing', 'Quality of life', 'Research', 'Research Methodology', 'Research Personnel', 'Retirement', 'Savings', 'Screening for cancer', 'Services', 'Side', 'Statistical Methods', 'System', 'Techniques', 'Testing', 'Training', 'Universities', 'Work', 'aging population', 'asthmatic patient', 'career', 'colorectal cancer screening', 'compliance behavior', 'computer science', 'cost', 'design', 'doctoral student', 'financial incentive', 'flexibility', 'health data', 'health economics', 'health plan', 'improved', 'innovation', 'learning strategy', 'mortality', 'novel', 'patient population', 'programs', 'response', 'semiparametric', 'skills', 'statistics', 'treatment effect']",NIA,RAND CORPORATION,K01,2019,130618,37281765,-0.013050578288146228
"Schizophrenia Comorbidities: Common Genes and Clusters The vastly reduced life expectancy in schizophrenia is primarily due to medical comorbidities, yet these are often overlooked in a research context. Numerous psychiatric and somatic diagnoses have increased rates in schizophrenia, and the majority of schizophrenia patients have comorbid conditions. Since lifestyle factors and medication side-effects likely contribute to many of these increased medical problems, it has been difficult to resolve the extent to which shared biological underpinnings contribute to comorbid conditions. The aims for this proposal will be accomplished using data from the Genomic Aggregation Project in Sweden (GAPS) with >200k genotyped subjects and comprehensive medical and demographic information from the Swedish National Registers. This wealth of information allows for additional clinical risk from schizophrenia-associated variants to be captured. In Aim 1, carriers of previously identified schizophrenia risk variants without this diagnosis will be studied for increased risk of diagnoses across multiple psychiatric and somatic domains compared to non-carriers using logistic regression. Furthermore, comorbidities may offer clues to the pathophysiological mechanisms leading to different forms of schizophrenia. With this in mind, comorbid conditions will be leveraged to define schizophrenia subtypes in Aim 2 using the >5000 cases in the Swedish Schizophrenia Study within GAPS. Following cluster analysis using comorbidities, validity will be assessed by testing for group differences in genetic and clinical variation. These studies will yield new insights into the relationships between schizophrenia and other medical conditions, and identify subtypes of schizophrenia that will facilitate personalized medical care. Comorbidities are a fundamental feature of schizophrenia and may arise due to shared biological foundations, deleterious lifestyle factors or combinations of these influences. This study explores the origins of these comorbidities by studying the extent to which genetic risk for schizophrenia in unaffected individuals impacts risk for other psychiatric or somatic diagnoses. Furthermore, in a population with schizophrenia, patterns of comorbidity will be leveraged to identify subtypes with etiological and clinical significance.",Schizophrenia Comorbidities: Common Genes and Clusters,9696906,R21MH116188,"['Address', 'Biological', 'Cardiovascular Diseases', 'Caring', 'Clinical', 'Cluster Analysis', 'Comorbidity', 'Data', 'Data Collection', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Etiology', 'Foundations', 'Gene Cluster', 'Genes', 'Genetic', 'Genetic Carriers', 'Genetic Risk', 'Genomics', 'Genotype', 'Individual', 'Knowledge', 'Life Expectancy', 'Logistic Regressions', 'Medical', 'Mental disorders', 'Mind', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Post-Traumatic Stress Disorders', 'Prevention', 'Research', 'Risk', 'Route', 'Schizophrenia', 'Sweden', 'Testing', 'Tissues', 'Variant', 'clinical care', 'clinical risk', 'clinically significant', 'cost effective', 'disorder subtype', 'genomic data', 'insight', 'lifestyle factors', 'pleiotropism', 'risk variant', 'side effect', 'societal costs']",NIMH,KAROLINSKA INSTITUTE,R21,2019,135778,1346985,-0.014676411296394373
"Obesity Prevention in Early Life (OPEL): Risk Screening and Targeted Intervention Given the difficulty of reversing obesity once present, there has been increasing focus on the primary prevention of obesity early in the lifecourse. Few attempts have been made to prevent obesity during the first years of life. This proposal summarizes a 5-year program of mentored professional development tied to a multi-method research project intended to improve the identification and potential treatment of infants and toddlers with high risk for obesity. My long-term goal is to prevent obesity by identifying infants at greatest risk and providing for them an effective, family-centered intervention that targets modifiable, life course factors. My central hypothesis, based on my prior research, is that identifying infants at risk for obesity prior to the onset of unhealthy weight gain will enable early intervention. My research plan aims to: (1) create risk prediction models for obesity at age 24 months by linking three existing data systems that combine birth certificate, contextual- level, and health outcome data; (2) test the feasibility of linking these data prospectively to validate the Aim 1 obesity risk prediction models over a 24-month period within a contemporary, clinical cohort; and (3) identify best approaches for family-focused risk communication regarding the prevention of excessive weight gain and obesity in infants and toddlers using a human-centered design approach. Through my career development plan and guidance from my mentors, I will expand upon a foundation in epidemiology and pediatric health services research to develop expertise in machine learning, health informatics, data integration, qualitative methods, human-centered design, and behavior change. Together, the research and educational aims of this proposal will provide me with the necessary groundwork to compete for additional funding as an independent investigator. Specifically, I will seek R03-level grant funding from the NIDDK in year 4 of my K01 award to test the communication strategy developed in Aim 3 and to partner with families to modify an existing behavioral change intervention for use in infancy. By the end of this award, I will be well positioned to apply for funding from the NIDDK to conduct a robust R01-level study that combines the validated prediction models, family- focused communication strategy, and modified intervention to determine whether we can effectively prevent obesity in those infants and toddlers identified as being at the highest risk. This line of research will help ensure that prevention efforts are deployed in an efficient, cost-effective manner and accepted by those who need them. I will accomplish this work under the mentorship of Dr. Aaron E. Carroll, a child health services researcher, and a multidisciplinary team of faculty with expertise machine learning, health informatics, data integration and surveillance, qualitative research, human-centered design approaches, behavior change, and childhood obesity. I am ideally suited to complete this research due to my past research productivity, current mentorship team, open access to health care data, and the established clinical decision support infrastructure at the Indiana University School of Medicine. ! Project Narrative Increasing evidence suggests that the infancy and toddler periods represent the best opportunity for obesity prevention, but few attempts have been made to prevent obesity during the first years of life. The current proposal seeks to develop practical methods to assess the risk of future obesity in infants and toddlers in the clinical setting, and to partner with families to explore new ways to communicate early life obesity risk in ways that account for their perceptions, concerns and beliefs. This proposal has the promise to lead to targeted, tailored interventions for infants most at-risk for obesity, ensuring that prevention efforts are deployed in an efficient, cost-effective manner and accepted by those who need them.",Obesity Prevention in Early Life (OPEL): Risk Screening and Targeted Intervention,9701190,K01DK114383,"['Address', 'Age', 'Age-Months', 'Award', 'Behavioral', 'Belief', 'Birth Certificates', 'Child', 'Child Health Services', 'Childhood', 'Clinical', 'Communication', 'Communities', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Support Systems', 'Development', 'Development Plans', 'Early Intervention', 'Early identification', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Faculty', 'Family', 'Foundations', 'Funding', 'Future', 'Geographic Information Systems', 'Goals', 'Grant', 'Health Services Research', 'Health Status', 'Human', 'Indiana', 'Infant', 'Information Systems', 'Infrastructure', 'Intervention', 'K-Series Research Career Programs', 'Lead', 'Life', 'Life Cycle Stages', 'Link', 'Machine Learning', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'National Institute of Child Health and Human Development', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Parents', 'Perception', 'Positioning Attribute', 'Pregnancy Histories', 'Prevention', 'Preventive Intervention', 'Primary Prevention', 'Process', 'Productivity', 'Public Health Informatics', 'Publishing', 'Qualitative Methods', 'Qualitative Research', 'Records', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Risk', 'Risk Factors', 'Source', 'Testing', 'Toddler', 'Universities', 'Weight', 'Weight Gain', 'Work', 'approach behavior', 'base', 'behavior change', 'career development', 'clinical decision support', 'cohort', 'cost effective', 'data access', 'data integration', 'data warehouse', 'design', 'epidemiologic data', 'health care availability', 'health data', 'healthy weight', 'high risk', 'improved', 'infancy', 'innovation', 'learning strategy', 'medical schools', 'multidisciplinary', 'obesity in children', 'obesity prevention', 'obesity risk', 'predictive modeling', 'prevent', 'programs', 'prospective', 'risk prediction model', 'screening', 'sociodemographics', 'tool']",NIDDK,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,K01,2019,139614,232986943,-0.009631771070182872
"Temporal Dietary and Physical Activity Patterns Related to Health Outcomes ABSTRACT Patterns (e.g. frequency, amount, etc.) of dietary intake and daily physical activity have each been independently linked with an increasing prevalence of obesity. Yet, connecting these patterns to obesity and chronic disease through the integration of time has not been previously considered. Given the strong evidence for independent linkages between each of these patterns and obesity, there is a critical need to determine the potential synergistic correlation of these patterns of behavior within the framework of a relationship with health. In the absence of such insights, opportunities for early detection of behavioral patterns that predispose obesity and chronic disease will be missed, and our long-term research goal to create these early detection strategies will not be met. The central hypothesis of this project is based on the analytical framework and methodology that was previously developed by the investigators: that daily patterns of energy intake, when integrated with physical activity, will be associated with health in a representative sample of U.S. adults 20 to 65 y (NHANES 2003-2006). The objectives in this R21 application include the development of data patterning methodology that can be used to create distinct dietary intake and physical activity patterns and then successfully integrate these patterns to identify population temporal pattern clusters. Next, the investigators will evaluate the cluster relationships with obesity and health outcomes and compare the integrated clusters to the un-integrated dietary and activity pattern clusters. The working hypotheses are firstly, that novel distance measures based on dynamic time warping for the dietary and physical activity data can be integrated to produce meaningful clustering related to health, and secondly, that a population cluster which exhibits a pattern of evenly spaced eating occasions, moderate energy consumption and moderate physical activity patterns in a 24 hour day will be associated with normal weight and without chronic disease, and that relationships with health outcomes will be stronger for the integrated temporal pattern clusters compared with un-integrated temporal dietary clusters and physical activity clusters. The rationale for this research is that its successful completion is expected to create data reduction methods that classify temporal lifestyle patterns linked to disease, further, the expectation is that these analytical techniques will integrate multidimensional temporal dietary and physical activity data. These outcomes are expected to have a significant positive impact, not only in developing/evaluating new analytic methods but in laying the groundwork for data based preventative interventions. This proposed research is potentially significant because results will provide a starting point for understanding the importance of the timing of dietary and physical activity patterns to the prevention of obesity and disease with potentially broad translational  RELEVANCE TO NIH The proposed research is relevant to public health because preventative time-based dietary and physical activity patterns will be identified among the US population, which are expected to open new research horizons for evidence-based recommendations for healthy lifestyles. The project is relevant to NIH's mission because individualized early detection of lifestyles supporting health or linked with disease may be attainable through the development of analytical techniques integrating multiple layers of data. Such strategies could be applied to utilize the increasing information from personal electronic monitoring devices and to detect patterns associated with positive and negative health outcomes.",Temporal Dietary and Physical Activity Patterns Related to Health Outcomes,9702773,R21CA224764,"['Accelerometer', 'Adult', 'Affect', 'Behavior', 'Behavioral', 'Chronic Disease', 'Consumption', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diet', 'Dietary Factors', 'Dietary Practices', 'Dietary intake', 'Digestion', 'Disease', 'Early Diagnosis', 'Eating', 'Energy Intake', 'Exhibits', 'Food', 'Frequencies', 'Genes', 'Goals', 'Health', 'Hour', 'Individual', 'Intervention', 'Life Style', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Metabolic', 'Metabolic syndrome', 'Metabolism', 'Methodology', 'Methods', 'Mission', 'Moderate Exercise', 'National Health and Nutrition Examination Survey', 'Nutrient', 'Obesity', 'Organ', 'Outcome', 'Participant', 'Pattern', 'Physical activity', 'Population', 'Prevalence', 'Preventive Intervention', 'Public Health', 'Regulation', 'Research', 'Research Design', 'Research Personnel', 'Sampling', 'Series', 'Sleep', 'Surveys', 'Techniques', 'Time', 'Tissues', 'United States National Institutes of Health', 'Weight', 'Work', 'analytical method', 'base', 'circadian', 'data reduction', 'design', 'evidence based guidelines', 'expectation', 'health data', 'healthy lifestyle', 'inferential statistics', 'innovation', 'insight', 'modifiable behavior', 'monitoring device', 'novel', 'obesity prevention', 'prevent', 'speech processing', 'unhealthy lifestyle', 'waist circumference']",NCI,PURDUE UNIVERSITY,R21,2019,156798,64946317,-0.005995624578657832
"Detecting Middle Ear Fluid Using Smartphones PROJECT SUMMARY Otitis media is one of the most common childhood diseases in developing countries; many of its complications are preventable if middle ear fluid is detected early. We propose an accessible and accurate smartphone-based screening tool that (i) sends a soft acoustic chirp into the ear canal using the smartphone speaker, (ii) detects reflected sound from the eardrum using the smartphone microphone, and (iii) employs a machine learning model to classify these reflections and predict middle ear fluid status in realtime. Given the ubiquity of smartphones and the inaccuracy of visual otoscopy, the system we propose has the potential to be the default screening tool used in developing countries by healthcare providers and caregivers at home. PROJECT NARRATIVE Otitis media is one of the most common childhood diseases in developing countries affecting over 1.23 billion people in 2013 and can lead to complications such as hearing loss, developmental delay, meningitis, mastoiditis, and death. Many of these complications are preventable if middle ear fluid is detected early. However, the absence of an accurate and accessible method to detect middle ear fluid has led to high misdiagnosis rates. The consequence is associated hearing and speech impairment rates greater than any other pediatric condition and growing microbial resistance as a result of antibiotic over-prescription. Currently, the technique of choice for detecting middle ear fluid by primary care providers is visual otoscopy, which has a diagnostic accuracy as low as 51%. Although more accurate methods like tympanometry and pneumatic otoscopy exist, they require significant expertise and referral to a specialist. Commercial acoustic reflectometers and smartphone-mounted otoscopes require specialized hardware. Thus, there is an urgent, unmet need for an accurate, rapid and easily accessible method for resource-limited healthcare providers and caregivers to detect middle ear fluid. This project aims to demonstrate the feasibility of using the speakers and microphones on existing smartphones to detect middle ear fluid by assessing eardrum mobility. Our proposed system would operate by (i) sending a soft acoustic chirp into the ear canal using the smartphone speaker, (ii) detecting reflected sound from the eardrum using the smartphone microphone, and (iii) employing a machine learning model to classify these reflections and predict middle ear fluid status. No additional attachments would be required beyond a paper funnel, which acts as a speculum to reduce waveform variability and can be constructed with printer paper, scissors, and tape. This technique is the first software-based screening tool for middle ear fluid detection that uses off-the-shelf smartphones which does not require hardware attachments or visual interpretation. Using data from our existing preliminary clinical study we aim to develop signal processing and machine learning algorithms to optimize sensitivity and specificity. We plan to develop a bench testing technique that enables previously unsupported smartphones to to run our test and prospectively validate our optimized algorithm clinically in parallel testing with an acoustic reflectometer. Further we aim to develop a user interface and improved funnel design. These new designs will undergo usability testing in physician and parent populations. Given the ubiquity of smartphones, our app has the potential to be the default screening tool used in developing countries by healthcare providers and caregivers at home.",Detecting Middle Ear Fluid Using Smartphones,9906782,R43DC018434,"['Acoustics', 'Affect', 'Agreement', 'Algorithms', 'Antibiotics', 'Caregivers', 'Cellular Phone', 'Cessation of life', 'Childhood', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Computer software', 'Data', 'Detection', 'Developing Countries', 'Development', 'Developmental Delay Disorders', 'Diagnosis', 'Disease', 'Ear', 'Earwax', 'Environment', 'External auditory canal', 'FDA approved', 'Feedback', 'Future', 'Galaxy', 'Health', 'Health Personnel', 'Hearing', 'Home environment', 'Impairment', 'Industry Standard', 'Lead', 'Liquid substance', 'Machine Learning', 'Mastoiditis', 'Measures', 'Meningitis', 'Methods', 'Modeling', 'Obstruction', 'Otitis Media', 'Otoscopes', 'Otoscopy', 'Outcome', 'Output', 'Paper', 'Parents', 'Patients', 'Performance', 'Peripheral', 'Phase', 'Physicians', 'Population', 'Preparation', 'Publishing', 'Research Personnel', 'Resistance', 'Resources', 'Running', 'Screening procedure', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Specialist', 'Specificity', 'Speculums', 'Speech', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Tympanic membrane', 'Tympanometry', 'Visual', 'base', 'care providers', 'clinical care', 'clinical practice', 'design', 'diagnostic accuracy', 'experience', 'hearing impairment', 'improved', 'machine learning algorithm', 'meetings', 'microbial', 'microphone', 'middle ear', 'prospective', 'screening', 'signal processing', 'sound', 'telehealth', 'tool', 'urgent care', 'usability']",NIDCD,"WAVELY DIAGNOSTICS, INC.",R43,2019,157842,0,-0.0071380504131825645
"Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings Project Summary (Abstract) With little change in incidence for over 50 years, pneumonia remains the top cause for morbid hospitalization1 in the USA, and is associated with healthcare costs exceeding $10 billion annually2. This study proposes to mine big data captured in an intergrated medical/dental record (iEHR) and enterprise data warehouse (EDW) of a large midwestern medical-dental integrated healthcare system and will test the hypothesis that poor oral health is an independent risk for subtypes of community-acquired and hospital-acquired pneumonia. Proposed specific aims include: 1) electronic identification and characterization of pneumonia types and 2) evaluation of the association of oral health status with risk of pneumonia. Tasks to achieve study aims are to: a) develop electronic, phenotype-based algorithm(s) to classify and characterize pneumonia by subtype and relative frequency of events; b) characterize impact of immediate and longitudinal oral health status on emergent pneumonia stratified by subtype; and c) evaluate relative risk contributed by medical and dental factors. Innovative application of natural language processing (NLP) to support evaluation of unstructured data and machine learning (ML) to identify as-yet unknown potential risk factors is proposed. These aims will be accomplished by established investigators including dentists and researchers with extensive research track records in oral and systemic health including pneumonia, clinical pulmonologist/intensivist to provide clinical expertise to inform data mining, biomedical informaticians with expertise in data mining, ML and NLP and data modeling, and experienced biostatisticians who will apply appropriate statistical approaches and traditional data modeling to big data. This team will collaboratively create and deliver a unique, well-defined, pneumonia- specific, oral health data registry resource and validated phenotype-based algorithm to classify pneumonia, stratified by subtypes, which will support future interrogation for additional permutations of medical and dental factors. Study outcomes are expected to leverage immediate translational value within the health system with high potential for relevance and portability to other settings. The project is expected to define risk factors which may represent actionable targets for reduction of pneumonia risk across various settings. Project Narrative- Relevance to public health: Pneumonia continues as a leading public health problem in hospitals, healthcare facilities and community settings. Pneumonia is the top disease-related cause for hospitalization. This study proposes to use data in electronic health records to classify pneumonia type and describe risk factors that may make individual susceptible to different types of pneumonia, including impact of diseases of the mouth, gums and teeth. The project expects to create models that can identify patients at risk for pneumonia based on information in their medical record so that those risks may be recognized and reduced.",Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings,9784789,R03DE027020,"['Address', 'Adoption', 'Adult', 'Affect', 'Age', 'Algorithms', 'Antibiotic Resistance', 'Aspiration Pneumonia', 'Big Data', 'Caring', 'Cessation of life', 'Characteristics', 'Chronic', 'Classification', 'Climate', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Comorbidity', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Dental', 'Dental Care', 'Dental Hygiene', 'Dental Records', 'Dentists', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Electronic Health Record', 'Environmental Risk Factor', 'Evaluation', 'Event', 'Frequencies', 'Future', 'General Hospitals', 'Health', 'Health Care Costs', 'Health Status', 'Health care facility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Inpatients', 'Integrated Health Care Systems', 'Intervention Studies', 'Investigation', 'Knowledge', 'Laboratories', 'Link', 'Logic', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Care Costs', 'Medical Records', 'Modeling', 'Mouth Diseases', 'Natural Language Processing', 'Nosocomial pneumonia', 'Oral', 'Oral health', 'Outcome Study', 'Outpatients', 'Pathogenesis', 'Patients', 'Periodontitis', 'Pharmaceutical Preparations', 'Phenotype', 'Pneumococcal vaccine', 'Pneumonia', 'Population Study', 'Prevalence', 'Prevention', 'Public Health', 'Pulmonology', 'Recording of previous events', 'Records', 'Recurrence', 'Relative Risks', 'Research', 'Research Institute', 'Research Personnel', 'Resolution', 'Resources', 'Respiratory Signs and Symptoms', 'Retrospective cohort', 'Risk', 'Risk Factors', 'Role', 'Scoring Method', 'Site', 'Smoking', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tooth structure', 'Translational Research', 'Update', 'Ventilator', 'Visit', 'base', 'burden of illness', 'case finding', 'clinically relevant', 'community setting', 'cost', 'data mining', 'data modeling', 'data registry', 'data warehouse', 'demographics', 'experience', 'follow-up', 'health care delivery', 'health record', 'healthcare community', 'high risk', 'innovation', 'member', 'mortality risk', 'novel', 'outreach', 'patient population', 'patient screening', 'pneumonia model', 'portability', 'secondary analysis', 'systems research', 'ventilator-associated pneumonia']",NIDCR,MARSHFIELD CLINIC RESEARCH FOUNDATION,R03,2019,159914,13396495,-0.015563383532864341
"Classifying addictions using machine learning analysis of multidimensional data ABSTRACT This Independent Scientist Award will significantly enhance my research capabilities, enabling me to become a leading quantitative investigator in the field of substance use disorders (SUDs). Specifically, it will allow me to increase my knowledge in the areas of SUD phenotypes, treatment and genetics. SUDs are clinically and etiologically heterogeneous and their classification has been difficult. This application reflects my ongoing commitment to developing an innovative and interdisciplinary research program on the classification of SUDs through quantitative analysis of multidimensional data. My extensive training in computational science and prior research on biomedical informatics have provided me with the skills to design, implement and evaluate advanced algorithms and sophisticated analyses to solve challenging problems in classifying SUDs. My ongoing NIDA-funded R01 employs a large (n=~12,000) sample aggregated from multiple genetic studies of cocaine, opioid, and alcohol dependence to develop and evaluate novel statistical models to generate clinical SUD subtypes that are optimized for gene finding. This K02 proposal extends that work to evaluate treatment outcome in refined subgroups of SUD populations using data from treatment studies for cocaine, opioid, alcohol and multiple substance dependence. This project will integrate data from diagnostic behavioral variables and genotypes, as well as biological/neurobiological features of the disorders and repeated measures of treatment outcome. The primary career development goals of this application are to: (1) understand the reliability, validity and functional mechanisms of various phenotyping methods; (2) to continue training in the genetics of addictions; and (3) to gain greater knowledge of different treatment approaches and their efficacy. A solid foundation in these areas will enhance my ability to realize the full potential of the data collected and aggregated from multiple dimensions, and to use the data to design the most clinically useful analysis and generate innovative solutions to diagnostic and predictive challenges in SUD research. Through formal coursework, directed readings, individual tutoring and intensive multidisciplinary collaboration with a diverse team of world-renowned researchers, I will receive training and collect pilot data for future R01 projects by examining (Aim I): whether clinically-defined highly heritable subtypes derived in my current R01 project predict differential treatment response; (Aim II) whether new statistical models that directly combine treatment data with behavioral, biological, and genomic data identify refined subtypes with confirmatory multilevel evidence; and (Aim III) whether there are genetic and social moderators of treatment outcome by subtype. The overall goal of this proposal is to further my independent and multidisciplinary research program in the development of statistical methods for refined classification of SUDs. The K02 award will provide me with the protected time necessary to fully engage in the training activities described that will enhance my knowledge and skills to enable me to make important, novel contributions to the genetics and treatment of SUD. PROJECT NARRATIVE This project will develop novel statistical and quantitative tools to identify homogeneous subtypes of substance use disorders (SUDs) and other complex diseases to enhance gene finding and treatment matching. The proposed project will perform secondary analyses of existing data from treatment studies of cocaine, opioid, alcohol, and mixed SUDs. The proposed novel approaches are expected to advance precision medicine approaches to SUDs by enabling treatment matching and a more refined SUD classification to gene finding.",Classifying addictions using machine learning analysis of multidimensional data,9625118,K02DA043063,"['Adherence', 'Aftercare', 'Alcohol dependence', 'Alcohols', 'Algorithms', 'Area', 'Behavioral', 'Biological', 'Biological Markers', 'Biosensor', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Cocaine', 'Cocaine Dependence', 'Collaborations', 'Combined Modality Therapy', 'Complex', 'Computational Science', 'DSM-IV', 'DSM-V', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic and Statistical Manual of Mental Disorders', 'Dimensions', 'Disease', 'Drug Use Disorder', 'Electroencephalography', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'Heterogeneity', 'Independent Scientist Award', 'Individual', 'Interdisciplinary Study', 'Investigation', 'Joints', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Neurobiology', 'Opiate Addiction', 'Opioid', 'Patients', 'Pattern', 'Pharmacogenetics', 'Pharmacotherapy', 'Phenotype', 'Population', 'Reading', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk Factors', 'Sampling', 'Scientist', 'Signs and Symptoms', 'Solid', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'Substance Addiction', 'Substance Use Disorder', 'Surveys', 'Symptoms', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Work', 'addiction', 'alcohol use disorder', 'biomarker performance', 'biomedical informatics', 'career development', 'cocaine use', 'contingency management', 'design', 'disease classification', 'disorder subtype', 'endophenotype', 'genetic association', 'genomic data', 'imaging genetics', 'improved', 'innovation', 'multidimensional data', 'neural correlate', 'novel', 'novel strategies', 'opioid use disorder', 'outcome prediction', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'secondary analysis', 'skills', 'social', 'tool', 'treatment planning', 'treatment response', 'tutoring']",NIDA,UNIVERSITY OF CONNECTICUT STORRS,K02,2019,162123,36067938,-0.03151929317783194
"Evaluation of multiple medication exposures concurrently using a novel algorithm PROJECT SUMMARY The development of large observational health databases (OHD) has expanded the data available for analysis by pharmacoepidemiology research. The efficiency of these studies may be improved by simultaneously studying the association of multiple medications with a disease of interest. Unfortunately, prior research has demonstrated that it is difficult to distinguish true-positive from false-positive results when studying multiple exposures simultaneously, thus limiting the conclusions drawn from these types of studies and representing a major gap in the field. The objective of this proposal, which is the first step in achieving the applicant's long- term goal of improving the diagnosis and treatment of gastrointestinal diseases using insights derived from OHD, is to evaluate and validate medication class enrichment analysis (MCEA), a novel set-based signal-to- noise enrichment algorithm developed by the applicant to analyze multiple exposures from OHD with high sensitivity and specificity. The central hypothesis of this proposal is that MCEA has equal sensitivity and greater specificity compared to logistic regression, the most widely used analytic method for OHD, for identifying true associations between medications and clinical outcomes. The applicant will complete the following two interrelated specific aims to test the hypothesis: Aim 1 – to calculate the sensitivity and specificity of medication class enrichment analysis (MCEA) and logistic regression (LR) for identifying medication associations with Clostridium difficile infection (CDI) and Aim 2 – to calculate the sensitivity and specificity of MCEA and LR for identifying medication associations with gastrointestinal hemorrhage (GIH). The rationale for these aims is that by reproducing known medication-disease associations without false positives, MCEA can be used to identify novel pharmacologic associations with gastrointestinal diseases in future studies. The expected outcome for the proposed research is that it will demonstrate MCEA as a valid method for pharmacoepidemiology research, opening new research opportunities for the study of multi-exposure OHD. These new research opportunities may lead to more rapid identification of potential pharmacologic causes of emerging diseases and discovery of unanticipated beneficial medication effects, allowing such medications to be repurposed for new indications. To attain the expected outcome, the applicant will complete additional coursework that builds on his Master of Science in Clinical Epidemiology to learn computational biology, machine learning, and econometrics techniques. With the support of this grant and his institution, he will also directly apply these techniques to pharmacoepidemiology applications under the close mentorship of a carefully selected team of faculty with extensive experience in gastroenterology, pharmacoepidemiology, medical informatics, and mentoring prior K-award grant recipients. Through these activities, the applicant will develop the skills necessary to obtain NIH R01-level funding and become a leader in developing novel techniques for application to the epidemiologic study of gastrointestinal diseases. PROJECT NARRATIVE Traditionally, research studying medications associated with diseases are limited to analyzing one medication at a time. This novel proposal will validate medication class enrichment analysis, a recently developed algorithm to study multiple medications simultaneously for association with a disease of interest. Validation of this method will allow researchers to use existing medical databases to more rapidly identify potential medication causes of emerging diseases and identify medications with unanticipated beneficial effects, allowing such medications to be repurposed for new indications.",Evaluation of multiple medication exposures concurrently using a novel algorithm,9645854,K08DK119475,"['Address', 'Algorithms', 'Aminoglycosides', 'Antibiotics', 'Anticoagulants', 'Antiplatelet Drugs', 'Big Data to Knowledge', 'Biological', 'Carbapenems', 'Case-Control Studies', 'Cephalosporins', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Computational Biology', 'Computer software', 'Data', 'Databases', 'Development', 'Development Plans', 'Diagnosis', 'Digestive System Disorders', 'Disease', 'Electronic Health Record', 'Epidemiologic Methods', 'Evaluation', 'Faculty', 'Fluoroquinolones', 'Funding', 'Future', 'Gastroenterology', 'Gastrointestinal Diseases', 'Gastrointestinal Hemorrhage', 'Generations', 'Genomics', 'Goals', 'Grant', 'Health', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'K-Series Research Career Programs', 'Lead', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Master of Science', 'Medical', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Noise', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Penicillins', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacology', 'Research', 'Research Design', 'Research Personnel', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Techniques', 'Testing', 'Time', 'United Kingdom', 'United States National Institutes of Health', 'Validation', 'Veterans', 'analytical method', 'base', 'beta-Lactams', 'career development', 'clinical epidemiology', 'econometrics', 'epidemiology study', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'interest', 'novel', 'research study', 'simulation', 'skills', 'usability']",NIDDK,UNIVERSITY OF PENNSYLVANIA,K08,2019,169440,593605914,-0.0014031538144971178
"Improving cancer family history collection through social networking and artificial intelligence PROJECT SUMMARY  The  activities  proposed  in  this  NCI  K07  application  are  designed  to  advance  the  career  development  and  research  independence  of  Dr.  Brandon  M.  Welch.  Family  health  history  (FHx)  is  one  of  the most important  resources available to help clinicians identify disease risks. By knowing a patient's FHx, clinicians can quickly  identify  disease risks and initiate risk-reducing strategies such as increased screening, prophylactic surgery,  risk-reducing  therapeutics,  and  lifestyle  changes.  FHx  is  also  the  foundation  of  genomic  medicine.  Unfortunately,  the  collection  and  use  of  FHx  by  patients  and  clinicians  is  suboptimal.  To  improve  the  collection and use of FHx among the general population, a better FHx tool that is easier and more convenient  to  use  than  current  FHx  tools  is  needed.  A  new  FHx  web  tool,  called  ​ItRunsInMyFamily.com,​  incorporates  artificial intelligence and social networking to improve user engagement with FHx collection.Utilizing artificial  intelligence  based  chat  entity  can  improve  the  collection  of  FHx  information  by  making  it  easier  and  more  engaging to record FHx information, likewise social networking allows users to tap into the collective wisdom  and  knowledge  of  the  family  to  correct  inaccuracies  and  overcome  gaps  in  FHx  knowledge.  This research  study  will  first  identify  enhancements  to  ​ItRunsInMyFamily.com  ​that  will  further  promote  user  engagement,  with  particular  focus  on  rural and underserved patients (Aim 1). We will then evaluate whether this new FHx  tool can improve collection of cancer FHx in comparison with current FHx tools (Aim 2). Finally, we will assess  the impact of ​ItRunsInMyFamily.com ​on the clinical settings (Aim 3). To implement the research plan, it will be  critical  to  apply,  skills  obtained  through  K  award  learning  objectives,  namely  clinical  oncology  (learning  objective  1),  iterative  patient-centered  design  (learning  objective  2),  and  health  technology  assessment  (learning  objective  3).  To  fulfill  these  learning  objectives,  an  interdisciplinary  group  of  mentors  will  direct  a  comprehensive training plan. The training plan includes coursework, seminars, workshops, journal clubs, and  conferences,  covering clinical oncology, patient engagement, health disparities, user-centered development,  human-computer  interaction,  clinical  research  methodologies,  health  technology  assessment,  and  ethical  conduct  of  research.  The  strong  support  of  an  excellent  team  of  mentors,  and  the  vast  resources  of  the  Medical  University  of  South  Carolina,  create  an  optimal  training  environment.  Collectively,  the  integrated  learning  objectives  and  research  plan  are  critical  to  establishing  a  successful,  innovative,  and  meaningful  academic career focused on developing patient-centric informatics tools for oncology.   PROJECT NARRATIVE Family health history (FHx) is one of the most important risk factors for cancer and the foundation of genomic medicine, but is under-utilized by patients and clinicians. By incorporating artificial intelligence and social networking into a FHx tool, it will lead to greater engagement with FHx collection. This research study will identify and incorporate features that promote user adoption, and evaluate its impact on FHx collection.  ",Improving cancer family history collection through social networking and artificial intelligence,9772995,K07CA211786,"['Adoption', 'Area', 'Artificial Intelligence', 'Breast Cancer Patient', 'Cancer Control', 'Cancer Family', 'Cellular Phone', 'Client satisfaction', 'Clinical', 'Clinical Oncology', 'Clinical Research', 'Collection', 'Data', 'Development', 'Educational workshop', 'Environment', 'Ethics', 'Family', 'Family Cancer History', 'Family health status', 'Foundations', 'General Population', 'Genetic screening method', 'Genomic medicine', 'Goals', 'Health Technology', 'Human', 'Internet', 'Journals', 'K-Series Research Career Programs', 'Knowledge', 'Learning', 'Life', 'Malignant Neoplasms', 'Measures', 'Medical', 'Mentors', 'Methodology', 'Minority', 'Outcome', 'Patient Care', 'Patients', 'Provider', 'Qualitative Research', 'Randomized Controlled Trials', 'Recording of previous events', 'Reporting', 'Research', 'Research Design', 'Research Methodology', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Rural Population', 'Social Network', 'South Carolina', 'Technology Assessment', 'Time', 'Training', 'Underserved Population', 'Universities', 'Workload', 'base', 'cancer care', 'cancer risk', 'career', 'career development', 'clinical care', 'computer human interaction', 'design', 'disorder risk', 'health disparity', 'improved', 'informatics\xa0tool', 'innovation', 'next generation', 'oncology', 'patient engagement', 'patient oriented', 'personalized care', 'prevent', 'prophylactic', 'research and development', 'research study', 'rural underserved', 'satisfaction', 'screening', 'skills', 'surgical risk', 'symposium', 'therapeutic lifestyle change', 'tool', 'user centered design']",NCI,MEDICAL UNIVERSITY OF SOUTH CAROLINA,K07,2019,173453,136810522,-0.0013209338302383627
"Identifying primary care patients at increased risk of atrial fibrillation for screening interventions Project Summary/Abstract Atrial Fibrillation (AF) increases the risk of stroke 5-fold and accounts for roughly 15% of all strokes in the United States. Many individuals may have undiagnosed AF whose arrhythmia does not prompt evaluation either because of minimal symptoms or brief episodes. Oral anticoagulation (OAC) is highly effective at reducing stroke risk in patients with AF, but is only prescribed to individuals with recognized disease. Identifying subjects with undiagnosed AF is important so they may be treated with OAC and prevent strokes from occurring. This project will help advance our knowledge of screening patients for undiagnosed AF in the primary care setting by identifying patients at high risk of developing AF for targeted clinic and home-based screening strategies. Fundamental questions of who to target and how to implement a screening program in the United States remain unanswered. To address these gaps in knowledge, the principal investigator (PI) proposes a career development program that blends rigorous methodologic and content area training with an innovative research agenda. This plan has three scientific objectives: 1) To identify predictors of AF incidence from electronic health record structured and free-text data, 2) To develop and implement an electronic algorithm that improves upon existing models to identify patients at increased risk for AF in a primary care population, and 3) To implement and evaluate feasibility, acceptability, appropriateness, and usability of a clinic and home-based screening program to identify undiagnosed AF. This project aligns with several objectives of the National Heart, Lung, and Blood Institute’s Strategic Vision by implementing novel diagnostic tools to diagnose AF and prevent strokes, by optimizing clinical and implementation research to improve health and reduce disease, and leveraging emerging opportunities in data science, through the use of natural language processing of text data in the electronic health record, to improve identification of patients at high risk for AF. The long-term goal of this career development award is to establish the PI as an independent researcher with expertise in cardiovascular disease and targeting populations for prevention of cardiovascular disease events. Career development activities include training in biomedical informatics, data mining and risk prediction, survey research design, implementation research, and cardiovascular disease pathophysiology and clinical management through formal coursework, clinical shadowing, as well as mentorship by an exceptionally qualified team of senior scientists. Successful completion of this career development proposal will improve prediction of which patients are at the highest risk of developing AF, and evaluate how to use this risk information to implement an effective screening strategy in primary care. Pilot data from this award will lay the groundwork for a highly competitive application for NIH R01 funding. Project Narrative Atrial fibrillation increases the risk of ischemic stroke and the prevalence is estimated to increase from 5.2 million adults in the United States to more than 12 million by 2030, however, many additional individuals have undiagnosed disease. The proposed research program will significantly advance our understanding of screening for undiagnosed atrial fibrillation, by 1) improving identification of patients at high risk of developing atrial fibrillation, and 2) targeting patients at high risk of developing atrial fibrillation in the primary care setting with an efficient strategy for clinic and home-based screening. This program will significantly increase knowledge of how to overcome the real-world issue of how to effectively and efficiently screen for atrial fibrillation in clinical practice.",Identifying primary care patients at increased risk of atrial fibrillation for screening interventions,9806592,K01HL148506,"['Address', 'Adhesives', 'Adult', 'Affect', 'Algorithms', 'Anticoagulation', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Award', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Research', 'Data', 'Data Science', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Evaluation', 'Event', 'Functional disorder', 'Funding', 'General Hospitals', 'Goals', 'Health', 'Health Technology', 'Home environment', 'Incidence', 'Individual', 'Intervention', 'Ischemic Stroke', 'K-Series Research Career Programs', 'Knowledge', 'Massachusetts', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Oral', 'Patient Care', 'Patients', 'Physicians', 'Population', 'Prevalence', 'Primary Health Care', 'Principal Investigator', 'Program Development', 'Research', 'Research Design', 'Research Personnel', 'Risk', 'Risk Factors', 'Senior Scientist', 'Stroke', 'Stroke prevention', 'Structure', 'Survey Methodology', 'Surveys', 'Symptoms', 'Target Populations', 'Techniques', 'Text', 'Training', 'United States', 'United States National Institutes of Health', 'Vision', 'Work', 'base', 'biomedical informatics', 'cardiovascular disorder prevention', 'career development', 'clinical practice', 'cohort', 'data mining', 'data registry', 'follow-up', 'high risk', 'implementation research', 'implementation science', 'improved', 'innovation', 'mHealth', 'medical specialties', 'mobile computing', 'novel', 'novel diagnostics', 'patient screening', 'population based', 'practice setting', 'primary care setting', 'programs', 'prospective', 'randomized trial', 'risk minimization', 'screening', 'screening program', 'stroke risk', 'tool', 'usability']",NHLBI,MASSACHUSETTS GENERAL HOSPITAL,K01,2019,176990,551214295,-0.06311405962845576
"Leveraging modern analytic approaches to improve diabetes outcomes ABSTRACT Diabetic patients are at risk of developing diabetic heart disease, which may lead to complications in care. Diabetic heart disease patients not only have exceptionally high healthcare expenditures and resource utilization but also are likely to have poor patient outcomes. Studies have shown that early intervention of patients likely to develop diabetic heart disease is cost-effective and yields favorable health outcomes. Therefore, early identiﬁcation of diabetic patients at high-risk of developing diabetic heart disease is crucial to provide effective interventions. The commonly accepted methodology for diabetic heart disease risk prediction is the use of one or more risk scoring systems. However, these risk functions may not generalize well for the diabetes patient and may suffer from poor calibration when used on different cohorts. Moreover, the scoring systems have only been studied on coronary heart disease, one variant of diabetic heart disease while heart failure and diabetic cardiomyopathy remain important, yet insufﬁciently studied problems. Machine learning offers the ability to perform accurate predictive analytics and has been proposed as a way to identify and manage high-risk patients. The primary goal of this proposal is to develop a high-impact and practical risk prediction model that can be used to per- form early identiﬁcation of high-risk diabetic heart disease patients. Given the heterogeneity and complexity of patient information in electronic health records, the model needs to capitalize on the multi-dimensional temporal nature of pa- tient records to extract identifying characteristics of patients that will develop diabetic heart disease. To accomplish this, we will leverage modern machine learning approaches such as tensor factorization and natural language processing to model complex patient characteristics, provide a more complete representation of the patient, and uncover excellent predictors of diabetic heart disease risk. An existing dataset that contains the de-identiﬁed electronic health records of approximately 4,100 diabetic patients from the Emory Healthcare System to compare the predictive power of machine learning-based algorithms with the standard risk scoring systems. These algorithms will be evaluated on calibration, discrimination, and ease of interpretability. The results of this work will provide insight as to how to develop a machine learning–based prediction system that can identify high-risk diabetic heart disease patients. The study may also shed light on the best approaches for fusing data from multiple heterogeneous sources to build a better predictive model and potentially identify novel indicators of high- risk diabetic heart disease factors. Moreover, the work will help inform a larger multi-site study of diabetic heart disease risk prediction and develop methods to generalize the results to a broader spectrum of comorbidities. This project is consistent with the National Library of Medicine's mission to translate biomedical research into practice. PROJECT NARRATIVE Diabetic patients are risk of developing diabetic heart disease which can lead to high healthcare expenditure, high resource utilization, and poor patient outcomes. Existing diabetic risk prediction models can suffer from poor calibration and predictive accuracy. This project develops a novel and practical analytic tool to identify patients at high-risk of developing diabetic heart disease.",Leveraging modern analytic approaches to improve diabetes outcomes,9741187,K01LM012924,"['Adopted', 'Age', 'Algorithms', 'Biomedical Research', 'Calibration', 'Caring', 'Characteristics', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Comorbidity', 'Complex', 'Complications of Diabetes Mellitus', 'Computer software', 'Congestive', 'Coronary', 'Coronary heart disease', 'Data', 'Data Set', 'Data Sources', 'Diabetes Mellitus', 'Diagnosis', 'Discrimination', 'Disease', 'Early Intervention', 'Early identification', 'Economic Burden', 'Elderly', 'Electronic Health Record', 'Epidemic', 'Evaluation', 'Future', 'Goals', 'Health', 'Health Expenditures', 'Healthcare', 'Healthcare Systems', 'Heart Diseases', 'Heart failure', 'Heterogeneity', 'Institution', 'Intervention', 'Lead', 'Light', 'Machine Learning', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Natural Language Processing', 'Nature', 'Outcome', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Predictive Analytics', 'Predictive Value', 'Prevalence', 'Prevention', 'Procedures', 'Records', 'Research Personnel', 'Resources', 'Risk', 'Site', 'Source', 'Structure', 'System', 'Translating', 'United States', 'United States National Library of Medicine', 'Variant', 'Work', 'analytical tool', 'base', 'clinical practice', 'cohort', 'computer science', 'cost effective', 'design', 'diabetic', 'diabetic cardiomyopathy', 'diabetic patient', 'effective intervention', 'electronic structure', 'epidemiologic data', 'heart disease risk', 'high risk', 'improved', 'insight', 'novel', 'open source', 'predictive modeling', 'prospective', 'prototype', 'research to practice', 'risk prediction model', 'secondary analysis']",NLM,EMORY UNIVERSITY,K01,2019,185004,507546965,-0.004209328970045529
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this ﬁeld typically produce an “all-cause” risk estimate which, even if accurate, overlooks the actionable mechanisms behind admis- sion risk and therefore fails to identify a prescribed response. This limitation may explain the only modest – at best – reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modiﬁable risks and their associated phenotypes driving hospital ad- missions; (2) using natural language processing techniques (NLP) to build classiﬁcation models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to signiﬁcantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close men- toring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a support- ive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identiﬁcation and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,9681485,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Comorbidity', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Preventive Intervention', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'randomized trial', 'response', 'risk prediction model', 'skills', 'social', 'supportive environment', 'trend', 'trial design']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2019,195076,593605914,-0.019472450344397478
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9749151,K01ES026833,"['Acute', 'Affect', 'Blood', 'Blood flow', 'Brain', 'Brain Injuries', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Healthcare', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Ruptured Aneurysm', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision support', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'public health relevance', 'standard of care', 'support tools', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2019,216241,558628098,-0.025432610564921375
"An interactive, digital platform to transform biological learning Abstract: The next generation of health care professionals will need to understand the foundational principles of biology. Science textbooks play a critical role in supporting biological understanding in school, yet these books are not designed to meet the diverse learning needs of students in today’s classrooms. By their nature, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current Life Science textbooks and to revolutionize reading with adaptable texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned inheritance (NGSS LS3A) content into Spanish (Aim 1); designing, developing, and testing the application to function through a web browser (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content to address 12 additional NGSS standards in English and Spanish (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive reading technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning needs. This Fast-Track project will produce an interactive, digital textbook to support students’ understanding of Life Science by giving them the ability to seamlessly move between different reading levels and languages and to play games that enhance their understanding of scientific language and concepts. This project will also solicit feedback from teachers and students to develop teacher support materials and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform biological learning",9778578,R44GM133245,"['Address', 'Adoption', 'Biological', 'Biological Sciences', 'Biology', 'Books', 'Brain', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Gametogenesis', 'Health Professional', 'Healthcare', 'Home environment', 'Individual', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Nature', 'Phase', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Spinal Cord', 'Students', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'Vocabulary', 'base', 'concept mapping', 'design', 'digital', 'education resources', 'egg', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'reading ability', 'resource guides', 'response', 'science teacher', 'scientific literacy', 'skills', 'sperm cell', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2019,225000,981500,-0.006531479321024144
"Novel Non-Invasive Coronary Flow Patterning to Predict Early Coronary Microvascular Disease PROJECT SUMMARY  Coronary microvascular disease (CMD) is notoriously difficult to diagnose non-invasively, and current methods of assessing CMD utilize only the peak velocity of the coronary flow pattern. While new imaging techniques such as cardiac magnetic resonance imaging (MRI) have improved the assessment coronary perfusion, there are currently no non-invasive methods that incorporate the coronary flow pattern over a complete cardiac cycle to definitively assess and predict the development of CMD.  Coronary blood flow (CBF) reflects the summation of flow in the coronary microcirculation, and our lab has begun to harness the full CBF pattern under varying flow and disease conditions (e.g. type 2 diabetes) to determine whether it might harbor novel clues leading to the early detection of CMD. Our past and preliminary data indicate an early onset of CMD in both type 2 diabetes mellitus (T2DM) and metabolic syndrome (MetS) that occurs prior to the onset of macrovascular complications and that are characterized by blood flow impairments and alterations in coronary resistance microvessel (CRM) structure, function, and biomechanics. Our data also uncovered innovative correlations between CRM structure/biomechanics and our newly-defined features of the coronary flow pattern, some of which were unique to normal or diabetic mice. We have initially utilized these CBF features, in the presence and absence of other factors such as cardiac function, to develop a mathematical model in collaboration with Drs. Christopher Bartlett and William Ray that to date demonstrated that 6 simple factors can predict a normal vs. diabetic coronary flow pattern with 85% predictive accuracy. Utilizing a multidisciplinary approach, these preliminary data strongly suggest that the coronary flow pattern and physiological modulators of it (e.g. coronary micovascular structure/function/biomechanics, cardiac function, etc), may be useful in directly diagnosing early CMD. Therefore, we hypothesize that dissecting the elements that influence coronary flow patterning will be critical determinants in the direct assessment of coronary microvascular disease using computational modeling. Using our previous publications and our preliminary data as guides, the hypothesis will be tested by addressing two specific aims: 1) Determine whether unique time-dependent CBF patterning in normal and T2DM is dictated by a combination of CRM remodeling and biomechanics, coronary flow pattern dynamics, and cardiac function, permitting the development of a computational model to accurately predict CMD; 2) Determine the reproducibility and robustness of the machine learning model in predicting CMD in a diet-induced obesity/diabetes mouse model. If successful, these studies will be the first to simultaneously examine the influence of CRMs, CBF, and cardiac structure/function on the distinct pattern of coronary flow, and it will determine whether a mathematical model may be useful in establishing a direct assessment of CMD to eventually enable clinicians to conduct a more direct non-invasive diagnosis of CMD for the prevention and/or treatment of heart disease. PROJECT NARRATIVE Coronary Artery Disease (CAD) is the leading cause of heart disease and is associated with hypertension, diabetes, and metabolic syndrome. Coronary Microvascular Disease (CMD) is comprised of structural and functional deficits of the tiny coronary arteries that may be an earlier indicator of disease prior to the onset of overt CAD. The proposed multidisciplinary research aims to develop a computational artificial intelligence model that will accurately predict CMD based on a non-invasive coronary flow pattern obtained by Doppler echocardiography.",Novel Non-Invasive Coronary Flow Patterning to Predict Early Coronary Microvascular Disease,9769734,R21EB026518,"['Address', 'Age', 'Artificial Intelligence', 'Biomechanics', 'Blood flow', 'Cardiac', 'Collaborations', 'Computer Simulation', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Development', 'Diabetes Mellitus', 'Diabetic mouse', 'Diet', 'Disease', 'Doppler Echocardiography', 'Early Diagnosis', 'Echocardiography', 'Elements', 'Heart Diseases', 'Hyperemia', 'Hypertension', 'Imaging Techniques', 'Impairment', 'Interdisciplinary Study', 'Laboratories', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Metabolic syndrome', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Pattern', 'Physiological', 'Publications', 'Reproducibility', 'Resistance', 'Structure', 'Testing', 'Time', 'base', 'coronary perfusion', 'db/db mouse', 'diabetic', 'disorder prevention', 'early onset', 'experimental study', 'heart function', 'improved', 'innovation', 'interdisciplinary approach', 'macrovascular disease', 'mathematical model', 'noninvasive diagnosis', 'novel', 'pressure', 'prevent']",NIBIB,RESEARCH INST NATIONWIDE CHILDREN'S HOSP,R21,2019,228000,43994644,-0.008426095312759714
"Development of a tracheal sound sensor for early detection of hypoventilation due to opioid overdose. Abstract More than 64,000 Americans died from drug overdose in 2016 and drug overdose is now the most common cause of death for people under 50 years old in the United States. Furthermore, the number of overdose deaths is increasing with the rise of abuse of powerful synthetic opioids, such as fentanyl. In May of 2017 National Institutes of Health (NIH) and National Institute on Drug Abuse (NIDA) directors Drs. Collins and Volkow outlined how research may help reduce the death toll associated with the current opioid epidemic; one of the current critical needs is the development of new overdose-reversal interventions, including wearable technologies that can detect an (impending) overdose from physiological signals to signal for help, or trigger a coupled automated injection of naloxone. Automated detection of overdose is essential because most opioid overdoses occur when individuals are alone and unobserved by family members or first responders. Opioids cause respiration to slow and become irregular due to mu-opioid receptor mediated suppression of respiratory related regions of the brainstem and spinal cord. Importantly, there are characteristic early changes in breathing pattern that indicate a progression towards significant hypoventilation, but there is currently no easy-to –use method or device to measure these patterns non-invasively. Recently, there has been a renewed interest in respiratory monitoring using tracheal sounds. Tracheal sounds originate from the vibrations of the tracheal wall and surrounding soft tissues caused by gas pressure fluctuations in the trachea. These sounds can be collected from a microphone placed over the trachea and analyzed to determine the real-time respiratory rate and an estimate of respiratory flow and tidal volume. We hypothesize that individual trends in tracheal sounds detected by a machine- learning algorithm will provide an early warning sign of the onset of hypoventilation as a result of opioid overdose in humans. The aims of this proposal are to develop a machine learning algorithm that detects impending hypoventilation due to an opioid overdose and to develop an initial design for a miniature wireless tracheal sound sensor. Project Narrative RTM Vital Signs, LLC is developing a non-invasive Tracheal Sound Sensor for early detection of impending hypoventilation due to an opioid overdose. The sensor will continuously monitor an individual’s respiratory pattern to detect a significant change from baseline, in which case it will contact a caregiver and/or emergency personnel detailing the location and status of the person experiencing an opioid overdose or initiate a coupled naloxone injection. This technology has the potential to prevent a significant number of deaths as a result of opioid overdose by allowing for the timely detection of hypoventilation and administration of naloxone.",Development of a tracheal sound sensor for early detection of hypoventilation due to opioid overdose.,9680488,R41DA047779,"['Abdomen', 'Accelerometer', 'Adult', 'Algorithms', 'American', 'Body Patterning', 'Brain Stem', 'Breathing', 'Caliber', 'Caregivers', 'Cause of Death', 'Cellular Phone', 'Cessation of life', 'Characteristics', 'Clinical', 'Coupled', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Emergency Medical Technicians', 'Engineering', 'Environmental air flow', 'Family member', 'Fentanyl', 'Future', 'Gases', 'Goals', 'Head', 'Human', 'Hypercapnic respiratory failure', 'Hypoxemia', 'Individual', 'Infusion procedures', 'Injections', 'Intervention', 'Location', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Monitor', 'Movement', 'Naloxone', 'National Institute of Drug Abuse', 'Noise', 'Opioid', 'Outpatients', 'Overdose', 'Patients', 'Pattern', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Protocols documentation', 'Research', 'Respiration', 'Risk', 'Sedation procedure', 'Signal Transduction', 'Skin', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Snoring', 'Sorbus', 'Spinal Cord', 'Study Subject', 'Subcutaneous Tissue', 'Substance abuse problem', 'System', 'Technology', 'Telemetry', 'Thick', 'Tidal Volume', 'Time', 'Tooth structure', 'Trachea', 'United States', 'United States National Institutes of Health', 'Universities', 'Validation', 'Vendor', 'Wireless Technology', 'Work', 'airway obstruction', 'alertness', 'base', 'body position', 'clinical predictors', 'clinically significant', 'design', 'emergency service responder', 'engineering design', 'experience', 'experimental study', 'first responder', 'high risk', 'indexing', 'interest', 'learning strategy', 'machine learning algorithm', 'microphone', 'mu opioid receptors', 'notch protein', 'opioid abuse', 'opioid epidemic', 'opioid overdose', 'overdose death', 'phase 2 study', 'prediction algorithm', 'pressure', 'prevent', 'programs', 'respiratory', 'sensor', 'signal processing', 'smartphone Application', 'soft tissue', 'sound', 'synthetic opioid', 'time use', 'trend', 'vibration', 'volunteer', 'wearable technology']",NIDA,"RTM VITAL SIGNS, LLC",R41,2019,236381,0,-0.01079479609052206
"Improving Critical Congenital Heart Disease Screening and Detection of ""Secondary"" Targets PROJECT SUMMARY/ABSTRACT  We propose to develop an automated critical congenital heart disease (CCHD) screening algorithm using machine learning techniques to combine non-invasive measurements of perfusion and oxygenation. Oxygen saturation (SpO2)-based screening is the current standard for CCHD screening, however it fails to detect up to 50% of asymptomatic newborns with CCHD or nearly 900 newborns in the United States annually. The majority of newborns missed by SpO2 screening have defects with aortic obstruction, such as coarctation of the aorta (CoA), that do not result in deoxygenated blood entering circulation. Non-invasive measurements of perfusion such as perfusion index (PIx) and pulse oximetry waveform analysis is expected to improve the detection of newborns with defects such as CoA, which is currently the most commonly missed CCHD by SpO2 screening. Both PIx and pulse oximetry waveforms can be measured non-invasively and with the same equipment used for SpO2 screening.  Members of our team recently showed that the addition of PIx, a non-invasive measurement of pulsatile blood flow, has the potential to improve CCHD detection otherwise missed by SpO2 screening. However, variability of PIx over brief time periods (seconds) and human error in its interpretation limit its clinical capabilities. Additionally, human error in interpretation of the current SpO2 screening algorithm leads to missed diagnoses and inappropriate testing in healthy newborns. Therefore, an automated SpO2-PIx screening algorithm is needed to both simplify the screening process, and improve detection of defects that are missed with SpO2 screening. In order to achieve that, we will identify the optimal PIx waveforms to create a metric that discriminates between newborns with and without CCHD. We will perform pulse oximetry waveform analysis to identify other non-invasive components with discriminatory capacity for newborns with CCHD. Additionally, we will apply supervised machine learning techniques to automate the algorithm interpretation.  The proposed research is significant because an automated SpO2-PIx screening algorithm could save the lives of hundreds of newborns with CCHD that are not diagnosed by SpO2 screening. Additionally, this is innovative as it will be the first automatic interpretation of PIx measurement among newborns with CCHD and merging of automated PIx and SpO2, which will allow for easy implementation at later steps. Through collaboration with four pediatric cardiac centers, we will establish the infrastructure and necessary multidisciplinary relationships to conduct future multicenter studies to evaluate this novel combined SpO2-PIx algorithm on a large scale involving thousands of newborns. Improving the detection of CCHD will require a multidisciplinary approach among all the individuals involved in the care and screening of newborns with CCHD. Additionally, collaboration with engineering and computer sciences will be necessary to automate the SpO2-PIx CCHD screening algorithm. PROJECT NARRATIVE A screening approach that improves earlier detection of critical congenital heart defects with systemic obstruction is critically necessary. This application seeks to develop a screening algorithm that will combine the current screening standard, oxygen saturation, with non-invasive measurements of perfusion. This high risk, high reward approach is fundamentally different from other approaches as it will use machine learning techniques, and is expected to improve the detection of critical congenital heart defects with systemic obstruction and automate the interpretation of the screening results.","Improving Critical Congenital Heart Disease Screening and Detection of ""Secondary"" Targets",9805011,R21HD099239,"['Affect', 'Algorithms', 'American Heart Association', 'Aortic coarctation', 'Automatic Data Processing', 'Blood', 'Blood Circulation', 'Blood Pressure', 'Blood flow', 'California', 'Cardiac', 'Caring', 'Cessation of life', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Congenital Abnormality', 'Critical Congenital Heart Defects', 'Critical Illness', 'Data', 'Defect', 'Detection', 'Diagnosis', 'Early Diagnosis', 'Engineering', 'Equipment', 'Evaluation', 'Funding', 'Future', 'Goals', 'Individual', 'Infant', 'Infrastructure', 'Interruption', 'Intervention', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Morbidity - disease rate', 'Multicenter Studies', 'National Heart, Lung, and Blood Institute', 'National Institute of Child Health and Human Development', 'Neonatal Screening', 'New York', 'Newborn Infant', 'Obstruction', 'Oxygen', 'Perfusion', 'Physiologic pulse', 'Population', 'Process', 'Pulsatile Flow', 'Pulse Oximetry', 'Research', 'Savings', 'Screening Result', 'Screening procedure', 'Sensitivity and Specificity', 'Specificity', 'Techniques', 'Testing', 'Time', 'Ultrasonography', 'United States', 'Upper Extremity', 'Validation', 'aortic arch', 'base', 'clinical application', 'cohort', 'computer science', 'congenital heart disorder', 'high reward', 'high risk', 'human error', 'improved', 'indexing', 'infant death', 'innovation', 'interdisciplinary approach', 'member', 'mortality', 'multidisciplinary', 'neonatal period', 'novel', 'prenatal', 'prevent', 'screening', 'supervised learning']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2019,240804,254622553,-0.044914813728500175
"QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring Modern health monitoring devices at hospitals and wearable sensors in households generate a large amount of time series data at high rate, capturing the physiological status of patients in a real-lime fashion. The premise is that these technology advances enable a data-driven healthcare system that starts making fast, accurate, objective and inexpensive decisions based upon data, in addition to an individual physician's experience and preference. However, there is a significant gap in the mathematical theory and computational tools to promptly extract actionable information from multi-modal non-stationary time series data in a robust and tractable manner, which has become a serious roadblock to further utilize bigger data for better healthcare monitoring. The goal of this research program is to develop a mathematical framework for extracting time-frequency and geometric representations of multi-modal physiological data, in an online and robust manner, and use them to design machine learning algorithms to improve real-lime health monitoring. Specifically, we hypothesize that the development of time-series and geometric methods for large streaming multi-modal monitoring data will lead to more accurate diagnosis on various physiological monitoring applications, including detection and prediction of rare events such as seizure and arrhythmia, classification of sleep stages for newborns and children, and real-time artifact removal of physiological data. To achieve our goal, we plan to develop novel theoretical and computational tools for analyzing non-stationary multi-modal time series data with noise, corruption and missing data as well as real-time algorithms for filtering and event detection from such data. The tools and algorithms will be applied on clinical tasks at the Nationwide Children's Hospital. In addition, the real-time workflow will be implemented on Hadoop clusters with a mission of public sharing of both data and software. The development from the interdisciplinary team composed of mathematicians, biomedical informaticians as well as the hospital will not only transform the frontiers of mathematics knowledge, but also significantly impact clinical applications, data science education, and the development of the $11 O billion emerging market of wireless health. The goal of this project is to develop a series of novel computational theory and software to extract physiological information from the large multi-modal data streams generated by modern health monitoring devices. The tools will be applied to various clinical tasks such as detection and prediction of seizure and arrhythmia and classification of sleep stages for newborns and children, aiming for more accurate diagnosis.",QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring,9771321,R01EB025018,"['Address', 'Algorithms', 'Arrhythmia', 'Behavior', 'Big Data', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Science', 'Detection', 'Development', 'Diagnostic', 'Education', 'Environment', 'Event', 'Excision', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Household', 'Human body', 'Individual', 'Infant', 'Knowledge', 'Limes', 'Machine Learning', 'Mathematics', 'Measures', 'Methods', 'Mission', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Nature', 'Newborn Infant', 'Noise', 'Outcome', 'Patients', 'Pattern', 'Pediatric Hospitals', 'Physicians', 'Physiologic Monitoring', 'Physiological', 'Property', 'Public Domains', 'Research', 'Resources', 'Seizures', 'Series', 'Sleep Stages', 'Stream', 'Techniques', 'Technology', 'Time', 'Universities', 'Validation', 'Wireless Technology', 'accurate diagnosis', 'base', 'biological systems', 'clinical application', 'clinical practice', 'computerized tools', 'design', 'diagnostic biomarker', 'education resources', 'experience', 'frontier', 'geometric methodologies', 'graduate student', 'heart rate variability', 'improved', 'insight', 'machine learning algorithm', 'mathematical theory', 'monitoring device', 'multimodal data', 'multimodality', 'novel', 'preference', 'programs', 'science education', 'signal processing', 'student training', 'theories', 'tool', 'wearable device']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2019,255543,30434536,0.0008688490232350958
"Cerebral Palsy Risk Identification System PROJECT SUMMARY AND ABSTRACT [ Pediatric specialists are often required to identify infants who are likely to suffer poor neurodevelopmental outcome, including Cerebral Palsy (CP). CP is the most common developmental disability among children in the United States and results from several factors, including low weight for gestational age, premature birth, and stroke. Although MRI and cranial ultrasound (cUS) provide valuable structural information in the preterm period, they have moderate sensitivity to CP and require transportation of the infant. Over the past 20 years, numerous studies have validated the clinical potential of General Movement Assessment (GMA) for CP risk identification. During the early period, (23 weeks to 36 weeks gestational age), the presence of Cramped Synchronized General Movements (CSGMs), has demonstrated very high sensitivity and specificity for CP, conjointly ranging from 80%-98%. CSGMs are assessed while preterm infants are still in an acute care facility (NICU) and can inform the clinician independently, and in combination with cUS and MRI. Despite its potential, GMA is available in only a few clinical centers, as adoption and routine application depend on lengthy, cost-intensive observation and availability of specially trained raters. A Cerebral Palsy Risk Identification System (CPRIS) is proposed that will automate GMA for bedside evaluations in both preterm and postterm periods. The CPRIS constitutes a key enabling technology not only for routine risk identification, but also for establishing disease trajectory and potentially differentiating CP subtypes and assessing efficacy of emerging treatments along the early developmental continuum.  Preliminary studies at UC Irvine have demonstrated that GMA analysis for CSGMs can be automated by quantifying infant limb movement using highly miniaturized, 3-axis wireless accelerometers and classifying CSGMs using a patented Markov-type approach that merges an application-specific Erlang-Cox state transition model with a Dynamic Bayesian Network (“EC-DBN”), treating instantaneous machine learning classification values as observations and explicitly modeling CSGM (and non-CSGM) duration and interval. In Phase I, this approach will be utilized in a comparative evaluation of two movement measurement modalities to determine which has the best overall performance and clinical utility at three leading NICU centers. Infant movement data will be concurrently acquired using an advanced, second generation prototype wireless accelerometer system (CPRIS-A) and a high definition 3D (infrared) optical camera (CPRIS-O). The optical modality offers significant potential advantages as it requires no infant contact and can monitor unattended, intermittently, over weeks or months. However, its potential for GMA automation must be systematically evaluated. Classifier results from both modalities will be compared to expert rater consensus in 80 preterm infants. The primary outcome will be CSGM identification accuracy, as determined by ROC-AUC analyses, with a threshold for success of 0.85. Additional comparative performance measures include reliability and practicability in the NICU environment. An Advisory Committee of experts in the fields of neonatology, pediatrics and cerebral palsy will evaluate project results and advise on the clinical potential of each modality. ] PROJECT NARRATIVE Cerebral palsy is the most common physical disability in childhood, with a prevalence of 2.1 cases per 1000 in high-income countries. The overall project goal is to develop a computerized hardware-software system capable of identifying preterm infants at high risk of developing cerebral palsy (CP), based on the systematic identification of specific patterns of movement-derived features. The Cerebral Palsy Risk Identification System (CPRIS) will enable clinical staff with only minimal training to cost effectively implement General Movement Assessment (GMA) for Cramped Synchronous General Movements (CSGMs), with interpretive reporting performed automatically. The CPRIS constitutes a key enabling technology for advancement in the identification, characterization and treatment assessment of CP.",Cerebral Palsy Risk Identification System,9769890,R43NS098840,"['3-Dimensional', 'Accelerometer', 'Acute', 'Adoption', 'Advisory Committees', 'Algorithms', 'Architecture', 'Area', 'Automation', 'Bayesian Network', 'Biological Markers', 'Birth', 'Brain', 'Budgets', 'Cephalic', 'Cerebral Palsy', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical assessments', 'Collaborations', 'Consensus', 'Country', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Development', 'Developmental Disabilities', 'Diagnosis', 'Diagnostic', 'Disease', 'Drops', 'Electronic Health Record', 'Enrollment', 'Environment', 'Equipment', 'Evaluation', 'Frequencies', 'Generations', 'Gestational Age', 'Goals', 'Health care facility', 'Healthcare Systems', 'Incidence', 'Income', 'Infant', 'Legal patent', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motor', 'Movement', 'Multicenter Trials', 'Muscle Cramp', 'National Institute of Child Health and Human Development', 'National Institute of Neurological Disorders and Stroke', 'Neonatology', 'Optics', 'Outcome', 'Patients', 'Pattern', 'Pediatrics', 'Performance', 'Phase', 'Physically Handicapped', 'Premature Birth', 'Premature Infant', 'Prevalence', 'Production', 'Progress Reports', 'Provider', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Specialist', 'Strategic Planning', 'Stroke', 'Structure', 'System', 'Technology', 'Time', 'Training', 'Transportation', 'Ultrasonography', 'United States', 'Validation', 'Video Recording', 'Weight', 'Wireless Technology', 'base', 'clinical practice', 'comparative', 'computerized', 'computerized data processing', 'cost', 'critical period', 'data modeling', 'data sharing', 'digital', 'experience', 'field study', 'follow-up', 'heuristics', 'high risk', 'improved', 'indexing', 'limb movement', 'miniaturize', 'new technology', 'off-patent', 'perinatal brain', 'postnatal period', 'primary outcome', 'prospective', 'prototype', 'software systems', 'success', 'tool', 'wireless communication']",NINDS,"NEUROCOMP SYSTEMS, INC.",R43,2019,261076,0,-0.015963115153834362
"Identifying Protective and Risk Factors for Non-infectious Uveitis Project Summary/Abstract Background Information and Relevance: Uveitis is an important cause of permanent vision loss that affects younger patients. Despite the human and economic impact of this disease, the risk factors for non-infectious uveitis are poorly understood. This is in part because epidemiologic studies of uveitis have been limited by insufficient numbers of participants. Newly available large health care claims databases provide an opportunity to increase the ability to detect uveitis risk factors. Hypotheses: Metformin, statin, angiotensin converting enzyme inhibitors are associated with a lower incidence of non-infectious uveitis, while female hormonal therapies are associated with a higher incidence of non-infectious uveitis. Specific Objectives: 1. To determine if non-infectious uveitis incidence varies in relation to putative protective medications, including metformin, statins and angiotensin converting enzyme inhibitors. 2. To determine if non-infectious uveitis incidence varies in relation the modifiable risk factor of female hormonal therapy, including hormonal replacement therapy and hormonal contraceptive therapy. Methods: The Clinformatics™ Data Mart Database contains medical claims on over 60 million beneficiaries from a large insurer in the United States. We will define non-infectious uveitis based on validated diagnosis codes recorded by an eye care provider twice within a 120-day period and exclusion of infectious or surgical causes of uveitis with diagnosis and procedural codes. Potential confounders including demographic (age, gender, race/ethnicity, education level, financial net worth) and clinical (smoking exposure) covariate information will be extracted from the database. Medication exposure will be rigorously captured based on the filling of outpatient prescriptions or coding of clinic-administered therapies. The cohort not exposed to the medication will be matched on age (±3 years), race/ethnicity, sex and date of plan entry and exit (±3 months) to the medication-exposed cohort. Propensity scores for each medication exposure will be estimated using multivariable logistic regression and the rich information on comorbid conditions and treatments available in the database. With multivariable Cox proportional hazards regression, we will calculate the hazard ratios for incident non-infectious uveitis based on exposure to each of the medications listed above. To account for the possibility of systematic differences between individuals with and without the exposures of interest, the Cox proportional hazards models will be weighted by the inverse of the predicted probability of their observed exposures using the propensity scores. We will interpret the results taking into the account the multiple comparisons being tested. Implications: The well-powered, rigorous analyses proposed here offer a unique opportunity to identify novel modifiable protective and risk factors for non-infectious uveitis, guide practice patterns for discontinuation of medications that increase uveitis risk, and inform the development of clinical trials for medications for secondary uveitis prevention. Project Narrative Uveitis is an eye disease that causes blindness disproportionately in young and working-age Americans, and we do not completely understand the risk factors for developing uveitis. Our study aims to uncover the risk factors for uveitis, including whether some medications may play a role in uveitis risk. The insights gained could improve the treatment and prevention of uveitis recurrence.",Identifying Protective and Risk Factors for Non-infectious Uveitis,9650743,R21EY029851,"['Adrenal Cortex Hormones', 'Affect', 'Age', 'American', 'Angiotensin-Converting Enzyme Inhibitors', 'Animals', 'Benefits and Risks', 'Blindness', 'Caring', 'Characteristics', 'Chronic', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Cohort Studies', 'Comorbidity', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease remission', 'Drug usage', 'Educational Background', 'Enrollment', 'Ethnic Origin', 'Exclusion', 'Exposure to', 'Eye', 'Eye diseases', 'Female', 'Gender', 'Health', 'Healthcare', 'Hormonal', 'Human', 'Immune', 'Immunosuppression', 'Incidence', 'Individual', 'Inflammation', 'Inflammatory', 'Insurance Carriers', 'Investigation', 'Logistic Regressions', 'Measurement', 'Mediating', 'Medical', 'Metformin', 'Methods', 'Modification', 'Nature', 'Office Visits', 'Operative Surgical Procedures', 'Outpatients', 'Panuveitis', 'Participant', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Play', 'Population Study', 'Prevention', 'Prevention strategy', 'Privatization', 'Probability', 'Procedures', 'Race', 'Recurrence', 'Relapse', 'Replacement Therapy', 'Research', 'Risk', 'Risk Factors', 'Role', 'Secondary Prevention', 'Smoking', 'Societies', 'Source', 'Testing', 'Time', 'United Kingdom', 'United States', 'Uveitis', 'Weight', 'age related', 'base', 'beneficiary', 'care providers', 'clinical development', 'cohort', 'cost', 'cost effective', 'disorder risk', 'economic impact', 'epidemiology study', 'hazard', 'high risk population', 'hormonal contraception', 'hormone therapy', 'improved', 'insight', 'interest', 'modifiable risk', 'novel', 'patient population', 'prevent', 'prevention clinical trial', 'protective factors', 'sex']",NEI,MASSACHUSETTS EYE AND EAR INFIRMARY,R21,2019,263573,32639530,-0.013052316396362408
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9688116,R01AR068456,"['3-Dimensional', 'Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Bone structure', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Screening procedure', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cortical bone', 'cost', 'density', 'experience', 'fracture risk', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'population based', 'public health relevance', 'response', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'treatment response']",NIAMS,UNIVERSITY OF COLORADO DENVER,R01,2019,275934,292134808,0.003524713545440312
"Real-Time Virtual Assessment of MitraClip Placement ABSTRACT Mitral regurgitation (MR) is the most common type of valvular heart disease in patients over the age of 75 years in the US. Despite the prevalence of MR in the elderly population, however, almost half of patients identified with moderate- severe MR are turned down for traditional open-heart surgery due to co-morbidities. MitraClip (MC) is a recent percutaneous approach to treat MR by placement of MC in the center of the mitral valve (MV) to reduce MR. Despite the positive short-term outcomes of the MC procedure in reducing MR, the long-term outcome can be further improved if the effects of MC on both the fluid and solid mechanics of the MV and left ventricle (LV) were available at the time the clip is placed. Recently, we developed a physics-based human cardiac function simulator for the optimal design of a novel annuloplasty ring with a sub-MV element for correction of MR, as well as physics-based simulations of MC placement. The problem with these simulations, as far as clinical applications is concerned, is they are extremely time consuming (3 days to complete simulations on 96-processor cluster). One way to make these time consuming simulations clinically applicable is to run them in advance for a wide range of patient characteristics (e.g., degree of MR, size and shape of the MV and LV, etc.) and MC placements. Currently, when clinicians are ready to place the MC on the MV, they have at their fingertips real-time data on degree of MR, and size and shape of the MV and LV measured using 3D transesophageal echocardiography (RT3D-TEE). We propose the development and validation of a searchable virtual patient atlas (SVPA) that will provide the clinician with detailed predictions of patient outcomes in real time that are based on MC placement and the RT3D-TEE patient-specific data. The first 50 models in our SVPA will be created from existing RT3D-TEE datasets provided by National Heart Centre Singapore, NHCS. Then, we will use our novel-shape dictionary learning models to automatically generate 150 additional models for our SVPA. Machine learning models will be trained with the simulation data in order to create machine learning-FE (ML-FE) surrogates that can predict FE outputs directly from the model geometry. This would enable real-time prediction of patient-specific MC device outcomes. Our preliminary studies using 3D heart simulations clearly show that the main advantage with the ML model over the 3D FE model is speed (i.e., ML runs in 1 CPU second versus 3D FE model runs in 1100 CPU hours!). We will validate the outcome predictions of our SVPA using an additional 50 existing RT3D-TEE datasets with known MC patient outcomes provided by NHCS. After the outcome prediction using SVPA for each case, we will use the dataset and the measured outcome to train the original SVPA further and validate a new dataset with the original and the updated SVPA. We will select the more accurate SVPA (the original or the updated) to determine possible correlations between the primary geometrical parameters and other patient overall biometric information with the MR and optimal MC placement. NARRATIVE A leaky inlet valve of the major pumping chamber of the heart is the most common valvular heart disease in elderly patients. Recently, the US Food and Drug Administration approved a device that can be inserted into the patient’s heart using a catheter. The purpose of this Phase-I proposal is to develop and validate a software tool for predicting patient-specific outcomes in order to optimize this therapy for patients.",Real-Time Virtual Assessment of MitraClip Placement,9679208,R43HL145896,"['3-Dimensional', 'Affect', 'Age', 'Atlases', 'Biometry', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiac Surgery procedures', 'Catheters', 'Characteristics', 'Clip', 'Comorbidity', 'Computing Methodologies', 'Consumption', 'Coronary', 'Data', 'Data Set', 'Development', 'Devices', 'Diagnosis', 'Dictionary', 'Differential Equation', 'Disease', 'Echocardiography', 'Elderly', 'Elements', 'Europe', 'Failure', 'Geometry', 'Growth', 'Heart', 'Heart Abnormalities', 'Heart Diseases', 'Heart Valve Diseases', 'Heart Ventricle', 'High Prevalence', 'Hour', 'Human', 'Imaging Techniques', 'Industry', 'Laws', 'Learning', 'Left ventricular structure', 'Letters', 'Liquid substance', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mechanics', 'Medical Device', 'Medical Imaging', 'Methods', 'Mitral Valve', 'Mitral Valve Insufficiency', 'Modeling', 'Motion', 'Myocardial', 'Myocardium', 'Organ', 'Outcome', 'Outcome Measure', 'Output', 'Oxygen Consumption', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Physics', 'Population', 'Prevalence', 'Procedures', 'Pump', 'Research', 'Running', 'Shapes', 'Singapore', 'Software Tools', 'Solid', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Time', 'TimeLine', 'Tissues', 'Training', 'Transesophageal Echocardiography', 'Translating', 'United States Food and Drug Administration', 'Update', 'Validation', 'base', 'clinical application', 'clinical practice', 'design', 'frailty', 'heart function', 'human tissue', 'improved', 'interest', 'mathematical model', 'mechanical properties', 'models and simulation', 'novel', 'older patient', 'outcome prediction', 'predictive modeling', 'predictive tools', 'pressure', 'simulation', 'tool', 'treatment optimization', 'treatment strategy', 'virtual']",NHLBI,"3DT HOLDINGS, LLC",R43,2019,289679,1082093,0.0019035481600339407
"Instrumental screening for dysphagia by combining high-resolution cervical auscultation with advanced data analysis tools to identify silent dysphagia and silent aspiration ABSTRACT Dysphagia (disordered swallowing) causes nearly 150,000 annual hospitalizations and over 220,000 additional hospital days, and prolongs hospital lengths of stay by 40%. Dysphagia risk is typically identified through subjective screening methods and those identified through screening undergo gold standard imaging testing such as videofluoroscopy (VF). However, screening methods over- or underestimate risk, and completely fail to identify patients with silent dysphagia (e.g., silent aspiration) that can cause pneumonia and other adverse events. Pre-emptive detection of silent or near-silent aspiration is essential. The long term goal is to develop an instrumental dysphagia screening approach based on high-resolution cervical auscultation (HRCA) in order to early predict dysphagia-related adverse events, and initiate intervention measures to mitigate them. The overall objective here is to develop accurate, advanced data analysis approaches to translate HRCA signals to swallowing events observed in VF images. Our strong preliminary data has led us to our central hypothesis: advanced data analytics tools are suitable approaches for the analysis of HRCA in order to automate dysphagia screening. The rationale is that a reliable, robust early-warning instrumental dysphagia screening approach will reduce adverse events in patients with silent aspiration/dysphagia, shorten length of stay and improve overall clinical outcomes. Guided by strong preliminary data, we will pursue the following three specific aims: (1) develop machine learning algorithms to differentiate HRCA signals produced by swallowing physiologic events from similar, non-swallow related signals produced during swallowing; (2) translate HRCA swallowing-signal signatures to actual swallow physiologic events to detect abnormal swallowing physiology; and (3) discriminate normal from abnormal airway protection and swallow physiology via machine-learning analysis of HRCA signals with similar accuracy as VF. Under the first aim, a machine learning approach will be used to detect pharyngeal swallowing events and differentiate them from speech, cough and other non- swallow events, with 90% accuracy, when compared to a human expert’s interpretation of our VF data sets. Under the second aim, objective swallowing physiology observations from VF will be matched to swallowing events observed with HRCA in order to show that abnormal swallow physiology and airway protection will produce distinctive HRCA signal signatures that predict the same events identified with VF. Under the third aim, analytical algorithms will be used to detect signs of disordered airway protection in HRCA signal signatures with 90% accuracy when compared to a human expert’s airway protection ratings from VF images. The approach is innovative, as it will produce analysis tools that will infer about dysphagia and aspiration based on the analysis of HRCA with unprecedented accuracy, before patients are placed in harm’s way. Our work is significant, because it will translate to an early-warning HRCA screening tool that predicts dysphagia- related adverse events in asymptomatic patients reducing medical adverse events, and length of stay. The proposed research is relevant to public health because dysphagia is related to nearly 150,000 annual hospitalizations and over 220,000 additional hospital days, it increases pneumonia incidence, prolongs hospital stays by 40% for patients with many diseases, and is prevalent in acute care hospitals and nursing homes. Choking (airway obstruction) and pneumonia due to aspiration (inhalation of swallowed food and liquids), are common results of dysphagia, and both are preventable when dysphagia is identified before patients are offered oral food, liquids or medications. The proposed research is relevant to the part of NIH’s mission that pertains to enhancing health, lengthening life and reducing illnesses, as we will develop new data analytics tools to be used along with high-resolution cervical auscultation in order to instrumentally screen for dysphagia and predict dysphagia-related adverse events before they can harm patients with dysphagia.",Instrumental screening for dysphagia by combining high-resolution cervical auscultation with advanced data analysis tools to identify silent dysphagia and silent aspiration,9735365,R01HD092239,"['Acute', 'Address', 'Adult', 'Adverse event', 'Algorithmic Analysis', 'Algorithms', 'Aspirate substance', 'Aspiration Pneumonia', 'Auscultation', 'Biomechanics', 'Caring', 'Cervical', 'Choking', 'Clinical', 'Coughing', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Deglutition', 'Deglutition Disorders', 'Dehydration', 'Dementia', 'Detection', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Disabled Persons', 'Disease', 'Equipment', 'Event', 'Food', 'Goals', 'Gold', 'Group Homes', 'Head and Neck Cancer', 'Health', 'Hospital Nursing', 'Hospitalization', 'Human', 'Image', 'Impairment', 'Incidence', 'Inhalation', 'Intervention', 'Lead', 'Learning', 'Length of Stay', 'Life', 'Liquid substance', 'Machine Learning', 'Malnutrition', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monte Carlo Method', 'Morbidity - disease rate', 'Nature', 'Neurodegenerative Disorders', 'Nursing Homes', 'Oral', 'Outcome', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Physiological', 'Physiology', 'Pneumonia', 'Positioning Attribute', 'Public Health', 'Research', 'Resolution', 'Risk', 'Screening procedure', 'Severities', 'Signal Transduction', 'Speech', 'Stroke', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Water', 'Work', 'airway obstruction', 'analytical tool', 'base', 'cancer therapy', 'clinical practice', 'clinically significant', 'image processing', 'improved', 'innovation', 'instrument', 'kinematics', 'machine learning algorithm', 'mortality', 'patient safety', 'post stroke', 'predictive signature', 'predictive tools', 'screening', 'tool', 'translational impact', 'vibration']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2019,302394,570146095,0.003078883493247137
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,9658524,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'actionable mutation', 'base', 'disease phenotype', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'learning strategy', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2019,305167,511185245,-0.019332391758118028
"Data-Driven Shape Analysis for Quantitative Severity Stratification in Patients with Metopic Craniosynostosis Abstract Craniosynostosis affects close to one in 2000 newborns and causes growth restriction perpendicular to the affected suture. Metopic craniosynostosis is the second most common form of craniosynostosis. The metopic suture is an important sight of cranial growth as the brain rapidly expands in the ﬁrst year of life. Patients affected by metopic craniosynostosis will present in the ﬁrst few months of life with varying degrees of narrowing of the forehead and brow, a triangular shaped head, and an abnormal eye position. Surgery is recommended early in childhood to normalize the head shape and expand the restricted skull to prevent complications such as headaches, cognitive impairment, and visual disturbances including blindness.  Imaging with computed tomography (CT) is employed to conﬁrm new diagnoses of metopic craniosynostosis and, together with the physical exam, is used in a descriptive and qualitative manner to assess the degree of head shape abnormality. Several methods have been employed to interpret the information provided in the CT scans to allow surgeons to utilize data for surgical decision making. However, these indices reduce the complex three-dimensional skull dysmorphology into isolated measurements of angles or proportions, require detailed calculations to perform, and no universally accepted standard has emerged so far despite signiﬁcant research efforts and clinical motivation.  In this grant proposal, we aim to increase our understanding of the cranial dysmorphology in patients with metopic craniosynostosis by employing latest results from statistical shape modeling and deep learning. Specif- ically, we will build a statistical shape model of pediatric skulls from CT images of patients with metopic cran- iosynostosis as well as a group of normal controls capturing normal phenotypical shape variations. The distance of a new shape from the normative shape space will represent the proposed Shape Normality Metric (SNM). The SNM will be validated against ratings from experts in the surgical community (current standard of care) who will be asked to assess the dysmorphology of the skulls in our database. To avoid surgeons' subjective bias, we will aggregate their response using statistical methods that compensate for potential individual bias. Finally, to streamline data collection for future research we will develop a head-shape portal that will allow users to upload CT scans of their patients and the system will automatically calculate the SNM.  By developing a severity metric that encompasses the entire extent of dysmorphology in metopic craniosyn- ostosis and establishing a head-shape portal, we will improve our understanding of the spectrum of metopic craniosynostosis, aid in pre-operative and surgical decision making, enable future research, and help facilitate longitudinal outcomes assessments and multi-center communication and collaboration. Narrative This grant proposal aims to improve our understanding of the head shape anomaly associated with metopic craniosynostosis by using recent results from statistical shape analysis and deep learning, with the goal of developing an objective metopic cranioynostosis severity scale. Different from previously proposed metrics, our approach evaluates the entire shape as a whole. With this information, surgeons will be able to objectively determine how severely affected their patients are and will be better able to tailor their interventions to the needs of their individual patients. Additionally, surgeons will be able to better communicate with each other and study the effects of surgical intervention on their patients which will improve patient care in the long run.",Data-Driven Shape Analysis for Quantitative Severity Stratification in Patients with Metopic Craniosynostosis,9778826,R21EB026061,"['Address', 'Affect', 'Age', 'Agreement', 'Applications Grants', 'Blindness', 'Brain', 'Cephalic', 'Child', 'Childhood', 'Clinical', 'Cognition', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer software', 'Craniosynostosis', 'Data', 'Data Collection', 'Databases', 'Decision Making', 'Deformity', 'Descriptor', 'Development', 'Diagnosis', 'Dimensions', 'Dysmorphology', 'Ethnic Origin', 'Eye Abnormalities', 'Forehead', 'Future', 'Gender', 'Goals', 'Gold', 'Graph', 'Growth', 'Head', 'Headache', 'Home environment', 'Human', 'Ice', 'Image', 'Imagery', 'Impaired cognition', 'Individual', 'Institution', 'Intervention', 'Joint structure of suture of skull', 'Left', 'Letters', 'Life', 'MRI Scans', 'Measurement', 'Measures', 'Methods', 'Modality', 'Modeling', 'Morphology', 'Motivation', 'Newborn Infant', 'Normalcy', 'Operative Surgical Procedures', 'Outcome Assessment', 'Output', 'Pathologic', 'Patient Care', 'Patient imaging', 'Patients', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Procedures', 'Protocols documentation', 'Reconstructive Surgical Procedures', 'Research', 'Sampling', 'Scanning', 'Severities', 'Shapes', 'Socialization', 'Statistical Methods', 'Stereophotogrammetries', 'Stratification', 'Supervision', 'Surgeon', 'Surgical sutures', 'System', 'Techniques', 'Training', 'Trauma patient', 'Treatment Protocols', 'United States', 'Validation', 'Variant', 'Vision', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical care', 'cranium', 'deep learning', 'experience', 'image processing', 'improved', 'indexing', 'individual patient', 'neural network', 'operation', 'patient stratification', 'power analysis', 'premature', 'prevent', 'reconstruction', 'response', 'self esteem', 'shape analysis', 'standard of care', 'surgery outcome', 'web-based tool']",NIBIB,UNIVERSITY OF UTAH,R21,2019,307172,228951281,1.0953355151837994e-05
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9705993,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'analysis pipeline', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2019,314000,560644462,-0.021444199248779924
"Inferential methods for functional data from wearable devices Project Summary/Abstract This is a project to develop new statistical methods for comparing groups of subjects in terms of health outcomes that are assessed using data from wearable devices. Inexpensive wearable sensors for health monitoring are now capable of generating massive amounts of data collected longitudinally, up to months at a time. The project will develop inferential methods that can deal with the complexity of such data. A serious challenge is the presence of unmeasured time-dependent confounders (e.g., circadian and dietary patterns), making direct comparisons or borrowing strength across subjects untenable unless the studies are carried out in controlled experimental con- ditions. Generic data mining and machine learning tools have been widely used to provide predictions of health status from such data. However, such tools cannot be used for signiﬁcance testing of covariate effects, which is necessary for designing precision medicine interventions, for example, without taking the inherent model selection or the presence of the unmeasured confounders into account. To overcome these difﬁculties, a systematic de- velopment of inferential methods for functional outcome data obtained from wearable devices will be carried out. There are three speciﬁc aims: 1) Develop metrics for functional outcome data from wearable devices, 2) Develop nonparametric estimation and testing methods for activity proﬁles and a screening method for predictors of activity proﬁles, 3) Implement the methods in an R package and carry out two case studies using accelerometer data. For Aim 1, the approach is to reduce the sensor data to occupation time proﬁles (e.g., as a function of activity level), and formulate the statistical modeling in terms of these proﬁles using survival and functional data analytic meth- ods. This will have a number of advantages, the principal one being that time-dependent confounders become less problematic because the effect of differences in temporal alignment across subjects is mitigated. In addition, survival analysis methods can be applied by viewing the occupation time as a time-to-event outcome indexed by activity level. For Aim 2, nonparametric methods will be used to compare and order occupation time distributions between groups of subjects that are speciﬁed in terms of baseline covariate levels or treatment groups. Further, a new method of post-selection inference based on marginal screening for function-on-scalar regression will be developed to identify and formally test whether covariates are signiﬁcantly associated with activity proﬁles. Aim 3 will develop an R-package implementation, and as a test-bed for the proposed methods they will be applied to two Columbia-based clinical studies: to the study of physical activity in children enrolled in New York City Head Start, and to the study of experimental drugs for the treatment of mitochondrial depletion syndrome. Project Narrative The relevance of the project to public health is that it will develop statistical methods for the physiological eval- uation of patients on the basis of data collected by inexpensive wearable sensors (e.g., accelerometers). By introducing methods for the rigorous comparison of healthcare status among groups of patients observed longi- tudinally over time using such devices, treatment decisions that can beneﬁt targeted populations of patients in terms of continuously-assessed health outcomes will become possible.",Inferential methods for functional data from wearable devices,9658873,R01AG062401,"['Acceleration', 'Accelerometer', 'Beds', 'Bypass', 'Case Study', 'Characteristics', 'Child', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Development', 'Devices', 'Dietary Practices', 'Drug Combinations', 'Enrollment', 'Evaluation', 'Event', 'Grant', 'Head Start Program', 'Health', 'Health Status', 'Healthcare', 'Intervention', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Monitor', 'Motivation', 'Nature', 'New York City', 'Obesity', 'Occupations', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmacotherapy', 'Physical activity', 'Physiological', 'Preschool Child', 'Process', 'Proxy', 'Public Health', 'Recording of previous events', 'Regimen', 'Signal Transduction', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Stochastic Processes', 'Survival Analysis', 'Syndrome', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Work', 'analytical method', 'base', 'circadian', 'data mining', 'design', 'experimental study', 'functional outcomes', 'indexing', 'interest', 'lower income families', 'novel', 'patient population', 'precision medicine', 'screening', 'sensor', 'theories', 'time use', 'tool', 'treatment group', 'wearable device']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,317858,558628098,0.001391474849009756
"Common Fund Data Supplement: Integration of KOMP2 (IMPC) and PHAROS into MARRVEL 2.0 for machine learning-assisted rare variant prioritization Project Summary  This application is being submitted in response to NOT-RM-19-009 as a supplement to the parent award U54NS093793.  The Common Fund supports a number of resources that can significantly enhance gene and variant prioritization for study in the Model Organisms Screening Center of the Undiagnosed Diseases Network and beyond. To facilitate the use of these resources, we propose to create a tool that can be easily accessed by clinical geneticists and model organism scientists alike.  MARRVEL (Model organism Aggregated Resources for Rare Variant ExpLoration) was created two years ago because important data that is necessary for rare variant analysis for personalized medicine is spread throughout the internet in tens of different locations. To improve efficiency and streamline access to these data sources, we created a web-tool that allows users to query tens of data sources at once, including GTEx, and links to IMPC, the display portal for KOMP2.  In this proposal, our goal is to develop version 2 of MARRVEL to promote the use of Common Fund resources in the rare disease research community for manual and automated data analysis. This goal will be accomplished by developing MARRVEL 2.0 by integrating KOMP2 (IMPC) and PHAROS data and using the aggregated dataset to develop a machine-assisted gene and variant prioritization for diagnosis and animal model generation.  Our goals align with those of the NIH Common Fund to increase the utility of resources for broader use in the biomedical community. Project Narrative  We aim to promote the use of Common Fund resources and facilitate the diagnosis of rare diseases and the subsequent generation of animal models for the Undiagnosed Diseases Network and beyond. This goal will be accomplished by developing the web resource, MARRVEL 2.0.",Common Fund Data Supplement: Integration of KOMP2 (IMPC) and PHAROS into MARRVEL 2.0 for machine learning-assisted rare variant prioritization,9984757,U54NS093793,"['Affect', 'Animal Model', 'Artificial Intelligence', 'Award', 'Clinical', 'Collaborations', 'Communities', 'Country', 'Data', 'Data Analyses', 'Data Display', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Discipline', 'Disease', 'Disease model', 'Drosophila genus', 'Drug Targeting', 'Expert Systems', 'Family', 'Funding', 'Generations', 'Genes', 'Genetic Diseases', 'Genotype-Tissue Expression Project', 'Goals', 'Growth', 'Healthcare Systems', 'Human Genetics', 'Individual', 'Internet', 'Investigation', 'Knowledge', 'Link', 'Location', 'Machine Learning', 'Manuals', 'Medical', 'Medical Genetics', 'Modeling', 'Mus', 'Parents', 'Pathogenicity', 'Pharmaceutical Preparations', 'Phenotype', 'Process', 'Proteins', 'Rare Diseases', 'Research', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Suggestion', 'Symptoms', 'System', 'Testing', 'Therapeutic', 'Therapeutic Studies', 'Time', 'Training', 'United States National Institutes of Health', 'Variant', 'Visit', 'Yeasts', 'Zebrafish', 'base', 'data wrangling', 'design', 'experimental study', 'feeding', 'fly', 'genetic disorder diagnosis', 'genetic variant', 'human data', 'improved', 'interest', 'learning community', 'machine learning algorithm', 'model organisms databases', 'online resource', 'personalized medicine', 'phenotypic data', 'rare genetic disorder', 'rare variant', 'response', 'screening', 'supervised learning', 'tool', 'web-based tool']",NINDS,BAYLOR COLLEGE OF MEDICINE,U54,2019,320000,323604360,-0.013695922105861
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,9859232,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Dimensions', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'One-Step dentin bonding system', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2019,345016,560644462,0.001701353435848688
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9731544,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'repository', 'research and development', 'software development', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,350620,758431960,0.0017582756261319292
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9608754,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2019,356625,323604360,-0.0013986293307253622
"A platform for mining, visualization and design of microbial interaction networks Project Summary One of the burning questions in the study of the human microbiome is whether and how it is possible to design specific strategies for rebalancing the taxonomic and functional properties of human-associated microbial communities, triggering the transition from “disease states” to “healthy states”. While empirical studies provide strong support for the idea that we may be able to cure, or at least  treat, a number of diseases by simply transplanting microbiomes, or inducing changes through taxonomic or environmental perturbations, to date little mechanistic understanding exists on how microbial communities work, and on how to extend microbiome research from an empirical science to a systematic, quantitative field of biomedicine. We propose here to establish a computational platform--   a database (Aim 1) with fully integrated analytical software (Aims 2 and 3) --- developed for and with the cooperation of the scientific community. The resource goes beyond cataloguing microbial abundances under different condition; its aim is to enable an understanding of networks of interacting species and their condition-dependence, with the goal of eventually facilitating disease diagnosis and prognosis, and designing therapeutic strategies for microbiome intervention. Our project is centered around three key aims: 1.	The creation of a Microbial Interaction Network Database (MIND), a public resource that will collect data on inter-species interactions from metagenomic sequencing projects, computer simulations and direct experiments. This database will be accessed through a web-based platform complemented with tools for microbial interaction network analysis and visualization, akin to highly fruitful tools previously developed for the study of genetic networks; the database will also serve as the public repository of microbial networks associated with human diseases; 2.	The implementation of an integrated tool for simulation of interspecies interactions under different environments, based on genomic data and whole-cell models of metabolism; 3.	The implementation of new algorithms for microbial community analysis and engineering. These algorithms, including stoichiometric, machine-learning and statistical approaches will facilitate a “synthetic ecology” approach to help design strategies (e.g. microbial transplants or probiotic mixtures) for preventing and targeting microbiome-associated diseases. Our work will fill a major gap in current microbiome research, creating the first platform for global microbial interaction data integration, mining and computation. Project Narrative Among the major developments of the genomic revolution has been the ability to identify thousands of microbial species and strains living in communities in 5 major habitats in the human body, and the recognition that the relative abundances of these populations is strongly correlated with environment: disease state, diet, treatment protocol and so on. A major challenge in utilizing the deluge of health relevant data is structuring it into a database that facilitates understanding inter-microbial interactions in these communities. The aim of this proposal is to create a database and integrated computational platform, open to and contributed to by the research community, which will greatly accelerate the conversion of data into health related actionable knowledge.","A platform for mining, visualization and design of microbial interaction networks",9638561,R01GM121950,"['Affect', 'Algorithms', 'Cataloging', 'Catalogs', 'Cell model', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Development', 'Diet', 'Discipline', 'Disease', 'Ecology', 'Ecosystem', 'Empirical Research', 'Engineering', 'Environment', 'Evolution', 'Future', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Habitats', 'Health', 'Human Biology', 'Human Microbiome', 'Human body', 'Imagery', 'Individual', 'Intervention', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Mediating', 'Metabolic', 'Metabolism', 'Metadata', 'Methods', 'Microbe', 'Mining', 'Nature', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Preventive Medicine', 'Probiotics', 'Property', 'Research', 'Resources', 'Science', 'Scientist', 'Structure', 'Taxonomy', 'Technology', 'Therapeutic', 'Time', 'Transplantation', 'Treatment Protocols', 'Work', 'base', 'computational platform', 'computer framework', 'data integration', 'data to knowledge', 'design', 'disease diagnosis', 'experimental study', 'feeding', 'genome-wide', 'genomic data', 'human disease', 'human microbiota', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microbiome research', 'microbiota transplantation', 'microorganism interaction', 'novel diagnostics', 'novel therapeutics', 'open source', 'outcome forecast', 'prevent', 'repository', 'simulation', 'tool', 'user-friendly']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2019,364865,61050884,-0.02011656040006963
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9741471,R01DE027027,"['3-Dimensional', 'Accounting', 'Affect', 'Algorithms', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2019,367570,135644722,-0.007480241397047244
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,9642618,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Effectiveness', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Imagery', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Universities', 'Virginia', 'absorption', 'artificial neural network', 'base', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2019,375602,169622494,-0.007735453983947732
"Advanced Risk Adjusters and Predictive Formulas for ICD-10 Based Risk Adjustment Diagnosis-based risk adjustment is widely used in the US and abroad for health plan payment, notably for Medicare Parts C and D, for commercial contracting and quality assessment, and in numerous state Medicaid programs. Yet the risk adjustment technology used for payments has not kept up with improved classification systems, larger patient datasets, improved estimation algorithms or recent theoretical and clinical developments. Our work will take advantage of the richer ICD-10-CM classification system, in use since October 2015, with over 5 times as many diagnoses as ICD-9-CM Codes. ICD-10 codes now recognize: left vs. right side for thousands of conditions, distinguish between initial, subsequent and sequela diagnoses, and incorporate hundreds of new clinical, demographic and biometric variables. Based on the ICD-10, more exact models can leverage increased diagnostic coding accuracy to reduce opportunities for gaming or discriminating against patients with conditions who are predicted to be unprofitable. Led by two of the three developers of the Centers for Medicare and Medicaid Services Hierarchical Condition Category (CMS-HCC) existing classification system, our team of physicians, public policy experts, statisticians and economists will comprehensively improve the accuracy of risk adjustment and predictive models using larger sample sizes, clinical judgment and state-of-art economic and statistical modeling. We will also expand the conventional regression methods explored, to include machine learning algorithms, constrained regression, and LASSO estimation. We will calculate a new “appropriateness to include” (ATI) score that captures diagnostic vagueness, discretion and suitability for use in risk adjustment models, and use this score to inform which variables are included in plan payment formulas. Selection incentives remain of concern in public US health plan payments formulas and may be costing Medicare over $5 billion per year (NBER 2017). Prediction and payment models from this project can reduce overpayment and offset plan incentives to skimp on services that attract sick people. To ensure that these models and formulas are useful for enrollees of all ages, they will initially be calibrated and tested on large commercially-insured claims data, covering ages 0 to 64. They will then be validated and refined for Medicare, Medicaid, and state employees using data from All-Payer Claims Data from five states and a second large commercial dataset. We will make development steps, statistical programs, and full details of the classification system and prediction formulas publicly available for comment, refinement, and use by health care delivery system researchers, payers and providers. Project Narrative This project will develop new classification systems and new prediction and payment models that take advantage of the fivefold increase in diagnostic codes available with the October 2015 change from ICD- 9-CM to ICD-10-CM. Using data from two national claims datasets and five state all-payer claims datasets that collectively cover over 75 million enrollees, we will identify new, underutilized ICD-10 capabilities, create new clusters of diagnoses useful for prediction, develop new algorithms for using these clusters, and estimate formulas that predict spending, utilization and diverse health care outcomes for all ages. Methods and results will be publicly described and software posted on the web for use in risk adjustment and diverse clinical, financial, policy evaluation, and quality assessment outcomes by health care delivery system researchers, payers and providers.",Advanced Risk Adjusters and Predictive Formulas for ICD-10 Based Risk Adjustment,9775421,R01HS026485,[' '],AHRQ,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2019,384093,61050884,0.0072826792958493505
"Genomic and Phenomic Architecture of Heart Failure The overarching goal of this project is to improve care for patients with heart failure (HF). HF, whether with reduced (HFrEF) or preserved (HFpEF) ejection fraction, is associated with significant morbidity, mortality, and cost. In the U.S. alone, HF affects over 5 million adults, and the prevalence is projected to exceed 8 million by 2030. HF is the most frequent cause of hospitalization among Medicare recipients and results in over $30 billion in health care expenditures each year. Advances in management, especially for HFrEF, have modestly reduced death rates over time, but mortality continues to be high, with approximately half of patients dying within 5 years of diagnosis. Moreover, the pace of drug discovery has been slow, and there are no proven therapies for patients suffering with HFpEF. Among patients with established HF there is substantial variation in illness severity, degree of cardiac remodeling, disease progression, and response to therapy. These observations highlight the heterogeneity of the HF syndrome and suggest existence of subtypes with differing clinical and potentially genetic profiles, with subsequent differences in downstream disease mechanisms, overall risk, and therapeutic response. However, the understanding of the phenotypic, genetic, and pathophysiological heterogeneity of HF is incomplete. This project investigates the phenotypic substructure and genetic architecture of HF by leveraging a unique collection of interrelated datasets from Vanderbilt University Medical Center (VUMC), including the de- identified electronic health record (EHR) and BioVU, a linked DNA biobank. The EHR contains ~2.6 million patients, including ~35,000 with HF, and BioVU currently houses >225,000 DNA samples. Dense genotype data are available in >28,000 subjects and an institutional genotyping project will increase this to >125,000 by mid- 2017; this includes >13,000 subjects with HF. The proposed research will: 1) identify HF subtypes from dense clinical data alone using advanced, unbiased, deep learning algorithms (Aim 1), 2) define the genetic architecture of HF and HF subtypes by using inferred gene expression, general linear mixed models, genetic risk scores, and traditional association testing to quantify heritability of and genetic correlations among HF subtypes, define the contribution of established risk factors to HF subtypes, and 3) discover subtype-specific genetic risk factors (Aim 2), and discover HF subtype-specific clinical outcomes, disease associations, and drug response phenotypes using advanced phenome scanning and network analysis (Aim 3). Heart failure (HF) is a complex, debilitating syndrome associated with significant morbidity and mortality. The heterogeneity of HF has limited success of prior efforts to understand HF pathobiology and develop effective interventions. By defining clinical and genetic modifiers of HF risk, disease course, and treatment response for clinically recognized and novel, data-driven HF subtypes, results from this work could result in a more sophisticated HF classification system based on underlying biology, and ultimately facilitate precision risk stratification, tailoring of therapeutic strategies, and rational HF clinical trials.",Genomic and Phenomic Architecture of Heart Failure,9625162,R01HL140074,"['Academic Medical Centers', 'Adult', 'Affect', 'Architecture', 'Biological', 'Biology', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular Diseases', 'Cardiovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collection', 'Comorbidity', 'Complex', 'Consensus', 'DNA', 'Data', 'Data Set', 'Death Rate', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'EFRAC', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Etiology', 'Failure', 'Gene Expression', 'Genetic', 'Genetic Heterogeneity', 'Genetic Risk', 'Genetic Transcription', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health Expenditures', 'Heart failure', 'Heritability', 'Heterogeneity', 'Hospitalization', 'Human', 'Link', 'Measures', 'Mediator of activation protein', 'Medical', 'Medical Genetics', 'Medicare', 'Modeling', 'Morbidity - disease rate', 'Myocardial dysfunction', 'Natural History', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Prevalence', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Sampling', 'Scanning', 'Severity of illness', 'Subgroup', 'Syndrome', 'System', 'Testing', 'Therapeutic', 'Time', 'Variant', 'Work', 'base', 'biobank', 'cohort', 'cost', 'deep learning', 'deep learning algorithm', 'defined contribution', 'disease phenotype', 'drug discovery', 'effective intervention', 'genetic architecture', 'genetic association', 'genetic profiling', 'genetic risk factor', 'genome wide association study', 'genomic data', 'improved', 'learning strategy', 'mortality', 'novel', 'phenome', 'phenomics', 'preservation', 'response', 'risk variant', 'success', 'treatment response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2019,395000,377931988,-0.005287641018704864
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,9735326,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Simulation', 'Cornea', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Image Analysis', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Structure', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2019,396887,197030888,-0.007934041793089102
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive, PhysioBank, was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. PhysioToolkit, its software collection, supports exploration and quantitative analyses of PhysioBank and similar data with a wide range of well-documented, rigorously tested open-source software that can be run on any platform. PhysioNet's team of researchers leverages results of other funded projects to drive the creation and enrichment of: i) Data collections that provide increasingly comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC III (Medical Information Mart for Intensive Care) Database of critical care patients; ii) Analytic methods that lead to more timely and accurate diagnoses of major public health problems (such as life-threatening cardiac arrhythmias, infant apneas, fall risk in older individuals and those with neurologic disease, and seizures), and iii) Elucidation of dynamical changes associated with a variety of pathophysiologic processes and aging (such as cardiopulmonary interactions during sleep disordered breathing syndromes); User interfaces, reference materials and services that add value and improve accessibility to PhysioNet's data and software (such as PhysioNetWorks, a virtual laboratory for data sharing). Impact: Cited in The White House Fact Sheet on Big Data Across the Federal Government (March 29, 2012), PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are inaccessible otherwise. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world- wide, growing community of researchers, clinicians, educators, students, and medical instrument and software developers, retrieve about 380 GB of data per day. By providing free access to its unique and wide-ranging data and software collections, PhysioNet is invaluable to studies that currently result in an impressive average of nearly 250 new scholarly articles per month by academic, clinical, and industry-affiliated researchers worldwide. Over the next year we aim to sustain and enhance PhysioNet's impact with new technology and data; and complete the 2019 PhysioNet/Computing in Cardiology Challenge on sepsis. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,9993811,R01GM104987,"['Aging', 'Algorithms', 'Apnea', 'Area', 'Arrhythmia', 'Big Data', 'Biomedical Research', 'Boston', 'Bypass', 'Cardiology', 'Cardiopulmonary', 'Categories', 'Clinical', 'Clinical Data', 'Cloud Service', 'Collection', 'Communities', 'Community Outreach', 'Complex', 'Computer software', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dedications', 'Development', 'Diagnostic radiologic examination', 'Entropy', 'FAIR principles', 'Federal Government', 'Functional disorder', 'Funding', 'Grant', 'Imagery', 'Individual', 'Industry', 'Infant', 'Infrastructure', 'Intensive Care', 'Israel', 'Journals', 'Laboratories', 'Lead', 'Licensing', 'Life', 'Link', 'Machine Learning', 'Maintenance', 'Medical', 'Medical center', 'Methods', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Phase Transition', 'Physiological', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Role', 'Running', 'Seizures', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Students', 'Switzerland', 'Syndrome', 'Testing', 'Thoracic Radiography', 'Time', 'United States National Institutes of Health', 'University Hospitals', 'Visit', 'accurate diagnosis', 'analytical method', 'clinical application', 'computerized data processing', 'computing resources', 'data archive', 'data sharing', 'experience', 'fall risk', 'heart rate variability', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'member', 'nervous system disorder', 'new technology', 'open source', 'preservation', 'repository', 'signal processing', 'software repository', 'symposium', 'time interval', 'virtual laboratory']",NIGMS,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2019,409563,135941803,-0.002835916683750638
"Automating Delirium Identification and Risk Prediction in Electronic Health Records Abstract. Delirium, or acute confusional state, affects 30-40% of hospitalized older adults, with the added cost of care estimated to be up to $7 billion. Although originally conceptualized as a transient disorder, delirium is now recognized to have significant consequences, including increased risk of death, functional decline, and long-term cognitive impairment. As up to 75% cases are not recognized by providers, there is an urgent need for additional methods to identify delirium for clinical and research purposes, and to stratify patients based on delirium risk. In this proposal, we present a novel approach to the identification of delirium based on large-scale data mining (i.e., pattern recognition) algorithms using machine learning and natural language processing applied to electronic health record (EHR) data, which will automate chart-based determination of delirium status and risk prediction. We will combine these algorithms with data collected through our recently implemented Virtual Acute Care for Elders (ACE) quality improvement project, which institutes delirium screening once per shift by nursing staff for all individuals over age 65 admitted to the University of Alabama at Birmingham (UAB) Hospital. This unprece- dented volume of data will allow us to achieve the necessary sample sizes for effective training and validation of our data mining algorithms. Data mining algorithms that discover patterns of associations in data, rather than testing predetermined hypotheses, are well suited to application in large-scale algorithms for identification of delirium. Using our Virtual ACE and hospital EHR data, we will be able to evaluate more than 10,000 individual features (e.g., text words and phrases, laboratory and other diagnostic tests, concurrent medical conditions) as- sociated with delirium, which will be classified as risk factors for delirium, as signs, symptoms, and descriptors of delirium itself, and as complications and consequences of delirium, based on expert consensus. We will then use these features to develop rules for identification of delirium in the EHR, as well as risk prediction models that can be integrated into the EHR to provide individualized assessments of delirium risk. This study will lay the foundation for methods of automated delirium identification and risk prediction in healthcare settings that are unable to implement the screening by providers done in our Virtual ACE, as well as for large-scale epidemiological investigations of delirium using EHR data, expanding the current armamentarium for studying this common and debilitating disorder. Project Narrative. Delirium, or acute confusional state, affects up to 7 million hospitalized older adults annu- ally and is associated with long-term declines in cognition and function, but is not recognized by providers in up to 75% of cases. The growth of electronic health records offers a unique opportunity to improve recognition of delir- ium, as methods for identifying delirium based on chart review by clinicians have been developed but are time- and resource-intensive. In this secondary data analysis, we will examine methods for automating delirium recog- nition and risk prediction in electronic health records using machine learning and natural language processing computer algorithms, which in turn will lead to improved care for this serious but often overlooked disorder.",Automating Delirium Identification and Risk Prediction in Electronic Health Records,9637480,R01AG060993,"['Acute', 'Address', 'Adult', 'Affect', 'Agreement', 'Alabama', 'Algorithms', 'Ally', 'Assessment tool', 'Automation', 'Caring', 'Characteristics', 'Clinical Research', 'Cognition', 'Cognitive', 'Computational algorithm', 'Confusion', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Delirium', 'Descriptor', 'Detection', 'Development', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Foundations', 'Growth', 'Health system', 'Hospitals', 'Impaired cognition', 'Individual', 'Inpatients', 'Institutes', 'Institutionalization', 'Laboratories', 'Link', 'Logistics', 'Long-Term Care for Elderly', 'Machine Learning', 'Measurable', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Nursing Staff', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pattern Recognition', 'Persons', 'Prevention', 'Property', 'Provider', 'Receiver Operating Characteristics', 'Reference Standards', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Signs and Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'adverse outcome', 'base', 'care costs', 'confusion assessment method', 'data mining', 'epidemiology study', 'functional decline', 'functional disability', 'health care settings', 'high dimensionality', 'human old age (65+)', 'improved', 'instrument', 'interest', 'model development', 'mortality risk', 'novel', 'novel strategies', 'patient stratification', 'phrases', 'prediction algorithm', 'programs', 'risk prediction model', 'screening', 'validation studies', 'virtual', 'ward']",NIA,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2019,432969,325573502,-0.023943473848882117
"3D temperature control to study biological processes Project Summary Temperature control technology is necessary for a broad range of biologically relevant processes including organ-on-chip operation, biomolecular kinetics, cell growth, studying gene function with temperature-sensitive mutations, cancer cell resistance to hyperthermia treatments, protein crystallization, and DNA analysis. Most biosensing devices lack the needed temperature measurement accuracy and precise temperature control to understand the thermal mechanisms of these processes. For example, temperature variations of 0.2°C can activate heat shock proteins, increasing the resistance of cancer cells to thermal ablation treatment, but reported temperature accuracies are often near ±1°C. This proposal aims to revolutionize the biomedical temperature measurement and control ecosystem by developing technology, models, and validated devices capable of microscopic, spatially resolved temperature sensing and control at ±0.1°C accuracy (10x better than what is used in most biosensing systems). Microfluidics is a promising technology for an extremely broad range of biomedical applications that notably lacks the necessary temperature accuracies and spatial temperature control to effectively study biothermal mechanisms. This proposal intends to impact human health by developing disruptive temperature control tools to accelerate biomedical innovation in thermally sensitive processes. Our group recently demonstrated the capacity to measure temperature at a single point with fluorescent dyes, achieving a ±0.05°C noise floor by using machine learning techniques. We have also 3D printed a cell-based genotype and phenotype assay device with cell growth chambers, monoliths for mRNA capture & fluorescence measurement, and integrated pumps and valves in a volume of only 2.2 mm × 2.2 mm × 1 mm. Aims 1 and 2 of this proposal will build on these successes by developing 3D printing technologies that easily incorporate complex temperature sensing, heating, and cooling channels, coupled with multi-physics/CAD models to rapidly iterate through the prototype development cycle. These advances will be used in Aim 3 to construct a microscopically temperature-controlled chip to measure DNA melt curves to determine the zygosity of a Factor 5 Leiden. This will show that the technology can detect the subtle difference in melting temperature that is undetectable by most PCR machines, as a proof-of-concept before the technology can be applied to other biological process. The overall objective of these studies is to develop a suite of affordable technologies researchers can use to understand biothermal mechanisms to lay the foundation for advances in disease diagnosis, treatment, and prevention. Project Narrative The instruments we use to study the effects of temperature on biological processes are less accurate than humans’ own ability to perceive temperature changes. The proposed research will develop improved microscopic temperature sensing & control technologies and demonstrate them by performing DNA analysis in a 3D printed device. Because the technology is cheap and accurate, it will be widely accessible to any lab, increasing our ability to understand the fundamental role biothermal processes have in disease occurrence, diagnosis, and treatment.",3D temperature control to study biological processes,9732034,R15GM132868,"['3-Dimensional', '3D Print', 'Automation', 'Biochemistry', 'Biological', 'Biological Assay', 'Biological Process', 'Biomedical Research', 'Biosensing Techniques', 'Blood specimen', 'Cells', 'Complex', 'Coupled', 'Crystallization', 'Custom', 'DNA', 'DNA analysis', 'Development', 'Devices', 'Diagnosis', 'Discipline', 'Disease', 'Ecosystem', 'Electrical Engineering', 'Engineering', 'Environment', 'Factor Analysis', 'Factor V', 'Floor', 'Fluorescence', 'Fluorescent Dyes', 'Foundations', 'Future', 'General Population', 'Genotype', 'Geometry', 'Goals', 'Grant', 'Health', 'Heat Stress Disorders', 'Heat shock proteins', 'Heating', 'High temperature of physical object', 'Hour', 'Human', 'Hyperthermia', 'Institution', 'Kinetics', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Messenger RNA', 'Microfluidic Analytical Techniques', 'Microfluidic Microchips', 'Microfluidics', 'Microscopic', 'Modeling', 'Mutation', 'Noise', 'Outcome', 'Performance', 'Persons', 'Phenotype', 'Physics', 'Plant Resins', 'Prevention', 'Printing', 'Process', 'Proteins', 'Pump', 'Quantum Dots', 'Reagent', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Risk', 'Role', 'Sampling', 'Shapes', 'Single Nucleotide Polymorphism', 'Source', 'Spatial Distribution', 'System', 'Techniques', 'Technology', 'Temperature', 'Temperature Sense', 'Testing', 'Thermal Ablation Therapy', 'Thermometry', 'Thermoreceptors', 'Thromboembolism', 'Training', 'Variant', 'Venous', 'Work', 'base', 'biological systems', 'cancer cell', 'career', 'cell growth', 'computer science', 'design', 'disease diagnosis', 'experience', 'gene function', 'graduate student', 'hyperthermia treatment', 'improved', 'improved outcome', 'innovation', 'innovative technologies', 'instrument', 'melting', 'new technology', 'operation', 'organ on a chip', 'prototype', 'sensor', 'sensor technology', 'success', 'tool', 'undergraduate student']",NIGMS,BRIGHAM YOUNG UNIVERSITY,R15,2019,439058,6579725,-0.022310216573498794
"Big Data Methods for Comprehensive Similarity based Risk Prediction Project Summary Electronic health records (EHR) provide rich source of data about representative populations and are yet to be fully utilized to enhance clinical decision-making. Conventional approaches in clinical decision-making start with the identification of relevant biomarkers based on subject-matter knowledge, followed by detailed but limited analysis using these biomarkers exclusively. As the current scientific literature indicates, many human disorders share a complex etiological basis and exhibit correlated disease progression. Therefore, it is desirable to use comprehensive patient data for patient similarity. This proposal focuses on deriving a comprehensive and integrated score of patient similarity from complete patient characteristics currently available, including but not limited to 1) demographic similarity; 2) genetic similarity; 3) clinical phenotype similarity; 4) treatment similarity; and 5) exposome similarity (here exposome defined as all available attributes of the living environment an individual is exposed to), when some of the aspects may overlap and interact. We will optimize information fusion and task-dependent feature selection for assessing patient similarity for clinical risk prediction. Since currently there does not exist a pipeline that is able to extract executable complete patient determinant data, to achieve the research goal described above, we propose first deliver an open- source data preparation pipeline that is based on a widely used clinical data standard, the OMOP (Observational Medical Outcomes Partnership) Common Data Model (CMD) version 5.2. Moreover, to mitigate common missingness and sparsity challenges in clinical data, we describe the first attempt to represent patients' sparse clinical information with missingness, including diagnosis information, medication data, treatment intervention, with a fixed-length feature vector (i.e. the Patient2Vec). This project has four specific aims. Aim 1 is to develop a clinical data processing pipeline for harmonizing patient information from multiple sources into a standards-based uniformed data representation and to evaluate its efficiency, interoperability, and accuracy. Aim 2 is to leverage a powerful machine learning technique, Document2Vec, from the natural language processing literature, to create an open-source Patient2Vec framework for the derivation of informative numerical representations of patients. Aim 3 is to develop a unified machine learning clinical- outcome-prediction framework for Optimized Patient Similarity Fusion (OptPSF) that integrates traditional medical covariates with the derived numerical patient representations from Patient2Vec (Aim 2) for improved clinical risk prediction. Aim 4 is to evaluate our similarity framework for predicting 1) the risk of end-stage kidney disease (ESKD) in general EHR patient population and 2) the risk of death among patients with chronic kidney disease (CKD). The project focus on developing a novel data science pipeline which includes a clinical data processing pipeline to format comprehensive patient health determinants from a variety of sources of clinical, genomic, socioenvironmental data, and a clinical-outcome-prediction framework that optimally fuses relevant patient health determinants to define patient similarity for improved clinical risk predictions.",Big Data Methods for Comprehensive Similarity based Risk Prediction,9687065,R01LM013061,"['Address', 'Automation', 'Big Data', 'Big Data Methods', 'Biological Markers', 'Biological Process', 'Biometry', 'Case Study', 'Characteristics', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complex', 'Data', 'Data Reporting', 'Data Science', 'Derivation procedure', 'Diagnosis', 'Disease', 'Disease Progression', 'Electronic Health Record', 'End stage renal failure', 'Environment', 'Etiology', 'Exhibits', 'Exposure to', 'Genetic', 'Genomics', 'Goals', 'Health', 'Health Professional', 'Healthcare', 'Heterogeneity', 'Human', 'Individual', 'Informatics', 'Interdisciplinary Study', 'Intervention', 'Knowledge', 'Length', 'Life', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Preparation', 'Reporting', 'Reproducibility', 'Research', 'Risk', 'Source', 'Surveys', 'Techniques', 'base', 'biomedical informatics', 'clinical decision support', 'clinical decision-making', 'clinical phenotype', 'clinical risk', 'computerized data processing', 'data modeling', 'design', 'disease diagnosis', 'health data', 'improved', 'interoperability', 'mortality risk', 'novel', 'open data', 'open source', 'outcome prediction', 'patient population', 'precision medicine', 'predict clinical outcome', 'socioeconomics', 'support tools', 'vector']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,448622,558628098,-0.01769055191253724
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,9862231,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Comorbidity', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2019,450365,560644462,-0.004162850399398118
"A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities ﻿    DESCRIPTION (provided by applicant): Our ultimate goal is to improve our ability to create and measure 3D models derived from cone-beam computed tomography (CBCT). Our main motivation is to improve quality and reduce costs in care of patients with craniomaxillofacial (CMF) deformities. The resulted innovations will also impact other fields. CMF deformities involve congenital and acquired deformities of the jaws and face. A large number of patients in the US and around the world suffered from CMF deformities. The evaluation of these patients includes an assessment of CMF form on 3D models that are traditionally generated from segmented spiral multi-slice CTs (MSCTs). These models are also used to plan their treatment. The purpose of segmentation is to separate different anatomical structures and to remove the artifacts on the CTs. Once 3D models are generated from the segmented CTs, anatomical and teeth landmarks are manually digitized for measurements. Finally, diagnosis and treatment planning are performed based on measurements. Although MSCT provides high- quality images and thus allows relatively fast and easy post processing, many concerns have been raised on excessive radiation exposure to patients. Therefore, more doctors are now using CBCT scanners in their offices. CBCT has less radiation and is inexpensive compared to the MSCT, but their use in generating 3D models is greatly limited by the poor image quality, i.e., low contrast / signal-to-noise ratio and artifacts. Thus, the existing automated segmentation algorithms developed for MSCT are incapable of practically segmenting CBCTs. The current solution to CBCT segmentation entails an arduous and lengthy process that involves labor-intensive manual editing of hundreds of slices. Besides, another arduous and inaccurate task in the assessment of CMF deformities is the digitization of anatomical landmarks on 3D models - the first step to quantify the deformities. Currently a typical 3D cephalometric and teeth analysis requires the manual digitization of more than 200 landmarks, which is time consuming and has limited accuracy. We hypothesize that the creation and measurement of high-quality 3D models can be significantly improved by developing innovative CBCT-friendly post processing tools. Therefore, in this renewal project, we propose to develop and validate a novel CBCT analysis platform to automate the process of CBCT segmentation and landmark digitization. The feasibility of our approaches has already been proven by our preliminary studies. Our innovative CBCT analysis platform will significantly improve the quality and reduce the cost of care to the individuals with CMF conditions. It will change our dental/CMF fields in effectively utilizing CBCT as a guide for on-the-fly diagnosis and treatment planning. With minimal user intervention, the computer will accurately and effectively do the work, which is currently artistically done by the labor-intensive human operators. The resulted innovations may also impact other fields in the future, e.g., orthopedic surgery and cardiovascular surgery where intraoperative whole-body CBCT is acquired for image-guided surgery and intervention. PUBLIC HEALTH RELEVANCE: Cone-beam computed tomography (CBCT) is widely used in physician's offices for orthodontics, craniomaxillofacial (CMF) surgery, facial plastic surgery and dentistry, but its segmentation and landmark digitization have to be completed artistically by human operators, which is labor-intensive and with limited accuracy.  We propose to develop and validate an innovative CBCT post processing system to automate the processes of CBCT segmentation and landmark digitization with minimal user intervention.  The proposed system will significantly improve the quality and reduce the cost of care to the individuals  with CMF conditions, and also change 1) the fields of orthodontics, CMF surgery and general dentistry in  effectively utilizing CBCT as a guide for diagnosis and treatment planning, and 2) the fields of orthopedic  surgery, general surgery, and cardiovascular surgery where the quality and the speed of intraoperative  imaging is critical.",A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities,9624752,R01DE022676,"['3-Dimensional', 'Algorithms', 'American', 'Anatomy', 'Atlases', 'Back', 'Cardiovascular Surgical Procedures', 'Cephalometry', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Assisted', 'Computer software', 'Computers', 'Consultations', 'Consumption', 'Deformity', 'Dental Care', 'Dentistry', 'Detection', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Ensure', 'Evaluation', 'Exposure to', 'Face', 'Future', 'Goals', 'Head', 'Hour', 'Human', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Individual', 'Intervention', 'Jaw', 'Label', 'Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motivation', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Oral', 'Orthodontics', 'Orthopedic Surgery procedures', 'Patient Care', 'Patients', 'Phase', 'Physicians&apos', ' Offices', 'Plastic Surgical Procedures', 'Process', 'Quality of Care', 'Quantitative Evaluations', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Running', 'Scanning', 'Services', 'Shapes', 'Signal Transduction', 'Slice', 'Speed', 'Syncope', 'System', 'Technology', 'Three-Dimensional Image', 'Time', 'Tomography, Computed, Scanners', 'Tooth structure', 'Training', 'Validation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'care costs', 'cone-beam computed tomography', 'cost', 'craniofacial', 'craniomaxillofacial', 'design', 'detector', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'psychologic', 'public health relevance', 'random forest', 'simulation', 'three-dimensional modeling', 'tool', 'treatment planning', 'usability', 'user-friendly']",NIDCR,METHODIST HOSPITAL RESEARCH INSTITUTE,R01,2019,490358,27487788,-0.015174673220665144
"Utility of Predictive Systems to identify Inpatient Diagnostic Errors: The UPSIDE Study PROJECT SUMMARY/ABSTRACT  While much research has been conducted on patient safety since the Institute of Medicine published “To Err is Human” in 2000, there is a comparative dearth of research on diagnostic errors in the hospital setting. The broad, long-term objectives of the proposed research is to better understand the incidence, causes, and risk factors for diagnostic errors in the inpatient setting. This work will provide foundational research for the development of interventions to reduce these errors, including predictive tools, targets for intervention, and a methodology for outcome assessment in future trials of interventions. To achieve this overall goal, we will carry out the following specific aims: 1) To determine the incidence of diagnostic errors among patients who die in hospital or are transferred to the ICU two days or more after admission to a general medicine service through a structured, standardized adjudication process of patient records, 2) To combine adjudication data with data from Vizient to determine which specific factors contribute to risks for diagnostic errors, and to use risk estimates to calculate incidence and impact of factors contributing to those errors, and 3)To create machine- learning models that can be used to retrospectively identify patients in whom a diagnostic error was likely to have taken place. The research will involve a retrospective evaluation of 2000 patients admitted to general medicine units at 20 US hospitals participating in a national research collaborative and which also contribute data to a benchmarking and purchasing organization (Vizient). Using the Safer-Diagnosis (Safer-Dx) and Diagnostic Error Evaluation and Research (DEER) taxonomy tools, both adapted for the inpatient setting, adjudicators will review electronic medical record data and determine the presence or absence of diagnostic errors using a rigorous training and continuous review process to ensure reliability across sites, adjudicators, and time. Standard modelling techniques will be used to understand the population-attributable risk of each of the DEER process failure points to diagnostic error as well as the contributions of several patient, provider, and system-level risk factors. Lastly, advanced machine-learning methods will be used to create models that can identify patients in whom diagnostic error occurred, with superior performance to standard approaches such as logistic regression. Together, these approaches will provide a broad and representative picture of the incidence of diagnostic errors among hospitalized patients who have suffered harm, develop models of patient and system-based factors that make a diagnostic error more or less likely, and build advanced, efficient, and scalable tools needed to support future surveillance and improvement programs for a variety of institutions. This research will establish a foundation from which healthcare systems can assess and achieve excellence in diagnosis in the inpatient setting. PROJECT NARRATIVE  This study seeks to accurately define the incidence of diagnostic errors among patients suffering serious inpatient events in a large network of US hospitals. Without a reliable method for determining the presence of diagnostic errors across many organizations, it is not otherwise possible to understand the incidence, impact, predictors, and underlying causes of these errors, to create and optimize future solutions to reduce diagnostic errors, to directly test the effects of these solutions, or to teach physicians how to avoid diagnostic pitfalls in the future. Our study addresses these issues while being responsive to the RFA’s goals of developing robust estimates of incidence and risk and using approaches that leverage electronic data, and our approach represents a novel application of rigorous outcome adjudication and advanced modeling techniques to the problem of inpatient diagnostic errors.",Utility of Predictive Systems to identify Inpatient Diagnostic Errors: The UPSIDE Study,9938134,R01HS027369,[' '],AHRQ,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2019,497444,685608202,-0.001900233800602064
"Multimodality imaging-driven multifidelity modeling of aortic dissection PROJECT SUMMARY. Aortic dissections are responsible for significant morbidity and mortality in young and old individuals alike. Whereas type A (ascending aorta) dissections are treated aggressively via surgery, type B (descending thoracic aorta) dissections are often monitored for long periods to determine the best treatment. These lesions can cease to propagate (i.e., stabilize or heal) or they can propagate further and either turn inward and connect again with the true lumen to form a re-entry tear or turn outward and result in rupture in the case of an compromised adventitia. Notwithstanding the importance of these later events, there is a pressing need to understand better the early processes that initiate the dissection and drive its initial propagation as well as to determine whether the presence of intramural thrombus is protective or not against early or continued propagation. Over the past 5 years our collaborative team has developed numerous new multimodality imaging techniques, biomechanical testing methods, and computational modeling approaches across multiple scales that uniquely positions us to understand better the process of early aortic dissection and the possible roles played by early intramural thrombus development. In this project, we propose to use nine complementary mouse models to gain broad understanding of the bio-chemo-mechanical processes that lead to aortic dissection and to introduce a new machine learning based multifidelity modeling approach to develop predictive probabilistic multiscale models of dissection. These models will be informed, trained, and validated via data obtained from a combination of unique in vitro biomechanical phenotyping experiments (wherein we can, for the first time, quantify the initial delamination process under well-controlled conditions and regional material properties thereafter) and novel multimodality imaging of delamination / dissection both in vitro and in vivo. We will consider, for example, the roles of different elastic lamellar geometries; we will assess separate roles of focal proteolytic activation and pooling of highly negatively charged mucoid material, which can degrade or swell the wall respectively; and we will model and assess the effects of early thrombus deposition within a false lumen. We submit that our new probabilistic paradigm, based on statistical autoregressive schemes and enabled by machine learning tools, could be transformative and lead to a paradigm shift in disease prediction where historical data, animal experiments, and limited clinical input (e.g., multiomics) can be used synergistically for robust prognosis and thus interventional planning. Our work is also expected to lead naturally to an eventual better understanding of the chronic processes associated with dissection via predictive models that are aided by the expected “revolution of resolution” in diagnostic imaging. PUBLIC HEALTH RELEVANCE Mounting evidence reveals that thoracic aortic dissections – which afflict young and old individuals alike – are responsible for even greater disability and death than long thought. We will use a unique combination of multiple mouse models, advanced medical imaging, and novel computational models to elucidate the mechanisms responsible for the initiation of a dissection and reasons for the extreme biological variability that characterizes these lethal lesions.",Multimodality imaging-driven multifidelity modeling of aortic dissection,9739188,U01HL142518,"['Acute', 'Address', 'Animal Experiments', 'Animal Model', 'Aorta', 'Aortic Rupture', 'Arteries', 'Attention', 'Biological', 'Biomechanics', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blunt Trauma', 'Carotid Arteries', 'Categories', 'Cervical', 'Cessation of life', 'Charge', 'Chest', 'Child', 'Chronic', 'Clinical', 'Coagulation Process', 'Collaborations', 'Communities', 'Computer Simulation', 'Coupling', 'Data', 'Defect', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dilatation - action', 'Disease', 'Dissection', 'Elderly', 'Event', 'Foundations', 'Geometry', 'Glycosaminoglycans', 'Goals', 'Heritability', 'Human', 'Hypertension', 'Image', 'Imaging Techniques', 'In Vitro', 'Individual', 'Infusion procedures', 'Intervention', 'Knowledge', 'Lead', 'Lesion', 'Long-Term Effects', 'Machine Learning', 'Mechanics', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Motivation', 'Multimodal Imaging', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Phase', 'Phenotype', 'Platelet aggregation', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Property', 'Research', 'Resolution', 'Risk Factors', 'Role', 'Rupture', 'Scheme', 'Site', 'Solid', 'Statistical Models', 'Testing', 'Thoracic aorta', 'Thrombus', 'Time', 'Training', 'Tunica Adventitia', 'Ultrasonography', 'Uncertainty', 'Video Microscopy', 'Work', 'ascending aorta', 'base', 'digital imaging', 'disability', 'experimental study', 'healing', 'hemodynamics', 'improved', 'in vivo', 'insight', 'intracranial artery', 'mortality', 'mouse model', 'mucoid', 'multi-scale modeling', 'multiple omics', 'normotensive', 'novel', 'novel strategies', 'outcome forecast', 'particle', 'predictive modeling', 'public health relevance', 'single photon emission computed tomography', 'spatiotemporal', 'supervised learning', 'tool', 'virtual', 'young adult']",NHLBI,YALE UNIVERSITY,U01,2019,506426,550947887,-0.0021930255808257255
"Predicting Diabetic Retinopathy from Risk Factor Data and Digital Retinal Images Abstract Diabetic retinopathy is the leading cause of blindness among US adults between the ages of 20 and 74 years. Laser photocoagulation surgery has been established as an effective way of treating retinopathy if it is detected early. Yearly retinal screening examinations are a potent tool in the battle to reduce the incidence of blindness from diabetic retinopathy because they provide diabetic patients with timely diagnoses and consequently, the potential for timely treatment. Primary care safety net clinics provide monitoring and other services for diabetic patients but they are often not equipped to provide specialty care services such as retinal screenings. Access to specialists who can provide retinal screenings can be increased through the use of telemedicine, which has shown great promise as a means of screening for diabetic retinopathy in the US and internationally. A pilot study by Charles Drew University investigators had a total of 2,876 teleretinal screenings performed for diabetic retinopathy, with 2,732 unique diabetic patients from six South Los Angeles safety net clinics screened. The present study aims to build on this prior work by: (a) developing novel software that utilizes information from clinical records to detect latent diabetic retinopathy in diabetic patients who have not yet received an annual eye examination, and (b) devising methods to speed up the diabetic retinopathy detection process for diabetic patients who have had digital retinal images taken by partially automating the process using image processing and machine learning techniques. Specifically, we propose to: 1. Develop predictive models for diabetic retinopathy using risk factors collected from patient clinical records. 2. Develop predictive models for automated diabetic retinopathy assessment using a combination of patient  risk factor data and data from digital retinal images previously evaluated by experts. 3. Evaluate the predictive accuracy of: a) the models developed for specific aim 2, and, b) the assessments of  optometrist readers against standard of care dilated retinal examinations by board certified  ophthalmologists for 300 diabetic patients utilizing a new Los Angeles County reading center. 4. Create web-based software tools based on the predictive models developed in specific aim 1 that can be  used to initiate outreach to high-risk patients in under-resourced settings, boosting detection rates for those  patients who are most at risk for diabetic retinopathy. 5. Establish targeted outreach methods to promote screening for patients that the predictive models from  specific aim 1 identify as potentially having undetected diabetic retinopathy. Narrative Diabetic retinopathy is the leading cause of blindness among US adults between the ages of 20 and 74 years. Although previous studies within the US and internationally have shown that teleretinal screening can increase access to eye examinations for detecting retinopathy, few studies have focused on the US urban safety net, which has ophthalmic screening rates that are well below the US average and a preponderance of diabetic patients who are from ethnic minority groups. Building on a previous teleretinal screening study that assessed 2,732 South Los Angeles patients for retinopathy, this study deploys machine learning and image processing techniques to detect latent retinopathy in unscreened diabetic patients and partially automate the diabetic retinopathy detection process for teleretinal screening.",Predicting Diabetic Retinopathy from Risk Factor Data and Digital Retinal Images,9751381,R01LM012309,"['Address', 'Adult', 'Affect', 'Age', 'Alaska Native', 'American Indians', 'Asian Americans', 'Blindness', 'Blood Circulation', 'Blood Vessels', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Clinic', 'Clinical', 'Complications of Diabetes Mellitus', 'Computer software', 'County', 'Data', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Eye', 'Glucose', 'Health Care Reform', 'Health Insurance', 'Health care facility', 'Hispanics', 'Incidence', 'International', 'Los Angeles', 'Machine Learning', 'Methods', 'Minority Groups', 'Modeling', 'Monitor', 'Not Hispanic or Latino', 'Online Systems', 'Operative Surgical Procedures', 'Ophthalmic examination and evaluation', 'Ophthalmologist', 'Optometrist', 'Patient risk', 'Patients', 'Pilot Projects', 'Population', 'Primary Health Care', 'Process', 'Protocols documentation', 'Publishing', 'Reader', 'Reading', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Retina', 'Retinal', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Rural', 'Services', 'Software Tools', 'Specialist', 'Speed', 'Techniques', 'Telemedicine', 'Time', 'United States', 'Universities', 'Work', 'aged', 'base', 'care systems', 'diabetic', 'diabetic patient', 'digital', 'digital imaging', 'ethnic minority population', 'high risk', 'image processing', 'inner city', 'laser photocoagulation', 'medical specialties', 'medically underserved', 'mortality', 'novel', 'outreach', 'patient screening', 'predictive modeling', 'primary care setting', 'racial minority', 'randomized trial', 'retinal imaging', 'safety net', 'screening', 'standard of care', 'statistics', 'tool', 'transmission process', 'trend']",NLM,CHARLES R. DREW UNIVERSITY OF MED & SCI,R01,2019,512263,7479461,-0.0189190293103413
"Identifying Personalized Risk of Acute Kidney Injury with Machine Learning PROJECT SUMMARY/ABSTRACT Acute Kidney Injury (AKI) is a common and highly lethal health problem, affecting 10-15% of all hospitalized patients and >50% of patients in intensive care units (ICUs). It has been shown that a small increase in serum creatinine (SCr) of ≥0.5 mg/dl was associated with a 6.5-fold increase in the odds of death, a 3.5-day increase in length of stay, and nearly $7,500 in excess hospital costs. Unfortunately, no specific treatment exists to cure AKI once it has developed. The ability to predict AKI in hospitalized patients would provide clinicians the opportunity to modify care pathways and implement interventions, which could in turn prevent AKI and yield better outcomes. Although electronic medical record (EMR) based monitoring systems for AKI have led to expedited interventions and may increase the percentage of patients returning to baseline kidney function, most of these systems are reactive rather than proactive, with little or no contribution to AKI prevention. Moreover, our current knowledge of AKI risk factors is far from complete, especially in the ICU and general inpatient populations, characterized by numerous deficiencies and systematic failings that may be avoidable To transform the reactive AKI care to proactive and personalized care, early identification of high risk patients and better understanding of individual modifiable risk factors for AKI is the key. In Aim 1, to discover novel risk factors predictive of AKI, we propose to develop an ensemble multi-view feature selection framework to simultaneously consider the differences and interrelations between feature spaces and obtain robust knowledge by synthesizing findings from diverse patient populations across multiple institutions in nine US states. In Aim 2, to discover general modifiable causes of AKI to help physicians design more effective AKI prevention policies, we propose to develop a novel multi-cause inference method to identify causal relationships between modifiable factors and AKI for susceptible patient subgroups. In Aim 3, to explain what caused AKI in individual patients to support physicians in designing personalized AKI intervention, we propose to develop a new causal explanation method by integrating causal inference and case based reasoning to quantify patient-level causal significance of modifiable factors. The proposed study will have a significant clinical impact by not only expanding the capacity of clinicians to identify high risk patients for AKI early and advancing the general knowledge on causal and modifiable risk factors for AKI but also supporting personalized AKI intervention with suggestions on potential patient-specific actionable items. The work will not only advance AKI but also the machine learning and clinical research informatics community and the methodology developed is generalizable to other clinical domains. PROJECT NARRATIVE The proposed research is to identify clinical risk factors of acute kidney injury (AKI) in hospitalized patients from electronic medical records (EMRs) with machine learning. AKI risk factors discovered from EMR of diverse populations from multiple institutions across nine US states will be reliable and robust and can assist clinicians in providing proactive and personalized care to high-risk patients.",Identifying Personalized Risk of Acute Kidney Injury with Machine Learning,9819327,R01DK116986,"['Acute Renal Failure with Renal Papillary Necrosis', 'Affect', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Computerized Medical Record', 'Creatinine', 'Data', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Early identification', 'Elderly', 'Event', 'Exposure to', 'Geographic Locations', 'Geographic state', 'Health', 'Health system', 'Heterogeneity', 'Hospital Costs', 'Hospital Mortality', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Injury to Kidney', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'Kidney', 'Knowledge', 'Learning', 'Length of Stay', 'Life', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Monitor', 'Myocardial', 'Outcome', 'Outcomes Research', 'Pathway interactions', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Physiology', 'Policies', 'Population', 'Population Heterogeneity', 'Predictive Factor', 'Renal function', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Role', 'Sepsis', 'Series', 'Serum', 'Suggestion', 'System', 'Time', 'Work', 'adjudication', 'base', 'case-based', 'clinical predictors', 'clinical risk', 'design', 'high dimensionality', 'high risk', 'improved', 'individual patient', 'inhibitor/antagonist', 'injury prevention', 'machine learning algorithm', 'modifiable risk', 'mortality risk', 'nephrotoxicity', 'novel', 'patient population', 'patient subsets', 'personalized care', 'prevent']",NIDDK,UNIVERSITY OF KANSAS MEDICAL CENTER,R01,2019,512304,77014486,-0.013154737282539583
"Using a Natural Experiment to Evaluate the Long-Term Effects of Neighborhood Deprivation on Alzheimer's Disease and Vascular Risk Factors ABSTRACT  The NIA has called for social science and community-based studies to clarify risk and protective factors for Alzheimer's disease and related dementias (ADRD), particularly among racial minorities who are disproportionately affected. Place, including both neighborhood of residence and region/state of birth, has consistently been correlated with ADRD, stroke, and impaired cognitive function. Yet it is unclear whether modifiable mechanisms explain this association, or whether the association is merely due to the selection of unhealthy individuals into poor regions. The goal of this study is to produce the first quasi-experimental evidence to understand the influence of neighborhood socioeconomic deprivation on ADRD and its vascular risk factors. We take advantage of a unique natural experiment, overcoming methodological challenges in the previous literature on neighborhood effects on ADRD. From 1986 to 1998, the Danish government actively dispersed roughly 76,000 incoming refugees across the country in a nearly randomized (“quasi-random”) fashion to avoid over-crowding in major cities. This cohort includes nearly 12,000 individuals who lived until at least age 60 in Denmark during the 30-year follow-up. Over 90% of families agreed to participate in the program, creating a natural experiment in which these individuals were quasi-randomly assigned to neighborhoods with different levels of deprivation. We will employ unique data spanning over 30 years from Denmark's population and clinical registers, which provide data on sociodemographics, clinical encounters, and prescriptions for all Danish residents. We identify cases of ADRD and its vascular risk factors among this racially diverse cohort via validated techniques using ICD codes and prescription data in clinical registers. We have successfully linked these registers to detailed geocoded data sources on eight measures of neighborhood socioeconomic deprivation. In Aim 1, our goal is to test the hypothesis that neighborhood deprivation increases the incidence of ADRD later in life. In Aim 2, we will examine the effects of neighborhood deprivation on vascular risk factors for ADRD, including highly prevalent conditions that occur across the life course. In Aim 3, we will identify vulnerable subgroups whose development of ADRD and vascular risk factors differs in response to neighborhood deprivation, taking advantage of the large sample size and complete register data available on all subjects. We will employ both hypothesis-driven and hypothesis-generating statistical techniques, including innovative machine learning methods that allow for more complex and robust subgroup identification. This will enable future interventions to be tailored to the most vulnerable individuals. Overall, the expected outcome of this research is to produce rigorous evidence on the effects of neighborhood characteristics on ADRD and vascular risk factors, overcoming the methodological challenges in previous work. This will directly inform the development of clinical, community, and policy strategies to address the neighborhood determinants of ADRD among vulnerable populations who are most at-risk. PROJECT NARRATIVE  The goal of this research is to examine the effects of neighborhood deprivation on Alzheimer's dementia and its vascular risk factors. We will examine the association of specific neighborhood characteristics with Alzheimer's and its risk factors, and we will assess whether specific subgroups may be more vulnerable to neighborhood deprivation. This will inform the development of interventions to address the neighborhood factors that affect Alzheimer's disease.",Using a Natural Experiment to Evaluate the Long-Term Effects of Neighborhood Deprivation on Alzheimer's Disease and Vascular Risk Factors,9745267,R01AG063385,"['Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Alzheimer&apos', 's disease risk', 'Attention', 'Biological Factors', 'Birth', 'Blood Vessels', 'Characteristics', 'Cities', 'Clinical', 'Communities', 'Community Developments', 'Complex', 'Country', 'Crowding', 'Data', 'Data Sources', 'Denmark', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disadvantaged', 'Discrimination', 'Environmental Risk Factor', 'Exposure to', 'Family', 'Future', 'Gender', 'Goals', 'Government', 'Health', 'Hyperlipidemia', 'Hypertension', 'Immigrant', 'Impaired cognition', 'Incidence', 'Individual', 'International Classification of Disease Codes', 'Intervention', 'Life', 'Life Cycle Stages', 'Life Experience', 'Link', 'Literature', 'Logistics', 'Long-Term Effects', 'Machine Learning', 'Measures', 'Methodology', 'Minority Groups', 'Natural experiment', 'Neighborhoods', 'Observational Study', 'Outcome', 'Outcomes Research', 'Pathway interactions', 'Pattern', 'Policies', 'Population', 'Poverty', 'Race', 'Randomized', 'Refugees', 'Research', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Schools', 'Social Sciences', 'Socialization', 'Stroke', 'Subgroup', 'Techniques', 'Testing', 'Time', 'Violence', 'Vulnerable Populations', 'Work', 'base', 'clinical development', 'cognitive function', 'cohort', 'dementia risk', 'deprivation', 'diabetes risk', 'environmental enrichment for laboratory animals', 'ethnic minority population', 'evidence base', 'experimental study', 'follow-up', 'forest', 'high risk', 'indexing', 'innovation', 'learning strategy', 'member', 'prevent', 'programs', 'protective factors', 'racial and ethnic', 'racial diversity', 'racial minority', 'residence', 'response', 'social', 'sociodemographics', 'socioeconomic disadvantage', 'socioeconomics', 'stressor', 'theories', 'therapy development', 'treatment effect', 'vascular risk factor', 'young adult']",NIA,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2019,567836,685608202,-0.028297930523655368
"Machine learning of physiological variables to predict diagnose and treat cardiorespiratory instability Project Summary/Abstract: If one could accurately predict who, when and why patients develop cardiorespiratory instability (CRI), then effective preemptive treatments could be given to improve outcome and better use care resources. However, CRI is often unrecognized until it is well established and patients are more refractory to treatment, or progressed to organ injury. We have shown that an integrated monitoring system alert obtained from continuous noninvasively acquired monitoring parameters and coupled to a care algorithm improved step-down unit (SDU) patient outcomes. We also showed that advanced HR variability analysis (sample entropy) identified SDU patients at CRI risk within 2 minutes, and if monitored for 5 minutes differentiated between patients who would develop CRI or remain stable over the next 48 hours. We also applied machine learning (ML) modeling to our clinically-relevant porcine model of hemorrhagic shock to characterize responses to hypovolemia, hemorrhage, and resuscitation, predict which animals would or would not collapse during hypovolemia, and identify occult bleeding 5 minutes earlier than with traditional monitoring. We now propose to apply our work to vulnerable and invasively monitored ICU patients. We will develop multivariable models through ML data-driven classification techniques such as regression, Fourier and principal component analysis, artificial neural networks, random forest classification, etc. as well as more novel approaches (temporal rule learning developed by our team; Bayesian Aggregation) to predict CRI in ICU patients. We will first use our existing annotated high fidelity waveform MIMIC II clinical data set (4200 patients) to develop predictive models and differential signatures for various CRI drivers. We will also use our high-density data collection and processing platform (Bernoulli) to prospectively collect data from ICUs in three institutions: Univ. Pittsburgh (PITT), Univ. California (UC) Irvine and UC San Diego (initial algorithm development conducted at PITT and validated in the UC systems). We will identify the number and type of independent measures, sampling frequency, and lead time necessary to create robust algorithms to: 1) predict impending CRI, 2) select the most effective treatments, 3) monitor treatment response, and 4) determine when treatment has restored physiologic stability and can be stopped. We will also determine the smallest number and types of parameters coupled to the longest CRI lead time to achieve the above four targets with the best sensitivity and specificity (a concept we call Monitoring Parsimony).We will simultaneously iteratively design and test a graphical user interface (GUI) and clinical decision support system (CDSS) driven by these parsimoniously derived predictive smart alerts and functional hemodynamic monitoring treatment approaches in two human simulation environments (PITT & UC Irvine).We envision a basic monitoring surveillance that identifies patients most likely to develop CRI to apply focused clinician attention and targeted treatments to deliver highly personalized medical care. Public Health Narrative If one could accurately predict who, when and why patients develop shock then effective preemptive treatments could be given to improve outcome and more effectively use healthcare resources. But signs of shock often occur late once organ injury is already present. The purpose of this study is to first develop multivariable models through data-driven classification techniques to parsimoniously predict cardiovascular insufficiency, etiology and response to treatment. We will do this first in our existing MIMIC II clinical data sets of 4200 ICU patients as to timing and types of instability. Then we will prospectively collect real time high- density data on patients admitted to our trauma intensive care units of University of Pittsburgh, UC Irvine and UC San Diego. We will create and test in simulators of ICU care bedside user interfaces to drive recognition and treatment algorithms based on these models in all three medical centers.",Machine learning of physiological variables to predict diagnose and treat cardiorespiratory instability,9685235,R01GM117622,"['Acute', 'Algorithms', 'Animals', 'Attention', 'California', 'Cardiovascular system', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Complex', 'Coupled', 'Critical Illness', 'Data', 'Data Collection', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Entropy', 'Environment', 'Etiology', 'Exposure to', 'Family suidae', 'Frequencies', 'Future', 'Health', 'Healthcare', 'Hemorrhage', 'Hemorrhagic Shock', 'Homeostasis', 'Hour', 'Human', 'Hypovolemia', 'Injury', 'Institution', 'Intensive Care Units', 'Intervention', 'Lead', 'Learning', 'Libraries', 'Machine Learning', 'Measures', 'Mechanical ventilation', 'Medical', 'Medical center', 'Modeling', 'Monitor', 'Normal Range', 'Organ', 'Organ failure', 'Pathologic Processes', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Perioperative', 'Physiologic Monitoring', 'Physiological', 'Principal Component Analysis', 'Process', 'Protocols documentation', 'Public Health', 'Recommendation', 'Refractory', 'Resolution', 'Resources', 'Resuscitation', 'Risk', 'Running', 'Sampling', 'Sensitivity and Specificity', 'Sepsis', 'Shock', 'Signal Transduction', 'Specificity', 'Stream', 'Stress', 'System', 'Techniques', 'Testing', 'Time', 'Trauma', 'Triage', 'Universities', 'Validation', 'Variant', 'Weaning', 'Work', 'artificial neural network', 'base', 'cardiovascular insufficiency', 'clinical care', 'clinical decision support', 'clinically relevant', 'computerized data processing', 'cost', 'database structure', 'density', 'diagnostic accuracy', 'early onset', 'effective therapy', 'fitness', 'graphical user interface', 'hemodynamics', 'high risk', 'improved', 'improved outcome', 'individual response', 'insight', 'iterative design', 'mortality', 'novel strategies', 'patient population', 'personalized medicine', 'predictive modeling', 'predictive tools', 'prospective', 'prototype', 'random forest', 'response', 'simulation', 'support tools', 'treatment response']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2019,586227,570146095,-0.014548840723242622
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,9739919,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Base Management', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistics', 'subchondral bone', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,588354,641965656,-0.0026337488343054372
"Using Machine Learning to Predict Problematic Prescription Opioid Use and Opioid Overdose Problematic prescription opioid use, defined as nonmedical use, misuse, or abuse of opioid medications, is epidemic in the US. Prescription opioid overdose deaths more than quadrupled from 1999 to 2015. Efforts by health care systems and payers to combat the opioid epidemic are impeded by a lack of accurate and efficient methods to identify individuals most at risk for problematic opioid use and overdose, leading to broad interventions that are burdensome to patients and expensive for payers. Payers are currently defining high risk and targeting interventions (e.g. pharmacy lock-in programs) based on individual risk factors, such as high opioid dosage, identified in prior studies using traditional statistical approaches. However, these traditional approaches have significant limitations, especially when handling large datasets with numerous variables, multi-level interactions, and missing data. Moreover, the prior studies focused on identifying risk factors rather than predicting actual risk. Alternatively, machine learning is an advanced technique that handles complex interactions in large data, uncovers hidden patterns, and yields precise prediction algorithms that, in many cases, are superior to those developed using traditional methods. Machine learning is widely used in activities from fraud detection to cancer genomics, but has not yet been applied to address the opioid epidemic. Accordingly, the proposed study will apply machine learning to develop prediction algorithms that can more accurately identify patients at high risk of problematic opioid use and overdose using data sources that are readily available to payers and health care systems. The project will build on existing academic-state partnerships to apply novel machine learning approaches to administrative claims data for all Medicaid beneficiaries in Pennsylvania (PA) and Arizona (AZ). The project will also link Medicaid data in AZ to electronic health records to capture clinical information (e.g., lab results, pain severity) not available in administrative data, along with death certificate data on lethal overdose. These data, covering 2007-2016, will be used to achieve two specific aims: (1) to develop and validate two separate prediction algorithms to identify patients at risk of problematic opioid use and opioid overdose; (2) to compare the accuracy of a prediction algorithm that integrates clinical data with Medicaid claims versus a claims-based approach alone to identify patients at risk of problematic opioid use and opioid overdose. The machine learning approaches will include random forests and TreeNet with representative classification trees, and the predictive ability (e.g., misclassification rates) of these algorithms will be compared to traditional statistical models. Given the high prevalence of mental health/substance use disorders (~50%) and opioid utilization (>20%) among Medicaid enrollees and the lack of adequate prediction algorithms, Medicaid is an ideal setting for the proposed project. These analyses will provide the partnering Medicaid programs with valuable information and tools that they can apply to more precisely target interventions to prevent problematic opioid use and overdose. Prescription opioid overdose deaths quadrupled from 1999 to 2015, and drug overdose is now the leading cause of injury deaths among adults in the United States. This project will use innovative machine learning methods and readily available data for Medicaid beneficiaries in two states hard hit by the epidemic – Pennsylvania and Arizona – to develop algorithms to accurately predict who is at risk of problematic prescription opioid use and overdose. This information will empower health systems, payers, and policymakers to more effectively target interventions to prevent prescription opioid misuse and its consequences.",Using Machine Learning to Predict Problematic Prescription Opioid Use and Opioid Overdose,9727956,R01DA044985,"['Accident and Emergency department', 'Address', 'Adult', 'Alcohol or Other Drugs use', 'Algorithms', 'American', 'Arizona', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Data Set', 'Data Sources', 'Death Certificates', 'Detection', 'Dose', 'Drug Screening', 'Electronic Health Record', 'Emergency department visit', 'Ensure', 'Epidemic', 'Fee-for-Service Plans', 'Fraud', 'Genomics', 'Health system', 'Healthcare Systems', 'High Prevalence', 'Hospitals', 'Individual', 'Injury', 'Inpatients', 'Intervention', 'Letters', 'Link', 'Logistic Regressions', 'Machine Learning', 'Managed Care', 'Medicaid', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Morphine', 'Opioid', 'Outcome', 'Overdose', 'Pain', 'Patients', 'Pattern', 'Pennsylvania', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Prescription opioid overdose', 'Prevalence', 'Reporting', 'Research', 'Risk', 'Risk Factors', 'Severities', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'Substance Use Disorder', 'Techniques', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Urine', 'Work', 'base', 'beneficiary', 'cancer genomics', 'classification trees', 'clinical predictors', 'combat', 'design', 'dosage', 'high risk', 'innovation', 'learning strategy', 'milligram', 'model building', 'nonmedical use', 'novel', 'opioid epidemic', 'opioid mortality', 'opioid overdose', 'opioid use', 'overdose risk', 'prediction algorithm', 'predictive modeling', 'prescription opioid', 'prescription opioid abuse', 'prescription opioid misuse', 'prevent', 'programs', 'random forest', 'service utilization', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2019,588500,570146095,-0.005130443529411879
"Optical Body Composition and Health Assessment ﻿    DESCRIPTION (provided by applicant):1 Of all markers of human health, the most intuitive is body shape but based on quantitative evidence.  2 Anthropometry and regional composition measures such as waist circumference (WC), waist to hip ratio  3 (WHR), and visceral adipose tissue area (VAT) are better predictors of obesity-related diseases and mortality  4 risk than body mass index (BMI). Dual-energy X-ray absorptiometry (DXA) can quantify regional adiposity in  5 more detail than the above measures but is underutilized for many reasons including potential harm from  6 ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments  7 in the ""quantified self movement"" to better describe phenotypes of body shape and its relation to metabolic  8 risks. The candidate developed in this proposal is 3D optical whole body scanning. If successful, sophisticated  9 obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with 10 disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment 11 technology. Whole body 3D imaging technology is already so accessible that it can be done with video games 12 such as the Microsoft Xbox Kinect, and consumer cameras. 13 The long term goal of the Optical Body Shape and Health Assessment Study is 1) to provide phenotype 14 descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in 15 research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive 16 models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, 17 muscle mass, lean mass, and percent fat), and then show how our 3DO body composition estimates are 18 associated to important metabolic risk factors. Our central hypothesis is that 3DO measures of body 19 composition with shape classification better predict metabolic risk factors than anthropometry or DXA body 20 composition alone. Our specific aims are: 1. Identify the unique associations of body shape to body 21 composition indices in a population that represents the variance of sex, age, BMI, and ethnicity found 22 in the US population; 2. Describe the precision and accuracy of 3DO scans to monitor change in body 23 composition and metabolic health interventions; and 3. Estimate the level of association of 3DO to 24 common health indicators including metabolic risk factors by gender, race, age, and BMI. In an 25 exploratory aim, we investigate holistic, high-resolution descriptors of 3D body shape as direct 26 predictors of body composition and metabolic risk using statistical shape models and Latent Class 27 Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self- 28 assessment technologies that are capable of representing over 95% of the shape variance in the US 29 population, and how these models relate to important metabolic status and body composition. The positive 30 impact will be the immediate applicability to clinicians and individuals for personalized risk assessment. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because they have the potential to provide a better understanding of who is at high risk of metabolic diseases because of a poor metabolic profile. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Optical Body Composition and Health Assessment,9736686,R01DK109008,"['3-Dimensional', 'Adipose tissue', 'Adult', 'Age', 'Animals', 'Anorexia Nervosa', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Classification', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Devices', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Ethnic Origin', 'Fatty acid glycerol esters', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Individual', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Personal Satisfaction', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Video Games', 'Visceral', 'Visceral fat', 'Waist-Hip Ratio', 'bariatric surgery', 'base', 'clinical practice', 'cost', 'disorder prevention', 'disorder risk', 'health assessment', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolic profile', 'metabolomics', 'mortality', 'mortality risk', 'muscle form', 'optical imaging', 'predictive modeling', 'public health relevance', 'sensor', 'sex', 'subcutaneous', 'tool', 'waist circumference', 'whole body imaging']",NIDDK,UNIVERSITY OF HAWAII AT MANOA,R01,2019,610346,45734163,0.017842522954837608
"Infrared Eyes(iREyes) Infrared Eyes Abstract Eden Medical, Inc. is pleased to resubmit this Phase 2 SBIR proposal to develop the “Infrared Eyes” (iREyes) imager system, an affordable and powerful mobile health (mHealth) tool for healthcare. The hand-held iREyes system will acquire both thermal and visible spectrum imagery to quantify healing via thermal indexing methodology. The iREyes will offer a user-friendly product with automated categorization. Diabetic foot wounds are common, complex and costly. Foot areas that are likely to ulcerate are associated with increased local skin temperature due to inflammation and enzymatic autolysis of tissue. Inflammation is characterized by the cardinal signs including redness, swelling, and heat. In addition to identifying inflammation associated with healing, the iREyes will also identify hot spots associated with repetitive stress to reduce ulceration and re-ulceration risk for people in diabetic foot remission. The iREyes will directly quantify inflammation pathophysiology implementing a powerful revised two-part strategy: wound healing via regional foot index analysis and ulcer reoccurrence risk through temperature asymmetry threshold analysis. The combined thermal indexing for healing existing wounds and asymmetry predictive analysis represents a significant breakthrough over current practice. Infrared Eyes Narrative To develop a low-cost mobile health (mHealth) infrared imaging system that acquires both thermal and visible spectrum imagery to quantify diabetic foot ulcer healing via thermal indexing and risk prediction with temperature asymmetry methodology.",Infrared Eyes(iREyes),9782901,R44DK102244,"['Agreement', 'Algorithms', 'Amputation', 'Area', 'Autolysis', 'Automation', 'Blood flow', 'California', 'Caring', 'Catalogs', 'Chronic', 'Clinical', 'Clinics and Hospitals', 'Collaborations', 'Complex', 'Consult', 'Data Analyses', 'Data Analytics', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Foot', 'Diabetic Foot Ulcer', 'Diagnosis', 'Discipline of Nursing', 'Disease remission', 'Electronic Health Record', 'Electronics', 'Evaluation', 'Eye', 'Functional disorder', 'Funding', 'Gifts', 'Grant', 'Hand', 'Hawaii', 'Health', 'Healthcare', 'Hospitals', 'Hot Spot', 'Image', 'Image Analysis', 'Imagery', 'Impairment', 'Inflammation', 'Inflammatory', 'Lead', 'Legal patent', 'Length', 'Licensing', 'Limb structure', 'Los Angeles', 'Lower Extremity', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Methodology', 'Methods', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Outpatients', 'Pain', 'Patients', 'Pattern', 'Phase', 'Physicians', 'Redness', 'Risk', 'Sales', 'Services', 'Shapes', 'Skin Temperature', 'Small Business Innovation Research Grant', 'Spottings', 'Stress', 'Swelling', 'System', 'Tablets', 'Technology', 'Temperature', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'Ulcer', 'United States', 'United States National Institutes of Health', 'Universities', 'Width', 'Work', 'Wound Healing', 'base', 'commercialization', 'computerized data processing', 'cost', 'design', 'diabetic patient', 'foot', 'healing', 'human subject', 'imager', 'imaging system', 'improved', 'indexing', 'mHealth', 'medical schools', 'off-patent', 'portability', 'programs', 'prototype', 'spectrograph', 'tool', 'user-friendly', 'web portal', 'wound']",NIDDK,"EDEN MEDICAL, INC.",R44,2019,613367,467010,-0.001634573261634572
"An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis Project Summary  Improved methods for the bedside diagnosis and evaluation of neuromuscular disorders are needed. One technology that is finding increasing use for this purpose is electrical impedance myography (EIM). In EIM, a very weak, high frequency electrical current is passed through a muscle of interest and the resulting surface voltages are measured. Disease associated alterations in the composition and microstructural features of the muscle produce characteristic changes that can be used to help classify specific conditions and grade disease severity. To date, most studies using EIM analysis have utilized a fairly limited data set for disease assessment. While effective, this approach ignores a great deal of information locked within the impedance data, including those values that can assist in predicting specific muscle features (such as myofiber diameter) and the presence of pathological change (e.g., fat or connective tissue deposition). In addition, as it stands, the data set is challenging for the clinician to understand without a detailed knowledge of impedance theory. Myolex, Inc is a small business concern located in Boston, MA has as its main focus the development of EIM technologies for clinical use. Myolex recently completed a Phase 1 SBIR that demonstrated the potential capability of machine learning based classification algorithms to effectively discriminate healthy muscle from diseased and to discriminate one disease from another. In this proposed work, we will greatly advance this concept by embodying classification algorithms into a powerful new software suite for Myolex’s current EIM system, the mView. Our underlying hypothesis is that EIM data analysis can be automated to the point that classification systems can provide data on disease diagnosis as well as disease severity for improved ease-of-use. We propose to study this hypothesis via 2 specific aims. In Specific Aim 1, we will design a software suite capable of assisting with artifact-free data collection to be incorporated into our current EIM system, the mViewTM. Then using classification paradigms based on a prodigious amount of previous collected data, we will develop an automated data analysis tool to help provide data on disease category as well as microscopic features, muscle based on the impedance data alone using Microsoft’s Azure Cloud platform. In Specific Aim 2, we will test this developed software suite in a total of180 adult and pediatric neuromuscular disease patients and healthy participants evaluated at Ohio State University Wexner Medical Center (adults) and Boston Children’s Hospital (children). During this data collection period, the Ohio State and Boston Children’s researchers will have real- time access to Myolex staff to provide feedback and have questions/problems answered and addressed. The user interface will continue to be refined and classification algorithms improved. At the conclusion of this work, a new diagnostic tool will be developed for potential 510(k) FDA approval. It will serve as the basis for a continuously self-refining system as additional data sets are collected by end-users employing them in regular clinical use. Project Narrative  Electrical impedance myography (EIM) is a valuable technique to assist with the evaluation of a variety of conditions affecting nerve and muscle. However, to date, only simplistic EIM outcomes have been utilized to assess muscle condition. In this proposed work, we will develop a software platform using machine learning to be incorporated into current EIM technology to allow for automated diseased classification and characterization using the entire large EIM data set collected with each muscle measurement. This will serve as the basis for a new, powerful and convenient tool for neuromuscular diagnosis that will continue to advance over time.",An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis,9846955,R44NS113756,"['Address', 'Adult', 'Affect', 'Algorithmic Software', 'Amyotrophic Lateral Sclerosis', 'Area', 'Back Pain', 'Boston', 'Businesses', 'Caliber', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Classification', 'Clinical', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Set', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Duchenne muscular dystrophy', 'Effectiveness', 'Electrodes', 'Ensure', 'Evaluation', 'Fatty acid glycerol esters', 'Feedback', 'Fiber', 'Frequencies', 'Functional disorder', 'Health', 'Inclusion Body Myositis', 'Individual', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Medical Technology', 'Medical center', 'Methods', 'Microscopic', 'Morphologic artifacts', 'Muscle', 'Muscular Dystrophies', 'Myography', 'Myopathy', 'Myositis', 'Nerve', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Ohio', 'Outcome', 'Participant', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Provider', 'Radiculopathy', 'Research Personnel', 'Role', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Work', 'base', 'classification algorithm', 'cloud based', 'cloud platform', 'commercialization', 'data acquisition', 'design', 'diagnosis evaluation', 'disease classification', 'disease diagnosis', 'electric impedance', 'improved', 'indexing', 'interest', 'machine learning algorithm', 'method development', 'nerve injury', 'neuromuscular', 'novel diagnostics', 'pediatric patients', 'physical therapist', 'prototype', 'sarcopenia', 'software development', 'success', 'theories', 'tool', 'usability', 'user friendly software', 'user-friendly', 'voltage']",NINDS,"MYOLEX, INC.",R44,2019,621318,869698,0.0026180114810748565
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,9713512,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Catalogs', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2019,647706,560644462,0.004180472926484033
"Shape up! Kids Project Summary/Abstract Of all markers of pediatric health, the most intuitive is body shape. Human and animal studies indicate that weight loss/gain correlates closely with increasing/decreasing insulin sensitivity, respectively. Anthropometry and regional composition measures such as waist circumference, waist to hip ratio (WHR), and visceral adipose tissue area are better predictors of obesity-related diseases and mortality risk than pediatric body mass index Z-score. Dual-energy X-ray absorptiometry can quantify regional adiposity in more detail than these measures but is underutilized for many reasons including the sensitivity to children to ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments in optical technology to better describe phenotypes of pediatric body shape and its relation to metabolic risks (obesity, “failure to thrive”) and bone density and size. If successful, sophisticated obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment technology. The long term goal of the Shape Up! Kids Study is 1) to provide pediatric phenotype descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, muscle mass, lean mass, and percent fat) and bone mineral density (BMD) over a wide range of ages (5 to 18 years), weights and heights, stratified by sex, and ethnicity. Our central hypothesis is that optical estimates with shape classification of soft tissue composition and bone density better predict fracture and metabolic risk factors than anthropometry (WC, WHR, and BM) alone. The Investigators will highly leverage existing data from the National Health and Nutrition Examination Survey and Bone Mineral Density in Children Study. Our specific aims are: 1) Identify the unique associations of body shape to body composition and bone density indices in a pediatric population that represents the variance found in the US population, 2) Describe the precision and accuracy of optical scans to monitor change in body composition, bone density, 3) Estimate the level of association of optical scans to common health indicators including metabolic risk factors. Our exploratory aim is to investigate holistic, high-resolution descriptors of 3D body shape as direct predictors of body composition and metabolic risk using statistical shape models and Latent Class Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self-assessment technologies that are capable of representing over 95% of the shape variance in the US pediatric population, and to define how these models relate to important metabolic status indicators. The positive impact of these outcomes will be the immediate applicability to other researcher studies and clinicians using the automated tools and models developed here for 3D optical images. PROJECT NARRATIVE  The proposed research is relevant to public health because they have the potential to provide a better understanding of what children are at high risk of metabolic consequences of obesity. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults, and are becoming epidemic in children as well. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Shape up! Kids,9623952,R01DK111698,"['3-Dimensional', 'Adipose tissue', 'Adult', 'Age', 'Algorithms', 'Animals', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Surface', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Bone Density', 'Child', 'Childhood', 'Classification', 'Clinical', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Epidemiology', 'Ethnic Origin', 'Failure to Thrive', 'Fatty acid glycerol esters', 'Fracture', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Liver', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'Muscle', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Pediatric Radiology', 'Personal Satisfaction', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Factors', 'Safety', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Visceral', 'Visceral fat', 'Waist-Hip Ratio', 'Weight', 'bone', 'clinical practice', 'cost', 'disorder prevention', 'disorder risk', 'handheld mobile device', 'health assessment', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolomics', 'mortality', 'mortality risk', 'muscle form', 'optical imaging', 'predictive modeling', 'sensor', 'sex', 'soft tissue', 'subcutaneous', 'tool', 'waist circumference']",NIDDK,UNIVERSITY OF HAWAII AT MANOA,R01,2019,653196,45734163,0.021316360644854374
"PREMIERE: A PREdictive Model Index and Exchange REpository The confluence of new machine learning (ML) data-driven approaches; increased computational power; and access to the wealth of electronic health records (EHRs) and other emergent types of data (e.g., omics, imaging, mHealth) are accelerating the development of biomedical predictive models. Such models range from traditional statistical approaches (e.g., regression) through to more advanced deep learning techniques (e.g., convolutional neural networks, CNNs), and span different tasks (e.g., biomarker/pathway discovery, diagnostic, prognostic). Two issues have become evident: 1) as there are no comprehensive standards to support the dissemination of these models, scientific reproducibility is problematic, given challenges in interpretation and implementation; and 2) as new models are put forth, methods to assess differences in performance, as well as insights into external validity (i.e., transportability), are necessary. Tools moving beyond the sharing of data and model “executables” are needed, capturing the (meta)data necessary to fully reproduce a model and its evaluation. The objective of this R01 is the development of an informatics standard supporting the requisite information for scientific reproducibility for statistical and ML-based biomedical predictive models; from this foundation, we then develop new computational approaches to compare models' performance. We begin by extending the current Predictive Model Markup Language (PMML) standard to fully characterize biomedical datasets and harmonize variable definitions; to elucidate the algorithms involved in model creation (e.g., data preprocessing, parameter estimation); and to explain the validation methodology. Importantly, models in this PMML format will become findable, accessible, interoperable, and reusable (i.e., following FAIR principles). We then propose novel meth- ods to compare and contrast predictive models, assessing transportability across datasets. While metrics exist for comparing models (e.g., c-statistics, calibration), often the required case-level information is not available to calculate these measures. We thus introduce an approach to simulate cases based on a model's reported da- taset statistics, enabling such calculations. Different levels of transportability are then assigned to the metrics, determining the extent to which a selected model is applicable to a given population/cohort (i.e., helping answer the question, can I use this published model with my own data?). We tie these efforts together in our proposed framework, the PREdictive Model Index & Exchange REpository (PREMIERE). We will develop an online portal and repository for model sharing around PREMIERE, and our efforts will include fostering a community of users to guide its development through workshops, model-thons, and other activities. To demonstrate these efforts, we will bootstrap PREMIERE with predictive models from a targeted domain (risk assessment in imaging-based lung cancer screening). Our efforts to evaluate these developments will engage a range of stakeholders (model developers, users) to inform the completeness of our standard; and biostatisticians and clinical experts to guide assessment of model transportability. PROGRAM NARRATIVE With growing access to information contained in the electronic health record and other data sources, the appli- cation of statistical and machine learning methods are generating more biomedical predictive models. However, there are significant challenges to reproducing these models for purposes of comparison and application in new environments/populations. This project develops informatics standards to facilitate the sharing and reproducibil- ity of these models, enabling a suite of comparative methods to evaluate model transportability.",PREMIERE: A PREdictive Model Index and Exchange REpository,9712304,R01EB027650,"['Access to Information', 'Address', 'Algorithms', 'Area', 'Attention', 'Bayesian Network', 'Big Data', 'Biological Markers', 'Calibration', 'Characteristics', 'Clinical', 'Communities', 'Computational Biology', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Decision Making', 'Decision Trees', 'Dermatology', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Ecosystem', 'Educational workshop', 'Electronic Health Record', 'Environment', 'Evaluation', 'FAIR principles', 'Fostering', 'Foundations', 'Goals', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Language', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Medical', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Ophthalmology', 'Pathway interactions', 'Performance', 'Population', 'Publications', 'Publishing', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Reporting', 'Reproducibility', 'Reproduction', 'Research Personnel', 'Risk Assessment', 'Source', 'Techniques', 'Testing', 'Training', 'Validation', 'Variant', 'Work', 'base', 'bioimaging', 'biomarker discovery', 'case-based', 'cohort', 'collaborative environment', 'comparative', 'computer aided detection', 'convolutional neural network', 'data sharing', 'deep learning', 'design', 'experience', 'indexing', 'innovation', 'insight', 'interest', 'interoperability', 'learning network', 'learning strategy', 'lung basal segment', 'lung cancer screening', 'mHealth', 'model development', 'novel', 'novel strategies', 'predictive modeling', 'prognostic', 'repository', 'software repository', 'statistics', 'stem', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2019,657823,673201228,-0.004955055395781981
"Accelerating phage evolution and tools via synthetic biology and machine learning Summary Phages, which are the naturally evolved predators of bacteria, may hold the key to combating bacterial pathogens, including the looming threat of multidrug resistant bacteria. Phages are viruses which while harmless to humans and have been successfully engineered as tools to separate, concentrate, and detect their bacterial hosts. Additionally, phages have been used as therapeutic agents to treat patients infected with pathogens resistant to known antibiotics. While the potential benefits of phages are numerous, certain limitations must be addressed in order to fully employ them. The central hypothesis of this proposal is that both top-down and bottom-up approaches can be utilized to design and synthesize novel phages, through a combination of synthetic biology and machine learning. This will result in phage-based tools with increased functionality and customizable host ranges. The rationale for the proposed research is that as the threat of bacterial infections including those with multi-drug resistance continues to grow, phages, which have evolved to efficiently recognize and kill bacteria, will become indispensable tools. Therefore, the ability to rapidly design and engineer new phages for biosensing and therapeutics will be a critical advantage to human health. The proposal contains three specific aims which are supported by preliminary data and cited literature. Aim 1: Site-directed conjugation for advanced phage-based biosensors and therapeutics. Under this aim, phages will be modified with alkyne-containing unnatural amino acids allowing their direct conjugation to 1) azide decorated magnetic nanoparticles, and 2) azide terminated polyethylene glycol. The modifications will allow the development of magnetic phages for bacteria separation and detection, and phages that are more effective therapeutics due to their ability to avoid a patient’s innate immune response, respectively. Aim 2: Decoding phage biorecognition elements using machine learning. In this aim, machine learning will be used to model the binding of phages and their bacterial hosts. The model will enable the prediction of host interactions as well as allow the design and synthesis of novel phage tail fibers which can target specific bacterial isolates. Aim 3: Repurposing phage biorecognition for a broader host ranges. Under the final aim, phage-binding proteins will be replaced with those known to recognize conserved regions of the bacterial LPS, resulting in a phage with a much broader host range. This approach is innovative because it uses top-down characterizations for bottom-up design and synthesis of novel phages. Traditional phage screening methods will be replaced with the rapid synthesis of phages, which are optimized for a particular bacterial isolate. Following the successful completion of the specific aims, the expected outcome is the design and synthesis of phages that can be used to target a selected group of bacteria within Enterobacteriaceae for advanced biosensing and therapeutics. A publically available computer model will allow rapid design of custom phage biorecognition elements which can be added to functionalized phages. These technologies will allow researchers to tip the scales of the co-evolutionary arms race between phage and bacteria. Narrative The project is relevant to public health because it accelerates the development of phage-based tools for the rapid detection of bacterial pathogens in human, food, and environmental samples, and the treatment of diseases from multidrug resistant bacteria by integrating machine learning and synthetic biology. Thus, it is specifically relevant to part of NIH's mission that pertains to the diagnosis, prevention, and cure of human diseases.",Accelerating phage evolution and tools via synthetic biology and machine learning,9714883,R01EB027895,"['Acinetobacter baumannii', 'Address', 'Alkynes', 'Amino Acid Sequence', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Azides', 'Bacteria', 'Bacterial Genome', 'Bacterial Infections', 'Bacteriophage T4', 'Bacteriophages', 'Binding', 'Binding Proteins', 'Biosensing Techniques', 'Biosensor', 'CRISPR/Cas technology', 'Capsid', 'Chemistry', 'Clinical', 'Computer Simulation', 'Consumption', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Drug resistance', 'Elements', 'Engineering', 'Enterobacteriaceae', 'Environment', 'Escherichia coli', 'Evolution', 'Family', 'Fiber', 'Food', 'Future', 'Genes', 'Genome', 'Goals', 'Health', 'Human', 'Infection', 'Innate Immune Response', 'Innate Immune System', 'Intervention', 'Life', 'Literature', 'Machine Learning', 'Magnetic nanoparticles', 'Magnetism', 'Methods', 'Mission', 'Modeling', 'Modification', 'Multi-Drug Resistance', 'Multidrug-resistant Acinetobacter', 'Multiple Bacterial Drug Resistance', 'Natural Immunity', 'Outcome', 'Patients', 'Phenotype', 'Polyethylene Glycols', 'Prevention', 'Process', 'Property', 'Public Health', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Site', 'Specificity', 'Surface', 'System', 'Tail', 'Technology', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Efficacy', 'United States National Institutes of Health', 'Viral', 'Virus', 'arm', 'base', 'combat', 'design', 'human disease', 'innovation', 'next generation', 'novel', 'pathogen', 'pathogenic bacteria', 'rapid detection', 'receptor', 'resistance mechanism', 'screening', 'synthetic biology', 'tool', 'unnatural amino acids']",NIBIB,CORNELL UNIVERSITY,R01,2019,666637,91477866,-0.026397049707333826
"Leveraging Social Media Data and Machine Learning to Optimize Treatment Paradigms for Youth with Schizophrenia Abstract Schizophrenia constitutes a chronic and disabling illness. While patients show high rates of response to treatment after a ﬁrst-episode of schizophrenia, the long-term course of the illness is typically characterized by frequent re- lapses, persistence of symptoms, and enduring cognitive and functional deﬁcits. Despite the prioritization of relapse prevention as a treatment goal, about four out of ﬁve patients experience a relapse within the ﬁrst ﬁve years of treatment. Relapses are known to have serious psychosocial, educational, or vocational implications in young adults—a population at high risk of psychosis. However, current psychiatric ability to recognize indicators of relapse in order to prevent escalation of psychotic symptoms is markedly limited. Challenges stem from a lack of availability of comprehensive information about early warning signs, and reliance on ﬁxed time point sampling of cross-sectional data as well as patient or family reported observations, that is subject to recall bias, or on clin- ician sought information, that needs frequent and timely contact. The present proposal seeks to address these gaps in early psychosis treatment, by leveraging patient-generated and patient-volunteered social media data, and developing and validating machine learning approaches for “digital phenotyping” and relapse prediction. Our proposed work is founded on the observation that social media sites have emerged as prominent platforms of emotional and linguistic expression—young adults are among the heaviest users of social media. The work signif- icantly advances the research agenda and extensive pilot investigations of the team, who a) have demonstrated that social media data of individuals can serve as a powerful “lens” toward understanding and inferring mental health state, illness course, and likelihood of relapse, including among young adults with early psychosis; and b) have been involved in examining the role of emergent technologies, like social media, in improving access to and delivery of psychiatric care. Aim 1 will provide theoretically-grounded and clinically meaningful methods for extracting and modeling digital phenotypes and symptoms from social media data of young adult early psychosis patients. Then in Aim 2, we will develop and evaluate machine learning methods that will utilize the extracted social media digital phenotypes to infer patient-speciﬁc personalized risk of relapse, and identify its antecedents. Finally, Aim 3 will develop a two-faceted validation framework, to assess the statistical and clinical efﬁcacy and utility of the social media derived inferences of psychosis and relapse in inﬂuencing clinical outcomes and in facilitating evidence-based treatment. To accomplish these aims, the project brings together a strong multidisci- plinary team, combining expertise in social media analytics, psychiatry, psychology, natural language analysis, machine learning, information privacy, and research ethics. Our novel approach offers unprecedented opportuni- ties to initiate the adoption of personalized, responsive, and preemptive evidence-based strategies in treatment of psychosis. The knowledge will set the stage for future research on launching large-scale trials aimed to develop interventions that diminish the severity of relapses, or prevent their occurrence altogether. Project Narrative Timely monitoring of symptoms and preventing relapse after an initial psychotic episode are essential component of early intervention programs and have a critical impact on long term outcome in individuals with psychotic dis- orders. Employing patient-contributed social media data as a viable source of collateral information, this proposal provides a suite of robust, scalable, and ﬁeld evaluated machine learning methods to facilitate early and precise identiﬁcation of digital phenotypes, symptomatic exacerbation, and risk of psychotic relapse in early psychosis patients. The knowledge would provide the necessary opportunity to initiate personalized, adaptive, and proac- tive illness management strategies, inform better nosology, and assist the adoption of improved evidence-based care approaches to diminish the severity of relapses, or prevent their occurrence altogether.",Leveraging Social Media Data and Machine Learning to Optimize Treatment Paradigms for Youth with Schizophrenia,9739933,R01MH117172,"['Address', 'Adolescent and Young Adult', 'Adopted', 'Adoption', 'Affect', 'Aftercare', 'Behavior', 'Behavioral', 'Big Data', 'Biometry', 'Caring', 'Chronic', 'Circadian Rhythms', 'Clinical', 'Clinical Data', 'Clinical Psychology', 'Clinical Research', 'Clinical Trials', 'Cognition', 'Cognitive', 'Computational Technique', 'Computers', 'Computing Methodologies', 'Data', 'Data Collection', 'Deterioration', 'Development', 'Disorientation', 'Doctor of Philosophy', 'Early Diagnosis', 'Early Intervention', 'Emerging Technologies', 'Emotional', 'Evaluation', 'Evidence based treatment', 'Family', 'Feedback', 'Foundations', 'Goals', 'Health', 'Hospitalization', 'Improve Access', 'Individual', 'Intervention', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methods', 'Monitor', 'Moods', 'National Institute of Mental Health', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Phenotype', 'Population', 'Privacy', 'Psychiatric therapeutic procedure', 'Psychiatry', 'Psychology', 'Psychotic Disorders', 'Relapse', 'Reporting', 'Research', 'Research Ethics', 'Research Methodology', 'Risk', 'Role', 'Sampling', 'Schizophrenia', 'Scientist', 'Severities', 'Site', 'Social Functioning', 'Social Psychology', 'Source', 'Stigmatization', 'Strategic Planning', 'Suicide', 'Surface', 'Symptoms', 'Techniques', 'Testing', 'Texas', 'Theoretical model', 'Time', 'Universities', 'Validation', 'Violence', 'Work', 'Youth', 'base', 'biological research', 'biomarker development', 'clinical decision support', 'clinical efficacy', 'clinical heterogeneity', 'cohort', 'computational basis', 'deep learning', 'digital', 'digital media', 'digital models', 'disability', 'disease classification', 'disorder later incidence prevention', 'evidence base', 'experience', 'first episode schizophrenia', 'high risk', 'improved', 'innovative technologies', 'intervention program', 'learning strategy', 'lens', 'medical complication', 'multidisciplinary', 'natural language', 'novel', 'novel strategies', 'peer', 'personalized intervention', 'prevent', 'prospective', 'psychosocial', 'psychotic symptoms', 'recruit', 'relapse patients', 'relapse prediction', 'relapse risk', 'response', 'social', 'social media', 'stem', 'support tools', 'treatment optimization', 'treatment response', 'treatment strategy', 'volunteer', 'willingness', 'young adult']",NIMH,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2019,682250,45341731,-0.006612492035219154
"Contextualized daily prediction of lapse risk in opioid use disorder by digital phenotyping PROJECT SUMMARY Opioid use disorder is increasingly widespread, leading to devastating consequences and costs for patients and their families, friends, and communities. Available treatments for opioid and other substance use disorders (SUD) are not successful at sustaining sobriety. The vast majority of people with SUD relapse within a year. Critically, they often fail to detect dynamic, day-by-day changes in their risk for relapse and do not adequately employ skills they developed or take advantage of support available through continuing care. The broad goals of this project are to develop and deliver a highly contextualized, lapse risk prediction models for forecasting day-by-day probability of opioid and other drug use lapse among people pursuing drug abstinence. This lapse risk prediction model will be delivered within the Addiction-Comprehensive Health Enhancement Support System (A-CHESS) mobile app, which has been established by RCT as a state-of-the-art mHealth system for providing continuing care services for alcohol and substance use disorders. To accomplish these broad goals, a diverse sample of 480 participants with opioid use disorder who are pursing abstinence will be recruited. These participants will be followed for 12 months of their recovery, with observations occurring as early as one week post-abstinence and as late as 18 months post-abstinence across participants in the sample. Well-established distal, static relapse risk signals (e.g., addiction severity, comorbid psychopathology) will be measured on intake. A range of more proximal, time-varying opioid (and other drug use) lapse risk signals will also be collected via participants’ smartphones. These signals include self-report surveys every two months, daily ecological momentary assessments, daily video recovery “check-ins”, voice phone call and text message logs, text message content, moment-by-moment location (via smartphone GPS and location services), physical activity (via smartphone sensors), and usage of the mobile A-CHESS Recovery Support app. The predictive power of these risk signals will be further increased by anchoring them within an inter-personal context of known people, locations, dates, and times that support or detract from participants’ abstinence efforts. Machine learning methods will be used to train, validate, and test opioid (and other drug) lapse risk prediction models based on these contextualized static and dynamic risk signals. These lapse risk prediction models will provide participant specific, day-by-day probabilistic forecast of a lapse to opioid (or other drug) use among opioid abstinent individuals. These lapse risk prediction models will be formally added to the A-CHESS continuing care mobile app at the completion of the project for use in clinical care. These project goals position A-CHESS to make relapse prevention and recovery support, information, and risk monitoring available to patients continuously. Compared to conventional continuing care, A-CHESS will provide personalized care and be available and implemented during moments of greatest need. Integrated real-time risk prediction holds substantial promise to encourage sustained recovery through adaptive use of these continuing care services. PROJECT NARRATIVE The project’s goals are to develop and deliver a real-time model for forecasting day-by-day opioid use lapse among abstinent patients with opioid use disorder. This lapse prediction model will be integrated into an existing, validated mHealth app to encourage sustained recovery through adaptive use of continuing care services.",Contextualized daily prediction of lapse risk in opioid use disorder by digital phenotyping,9818617,R01DA047315,"['Abstinence', 'Acoustics', 'Advertising', 'Affect', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Behavior', 'Caring', 'Cellular Phone', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Comorbidity', 'Data Sources', 'Diagnosis', 'Distal', 'Drug usage', 'Ecological momentary assessment', 'Enrollment', 'Equilibrium', 'Face', 'Facebook', 'Family', 'Foundations', 'Frequencies', 'Friends', 'Gender', 'Goals', 'Health', 'Home environment', 'Individual', 'Intake', 'Location', 'Machine Learning', 'Measures', 'Medical', 'Mental disorders', 'Methods', 'Mobile Health Application', 'Modeling', 'Monitor', 'Narcotics', 'Natural Language Processing', 'Opioid', 'Paper', 'Participant', 'Patient Recruitments', 'Patient Self-Report', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physical activity', 'Positioning Attribute', 'Predictive Analytics', 'Probability', 'Psychopathology', 'Publishing', 'Race', 'Recovery', 'Relapse', 'Risk', 'Risk Factors', 'Sampling', 'Services', 'Severities', 'Signal Transduction', 'Social Environment', 'Social Network', 'Substance Use Disorder', 'Support System', 'Surveys', 'System', 'Telephone', 'Testing', 'Text Messaging', 'Theoretical model', 'Time', 'Training', 'Visual', 'Voice', 'addiction', 'alcohol testing', 'base', 'care providers', 'care systems', 'chronic pain', 'clinical care', 'cost', 'craving', 'digital', 'disorder later incidence prevention', 'drug abstinence', 'experience', 'information gathering', 'innovation', 'learning strategy', 'mHealth', 'meetings', 'microphone', 'mobile application', 'opioid use', 'opioid use disorder', 'overdose death', 'peer', 'personalized care', 'predictive modeling', 'prevent', 'real time model', 'recruit', 'relapse risk', 'risk prediction model', 'rural setting', 'sensor', 'signal processing', 'skills', 'sleep quality', 'sobriety', 'social media', 'stressor', 'suburb']",NIDA,UNIVERSITY OF WISCONSIN-MADISON,R01,2019,683430,338121506,-0.0079482884275895
"Machine learning for the automated identification and tracking of rare myocardial diseases PROJECT SUMMARY Although cardiac amyloidosis and hypertrophic cardiomyopathy (HCM) are relatively rare causes of heart failure (HF), they are particularly challenging to detect and treat for several shared reasons: (1) on routine clinical imaging (i.e., echocardiography [echo]), they can be difficult to distinguish from superficially similar, more common forms of cardiac disease that cause left ventricular (LV) hypertrophy; (2) the diagnoses are often missed and thus patients can present late in the course of disease at a time when treatment is difficult; (3) objective, noninvasive metrics that reliably reflect disease progression have not been identified; and (4) the small number of known patients with these diseases can make epidemiology studies and clinical trials difficult to organize and conduct. For both cardiac amyloidosis and HCM, echo plays a critical role in both diagnosis and longitudinal monitoring given its ubiquitous clinical availability, safety, and low cost. More broadly, echo dominates the current landscape of routine cardiac imaging, with tens of millions of echos performed in the United States each year. However, the clinical challenges described above highlight several shortcomings of echo: it is limited in its ability to (1) diagnose disease at its early stages; (2) discriminate between morphologically similar diseases; and (3) quantify disease progression. This proposal seeks to address deficiencies in the current echo reading workflow, which is subjective and captures only a small fraction of the data available in each study. The overall objective of this application is to use advances in machine learning to develop and validate fully-automated echo image analytic approaches to diagnose and track rare cardiomyopathies, focusing on cardiac amyloidosis and HCM. Our proposal is centered on the hypothesis that highly scalable computer vision methods can be applied to echo studies to overcome limitations of the standard clinical echo reading workflow. Accordingly our aims are: (1) Apply an automated method for echo quantification and disease identification to detect and differentiate cardiac diseases that cause increased LV wall thickness; and (2) Characterize quantifiable echo measures of disease progression in cardiac amyloidosis and HCM and associate these with clinical outcomes. Our multidisciplinary team, which is composed of experts in cardiomyopathies, echocardiography, computer vision, and machine learning, will analyze echos and patient data from 2 large patient registries: the Multicenter Amyloid Phenotyping Study (MAPS) and the Sarcomeric Human Cardiomyopathy Registry (SHaRe) HCM Network, with validation using a repository of nearly 400,000 echos. The successful completion of our aims will result in an innovative tool for early diagnosis of myocardial diseases and tracking of disease progression. Importantly, our project will set the stage for conducting larger epidemiology studies of rare myocardial diseases by automating the identification of these patients, and thereby developing previously unattainable broad-based cohorts for these conditions. PROJECT NARRATIVE Rare heart diseases such as amyloidosis (due to abnormal deposition of a protein into the heart muscle) and hypertrophic cardiomyopathy (due to a genetic mutation) are important causes of heart failure and sudden death in the general population. These heart diseases are difficult to diagnose, monitor, and treat because: (1) they appear superficially similar to more common forms of heart disease (e.g., high blood pressure) on imaging tests; (2) the optimal monitoring of disease progression over time has not been established; and (3) there is a lack of large-scale studies of patients with these diseases given their rarity. This project aims to use machine learning (artificial intelligence) of digital echocardiographic images to create a completely automated method for diagnosing and tracking these rare heart diseases with the ultimate goal of broad deployment of artificial intelligence algorithms in hospitals and clinics to help identify patients with these rare heart diseases earlier, better predict adverse outcomes, and increase the size and scope of patient registries to enhance research of these conditions.",Machine learning for the automated identification and tracking of rare myocardial diseases,9838368,R01HL140731,"['Address', 'Affect', 'Algorithm Design', 'Algorithms', 'Amyloid', 'Amyloidosis', 'Arrhythmia', 'Artificial Intelligence', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular system', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Clinics and Hospitals', 'Cohort Studies', 'Communities', 'Comorbidity', 'Computer Vision Systems', 'Coronary heart disease', 'DNA Sequence Alteration', 'Data', 'Deposition', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Echocardiography', 'Face', 'General Population', 'Goals', 'Heart Diseases', 'Heart failure', 'Hospitalization', 'Human', 'Hypertension', 'Hypertrophic Cardiomyopathy', 'Image', 'Image Analysis', 'Individual', 'Inherited', 'Left', 'Left Ventricular Hypertrophy', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Monitor', 'Morphology', 'Myocardium', 'Outcome', 'Output', 'Patients', 'Phenotype', 'Play', 'Process', 'Proteins', 'Reader', 'Reading', 'Registries', 'Research', 'Research Personnel', 'Role', 'Safety', 'Standardization', 'Structure', 'Sudden Death', 'Symptoms', 'Testing', 'Thick', 'Time', 'Two-Dimensional Echocardiography', 'United States', 'Validation', 'Ventricular', 'adverse outcome', 'automated image analysis', 'base', 'career', 'clinical care', 'clinical imaging', 'cohort', 'cost', 'digital', 'disease diagnosis', 'epidemiology study', 'heart imaging', 'hypertensive heart disease', 'image processing', 'innovation', 'interest', 'multidisciplinary', 'novel therapeutics', 'particle', 'patient registry', 'repository', 'response', 'tool']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2019,687155,327644200,-0.009600534532977562
"Olfactory and facial markers of developmental risk for psychosis in 22q11 deletion syndrome Project Summary: 22q11.2 deletion syndrome (22q11DS) is associated with an increased risk for psychiatric disorders, including psychosis with similar symptoms to individuals with idiopathic schizophrenia (SZ), and about 1-2% of cases of idiopathic SZ have 22q11.2 deletions. Thus, targeted approaches detailing specific brain dysfunction in 22q11DS may elucidate critical neural mechanisms in psychosis. Specifically, approaches that capture abnormalities common to individuals at-risk for psychosis and with a genetic risk to psychosis, such as 22q11DS, may help explain risk and resilience for psychosis. Minor physical anomalies (MPAs) are phenotypic abnormalities of aberrant development. MPAs include subtle abnormalities of morphological structures encompassing numerous body parts including eyes, ears, mouth and head. Abnormalities of the face and head likely represent a disruption of early embryologic development, including the olfactory system and facial morphology, making these promising entry points for understanding neurodevelopmental neuropathology associated with 22q11DS and psychosis In this study, we seek to compare 1) measures of olfactory function; 2) structural abnormalities of the olfactory system and 3) structural abnormalities of the face in a large cohort of patients with 22q11DS (n=100), including those with and without psychosis, to typically developing (TD) individual. Finally, we will employ machine learning algorithms to select features that best differentiate 22q11DS+ from 22q11DS- and use those features to classify individual with idiopathic risk for psychosis (PS). In addition, analyses will leverage recent advances in machine learning to predict salient features associated with dimensional measures of psychosis. We believe this innovative approach can significantly advance our understanding of the etiology of psychosis and provide advances to precision medicine in psychiatry. Through the proposed multi-level analysis, this innovative research will provide a substantial advance in our understanding of the neurodevelopmental substrates of psychosis. RELEVANCE: Psychosis is a debilitating psychiatric condition. Greater understanding of how abnormalities in neural development lead to dysfunction during youth and produce symptoms of psychosis or psychosis risk may be critical for the conceptualization of earlier and more effective treatments. This would benefit public health by reducing the great costs of psychosis to individuals and society at large.",Olfactory and facial markers of developmental risk for psychosis in 22q11 deletion syndrome,9885029,R01MH119185,"['22q11.2', '3-Dimensional', 'Acoustic Rhinometry', 'Behavioral', 'Biometry', 'Body part', 'Brain region', 'Characteristics', 'Classification', 'Clinical', 'Craniofacial Abnormalities', 'Data', 'Development', 'Diffuse', 'Dimensions', 'Distress', 'Dysmorphology', 'Ear', 'Etiology', 'Event', 'Exhibits', 'Eye', 'Face', 'Functional disorder', 'Genetic Diseases', 'Genetic Risk', 'Geometry', 'Head', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mandible', 'Measures', 'Medial', 'Mental disorders', 'Minor', 'Modeling', 'Morphology', 'Nasal cavity', 'Neurobiology', 'Nose', 'Odors', 'Olfactory Cortex', 'Olfactory Pathways', 'Oral cavity', 'Patients', 'Performance', 'Peripheral', 'Phenotype', 'Process', 'Psychiatry', 'Psychophysics', 'Psychotic Disorders', 'Public Health', 'Research', 'Risk', 'Sampling', 'Schizophrenia', 'Severities', 'Smell Perception', 'Societies', 'Structural defect', 'Structure', 'Symptoms', 'Syndrome', 'Techniques', 'Temporal Lobe', 'Testing', 'Three-Dimensional Imaging', 'Work', 'Youth', 'associated symptom', 'base', 'behavior measurement', 'brain dysfunction', 'clinically relevant', 'cohort', 'conotruncal anomaly face syndrome', 'cost', 'effective therapy', 'functional outcomes', 'genetic disorder diagnosis', 'high risk', 'improved', 'innovation', 'machine learning algorithm', 'microdeletion', 'multilevel analysis', 'neurodevelopment', 'neuromechanism', 'neuropathology', 'olfactory bulb', 'olfactory sulcus', 'precision medicine', 'psychotic symptoms', 'resilience', 'trait']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2019,746845,593605914,-0.013476451689977034
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9754269,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Anti-Tumor Necrosis Factor Therapy', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Big Data', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Individual', 'Injury', 'Institution', 'Intuition', 'Leukocyte Chemotaxis', 'Lymphocyte Immunophenotypings', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Myocardial', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Sampling', 'Series', 'Stains', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'analysis pipeline', 'base', 'clinical diagnostics', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'education resources', 'human disease', 'improved', 'inquiry-based learning', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2019,794562,3808719,-0.0007807124647791958
"Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease PROJECT SUMMARY / ABSTRACT Cardiovascular disease (CVD) is the single largest killer in the United States for both men and women in every racial/ethnic group. Thus, accurate and systematic evaluation of CVD risk represents an aspect of Precision Medicine that will touch every patient. CVD risk scores that are currently the standard of care are derived from research cohorts and are particularly inaccurate in women, older patients, and those with missing data. The goal of this Precision Medicine based application is to capitalize on the depth and breadth of clinical data within electronic health record (EHR) systems to revolutionize CVD risk prediction, thereby optimizing personalized care for every patient. Our proposed approach is innovative in that we have identified and addressed the most significant barriers to development of an EHR-based risk score. Novel aspects of this research include: 1) use of complete EHR data to develop and validate algorithms to define a variety of risk factors (e.g., reproductive history), thus building a comprehensive risk profile for each patient that incorporates diagnosis and procedure codes, laboratory values, clinical test results, patient provided information (e.g., alcohol use), and natural language processing of unstructured clinical text; 2) incorporation of age at onset of risk factors; 3) use of highly flexible machine learning techniques in the form of generalized boosted regression modeling; 4) exploration of a new deep learning model for censored EHR data; and 5) determination of the extent of risk reclassification in multiple geographically-defined populations, including an underserved minority population. Furthermore, genetic studies demonstrate that incorporating variants into current risk models improves risk prediction and use of an individual's genetic risk could further enhance our ability to deliver precision medicine to every patient. Therefore, we seek to develop a sex-specific next-generation CVD risk prediction score using EHR data in combination with genetic variants. This paradigm is a significant departure from the current one that relies on scores derived from relatively small research cohorts that use only a restricted set of clinical parameters that differentially misclassify an individual's risk, especially in women. Our access to empirical clinical EHR data for hundreds of thousands of patients uniquely positions us to 1) develop a sex-specific risk prediction model for incident CVD using data from the EHR; 2) assess the performance of the sex-specific EHR risk score in an independent non-urban and rural population; and 3) identify and characterize patients for whom genetic information improves CVD prediction beyond the clinical risk score. Successful completion of these aims has the potential to impact all adult patients, drive clinical practice changes to systematically collect sex-specific risk factors, and inform attempts to embed the next-generation CVD risk score into EHR systems for automated use in clinical care. PROJECT NARRATIVE Cardiovascular disease (CVD) is the single largest killer in the United States. We propose to use electronic health record data to improve our ability to accurately classify risk and identify those who would benefit from preventive therapies. Improved risk prediction will shed light on the mechanisms of CVD and potentially reduce incidence, save lives, and lower health care costs.",Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease,9610723,R01HL136659,"['Address', 'Adult', 'Age', 'Alcohol consumption', 'Algorithms', 'Cardiovascular Diseases', 'Clinical', 'Clinical Data', 'Clinics and Hospitals', 'Code', 'Communities', 'Community Hospitals', 'County', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Ethnic group', 'Evaluation', 'Event', 'Genetic Risk', 'Genetic study', 'Geography', 'Goals', 'Health', 'Health Care Costs', 'Hybrids', 'Incidence', 'Individual', 'Laboratories', 'Latino', 'Light', 'Machine Learning', 'Minnesota', 'Modeling', 'Natural Language Processing', 'Not Hispanic or Latino', 'Patients', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevention strategy', 'Preventive', 'Preventive therapy', 'Procedures', 'Reproducibility', 'Reproductive History', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Rural', 'Rural Population', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Touch sensation', 'United States', 'Variant', 'Wisconsin', 'Woman', 'base', 'biobank', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'clinical care', 'clinical practice', 'clinical risk', 'cohort', 'deep learning', 'electronic data', 'flexibility', 'genetic information', 'genetic panel test', 'genetic variant', 'improved', 'innovation', 'men', 'next generation', 'novel', 'older patient', 'personalized care', 'precision genetics', 'precision medicine', 'prospective', 'racial and ethnic', 'research clinical testing', 'risk prediction model', 'sex', 'standard of care', 'time use', 'underserved minority']",NHLBI,MAYO CLINIC ROCHESTER,R01,2019,794994,276703803,-0.03352772916320478
"Evolution of Psychosis in Youth: Multimodal Risk and Resilience Markers PROJECT SUMMARY Efforts at early identification of individuals at risk for psychosis are propelled by the realization that psychosis is neurodevelopmental, with brain and behavioral abnormalities anteceding diagnosis of schizophrenia (SZ) by years. As longer duration of untreated psychosis portends poor outcome, early identification is important to bend the developmental trajectory in a favorable direction. Since most current studies of psychosis risk are based on help-seeking samples, there is a gap in knowledge on how psychosis unfolds in diverse community samples. While it is generally recognized that genomic and environmental factors (GxE) contribute to risk for psychosis, there is a paucity of complementary integrative studies that can chart causal pathways. Genomic “case-control” GWAS studies of SZ identified multiple common alleles permitting calculation of a polygenic risk score (PRS). Recently, increased attention has been given to childhood adversity related to SZ. The goal of the proposed R01 is to build on our genotyped ~10,000 Philadelphia Neurodevelopmental Cohort (PNC) of 8 to 21 years old youths studied in 2009-2011, where we are following those who meet criteria or are at risk for psychosis (PS) and typically developing (TD) participants, whose current age range is 15-30 years. Available multi-level “deep phenotyping” includes clinical, neurocognition and multi-modal neuroimaging on a subsample of ~1600. We have developed a preliminary environmental risk score (ERS) and will use it to dissect GxE. The proposed followup design will recruit PS and TD participants with the highest and lowest scorers (quartile) on the ERS, and within each of these four cells we will examine 120 individuals, 60 males and 60 females (total N=480). This sample will be examined clinically, neurocognitively and with multimodal neuroimaging. We will test the hypothesis that genomic vulnerabilities, based on PRS and family history, and environmental adversity, based on ERS, updated longitudinally, affect onset and course of PS by altering brain development in temporolimbic regions affecting fronto-limbic connectivity that underlies social functioning. We will augment current data with information on risk and resilience and multimodal brain-behavior parameters to establish developmental trajectories during this critical period of brain maturation when psychosis emerges. Our aims are: 1. Examine effects of ERS on PS clinical features and progression in relation to PRS. 2. Investigate brain- behavior parameters that bridge from genetic and environmental factors to clinical manifestations. 3. Establish developmental trajectories for PS features, associated brain parameters and neurocognitive deficits, and apply novel computational models to enable an adaptive “risk and resilience calculator”. The proposed study will produce the data absent for a diverse US community sample but needed to move psychiatry into the precision medicine era. The project will inform on genomic and environmental risk and resilience indicators, offering an essential rung in the ladder toward individualized prediction, a part of implementation science. As with the PNC, data and associated algorithms will be a resource shared with the scientific community. PROJECT NARRATIVE The proposed R01 aims to bridge genomic, environment and phenotypic brain-behavior measures to advance the understanding of risk and resilience to psychosis. We will build on informative samples of the Philadelphia Neurodevelopmental Cohort and integrate multidimensional behavioral measures of psychosis and cognition, multimodal neuroimaging parameters of brain structure, function and connectivity, environmental parameters, and genomic variations in risk for schizophrenia. Computational modeling will aim at developing risk and resilience predictors, essential for early identification and intervention during a dynamic period of brain maturation.",Evolution of Psychosis in Youth: Multimodal Risk and Resilience Markers,9838618,R01MH119219,"['21 year old', 'Address', 'Affect', 'African American', 'Age', 'Algorithms', 'Alleles', 'Attention', 'Behavioral', 'Benign', 'Brain', 'Cells', 'Childhood', 'Clinical', 'Clinical assessments', 'Cognition', 'Cognitive', 'Communities', 'Computer Simulation', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early Intervention', 'Early identification', 'Environment', 'Environmental Risk Factor', 'Epigenetic Process', 'Evaluation', 'Evolution', 'Family', 'Family history of', 'Female', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Heterogeneity', 'Image', 'Individual', 'Knowledge', 'Language', 'Lead', 'Linear Regressions', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Neurocognition', 'Neurocognitive', 'Neurocognitive Deficit', 'Neurosciences', 'Outcome', 'Participant', 'Pathway interactions', 'Performance', 'Phenotype', 'Philadelphia', 'Positioning Attribute', 'Process', 'Psychiatry', 'Psychotic Disorders', 'Public Domains', 'Race', 'Recording of previous events', 'Resource Sharing', 'Resources', 'Risk', 'Sampling', 'Schizophrenia', 'Severities', 'Sex Differences', 'Social Functioning', 'Structure', 'Symptoms', 'System', 'Testing', 'Update', 'Work', 'Youth', 'aged', 'base', 'behavior measurement', 'brain behavior', 'case control', 'childhood adversity', 'cohort', 'critical period', 'data anonymization', 'design', 'early adolescence', 'emerging adult', 'follow-up', 'genome wide association study', 'genomic variation', 'help-seeking behavior', 'high risk', 'implementation science', 'improved', 'innovation', 'learning strategy', 'machine learning algorithm', 'male', 'multidisciplinary', 'multimodality', 'neuroimaging', 'novel', 'personalized predictions', 'precision medicine', 'predictive modeling', 'predictive test', 'recruit', 'resilience', 'sex', 'social']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2019,795608,593605914,-0.028098614996700095
"Safety Promotion through Early Event Detection in the Elderly (SPEEDe) ABSTRACT Adverse events (AEs) – harm to patients that results from medical care – affect as many as 13.5% of hospitalized patients; half of these AEs are preventable and AEs particularly affect the elderly. AEs are notoriously difficult to measure accurately. A variety of paper and electronic trigger tools have been developed to identify AEs; however, their positive predictive value (PPV) is low, requiting subsequent, time-intensive manual chart review to accurately measure AEs. In the proposed project, we will use innovative, state-of-the-art machine interactive learning (IML) techniques to refine existing AE triggers, improving their accuracy substantially. We will also develop a novel AE Explorer to speed review of possible AEs, as well as an innovative package of predictive analytics tools and methods to measure and detect them. Our approach combines and compares expert-driven improvement with the most recent IML techniques to make triggers more accurate, with the ultimate goal of creating triggers that are accurate enough to stand in as proxies for actual measurement of harm. We call our approach Safety Promotion through Early Event Detection in the Elderly, or SPEEDe. Our team of accomplished machine learning, patient safety, risk management, AE detection, geriatric medicine and trigger tool experts will work together to carry out the specific aims of this project: (1) prototype and rapidly iterate a trigger review dashboard (the Adverse Event Explorer) using a user-centered design process, (2) develop and evaluate novel Interactive Machine Learning approaches for more efficient and accurate adverse event chart review and trigger refinement, and (3) Integrate Interactive Machine Learning into the Adverse Event Explorer and evaluate it prospectively in a clinical setting. PROJECT NARRATIVE Adverse events – harm to patients that results from medical care – are common and difficult to identify and measure using existing tools. Accurate real-time measures of adverse events would enable organizations to track harm over time, identify and prioritize areas for safety improvements, evaluate whether patient safety programs are effective, and communicate risks of harm to patients and caregivers. Through SPEEDe, we will develop an innovative machine- learning approach for accurately detecting adverse events in the elderly in real-time.",Safety Promotion through Early Event Detection in the Elderly (SPEEDe),9711286,R01AG062499,"['Active Learning', 'Adopted', 'Adverse event', 'Affect', 'Area', 'Benchmarking', 'Caregivers', 'Caring', 'Cessation of life', 'Clinical', 'Computer software', 'Detection', 'Elderly', 'Environment', 'Event', 'Feedback', 'Foundations', 'Frequencies', 'Geriatrics', 'Goals', 'Gold', 'Grant', 'Hospitals', 'Human', 'Human Resources', 'Incentives', 'Intuition', 'Learning', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Memory', 'Minority', 'Modeling', 'Paper', 'Patients', 'Performance', 'Personal Satisfaction', 'Policies', 'Predictive Analytics', 'Predictive Value', 'Process', 'Proxy', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Management', 'Safety', 'Sampling', 'Screening procedure', 'Speed', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Woman', 'Work', 'analytical method', 'analytical tool', 'base', 'biomedical informatics', 'cost', 'dashboard', 'detector', 'forging', 'hands-on learning', 'health information technology', 'improved', 'innovation', 'iterative design', 'learning strategy', 'novel', 'open source', 'patient safety', 'prevent', 'programs', 'prospective', 'prototype', 'supervised learning', 'tool', 'user centered design']",NIA,BRIGHAM AND WOMEN'S HOSPITAL,R01,2019,802341,327644200,-0.013889371710414157
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,9737676,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Quality', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2019,804907,593605914,-0.008123160752214382
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,9724344,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Streptococcus pyogenes', 'Streptococcus vaccine', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2019,872121,46216755,-0.030429162375384178
"Development and validation of an electronic health record prediction tool for first-episode psychosis Psychosis is a major public health challenge, with approximately 100,000 adolescents and young adults in the US experiencing a first episode of psychosis (FEP) every year. Early intervention following FEP is critical for achieving improved outcomes, yet treatment of FEP is often delayed between 1 and 3 years in the US due to delays in detection and referral. The World Health Organization has advocated shortening the duration of untreated psychosis (DUP) to three months or less. The goal of this study is to develop and validate a universal EHR-based screening tool for early detection of FEP across large clinical populations in diverse healthcare settings. In order to maximize the impact and generalizability of the tool across a wide range of healthcare settings, we will rely only on coded medical information collected in the course of care and thus widely available in EHRs. The tool will be developed and validated with data from three diverse health systems that cover over 8 million patients spanning a wide range of demographic, socioeconomic and ethnic backgrounds: Partners Healthcare System, Boston Children's Hospital, and Boston Medical Center. The study will be conducted by a closely collaborating interdisciplinary team of clinical specialists, psychosis researchers, and risk modeling experts based at these health systems and Harvard Medical School, with extensive experience in treating psychosis patients, and developing strategies for detecting FEP and EHR-based risk screening tools for early detection of various clinical conditions. Our preliminary studies show that EHR-based risk models can be used to sensitively and specifically detect FEP cases, on average 2 years before the first psychosis diagnosis appears in their EHR. Our specific aims include: 1. Define a robust cross-site case definition for FEP that relies only on information commonly available in EHRs and validate it through expert chart review; 2. Train and validate a predictive model for early detection of FEP based on large samples of patient data from the three sites; 3. Develop and validate FEP early detection models for key subpopulations, including patients receiving care at mental health clinics, adolescent medicine outpatient programs, and substance abuse treatment programs; and 4. Engage clinical stakeholders in the process of developing a prototype clinician-facing EHR-based risk screening tool for FEP, and release it as an open source SMART App, enabling further validation and clinical integration across a wide range of healthcare settings. Completion of these aims would provide a novel, clinically deployable, and potentially transformative tool for improving the trajectory of those affected with psychosis and reducing the burden and costs of untreated illness. Psychosis is a major public health challenge, with difficulties and delays in detecting its onset that can lead to worse clinical outcomes. The proposed research will develop a clinician-facing electronic-health-record-based automated screening tool for early detection of the first episode of psychosis, with implications for reducing the duration of untreated psychosis as recommended by the NIMH and World Health Organization. The tool will be validated across three large and diverse health systems and released as an open source application (SMART App), increasing its potential for rapid implementation in health systems and clinical care.",Development and validation of an electronic health record prediction tool for first-episode psychosis,9660167,R01MH116042,"['Accident and Emergency department', 'Adolescent Medicine', 'Adolescent and Young Adult', 'Advocate', 'Affect', 'Boston', 'Calibration', 'Caring', 'Clinic', 'Clinical', 'Code', 'Communities', 'Data', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Early Intervention', 'Electronic Health Record', 'General Population', 'Goals', 'Health system', 'Healthcare Systems', 'Inpatients', 'Intervention', 'Laboratories', 'Lead', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical center', 'Mental Health', 'Modeling', 'National Institute of Mental Health', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Primary Health Care', 'Procedures', 'Process', 'Psychotic Disorders', 'Public Health', 'Research', 'Research Personnel', 'Research Support', 'Risk', 'Risk Factors', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Specialist', 'Suicide', 'Testing', 'Time', 'Training', 'Validation', 'Work', 'World Health Organization', 'base', 'clinical care', 'cost', 'data resource', 'design', 'experience', 'first episode psychosis', 'health care settings', 'improved', 'improved outcome', 'individual patient', 'interest', 'medical schools', 'medical specialties', 'novel', 'open source', 'outpatient programs', 'predictive modeling', 'prototype', 'random forest', 'socioeconomics', 'substance abuse treatment', 'tool', 'treatment program']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,892010,551214295,-0.009323110597292877
"Familial hypercholesterolemia screening in children: population impact of phenotype, genotype, and cascade approaches Project Summary  Familial hypercholesterolemia (FH) is a common genetic disorder, affecting every 200-1000 people, depending on the population and diagnostic criteria. FH leads to lifetime raised low-density lipoprotein (LDL) cholesterol, a high risk for premature atherosclerosis and downstream coronary heart disease. FH is designated as Tier 1 disease by the Center for Disease Control and Prevention, notably one of only three such diseases, because it is common, is associated with a high risk of premature illness, and is treatable with lifestyle or medications. Great uncertainty exists about the optimal approach to FH screening, which is reflected in conflicting recommendations in national screening guidelines.  We propose to synthesize high quality data from national surveys and population-based cohort studies in a health policy computer simulation model comparing the health and economic value of different FH screening strategies. This study will prioritize the optimal approaches to FH screening in the U.S. population, identifying optimal initial screening age and defining the role of genetic testing in screening.  We have assembled a team of experts in pediatric preventive cardiology, decision analysis, cardiovascular disease epidemiology, population genetics, biostatistics, health economic evaluation, and computer simulation modeling in order to evaluate and compare different FH screening strategies in children and adults. We aim to use this expertise and these methods in order to:   Quantify diagnostic yield, clinical effectiveness, and economic value of universal FH phenotype  screening in childhood or adulthood, and the added value of FH genotype screening   Compare universal FH screening to the alternatives of using family history or a Big Data-based  algorithm to direct targeted screening limited to children and adults with possible FH diagnosis   Quantify the health and economic value of cascade screening families of FH cases  We hypothesize that FH screening in childhood will be the highest value screening strategy in the U.S. population, and that genetic testing will improve diagnosis and treatment decisions most in cases of diagnostic uncertainty (e.g., borderline high cholesterol or absent family history). We hypothesize that a machine-learning algorithm will avoid the costs and complexity of universal screening, while yielding a similar case yield, as long as cholesterol testing is sufficiently common in children.  This study will identify the optimal approach to FH screening in the U.S. population and the most influential data based on current knowledge and set the stage for efficiently designed clinical trials of FH screening. This study will be a test case for the concept of a “precision” population health approach to screening for genetically-determined diseases in the general population. Familial hypercholesterolemia (FH) is a common genetic disorder characterized by lifetime elevated cholesterol, which, if uncontrolled, is associated with premature atherosclerotic cardiovascular disease. Conflicting current national guidelines highlight that the optimal approach to FH screening in the U.S. population is controversial: it is unclear if screening should start in childhood or adulthood, or if it should include genetic testing. We propose to synthesize data from national surveys, high quality cohort studies, and clinical trials of cholesterol lowering interventions in a lifetime cardiovascular disease risk computer simulation model to project the life time health impact of different FH screening approaches and identify optimal screening strategies in children and adults.","Familial hypercholesterolemia screening in children: population impact of phenotype, genotype, and cascade approaches",9661259,R01HL141823,"['Adult', 'Adverse effects', 'Advisory Committees', 'Affect', 'Age', 'Algorithms', 'Atherosclerosis', 'Big Data', 'Biometry', 'Cardiology', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Childhood', 'Cholesterol', 'Clinical Trials', 'Clinical Trials Design', 'Clinical effectiveness', 'Cohort Studies', 'Computer Simulation', 'Conflict (Psychology)', 'Coronary heart disease', 'County', 'Data', 'Data Quality', 'Decision Analysis', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Event', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Future', 'General Population', 'Genetic Diseases', 'Genetic Screening', 'Genetic screening method', 'Genotype', 'Guidelines', 'Health', 'Health Benefit', 'Health Policy', 'Hepatocyte', 'Influentials', 'Intervention', 'Knowledge', 'LDL Cholesterol Lipoproteins', 'Laboratories', 'Life', 'Life Style', 'Low Prevalence', 'Low-Density Lipoproteins', 'Machine Learning', 'Medical Care Costs', 'Methods', 'Mutation', 'Parents', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Population Genetics', 'Prevalence', 'Preventive', 'Preventive service', 'Preventive treatment', 'Proxy', 'Puberty', 'Public Health', 'Randomized Controlled Trials', 'Recommendation', 'Recording of previous events', 'Role', 'Serum', 'Surveys', 'Testing', 'Time', 'Uncertainty', 'Visit', 'Youth', 'base', 'cardiovascular disorder epidemiology', 'cardiovascular disorder risk', 'clinical practice', 'cost', 'cost effective', 'cost effectiveness', 'diagnostic accuracy', 'economic evaluation', 'economic value', 'health economics', 'high risk', 'improved', 'improved outcome', 'learning strategy', 'lifestyle intervention', 'machine learning algorithm', 'models and simulation', 'pediatric patients', 'population based', 'population health', 'premature', 'premature atherosclerosis', 'prevent', 'screening', 'screening guidelines', 'screening program', 'treatment strategy', 'uptake']",NHLBI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,894544,558628098,-0.0667717198593419
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,9748417,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'machine learning algorithm', 'multidisciplinary', 'pathogen', 'point of care', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,991540,51931732,-0.011617114570477842
"IGF::OT::IGF  BIOINFORMATICS SUPPORT FOR THE NIEHS IN DIR & DNTP The purpose of this contract is to provide bioinformatic support to researchers in the Divisions of National Toxicology Program (DNTP) and Intramural Research (DIR) at the National Institute of Environmental Health Sciences (NIEHS). NIEHS researchers conduct studies that produce large amounts of data, varying in size and complexity. Fields of scientific study are diverse and include toxicology, genomics, transcriptomics, high throughput screening (HTS) data and data extraction from diverse text resources. The variety and complexity of NIEHS scientific studies dictates the need for innovative analytical techniques and the development of new software tools. Bioinformatic data analyses are required to support accurate and precise interpretation of study results. Specific bioinformatics needs include data analysis, data mining, creating bioinformatics pipelines for gene expression and pathway analysis and computational support for the vast amount of data collected through studies conducted at NIEHS and NIEHS contract laboratories. n/a",IGF::OT::IGF  BIOINFORMATICS SUPPORT FOR THE NIEHS IN DIR & DNTP,9915697,73201700001C,"['Artificial Intelligence', 'Bioinformatics', 'Biological Assay', 'ChIP-seq', 'Chemical Exposure', 'Chemicals', 'Contractor', 'Contracts', 'DNA Methylation', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Epigenetic Process', 'Evaluation', 'Exons', 'Gene Expression', 'Genes', 'Genomics', 'Informatics', 'Intramural Research', 'Knowledge', 'Laboratories', 'Literature', 'Measures', 'Mining', 'National Institute of Environmental Health Sciences', 'National Toxicology Program', 'Output', 'Pathway Analysis', 'Peer Review', 'Privatization', 'Programming Languages', 'Proteomics', 'Publications', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scientific Evaluation', 'Scientist', 'Series', 'Software Tools', 'Specific qualifier value', 'Technology', 'Text', 'Toxicogenomics', 'Toxicology', 'analysis pipeline', 'bioinformatics tool', 'bisulfite sequencing', 'cheminformatics', 'computational intelligence', 'data integration', 'data mining', 'differential expression', 'high throughput screening', 'innovation', 'meetings', 'metabolomics', 'method development', 'next generation sequencing', 'physical property', 'programs', 'screening', 'technique development', 'transcriptomics', 'whole genome']",NIEHS,"SCIOME, LLC",N01,2019,2464037,2510992,-0.011185990062544433
"Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)? PROJECT SUMMARY The North Coast Conference on Precision Medicine is a national annual mid-sized conference series held in Cleveland, Ohio. The conference series aims to serve as a venue for the continuing education and exchange of scientific ideas related to the rapidly evolving and highly interdisciplinary landscape that is precision medicine research. The topics for each conference coincide with the national conversation and research agenda set by national research programs focused on precision medicine. The 2018 conference is a symposium that will focus on issues related to return of genomic results both in clinical and research settings with an emphasis on diverse populations. The conference will be organized as a traditional format with invited speakers from among national experts for topics ranging from issues returning research results to culturally diverse participants and family members, inclusion of diverse patient and participant populations in the Clinical Sequencing Evidence- Generating Research (CSER) consortium and the Trans-Omics for Precision Medicine (TOPMed) Program, pharmacogenomics-guided dosing and race/ethnicity, strategies used to return results, among others. 2019 and beyond conference topics are being considered from previous symposia attendees and trends in precision medicine research. Odd-numbered year conferences include a workshop component that has previously covered outcome and exposure variable extraction from electronic health records. Future workshop topics being considered include integration of multiple ‘omics, drug response in different populations, pharmacogenomics clinical implementation, precision medicine in cancer, data sharing and informed consent, and the use of apps for recruitment, diagnosis, follow-up, and treatment. Our second major objective of this conference series is the promotion of diversity in the biomedical workforce. It is well-known that the pipeline from training to full professor for women in biomedical research is leaky whereas the pipeline for under-represented minorities is practically non-existent. Drawing from national and local sources, we vet women and under-represented minorities for every invited speaker opportunity, thereby providing valuable career currency and networking opportunities. We will also encourage women and under-represented minorities, particularly at the trainee level, to attend and participate in this conference series to spur interest in pursuing precision medicine research as a career. Overall, the North Coast Conference on Precision Medicine series is a valuable addition to the national conference landscape, and with its unique location and low cost to participants, will serve as an important educational opportunity as precision medicine research accelerates in earnest. PROJECT NARRATIVE The North Coast Conference on Precision Medicine is a yearly fall conference series in Cleveland, Ohio designed as a continuing education forum in the burgeoning area of precision medicine research. The conference brings together national experts on a host of topics ranging from bioethics to bioinformatics to biomedical informatics to speak and lead workshops on timely challenges posed in translating complex genomic and health data into clinical practice. The conference series also serves to promote diversity in the biomedical workforce. This year’s symposium will focus issues related to return of genomic results in both clinical and research settings with an emphasis on diverse populations.",Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)?,9612854,R13HG010286,"['Academic Medical Centers', 'Acceleration', 'African American', 'Area', 'Back', 'Big Data', 'Bioethics', 'Bioinformatics', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Computational Biology', 'Computer Simulation', 'Continuing Education', 'Custom', 'Data', 'Databases', 'Diagnosis', 'Dose', 'Educational workshop', 'Electronic Health Record', 'Ensure', 'Ethnic Origin', 'Family member', 'Funding', 'Future', 'Generations', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidental Findings', 'Informed Consent', 'Institution', 'Knowledge', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mining', 'Names', 'Ohio', 'Outcome', 'PMI cohort', 'Participant', 'Pathogenicity', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Population Heterogeneity', 'Prevention', 'Process', 'Race', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Schedule', 'Science', 'Series', 'Source', 'Surveys', 'Technology', 'Time', 'Training', 'Trans-Omics for Precision Medicine', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Minority', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'Woman', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'clinical care', 'clinical implementation', 'clinical practice', 'clinical sequencing', 'clinically relevant', 'cost', 'cost effective', 'data sharing', 'design', 'falls', 'follow-up', 'forging', 'frontier', 'genome-wide', 'genomic data', 'health data', 'health disparity', 'health information technology', 'incentive program', 'individual patient', 'interest', 'medical specialties', 'multiple omics', 'patient population', 'point of care', 'posters', 'precision medicine', 'programs', 'recruit', 'response', 'science education', 'senior faculty', 'symposium', 'trend']",NHGRI,CASE WESTERN RESERVE UNIVERSITY,R13,2018,10000,197030888,-0.028841216358092326
"MHealth Monitoring of Acoustic and Behavioral Patterns in Bipolar Disorder Across Cultures Abstract: The ability to prioritize individuals for health care based on behavioral and acoustic patterns in speech will allow for efficient use of health care resources. The ability to predict mood states using daily monitoring of acoustics derived from mobile technology provides the basis for a real-time proxy measure of moods and affective states. Identification and monitoring of these and other dimensional features of human disease is the base for anticipating outcomes, offering the future possibility of timely and mitigating interventions. Technological and mHealth methods are well suited for the global health community due to the flexibility and adaptability of the approach; the capacity to reach large numbers of patients can be easily amplified with modest increase in infrastructure. We have developed an accurate prediction model for mood states in bipolar (BP) individuals using machine-learning strategies and established a process that involves preprocessing, feature extraction, and an integrated data analysis of clinical and acoustic data gathered from personal use of a mobile device for up to one year. The results show mood states are predicted with an AUC statistic of 0.74 (mania) and 0.77 (depression). We hypothesize that analyses across cultures will identify common features of illness that can be identified using our methods. BP is ideal for study because of the wide range of mood states and temperamental traits. This study aims to 1) ascertain 30 individuals with BP and 10 healthy controls from Lebanon and a multilingual community in SE Michigan, recording daily acoustic and behavioral data using a smart-phone, all outgoing speech from the device is gathered and all personal digital activity is recorded from the device. We propose to study participants in Lebanon and SE Michigan in order to identify the fundamental acoustic elements of mood variation among bipolar patients. 2) apply integrated computational analyses using static (Gaussian Mixture Models and Support Vector Machines) and dynamic (Hidden Markov Models) modeling of categorical, dimensional and derived features from clinical, acoustic, and behavioral signals; we will compare data from the 15 BP from Lebanon and 15 BP from SE Michigan that have been resident in USA >2 years but originate from a geographical region comparable to Lebanon in language and culture, and 15 American born BP Caucasians (from our current cohort). Our hypothesis is that there are fundamental elements of acoustics that associate with mood states regardless of the culture. The impact is the longitudinal use of mobile technology to passively gather personal data to establish computational models that use extensive individual state and trait data to accurately predict mood and health states. This provides a foundation for predictive modeling that can be integrated into subsequent clinical interventional studies to predict and test causal effects of specific interventions on disease mechanisms. Expertise in clinical, computational, and technology disciplines form the team to realize these goals. This is a study that focuses on the ability of technological methods to detect speech and behavioral patterns in patients with bipolar disorder across cultural boundaries to identify common features that predict mood states. The overall goal is to use computational methods for the early detection of affect and mood changes that will provide the opportunity to monitor mood disorders using common methods regardless of cultural differences.",MHealth Monitoring of Acoustic and Behavioral Patterns in Bipolar Disorder Across Cultures,9566306,R21MH114835,"['Acoustics', 'Address', 'Adherence', 'Affect', 'Affective', 'American', 'Arabs', 'Behavioral', 'Bipolar Disorder', 'Bipolar I', 'Caring', 'Categories', 'Caucasians', 'Cellular Phone', 'Characteristics', 'Clinical', 'Clinical assessments', 'Communities', 'Community Health', 'Computer Analysis', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Databases', 'Depressed mood', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'Discipline', 'Disease', 'Early Diagnosis', 'Elements', 'Emotions', 'Evaluation', 'Foundations', 'Future', 'Gaussian model', 'Geographic Locations', 'Goals', 'Health', 'Health Technology', 'Healthcare', 'Immigrant', 'Immigration', 'Impairment', 'Individual', 'Intervention', 'Intervention Studies', 'Interview', 'Language', 'Lebanon', 'Locales', 'Machine Learning', 'Manic', 'Measures', 'Medical', 'Mental Depression', 'Metadata', 'Methods', 'Michigan', 'Middle East', 'Modeling', 'Monitor', 'Mood Disorders', 'Moods', 'Multilingualism', 'Outcome', 'Participant', 'Pathologic', 'Patient Care', 'Patient Triage', 'Patients', 'Pattern', 'Population', 'Probability', 'Process', 'Protocols documentation', 'Proxy', 'Psychiatric therapeutic procedure', 'Recording of previous events', 'Research Infrastructure', 'Resources', 'Safety', 'Secure', 'Severities', 'Signal Transduction', 'Social Functioning', 'Speech', 'Supervision', 'Symptoms', 'Technology', 'Telephone', 'Temperament', 'Testing', 'Time', 'Universities', 'Variant', 'base', 'bipolar patients', 'cognitive function', 'cohort', 'data management', 'design', 'digital', 'flexibility', 'global health', 'handheld mobile device', 'health data', 'human disease', 'learning strategy', 'lexical', 'lexical processing', 'low and middle-income countries', 'mHealth', 'markov model', 'mobile computing', 'predictive modeling', 'predictive test', 'programs', 'tool', 'trait']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2018,30000,641965656,-0.07281414735705491
"Identifying Children and Teens at Risk for Early Onset Alcohol Use: An Innovative Application of Machine Learning Algorithms to Prevention PROJECT SUMMARY Early onset of alcohol use during adolescence is associated with increased probability of later alcohol dependence, polydrug abuse, victimization, conduct problems, psychiatric comorbidities, and delayed achievement of adult milestones. Methods that yield rapid, accurate, and reliable predictions of which children and teens are at risk for early onset can improve the targeting of prevention interventions and enable the concentration of resources on the most debilitating and costly cases. One promising and untapped approach to this prediction problem is machine learning (also called “statistical learning,” “data mining,” or “predictive modeling”), a class of techniques arising from statistics, computer science, and engineering that seeks to build data-driven predictive algorithms. These techniques are most noticeably distinguished from “traditional” statistical methods (e.g., ordinary least squares regression) by their extreme emphasis on prediction of future cases, rather than explanation of the current data, and thus they may offer dramatic advantages over traditional approaches to identifying which children and teens will develop early onset alcohol use. This proposal will explore the potential contribution of machine learning methods by directly comparing their predictive performance to that of the traditional approach in a large-scale, multisite longitudinal study of the development of early onset alcohol use (N = 731). If machine learning methods do significantly outperform the traditional approach, future directions might include the development and implementation of machine-learning- based screening methods for real-world use. On the other hand, if machine learning methods do not outperform the traditional approach, this will suggest that at least in the context of the present study (i.e., these predictors, timeline, and outcome), machine learning does not improve the prediction of early onset alcohol use. Analyses will investigate whether the performance of machine learning methods varies across the nature of predictor variables use, the age span covered, and the outcome to be predicted. Thus, the current proposal uses an extant longitudinal dataset to carry out two specific aims: (1) Train five different machine learning algorithms and one traditional algorithm (ordinary logistic regression) for predicting later early onset alcohol use in a subset (70%) of the data. (2) Test these six predictive algorithms on the rest (30%) of the data and directly compare their predictive performance in multiple contexts. PROJECT NARRATIVE Prospectively predicting which children and teens are at risk for early onset alcohol use enables targeted implementation of preventive interventions. Machine learning is a promising yet untapped approach that may be well-suited to this task. This study investigates the potential of several machine learning algorithms to contribute to the rapid, accurate, and reliable identification of individuals at risk for early onset alcohol use.",Identifying Children and Teens at Risk for Early Onset Alcohol Use: An Innovative Application of Machine Learning Algorithms to Prevention,9540250,F31AA026768,"['Achievement', 'Address', 'Adolescent', 'Adult', 'Advertising', 'Age', 'Alcohol abuse', 'Alcohol consumption', 'Alcohol dependence', 'Algorithms', 'American', 'Attention', 'Behavioral', 'Child', 'Childhood', 'Classification', 'Cocaine Dependence', 'Comorbidity', 'Data', 'Data Set', 'Dependence', 'Development', 'Engineering', 'Fraud', 'Future', 'Goals', 'Impulsivity', 'Individual', 'Lasso', 'Least-Squares Analysis', 'Logistic Regressions', 'Longitudinal Studies', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Noise', 'Outcome', 'Performance', 'Prevention', 'Preventive Intervention', 'Probability', 'Procedures', 'Public Health', 'Recommendation', 'Research', 'Resources', 'Rest', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Services', 'Statistical Methods', 'Structure', 'Substance abuse problem', 'Techniques', 'Teenagers', 'Testing', 'TimeLine', 'Training', 'Trees', 'Victimization', 'Work', 'addiction', 'alcohol screening', 'base', 'computer science', 'conduct problem', 'cost', 'data mining', 'early alcohol use', 'early onset', 'field study', 'forest', 'improved', 'innovation', 'learning strategy', 'longitudinal dataset', 'multidrug abuse', 'outcome prediction', 'prediction algorithm', 'predictive modeling', 'prevent', 'prospective', 'psychologic', 'screening', 'search engine', 'spam', 'speech recognition', 'statistics', 'success', 'underage drinking', 'vector']",NIAAA,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,F31,2018,44524,51931732,-0.08846070337748821
"Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients Failure to rescue (FTR), a nurse-sensitive national metric of health care quality, refers to death of a hospitalized patient from a treatable complication, and is potentiated by failure to recognize and appropriately respond to early signs of complications. There is a paucity of research examining patient features predictive of FTR complications. Such information could shift the current paradigm of nursing surveillance to earlier recognition, prevention and treatment of FTR complications, thereby saving lives. New-onset venous thromboembolism (VTE), an FTR complication occurring as either a deep vein thrombosis (DVT) or a pulmonary embolism (PE), is the leading cause of preventable hospital death, carrying a high risk of mortality and a national cost burden of $7 billion annually. VTE is a complex disease process involving interactions between clinical risk factors and acquired and/or inherited susceptibilities to thrombosis. Although biomarkers and clinical factors associated with VTE have been identified, clinical manifestations are subtle, presenting gradually over hours to days. Current VTE risk assessment models (RAM), the cornerstone of prevention, have limited utility due to their complexity and lack of reliability, generalizability and external validation. A critical gap in VTE risk modeling research is that while new-onset VTE pathology evolves over the course of hospitalization, no current models incorporate the progressive accrual of dynamic patient data and pattern evolution over time in their modeling approaches. The totality of routinely collected electronic health record (EHR) data is massive in terms of volume, variety, and production at a rapid velocity in real-time. Such big data could be used in machine learning (ML) analytic approaches to process time series clinical data to identify subtle, evolving feature patterns predictive of new-onset VTE and address this gap. This study proposes to assemble a large scale, multi-source, multi-dimensional VTE study dataset, and in tandem, systematically define the EHR data elements associated with a new-onset VTE diagnosis for computable phenotype algorithm development. We will then apply machine learning analytic approaches to baseline and accruing intensive time series clinical data in the curated dataset to develop models identifying data patterns and features predictive of dynamically evolving new-onset VTE in adult hospitalized patients. This proposal aligns with NINR’s strategic vision for nurse scientists to employ new strategies for collecting and analyzing complex big data sets to permit better understanding of the biological underpinnings of health, and improve ways nurses prevent and manage illness. This innovative study and individualized training plan under a strong and well- established team, represents initial steps in the applicant’s research trajectory focused on data science approaches to predict FTR complication risk, and develop, implement and test dynamic RAMs to inform targeted prevention and treatment decisions. Discovering new knowledge informing real-time decision making, nursing surveillance practices and care delivery systems can improve nurse sensitive patient outcomes. PROJECT NARRATIVE Venous thromboembolism (VTE) is the leading cause of preventable hospital death. This study first proposes to develop a reproducible computable phenotype definition for new-onset VTE cohort ascertainment from the electronic health record, and then develop dynamic models for VTE risk assessment through the application of machine learning algorithms to massive electronic health record clinical data repositories. Such models can inform the mechanisms underlying this complex disease and identify subtle pattern changes in a patient’s condition forecasting a VTE event, enabling earlier nurse identification and intervention, and decreasing the development of complications and failure to rescue in hospitalized patients.",Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients,9610301,F31NR018102,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Big Data', 'Biological', 'Biological Markers', 'Censuses', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Cohort Studies', 'Complex', 'Complication', 'Data', 'Data Element', 'Data Science', 'Data Set', 'Decision Making', 'Deep Vein Thrombosis', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Electronic Health Record', 'Event', 'Evolution', 'Failure', 'Frequencies', 'Future', 'Genetic Predisposition to Disease', 'Gold', 'Health', 'Hospitalization', 'Hospitals', 'Hour', 'Human', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Link', 'Logic', 'Machine Learning', 'Manuals', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Pathology', 'Patient Triage', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Prevention', 'Process', 'Production', 'Pulmonary Embolism', 'Quality of Care', 'Readability', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Savings', 'Scientist', 'Selection for Treatments', 'Sensitivity and Specificity', 'Series', 'Signs and Symptoms', 'Source', 'Standardization', 'System', 'Testing', 'Thromboembolism', 'Thrombosis', 'Time', 'Training', 'Treatment Failure', 'Validation', 'Venous', 'Vision', 'base', 'care delivery', 'clinical data warehouse', 'clinical decision-making', 'clinical risk', 'cohort', 'cost', 'disease phenotype', 'health care quality', 'high risk', 'improved', 'innovation', 'interest', 'mortality', 'prevent']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F31,2018,44524,570146095,-0.005670731667408527
"Prediction of short-term risk of coronary heart disease and overall risk of ischemic cardiomyopathy PROJECT SUMMARY/ABSTRACT  Coronary heart disease (CHD) is the leading cause of morbidity and mortality worldwide. In the United States, although mortality from CHD has declined over recent decades, the incidence of CHD has remained high. This year, nearly 600,000 Americans will experience their first myocardial infarction (MI) and a larger number will have undiagnosed ischemia. Both groups are at risk of developing ischemic cardiomyopathy (ICM), which compounds the burden of morbidity and mortality they face. Efforts to prevent CHD and its complications like ICM have been hampered by poor patient adherence, which is in large part due to misperceptions of risk. Patients are more likely to engage in preventive behaviors if they know their risk of disease, particularly if their risk is imminent. However, although several models estimate long-term risk of CHD over the next 10 years, there are no established models for predicting short-term risk of CHD within a one year time frame. Likewise, among patients with CHD, there are no existing models to assess the overall risk of coexisting ICM. To address these knowledge gaps in the field, I will build robust prediction models by applying the latest machine learning algorithms to the recently available large datasets comprising the UK Biobank and the Veterans Affairs (VA) cohorts.  In Aim 1, I will examine the 477,000 UK Biobank participants without preexisting CHD to develop a prediction model for one-year risk of new onset CHD. I will use several different machine learning algorithms, compare their respective predictive performances, and select the best-performing and most clinically applicable model. I will also compare the risk classification ability of this new model with existing long-term risk prediction models such as the Framingham and Atherosclerotic Cardiovascular Disease (ASCVD) risk scores.  In Aim 2, I will apply machine learning techniques to a large VA patient cohort consisting of over 300,000 patients with known coronary anatomy and left ventricular systolic function to develop a prediction model for the presence of ICM. In light of the two primary mechanisms for ischemic cardiomyopathy, irreversible myocyte loss from MI and hibernating myocardium from chronic ischemia, I will perform a stratified analysis by history of prior MI to determine if the risk factors for ICM vary depending on whether the pathological mechanism is infarction versus ischemia.  An improved understanding of the predictors of CHD and ICM will lead to insights into the biological basis of ischemic heart disease. Moreover, accurate identification of individuals who are at imminent risk for CHD and its complication, ICM, is of central importance to efforts in preventing cardiovascular disease. PROJECT NARRATIVE Coronary heart disease and its complications such as ischemic cardiomyopathy are the global leading cause of morbidity and mortality, and an improved ability to assess risk along this continuum of ischemic heart disease is urgently needed. I will apply the latest machine learning techniques to the recently available large datasets comprising the UK Biobank and VA cohorts to develop robust prediction models for short-term risk of coronary heart disease and overall risk of ischemic cardiomyopathy. My work is anticipated to yield important insights into the biological basis of ischemic heart disease and to improve preventive measures for public health.",Prediction of short-term risk of coronary heart disease and overall risk of ischemic cardiomyopathy,9609396,F32HL143848,"['Address', 'Admission activity', 'Algorithms', 'American', 'Anatomy', 'Atherosclerosis', 'Behavior', 'Biological', 'Cardiac Catheterization Procedures', 'Cardiovascular Diseases', 'Chronic', 'Classification', 'Collaborations', 'Complication', 'Computer Analysis', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Data', 'Data Science', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Echocardiography', 'Enrollment', 'Event', 'Face', 'Goals', 'Incidence', 'Individual', 'Infarction', 'Ischemia', 'K-Series Research Career Programs', 'Knowledge', 'Left', 'Light', 'Machine Learning', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Muscle Cells', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardium', 'Participant', 'Pathologic', 'Patient Noncompliance', 'Patient Self-Report', 'Patients', 'Performance', 'Population', 'Prevention', 'Preventive', 'Preventive measure', 'Process', 'Prospective cohort study', 'Public Health', 'Recording of previous events', 'Research Personnel', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Severities', 'Techniques', 'Time', 'United States', 'Ventricular', 'Veterans', 'Work', 'biobank', 'cardiovascular disorder risk', 'career', 'clinical application', 'cohort', 'compliance behavior', 'disorder risk', 'experience', 'follow-up', 'heart disease risk', 'improved', 'insight', 'ischemic cardiomyopathy', 'mortality', 'predictive modeling', 'prevent', 'tool']",NHLBI,STANFORD UNIVERSITY,F32,2018,51162,560644462,0.002475080660435487
"Automatic quantification of myocardial motion in older adults Abstract  Heart failure (HF) is a common condition that represents the end stage of cardiovascular diseases (CVDs) subsequent to progressing myocardial damage or ischemia. In populations at ages 65 and older, coronary artery disease (CAD) serves as the leading cause of HF. Although low left ventricular (LV) ejection fraction (EF) is a major evidence for the diagnosis of HF in clinical practice, impaired regional myocardial dysfunction is expected to present the existence of CAD in its early stage.  Heart deformation analysis (HDA) is a cutting-edge myocardial motion analysis technique that is able to automatically track the myocardium borders on time frames and calculate global and regional cardiac functional and motional indices on existing cine images without extra scans. In the present study, we will use the HDA tool to analyze existing cine images of CHARISMA study. From 2009 to 2012, cardiac MRI exams (including coronary wall imaging and cine MRI at two-chamber, four-chamber and short-axis views) and concurrent tests for traditional cardiovascular risk factors were performed on 440 older participants (age: 65 - 84 years old at the time of MRI scans) without documented history of CVDs. During the present R03 project (2019-2021), CHARISMA participants would have been followed-up for 10 - 12 years. We plan to relate newly- acquired regional myocardial motion indices (displacement, velocity, strain and strain rate) to clinical outcomes, existing coronary wall measures and results of lab tests in CHARISMA datasets. We will test the overall hypothesis that regional myocardial motion indices have the potential to present cardiovascular risk in asymptomatic elderly. Three specific aims are: 1) Predict cardiovascular events using baseline regional myocardial motion indices; 2) Relate regional myocardial motion indices to MRI-derived features of coronary remodeling; and 3) Determine correlations between regional myocardial motion indices and traditional cardiovascular risk biomarkers/conditions collected in CHARISMA study.  No new MRI scans or lab tests are required in this project. Through a cost-effective approach, the immediate objective of the proposed project is to evaluate the clinical value of regional myocardial motion for cardiovascular risk stratification in asymptomatic older adults, a major target population of cardiovascular prevention. This study will also help us better understand the correlations between impaired myocardial function/motion and subclinical CAD burden. Furthermore, the results will facilitate the selection of quantitative imaging biomarkers and their optimal cut-off points for predicting cardiovascular events in future clinical studies. Project Narrative  In the present study, we will use heart deformation analysis (HDA) to reanalyze existing cardiac MRI data of CHARISMA study. The goal of the present study was to test the hypothesis that regional myocardial motion indices have the potential to predict cardiovascular risk in older adults.",Automatic quantification of myocardial motion in older adults,9647817,R03HL144891,"['Adopted', 'Age', 'Area', 'Artificial Intelligence', 'Biological Markers', 'Biomechanics', 'C-reactive protein', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chicago', 'Cine Magnetic Resonance Imaging', 'Clinical', 'Clinical Research', 'Comorbidity', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Echocardiography', 'Elderly', 'Event', 'Functional disorder', 'Funding', 'Future', 'Gelatinase B', 'Goals', 'Heart', 'Heart failure', 'Hypertension', 'Image', 'Impairment', 'Incidence', 'Individual', 'LDL Cholesterol Lipoproteins', 'Left', 'Left Ventricular Ejection Fraction', 'Left Ventricular Mass', 'Left ventricular structure', 'Longitudinal observational study', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Angiography', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Medicine', 'Methods', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial dysfunction', 'Myocardium', 'National Heart, Lung, and Blood Institute', 'Older Population', 'Outcome', 'Participant', 'Patients', 'Pattern', 'Peroxidases', 'Population', 'Prevention', 'Prospective Studies', 'Protocols documentation', 'Radial', 'Recording of previous events', 'Research Project Grants', 'Risk', 'Risk stratification', 'Scanning', 'Series', 'Smoking', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Ventricular', 'base', 'burden of illness', 'cardiovascular risk factor', 'clinical practice', 'coronary plaque', 'cost', 'cost effective', 'design', 'diabetic patient', 'follow-up', 'healthy aging', 'heart damage', 'human old age (65+)', 'human subject', 'imaging biomarker', 'improved', 'indexing', 'myocardial damage', 'quantitative imaging', 'tool']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R03,2018,79000,367414121,-0.023931384571718048
"Innovative text-mining tools to accelerate citation screening: comparative efficiency and impact on conclusions Project Summary Systematic reviews (SRs) synthesize and critically assess bodies of evidence to produce a comprehensive unbiased assessment of what is known. As such, SRs are vital for evidence-based decision-making. However, given the pace of new research, the process of developing an SR remains too slow. One particularly time-consuming step in the process is citation screening, which requires manual review of thousands of abstracts to identify only a small number of relevant studies. Screening such large numbers of studies is necessary because systematic reviewers place a high priority on identifying all relevant studies to avoid bias. Innovative citation screening tools, which utilize text-mining and new sophisticated machine learning methods, represent one potential solution. Abstrackr (Brown University) and EPPI-Reviewer (University College London) are off- the-shelf, web-based citation screening tools designed to improve screening efficiency. Both programs utilize machine- learning techniques to semi-automate the screening process by modeling the probability that each citation will meet criteria for inclusion. This allows efficiency gains through screening prioritization and screening truncation. With screening prioritization, citations are organized for screening from highest to lowest likelihood of inclusion. This allows earlier retrieval of full-text articles and facilitates workflow planning. Organizing citations by likelihood of inclusion also allows reviewers the option of truncating the screening process when remaining citations fall below a certain threshold. While promising, existing studies have predominantly been performed by computer scientists testing individual tools or comparing different modeling algorithms (e.g., various classifiers). To date, no studies have performed a direct comparison of citation screening tools. Similarly, although automatically excluding citations that fall below particular thresholds could substantively improve efficiency, adoption has been low due to concerns that relevant studies could be missed. However, how often studies would be missed and how important such omissions would be remains unknown. To address these knowledge gaps, this project will (1) Compare screening efficiency for two citation-screening tools, Abstrackr and EPPI-reviewer, and (2) Characterize the potential impact of using thresholds to exclude low probability studies automatically. To address aim 1, using citations from 3 large and 6 small completed evidence reports, we will compare Abstrackr to EPPI-Reviewer for citation screening. Using screening prioritization, we will assess what proportion of articles must be screened to identify all included studies (e.g., to achieve 100% sensitivity). For Aim 2, we will explore the potential impact of excluding all citations that fall below particular thresholds during the screening process. We will also assess to what extent missing these studies would alter report conclusions. By characterizing potential efficiency gains from new, innovative, and widely accessible tools, this project can facilitate wider adoption by evidence based practice centers seeking to speed systematic review production. Project Narrative Systematic reviews provide a comprehensive, unbiased assessment of a body of literature and are vital for timely, evidence-based decision-making. However, development of systematic reviews remains too slow, with one particularly time-consuming step being citation screening, in which thousands of research abstracts are manually reviewed to identify a small number of relevant studies. By testing potential gains in citation screening efficiency offered by two innovative, widely-accessible machine- learning tools (Abstrackr and EPPI–Reviewer), and determining if automatically excluding studies to improve speed compromises report conclusions, we hope to enable more rapid production of systematic reviews to inform clinicians and policy-makers and promote high quality, evidence-based patient care.",Innovative text-mining tools to accelerate citation screening: comparative efficiency and impact on conclusions,9435231,R03HS025859,[' '],AHRQ,ECRI INSTITUTE,R03,2018,95324,0,-0.04947635857779185
"Schizophrenia Comorbidities: Common Genes and Clusters The vastly reduced life expectancy in schizophrenia is primarily due to medical comorbidities, yet these are often overlooked in a research context. Numerous psychiatric and somatic diagnoses have increased rates in schizophrenia, and the majority of schizophrenia patients have comorbid conditions. Since lifestyle factors and medication side-effects likely contribute to many of these increased medical problems, it has been difficult to resolve the extent to which shared biological underpinnings contribute to comorbid conditions. The aims for this proposal will be accomplished using data from the Genomic Aggregation Project in Sweden (GAPS) with >200k genotyped subjects and comprehensive medical and demographic information from the Swedish National Registers. This wealth of information allows for additional clinical risk from schizophrenia-associated variants to be captured. In Aim 1, carriers of previously identified schizophrenia risk variants without this diagnosis will be studied for increased risk of diagnoses across multiple psychiatric and somatic domains compared to non-carriers using logistic regression. Furthermore, comorbidities may offer clues to the pathophysiological mechanisms leading to different forms of schizophrenia. With this in mind, comorbid conditions will be leveraged to define schizophrenia subtypes in Aim 2 using the >5000 cases in the Swedish Schizophrenia Study within GAPS. Following cluster analysis using comorbidities, validity will be assessed by testing for group differences in genetic and clinical variation. These studies will yield new insights into the relationships between schizophrenia and other medical conditions, and identify subtypes of schizophrenia that will facilitate personalized medical care. Comorbidities are a fundamental feature of schizophrenia and may arise due to shared biological foundations, deleterious lifestyle factors or combinations of these influences. This study explores the origins of these comorbidities by studying the extent to which genetic risk for schizophrenia in unaffected individuals impacts risk for other psychiatric or somatic diagnoses. Furthermore, in a population with schizophrenia, patterns of comorbidity will be leveraged to identify subtypes with etiological and clinical significance.",Schizophrenia Comorbidities: Common Genes and Clusters,9506887,R21MH116188,"['Address', 'Adverse effects', 'Biological', 'Cardiovascular Diseases', 'Caring', 'Clinical', 'Cluster Analysis', 'Comorbidity', 'Data', 'Data Collection', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Etiology', 'Foundations', 'Gene Cluster', 'Genes', 'Genetic', 'Genetic Carriers', 'Genetic Risk', 'Genomics', 'Genotype', 'Individual', 'Knowledge', 'Life Expectancy', 'Logistic Regressions', 'Medical', 'Mental disorders', 'Mind', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Post-Traumatic Stress Disorders', 'Prevention', 'Research', 'Risk', 'Route', 'Schizophrenia', 'Sweden', 'Testing', 'Tissues', 'Variant', 'clinical care', 'clinical risk', 'clinically significant', 'cost effective', 'disorder subtype', 'genomic data', 'insight', 'lifestyle factors', 'pleiotropism', 'risk variant', 'societal costs']",NIMH,KAROLINSKA INSTITUTE,R21,2018,135778,1346985,-0.014676411296394373
"Obesity Prevention in Early Life (OPEL): Risk Screening and Targeted Intervention Given the difficulty of reversing obesity once present, there has been increasing focus on the primary prevention of obesity early in the lifecourse. Few attempts have been made to prevent obesity during the first years of life. This proposal summarizes a 5-year program of mentored professional development tied to a multi-method research project intended to improve the identification and potential treatment of infants and toddlers with high risk for obesity. My long-term goal is to prevent obesity by identifying infants at greatest risk and providing for them an effective, family-centered intervention that targets modifiable, life course factors. My central hypothesis, based on my prior research, is that identifying infants at risk for obesity prior to the onset of unhealthy weight gain will enable early intervention. My research plan aims to: (1) create risk prediction models for obesity at age 24 months by linking three existing data systems that combine birth certificate, contextual- level, and health outcome data; (2) test the feasibility of linking these data prospectively to validate the Aim 1 obesity risk prediction models over a 24-month period within a contemporary, clinical cohort; and (3) identify best approaches for family-focused risk communication regarding the prevention of excessive weight gain and obesity in infants and toddlers using a human-centered design approach. Through my career development plan and guidance from my mentors, I will expand upon a foundation in epidemiology and pediatric health services research to develop expertise in machine learning, health informatics, data integration, qualitative methods, human-centered design, and behavior change. Together, the research and educational aims of this proposal will provide me with the necessary groundwork to compete for additional funding as an independent investigator. Specifically, I will seek R03-level grant funding from the NIDDK in year 4 of my K01 award to test the communication strategy developed in Aim 3 and to partner with families to modify an existing behavioral change intervention for use in infancy. By the end of this award, I will be well positioned to apply for funding from the NIDDK to conduct a robust R01-level study that combines the validated prediction models, family- focused communication strategy, and modified intervention to determine whether we can effectively prevent obesity in those infants and toddlers identified as being at the highest risk. This line of research will help ensure that prevention efforts are deployed in an efficient, cost-effective manner and accepted by those who need them. I will accomplish this work under the mentorship of Dr. Aaron E. Carroll, a child health services researcher, and a multidisciplinary team of faculty with expertise machine learning, health informatics, data integration and surveillance, qualitative research, human-centered design approaches, behavior change, and childhood obesity. I am ideally suited to complete this research due to my past research productivity, current mentorship team, open access to health care data, and the established clinical decision support infrastructure at the Indiana University School of Medicine. ! Project Narrative Increasing evidence suggests that the infancy and toddler periods represent the best opportunity for obesity prevention, but few attempts have been made to prevent obesity during the first years of life. The current proposal seeks to develop practical methods to assess the risk of future obesity in infants and toddlers in the clinical setting, and to partner with families to explore new ways to communicate early life obesity risk in ways that account for their perceptions, concerns and beliefs. This proposal has the promise to lead to targeted, tailored interventions for infants most at-risk for obesity, ensuring that prevention efforts are deployed in an efficient, cost-effective manner and accepted by those who need them.",Obesity Prevention in Early Life (OPEL): Risk Screening and Targeted Intervention,9526588,K01DK114383,"['Address', 'Age', 'Age-Months', 'Award', 'Behavioral', 'Belief', 'Birth Certificates', 'Child', 'Child Health Services', 'Childhood', 'Clinical', 'Communication', 'Communities', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Support Systems', 'Development', 'Development Plans', 'Early Intervention', 'Early identification', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Epidemiology', 'Faculty', 'Family', 'Foundations', 'Funding', 'Future', 'Geographic Information Systems', 'Goals', 'Grant', 'Health Services Research', 'Health Status', 'Human', 'Indiana', 'Infant', 'Information Systems', 'Intervention', 'K-Series Research Career Programs', 'Lead', 'Life', 'Life Cycle Stages', 'Link', 'Machine Learning', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'National Institute of Child Health and Human Development', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Obesity', 'Outcome', 'Parents', 'Perception', 'Positioning Attribute', 'Pregnancy Histories', 'Prevention', 'Preventive Intervention', 'Primary Prevention', 'Process', 'Productivity', 'Public Health Informatics', 'Publishing', 'Qualitative Methods', 'Qualitative Research', 'Records', 'Research', 'Research Infrastructure', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Risk', 'Risk Factors', 'Source', 'Testing', 'Toddler', 'Universities', 'Weight', 'Weight Gain', 'Work', 'approach behavior', 'base', 'behavior change', 'career development', 'clinical decision support', 'cohort', 'cost effective', 'data access', 'data integration', 'data warehouse', 'design', 'epidemiologic data', 'health care availability', 'health data', 'healthy weight', 'high risk', 'improved', 'infancy', 'innovation', 'learning strategy', 'medical schools', 'multidisciplinary', 'obesity in children', 'obesity prevention', 'obesity risk', 'predictive modeling', 'prevent', 'programs', 'prospective', 'screening', 'tool']",NIDDK,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,K01,2018,141114,232986943,-0.009631771070182872
"Classifying addictions using machine learning analysis of multidimensional data ABSTRACT This Independent Scientist Award will significantly enhance my research capabilities, enabling me to become a leading quantitative investigator in the field of substance use disorders (SUDs). Specifically, it will allow me to increase my knowledge in the areas of SUD phenotypes, treatment and genetics. SUDs are clinically and etiologically heterogeneous and their classification has been difficult. This application reflects my ongoing commitment to developing an innovative and interdisciplinary research program on the classification of SUDs through quantitative analysis of multidimensional data. My extensive training in computational science and prior research on biomedical informatics have provided me with the skills to design, implement and evaluate advanced algorithms and sophisticated analyses to solve challenging problems in classifying SUDs. My ongoing NIDA-funded R01 employs a large (n=~12,000) sample aggregated from multiple genetic studies of cocaine, opioid, and alcohol dependence to develop and evaluate novel statistical models to generate clinical SUD subtypes that are optimized for gene finding. This K02 proposal extends that work to evaluate treatment outcome in refined subgroups of SUD populations using data from treatment studies for cocaine, opioid, alcohol and multiple substance dependence. This project will integrate data from diagnostic behavioral variables and genotypes, as well as biological/neurobiological features of the disorders and repeated measures of treatment outcome. The primary career development goals of this application are to: (1) understand the reliability, validity and functional mechanisms of various phenotyping methods; (2) to continue training in the genetics of addictions; and (3) to gain greater knowledge of different treatment approaches and their efficacy. A solid foundation in these areas will enhance my ability to realize the full potential of the data collected and aggregated from multiple dimensions, and to use the data to design the most clinically useful analysis and generate innovative solutions to diagnostic and predictive challenges in SUD research. Through formal coursework, directed readings, individual tutoring and intensive multidisciplinary collaboration with a diverse team of world-renowned researchers, I will receive training and collect pilot data for future R01 projects by examining (Aim I): whether clinically-defined highly heritable subtypes derived in my current R01 project predict differential treatment response; (Aim II) whether new statistical models that directly combine treatment data with behavioral, biological, and genomic data identify refined subtypes with confirmatory multilevel evidence; and (Aim III) whether there are genetic and social moderators of treatment outcome by subtype. The overall goal of this proposal is to further my independent and multidisciplinary research program in the development of statistical methods for refined classification of SUDs. The K02 award will provide me with the protected time necessary to fully engage in the training activities described that will enhance my knowledge and skills to enable me to make important, novel contributions to the genetics and treatment of SUD. PROJECT NARRATIVE This project will develop novel statistical and quantitative tools to identify homogeneous subtypes of substance use disorders (SUDs) and other complex diseases to enhance gene finding and treatment matching. The proposed project will perform secondary analyses of existing data from treatment studies of cocaine, opioid, alcohol, and mixed SUDs. The proposed novel approaches are expected to advance precision medicine approaches to SUDs by enabling treatment matching and a more refined SUD classification to gene finding.",Classifying addictions using machine learning analysis of multidimensional data,9427988,K02DA043063,"['Adherence', 'Aftercare', 'Alcohol dependence', 'Alcohols', 'Algorithms', 'Area', 'Behavioral', 'Biological', 'Biological Markers', 'Biosensor', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Cocaine', 'Cocaine Dependence', 'Collaborations', 'Combined Modality Therapy', 'Complex', 'Computational Science', 'DSM-IV', 'DSM-V', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic and Statistical Manual of Mental Disorders', 'Dimensions', 'Disease', 'Drug Use Disorder', 'Electroencephalography', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'Heterogeneity', 'Independent Scientist Award', 'Individual', 'Interdisciplinary Study', 'Investigation', 'Joints', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Neurobiology', 'Opiate Addiction', 'Opioid', 'Patients', 'Pattern', 'Pharmacogenetics', 'Pharmacotherapy', 'Phenotype', 'Population', 'Reading', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk Factors', 'Sampling', 'Scientist', 'Signs and Symptoms', 'Solid', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'Substance Addiction', 'Substance Use Disorder', 'Surveys', 'Symptoms', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Work', 'addiction', 'alcohol use disorder', 'biomarker performance', 'biomedical informatics', 'career development', 'cocaine use', 'contingency management', 'design', 'disease classification', 'disorder subtype', 'endophenotype', 'genetic association', 'genomic data', 'imaging genetics', 'improved', 'innovation', 'neural correlate', 'novel', 'novel strategies', 'opioid use disorder', 'outcome prediction', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'secondary analysis', 'skills', 'social', 'tool', 'treatment planning', 'treatment response', 'tutoring']",NIDA,UNIVERSITY OF CONNECTICUT STORRS,K02,2018,162800,36067938,-0.03151929317783194
"Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data DESCRIPTION (provided by applicant): In-hospital cardiac arrest (IHCA) is a significant public health problem, afflicting over 200,000 patients in the United States annually with a mortality rate of approximately 80%. The majority of these patients show signs of clinical deterioration in the hours before the event. This has led to the development of vital sign-based early warning scores designed to detect high-risk patients before IHCA to trigger life-saving interventions. However, the vast majority of these risk scores were created subjectively in individual hospitals and have shown limited accuracy for detecting adverse outcomes. Developing an accurate risk score to detect patients at highest risk of IHCA is essential to decreasing preventable in-hospital death. In my prior work, I completed several studies investigating the accuracy of vital signs for predicting IHCA. These studies, previous literature, and my preliminary data have resulted in the following conclusions: 1) statistically developed risk scores are more accurate than previously published risk scores, 2) multicenter data is needed to create the most accurate and generalizable risk score, 3) additional data, such as laboratory results, will likely improve the accuracy of risk scores, and 4) a cutting-edge method for developing prediction models, called machine learning, may result in more accurate risk scores. Importantly, significant improvement in accuracy leads to better identification of patients at highest risk of IHCA and decreased resource utilization. Therefore, in this grant proposal I aim to develop and validate IHCA prediction models using different statistical techniques in a multicenter database and then estimate the impact of the most accurate risk score using simulation studies. I will do this by firt developing prediction models using classic survival analysis methods (Aim 1a) and machine learning methods, such as neural networks and decision trees (Aim 1b). Then, I will compare the models I develop to the most accurate previously published risk scores in Aim 2. Finally, I will investigate the impact of the most accurate model from Aim 2 on patient outcomes using simulation modeling (Aim 3). Completion of this proposal will result in a validated IHCA risk score that can be implemented in the electronic health record to trigger life- saving interventions to decrease preventable in-hospital death. In addition, this career development award will provide critical data to inform future R01-level awards, including a clinical trial to investigate he impact of the developed prediction model on patient outcomes. I will complete this project under the direct supervision of my mentor (Dr. David Meltzer), co-mentor (Dr. Dana Edelson), and the rest of my advisory team (Drs. Jesse Hall, Robert Gibbons, and Michael Kattan). Together, this multidisciplinary team brings nationally renowned expertise in in-hospital cardiac arrest, outcomes research, critical care, and clinical prediction modeling. In addition, they serve as Chairs of the Section of Hospital Medicine (Dr. Meltzer), Section of Pulmonary and Critical Care (Dr. Hall), and Quantitative Health Sciences at the Cleveland Clinic (Dr. Kattan), and Directors of the Center for Health and the Social Sciences (Dr. Meltzer), Center for Health Statistics (Dr. Gibbons), and Clinical Research for the Emergency Resuscitation Center (Dr. Edelson). The mentorship, expertise, and resources that they provide will ensure my success as I grow into an independent physician-scientist. My career goal is to become an independent critical care outcomes researcher with a focus on developing prediction models for clinical deterioration that will improve patient outcomes. To accomplish this long-term goal, I have three short-term goals: (1) to gain expertise in the development and implementation of clinical prediction models, (2) to create an IHCA prediction model that will identify high-risk patients on the wards to trigger life-saving interventions, and (3) to gain expertise in simulation modeling in order to study the impact of the developed prediction model. To accomplish these goals, I will build upon the foundation I developed when earning my Master's Degree in Public Health and during my initial training in the PhD program in the Department of Health Studies. Although my training to date has provided me with a strong background in epidemiology and biostatistics, further advanced training in biostatistics is crucial for my development into a successful independent researcher. An integrated program of didactic coursework, seminars, research activities, and conference participation will span the duration of the award. By accomplishing my three short- term goals, I will develop unique skills that will allow me to become a successful independent researcher. Specifically, the expertise I will gain in prediction model development, implementation, and simulation modeling can be applied not only to IHCA research but also to other areas of critical care medicine. In addition, completion of these goals will result in a validated IHCA prediction model that I will study in future implementation and cost-effectiveness studies and will serve as a basis for future R01-level grant submissions. PUBLIC HEALTH RELEVANCE: Over 200,000 in-hospital cardiac arrests occur in the United States each year, and studies suggest that many of these events may be preventable if the clinical warning signs can be identified and acted upon quickly. However, the vast majority of tools used to identify patients at high risk of cardiac arrest were created subjectively and have limited accuracy. Development of a statistically derived risk tool is essential to detect at- risk patients accurately and early in order to provide the best opportunity to improve patient outcomes and reduce preventable in-hospital death.",Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data,9393346,K08HL121080,"['Adult', 'Advisory Committees', 'Applications Grants', 'Area', 'Award', 'Biological Neural Networks', 'Biometry', 'Brain', 'Case-Control Studies', 'Categories', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Critical Care', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Decision Trees', 'Deterioration', 'Development', 'Diastolic blood pressure', 'Doctor of Philosophy', 'Early Diagnosis', 'Electronic Health Record', 'Emergency research', 'Ensure', 'Epidemiology', 'Event', 'Foundations', 'Frequencies', 'Future', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Heart Arrest', 'Hospitalization', 'Hospitals', 'Hour', 'Hylobates Genus', 'Individual', 'Intensive Care Units', 'Intervention', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Life', 'Literature', 'Lung', 'Machine Learning', 'Master&apos', 's Degree', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Outcome', 'Outcomes Research', 'Patient Discharge', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Procedures', 'Public Health', 'Publishing', 'Receiver Operating Characteristics', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Rest', 'Resuscitation', 'Risk', 'Savings', 'Scientist', 'Sensitivity and Specificity', 'Social Sciences', 'Statistical Methods', 'Statistical Models', 'Supervision', 'Survival Analysis', 'Techniques', 'Testing', 'Time', 'Training', 'Uncertainty', 'United States', 'Update', 'Validation', 'Work', 'adverse outcome', 'base', 'care outcomes', 'career', 'clinical implementation', 'cost effectiveness', 'design', 'evidence base', 'high risk', 'implementation strategy', 'improved', 'learning strategy', 'model development', 'models and simulation', 'mortality', 'multidisciplinary', 'predictive modeling', 'programs', 'public health relevance', 'simulation', 'skills', 'statistics', 'success', 'symposium', 'tool', 'ward']",NHLBI,UNIVERSITY OF CHICAGO,K08,2018,163944,246330700,-0.01957622304176019
"Improving cancer family history collection through social networking and artificial intelligence PROJECT SUMMARY  The  activities  proposed  in  this  NCI  K07  application  are  designed  to  advance  the  career  development  and  research  independence  of  Dr.  Brandon  M.  Welch.  Family  health  history  (FHx)  is  one  of  the most important  resources available to help clinicians identify disease risks. By knowing a patient's FHx, clinicians can quickly  identify  disease risks and initiate risk-reducing strategies such as increased screening, prophylactic surgery,  risk-reducing  therapeutics,  and  lifestyle  changes.  FHx  is  also  the  foundation  of  genomic  medicine.  Unfortunately,  the  collection  and  use  of  FHx  by  patients  and  clinicians  is  suboptimal.  To  improve  the  collection and use of FHx among the general population, a better FHx tool that is easier and more convenient  to  use  than  current  FHx  tools  is  needed.  A  new  FHx  web  tool,  called  ​ItRunsInMyFamily.com,​  incorporates  artificial intelligence and social networking to improve user engagement with FHx collection.Utilizing artificial  intelligence  based  chat  entity  can  improve  the  collection  of  FHx  information  by  making  it  easier  and  more  engaging to record FHx information, likewise social networking allows users to tap into the collective wisdom  and  knowledge  of  the  family  to  correct  inaccuracies  and  overcome  gaps  in  FHx  knowledge.  This research  study  will  first  identify  enhancements  to  ​ItRunsInMyFamily.com  ​that  will  further  promote  user  engagement,  with  particular  focus  on  rural and underserved patients (Aim 1). We will then evaluate whether this new FHx  tool can improve collection of cancer FHx in comparison with current FHx tools (Aim 2). Finally, we will assess  the impact of ​ItRunsInMyFamily.com ​on the clinical settings (Aim 3). To implement the research plan, it will be  critical  to  apply,  skills  obtained  through  K  award  learning  objectives,  namely  clinical  oncology  (learning  objective  1),  iterative  patient-centered  design  (learning  objective  2),  and  health  technology  assessment  (learning  objective  3).  To  fulfill  these  learning  objectives,  an  interdisciplinary  group  of  mentors  will  direct  a  comprehensive training plan. The training plan includes coursework, seminars, workshops, journal clubs, and  conferences,  covering clinical oncology, patient engagement, health disparities, user-centered development,  human-computer  interaction,  clinical  research  methodologies,  health  technology  assessment,  and  ethical  conduct  of  research.  The  strong  support  of  an  excellent  team  of  mentors,  and  the  vast  resources  of  the  Medical  University  of  South  Carolina,  create  an  optimal  training  environment.  Collectively,  the  integrated  learning  objectives  and  research  plan  are  critical  to  establishing  a  successful,  innovative,  and  meaningful  academic career focused on developing patient-centric informatics tools for oncology.   PROJECT NARRATIVE Family health history (FHx) is one of the most important risk factors for cancer and the foundation of genomic medicine, but is under-utilized by patients and clinicians. By incorporating artificial intelligence and social networking into a FHx tool, it will lead to greater engagement with FHx collection. This research study will identify and incorporate features that promote user adoption, and evaluate its impact on FHx collection.  ",Improving cancer family history collection through social networking and artificial intelligence,9545733,K07CA211786,"['Adoption', 'Area', 'Artificial Intelligence', 'Breast Cancer Patient', 'Cancer Control', 'Cancer Family', 'Cellular Phone', 'Client satisfaction', 'Clinical', 'Clinical Oncology', 'Clinical Research', 'Collection', 'Data', 'Development', 'Educational workshop', 'Environment', 'Ethics', 'Family', 'Family Cancer History', 'Family health status', 'Foundations', 'General Population', 'Genetic screening method', 'Genomic medicine', 'Goals', 'Health Technology', 'Human', 'Informatics', 'Internet', 'Journals', 'K-Series Research Career Programs', 'Knowledge', 'Learning', 'Life', 'Malignant Neoplasms', 'Measures', 'Medical', 'Mentors', 'Methodology', 'Minority', 'Operative Surgical Procedures', 'Outcome', 'Patient Care', 'Patients', 'Provider', 'Qualitative Research', 'Randomized Controlled Trials', 'Recording of previous events', 'Reporting', 'Research', 'Research Design', 'Research Methodology', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Rural Population', 'Social Network', 'South Carolina', 'Technology Assessment', 'Time', 'Training', 'Underserved Population', 'Universities', 'Workload', 'base', 'cancer care', 'cancer risk', 'career', 'career development', 'clinical care', 'computer human interaction', 'design', 'disorder risk', 'health disparity', 'improved', 'innovation', 'next generation', 'oncology', 'patient engagement', 'patient oriented', 'personalized care', 'prevent', 'prophylactic', 'research and development', 'research study', 'rural underserved', 'satisfaction', 'screening', 'skills', 'symposium', 'therapeutic lifestyle change', 'tool', 'user centered design']",NCI,MEDICAL UNIVERSITY OF SOUTH CAROLINA,K07,2018,173453,136810522,-0.0013209338302383627
"Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings Project Summary (Abstract) With little change in incidence for over 50 years, pneumonia remains the top cause for morbid hospitalization1 in the USA, and is associated with healthcare costs exceeding $10 billion annually2. This study proposes to mine big data captured in an intergrated medical/dental record (iEHR) and enterprise data warehouse (EDW) of a large midwestern medical-dental integrated healthcare system and will test the hypothesis that poor oral health is an independent risk for subtypes of community-acquired and hospital-acquired pneumonia. Proposed specific aims include: 1) electronic identification and characterization of pneumonia types and 2) evaluation of the association of oral health status with risk of pneumonia. Tasks to achieve study aims are to: a) develop electronic, phenotype-based algorithm(s) to classify and characterize pneumonia by subtype and relative frequency of events; b) characterize impact of immediate and longitudinal oral health status on emergent pneumonia stratified by subtype; and c) evaluate relative risk contributed by medical and dental factors. Innovative application of natural language processing (NLP) to support evaluation of unstructured data and machine learning (ML) to identify as-yet unknown potential risk factors is proposed. These aims will be accomplished by established investigators including dentists and researchers with extensive research track records in oral and systemic health including pneumonia, clinical pulmonologist/intensivist to provide clinical expertise to inform data mining, biomedical informaticians with expertise in data mining, ML and NLP and data modeling, and experienced biostatisticians who will apply appropriate statistical approaches and traditional data modeling to big data. This team will collaboratively create and deliver a unique, well-defined, pneumonia- specific, oral health data registry resource and validated phenotype-based algorithm to classify pneumonia, stratified by subtypes, which will support future interrogation for additional permutations of medical and dental factors. Study outcomes are expected to leverage immediate translational value within the health system with high potential for relevance and portability to other settings. The project is expected to define risk factors which may represent actionable targets for reduction of pneumonia risk across various settings. Project Narrative- Relevance to public health: Pneumonia continues as a leading public health problem in hospitals, healthcare facilities and community settings. Pneumonia is the top disease-related cause for hospitalization. This study proposes to use data in electronic health records to classify pneumonia type and describe risk factors that may make individual susceptible to different types of pneumonia, including impact of diseases of the mouth, gums and teeth. The project expects to create models that can identify patients at risk for pneumonia based on information in their medical record so that those risks may be recognized and reduced.",Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings,9599192,R03DE027020,"['Address', 'Adoption', 'Adult', 'Affect', 'Age', 'Algorithms', 'Antibiotic Resistance', 'Aspiration Pneumonia', 'Big Data', 'Caring', 'Cessation of life', 'Characteristics', 'Chronic', 'Classification', 'Climate', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Comorbidity', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Dental', 'Dental Care', 'Dental Hygiene', 'Dental Records', 'Dentists', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Electronic Health Record', 'Environmental Risk Factor', 'Evaluation', 'Event', 'Frequencies', 'Future', 'General Hospitals', 'Health', 'Health Care Costs', 'Health Status', 'Health care facility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Inpatients', 'Integrated Health Care Systems', 'Intervention Studies', 'Investigation', 'Knowledge', 'Laboratories', 'Link', 'Logic', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Care Costs', 'Medical Records', 'Modeling', 'Mouth Diseases', 'Natural Language Processing', 'Nosocomial pneumonia', 'Oral', 'Oral health', 'Outcome Study', 'Outpatients', 'Pathogenesis', 'Patients', 'Periodontitis', 'Pharmaceutical Preparations', 'Phenotype', 'Pneumococcal vaccine', 'Pneumonia', 'Population Study', 'Prevalence', 'Prevention', 'Public Health', 'Pulmonology', 'Recording of previous events', 'Records', 'Recurrence', 'Relative Risks', 'Research', 'Research Institute', 'Research Personnel', 'Resolution', 'Resources', 'Respiratory Signs and Symptoms', 'Retrospective cohort', 'Risk', 'Risk Factors', 'Role', 'Scoring Method', 'Site', 'Smoking', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tooth structure', 'Translational Research', 'Update', 'Ventilator', 'Visit', 'base', 'burden of illness', 'case finding', 'clinically relevant', 'community setting', 'cost', 'data mining', 'data modeling', 'data registry', 'data warehouse', 'demographics', 'experience', 'follow-up', 'health care delivery', 'health record', 'healthcare community', 'high risk', 'innovation', 'member', 'mortality', 'novel', 'outreach', 'patient population', 'patient screening', 'pneumonia model', 'portability', 'secondary analysis', 'systems research', 'ventilator-associated pneumonia']",NIDCR,MARSHFIELD CLINIC RESEARCH FOUNDATION,R03,2018,174917,13396495,-0.015563383532864341
"New Approach to US Elasticity Imaging Project Summary To more fully exploit the basic science of mechanobiology as it pertains to breast cancer progression, the medical imaging field continues to search for fast, safe, and effective elasticity imaging methods. In this project we propose a fundamentally new approach to ultrasonic elasticity imaging in which the weak forces applied to patient tissues and the measured displacements that result are used to train a numerical model specifically for that patient. This constitutive model is developed using finite-element methods and neural networks assembled in a unique configuration called the AutoProgressive (AutoP) Method. AutoP “learns” complete stress and strain properties directly from sparse force and displacement measurements and without a mathematical model. Using quasi-static stimuli, AutoP exploits the fact that each force-displacement estimate contains information about mechanical properties at all locations in the contiguous tissue. From measurement information and conservation laws, AutoP generates an informational model without the need to make assumptions about tissue linearity, isotropy, or other material properties normally required when constructing images that display tissue mechanical properties. Once an accurate material-property model is formed by AutoP, we adopt a separate rheological model (e.g., Kelvin Voigt) to form viscoelastic parameters for image display. The AutoP method employs beamformed RF-echo acquisitions from which point displacements are estimated, applied compressional force sensed at the transducer surface, and tissue shape.  No other imaging method is capable of estimating all relevant stress fields, which gives AutoP unique capabilities. AutoP estimates the mechanical properties that one strives to obtain from an inverse problem approach, but AutoP is not a mathematical inverse technique and hence does not suffer from nonunique solutions. Without the need to assume material properties, AutoP can (in principle) model tissue properties in three dimensions and in time following large deformations in highly-nonlinear, anisotropic media. This R21 proposal focuses on establishing the feasibility of the AutoP methodology for subsequent clinical trials under future funding. At the completion of this two-year project, we will demonstrate a new tool for medical imaging capable of exploring the mechanical properties of tissues over a very broad range of deformations. We specifically target ultrasonic methods and quasi-static force stimuli in this project. However AutoP could eventually be coupled to other imaging modalities (e.g., MRE, OCE) or dynamic force-stimulus methods.  The scientific premise underlying AutoP is that we already record all of the information needed to generate a very broad range of elasticity images. The key to unlocking this information is to set aside mathematical models in favor of data-driven informational models built using the unique machine learning abilities of the AutoP method. If successful, AutoP will have a major influence on medical elasticity imaging methods. Project Narrative: A new type of machine-learning method is proposed for elasticity imaging of patient tissues that offers the potential to minimize many current limitations. If we are successful in this development, ultrasonic elasticity imaging would significantly improve in its ability to accurately represent mechanical properties of breast tissues, without any changes in current instrumentation and without increasing cost to the healthcare system or adding risk to patients.",New Approach to US Elasticity Imaging,9560761,R21EB023402,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Basic Science', 'Behavior', 'Biological Neural Networks', 'Breast', 'Clinical', 'Clinical Trials', 'Code', 'Coupled', 'Data', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'Disease', 'Elasticity', 'Elements', 'Engineering', 'Environment', 'Feedback', 'Funding', 'Future', 'Goals', 'Healthcare Systems', 'Image', 'Inflammatory', 'Isotropy', 'Laws', 'Learning', 'Legal patent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammary Gland Parenchyma', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modulus', 'Patients', 'Procedures', 'Process', 'Property', 'Recording of previous events', 'Risk', 'Role', 'Scanning', 'Shapes', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Study Subject', 'Surface', 'Techniques', 'Time', 'Tissue Model', 'Tissues', 'Training', 'Transducers', 'Ultrasonic Transducer', 'Ultrasonics', 'Writing', 'aged', 'base', 'breast cancer progression', 'breast imaging', 'cost', 'experience', 'healthy volunteer', 'human subject', 'imaging modality', 'imaging properties', 'improved', 'in vivo', 'information model', 'insight', 'instrumentation', 'learning strategy', 'mathematical model', 'mechanical properties', 'model building', 'model development', 'novel strategies', 'object shape', 'processing speed', 'sensor technology', 'tool', 'viscoelasticity']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2018,179876,76545728,-0.028317958269150963
"Leveraging modern analytic approaches to improve diabetes outcomes ABSTRACT Diabetic patients are at risk of developing diabetic heart disease, which may lead to complications in care. Diabetic heart disease patients not only have exceptionally high healthcare expenditures and resource utilization but also are likely to have poor patient outcomes. Studies have shown that early intervention of patients likely to develop diabetic heart disease is cost-effective and yields favorable health outcomes. Therefore, early identiﬁcation of diabetic patients at high-risk of developing diabetic heart disease is crucial to provide effective interventions. The commonly accepted methodology for diabetic heart disease risk prediction is the use of one or more risk scoring systems. However, these risk functions may not generalize well for the diabetes patient and may suffer from poor calibration when used on different cohorts. Moreover, the scoring systems have only been studied on coronary heart disease, one variant of diabetic heart disease while heart failure and diabetic cardiomyopathy remain important, yet insufﬁciently studied problems. Machine learning offers the ability to perform accurate predictive analytics and has been proposed as a way to identify and manage high-risk patients. The primary goal of this proposal is to develop a high-impact and practical risk prediction model that can be used to per- form early identiﬁcation of high-risk diabetic heart disease patients. Given the heterogeneity and complexity of patient information in electronic health records, the model needs to capitalize on the multi-dimensional temporal nature of pa- tient records to extract identifying characteristics of patients that will develop diabetic heart disease. To accomplish this, we will leverage modern machine learning approaches such as tensor factorization and natural language processing to model complex patient characteristics, provide a more complete representation of the patient, and uncover excellent predictors of diabetic heart disease risk. An existing dataset that contains the de-identiﬁed electronic health records of approximately 4,100 diabetic patients from the Emory Healthcare System to compare the predictive power of machine learning-based algorithms with the standard risk scoring systems. These algorithms will be evaluated on calibration, discrimination, and ease of interpretability. The results of this work will provide insight as to how to develop a machine learning–based prediction system that can identify high-risk diabetic heart disease patients. The study may also shed light on the best approaches for fusing data from multiple heterogeneous sources to build a better predictive model and potentially identify novel indicators of high- risk diabetic heart disease factors. Moreover, the work will help inform a larger multi-site study of diabetic heart disease risk prediction and develop methods to generalize the results to a broader spectrum of comorbidities. This project is consistent with the National Library of Medicine's mission to translate biomedical research into practice. PROJECT NARRATIVE Diabetic patients are risk of developing diabetic heart disease which can lead to high healthcare expenditure, high resource utilization, and poor patient outcomes. Existing diabetic risk prediction models can suffer from poor calibration and predictive accuracy. This project develops a novel and practical analytic tool to identify patients at high-risk of developing diabetic heart disease.",Leveraging modern analytic approaches to improve diabetes outcomes,9583770,K01LM012924,"['Adopted', 'Age', 'Algorithms', 'Biomedical Research', 'Calibration', 'Caring', 'Characteristics', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Comorbidity', 'Complex', 'Complications of Diabetes Mellitus', 'Computer software', 'Congestive', 'Coronary', 'Coronary heart disease', 'Data', 'Data Set', 'Data Sources', 'Diabetes Mellitus', 'Diagnosis', 'Discrimination', 'Disease', 'Early Intervention', 'Early identification', 'Economic Burden', 'Elderly', 'Electronic Health Record', 'Epidemic', 'Evaluation', 'Future', 'Goals', 'Health', 'Health Expenditures', 'Healthcare', 'Healthcare Systems', 'Heart Diseases', 'Heart failure', 'Heterogeneity', 'Institution', 'Intervention', 'Lead', 'Light', 'Machine Learning', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Natural Language Processing', 'Nature', 'Outcome', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Predictive Analytics', 'Predictive Value', 'Prevalence', 'Prevention', 'Procedures', 'Records', 'Research Personnel', 'Resources', 'Risk', 'Site', 'Source', 'Structure', 'System', 'Translating', 'United States', 'United States National Library of Medicine', 'Variant', 'Work', 'analytical tool', 'base', 'clinical practice', 'cohort', 'computer science', 'cost effective', 'design', 'diabetic', 'diabetic cardiomyopathy', 'diabetic patient', 'effective intervention', 'electronic structure', 'epidemiologic data', 'heart disease risk', 'high risk', 'improved', 'insight', 'novel', 'open source', 'predictive modeling', 'prospective', 'prototype', 'research to practice', 'secondary analysis']",NLM,EMORY UNIVERSITY,K01,2018,180684,507546965,-0.004209328970045529
"Novel Non-Invasive Coronary Flow Patterning to Predict Early Coronary Microvascular Disease PROJECT SUMMARY  Coronary microvascular disease (CMD) is notoriously difficult to diagnose non-invasively, and current methods of assessing CMD utilize only the peak velocity of the coronary flow pattern. While new imaging techniques such as cardiac magnetic resonance imaging (MRI) have improved the assessment coronary perfusion, there are currently no non-invasive methods that incorporate the coronary flow pattern over a complete cardiac cycle to definitively assess and predict the development of CMD.  Coronary blood flow (CBF) reflects the summation of flow in the coronary microcirculation, and our lab has begun to harness the full CBF pattern under varying flow and disease conditions (e.g. type 2 diabetes) to determine whether it might harbor novel clues leading to the early detection of CMD. Our past and preliminary data indicate an early onset of CMD in both type 2 diabetes mellitus (T2DM) and metabolic syndrome (MetS) that occurs prior to the onset of macrovascular complications and that are characterized by blood flow impairments and alterations in coronary resistance microvessel (CRM) structure, function, and biomechanics. Our data also uncovered innovative correlations between CRM structure/biomechanics and our newly-defined features of the coronary flow pattern, some of which were unique to normal or diabetic mice. We have initially utilized these CBF features, in the presence and absence of other factors such as cardiac function, to develop a mathematical model in collaboration with Drs. Christopher Bartlett and William Ray that to date demonstrated that 6 simple factors can predict a normal vs. diabetic coronary flow pattern with 85% predictive accuracy. Utilizing a multidisciplinary approach, these preliminary data strongly suggest that the coronary flow pattern and physiological modulators of it (e.g. coronary micovascular structure/function/biomechanics, cardiac function, etc), may be useful in directly diagnosing early CMD. Therefore, we hypothesize that dissecting the elements that influence coronary flow patterning will be critical determinants in the direct assessment of coronary microvascular disease using computational modeling. Using our previous publications and our preliminary data as guides, the hypothesis will be tested by addressing two specific aims: 1) Determine whether unique time-dependent CBF patterning in normal and T2DM is dictated by a combination of CRM remodeling and biomechanics, coronary flow pattern dynamics, and cardiac function, permitting the development of a computational model to accurately predict CMD; 2) Determine the reproducibility and robustness of the machine learning model in predicting CMD in a diet-induced obesity/diabetes mouse model. If successful, these studies will be the first to simultaneously examine the influence of CRMs, CBF, and cardiac structure/function on the distinct pattern of coronary flow, and it will determine whether a mathematical model may be useful in establishing a direct assessment of CMD to eventually enable clinicians to conduct a more direct non-invasive diagnosis of CMD for the prevention and/or treatment of heart disease. PROJECT NARRATIVE Coronary Artery Disease (CAD) is the leading cause of heart disease and is associated with hypertension, diabetes, and metabolic syndrome. Coronary Microvascular Disease (CMD) is comprised of structural and functional deficits of the tiny coronary arteries that may be an earlier indicator of disease prior to the onset of overt CAD. The proposed multidisciplinary research aims to develop a computational artificial intelligence model that will accurately predict CMD based on a non-invasive coronary flow pattern obtained by Doppler echocardiography.",Novel Non-Invasive Coronary Flow Patterning to Predict Early Coronary Microvascular Disease,9584176,R21EB026518,"['Address', 'Age', 'Artificial Intelligence', 'Biomechanics', 'Blood flow', 'Cardiac', 'Collaborations', 'Computer Simulation', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Development', 'Diabetes Mellitus', 'Diabetic mouse', 'Diet', 'Disease', 'Doppler Echocardiography', 'Early Diagnosis', 'Echocardiography', 'Elements', 'Heart Diseases', 'Hyperemia', 'Hypertension', 'Imaging Techniques', 'Impairment', 'Interdisciplinary Study', 'Laboratories', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Metabolic syndrome', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Pattern', 'Physiological', 'Publications', 'Reproducibility', 'Resistance', 'Structure', 'Testing', 'Time', 'base', 'coronary perfusion', 'db/db mouse', 'diabetic', 'disorder prevention', 'early onset', 'experimental study', 'heart function', 'improved', 'innovation', 'interdisciplinary approach', 'macrovascular disease', 'mathematical model', 'noninvasive diagnosis', 'novel', 'pressure', 'prevent']",NIBIB,RESEARCH INST NATIONWIDE CHILDREN'S HOSP,R21,2018,190000,43994644,-0.008426095312759714
"Characterization of Thyroid Nodules by Quantitative Ultrasound Project Summary Thyroid cancer is the most-common endocrine malignancy. Its incidence has tripled in the last thirty years. Diagnosis of thyroid cancer is difficult because 50% of people older than 65 have at least 1 thyroid nodule, but only 10% of the nodules are cancerous. Approximately 1.6 billion dollars are spent annually in the US to detect thyroid cancer. Conventional ultrasound is used to identify nodules that warrant a needle biopsy. However, 65% of needle biopsies are negative for cancer and 30% are “indeterminate.” The indeterminate nodules are surgically removed for definitive diagnosis and 75% of them prove to be benign. Therefore, well more than 80% of initially presenting nodules undergo unnecessary biopsies and more than 20% of them also undergo subsequent unnecessary surgery procedures. Accordingly, the broad objective of the proposed study is to assess the feasibility of using quantitative-ultrasound (QUS) methods to distinguish cancerous from benign nodules reliably and thereby to reduce the enormous cost and risks associated with unnecessary biopsies and surgical excisions. The first aim of the project is to develop and asses the ability of QUS to distinguish cancerous from benign nodules and to compare the ability of QUS to the ability of conventional methods to select nodules that warrant biopsies; the second aim is to expand QUS methods by combining existing QUS measures developed by Riverside Research with measures derived from so-called B-flow- imaging (BFI) and shear-wave-elasticity (SWE) techniques developed by GE; the third aim is to formulate an objective basis for planning future, prospective studies to translate the findings of the present study to a commercial instrument that can bring QUS-based nodule evaluation into the clinic. To achieve these three aims, QUS performance in classifying cancerous and benign nodules will be compared to the performance of conventional ultrasound and the results of fine needle cytology, molecular marker analyses, and, in the cases of that undergo surgical excision, histology, will used as gold standards. Classification will be performed using standard, well understood, linear, and non-linear methods, such as linear-discriminant analysis and support- vector machines respectively. If feasibility is successfully demonstrated in the proposed project, and if the demonstration of feasibility ultimately leads to future incorporation into an instrument capable of real-time QUS analysis for reliable nodule evaluation, then a highly significant technological advance will be realized that can provide valuable, risk-reducing, cost-effective health-care benefits for patients presenting with thyroid nodules.   PROJECT NARRATIVE: Thyroid cancer rates have tripled in the last thirty years, but current methods of diagnosis are very inefficient. Far too many thyroid biopsies and surgeries are performed with >80% of biopsies and >25% of thyroid surgeries being performed on benign nodules. The advanced ultrasound methods to be evaluated in this proposal seek to drastically reduce the number of unnecessary biopsies and surgeries of benign thyroid nodules.",Characterization of Thyroid Nodules by Quantitative Ultrasound,9405532,R21CA212744,"['Achievement', 'Age', 'Architecture', 'Area', 'Asses', 'Benign', 'Biopsy', 'Breast Microcalcification', 'Cancer Death Rates', 'Cancerous', 'Classification', 'Clinic', 'Clinical', 'Cytology', 'Cytology Histology', 'Data', 'Detection', 'Diagnosis', 'Discriminant Analysis', 'Elasticity', 'Endocrine', 'Evaluation', 'Excision', 'Fine-needle biopsy', 'Foundations', 'Future', 'Goals', 'Gold', 'Healthcare', 'Histology', 'Image', 'In Situ', 'Incidence', 'Investigation', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measures', 'Methods', 'Molecular', 'Needle biopsy procedure', 'Needles', 'Nodule', 'Non-Malignant', 'Operative Surgical Procedures', 'Patient Care', 'Patients', 'Performance', 'Population', 'Probability', 'Procedures', 'Property', 'Prospective Studies', 'Prostate', 'ROC Curve', 'Research', 'Risk', 'Signal Transduction', 'Solid', 'Specificity', 'Techniques', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Time', 'Tissues', 'Training', 'Translating', 'Ultrasonography', 'United States', 'Unnecessary Surgery', 'base', 'calcification', 'care costs', 'cost', 'cost effective', 'design', 'elastography', 'improved', 'instrument', 'lymph nodes', 'molecular marker', 'novel', 'prevent', 'prospective', 'quantitative ultrasound', 'statistics']",NCI,BOSTON MEDICAL CENTER,R21,2018,190102,61416950,-0.0500487104513576
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this ﬁeld typically produce an “all-cause” risk estimate which, even if accurate, overlooks the actionable mechanisms behind admis- sion risk and therefore fails to identify a prescribed response. This limitation may explain the only modest – at best – reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modiﬁable risks and their associated phenotypes driving hospital ad- missions; (2) using natural language processing techniques (NLP) to build classiﬁcation models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to signiﬁcantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close men- toring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a support- ive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identiﬁcation and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,9505570,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Comorbidity', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patient risk', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Preventive Intervention', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'collaborative environment', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'randomized trial', 'response', 'skills', 'social', 'trend', 'trial design']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2018,195205,593605914,-0.019472450344397478
"Temporal Dietary and Physical Activity Patterns Related to Health Outcomes ABSTRACT Patterns (e.g. frequency, amount, etc.) of dietary intake and daily physical activity have each been independently linked with an increasing prevalence of obesity. Yet, connecting these patterns to obesity and chronic disease through the integration of time has not been previously considered. Given the strong evidence for independent linkages between each of these patterns and obesity, there is a critical need to determine the potential synergistic correlation of these patterns of behavior within the framework of a relationship with health. In the absence of such insights, opportunities for early detection of behavioral patterns that predispose obesity and chronic disease will be missed, and our long-term research goal to create these early detection strategies will not be met. The central hypothesis of this project is based on the analytical framework and methodology that was previously developed by the investigators: that daily patterns of energy intake, when integrated with physical activity, will be associated with health in a representative sample of U.S. adults 20 to 65 y (NHANES 2003-2006). The objectives in this R21 application include the development of data patterning methodology that can be used to create distinct dietary intake and physical activity patterns and then successfully integrate these patterns to identify population temporal pattern clusters. Next, the investigators will evaluate the cluster relationships with obesity and health outcomes and compare the integrated clusters to the un-integrated dietary and activity pattern clusters. The working hypotheses are firstly, that novel distance measures based on dynamic time warping for the dietary and physical activity data can be integrated to produce meaningful clustering related to health, and secondly, that a population cluster which exhibits a pattern of evenly spaced eating occasions, moderate energy consumption and moderate physical activity patterns in a 24 hour day will be associated with normal weight and without chronic disease, and that relationships with health outcomes will be stronger for the integrated temporal pattern clusters compared with un-integrated temporal dietary clusters and physical activity clusters. The rationale for this research is that its successful completion is expected to create data reduction methods that classify temporal lifestyle patterns linked to disease, further, the expectation is that these analytical techniques will integrate multidimensional temporal dietary and physical activity data. These outcomes are expected to have a significant positive impact, not only in developing/evaluating new analytic methods but in laying the groundwork for data based preventative interventions. This proposed research is potentially significant because results will provide a starting point for understanding the importance of the timing of dietary and physical activity patterns to the prevention of obesity and disease with potentially broad translational  RELEVANCE TO NIH The proposed research is relevant to public health because preventative time-based dietary and physical activity patterns will be identified among the US population, which are expected to open new research horizons for evidence-based recommendations for healthy lifestyles. The project is relevant to NIH's mission because individualized early detection of lifestyles supporting health or linked with disease may be attainable through the development of analytical techniques integrating multiple layers of data. Such strategies could be applied to utilize the increasing information from personal electronic monitoring devices and to detect patterns associated with positive and negative health outcomes.",Temporal Dietary and Physical Activity Patterns Related to Health Outcomes,9601212,R21CA224764,"['Accelerometer', 'Adult', 'Affect', 'Behavior', 'Behavioral', 'Chronic Disease', 'Circadian Rhythms', 'Consumption', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diet', 'Dietary Factors', 'Dietary Practices', 'Dietary intake', 'Digestion', 'Disease', 'Early Diagnosis', 'Eating', 'Energy Intake', 'Exhibits', 'Food', 'Frequencies', 'Genes', 'Goals', 'Health', 'Hour', 'Individual', 'Intervention', 'Life Style', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Metabolic', 'Metabolic syndrome', 'Metabolism', 'Methodology', 'Methods', 'Mission', 'Moderate Exercise', 'National Health and Nutrition Examination Survey', 'Nutrient', 'Obesity', 'Organ', 'Outcome', 'Participant', 'Pattern', 'Physical activity', 'Population', 'Prevalence', 'Preventive Intervention', 'Public Health', 'Regulation', 'Research', 'Research Design', 'Research Personnel', 'Sampling', 'Series', 'Sleep', 'Surveys', 'Techniques', 'Time', 'Tissues', 'United States National Institutes of Health', 'Weight', 'Work', 'analytical method', 'base', 'data reduction', 'design', 'evidence based guidelines', 'expectation', 'health data', 'healthy lifestyle', 'inferential statistics', 'innovation', 'insight', 'modifiable behavior', 'monitoring device', 'novel', 'obesity prevention', 'prevent', 'speech processing', 'unhealthy lifestyle', 'waist circumference']",NCI,PURDUE UNIVERSITY,R21,2018,195600,64946317,-0.005995624578657832
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9538189,K01ES026833,"['Acute', 'Affect', 'Blood', 'Blood flow', 'Brain', 'Brain Injuries', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Healthcare', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Ruptured Aneurysm', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision support', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'public health relevance', 'standard of care', 'support tools', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2018,216241,558628098,-0.025432610564921375
"Real-time Monitoring of Zebrafish ECG with Automated Aberrant Pattern Detection Abstract Sensoriis, Inc is a company that, develops evidence-based sensing solutions to support biological investigations and address health care problems. The goal of this NIH STTR grant with University of Washington (UW) is to provide a flexible system to assess cardiac electrical activities in zebrafish models, supporting heart disease studies and drug screening. Unlike humans, zebrafish hearts can fully regenerate following cardiac injury, thereby providing a tractable model system to study endogenous heart regeneration. Zebrafish have also proven to be an ideal vertebrate model system for phenotype-based screening owing to their physiological similarity to mammals. Further, zebrafish model enables a forward genetic approach to reveal the genetic basis and underlying molecular mechanisms of numerous heart diseases. The conventional setup for cardiac phenotype acquisition in zebrafish (i.e. electrocardiogram – ECG) involves sedation causing variation in functionality. To date, there is no system which can offer cardiac phenotype monitoring in freely-swimming zebrafish, not to mention for multiple fish simultaneously. In this context, we propose and develop 1) a wireless flexible “jacket” to be worn by zebrafish for real-time assessment of electrical cardiac phenotypes, namely ECG; and 2) a simple-yet-novel apparatus to collect ECG of multiple awake fish. Our devices provide pivotal platforms for cardiac phenotype-related investigations. The obtained data will be processed by smart algorithms to detect aberrant ECG patterns in real time. The proposed systems will facilitate related studies using zebrafish models. Further, the success of this platform also paves the avenue for regenerative medicine and developmental biology studies as well as stem cell-based therapies for cardiac repair. In Phase I of this STTR grant, we will develop i) a polymer-based microelectrode array (MEA) jacket that could be comfortably worn by the zebrafish and provide wireless ECG acquisition; and ii) a 4-chamber apparatus for simultaneous recording of ECG in awake fish. Machine learning-based programs with embedded algorithms will be developed to distinguish ECG patterns such as heart rate, ST and QT intervals, thus can identify anomalies, such as arrhythmias or prolonged QTs. For proof of concept, the system will be validated and compared. PROJECT NARRATIVE In this Phase I STTR grant, Sensoriis, Inc and the University of Washington will develop 1) a world-first wireless flexible membrane for zebrafish with a micro-electrode array (MEA) for ECG measurement and electronics for wireless powering and communication with an external unit; 2) a simple-yet-novel 4-chamber apparatus to acquire ECG of 4 awake fish; and 3) Machine learning-based programs to process the data and detect desired patterns. The goal is to facilitate and reduce cost and time of cardiac phenotype-based screening in the zebrafish models, supporting numerous studies. The proposed system also pave the avenue for heart-disease investigations and stem cell-based therapy validation using zebrafish models.",Real-time Monitoring of Zebrafish ECG with Automated Aberrant Pattern Detection,9556073,R41OD024874,"['Address', 'Adult', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Amiodarone', 'Animals', 'Arrhythmia', 'Behavior', 'Biological', 'Biological Models', 'Cardiac', 'Cardiac development', 'Cell Therapy', 'Characteristics', 'Collaborations', 'Collection', 'Columbidae', 'Communication', 'Coupling', 'Custom', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Devices', 'Discipline', 'Drug Screening', 'EKG P Wave', 'EKG QRS Complex', 'Electrocardiogram', 'Electrodes', 'Electronics', 'Embryo', 'Environment', 'Fishes', 'Generations', 'Genetic', 'Genetic Diseases', 'Goals', 'Grant', 'Healthcare', 'Heart', 'Heart Diseases', 'Heart Injuries', 'Heart Rate', 'Housing', 'Human', 'Human Genetics', 'Investigation', 'Machine Learning', 'Mammals', 'Manuals', 'Measurement', 'Membrane', 'Mental Depression', 'Microelectrodes', 'Modeling', 'Molecular', 'Molecular Biology', 'Monitor', 'Mutagenesis', 'Myocardium', 'Names', 'Natural regeneration', 'Neurobiology', 'Noise', 'Optics', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacology and Toxicology', 'Phase', 'Phenotype', 'Physiological', 'Polymers', 'Process', 'Regenerative Medicine', 'Resources', 'Role', 'Sampling', 'Scientist', 'Sedation procedure', 'Signal Pathway', 'Signal Transduction', 'Sinus', 'Small Business Technology Transfer Research', 'Stem cells', 'Swimming', 'System', 'Systems Biology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Washington', 'Wireless Technology', 'Work', 'Zebrafish', 'awake', 'base', 'cardiac regeneration', 'cardiac repair', 'cost', 'drug use screening', 'evidence base', 'flexibility', 'gene function', 'genetic approach', 'heart electrical activity', 'injured', 'new technology', 'novel', 'programs', 'real time monitoring', 'screening', 'success', 'temporal measurement', 'tool']",OD,"SENSORIIS, INC.",R41,2018,224229,769421,-0.009727883045759927
"An integrated neural network analysis and video microscopy platform for fully automated particle tracking Project Summary/Abstract  Particle tracking (PT) is a biophysical tool for elucidating molecular interactions, transport phenomena of diverse species, and rheological properties of complex materials. PT experiments involve first obtaining high resolution videos that capture time-resolved increments of particles, followed by extraction of traces of entities of interest from videos in the form of spatial locations over time, a process we refer to as path conversion. Finally, quantitative analysis of the traces will yield diffusivities, viscoelasticity, etc.  Lung diseases, such as cystic fibrosis and COPD, are characterized by a highly viscoelastic mucus layer that is incapable of being cleared by mucociliary clearance. Not surprisingly, the viscoelasticity of mucus often directly reflects disease progression. A variety of mucolytics are being investigated, but due to the variable composition and properties of mucus between patients, effective mucolytics treatment will likely be different between individuals; too little/inappropriate mucolytics will not be effective in restoring mucus clearance, whereas too much may result in bronchorrhea. Although microbeads-based rheology has been performed on a variety of mucus specimens in basic research, the capacity for high throughput characterization of rheological properties of biological specimens in a clinical setting is currently not available. This limitation can be attributed to inefficiencies of path conversion: current PT software requires extensive human supervision/intervention to achieve accurate path conversion, not only resulting in poor reproducibility and throughput but also restricting its use to only expert labs. Our vision is to make PT as objective and easy to use as a simple plate reader that can be readily utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening), and research professionals. Towards this goal, we have created a neural network tracker (NNT) that automatically determines the location of all particles in each frame with zero user-input (i.e. no parameter for users to change), and retains the identity of all particles from frame to frame. The innovation is that NNT can robustly, reproducibly, and accurately track a wide range of 2D/3D videos with virtually no need for human intervention, achieving unparalleled time savings. We have already successfully deployed NNT over the Google cloud, which offers exceptional scalability. Nevertheless, for time-sensitive applications, such as an automated PT rheometer, the transfer of large video data files is likely prohibitive. Therefore, in this Phase I STTR, we seek to enable real-time NNT-based PT analysis on the local machine while video microscopy data is being acquired by the microscope, and allow data from PT analysis to drive the operation of the microscope. In Aim 1, we will integrate our NNT with a single objective fluorescence microscope system called Monoptes. Aim 2 will evaluate the performance of our NNT- Monoptes system. If successful, our technology would form the basis of a fully automated PT system capable of measuring rheological properties of fluids/materials or distribution of particle sizes in a 96-well plate format. Project Narrative Particle tracking is a powerful biophysical tool in life and physical sciences, but unfortunately, its application has been strongly limited by inefficiencies in accurately extracting particle traces from raw movies. Unlike conventional particle tracking methods, we have combined artificial intelligence and machine learning to create a software that can consistently provide superior and truly automated tracking performance compared to current alternatives. In this proposal, we will integrate this latest advance with sophisticated instrumentation to develop a microscope system capable of fully automated particle tracking microscopy in a 96-well plate format. If successful, the instrument will likely be utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening of patients), and research professionals.",An integrated neural network analysis and video microscopy platform for fully automated particle tracking,9620574,R41GM130202,"['Acceleration', 'Adopted', 'Antibodies', 'Artificial Intelligence', 'Basic Science', 'Binding', 'Biological', 'Biological Neural Networks', 'Biological Sciences', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Trials', 'Code', 'Complex', 'Computer software', 'Cystic Fibrosis', 'Data', 'Data Files', 'Decision Making', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease Progression', 'Drug Carriers', 'Drug Screening', 'Effectiveness', 'Elasticity', 'Engineering', 'Gaussian model', 'Goals', 'HIV Infections', 'Heterogeneity', 'Human', 'Image', 'Individual', 'Intervention', 'Liquid substance', 'Location', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Microspheres', 'Motion', 'Mucociliary Clearance', 'Mucolytics', 'Mucous body substance', 'Output', 'Particle Size', 'Particulate', 'Pathway Analysis', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Positioning Attribute', 'Process', 'Property', 'Radial', 'Reader', 'Reproducibility', 'Research', 'Resolution', 'Respiratory physiology', 'Rheology', 'Risk', 'Running', 'Sampling', 'Savings', 'Series', 'Small Business Technology Transfer Research', 'Software Tools', 'Specimen', 'Spottings', 'Supervision', 'System', 'Technology', 'TensorFlow', 'Time', 'Video Microscopy', 'Viscosity', 'Vision', 'Woman', 'base', 'biophysical tools', 'cloud based', 'drug development', 'experimental study', 'fluorescence microscope', 'innovation', 'instrument', 'instrumentation', 'interest', 'movie', 'novel', 'operation', 'particle', 'patient screening', 'physical science', 'pre-clinical', 'submicron', 'virtual', 'viscoelasticity']",NIGMS,"AI TRACKING SOLUTIONS, LLC",R41,2018,224894,0,-0.01163916015513848
"A wearable device to detect opioid overdose and to prevent death Bioresp Technologies, Inc. proposes development of RespiLife, a new wearable device to to track physiologic data for early detection of opioid overdose and to relay data and the generated alerts to relevant caregivers for further intervention. The goal is to reduce the number opioids-related deaths by early detection of overdose. Opioid epidemic death toll has quadrupled since 1999. About half of those deaths are due to prescription opioids and for the most part are unintentional. RespiLife tracks oxygen saturation, respiratory rate, and pulse rate and based on a machine learning algorithm will determine changes from the baseline and correlation of those changes with changes in medications. Our specific aims are: (1) Production of five working prototypes with their algorithm to use in our validation study. (2) A validation study to compare our data with a gold-standard device and carry out statistical analysis for evaluation of agreement and accuracy. Public health relevance: Currently we in the midst of an opioid overdose epidemic that has resulted in a four fold increase in death rate since 1999.",A wearable device to detect opioid overdose and to prevent death,9465942,R43DA045407,"['911 call', 'Adverse effects', 'Advertisements', 'Agreement', 'Alcohols', 'Algorithms', 'Benzodiazepines', 'California', 'Caregivers', 'Cause of Death', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Communities', 'Conduct Clinical Trials', 'Data', 'Data Analyses', 'Databases', 'Death Rate', 'Development', 'Devices', 'Doctor of Philosophy', 'Dose', 'Early Diagnosis', 'Electrical Engineering', 'Emergency Situation', 'Emergency response', 'Epidemic', 'Evaluation', 'Event', 'FDA approved', 'Family member', 'Forehead', 'Goals', 'Gold', 'Home environment', 'Human', 'Industry', 'Intervention', 'Life', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Naloxone', 'Opioid', 'Opioid user', 'Overdose', 'Oxygen', 'Pain', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Physiological', 'Polysomnography', 'Positioning Attribute', 'Production', 'Pulse Rates', 'Regimen', 'Reporting', 'Research Personnel', 'Safety', 'Signal Transduction', 'Sleep', 'Specialist', 'Statistical Data Interpretation', 'Supervision', 'Technology', 'Testing', 'Tidal Volume', 'United States National Institutes of Health', 'addiction', 'base', 'care providers', 'chronic pain patient', 'design', 'dosage', 'emergency service responder', 'experience', 'follow-up', 'innovation', 'monitoring device', 'opioid epidemic', 'opioid mortality', 'opioid overdose', 'prescription opioid', 'prevent', 'programs', 'prototype', 'public health relevance', 'recruit', 'respiratory', 'signal processing', 'validation studies', 'wearable device', 'web site']",NIDA,"BIORESP TECHNOLOGIES, INC.",R43,2018,225000,0,-0.013668787451570451
"Towards automated phenotyping in epilepsy Over 5 million children and adults in the United States have had a diagnosis of epilepsy or a seizure disorder. However, treatment options for the epilepsies remain inadequate, because many patients suffer from uncontrolled seizures and from the negative side effects of treatment. A major obstacle to the faster development of new anti-convulsant therapies is the fact that rigorous preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). We propose to test if it is possible to perform objective, inexpensive and automated phenotyping of mice in various mouse models of acquired and genetic epilepsies. The approach rests on the recent recognition that mouse behaviors are structured in stereotyped modules at sub-second timescales that are arranged according to specific rules. These characteristic behavioral modules, and the transitions between them, can be identified without observer bias by combined 3D imaging and machine learning (ML) -assisted analytic methods. We propose to adopt this novel ML-assisted 3D video analysis technology to epilepsy research, in order to test if it can be used to identify mice with chronic temporal lobe epilepsy (TLE) during inter-ictal and ictal periods in two distinct experimental TLE models, and under various experimental conditions. In addition, we will also test whether the approach is able to automatically detect not only the overtly epileptic mice in a genetic model of severe childhood epilepsy (homozygous voltage-gated sodium channel β-subunit SCN1B-/- knock-out mice), but also distinguish the seemingly normal, non-epileptic, SCN1B+/- heterozygous mice from the wild-type controls. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user-independent, inexpensive analysis of acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will test if it is possible to objectively characterize epileptic phenotypes in mice using a breakthrough technology involving machine learning-assisted analysis of 3-dimensional video data of behavior. If successful, this innovative approach is expected to dramatically accelerate epilepsy research by enabling the objective, automated, inexpensive phenotyping of experimental animals to aid the testing of novel anticonvulsant therapies.",Towards automated phenotyping in epilepsy,9503816,R21NS102908,"['Adopted', 'Adult', 'Adverse effects', 'Animal Behavior', 'Animal Model', 'Animals', 'Anticonvulsants', 'Behavior', 'Behavioral', 'Characteristics', 'Child', 'Childhood', 'Chronic', 'Complex', 'Data', 'Development', 'Diagnosis', 'Electroencephalography', 'Epilepsy', 'Exhibits', 'Frequencies', 'Genetic', 'Genetic Models', 'Hippocampus (Brain)', 'Human', 'Human immunodeficiency virus test', 'Image', 'Knockout Mice', 'Machine Learning', 'Modeling', 'Monitor', 'Mus', 'Neurons', 'Observer Variation', 'Patients', 'Phenotype', 'Pilocarpine', 'Probability', 'Recurrence', 'Research', 'Rest', 'Seizures', 'Sodium Channel', 'Stereotyping', 'Structure', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Translational Research', 'United States', 'Wild Type Mouse', 'analytical method', 'base', 'cost', 'dravet syndrome', 'evidence base', 'high throughput analysis', 'innovation', 'kainate', 'learning strategy', 'mouse model', 'novel', 'novel therapeutics', 'pre-clinical', 'voltage']",NINDS,STANFORD UNIVERSITY,R21,2018,237423,560644462,-0.003683388826535375
"QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring Modern health monitoring devices at hospitals and wearable sensors in households generate a large amount of time series data at high rate, capturing the physiological status of patients in a real-lime fashion. The premise is that these technology advances enable a data-driven healthcare system that starts making fast, accurate, objective and inexpensive decisions based upon data, in addition to an individual physician's experience and preference. However, there is a significant gap in the mathematical theory and computational tools to promptly extract actionable information from multi-modal non-stationary time series data in a robust and tractable manner, which has become a serious roadblock to further utilize bigger data for better healthcare monitoring. The goal of this research program is to develop a mathematical framework for extracting time-frequency and geometric representations of multi-modal physiological data, in an online and robust manner, and use them to design machine learning algorithms to improve real-lime health monitoring. Specifically, we hypothesize that the development of time-series and geometric methods for large streaming multi-modal monitoring data will lead to more accurate diagnosis on various physiological monitoring applications, including detection and prediction of rare events such as seizure and arrhythmia, classification of sleep stages for newborns and children, and real-time artifact removal of physiological data. To achieve our goal, we plan to develop novel theoretical and computational tools for analyzing non-stationary multi-modal time series data with noise, corruption and missing data as well as real-time algorithms for filtering and event detection from such data. The tools and algorithms will be applied on clinical tasks at the Nationwide Children's Hospital. In addition, the real-time workflow will be implemented on Hadoop clusters with a mission of public sharing of both data and software. The development from the interdisciplinary team composed of mathematicians, biomedical informaticians as well as the hospital will not only transform the frontiers of mathematics knowledge, but also significantly impact clinical applications, data science education, and the development of the $11 O billion emerging market of wireless health. The goal of this project is to develop a series of novel computational theory and software to extract physiological information from the large multi-modal data streams generated by modern health monitoring devices. The tools will be applied to various clinical tasks such as detection and prediction of seizure and arrhythmia and classification of sleep stages for newborns and children, aiming for more accurate diagnosis.",QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring,9568758,R01EB025018,"['Address', 'Algorithms', 'Arrhythmia', 'Behavior', 'Big Data', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Science', 'Detection', 'Development', 'Diagnostic', 'Education', 'Environment', 'Event', 'Excision', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Household', 'Human body', 'Individual', 'Infant', 'Knowledge', 'Limes', 'Machine Learning', 'Mathematics', 'Measures', 'Methods', 'Mission', 'Modality', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Nature', 'Newborn Infant', 'Noise', 'Outcome', 'Patients', 'Pattern', 'Pediatric Hospitals', 'Physicians', 'Physiologic Monitoring', 'Physiological', 'Property', 'Public Domains', 'Research', 'Resources', 'Seizures', 'Series', 'Sleep Stages', 'Stream', 'Techniques', 'Technology', 'Time', 'Universities', 'Validation', 'Wireless Technology', 'accurate diagnosis', 'base', 'biological systems', 'clinical application', 'clinical practice', 'computerized tools', 'design', 'diagnostic biomarker', 'experience', 'frontier', 'geometric methodologies', 'graduate student', 'heart rate variability', 'improved', 'insight', 'mathematical theory', 'monitoring device', 'multimodality', 'novel', 'preference', 'programs', 'science education', 'signal processing', 'student training', 'theories', 'tool', 'wearable device']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2018,258070,30434536,0.0008688490232350958
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9548457,R01AR068456,"['Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Bone structure', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Screening procedure', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cortical bone', 'cost', 'density', 'experience', 'fracture risk', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'population based', 'public health relevance', 'response', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'treatment response']",NIAMS,UNIVERSITY OF COLORADO DENVER,R01,2018,273031,292134808,0.003524713545440312
"Adolescent Personality and the Incidence of Alzheimer's Disease and Alzheimer's Related Dementias in Later Life. Alzheimer’s Disease and Alzheimer’s related dementias (ADRD) are now regarded as a public health problem of pressing importance. While the race for disease-altering treatments continues, another strand of work has focused on identifying social and psychological precursors of these conditions. Such biopsychosocial risks often can be traced back to phases of life that predate symptom onset by years or decades. Therefore, a robust social and life course epidemiology of ADRD requires study designs that feature a) broad and deep psychosocial characterization of b) a large, population-relevant cohort c) during early phases of life, with d) medically-documented outcome data. Parent project R01AG053155 features a) through c), specifically in 90,000 members of the Project Talent cohort assessed in 1960 and again in 1970-74. The current supplement expands its scope to all members of Project Talent baseline (roughly 340,000) from 1960, and focuses on two scientific aims. The first seeks to estimate the relative risk of ADRD by the early 70s arising from adolescent personality traits, as documented in Medicare data linked to the cohort. One key feature of this aim is to determine if aspects of personality in adolescence are associated with ADRD incidence in later life independently of adolescent IQ, which is a known predictor. The second key aspect of this aim is to use the size and population representativeness of the sample to derive reasonably precise population-relevant effect size estimates of personality relative risks, and compare these effect sizes to benchmark risk estimates of adolescent IQ and socioeconomic status, which are considered to have policy and public health significance. The second aim also leverages the size and scope of the sample to identify personality traits which may moderate the ADRD risk of low adolescent IQ, in more complex and realistic patterns than can be studied in smaller or less representative data sets. This is accomplished via machine learning methods focused on identifying non-linear interactions via intensive cross-validation, another scientific question that takes full advantage of the size and scope of this unique cohort. Alzheimer’s Disease and Alzheimer’s related dementias are on the rise, due to both increasing life spans and the size of the Baby Boom generation as it reaches these later years. While scientists have yet to develop cures for dementias, it may be possible to learn how to prevent or delay their onset by studying life circumstances that give rise to these conditions. The goal of this project is to determine how personality traits in adolescence may compensate for the dementia risk posed by low adolescence IQ scores.",Adolescent Personality and the Incidence of Alzheimer's Disease and Alzheimer's Related Dementias in Later Life.,9688395,R01AG053155,"['Adolescence', 'Adolescent', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease model', 'Alzheimer&apos', 's disease risk', 'Area', 'Awareness', 'Baby Booms', 'Back', 'Behavioral', 'Benchmarking', 'Complex', 'Data', 'Data Set', 'Deltastab', 'Dementia', 'Diagnosis', 'Disease', 'Elderly', 'Etiology', 'Funding', 'Generations', 'Goals', 'High School Student', 'Incidence', 'Knowledge', 'Learning', 'Life', 'Life Cycle Stages', 'Life course epidemiology', 'Link', 'Literature', 'Longevity', 'Machine Learning', 'Measurement', 'Medical', 'Medicare', 'Methods', 'Modification', 'Neurotic Disorders', 'Outcome', 'Pattern', 'Personality', 'Personality Traits', 'Phase', 'Policies', 'Policy Maker', 'Population', 'Psychosocial Factor', 'Public Health', 'Race', 'Relative Risks', 'Research Design', 'Research Personnel', 'Risk', 'Risk Estimate', 'Risk Factors', 'Role', 'Sampling', 'Scientist', 'Socioeconomic Status', 'Symptoms', 'Talents', 'Techniques', 'Testing', 'Validation', 'Work', 'biopsychosocial', 'cohort', 'epidemiologic data', 'exhaustion', 'flexibility', 'follow-up', 'learning strategy', 'member', 'middle age', 'mortality', 'parent project', 'population based', 'pre-clinical', 'prevent', 'prospective', 'psychologic', 'psychosocial', 'public health priorities', 'social', 'trait']",NIA,UNIVERSITY OF ROCHESTER,R01,2018,287001,179705973,-0.04972468600015542
"Cerebral Palsy Risk Identification System PROJECT SUMMARY AND ABSTRACT [ Pediatric specialists are often required to identify infants who are likely to suffer poor neurodevelopmental outcome, including Cerebral Palsy (CP). CP is the most common developmental disability among children in the United States and results from several factors, including low weight for gestational age, premature birth, and stroke. Although MRI and cranial ultrasound (cUS) provide valuable structural information in the preterm period, they have moderate sensitivity to CP and require transportation of the infant. Over the past 20 years, numerous studies have validated the clinical potential of General Movement Assessment (GMA) for CP risk identification. During the early period, (23 weeks to 36 weeks gestational age), the presence of Cramped Synchronized General Movements (CSGMs), has demonstrated very high sensitivity and specificity for CP, conjointly ranging from 80%-98%. CSGMs are assessed while preterm infants are still in an acute care facility (NICU) and can inform the clinician independently, and in combination with cUS and MRI. Despite its potential, GMA is available in only a few clinical centers, as adoption and routine application depend on lengthy, cost-intensive observation and availability of specially trained raters. A Cerebral Palsy Risk Identification System (CPRIS) is proposed that will automate GMA for bedside evaluations in both preterm and postterm periods. The CPRIS constitutes a key enabling technology not only for routine risk identification, but also for establishing disease trajectory and potentially differentiating CP subtypes and assessing efficacy of emerging treatments along the early developmental continuum.  Preliminary studies at UC Irvine have demonstrated that GMA analysis for CSGMs can be automated by quantifying infant limb movement using highly miniaturized, 3-axis wireless accelerometers and classifying CSGMs using a patented Markov-type approach that merges an application-specific Erlang-Cox state transition model with a Dynamic Bayesian Network (“EC-DBN”), treating instantaneous machine learning classification values as observations and explicitly modeling CSGM (and non-CSGM) duration and interval. In Phase I, this approach will be utilized in a comparative evaluation of two movement measurement modalities to determine which has the best overall performance and clinical utility at three leading NICU centers. Infant movement data will be concurrently acquired using an advanced, second generation prototype wireless accelerometer system (CPRIS-A) and a high definition 3D (infrared) optical camera (CPRIS-O). The optical modality offers significant potential advantages as it requires no infant contact and can monitor unattended, intermittently, over weeks or months. However, its potential for GMA automation must be systematically evaluated. Classifier results from both modalities will be compared to expert rater consensus in 80 preterm infants. The primary outcome will be CSGM identification accuracy, as determined by ROC-AUC analyses, with a threshold for success of 0.85. Additional comparative performance measures include reliability and practicability in the NICU environment. An Advisory Committee of experts in the fields of neonatology, pediatrics and cerebral palsy will evaluate project results and advise on the clinical potential of each modality. ] PROJECT NARRATIVE Cerebral palsy is the most common physical disability in childhood, with a prevalence of 2.1 cases per 1000 in high-income countries. The overall project goal is to develop a computerized hardware-software system capable of identifying preterm infants at high risk of developing cerebral palsy (CP), based on the systematic identification of specific patterns of movement-derived features. The Cerebral Palsy Risk Identification System (CPRIS) will enable clinical staff with only minimal training to cost effectively implement General Movement Assessment (GMA) for Cramped Synchronous General Movements (CSGMs), with interpretive reporting performed automatically. The CPRIS constitutes a key enabling technology for advancement in the identification, characterization and treatment assessment of CP.",Cerebral Palsy Risk Identification System,9621149,R43NS098840,"['Accelerometer', 'Acute', 'Adoption', 'Advisory Committees', 'Algorithms', 'Architecture', 'Area', 'Automation', 'Biological Markers', 'Birth', 'Brain', 'Budgets', 'Cephalic', 'Cerebral Palsy', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical assessments', 'Collaborations', 'Communication', 'Consensus', 'Country', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Development', 'Developmental Disabilities', 'Diagnosis', 'Diagnostic', 'Disease', 'Drops', 'Electronic Health Record', 'Enrollment', 'Environment', 'Equipment', 'Evaluation', 'Frequencies', 'Generations', 'Gestational Age', 'Goals', 'Health care facility', 'Healthcare Systems', 'Incidence', 'Income', 'Infant', 'Legal patent', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motor', 'Movement', 'Multicenter Trials', 'Muscle Cramp', 'National Institute of Child Health and Human Development', 'National Institute of Neurological Disorders and Stroke', 'Neonatology', 'Optics', 'Outcome', 'Patients', 'Pattern', 'Pediatrics', 'Performance', 'Phase', 'Physically Handicapped', 'Premature Birth', 'Premature Infant', 'Prevalence', 'Production', 'Progress Reports', 'Provider', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Specialist', 'Strategic Planning', 'Stroke', 'System', 'Technology', 'Time', 'Training', 'Transportation', 'Ultrasonography', 'United States', 'Validation', 'Video Recording', 'Weight', 'Wireless Technology', 'base', 'clinical practice', 'comparative', 'computer based statistical methods', 'computerized', 'computerized data processing', 'cost', 'critical period', 'data modeling', 'data sharing', 'digital', 'experience', 'field study', 'follow-up', 'heuristics', 'high risk', 'improved', 'indexing', 'limb movement', 'miniaturize', 'new technology', 'perinatal brain', 'postnatal period', 'primary outcome', 'prospective', 'prototype', 'software systems', 'success', 'tool']",NINDS,"NEUROCOMP SYSTEMS, INC.",R43,2018,300502,0,-0.015963115153834362
"Instrumental screening for dysphagia by combining high-resolution cervical auscultation with advanced data analysis tools to identify silent dysphagia and silent aspiration ABSTRACT Dysphagia (disordered swallowing) causes nearly 150,000 annual hospitalizations and over 220,000 additional hospital days, and prolongs hospital lengths of stay by 40%. Dysphagia risk is typically identified through subjective screening methods and those identified through screening undergo gold standard imaging testing such as videofluoroscopy (VF). However, screening methods over- or underestimate risk, and completely fail to identify patients with silent dysphagia (e.g., silent aspiration) that can cause pneumonia and other adverse events. Pre-emptive detection of silent or near-silent aspiration is essential. The long term goal is to develop an instrumental dysphagia screening approach based on high-resolution cervical auscultation (HRCA) in order to early predict dysphagia-related adverse events, and initiate intervention measures to mitigate them. The overall objective here is to develop accurate, advanced data analysis approaches to translate HRCA signals to swallowing events observed in VF images. Our strong preliminary data has led us to our central hypothesis: advanced data analytics tools are suitable approaches for the analysis of HRCA in order to automate dysphagia screening. The rationale is that a reliable, robust early-warning instrumental dysphagia screening approach will reduce adverse events in patients with silent aspiration/dysphagia, shorten length of stay and improve overall clinical outcomes. Guided by strong preliminary data, we will pursue the following three specific aims: (1) develop machine learning algorithms to differentiate HRCA signals produced by swallowing physiologic events from similar, non-swallow related signals produced during swallowing; (2) translate HRCA swallowing-signal signatures to actual swallow physiologic events to detect abnormal swallowing physiology; and (3) discriminate normal from abnormal airway protection and swallow physiology via machine-learning analysis of HRCA signals with similar accuracy as VF. Under the first aim, a machine learning approach will be used to detect pharyngeal swallowing events and differentiate them from speech, cough and other non- swallow events, with 90% accuracy, when compared to a human expert’s interpretation of our VF data sets. Under the second aim, objective swallowing physiology observations from VF will be matched to swallowing events observed with HRCA in order to show that abnormal swallow physiology and airway protection will produce distinctive HRCA signal signatures that predict the same events identified with VF. Under the third aim, analytical algorithms will be used to detect signs of disordered airway protection in HRCA signal signatures with 90% accuracy when compared to a human expert’s airway protection ratings from VF images. The approach is innovative, as it will produce analysis tools that will infer about dysphagia and aspiration based on the analysis of HRCA with unprecedented accuracy, before patients are placed in harm’s way. Our work is significant, because it will translate to an early-warning HRCA screening tool that predicts dysphagia- related adverse events in asymptomatic patients reducing medical adverse events, and length of stay. The proposed research is relevant to public health because dysphagia is related to nearly 150,000 annual hospitalizations and over 220,000 additional hospital days, it increases pneumonia incidence, prolongs hospital stays by 40% for patients with many diseases, and is prevalent in acute care hospitals and nursing homes. Choking (airway obstruction) and pneumonia due to aspiration (inhalation of swallowed food and liquids), are common results of dysphagia, and both are preventable when dysphagia is identified before patients are offered oral food, liquids or medications. The proposed research is relevant to the part of NIH’s mission that pertains to enhancing health, lengthening life and reducing illnesses, as we will develop new data analytics tools to be used along with high-resolution cervical auscultation in order to instrumentally screen for dysphagia and predict dysphagia-related adverse events before they can harm patients with dysphagia.",Instrumental screening for dysphagia by combining high-resolution cervical auscultation with advanced data analysis tools to identify silent dysphagia and silent aspiration,9540043,R01HD092239,"['Acute', 'Address', 'Admission activity', 'Adult', 'Adverse event', 'Algorithmic Analysis', 'Algorithms', 'Aspirate substance', 'Aspiration Pneumonia', 'Auscultation', 'Biomechanics', 'Caring', 'Cervical', 'Choking', 'Clinical', 'Coughing', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Deglutition', 'Deglutition Disorders', 'Dehydration', 'Dementia', 'Detection', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Disabled Persons', 'Disease', 'Equipment', 'Event', 'Food', 'Goals', 'Gold', 'Group Homes', 'Head and Neck Cancer', 'Health', 'Hospital Nursing', 'Hospitalization', 'Hospitals', 'Human', 'Image', 'Impairment', 'Incidence', 'Inhalation', 'Intervention', 'Lead', 'Learning', 'Length of Stay', 'Life', 'Liquid substance', 'Machine Learning', 'Malnutrition', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monte Carlo Method', 'Morbidity - disease rate', 'Nature', 'Neurodegenerative Disorders', 'Nursing Homes', 'Oral', 'Outcome', 'Pathologic', 'Patient risk', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Physiological', 'Physiology', 'Pneumonia', 'Positioning Attribute', 'Public Health', 'Research', 'Resolution', 'Risk', 'Screening procedure', 'Severities', 'Signal Transduction', 'Speech', 'Stroke', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Water', 'Work', 'airway obstruction', 'analytical tool', 'base', 'cancer therapy', 'clinical practice', 'clinically significant', 'image processing', 'improved', 'innovation', 'instrument', 'kinematics', 'mortality', 'patient safety', 'predictive signature', 'predictive tools', 'screening', 'tool', 'translational impact', 'vibration']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2018,304104,570146095,0.003078883493247137
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,9445086,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'actionable mutation', 'base', 'disease phenotype', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'learning strategy', 'metabolomics', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,305167,511185245,-0.019332391758118028
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9579149,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2018,314000,560644462,-0.021444199248779924
"Data-Driven Shape Analysis for Quantitative Severity Stratification in Patients with Metopic Craniosynostosis Abstract Craniosynostosis affects close to one in 2000 newborns and causes growth restriction perpendicular to the affected suture. Metopic craniosynostosis is the second most common form of craniosynostosis. The metopic suture is an important sight of cranial growth as the brain rapidly expands in the ﬁrst year of life. Patients affected by metopic craniosynostosis will present in the ﬁrst few months of life with varying degrees of narrowing of the forehead and brow, a triangular shaped head, and an abnormal eye position. Surgery is recommended early in childhood to normalize the head shape and expand the restricted skull to prevent complications such as headaches, cognitive impairment, and visual disturbances including blindness.  Imaging with computed tomography (CT) is employed to conﬁrm new diagnoses of metopic craniosynostosis and, together with the physical exam, is used in a descriptive and qualitative manner to assess the degree of head shape abnormality. Several methods have been employed to interpret the information provided in the CT scans to allow surgeons to utilize data for surgical decision making. However, these indices reduce the complex three-dimensional skull dysmorphology into isolated measurements of angles or proportions, require detailed calculations to perform, and no universally accepted standard has emerged so far despite signiﬁcant research efforts and clinical motivation.  In this grant proposal, we aim to increase our understanding of the cranial dysmorphology in patients with metopic craniosynostosis by employing latest results from statistical shape modeling and deep learning. Specif- ically, we will build a statistical shape model of pediatric skulls from CT images of patients with metopic cran- iosynostosis as well as a group of normal controls capturing normal phenotypical shape variations. The distance of a new shape from the normative shape space will represent the proposed Shape Normality Metric (SNM). The SNM will be validated against ratings from experts in the surgical community (current standard of care) who will be asked to assess the dysmorphology of the skulls in our database. To avoid surgeons' subjective bias, we will aggregate their response using statistical methods that compensate for potential individual bias. Finally, to streamline data collection for future research we will develop a head-shape portal that will allow users to upload CT scans of their patients and the system will automatically calculate the SNM.  By developing a severity metric that encompasses the entire extent of dysmorphology in metopic craniosyn- ostosis and establishing a head-shape portal, we will improve our understanding of the spectrum of metopic craniosynostosis, aid in pre-operative and surgical decision making, enable future research, and help facilitate longitudinal outcomes assessments and multi-center communication and collaboration. Narrative This grant proposal aims to improve our understanding of the head shape anomaly associated with metopic craniosynostosis by using recent results from statistical shape analysis and deep learning, with the goal of developing an objective metopic cranioynostosis severity scale. Different from previously proposed metrics, our approach evaluates the entire shape as a whole. With this information, surgeons will be able to objectively determine how severely affected their patients are and will be better able to tailor their interventions to the needs of their individual patients. Additionally, surgeons will be able to better communicate with each other and study the effects of surgical intervention on their patients which will improve patient care in the long run.",Data-Driven Shape Analysis for Quantitative Severity Stratification in Patients with Metopic Craniosynostosis,9669833,R21EB026061,"['Address', 'Affect', 'Age', 'Agreement', 'Applications Grants', 'Biological Neural Networks', 'Blindness', 'Brain', 'Cephalic', 'Child', 'Childhood', 'Clinical', 'Cognition', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer software', 'Craniosynostosis', 'Data', 'Data Collection', 'Databases', 'Decision Making', 'Deformity', 'Descriptor', 'Development', 'Diagnosis', 'Dimensions', 'Dysmorphology', 'Ethnic Origin', 'Eye Abnormalities', 'Forehead', 'Future', 'Gender', 'Goals', 'Gold', 'Graph', 'Growth', 'Head', 'Headache', 'Home environment', 'Human', 'Ice', 'Image', 'Imagery', 'Impaired cognition', 'Individual', 'Institution', 'Intervention', 'Joint structure of suture of skull', 'Left', 'Letters', 'Life', 'MRI Scans', 'Measurement', 'Measures', 'Methods', 'Modality', 'Modeling', 'Morphology', 'Motivation', 'Newborn Infant', 'Normalcy', 'Operative Surgical Procedures', 'Outcome Assessment', 'Output', 'Pathologic', 'Patient Care', 'Patients', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Procedures', 'Protocols documentation', 'Reconstructive Surgical Procedures', 'Research', 'Sampling', 'Scanning', 'Severities', 'Shapes', 'Socialization', 'Statistical Methods', 'Stereophotogrammetries', 'Stratification', 'Supervision', 'Surgeon', 'Surgical sutures', 'System', 'Techniques', 'Training', 'Trauma patient', 'Treatment Protocols', 'United States', 'Validation', 'Variant', 'Vision', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical care', 'cranium', 'deep learning', 'experience', 'image processing', 'improved', 'indexing', 'individual patient', 'operation', 'patient stratification', 'power analysis', 'premature', 'prevent', 'reconstruction', 'response', 'self esteem', 'shape analysis', 'standard of care', 'surgery outcome', 'web-based tool']",NIBIB,UNIVERSITY OF UTAH,R21,2018,317513,228951281,1.0953355151837994e-05
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9406318,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cancer Etiology', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2018,356625,323604360,-0.0013986293307253622
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9547376,R01DE027027,"['Accounting', 'Affect', 'Algorithms', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,362947,135644722,-0.007480241397047244
"A platform for mining, visualization and design of microbial interaction networks Project Summary One of the burning questions in the study of the human microbiome is whether and how it is possible to design specific strategies for rebalancing the taxonomic and functional properties of human-associated microbial communities, triggering the transition from “disease states” to “healthy states”. While empirical studies provide strong support for the idea that we may be able to cure, or at least  treat, a number of diseases by simply transplanting microbiomes, or inducing changes through taxonomic or environmental perturbations, to date little mechanistic understanding exists on how microbial communities work, and on how to extend microbiome research from an empirical science to a systematic, quantitative field of biomedicine. We propose here to establish a computational platform--   a database (Aim 1) with fully integrated analytical software (Aims 2 and 3) --- developed for and with the cooperation of the scientific community. The resource goes beyond cataloguing microbial abundances under different condition; its aim is to enable an understanding of networks of interacting species and their condition-dependence, with the goal of eventually facilitating disease diagnosis and prognosis, and designing therapeutic strategies for microbiome intervention. Our project is centered around three key aims: 1.	The creation of a Microbial Interaction Network Database (MIND), a public resource that will collect data on inter-species interactions from metagenomic sequencing projects, computer simulations and direct experiments. This database will be accessed through a web-based platform complemented with tools for microbial interaction network analysis and visualization, akin to highly fruitful tools previously developed for the study of genetic networks; the database will also serve as the public repository of microbial networks associated with human diseases; 2.	The implementation of an integrated tool for simulation of interspecies interactions under different environments, based on genomic data and whole-cell models of metabolism; 3.	The implementation of new algorithms for microbial community analysis and engineering. These algorithms, including stoichiometric, machine-learning and statistical approaches will facilitate a “synthetic ecology” approach to help design strategies (e.g. microbial transplants or probiotic mixtures) for preventing and targeting microbiome-associated diseases. Our work will fill a major gap in current microbiome research, creating the first platform for global microbial interaction data integration, mining and computation. Project Narrative Among the major developments of the genomic revolution has been the ability to identify thousands of microbial species and strains living in communities in 5 major habitats in the human body, and the recognition that the relative abundances of these populations is strongly correlated with environment: disease state, diet, treatment protocol and so on. A major challenge in utilizing the deluge of health relevant data is structuring it into a database that facilitates understanding inter-microbial interactions in these communities. The aim of this proposal is to create a database and integrated computational platform, open to and contributed to by the research community, which will greatly accelerate the conversion of data into health related actionable knowledge.","A platform for mining, visualization and design of microbial interaction networks",9420621,R01GM121950,"['Affect', 'Algorithms', 'Cataloging', 'Catalogs', 'Cell model', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Development', 'Diet', 'Discipline', 'Disease', 'Ecology', 'Ecosystem', 'Empirical Research', 'Engineering', 'Environment', 'Evolution', 'Future', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Habitats', 'Health', 'Human Biology', 'Human Microbiome', 'Human body', 'Imagery', 'Individual', 'Intervention', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Mediating', 'Metabolic', 'Metabolism', 'Metadata', 'Methods', 'Microbe', 'Mining', 'Nature', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Preventive Medicine', 'Probiotics', 'Property', 'Research', 'Resources', 'Science', 'Scientist', 'Structure', 'Taxonomy', 'Technology', 'Therapeutic', 'Time', 'Transplantation', 'Treatment Protocols', 'Work', 'base', 'computer framework', 'data integration', 'data to knowledge', 'design', 'disease diagnosis', 'experimental study', 'feeding', 'genome-wide', 'genomic data', 'human disease', 'human microbiota', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microbiome research', 'microbiota transplantation', 'microorganism interaction', 'novel diagnostics', 'novel therapeutics', 'open source', 'outcome forecast', 'prevent', 'repository', 'simulation', 'tool', 'user-friendly']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2018,374683,61050884,-0.02011656040006963
"Smartphone phenotype collection for diagnostic screening of mild cognitive impairment Project Summary This project addresses a critical need for early detection of mild cognitive impairment (MCI) and other Alzheimer's-related dementias (ADRD). Advances in smartphone hardware, computer vision, and machine learning have enabled the possibility of producing smartphone-based cognitive testing applications able to collect electronic sensor data and transform it into highly informative phenotypes that can serve as early indicators of future disease progression. In this project, we aim to develop a revolutionary new smartphone- based cognitive testing platform, called CTX, that will enable the rapid development and deployment of smartphone-based tests that can capture raw sensor streams in a synchronized fashion, subsample and compress the combined streams, and transmit them to a cloud server for subsequent analysis and modeling. CTX will provide a high-level application development framework that will significantly reduce the time and technical knowledge required to produce a smartphone-based cognitive testing application by providing an application programming interface (API) that enables developers to simply declare what sensor data should be collected and when. The framework will handle all the details of collecting the sensor data, synchronizing it, and transmitting it to a back-end server. The API will also have a variety of other high-level features to facilitate development of cognitive test apps. To demonstrate the feasibility of our vision for CTX, in Aim 1 of this project we will develop the software framework, back-end server software and a prototype smartphone app to exercise and validate many of the platform's features. For Aim 2, we will develop three different tests for this app to test saccade (eye movement) latency, verbal recall, and wrist mobility, each collecting a different type of sensor data (video, audio, and inertial measurement). These tests were selected because their results have been been shown to be predictive of MCI. We will implement phenotype extraction pipelines that employ advanced signal processing, machine learning, and computer vision algorithms to extract the target phenotypes from the sensor data collected for these tests and demonstrate they operate with sufficient accuracy to replicate published experimental designs. Successful completion of this project will eliminate the need for expensive and cumbersome phenotype collection equipment (e.g., eye tracking stations) and create the possibility of generating data from which MCI onset can be predicted. Data collected in Phase II via these and other such tests will enable us to apply our machine learning expertise to produce models able to predict transition to MCI that are both sensitive and specific, transforming any smartphone into an MCI risk assessment tool available for at-home use by millions of people. Project Narrative This NIH Phase I project will address the critical need for early detection of Alzheimer's Disease (AD) and Alzheimer's-related dementias (ADRD) by developing a revolutionary new smartphone-based cognitive testing platform that will provide individuals with an ongoing status of their cognitive health. Doctors who are given access to the results of these tests will be able to monitor patients more closely and provide more timely diagnoses. By studying test results from many people, researchers may someday be able to identify patterns that can distinguish mild cognitive impairment from normative age-related cognitive decline.",Smartphone phenotype collection for diagnostic screening of mild cognitive impairment,9679400,R43AG062072,"['Achievement', 'Address', 'Adult', 'Age', 'Age-associated memory impairment', 'Algorithms', 'Alzheimer disease detection', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease model', 'Apple', 'Assessment tool', 'Back', 'Big Data', 'Cellular Phone', 'Cognitive', 'Collection', 'Computer Vision Systems', 'Computer software', 'Cyclophosphamide', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic tests', 'Disease Progression', 'Early Diagnosis', 'Elderly', 'Emotional', 'Equipment', 'Exercise', 'Exhibits', 'Experimental Designs', 'Eye', 'Eye Movements', 'Face', 'Facial Expression', 'Forearm', 'Frequencies', 'Future', 'Genetic Risk', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Image', 'Individual', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Memory impairment', 'Methods', 'Modeling', 'Monitor', 'Patient Monitoring', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Publishing', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Risk Assessment', 'Rotation', 'Saccades', 'Scanning', 'Secure', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Software Framework', 'Software Tools', 'Stream', 'Tablets', 'Telephone', 'Test Result', 'Testing', 'Time', 'United States National Institutes of Health', 'Vision', 'Visuospatial', 'Work', 'Wrist', 'Yang', 'age related', 'age related cognitive change', 'application programming interface', 'base', 'cloud platform', 'cognitive development', 'cognitive task', 'cognitive testing', 'cohort', 'cost', 'crowdsourcing', 'data modeling', 'diagnostic screening', 'interest', 'markov model', 'mild cognitive impairment', 'predictive modeling', 'prototype', 'response', 'screening', 'sensor', 'signal processing', 'smartphone Application', 'software development', 'success']",NIA,"PARABON NANOLABS, INC.",R43,2018,394297,0,-0.05459238463927014
"Genomic and Phenomic Architecture of Heart Failure The overarching goal of this project is to improve care for patients with heart failure (HF). HF, whether with reduced (HFrEF) or preserved (HFpEF) ejection fraction, is associated with significant morbidity, mortality, and cost. In the U.S. alone, HF affects over 5 million adults, and the prevalence is projected to exceed 8 million by 2030. HF is the most frequent cause of hospitalization among Medicare recipients and results in over $30 billion in health care expenditures each year. Advances in management, especially for HFrEF, have modestly reduced death rates over time, but mortality continues to be high, with approximately half of patients dying within 5 years of diagnosis. Moreover, the pace of drug discovery has been slow, and there are no proven therapies for patients suffering with HFpEF. Among patients with established HF there is substantial variation in illness severity, degree of cardiac remodeling, disease progression, and response to therapy. These observations highlight the heterogeneity of the HF syndrome and suggest existence of subtypes with differing clinical and potentially genetic profiles, with subsequent differences in downstream disease mechanisms, overall risk, and therapeutic response. However, the understanding of the phenotypic, genetic, and pathophysiological heterogeneity of HF is incomplete. This project investigates the phenotypic substructure and genetic architecture of HF by leveraging a unique collection of interrelated datasets from Vanderbilt University Medical Center (VUMC), including the de- identified electronic health record (EHR) and BioVU, a linked DNA biobank. The EHR contains ~2.6 million patients, including ~35,000 with HF, and BioVU currently houses >225,000 DNA samples. Dense genotype data are available in >28,000 subjects and an institutional genotyping project will increase this to >125,000 by mid- 2017; this includes >13,000 subjects with HF. The proposed research will: 1) identify HF subtypes from dense clinical data alone using advanced, unbiased, deep learning algorithms (Aim 1), 2) define the genetic architecture of HF and HF subtypes by using inferred gene expression, general linear mixed models, genetic risk scores, and traditional association testing to quantify heritability of and genetic correlations among HF subtypes, define the contribution of established risk factors to HF subtypes, and 3) discover subtype-specific genetic risk factors (Aim 2), and discover HF subtype-specific clinical outcomes, disease associations, and drug response phenotypes using advanced phenome scanning and network analysis (Aim 3). Heart failure (HF) is a complex, debilitating syndrome associated with significant morbidity and mortality. The heterogeneity of HF has limited success of prior efforts to understand HF pathobiology and develop effective interventions. By defining clinical and genetic modifiers of HF risk, disease course, and treatment response for clinically recognized and novel, data-driven HF subtypes, results from this work could result in a more sophisticated HF classification system based on underlying biology, and ultimately facilitate precision risk stratification, tailoring of therapeutic strategies, and rational HF clinical trials.",Genomic and Phenomic Architecture of Heart Failure,9427555,R01HL140074,"['Academic Medical Centers', 'Adult', 'Affect', 'Algorithms', 'Architecture', 'Biological', 'Biology', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular Diseases', 'Cardiovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collection', 'Comorbidity', 'Complex', 'Consensus', 'DNA', 'Data', 'Data Set', 'Death Rate', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'EFRAC', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Etiology', 'Failure', 'Gene Expression', 'Genetic', 'Genetic Heterogeneity', 'Genetic Risk', 'Genetic Transcription', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health Expenditures', 'Heart failure', 'Heritability', 'Heterogeneity', 'Hospitalization', 'Human', 'Link', 'Measures', 'Mediator of activation protein', 'Medical', 'Medical Genetics', 'Medicare', 'Modeling', 'Morbidity - disease rate', 'Myocardial dysfunction', 'Natural History', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Prevalence', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Sampling', 'Scanning', 'Severity of illness', 'Subgroup', 'Syndrome', 'System', 'Testing', 'Therapeutic', 'Time', 'Variant', 'Work', 'base', 'biobank', 'cohort', 'cost', 'deep learning', 'defined contribution', 'disease phenotype', 'drug discovery', 'effective intervention', 'genetic architecture', 'genetic association', 'genetic profiling', 'genetic risk factor', 'genome wide association study', 'genomic data', 'improved', 'learning strategy', 'mortality', 'novel', 'phenome', 'phenomics', 'response', 'risk variant', 'success', 'treatment response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,395000,377931988,-0.005287641018704864
"Advanced Risk Adjusters and Predictive Formulas for ICD-10 Based Risk Adjustment Diagnosis-based risk adjustment is widely used in the US and abroad for health plan payment, notably for Medicare Parts C and D, for commercial contracting and quality assessment, and in numerous state Medicaid programs. Yet the risk adjustment technology used for payments has not kept up with improved classification systems, larger patient datasets, improved estimation algorithms or recent theoretical and clinical developments. Our work will take advantage of the richer ICD-10-CM classification system, in use since October 2015, with over 5 times as many diagnoses as ICD-9-CM Codes. ICD-10 codes now recognize: left vs. right side for thousands of conditions, distinguish between initial, subsequent and sequela diagnoses, and incorporate hundreds of new clinical, demographic and biometric variables. Based on the ICD-10, more exact models can leverage increased diagnostic coding accuracy to reduce opportunities for gaming or discriminating against patients with conditions who are predicted to be unprofitable. Led by two of the three developers of the Centers for Medicare and Medicaid Services Hierarchical Condition Category (CMS-HCC) existing classification system, our team of physicians, public policy experts, statisticians and economists will comprehensively improve the accuracy of risk adjustment and predictive models using larger sample sizes, clinical judgment and state-of-art economic and statistical modeling. We will also expand the conventional regression methods explored, to include machine learning algorithms, constrained regression, and LASSO estimation. We will calculate a new “appropriateness to include” (ATI) score that captures diagnostic vagueness, discretion and suitability for use in risk adjustment models, and use this score to inform which variables are included in plan payment formulas. Selection incentives remain of concern in public US health plan payments formulas and may be costing Medicare over $5 billion per year (NBER 2017). Prediction and payment models from this project can reduce overpayment and offset plan incentives to skimp on services that attract sick people. To ensure that these models and formulas are useful for enrollees of all ages, they will initially be calibrated and tested on large commercially-insured claims data, covering ages 0 to 64. They will then be validated and refined for Medicare, Medicaid, and state employees using data from All-Payer Claims Data from five states and a second large commercial dataset. We will make development steps, statistical programs, and full details of the classification system and prediction formulas publicly available for comment, refinement, and use by health care delivery system researchers, payers and providers. Project Narrative This project will develop new classification systems and new prediction and payment models that take advantage of the fivefold increase in diagnostic codes available with the October 2015 change from ICD- 9-CM to ICD-10-CM. Using data from two national claims datasets and five state all-payer claims datasets that collectively cover over 75 million enrollees, we will identify new, underutilized ICD-10 capabilities, create new clusters of diagnoses useful for prediction, develop new algorithms for using these clusters, and estimate formulas that predict spending, utilization and diverse health care outcomes for all ages. Methods and results will be publicly described and software posted on the web for use in risk adjustment and diverse clinical, financial, policy evaluation, and quality assessment outcomes by health care delivery system researchers, payers and providers.",Advanced Risk Adjusters and Predictive Formulas for ICD-10 Based Risk Adjustment,9644117,R01HS026485,[' '],AHRQ,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2018,397399,61050884,0.0072826792958493505
"Geometric Surrogates for Clinical Management of Abdominal Aortic Aneurysms ﻿    DESCRIPTION (provided by applicant): This proposal will investigate the following hypothesis: that the quantification of geometric surrogates, which predict the ensuing peak wall rupture risk index (PWRRI), will provide an improved estimate of aneurysm rupture risk compared to the clinical standard of maximum aneurysm diameter. We thus propose the highly innovative use of both radiological and non-radiological clinical imaging to develop a computational tool that can assess AAA risk of rupture with greater accuracy than the current clinical standard. Such a tool will allow the accurate quantification of individual AAA geometry to achieve the main goal of the study, which is to identify the patient-specific AAA geometry characteristics that are surrogates for patient-specific PWRRI. In the proposed approach, we will first compute a truly individualized PWRRI based on an innovative method called image-based Vascular Mechanical Characterization technology (iV-MeCh). The geometry characteristics highly correlated with PWRRI will be considered the surrogates of this biomechanics-based index. A second phase of the study will be the validation of the surrogates with actual clinical outcomes, which will yield the accurate predictors of rupture. This approach, devoid of complex finite element modeling and based on a fast, nearly automated computational tool for geometry quantification, would provide an exceptional rationale for the need for surgical intervention and be of major clinical significance. Therefore, the following specific aims are to be completed during the project period to address the aforementioned hypothesis: (1) Validate iV-MeCh for estimating patient-specific spatio-temporal AAA wall stress; (2) Calculate individual PWRRI using iV-MeCh for high and low risk of rupture AAA; (3) Identify the individual geometry characteristics that are surrogates of PWRRI; and (4) Assess the clinical significance of geometric surrogates for the prediction of AAA rupture risk. The primary outcome of this research will be the ability to disambiguate or demystify rupture risk in AAA for which the standard of care (maximum diameter) is not an accurate metric for assessing their at-risk condition. The geometric surrogates of PWRRI are hypothesized to reduce false positives and false negatives compared to the conventional maximum diameter cut-off for recommending elective repair. In addition, PWRRI is predicted by means of a new, novel technique (iV-MeCh), which estimates wall stress in aneurysms by means of non-radiological clinical imaging and without the use of constitutive soft tissue mechanics. PUBLIC HEALTH RELEVANCE: This award will enable the validation of computational tools for non-invasively predicting the at-risk condition of patients with abdominal aortic aneurysms (AAAs) based on the assessment of aneurysm geometry. This research is expected to impact the clinical management of AAA disease, as well as the pre-surgical planning capabilities of vascular and endovascular aneurysm repair.",Geometric Surrogates for Clinical Management of Abdominal Aortic Aneurysms,9463479,R01HL121293,"['Abdominal Aortic Aneurysm', 'Address', 'Aneurysm', 'Award', 'Biomechanics', 'Blood Vessels', 'Caliber', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Complex', 'Consent', 'Data', 'Development', 'Diagnosis', 'Disease', 'Electrocardiogram', 'Elements', 'Foundations', 'Geometry', 'Goals', 'Growth', 'Image', 'Individual', 'Intervention', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Motion', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Patients', 'Phase', 'Physiological', 'Property', 'Radiology Specialty', 'Records', 'Research', 'Risk', 'Rupture', 'Ruptured Abdominal Aortic Aneurysm', 'Ruptured Aneurysm', 'Spatial Distribution', 'Stress', 'Surgeon', 'Surveillance Program', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Time', 'Validation', 'X-Ray Computed Tomography', 'base', 'clinical imaging', 'clinically significant', 'computerized tools', 'design', 'high risk', 'improved', 'indexing', 'individual patient', 'innovation', 'novel', 'pressure', 'primary outcome', 'prospective', 'public health relevance', 'radiologist', 'recruit', 'repaired', 'soft tissue', 'spatiotemporal', 'standard of care', 'tool']",NHLBI,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2018,398926,14847250,0.00486483354108296
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,9427452,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Simulation', 'Cornea', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Image Analysis', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patient risk', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2018,400000,197030888,-0.007934041793089102
"Developing Classification Criteria for the Uveitides ﻿    DESCRIPTION (provided by applicant): The uveitides are a collection of ~30 distinct diseases characterized by intraocular infection. Each disease has its own features, course, treatment, and prognosis. Traditionally, the uveitides have been grouped by the primary anatomic site of inflammation as anterior uveitis, intermediate uveitis, posterior uveitis, and panuveitis. However, there are substantial limitations to this ""lumping"" of diseases. For example, among the posterior uveitides, some (e.g. toxoplasmic retinitis and cytomegalovirus retinitis) are infectious and require treatment with antimicrobial/antiviral agents, some are chronic, presumed immune-mediated diseases that require immunosuppression (e.g. birdshot chorioretinitis, multifocal choroiditis, serpiginous choroiditis), and a few are self-limited, spontaneously-remitting diseases with a good prognosis (e.g. acute posterior multifocal placoid pigment epitheliopathy and multiple evanescent white dot syndrome). As such precise diagnosis is critical for research, including epidemiology, translational pathogenesis research, outcomes research, and disease specific clinical trials. Classification criteria are a type of ""diagnostic"" criteria used for reserch purposes. Although classification criteria seek to optimize sensitivity and specificity, when a trade-off is required, they emphasize specificity in order to ensure that a homogeneous group of patients is being studied. A precise phenotype is required particularly for genomic risk factor studies of complex disorders and translational pathogenesis research, as inclusion of other diseases with different risk factors and disease mechanisms would confound the results. Currently there are no widely-accepted and validated classification criteria for any of the uveitides. Preliminary data indicate ""fair to moderate"" agreement at best on the independent diagnosis of any one case by uveitis experts (κ's 0.27-0.40), but the ability of committees to reach agreement on the diagnosis of >98% of cases. The goal of the ""Developing Classification Criteria for the Uveitides"" project is for the Standardization of Uveitis Nomenclature (SUN) Working Group to develop classification criteria for the 25 leading uveitides using a formal, rigorous approach. There are 4 phases to the project: 1) informatics, to develop a standardized terminology; 2) case collection, to develop a preliminary database of ~250 cases of each disease; 3) case selection, to select at least 150-200 cases of each disease that are generally accepted to be the disease (using formal consensus techniques) from the preliminary database into a final database; and 4) data analysis, using machine learning approaches, of the final database to develop a parsimonious set of criteria for each disease that minimizes misclassification. The informatics and case collection phases of the Project are complete. The case selection phase is well underway and uses online voting and consensus conference calls to achieve supermajority acceptance on all cases included in the final database. The goals of this application are to complete case selection and data analysis and develop classification criteria for the 25 of the major uveitides. These results are crucial to future clinical research i the field of uveitis. PUBLIC HEALTH RELEVANCE:  Collectively, the uveitides are the 5th leading cause of blindness in the U.S., and the cost of treating them is estimated to be similar to that of treating diabetic retinopathy. Because uveitis occurs in all age groups, including children and working-age adults, there is a greater potential for years of vision lost than with age- related diseases. Clinical research in the field of uveitis has been hampered by diagnostic imprecision and a lack of widely-accepted and validated classification criteria, the development of which is the goal of this application; these criteria are needed urgently to advance epidemiology, genomic research, translational pathogenesis research, outcomes research, and disease-specific clinical trials.",Developing Classification Criteria for the Uveitides,9472335,R01EY026593,"['Acute', 'Adult', 'Affect', 'Age', 'Agreement', 'Anatomy', 'Anterior uveitis', 'Antiviral Agents', 'Blindness', 'Child', 'Choroiditis', 'Chronic', 'Classification', 'Clinical Research', 'Clinical Trials', 'Collection', 'Complex', 'Consensus', 'Cytomegalovirus Retinitis', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Enrollment', 'Ensure', 'Epidemiology', 'Future', 'Genomics', 'Goals', 'Immune', 'Immunosuppression', 'Infection', 'Inflammation', 'Informatics', 'Intermediate Uveitis', 'Machine Learning', 'Mediating', 'Nomenclature', 'Outcomes Research', 'Panuveitis', 'Pathogenesis', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Pigments', 'Posterior Uveitis', 'Publications', 'Research', 'Retinitis', 'Risk Factors', 'Sensitivity and Specificity', 'Specificity', 'Standardization', 'Syndrome', 'Techniques', 'Terminology', 'United States', 'Uveitis', 'Vision', 'Visual impairment', 'Voting', 'age group', 'age related', 'aging population', 'antimicrobial', 'birdshot chorioretinitis', 'cost', 'outcome forecast', 'public health relevance', 'symposium', 'tool', 'web page', 'working group']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2018,418408,415711940,-0.0021712629364851704
"Assess and Model the Health Effects, Population, and Infrastructural Vulnerabilities of Power Outage PROJECT SUMMARY / ABSTRACT Climate change will lead to more intense and longer-lasting extreme weather events, such as floods, hurricanes, and severe storms, which will lead to more frequent power outage (PO). Significant gaps remain in our understanding of the impact of PO on human health: most previous studies were based on self-reported survey data, which is subject to reporting bias. In addition to weather factors that directly affect human health, other concurrent factors such as PO may also mediate with extreme weather on health, for which research is also lacking. Few studies assessed both power infrastructures and population vulnerabilities, and compared the effects of different PO causes. Furthermore, no health prediction models have been developed for PO. To fill these knowledge gaps, the proposed study will build upon multiple ongoing/ completed studies to: 1) assess the effects and mediating pathways of PO on electricity-dependent health outcomes, co-morbidities, and nursing home transfers; 2) identify infrastructure, environmental, and population vulnerabilities (individual and community); and 3) develop a vulnerability index and prediction model. We will effectively link the accessible New York statewide hospital admission and emergency department (ED) visit data with the existing data on PO, weather, air pollution, census, and nursing home transfer data. The associations between PO causes, frequency, duration, or area coverage of PO and electricity-dependent hospitalizations or ED visits due to asthma, chronic obstructive pulmonary disease (COPD), dialysis, water-/food-borne diseases, injury, and carbon monoxide poisoning will be assessed through Bayesian spatial-temporal model. This advanced technique will be able to control for both socio-demographic differences by regions and multiple temporal variables simultaneously. To improve scientific rigor, we will use control days (without PO and extreme weather) to separate PO from weather effects, and control diseases (e.g. appendicitis) to examine temporal changes of disease reporting. To understand PO’s natural direct and indirect effects, causal mediation analysis will be used. Furthermore, new variable selection methods, including Sure Independence Screening and Generalized Additive Model Selection will be used to screen and select predictors highly associated with outcomes. A composite vulnerability index weighed by risk factors identified and vulnerability maps will be developed. We will establish PO and PO-related health predictive models using the state-of-the-art data mining techniques, including Random Forest, Gradient Boosted Tree, and Ensemble Learning Decision Tree model. The excellent team with multidisciplinary and experienced investigators, numerous already collected and geocoded datasets, innovative data mining and analysis methods, continuation of student training, and successful prior partnerships with government agencies will maximize the probability of our success and feasibility. This project will also significantly enhance our institute’s environment and students’ involvement in research, and our findings will identify evidence-based strategies for emergency management and public health preparedness. NARRATIVE The proposed study will evaluate whether frequency, duration, coverage, and certain causes of power outage (PO) are associated with increased risks of electricity-dependent diseases, including asthma, chronic obstructive pulmonary disease (COPD), dialysis, water-/food-borne diseases, injury, and carbon monoxide poisoning. This may be the first study to assess whether people with certain demographic characteristics (e.g. elderly or different sex), living in a neighborhood with certain vulnerabilities (e.g. high land coverage or low hospital density), in certain seasons, degree of urbanicity, or specific causes of PO are more vulnerable to the impact of PO. The findings, vulnerability index and maps, and the forecast models derived from this study will help guide the state or federal environmental and health agencies to plan interventions and climate adaptation programs.","Assess and Model the Health Effects, Population, and Infrastructural Vulnerabilities of Power Outage",9440510,R15ES028000,"['Accident and Emergency department', 'Address', 'Admission activity', 'Adverse effects', 'Affect', 'Age', 'Air Pollution', 'Appendicitis', 'Area', 'Asthma', 'Carbon Monoxide Poisoning', 'Censuses', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Climate', 'Collaborations', 'Communities', 'Comorbidity', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Decision Trees', 'Dialysis procedure', 'Disasters', 'Disease', 'Elderly', 'Electricity', 'Emergency Situation', 'Emergency department visit', 'Engineering', 'Ensure', 'Environment', 'Environmental Health', 'Equipment Failure', 'Ethnic Origin', 'Event', 'Evidence based intervention', 'Floods', 'Frequencies', 'Gender', 'Geographic Factor', 'Government Agencies', 'Grant', 'Health', 'Hospitalization', 'Hospitals', 'Human', 'Hurricane', 'Individual', 'Injury', 'Institutes', 'Intervention', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Maps', 'Mediating', 'Mediation', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Natural Disasters', 'Neighborhoods', 'New York', 'Nursing Homes', 'Outcome', 'Pathway interactions', 'Patient Self-Report', 'Pattern', 'Population', 'Population Characteristics', 'Positioning Attribute', 'Predisposition', 'Probability', 'Public Health', 'Readiness', 'Recording of previous events', 'Recovery', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Risk Factors', 'Seasons', 'Socioeconomic Status', 'Statistical Methods', 'Students', 'Surveys', 'Techniques', 'Trees', 'Vulnerable Populations', 'Water', 'Weather', 'Work', 'base', 'climate change', 'climate impact', 'data mining', 'density', 'disorder control', 'evidence base', 'experience', 'extreme heat', 'foodborne', 'forest', 'health data', 'improved', 'indexing', 'innovation', 'learning strategy', 'low socioeconomic status', 'member', 'modifiable risk', 'multidisciplinary', 'predictive modeling', 'programs', 'public health priorities', 'screening', 'sex', 'student training', 'success']",NIEHS,STATE UNIVERSITY OF NEW YORK AT ALBANY,R15,2018,443750,9804373,-0.05784076106128089
"Predicting Diabetic Retinopathy from Risk Factor Data and Digital Retinal Images Abstract Diabetic retinopathy is the leading cause of blindness among US adults between the ages of 20 and 74 years. Laser photocoagulation surgery has been established as an effective way of treating retinopathy if it is detected early. Yearly retinal screening examinations are a potent tool in the battle to reduce the incidence of blindness from diabetic retinopathy because they provide diabetic patients with timely diagnoses and consequently, the potential for timely treatment. Primary care safety net clinics provide monitoring and other services for diabetic patients but they are often not equipped to provide specialty care services such as retinal screenings. Access to specialists who can provide retinal screenings can be increased through the use of telemedicine, which has shown great promise as a means of screening for diabetic retinopathy in the US and internationally. A pilot study by Charles Drew University investigators had a total of 2,876 teleretinal screenings performed for diabetic retinopathy, with 2,732 unique diabetic patients from six South Los Angeles safety net clinics screened. The present study aims to build on this prior work by: (a) developing novel software that utilizes information from clinical records to detect latent diabetic retinopathy in diabetic patients who have not yet received an annual eye examination, and (b) devising methods to speed up the diabetic retinopathy detection process for diabetic patients who have had digital retinal images taken by partially automating the process using image processing and machine learning techniques. Specifically, we propose to: 1. Develop predictive models for diabetic retinopathy using risk factors collected from patient clinical records. 2. Develop predictive models for automated diabetic retinopathy assessment using a combination of patient  risk factor data and data from digital retinal images previously evaluated by experts. 3. Evaluate the predictive accuracy of: a) the models developed for specific aim 2, and, b) the assessments of  optometrist readers against standard of care dilated retinal examinations by board certified  ophthalmologists for 300 diabetic patients utilizing a new Los Angeles County reading center. 4. Create web-based software tools based on the predictive models developed in specific aim 1 that can be  used to initiate outreach to high-risk patients in under-resourced settings, boosting detection rates for those  patients who are most at risk for diabetic retinopathy. 5. Establish targeted outreach methods to promote screening for patients that the predictive models from  specific aim 1 identify as potentially having undetected diabetic retinopathy. Narrative Diabetic retinopathy is the leading cause of blindness among US adults between the ages of 20 and 74 years. Although previous studies within the US and internationally have shown that teleretinal screening can increase access to eye examinations for detecting retinopathy, few studies have focused on the US urban safety net, which has ophthalmic screening rates that are well below the US average and a preponderance of diabetic patients who are from ethnic minority groups. Building on a previous teleretinal screening study that assessed 2,732 South Los Angeles patients for retinopathy, this study deploys machine learning and image processing techniques to detect latent retinopathy in unscreened diabetic patients and partially automate the diabetic retinopathy detection process for teleretinal screening.",Predicting Diabetic Retinopathy from Risk Factor Data and Digital Retinal Images,9566291,R01LM012309,"['Address', 'Adult', 'Affect', 'Age', 'Alaska Native', 'American Indians', 'Asian Americans', 'Blindness', 'Blood Circulation', 'Blood Vessels', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Clinic', 'Clinical', 'Complications of Diabetes Mellitus', 'Computer software', 'County', 'Data', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Eye', 'Glucose', 'Health Care Reform', 'Health Insurance', 'Health care facility', 'Hispanics', 'Incidence', 'International', 'Los Angeles', 'Machine Learning', 'Methods', 'Minority Groups', 'Modeling', 'Monitor', 'Not Hispanic or Latino', 'Online Systems', 'Operative Surgical Procedures', 'Ophthalmic examination and evaluation', 'Ophthalmologist', 'Optometrist', 'Patient risk', 'Patients', 'Pilot Projects', 'Population', 'Primary Health Care', 'Process', 'Protocols documentation', 'Publishing', 'Reader', 'Reading', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Retina', 'Retinal', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Rural', 'Services', 'Software Tools', 'Specialist', 'Speed', 'Techniques', 'Telemedicine', 'Time', 'United States', 'Universities', 'Work', 'aged', 'base', 'care systems', 'diabetic', 'diabetic patient', 'digital', 'digital imaging', 'ethnic minority population', 'high risk', 'image processing', 'inner city', 'laser photocoagulation', 'medical specialties', 'medically underserved', 'mortality', 'novel', 'outreach', 'patient screening', 'predictive modeling', 'primary care setting', 'racial minority', 'randomized trial', 'retinal imaging', 'safety net', 'screening', 'standard of care', 'statistics', 'tool', 'transmission process', 'trend']",NLM,CHARLES R. DREW UNIVERSITY OF MED & SCI,R01,2018,515636,7479461,-0.0189190293103413
"Multimodality imaging-driven multifidelity modeling of aortic dissection PROJECT SUMMARY. Aortic dissections are responsible for significant morbidity and mortality in young and old individuals alike. Whereas type A (ascending aorta) dissections are treated aggressively via surgery, type B (descending thoracic aorta) dissections are often monitored for long periods to determine the best treatment. These lesions can cease to propagate (i.e., stabilize or heal) or they can propagate further and either turn inward and connect again with the true lumen to form a re-entry tear or turn outward and result in rupture in the case of an compromised adventitia. Notwithstanding the importance of these later events, there is a pressing need to understand better the early processes that initiate the dissection and drive its initial propagation as well as to determine whether the presence of intramural thrombus is protective or not against early or continued propagation. Over the past 5 years our collaborative team has developed numerous new multimodality imaging techniques, biomechanical testing methods, and computational modeling approaches across multiple scales that uniquely positions us to understand better the process of early aortic dissection and the possible roles played by early intramural thrombus development. In this project, we propose to use nine complementary mouse models to gain broad understanding of the bio-chemo-mechanical processes that lead to aortic dissection and to introduce a new machine learning based multifidelity modeling approach to develop predictive probabilistic multiscale models of dissection. These models will be informed, trained, and validated via data obtained from a combination of unique in vitro biomechanical phenotyping experiments (wherein we can, for the first time, quantify the initial delamination process under well-controlled conditions and regional material properties thereafter) and novel multimodality imaging of delamination / dissection both in vitro and in vivo. We will consider, for example, the roles of different elastic lamellar geometries; we will assess separate roles of focal proteolytic activation and pooling of highly negatively charged mucoid material, which can degrade or swell the wall respectively; and we will model and assess the effects of early thrombus deposition within a false lumen. We submit that our new probabilistic paradigm, based on statistical autoregressive schemes and enabled by machine learning tools, could be transformative and lead to a paradigm shift in disease prediction where historical data, animal experiments, and limited clinical input (e.g., multiomics) can be used synergistically for robust prognosis and thus interventional planning. Our work is also expected to lead naturally to an eventual better understanding of the chronic processes associated with dissection via predictive models that are aided by the expected “revolution of resolution” in diagnostic imaging. PUBLIC HEALTH RELEVANCE Mounting evidence reveals that thoracic aortic dissections – which afflict young and old individuals alike – are responsible for even greater disability and death than long thought. We will use a unique combination of multiple mouse models, advanced medical imaging, and novel computational models to elucidate the mechanisms responsible for the initiation of a dissection and reasons for the extreme biological variability that characterizes these lethal lesions.",Multimodality imaging-driven multifidelity modeling of aortic dissection,9570304,U01HL142518,"['Acute', 'Address', 'Animal Experiments', 'Animal Model', 'Aorta', 'Aortic Rupture', 'Arteries', 'Attention', 'Biological', 'Biomechanics', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blunt Trauma', 'Carotid Arteries', 'Categories', 'Cervical', 'Cessation of life', 'Charge', 'Chest', 'Child', 'Chronic', 'Clinical', 'Coagulation Process', 'Collaborations', 'Communities', 'Computer Simulation', 'Coupling', 'Data', 'Defect', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dilatation - action', 'Disease', 'Dissection', 'Elderly', 'Event', 'Foundations', 'Geometry', 'Glycosaminoglycans', 'Goals', 'Heritability', 'Human', 'Hypertension', 'Image', 'Imaging Techniques', 'In Vitro', 'Individual', 'Infusion procedures', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Lesion', 'Long-Term Effects', 'Machine Learning', 'Mechanics', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Motivation', 'Multimodal Imaging', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Phase', 'Phenotype', 'Platelet aggregation', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Property', 'Research', 'Resolution', 'Risk Factors', 'Role', 'Rupture', 'Scheme', 'Site', 'Solid', 'Statistical Models', 'Supervision', 'Testing', 'Thoracic aorta', 'Thrombus', 'Time', 'Training', 'Tunica Adventitia', 'Ultrasonography', 'Uncertainty', 'Video Microscopy', 'Work', 'ascending aorta', 'base', 'digital imaging', 'disability', 'experimental study', 'healing', 'hemodynamics', 'improved', 'in vivo', 'insight', 'intracranial artery', 'mortality', 'mouse model', 'mucoid', 'multi-scale modeling', 'normotensive', 'novel', 'novel strategies', 'outcome forecast', 'particle', 'predictive modeling', 'public health relevance', 'single photon emission computed tomography', 'spatiotemporal', 'tool', 'virtual', 'young adult']",NHLBI,YALE UNIVERSITY,U01,2018,528639,550947887,-0.0021930255808257255
"Machine Learning for Identifying Adverse Drug Events ﻿    DESCRIPTION (provided by applicant): Because of the profound effect of adverse drug events (ADEs) on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post-marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA formed the Observational Medical Outcomes Partnership (OMOP) to develop and compare methods for identification of ADEs, and the FDA announced its Sentinel Initiative. Congress created the Reagan Udall Foundation (RUF) for the FDA in response to the FDA's own ""FDA Science and Mission at Risk"" report, and two years ago OMOP activities were incorporated into RUF. As the FDA moves forward with its development of Sentinel, including work on Mini-Sentinel, there is a need for researchers around the country to continue to develop better methods, and better evaluation methodologies for those methods. A robust research community working on algorithms for pharmacosurveillance, using electronic health records (EHRs) and claims databases will provide a substrate of ever-improving methods on which the nation's regulatory pharmacovigilance infrastructure can build. Indeed an important motivation of OMOP and Mini-Sentinel was to spur the development of such a community. Machine learning has attracted widespread attention across a range of disciplines for its ability to construct accurate predictive models. Therefore machine learning is especially appropriate for the problems of ADE identification and prediction: identifying ADEs from observational data, and predicting which patients are most at risk of suffering the identified ADE. Our current award has demonstrated the ability of machine learning to address both of these tasks. It has added to the existing evidence that consideration of temporal ordering of events, such as drug exposure and diagnoses, is critical for accuracy in identification and prediction of ADEs. The proposed work seeks to further improve upon these methods by building on recent advances in the field of machine learning, by our group and by others, in graphical model learning and in explicit modeling of irregularly-sampled temporal data. The latter is especially important because observational health databases, such as EHRs and claims databases, are not simple time series. Patients typically do not come into the clinic at regular intervals and have the same labs, vitals, and other measurements in lock step with one another. Building better ADE detection and prediction algorithms cannot be accomplished simply by machine learning research, even if that research is taking account of related work from relevant parts of computer science, statistics, biostatistics, epidemiology, pharmaco-epidemiology, and clinical research. Better methods are needed also for evaluation, that is, for estimating how well a new algorithm, or a new use of an existing algorithm, will perform at identifying ADEs associated with a new drug on the market, or at predicting which patients are most at risk of that ADE. More research and evaluation is also needed at the systems level: how can we best construct end-to-end pharmacovigilance systems that sit atop a large observational database and flag potential ADEs for human experts to further investigate? What kinds of information and statistics should such a system provide to the human experts?        This renewal will address the following aims: (1) improve upon machine learning methods for identification and prediction of ADEs, taking advantage of synergies between these two distinct tasks; (2) improve upon existing methods for evaluating ADE detection, building on advances in machine learning for information extraction from scientific literature; (3) improve upon existing methods for evaluating ADE prediction, building upon advances in machine learning for automated support of phenotyping and also building upon improved methods for efficiently obtaining expert labeling of borderline examples of a phenotype; and (4) use the methods developed in the first three aims to construct and evaluate an end-to-end pharmacosurveillance system integrated with the Marshfield Clinic EHR Data Warehouse. Machine learning plays a central and unifying role throughout all four aims. Our investigator team consists of machine learning researchers with experience in analysis of clinical, genomic, and natural language data (Page, Natarajan), a leading pharmaco-epidemiologist with expertise in building systems to efficiently obtain expert evaluation and labeling of phenotypes (Hansen), a leader in phenotyping from EHR data (Peissig), and an MD/PhD practicing physician with years of experience and leadership in the study of ADEs (Caldwell). In addition to building on results of the prior award, we will build on our experiences with OMOP, the International Warfarin Pharmacogenetics Consortium, the DARPA Machine Reading Program, and interactions with the FDA. PUBLIC HEALTH RELEVANCE: Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It also addresses the needs for improved evaluation and integrated systems approaches.",Machine Learning for Identifying Adverse Drug Events,9522037,R01GM097618,"['Address', 'Adverse drug effect', 'Adverse drug event', 'Algorithms', 'Attention', 'Award', 'Biometry', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Congresses', 'Country', 'Coxibs', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Discipline', 'Doctor of Philosophy', 'Drug Exposure', 'Early Diagnosis', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Evaluation Methodology', 'Event', 'Foundations', 'Genomics', 'Health', 'Human', 'Institute of Medicine (U.S.)', 'International', 'Label', 'Leadership', 'Learning', 'Life', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Markov Chains', 'Measurement', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Motivation', 'Myocardial Infarction', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenetics', 'Phenotype', 'Physicians', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Priority', 'Risk', 'Role', 'Safety', 'Sampling', 'Science', 'Sentinel', 'Series', 'Serious Adverse Event', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Wisconsin', 'Work', 'base', 'computer science', 'cost', 'data mining', 'data warehouse', 'experience', 'improved', 'interest', 'learning strategy', 'natural language', 'novel', 'novel therapeutics', 'patient safety', 'prediction algorithm', 'predictive modeling', 'programs', 'public health relevance', 'response', 'statistics', 'synergism']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2018,536041,338121506,-0.009181669640358605
"Using Machine Learning to Predict Problematic Prescription Opioid Use and Opioid Overdose Problematic prescription opioid use, defined as nonmedical use, misuse, or abuse of opioid medications, is epidemic in the US. Prescription opioid overdose deaths more than quadrupled from 1999 to 2015. Efforts by health care systems and payers to combat the opioid epidemic are impeded by a lack of accurate and efficient methods to identify individuals most at risk for problematic opioid use and overdose, leading to broad interventions that are burdensome to patients and expensive for payers. Payers are currently defining high risk and targeting interventions (e.g. pharmacy lock-in programs) based on individual risk factors, such as high opioid dosage, identified in prior studies using traditional statistical approaches. However, these traditional approaches have significant limitations, especially when handling large datasets with numerous variables, multi-level interactions, and missing data. Moreover, the prior studies focused on identifying risk factors rather than predicting actual risk. Alternatively, machine learning is an advanced technique that handles complex interactions in large data, uncovers hidden patterns, and yields precise prediction algorithms that, in many cases, are superior to those developed using traditional methods. Machine learning is widely used in activities from fraud detection to cancer genomics, but has not yet been applied to address the opioid epidemic. Accordingly, the proposed study will apply machine learning to develop prediction algorithms that can more accurately identify patients at high risk of problematic opioid use and overdose using data sources that are readily available to payers and health care systems. The project will build on existing academic-state partnerships to apply novel machine learning approaches to administrative claims data for all Medicaid beneficiaries in Pennsylvania (PA) and Arizona (AZ). The project will also link Medicaid data in AZ to electronic health records to capture clinical information (e.g., lab results, pain severity) not available in administrative data, along with death certificate data on lethal overdose. These data, covering 2007-2016, will be used to achieve two specific aims: (1) to develop and validate two separate prediction algorithms to identify patients at risk of problematic opioid use and opioid overdose; (2) to compare the accuracy of a prediction algorithm that integrates clinical data with Medicaid claims versus a claims-based approach alone to identify patients at risk of problematic opioid use and opioid overdose. The machine learning approaches will include random forests and TreeNet with representative classification trees, and the predictive ability (e.g., misclassification rates) of these algorithms will be compared to traditional statistical models. Given the high prevalence of mental health/substance use disorders (~50%) and opioid utilization (>20%) among Medicaid enrollees and the lack of adequate prediction algorithms, Medicaid is an ideal setting for the proposed project. These analyses will provide the partnering Medicaid programs with valuable information and tools that they can apply to more precisely target interventions to prevent problematic opioid use and overdose. Prescription opioid overdose deaths quadrupled from 1999 to 2015, and drug overdose is now the leading cause of injury deaths among adults in the United States. This project will use innovative machine learning methods and readily available data for Medicaid beneficiaries in two states hard hit by the epidemic – Pennsylvania and Arizona – to develop algorithms to accurately predict who is at risk of problematic prescription opioid use and overdose. This information will empower health systems, payers, and policymakers to more effectively target interventions to prevent prescription opioid misuse and its consequences.",Using Machine Learning to Predict Problematic Prescription Opioid Use and Opioid Overdose,9547370,R01DA044985,"['Accident and Emergency department', 'Address', 'Adult', 'Alcohol or Other Drugs use', 'Algorithms', 'American', 'Arizona', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Data Set', 'Data Sources', 'Death Certificates', 'Detection', 'Dose', 'Drug Screening', 'Electronic Health Record', 'Emergency department visit', 'Ensure', 'Epidemic', 'Fee-for-Service Plans', 'Fraud', 'Genomics', 'Health system', 'Healthcare Systems', 'High Prevalence', 'Hospitals', 'Individual', 'Injury', 'Inpatients', 'Intervention', 'Letters', 'Link', 'Logistic Regressions', 'Machine Learning', 'Managed Care', 'Medicaid', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Morphine', 'Opioid', 'Outcome', 'Overdose', 'Pain', 'Patients', 'Pattern', 'Pennsylvania', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Prescription opioid overdose', 'Prevalence', 'Reporting', 'Research', 'Risk', 'Risk Factors', 'Severities', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'Substance Use Disorder', 'Techniques', 'Time', 'Trees', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Urine', 'Work', 'base', 'beneficiary', 'cancer genomics', 'clinical predictors', 'combat', 'design', 'dosage', 'forest', 'high risk', 'innovation', 'learning strategy', 'milligram', 'model building', 'nonmedical use', 'novel', 'opioid epidemic', 'opioid mortality', 'opioid overdose', 'opioid use', 'overdose risk', 'prediction algorithm', 'predictive modeling', 'prescription opioid', 'prescription opioid abuse', 'prescription opioid misuse', 'prevent', 'programs', 'service utilization', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2018,585626,570146095,-0.005130443529411879
"Machine learning of physiological variables to predict diagnose and treat cardiorespiratory instability Project Summary/Abstract: If one could accurately predict who, when and why patients develop cardiorespiratory instability (CRI), then effective preemptive treatments could be given to improve outcome and better use care resources. However, CRI is often unrecognized until it is well established and patients are more refractory to treatment, or progressed to organ injury. We have shown that an integrated monitoring system alert obtained from continuous noninvasively acquired monitoring parameters and coupled to a care algorithm improved step-down unit (SDU) patient outcomes. We also showed that advanced HR variability analysis (sample entropy) identified SDU patients at CRI risk within 2 minutes, and if monitored for 5 minutes differentiated between patients who would develop CRI or remain stable over the next 48 hours. We also applied machine learning (ML) modeling to our clinically-relevant porcine model of hemorrhagic shock to characterize responses to hypovolemia, hemorrhage, and resuscitation, predict which animals would or would not collapse during hypovolemia, and identify occult bleeding 5 minutes earlier than with traditional monitoring. We now propose to apply our work to vulnerable and invasively monitored ICU patients. We will develop multivariable models through ML data-driven classification techniques such as regression, Fourier and principal component analysis, artificial neural networks, random forest classification, etc. as well as more novel approaches (temporal rule learning developed by our team; Bayesian Aggregation) to predict CRI in ICU patients. We will first use our existing annotated high fidelity waveform MIMIC II clinical data set (4200 patients) to develop predictive models and differential signatures for various CRI drivers. We will also use our high-density data collection and processing platform (Bernoulli) to prospectively collect data from ICUs in three institutions: Univ. Pittsburgh (PITT), Univ. California (UC) Irvine and UC San Diego (initial algorithm development conducted at PITT and validated in the UC systems). We will identify the number and type of independent measures, sampling frequency, and lead time necessary to create robust algorithms to: 1) predict impending CRI, 2) select the most effective treatments, 3) monitor treatment response, and 4) determine when treatment has restored physiologic stability and can be stopped. We will also determine the smallest number and types of parameters coupled to the longest CRI lead time to achieve the above four targets with the best sensitivity and specificity (a concept we call Monitoring Parsimony).We will simultaneously iteratively design and test a graphical user interface (GUI) and clinical decision support system (CDSS) driven by these parsimoniously derived predictive smart alerts and functional hemodynamic monitoring treatment approaches in two human simulation environments (PITT & UC Irvine).We envision a basic monitoring surveillance that identifies patients most likely to develop CRI to apply focused clinician attention and targeted treatments to deliver highly personalized medical care. Public Health Narrative If one could accurately predict who, when and why patients develop shock then effective preemptive treatments could be given to improve outcome and more effectively use healthcare resources. But signs of shock often occur late once organ injury is already present. The purpose of this study is to first develop multivariable models through data-driven classification techniques to parsimoniously predict cardiovascular insufficiency, etiology and response to treatment. We will do this first in our existing MIMIC II clinical data sets of 4200 ICU patients as to timing and types of instability. Then we will prospectively collect real time high- density data on patients admitted to our trauma intensive care units of University of Pittsburgh, UC Irvine and UC San Diego. We will create and test in simulators of ICU care bedside user interfaces to drive recognition and treatment algorithms based on these models in all three medical centers.",Machine learning of physiological variables to predict diagnose and treat cardiorespiratory instability,9459930,R01GM117622,"['Acute', 'Algorithms', 'Animals', 'Attention', 'California', 'Cardiovascular system', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Complex', 'Coupled', 'Critical Illness', 'Data', 'Data Collection', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Entropy', 'Environment', 'Etiology', 'Exposure to', 'Family suidae', 'Frequencies', 'Future', 'Health', 'Healthcare', 'Hemorrhage', 'Hemorrhagic Shock', 'Homeostasis', 'Hour', 'Human', 'Hypovolemia', 'Injury', 'Institution', 'Intensive Care Units', 'Intervention', 'Lead', 'Learning', 'Libraries', 'Machine Learning', 'Measures', 'Mechanical ventilation', 'Medical', 'Medical center', 'Modeling', 'Monitor', 'Normal Range', 'Organ', 'Organ failure', 'Pathologic Processes', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Perioperative', 'Physiologic Monitoring', 'Physiological', 'Principal Component Analysis', 'Process', 'Protocols documentation', 'Public Health', 'Recommendation', 'Refractory', 'Resolution', 'Resources', 'Resuscitation', 'Risk', 'Running', 'Sampling', 'Sensitivity and Specificity', 'Sepsis', 'Shock', 'Signal Transduction', 'Specificity', 'Stream', 'Stress', 'System', 'Techniques', 'Testing', 'Time', 'Trauma', 'Triage', 'Universities', 'Validation', 'Variant', 'Weaning', 'Work', 'artificial neural network', 'base', 'cardiovascular insufficiency', 'clinical care', 'clinical decision support', 'clinically relevant', 'computerized data processing', 'cost', 'database structure', 'density', 'diagnostic accuracy', 'early onset', 'effective therapy', 'fitness', 'forest', 'graphical user interface', 'hemodynamics', 'high risk', 'improved', 'improved outcome', 'individual response', 'insight', 'iterative design', 'mortality', 'novel strategies', 'patient population', 'personalized medicine', 'predictive modeling', 'predictive tools', 'prospective', 'prototype', 'response', 'simulation', 'support tools', 'treatment response']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2018,601883,570146095,-0.014548840723242622
"Infrared Eyes(iREyes) Infrared Eyes Abstract Eden Medical, Inc. is pleased to resubmit this Phase 2 SBIR proposal to develop the “Infrared Eyes” (iREyes) imager system, an affordable and powerful mobile health (mHealth) tool for healthcare. The hand-held iREyes system will acquire both thermal and visible spectrum imagery to quantify healing via thermal indexing methodology. The iREyes will offer a user-friendly product with automated categorization. Diabetic foot wounds are common, complex and costly. Foot areas that are likely to ulcerate are associated with increased local skin temperature due to inflammation and enzymatic autolysis of tissue. Inflammation is characterized by the cardinal signs including redness, swelling, and heat. In addition to identifying inflammation associated with healing, the iREyes will also identify hot spots associated with repetitive stress to reduce ulceration and re-ulceration risk for people in diabetic foot remission. The iREyes will directly quantify inflammation pathophysiology implementing a powerful revised two-part strategy: wound healing via regional foot index analysis and ulcer reoccurrence risk through temperature asymmetry threshold analysis. The combined thermal indexing for healing existing wounds and asymmetry predictive analysis represents a significant breakthrough over current practice. Infrared Eyes Narrative To develop a low-cost mobile health (mHealth) infrared imaging system that acquires both thermal and visible spectrum imagery to quantify diabetic foot ulcer healing via thermal indexing and risk prediction with temperature asymmetry methodology.",Infrared Eyes(iREyes),9680234,R44DK102244,"['Agreement', 'Algorithms', 'Amputation', 'Area', 'Autolysis', 'Automation', 'Blood flow', 'California', 'Caring', 'Catalogs', 'Chronic', 'Clinical', 'Clinics and Hospitals', 'Collaborations', 'Complex', 'Consult', 'Data Analyses', 'Data Analytics', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Foot', 'Diabetic Foot Ulcer', 'Diagnosis', 'Discipline of Nursing', 'Disease remission', 'Electronic Health Record', 'Electronics', 'Evaluation', 'Eye', 'Functional disorder', 'Funding', 'Gifts', 'Grant', 'Hand', 'Hawaii', 'Health', 'Healthcare', 'Hospitals', 'Hot Spot', 'Image', 'Image Analysis', 'Imagery', 'Impairment', 'Inflammation', 'Inflammatory', 'Lead', 'Legal patent', 'Length', 'Licensing', 'Limb structure', 'Los Angeles', 'Lower Extremity', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Methodology', 'Methods', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Outpatients', 'Pain', 'Patients', 'Pattern', 'Phase', 'Physicians', 'Redness', 'Risk', 'Sales', 'Services', 'Shapes', 'Skin Temperature', 'Small Business Innovation Research Grant', 'Spottings', 'Stress', 'Swelling', 'System', 'Tablets', 'Technology', 'Temperature', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'Ulcer', 'United States', 'United States National Institutes of Health', 'Universities', 'Width', 'Work', 'Wound Healing', 'base', 'commercialization', 'computerized data processing', 'cost', 'design', 'diabetic patient', 'foot', 'healing', 'human subject', 'imager', 'imaging system', 'improved', 'indexing', 'mHealth', 'medical schools', 'portability', 'programs', 'prototype', 'spectrograph', 'tool', 'user-friendly', 'web portal', 'wound']",NIDDK,"EDEN MEDICAL, INC.",R44,2018,616276,467010,-0.001634573261634572
"Optical Body Composition and Health Assessment ﻿    DESCRIPTION (provided by applicant):1 Of all markers of human health, the most intuitive is body shape but based on quantitative evidence.  2 Anthropometry and regional composition measures such as waist circumference (WC), waist to hip ratio  3 (WHR), and visceral adipose tissue area (VAT) are better predictors of obesity-related diseases and mortality  4 risk than body mass index (BMI). Dual-energy X-ray absorptiometry (DXA) can quantify regional adiposity in  5 more detail than the above measures but is underutilized for many reasons including potential harm from  6 ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments  7 in the ""quantified self movement"" to better describe phenotypes of body shape and its relation to metabolic  8 risks. The candidate developed in this proposal is 3D optical whole body scanning. If successful, sophisticated  9 obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with 10 disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment 11 technology. Whole body 3D imaging technology is already so accessible that it can be done with video games 12 such as the Microsoft Xbox Kinect, and consumer cameras. 13 The long term goal of the Optical Body Shape and Health Assessment Study is 1) to provide phenotype 14 descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in 15 research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive 16 models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, 17 muscle mass, lean mass, and percent fat), and then show how our 3DO body composition estimates are 18 associated to important metabolic risk factors. Our central hypothesis is that 3DO measures of body 19 composition with shape classification better predict metabolic risk factors than anthropometry or DXA body 20 composition alone. Our specific aims are: 1. Identify the unique associations of body shape to body 21 composition indices in a population that represents the variance of sex, age, BMI, and ethnicity found 22 in the US population; 2. Describe the precision and accuracy of 3DO scans to monitor change in body 23 composition and metabolic health interventions; and 3. Estimate the level of association of 3DO to 24 common health indicators including metabolic risk factors by gender, race, age, and BMI. In an 25 exploratory aim, we investigate holistic, high-resolution descriptors of 3D body shape as direct 26 predictors of body composition and metabolic risk using statistical shape models and Latent Class 27 Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self- 28 assessment technologies that are capable of representing over 95% of the shape variance in the US 29 population, and how these models relate to important metabolic status and body composition. The positive 30 impact will be the immediate applicability to clinicians and individuals for personalized risk assessment. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because they have the potential to provide a better understanding of who is at high risk of metabolic diseases because of a poor metabolic profile. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Optical Body Composition and Health Assessment,9670701,R01DK109008,"['Adipose tissue', 'Adult', 'Age', 'Animals', 'Anorexia Nervosa', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Classification', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Devices', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Ethnic Origin', 'Fatty acid glycerol esters', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Individual', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Personal Satisfaction', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Video Games', 'Visceral', 'Waist-Hip Ratio', 'bariatric surgery', 'base', 'clinical practice', 'cost', 'disorder prevention', 'health assessment', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolic profile', 'metabolomics', 'mortality', 'muscle form', 'optical imaging', 'predictive modeling', 'public health relevance', 'sensor', 'sex', 'subcutaneous', 'tool', 'waist circumference', 'whole body imaging']",NIDDK,UNIVERSITY OF HAWAII AT MANOA,R01,2018,679629,45734163,0.017842522954837608
"Shape up! Kids Project Summary/Abstract Of all markers of pediatric health, the most intuitive is body shape. Human and animal studies indicate that weight loss/gain correlates closely with increasing/decreasing insulin sensitivity, respectively. Anthropometry and regional composition measures such as waist circumference, waist to hip ratio (WHR), and visceral adipose tissue area are better predictors of obesity-related diseases and mortality risk than pediatric body mass index Z-score. Dual-energy X-ray absorptiometry can quantify regional adiposity in more detail than these measures but is underutilized for many reasons including the sensitivity to children to ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments in optical technology to better describe phenotypes of pediatric body shape and its relation to metabolic risks (obesity, “failure to thrive”) and bone density and size. If successful, sophisticated obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment technology. The long term goal of the Shape Up! Kids Study is 1) to provide pediatric phenotype descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, muscle mass, lean mass, and percent fat) and bone mineral density (BMD) over a wide range of ages (5 to 18 years), weights and heights, stratified by sex, and ethnicity. Our central hypothesis is that optical estimates with shape classification of soft tissue composition and bone density better predict fracture and metabolic risk factors than anthropometry (WC, WHR, and BM) alone. The Investigators will highly leverage existing data from the National Health and Nutrition Examination Survey and Bone Mineral Density in Children Study. Our specific aims are: 1) Identify the unique associations of body shape to body composition and bone density indices in a pediatric population that represents the variance found in the US population, 2) Describe the precision and accuracy of optical scans to monitor change in body composition, bone density, 3) Estimate the level of association of optical scans to common health indicators including metabolic risk factors. Our exploratory aim is to investigate holistic, high-resolution descriptors of 3D body shape as direct predictors of body composition and metabolic risk using statistical shape models and Latent Class Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self-assessment technologies that are capable of representing over 95% of the shape variance in the US pediatric population, and to define how these models relate to important metabolic status indicators. The positive impact of these outcomes will be the immediate applicability to other researcher studies and clinicians using the automated tools and models developed here for 3D optical images. PROJECT NARRATIVE  The proposed research is relevant to public health because they have the potential to provide a better understanding of what children are at high risk of metabolic consequences of obesity. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults, and are becoming epidemic in children as well. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Shape up! Kids,9671795,R01DK111698,"['Adipose tissue', 'Adult', 'Age', 'Algorithms', 'Animals', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Surface', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Bone Density', 'Child', 'Childhood', 'Classification', 'Clinical', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Epidemiology', 'Ethnic Origin', 'Failure to Thrive', 'Fatty acid glycerol esters', 'Fracture', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Liver', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'Muscle', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Pediatric Radiology', 'Personal Satisfaction', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Factors', 'Safety', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Visceral', 'Waist-Hip Ratio', 'Weight', 'bone', 'clinical practice', 'cost', 'disorder prevention', 'handheld mobile device', 'health assessment', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolomics', 'mortality', 'muscle form', 'optical imaging', 'predictive modeling', 'sensor', 'sex', 'soft tissue', 'subcutaneous', 'tool', 'waist circumference']",NIDDK,UNIVERSITY OF HAWAII AT MANOA,R01,2018,686182,45734163,0.021316360644854374
"Electronic Health Record Data and Predictive Analytic Methods for HF The goal of this proposal is to develop accurate, generalizable and interpretable predictive models based on electronic health records (EHR) that detect heart failure (HF) in primary care patients one to two years before a clinical diagnosis and to translate the models for use in clinical care. Case-control datasets from two large US health systems (i.e., >13,000 incident HF cases and >120,000 controls) will be created and used to address two of the three study aims. For Aim 1 (Improve prediction of pre-diagnostic HF and model generalizability), recursive neural network (RNN) models will be used to improve prediction accuracy when compared to prior work that was based on traditional machine learning models (e.g., random forest, lasso logistic regression). It is expected that RNN models will perform better because temporality of EHR events can be captured. Aim 1 will also focus on improving model generalizability (i.e., among patients within and across health systems) by leveraging RNN models and by addressing challenges caused by variation in patient level EHR data (e.g., density of data) that are independent of a patient's actual health status. Aim 2 (Identify and clinically validate pre-diagnostic HF phenotypes) will focus on the identification of pre-diagnostic HF phenotypes and the use of content from RNN models derived under Aim 1. Three levels of analysis will be completed. First, we will focus on pathophysiologic heterogeneity that is represented, in part, by HF with preserved ejection fraction (HFpEF) and HF with reduced ejection fraction (HFrEF). But, HFpEF is considered to be more heterogeneous than HFrEF. New methods will be developed to reliably identify pre-diagnostic HF phenotypes. Second, phenotypes will be clinically validated for reliability and coherence and compared to clinical judgement based on a review of the patient's record. Third, we will address a challenge with RNN models, as they generate “black box” solutions that are seemingly uninterpretable. We propose to develop new methods to extract and represent the content from RNN models. We hypothesize that when phenotype status is combined with information extracted from Aim 1 RNN models it will be judged by expert clinician reviews to be superior for prevention care to phenotype status when it is combined with information extracted from traditional machine learning models or to a direct review of the patient's EHR. Finally, we will prospectively validate the phenotype and RNN models using a large primary care cohort being created by Sutter and related serial biobanked blood samples. For aim 3 we will determine how accurately the models predict elevated biomarker levels that are known to be sensitive and specific indicators of HF disease progression.   The proposed research will contribute valuable knowledge that will assist doctors to identify patients who are at high-risk of incident heart failure 12 to 24 months before the actual diagnosis and that exceed what is possible when relying on traditional signs, symptoms or risk factors. Doctors will be able to provide a more targeted approach to reduce the future risk of heart failure and the risks of morbidity and accelerated mortality that high risk patients face. Moreover, the methods that are developed for the early detection of heart failure in this study will help other researchers in creating more accurate and generalizable predictive models when using electronic health records data and when applying these models for use in clinical care.  ",Electronic Health Record Data and Predictive Analytic Methods for HF,9779100,R56HL116832,"['Accounting', 'Address', 'Adopted', 'Adult', 'Biochemical', 'Biological Assay', 'Biological Markers', 'Blood specimen', 'Cardiac', 'Caring', 'Clinical', 'Data', 'Data Analytics', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'EFRAC', 'Early Diagnosis', 'Electronic Health Record', 'Engineering', 'Etiology', 'Event', 'Evidence based intervention', 'Face', 'Feeds', 'Future', 'Goals', 'Health Status', 'Health system', 'Heart failure', 'Heterogeneity', 'Individual', 'Knowledge', 'Lasso', 'Logistic Regressions', 'Logistics', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Muscle Cells', 'Neural Network Simulation', 'Patient Care', 'Patient risk', 'Patients', 'Phenotype', 'Physiological', 'Population', 'Predictive Analytics', 'Prevention', 'Primary Health Care', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Role', 'Sampling', 'Serum', 'Signs and Symptoms', 'Stretching', 'Symptoms', 'Testing', 'Time', 'Translating', 'Translations', 'Troponin T', 'Validation', 'Variant', 'Work', 'adjudicate', 'analytical method', 'base', 'biobank', 'case control', 'clinical Diagnosis', 'clinical care', 'cohort', 'density', 'expectation', 'feeding', 'forest', 'high risk', 'improved', 'improved outcome', 'mortality', 'patient population', 'patient subsets', 'predictive modeling', 'pressure', 'prospective', 'recurrent neural network', 'recursive neural network']",NHLBI,CALIFORNIA PACIFIC MED CTR RES INSTITUTE,R56,2018,761303,26815282,-0.008784622726649009
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9533373,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Anti-Tumor Necrosis Factor Therapy', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Big Data', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Individual', 'Injury', 'Institution', 'Intuition', 'Leukocyte Chemotaxis', 'Lymphocyte Immunophenotypings', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Myocardial', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Sampling', 'Series', 'Stains', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'base', 'clinical diagnostics', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'human disease', 'improved', 'inquiry-based learning', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2018,787091,3808719,-0.0007807124647791958
"Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease PROJECT SUMMARY / ABSTRACT Cardiovascular disease (CVD) is the single largest killer in the United States for both men and women in every racial/ethnic group. Thus, accurate and systematic evaluation of CVD risk represents an aspect of Precision Medicine that will touch every patient. CVD risk scores that are currently the standard of care are derived from research cohorts and are particularly inaccurate in women, older patients, and those with missing data. The goal of this Precision Medicine based application is to capitalize on the depth and breadth of clinical data within electronic health record (EHR) systems to revolutionize CVD risk prediction, thereby optimizing personalized care for every patient. Our proposed approach is innovative in that we have identified and addressed the most significant barriers to development of an EHR-based risk score. Novel aspects of this research include: 1) use of complete EHR data to develop and validate algorithms to define a variety of risk factors (e.g., reproductive history), thus building a comprehensive risk profile for each patient that incorporates diagnosis and procedure codes, laboratory values, clinical test results, patient provided information (e.g., alcohol use), and natural language processing of unstructured clinical text; 2) incorporation of age at onset of risk factors; 3) use of highly flexible machine learning techniques in the form of generalized boosted regression modeling; 4) exploration of a new deep learning model for censored EHR data; and 5) determination of the extent of risk reclassification in multiple geographically-defined populations, including an underserved minority population. Furthermore, genetic studies demonstrate that incorporating variants into current risk models improves risk prediction and use of an individual's genetic risk could further enhance our ability to deliver precision medicine to every patient. Therefore, we seek to develop a sex-specific next-generation CVD risk prediction score using EHR data in combination with genetic variants. This paradigm is a significant departure from the current one that relies on scores derived from relatively small research cohorts that use only a restricted set of clinical parameters that differentially misclassify an individual's risk, especially in women. Our access to empirical clinical EHR data for hundreds of thousands of patients uniquely positions us to 1) develop a sex-specific risk prediction model for incident CVD using data from the EHR; 2) assess the performance of the sex-specific EHR risk score in an independent non-urban and rural population; and 3) identify and characterize patients for whom genetic information improves CVD prediction beyond the clinical risk score. Successful completion of these aims has the potential to impact all adult patients, drive clinical practice changes to systematically collect sex-specific risk factors, and inform attempts to embed the next-generation CVD risk score into EHR systems for automated use in clinical care. PROJECT NARRATIVE Cardiovascular disease (CVD) is the single largest killer in the United States. We propose to use electronic health record data to improve our ability to accurately classify risk and identify those who would benefit from preventive therapies. Improved risk prediction will shed light on the mechanisms of CVD and potentially reduce incidence, save lives, and lower health care costs.",Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease,9442890,R01HL136659,"['Address', 'Adult', 'Age', 'Alcohol consumption', 'Algorithms', 'Cardiovascular Diseases', 'Clinical', 'Clinical Data', 'Clinics and Hospitals', 'Code', 'Communities', 'Community Hospitals', 'County', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Ethnic group', 'Evaluation', 'Event', 'Genetic Risk', 'Genetic study', 'Geography', 'Goals', 'Health', 'Health Care Costs', 'Hybrids', 'Incidence', 'Individual', 'Laboratories', 'Latino', 'Light', 'Machine Learning', 'Minnesota', 'Modeling', 'Natural Language Processing', 'Not Hispanic or Latino', 'Patients', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevention strategy', 'Preventive', 'Preventive therapy', 'Procedures', 'Reproducibility', 'Reproductive History', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Rural', 'Rural Population', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Touch sensation', 'United States', 'Variant', 'Wisconsin', 'Woman', 'base', 'biobank', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'clinical care', 'clinical practice', 'clinical risk', 'cohort', 'deep learning', 'electronic data', 'flexibility', 'genetic information', 'genetic panel test', 'genetic variant', 'improved', 'innovation', 'men', 'next generation', 'novel', 'older patient', 'personalized care', 'precision genetics', 'precision medicine', 'predictive modeling', 'prospective', 'racial and ethnic', 'research clinical testing', 'sex', 'standard of care', 'time use', 'underserved minority']",NHLBI,MAYO CLINIC ROCHESTER,R01,2018,794994,276703803,-0.03352772916320478
"Machine learning for the automated identification and tracking of rare myocardial diseases PROJECT SUMMARY Although cardiac amyloidosis and hypertrophic cardiomyopathy (HCM) are relatively rare causes of heart failure (HF), they are particularly challenging to detect and treat for several shared reasons: (1) on routine clinical imaging (i.e., echocardiography [echo]), they can be difficult to distinguish from superficially similar, more common forms of cardiac disease that cause left ventricular (LV) hypertrophy; (2) the diagnoses are often missed and thus patients can present late in the course of disease at a time when treatment is difficult; (3) objective, noninvasive metrics that reliably reflect disease progression have not been identified; and (4) the small number of known patients with these diseases can make epidemiology studies and clinical trials difficult to organize and conduct. For both cardiac amyloidosis and HCM, echo plays a critical role in both diagnosis and longitudinal monitoring given its ubiquitous clinical availability, safety, and low cost. More broadly, echo dominates the current landscape of routine cardiac imaging, with tens of millions of echos performed in the United States each year. However, the clinical challenges described above highlight several shortcomings of echo: it is limited in its ability to (1) diagnose disease at its early stages; (2) discriminate between morphologically similar diseases; and (3) quantify disease progression. This proposal seeks to address deficiencies in the current echo reading workflow, which is subjective and captures only a small fraction of the data available in each study. The overall objective of this application is to use advances in machine learning to develop and validate fully-automated echo image analytic approaches to diagnose and track rare cardiomyopathies, focusing on cardiac amyloidosis and HCM. Our proposal is centered on the hypothesis that highly scalable computer vision methods can be applied to echo studies to overcome limitations of the standard clinical echo reading workflow. Accordingly our aims are: (1) Apply an automated method for echo quantification and disease identification to detect and differentiate cardiac diseases that cause increased LV wall thickness; and (2) Characterize quantifiable echo measures of disease progression in cardiac amyloidosis and HCM and associate these with clinical outcomes. Our multidisciplinary team, which is composed of experts in cardiomyopathies, echocardiography, computer vision, and machine learning, will analyze echos and patient data from 2 large patient registries: the Multicenter Amyloid Phenotyping Study (MAPS) and the Sarcomeric Human Cardiomyopathy Registry (SHaRe) HCM Network, with validation using a repository of nearly 400,000 echos. The successful completion of our aims will result in an innovative tool for early diagnosis of myocardial diseases and tracking of disease progression. Importantly, our project will set the stage for conducting larger epidemiology studies of rare myocardial diseases by automating the identification of these patients, and thereby developing previously unattainable broad-based cohorts for these conditions. PROJECT NARRATIVE Rare heart diseases such as amyloidosis (due to abnormal deposition of a protein into the heart muscle) and hypertrophic cardiomyopathy (due to a genetic mutation) are important causes of heart failure and sudden death in the general population. These heart diseases are difficult to diagnose, monitor, and treat because: (1) they appear superficially similar to more common forms of heart disease (e.g., high blood pressure) on imaging tests; (2) the optimal monitoring of disease progression over time has not been established; and (3) there is a lack of large-scale studies of patients with these diseases given their rarity. This project aims to use machine learning (artificial intelligence) of digital echocardiographic images to create a completely automated method for diagnosing and tracking these rare heart diseases with the ultimate goal of broad deployment of artificial intelligence algorithms in hospitals and clinics to help identify patients with these rare heart diseases earlier, better predict adverse outcomes, and increase the size and scope of patient registries to enhance research of these conditions.",Machine learning for the automated identification and tracking of rare myocardial diseases,9614825,R01HL140731,"['Address', 'Affect', 'Algorithm Design', 'Algorithms', 'Amyloid', 'Amyloidosis', 'Arrhythmia', 'Artificial Intelligence', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular system', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Clinics and Hospitals', 'Cohort Studies', 'Communities', 'Comorbidity', 'Computer Vision Systems', 'Coronary heart disease', 'DNA Sequence Alteration', 'Data', 'Deposition', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Echocardiography', 'Face', 'General Population', 'Goals', 'Heart Diseases', 'Heart failure', 'Hospitalization', 'Human', 'Hypertension', 'Hypertrophic Cardiomyopathy', 'Image', 'Image Analysis', 'Individual', 'Inherited', 'Left', 'Left Ventricular Hypertrophy', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Monitor', 'Morphology', 'Myocardium', 'Outcome', 'Output', 'Patients', 'Phenotype', 'Play', 'Process', 'Proteins', 'Reader', 'Reading', 'Registries', 'Research', 'Research Personnel', 'Role', 'Safety', 'Standardization', 'Structure', 'Sudden Death', 'Symptoms', 'Testing', 'Thick', 'Time', 'Two-Dimensional Echocardiography', 'United States', 'Validation', 'Ventricular', 'adverse outcome', 'base', 'career', 'clinical care', 'clinical imaging', 'cohort', 'cost', 'digital', 'disease diagnosis', 'epidemiology study', 'heart imaging', 'hypertensive heart disease', 'image processing', 'innovation', 'interest', 'multidisciplinary', 'novel therapeutics', 'particle', 'patient registry', 'repository', 'response', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2018,826025,685608202,-0.009600534532977562
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,9502903,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2018,879004,46216755,-0.030429162375384178
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9478117,U54AI117924,"['Address', 'Biological', 'Blood coagulation', 'Breast Cancer Risk Factor', 'Clinical', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'biomedical scientist', 'clinical investigation', 'clinical predictors', 'education research', 'graduate student', 'high dimensionality', 'improved', 'innovation', 'interest', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning', 'undergraduate student']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2018,897471,338121506,-0.0001761296559152404
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,9542295,U54EB020405,"['Accelerometer', 'Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Big Data to Knowledge', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Overweight', 'Pathology', 'Personal Satisfaction', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Walking', 'Work', 'base', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'health data', 'improved', 'improved outcome', 'industry partner', 'insight', 'massive open online courses', 'models and simulation', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'online resource', 'prevent', 'programs', 'public health relevance', 'reduce symptoms', 'role model', 'social', 'social model', 'societal costs', 'surgery outcome', 'tool', 'visiting scholar', 'wearable device']",NIBIB,STANFORD UNIVERSITY,U54,2018,955747,560644462,0.0004879992821547506
"Transition from Risk Factors to Early HF: Prevalence, Pathogenesis, and Phenomics ﻿    DESCRIPTION (provided by applicant): Heart failure (HF) is a major public health problem: it affects >6 million people in the U.S., it is the #1 cause of hospitalization and readmission in older adults, and 5-year survival after HF hospitalization is a dismal 35%, regardless of underlying ejection fraction (EF). These statistics highlight the urgent need for prevention of HF and better understanding of how and why HF develops in high-risk individuals. However, a critical limitation of prior population-based studies is the ascertainment of incident HF based on hospitalizations for HF and/or signs of overt volume overload. Many older individuals may suffer from early HF: breathlessness, fatigue, and exercise intolerance (without overt volume overload) due to underlying cardiac structure/function abnormalities, typically with a preserved EF (i.e. early HFpEF). Thus, the current epidemiology of HF is most likely missing a major form of prevalent HF. In this ancillary study of the Multi-Ethnic Study of Atherosclerosis (MESA, Year-15 Exam, n=3500), we will define early HF in a contemporary, multi-ethnic, elderly cohort; we will utilize cutting- edge indices of cardiac mechanics and ventricular-arterial interactions, including Lagrangian strain and time- varying pressure-stress analyses; and we will perform novel phenomics analyses to better characterize the interplay of risk factors and cardiac structure/function abnormalities (i.e., multi-dimensional phenotypic signatures) as they relate to early and overt HF. The aims of our study are to: (1) determine the prevalence of early HF using a combination of validated symptom surveys, 6-minute walk test, NTproBNP, and echocardiography, with validation using cardiopulmonary exercise testing (CPEX); (2) better understand the pathophysiology of early HF, particularly HFpEF; and (3) delineate the key phenotypic signatures associated with early and overt HF. The proposed exam will include anthropometry, blood pressure, symptom surveys, functional status (6-minute walk test), physical activity, laboratory measures (NTproBNP, fasting glucose, renal function), and comprehensive echocardiography (with tissue Doppler and speckle-tracking at rest and during physiologic maneuvers) in all participants. In sub-samples we will also measure arterial tonometry, novel biomarkers, and fitness (CPEX). We will utilize the wealth of data collected during the 5 prior MESA exams to perform longitudinal analyses (including latent class trajectory and statistical learning analyses) to determine the extent to which risk factors are associated with early HF, particularly early HFpEF. By the end of our 4-year study, we will accomplish the following key goals, each of which will have a lasting impact on the field of HF: (1) we will establish the prevalence of early HF in the community; (2) we will have a standardized method for the screening/diagnosis of early HFpEF, validated by CPEX, and readily applicable to the clinical setting; (3) we will define novel mechanisms by which risk factors, alone and in combination, relate to abnormalities in cardiac mechanics and ventricular-arterial coupling in the general population; and (4) we will have defined phenotypic signatures of HF development that will inform future clinical trials for HF prevention and treatment. PUBLIC HEALTH RELEVANCE: Heart failure is a common, expensive, and deadly health problem, especially among the elderly. Unfortunately, once overt heart failure develops it is difficult to treat and results in poor outcomes. Therefore it is critical to determine the relationhip between risk factors and abnormalities in heart structure and function that lead to early forms of heart failure. This project aims to: (1) determine how common early heart failure is in the population; (2) better understand the mechanisms of early heart failure by studying the heart and blood vessels using imaging and laboratory tests; and (3) use ""big data"" techniques to harness the wealth of quantitative data we have collected to determine individuals at highest risk for the development of early heart failure.","Transition from Risk Factors to Early HF: Prevalence, Pathogenesis, and Phenomics",9505972,R01HL127028,"['Address', 'Adult', 'Affect', 'Age', 'Air Pollution', 'Ancillary Study', 'Anthropometry', 'Big Data', 'Biological Markers', 'Blood Pressure', 'Blood Vessels', 'Cardiac', 'Cardiac Output', 'Cardiopulmonary', 'Cardiovascular Abnormalities', 'Chronic Kidney Failure', 'Clinical', 'Clinical Trials', 'Code', 'Communities', 'Coronary', 'Coronary Arteriosclerosis', 'Coupling', 'Data', 'Development', 'Diabetes Mellitus', 'Diet', 'Dyspnea', 'EFRAC', 'Early Diagnosis', 'Echocardiography', 'Elderly', 'Electrocardiogram', 'Epidemiology', 'Ethnic Origin', 'Exercise stress test', 'Fatigue', 'Functional disorder', 'Future', 'Galectin 3', 'Gender', 'General Population', 'Goals', 'Health', 'Heart', 'Heart Atrium', 'Heart failure', 'Hospitalization', 'Hypertension', 'ICD-9', 'Image', 'Incidence', 'Individual', 'Laboratories', 'Lead', 'Left', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Multi-Ethnic Study of Atherosclerosis', 'Myocardial', 'Myocardial Infarction', 'Obesity', 'Outcome', 'Outpatients', 'Participant', 'Pathogenesis', 'Patients', 'Phenotype', 'Physical activity', 'Physiological', 'Population', 'Population Study', 'Prevalence', 'Prevention', 'Prevention strategy', 'Public Health', 'Race', 'Renal function', 'Rest', 'Risk', 'Risk Factors', 'Sampling', 'Spirometry', 'Standardization', 'Stress', 'Structure', 'Surveys', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Validation', 'Ventricular', 'Walking', 'Weight', 'aged', 'arterial stiffness', 'arterial tonometry', 'base', 'brachial artery', 'clinical Diagnosis', 'cohort', 'design', 'endothelial dysfunction', 'epidemiology study', 'ethnic diversity', 'exercise intolerance', 'fasting glucose', 'fitness', 'functional status', 'high risk', 'hospital readmission', 'indexing', 'longitudinal analysis', 'novel', 'novel marker', 'phenomics', 'population based', 'pressure', 'public health relevance', 'recruit', 'screening', 'statistics', 'trend']",NHLBI,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R01,2018,1319272,134382703,0.0069977856261783525
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,9577245,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'multidisciplinary', 'pathogen', 'point of care', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2018,1329765,51931732,-0.011617114570477842
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9266344,U54AI117924,"['Address', 'Biological', 'Blood coagulation', 'Clinical', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'biomedical scientist', 'clinical investigation', 'clinical predictors', 'education research', 'graduate student', 'high dimensionality', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning', 'undergraduate student']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2017,18271,338121506,-0.0001761296559152404
"MHealth Monitoring of Acoustic and Behavioral Patterns in Bipolar Disorder Across Cultures Abstract: The ability to prioritize individuals for health care based on behavioral and acoustic patterns in speech will allow for efficient use of health care resources. The ability to predict mood states using daily monitoring of acoustics derived from mobile technology provides the basis for a real-time proxy measure of moods and affective states. Identification and monitoring of these and other dimensional features of human disease is the base for anticipating outcomes, offering the future possibility of timely and mitigating interventions. Technological and mHealth methods are well suited for the global health community due to the flexibility and adaptability of the approach; the capacity to reach large numbers of patients can be easily amplified with modest increase in infrastructure. We have developed an accurate prediction model for mood states in bipolar (BP) individuals using machine-learning strategies and established a process that involves preprocessing, feature extraction, and an integrated data analysis of clinical and acoustic data gathered from personal use of a mobile device for up to one year. The results show mood states are predicted with an AUC statistic of 0.74 (mania) and 0.77 (depression). We hypothesize that analyses across cultures will identify common features of illness that can be identified using our methods. BP is ideal for study because of the wide range of mood states and temperamental traits. This study aims to 1) ascertain 30 individuals with BP and 10 healthy controls from Lebanon and a multilingual community in SE Michigan, recording daily acoustic and behavioral data using a smart-phone, all outgoing speech from the device is gathered and all personal digital activity is recorded from the device. We propose to study participants in Lebanon and SE Michigan in order to identify the fundamental acoustic elements of mood variation among bipolar patients. 2) apply integrated computational analyses using static (Gaussian Mixture Models and Support Vector Machines) and dynamic (Hidden Markov Models) modeling of categorical, dimensional and derived features from clinical, acoustic, and behavioral signals; we will compare data from the 15 BP from Lebanon and 15 BP from SE Michigan that have been resident in USA >2 years but originate from a geographical region comparable to Lebanon in language and culture, and 15 American born BP Caucasians (from our current cohort). Our hypothesis is that there are fundamental elements of acoustics that associate with mood states regardless of the culture. The impact is the longitudinal use of mobile technology to passively gather personal data to establish computational models that use extensive individual state and trait data to accurately predict mood and health states. This provides a foundation for predictive modeling that can be integrated into subsequent clinical interventional studies to predict and test causal effects of specific interventions on disease mechanisms. Expertise in clinical, computational, and technology disciplines form the team to realize these goals. This is a study that focuses on the ability of technological methods to detect speech and behavioral patterns in patients with bipolar disorder across cultural boundaries to identify common features that predict mood states. The overall goal is to use computational methods for the early detection of affect and mood changes that will provide the opportunity to monitor mood disorders using common methods regardless of cultural differences.",MHealth Monitoring of Acoustic and Behavioral Patterns in Bipolar Disorder Across Cultures,9340389,R21MH114835,"['Acoustics', 'Address', 'Adherence', 'Affect', 'Affective', 'American', 'Arabs', 'Behavioral', 'Bipolar Disorder', 'Bipolar I', 'Caring', 'Categories', 'Caucasians', 'Cellular Phone', 'Characteristics', 'Clinical', 'Clinical assessments', 'Communities', 'Community Health', 'Computer Analysis', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Databases', 'Depressed mood', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'Discipline', 'Disease', 'Early Diagnosis', 'Elements', 'Emotions', 'Evaluation', 'Foundations', 'Future', 'Gaussian model', 'Geographic Locations', 'Goals', 'Health', 'Health Technology', 'Healthcare', 'Immigrant', 'Immigration', 'Impairment', 'Individual', 'Intervention', 'Intervention Studies', 'Interview', 'Language', 'Lebanon', 'Locales', 'Machine Learning', 'Manic', 'Measures', 'Medical', 'Mental Depression', 'Metadata', 'Methods', 'Michigan', 'Middle East', 'Modeling', 'Monitor', 'Mood Disorders', 'Moods', 'Multilingualism', 'Outcome', 'Participant', 'Pathologic', 'Patient Care', 'Patient Triage', 'Patients', 'Pattern', 'Phonation', 'Population', 'Probability', 'Process', 'Protocols documentation', 'Proxy', 'Psychiatric therapeutic procedure', 'Recording of previous events', 'Research Infrastructure', 'Resources', 'Safety', 'Secure', 'Severities', 'Signal Transduction', 'Social Functioning', 'Speech', 'Supervision', 'Symptoms', 'Technology', 'Telephone', 'Temperament', 'Testing', 'Time', 'Universities', 'Variant', 'base', 'bipolar patients', 'cognitive function', 'cohort', 'data management', 'design', 'digital', 'flexibility', 'global health', 'handheld mobile device', 'health data', 'human disease', 'learning strategy', 'lexical', 'lexical processing', 'low and middle-income countries', 'mHealth', 'markov model', 'mobile computing', 'predictive modeling', 'programs', 'tool', 'trait']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2017,30000,641965656,-0.07281414735705491
"Infection Control Implications of Heterogeneous Resistance Mechanisms in Carbapenem-resistant Enterobacteriaceae (CRE) PROJECT SUMMARY In 2013, the Centers for Disease Control and Prevention (CDC) assigned its highest antibiotic resistance threat level to carbapenem-resistant Enterobacteriaceae (CRE). CRE are resistant to nearly all routinely used antibiotics with gram-negative coverage and have been implicated in several high-profile nosocomial outbreaks in United States (U.S.) facilities. Although in past outbreaks institutions have deployed aggressive and highly bundled responses, this “kitchen sink” approach is unlikely to be resource- or cost-effective as CRE become endemic in the U.S. Evidence-based CRE policies are necessary, but fundamental gaps in knowledge remain. In particular, heterogeneous mechanisms encode carbapenem resistance in CRE, which are broadly classifiable by whether carbapenem resistance does (“CP-CRE”) or does not (“non-CP-CRE”) arise from carbapenemase production. Until recently resistance testing was limited in clinical settings, but this landscape is changing with the rollout of commercially available assays for identifying carbapenemase production. However, data on the prevalence of CP-CRE and non-CP-CRE in U.S. patients, especially among high-risk hospitalized populations, are limited. Moreover, some evidence suggests that propensity for intra-facility spread differs between CP-CRE and non-CP-CRE, but rigorous data are lacking. Evaluating epidemiological differences in CRE resistance types is essential to establishing public health priorities for CRE prevention in U.S. healthcare facilities. Aim 1 will evaluate the prevalence of and pre-admission risk factors for rectal colonization with CP-CRE and non-CP-CRE in a cohort of approximately 1900 patients admitted to the medical intensive care unit (MICU) and comprehensive transplant unit (CTU) at The Johns Hopkins Hospital. Risk factors will be analyzed with machine learning methodologies in order to develop a user-friendly decision tree to identify patients at high-risk of CP-CRE and/or non-CP-CRE carriage for future targeted surveillance screening. Aim 2 will utilize serially collected rectal swabs, in conjunction with clinical and environmental data, to estimate the incidence of nosocomial CP-CRE and non-CP-CRE colonization and to evaluate the contribution of asymptomatic CRE carriers and individual-level risk factors on a patient's risk of CRE acquisition during unit hospitalization. Strain-typing and other analyses as needed (e.g., whole genome sequencing) will be available to ascertain transmission events. This will be the first study in a U.S. hospital to investigate CRE spread associated exclusively with asymptomatic carriers and stratified by resistance type in a non-outbreak setting. The broad, long-term goals of this proposal are to advance our understanding of the epidemiology of CRE colonization and the implications of CRE resistance mechanisms to routes of nosocomial acquisition in order to guide CRE control policies and resource prioritization in U.S. healthcare facilities. PROJECT NARRATIVE Heterogeneous mechanisms encode carbapenem resistance in carbapenem-resistant Enterobacteriaceae (CRE). Understanding the infection control implications of this heterogeneity has assumed newfound relevance with the rollout of resistance mechanism assays to identify carbapenemase production. The proposed research seeks to examine whether risk factors for CRE colonization and propensity for organism spread in the hospital environment differ by CRE resistance type, in order to promote evidence-based strategies for CRE control in U.S. hospitals.",Infection Control Implications of Heterogeneous Resistance Mechanisms in Carbapenem-resistant Enterobacteriaceae (CRE),9267654,R36HS025089,[' '],AHRQ,JOHNS HOPKINS UNIVERSITY,R36,2017,41785,807432003,-0.012243819787540763
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,9333122,U54EB020405,"['Accelerometer', 'Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Big Data to Knowledge', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Walking', 'Work', 'base', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'health data', 'improved', 'improved outcome', 'industry partner', 'insight', 'massive open online courses', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'online resource', 'prevent', 'programs', 'public health relevance', 'reduce symptoms', 'role model', 'sensor', 'social', 'social model', 'tool', 'visiting scholar']",NIBIB,STANFORD UNIVERSITY,U54,2017,68981,560644462,0.0004879992821547506
"Examination of Readmissions after Cardiac Surgery in Pennsylvania: Development of Risk Models with Clinical Relevance The Centers for Medicare and Medicaid Services (CMS) initiated policies meant to improve this period of care in an effort to encourage health care providers to engage in better coordination of care. In 2012, CMS began to assess penalties from “excess” rehospitalization for selected diagnoses, including pneumonia, heart failure, and acute myocardial infarction. The financial incentive spurred hospitals to identify patients at risk and to devise strategies to reduce readmissions. Readmissions decreased.2 Given the program's apparent success, the list of admission diagnoses was expanded to include total hip arthroplasty, total knee arthroplasty, and chronic obstructive pulmonary disease (COPD) in 2015, and readmission after coronary artery bypass grafting was added beginning in 2017. The largest, most reliable studies of rehospitalization after cardiac surgery describe a rate of thirty day readmission of 13-19%.3-5 281,000 cardiac surgeries were reported to the Society of Thoracic Surgeons Adult Cardiac Surgery Database last year.6 A conservative estimate of the number of readmissions after heart surgery is therefore approximately 40,000. Multiple publications have developed logistic regression models designed to identify patients who are at increased risk of readmission, but these models have had disappointing predictive value, with c-statistics that range from 0.6 to 0.65.3-5, 8 Using data from the Pennsylvania Health Care Cost Containment Council, we seek to improve upon these models.  The most common causes of readmission after heart surgery are heart failure, arrhythmia and infection. A recent publication from a consortium of academic centers described that these three diagnoses represented about half of all readmissions within 30 days.7 Identifying patients who are at high risk for cause-specific readmissions would facilitate tailored interventions to prevent this unwanted outcome. We seek to develop models that predict cause- specific readmissions and to define high-risk populations in whom targeted strategies to prevent readmission can be efficiently implemented. In Aim 1, we will test the hypothesis that a diagnosis-specific multivariable analysis will yield models that are more predictive and can better define a high risk population.  Development of cause-specific readmission models would be a step forward in confronting this problem. These tools would aid hospitals and healthcare systems in implementing strategies to improve rates of readmission. Readmission to an acute care facility after cardiac surgery is an important clinical problem; it is estimated that 40,000 patients are readmitted within thirty days each year, and the Centers for Medicare and Medicaid will begin penalizing hospitals for excess readmissions after coronary artery bypass graft surgery beginning in 2017. A better understanding of the characteristics of patients who face a high risk of readmission is imperative to implement targeted transitional care strategies to prevent unnecessary readmission. Development of cause-specific readmission models would be a step forward in confronting this problem.",Examination of Readmissions after Cardiac Surgery in Pennsylvania: Development of Risk Models with Clinical Relevance,9387177,R03HS025038,[' '],AHRQ,UNIVERSITY OF PENNSYLVANIA,R03,2017,99609,593605914,-0.008488271155890416
"Optimizing electrical impedance myography outcomes through data mining Project summary  Electrical impedance myography (EIM) is a non-invasive technology for the assessment of muscle that is based on the application of a weak, high frequency electrical current to a muscle and the measurement of the resulting surface voltages. The further development and application of EIM remains the main business focus of Skulpt, Inc, a small business concern based in Boston and San Francisco (Specific Aims just say San Francisco). Alterations to the condition of the muscle, including myocyte atrophy, fat and connective tissue deposition, and inflammation all alter the EIM data in predictable and consistent ways. To date, through Skulpt, EIM has been applied as a potential biomarker for assessing disease progression and response to therapy in a wide variety of neuromuscular disorders, including amyotrophic lateral sclerosis, Duchenne muscular dystrophy, and spinal muscular atrophy, as well as other disorders that impact muscle condition, such as disuse atrophy and sarcopenia (age related muscle loss); over 1000 people have been studied with Skulpt’s EIM technology. Whereas the results of these applications are promising, the analytic approaches taken to the data sets have been fairly basic, utilizing only simple single frequency or simplistic multifrequency values. However, with every single muscle measurement, over 240 individual data points are acquired at different frequencies, different depths of muscle penetration, and at different angles to the major muscle fiber direction. Moreover, each of the above studies has been done in isolation, and thus how results differ between diseases is unknown. Given the plethora of data, applying more sophisticated analytic approaches has the potential of yielding improved EIM measures. Moreover, collaborators have already collected an associated wealth of animal EIM data that will help further inform this analysis. Thus, in this proposed Phase 1 SBIR, we plan to apply a variety of data mining techniques to the vast set of data already accumulated at Skulpt, Inc such that improved EIM outcomes can be developed and implemented. In Specific Aim 1, we will study human data across all disease types evaluated to determine which data sets are most effective at discriminating diseased from healthy muscle as well as distinguishing between diseases. In Specific Aim 2, we will focus on finding the metrics that are most sensitive to the degree of muscle pathology in a specific disease. In both of these aims, we will evaluate how these new metrics are mirrored in already obtained animal data. In Specific Aim 3, we will study these metrics in a new set of data (a test set) that was not used to develop the analytical paradigms so as to ensure their robustness. With the conclusion of this work, we will plan to pursue a Phase 2 SBIR that will focus on the development of a software suite to assist in EIM data interpretation based upon these results followed by a prospective observational clinical study to evaluate the efficacy of these newly developed metrics for disease diagnosis and tracking of progression/response to therapy. Project Narrative  Electrical impedance myography (EIM) is a non-invasive technology for the assessment of muscle that remains the main focus of Skulpt, Inc. Considerable EIM data has already been collected in a variety of neuromuscular diseases. In this study, the investigators plan to perform a more detailed analysis of all data collected to date (so-called “data mining”), such that improved EIM outcomes can be developed that will be applied to future studies.",Optimizing electrical impedance myography outcomes through data mining,9466075,R43AR073114,"['Age', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Animals', 'Area', 'Atrophic', 'Back Pain', 'Boston', 'Businesses', 'Categories', 'Characteristics', 'Clinical', 'Clinical Research', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Set', 'Deposition', 'Development', 'Diagnostic', 'Disease', 'Disease Progression', 'Disease model', 'Disease remission', 'Disuse Atrophy', 'Duchenne muscular dystrophy', 'Electrodes', 'Electrophysiology (science)', 'Ensure', 'Fatty acid glycerol esters', 'Fiber', 'Frequencies', 'Functional disorder', 'Funding', 'Future', 'Glycogen storage disease type II', 'Health', 'Inclusion Bodies', 'Individual', 'Inflammation', 'Laboratories', 'Machine Learning', 'Measurement', 'Measures', 'Medical Technology', 'Methods', 'Mining', 'Muscle', 'Muscle Cells', 'Muscle Fibers', 'Muscular Dystrophies', 'Musculoskeletal', 'Myography', 'Myopathy', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Penetration', 'Phase', 'Play', 'Positioning Attribute', 'Radiculopathy', 'Research Personnel', 'Role', 'San Francisco', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Tissues', 'Validation', 'Work', 'animal data', 'base', 'commercialization', 'data mining', 'disease classification', 'disease diagnosis', 'electric impedance', 'human data', 'improved', 'indexing', 'neuromuscular', 'potential biomarker', 'prospective', 'response', 'sarcopenia', 'voltage']",NIAMS,"MYOLEX, INC.",R43,2017,149998,869698,-0.004699940465489118
"Classifying addictions using machine learning analysis of multidimensional data ABSTRACT This Independent Scientist Award will significantly enhance my research capabilities, enabling me to become a leading quantitative investigator in the field of substance use disorders (SUDs). Specifically, it will allow me to increase my knowledge in the areas of SUD phenotypes, treatment and genetics. SUDs are clinically and etiologically heterogeneous and their classification has been difficult. This application reflects my ongoing commitment to developing an innovative and interdisciplinary research program on the classification of SUDs through quantitative analysis of multidimensional data. My extensive training in computational science and prior research on biomedical informatics have provided me with the skills to design, implement and evaluate advanced algorithms and sophisticated analyses to solve challenging problems in classifying SUDs. My ongoing NIDA-funded R01 employs a large (n=~12,000) sample aggregated from multiple genetic studies of cocaine, opioid, and alcohol dependence to develop and evaluate novel statistical models to generate clinical SUD subtypes that are optimized for gene finding. This K02 proposal extends that work to evaluate treatment outcome in refined subgroups of SUD populations using data from treatment studies for cocaine, opioid, alcohol and multiple substance dependence. This project will integrate data from diagnostic behavioral variables and genotypes, as well as biological/neurobiological features of the disorders and repeated measures of treatment outcome. The primary career development goals of this application are to: (1) understand the reliability, validity and functional mechanisms of various phenotyping methods; (2) to continue training in the genetics of addictions; and (3) to gain greater knowledge of different treatment approaches and their efficacy. A solid foundation in these areas will enhance my ability to realize the full potential of the data collected and aggregated from multiple dimensions, and to use the data to design the most clinically useful analysis and generate innovative solutions to diagnostic and predictive challenges in SUD research. Through formal coursework, directed readings, individual tutoring and intensive multidisciplinary collaboration with a diverse team of world-renowned researchers, I will receive training and collect pilot data for future R01 projects by examining (Aim I): whether clinically-defined highly heritable subtypes derived in my current R01 project predict differential treatment response; (Aim II) whether new statistical models that directly combine treatment data with behavioral, biological, and genomic data identify refined subtypes with confirmatory multilevel evidence; and (Aim III) whether there are genetic and social moderators of treatment outcome by subtype. The overall goal of this proposal is to further my independent and multidisciplinary research program in the development of statistical methods for refined classification of SUDs. The K02 award will provide me with the protected time necessary to fully engage in the training activities described that will enhance my knowledge and skills to enable me to make important, novel contributions to the genetics and treatment of SUD. PROJECT NARRATIVE This project will develop novel statistical and quantitative tools to identify homogeneous subtypes of substance use disorders (SUDs) and other complex diseases to enhance gene finding and treatment matching. The proposed project will perform secondary analyses of existing data from treatment studies of cocaine, opioid, alcohol, and mixed SUDs. The proposed novel approaches are expected to advance precision medicine approaches to SUDs by enabling treatment matching and a more refined SUD classification to gene finding.",Classifying addictions using machine learning analysis of multidimensional data,9224405,K02DA043063,"['Adherence', 'Aftercare', 'Alcohol dependence', 'Alcohols', 'Algorithms', 'Area', 'Behavioral', 'Biological', 'Biological Markers', 'Biosensor', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Cocaine', 'Cocaine Dependence', 'Collaborations', 'Combined Modality Therapy', 'Complex', 'Computational Science', 'DSM-IV', 'DSM-V', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic and Statistical Manual of Mental Disorders', 'Dimensions', 'Disease', 'Drug Use Disorder', 'Electroencephalography', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'Heterogeneity', 'Independent Scientist Award', 'Individual', 'Interdisciplinary Study', 'Investigation', 'Joints', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Neurobiology', 'Opiate Addiction', 'Opioid', 'Patients', 'Pattern', 'Pharmacogenetics', 'Pharmacotherapy', 'Phenotype', 'Population', 'Reading', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Research Personnel', 'Risk Factors', 'Sampling', 'Scientist', 'Signs and Symptoms', 'Solid', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'Substance Addiction', 'Substance Use Disorder', 'Surveys', 'Symptoms', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Work', 'addiction', 'alcohol use disorder', 'biomedical informatics', 'career development', 'cocaine use', 'contingency management', 'design', 'disease classification', 'disorder subtype', 'endophenotype', 'genetic association', 'genomic data', 'imaging genetics', 'improved', 'innovation', 'neural correlate', 'novel', 'novel strategies', 'opioid use disorder', 'outcome prediction', 'personalized medicine', 'precision medicine', 'programs', 'secondary analysis', 'skills', 'social', 'tool', 'treatment planning', 'treatment response', 'tutoring']",NIDA,UNIVERSITY OF CONNECTICUT STORRS,K02,2017,163452,36067938,-0.03151929317783194
"Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data DESCRIPTION (provided by applicant): In-hospital cardiac arrest (IHCA) is a significant public health problem, afflicting over 200,000 patients in the United States annually with a mortality rate of approximately 80%. The majority of these patients show signs of clinical deterioration in the hours before the event. This has led to the development of vital sign-based early warning scores designed to detect high-risk patients before IHCA to trigger life-saving interventions. However, the vast majority of these risk scores were created subjectively in individual hospitals and have shown limited accuracy for detecting adverse outcomes. Developing an accurate risk score to detect patients at highest risk of IHCA is essential to decreasing preventable in-hospital death. In my prior work, I completed several studies investigating the accuracy of vital signs for predicting IHCA. These studies, previous literature, and my preliminary data have resulted in the following conclusions: 1) statistically developed risk scores are more accurate than previously published risk scores, 2) multicenter data is needed to create the most accurate and generalizable risk score, 3) additional data, such as laboratory results, will likely improve the accuracy of risk scores, and 4) a cutting-edge method for developing prediction models, called machine learning, may result in more accurate risk scores. Importantly, significant improvement in accuracy leads to better identification of patients at highest risk of IHCA and decreased resource utilization. Therefore, in this grant proposal I aim to develop and validate IHCA prediction models using different statistical techniques in a multicenter database and then estimate the impact of the most accurate risk score using simulation studies. I will do this by firt developing prediction models using classic survival analysis methods (Aim 1a) and machine learning methods, such as neural networks and decision trees (Aim 1b). Then, I will compare the models I develop to the most accurate previously published risk scores in Aim 2. Finally, I will investigate the impact of the most accurate model from Aim 2 on patient outcomes using simulation modeling (Aim 3). Completion of this proposal will result in a validated IHCA risk score that can be implemented in the electronic health record to trigger life- saving interventions to decrease preventable in-hospital death. In addition, this career development award will provide critical data to inform future R01-level awards, including a clinical trial to investigate he impact of the developed prediction model on patient outcomes. I will complete this project under the direct supervision of my mentor (Dr. David Meltzer), co-mentor (Dr. Dana Edelson), and the rest of my advisory team (Drs. Jesse Hall, Robert Gibbons, and Michael Kattan). Together, this multidisciplinary team brings nationally renowned expertise in in-hospital cardiac arrest, outcomes research, critical care, and clinical prediction modeling. In addition, they serve as Chairs of the Section of Hospital Medicine (Dr. Meltzer), Section of Pulmonary and Critical Care (Dr. Hall), and Quantitative Health Sciences at the Cleveland Clinic (Dr. Kattan), and Directors of the Center for Health and the Social Sciences (Dr. Meltzer), Center for Health Statistics (Dr. Gibbons), and Clinical Research for the Emergency Resuscitation Center (Dr. Edelson). The mentorship, expertise, and resources that they provide will ensure my success as I grow into an independent physician-scientist. My career goal is to become an independent critical care outcomes researcher with a focus on developing prediction models for clinical deterioration that will improve patient outcomes. To accomplish this long-term goal, I have three short-term goals: (1) to gain expertise in the development and implementation of clinical prediction models, (2) to create an IHCA prediction model that will identify high-risk patients on the wards to trigger life-saving interventions, and (3) to gain expertise in simulation modeling in order to study the impact of the developed prediction model. To accomplish these goals, I will build upon the foundation I developed when earning my Master's Degree in Public Health and during my initial training in the PhD program in the Department of Health Studies. Although my training to date has provided me with a strong background in epidemiology and biostatistics, further advanced training in biostatistics is crucial for my development into a successful independent researcher. An integrated program of didactic coursework, seminars, research activities, and conference participation will span the duration of the award. By accomplishing my three short- term goals, I will develop unique skills that will allow me to become a successful independent researcher. Specifically, the expertise I will gain in prediction model development, implementation, and simulation modeling can be applied not only to IHCA research but also to other areas of critical care medicine. In addition, completion of these goals will result in a validated IHCA prediction model that I will study in future implementation and cost-effectiveness studies and will serve as a basis for future R01-level grant submissions. PUBLIC HEALTH RELEVANCE: Over 200,000 in-hospital cardiac arrests occur in the United States each year, and studies suggest that many of these events may be preventable if the clinical warning signs can be identified and acted upon quickly. However, the vast majority of tools used to identify patients at high risk of cardiac arrest were created subjectively and have limited accuracy. Development of a statistically derived risk tool is essential to detect at- risk patients accurately and early in order to provide the best opportunity to improve patient outcomes and reduce preventable in-hospital death.",Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data,9198041,K08HL121080,"['Adult', 'Advisory Committees', 'Applications Grants', 'Area', 'Award', 'Biological Neural Networks', 'Biometry', 'Brain', 'Case-Control Studies', 'Categories', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Critical Care', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Decision Trees', 'Deterioration', 'Development', 'Diastolic blood pressure', 'Doctor of Philosophy', 'Early Diagnosis', 'Electronic Health Record', 'Emergency research', 'Ensure', 'Epidemiology', 'Event', 'Foundations', 'Frequencies', 'Future', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Heart Arrest', 'Hospitalization', 'Hospitals', 'Hour', 'Hylobates Genus', 'Individual', 'Intensive Care Units', 'Intervention', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Life', 'Literature', 'Lung', 'Machine Learning', 'Master&apos', 's Degree', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Outcome', 'Outcomes Research', 'Patient Discharge', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Procedures', 'Public Health', 'Publishing', 'Receiver Operating Characteristics', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Rest', 'Resuscitation', 'Risk', 'Savings', 'Scientist', 'Sensitivity and Specificity', 'Social Sciences', 'Statistical Methods', 'Statistical Models', 'Supervision', 'Survival Analysis', 'Techniques', 'Testing', 'Time', 'Training', 'Uncertainty', 'United States', 'Update', 'Validation', 'Work', 'adverse outcome', 'base', 'career', 'cost effectiveness', 'design', 'evidence base', 'high risk', 'improved', 'learning strategy', 'model development', 'models and simulation', 'mortality', 'multidisciplinary', 'predictive modeling', 'programs', 'public health relevance', 'simulation', 'skills', 'statistics', 'success', 'symposium', 'tool', 'ward']",NHLBI,UNIVERSITY OF CHICAGO,K08,2017,163944,246330700,-0.01957622304176019
"Improving cancer family history collection through social networking and artificial intelligence PROJECT SUMMARY  The  activities  proposed  in  this  NCI  K07  application  are  designed  to  advance  the  career  development  and  research  independence  of  Dr.  Brandon  M.  Welch.  Family  health  history  (FHx)  is  one  of  the most important  resources available to help clinicians identify disease risks. By knowing a patient's FHx, clinicians can quickly  identify  disease risks and initiate risk-reducing strategies such as increased screening, prophylactic surgery,  risk-reducing  therapeutics,  and  lifestyle  changes.  FHx  is  also  the  foundation  of  genomic  medicine.  Unfortunately,  the  collection  and  use  of  FHx  by  patients  and  clinicians  is  suboptimal.  To  improve  the  collection and use of FHx among the general population, a better FHx tool that is easier and more convenient  to  use  than  current  FHx  tools  is  needed.  A  new  FHx  web  tool,  called  ​ItRunsInMyFamily.com,​  incorporates  artificial intelligence and social networking to improve user engagement with FHx collection.Utilizing artificial  intelligence  based  chat  entity  can  improve  the  collection  of  FHx  information  by  making  it  easier  and  more  engaging to record FHx information, likewise social networking allows users to tap into the collective wisdom  and  knowledge  of  the  family  to  correct  inaccuracies  and  overcome  gaps  in  FHx  knowledge.  This research  study  will  first  identify  enhancements  to  ​ItRunsInMyFamily.com  ​that  will  further  promote  user  engagement,  with  particular  focus  on  rural and underserved patients (Aim 1). We will then evaluate whether this new FHx  tool can improve collection of cancer FHx in comparison with current FHx tools (Aim 2). Finally, we will assess  the impact of ​ItRunsInMyFamily.com ​on the clinical settings (Aim 3). To implement the research plan, it will be  critical  to  apply,  skills  obtained  through  K  award  learning  objectives,  namely  clinical  oncology  (learning  objective  1),  iterative  patient-centered  design  (learning  objective  2),  and  health  technology  assessment  (learning  objective  3).  To  fulfill  these  learning  objectives,  an  interdisciplinary  group  of  mentors  will  direct  a  comprehensive training plan. The training plan includes coursework, seminars, workshops, journal clubs, and  conferences,  covering clinical oncology, patient engagement, health disparities, user-centered development,  human-computer  interaction,  clinical  research  methodologies,  health  technology  assessment,  and  ethical  conduct  of  research.  The  strong  support  of  an  excellent  team  of  mentors,  and  the  vast  resources  of  the  Medical  University  of  South  Carolina,  create  an  optimal  training  environment.  Collectively,  the  integrated  learning  objectives  and  research  plan  are  critical  to  establishing  a  successful,  innovative,  and  meaningful  academic career focused on developing patient-centric informatics tools for oncology.   PROJECT NARRATIVE Family health history (FHx) is one of the most important risk factors for cancer and the foundation of genomic medicine, but is under-utilized by patients and clinicians. By incorporating artificial intelligence and social networking into a FHx tool, it will lead to greater engagement with FHx collection. This research study will identify and incorporate features that promote user adoption, and evaluate its impact on FHx collection.  ",Improving cancer family history collection through social networking and artificial intelligence,9353355,K07CA211786,"['Adoption', 'Area', 'Artificial Intelligence', 'Breast Cancer Patient', 'Cancer Control', 'Cancer Family', 'Cellular Phone', 'Client satisfaction', 'Clinical', 'Clinical Oncology', 'Clinical Research', 'Collection', 'Data', 'Development', 'Educational workshop', 'Environment', 'Ethics', 'Family', 'Family Cancer History', 'Family health status', 'Foundations', 'General Population', 'Genetic screening method', 'Genomic medicine', 'Goals', 'Health Technology', 'Human', 'Informatics', 'Internet', 'Journals', 'K-Series Research Career Programs', 'Knowledge', 'Learning', 'Life', 'Malignant Neoplasms', 'Measures', 'Medical', 'Mentors', 'Methodology', 'Minority', 'Operative Surgical Procedures', 'Outcome', 'Patient Care', 'Patients', 'Provider', 'Qualitative Research', 'Randomized Controlled Trials', 'Recording of previous events', 'Reporting', 'Research', 'Research Methodology', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Social Network', 'South Carolina', 'Technology Assessment', 'Time', 'Training', 'Underserved Population', 'Universities', 'Workload', 'base', 'cancer risk', 'career', 'career development', 'clinical care', 'computer human interaction', 'design', 'disorder risk', 'health disparity', 'improved', 'innovation', 'next generation', 'oncology', 'patient oriented', 'personalized care', 'prevent', 'prophylactic', 'research and development', 'research study', 'rural underserved', 'satisfaction', 'screening', 'skills', 'symposium', 'therapeutic lifestyle change', 'tool', 'user centered design']",NCI,MEDICAL UNIVERSITY OF SOUTH CAROLINA,K07,2017,173453,136810522,-0.0013209338302383627
"Preventable Hospitalization in Dementia: The Impact of Neuropsychiatric Symptoms DESCRIPTION (provided by applicant): Older adults with dementia are at increased risk of hospitalization when compared to adults without dementia of similar age and medical comorbidity. The increased risk of hospitalization extends to potentially preventable hospitalization (PPH) for conditions such as a urinary tract infection or asthma exacerbation, suggesting difficulty in outpatient management of patients with dementia. Neuropsychiatric symptoms (NPS) of dementia such as agitation or delusions likely account for a significant amount of this risk, given their prevalence and potential to cause caregiver distress. While there are effective interventions for patients and caregivers to reduce NPS, the profile of patients that could benefit the most from intervention, therefore reducing their hospitalization risk, is unknown. Through the coordinated program of mentorship, didactics, and research that I propose, I will develop the advanced skills to derive and apply administrative, claims, and clinical encounter data to prospectively identify those patients with dementia at highest risk for hospitalization. Development of this patient-level risk phenotype means that future interventions to reduce hospitalization can then be prospectively matched to the patients most likely to benefit, a development of critical public health importance given both financial and geriatric work force constraints.  Over the next four years, my short-term training goals include: (1) address gaps in my formal research training, specifically: (a) to conduct observational analyses using large-scale claims and administrative data; (b) to derive clinical data from the electronic health record using natural language processing; and (c) to apply advanced methods of data analysis for risk prediction; (2) train in presentations, manuscript writing, and grantsmanship that culminate with a R01 proposal; (3) establish further connections with potential collaborators in the University of Michigan (UM) Pepper Center and broader community of aging researchers, national geriatrics and geriatric psychiatry communities, and the Beeson Scholar community; and (4) engage in leadership development with an emphasis on skills to lead a research team, mentor junior investigators, and communicate findings in research and clinical care settings.  These short-term goals will be paired with research aims that focus on elaborating the PPH risk profile for patients with dementia. Such research objectives can only be achieved when: (1) full clinical characteristics are available for the at-risk (i.e., non-hospitalized) population, includig (2) NPS data, which are rarely captured in standard administrative claims data. These criteria are uniquely met in the Veterans Affairs healthcare system, which has one of the nation's most advanced electronic health records (EHR). Using a national dementia case repository (N=269,565) from which I will draw matched cases (patients with dementia + PPH) and controls (non-hospitalized patients with dementia). Aim 1 will use claims and administrative data to explore patient, treatment, and facility risk factors associated with PPH. Aim 2 will use natural language processing to derive NPS from EHR clinical encounter notes and then characterize the association of NPS with PPH. Using the risk phenotype described in Aims 1 and 2, Aim 3 will develop logistic risk-prediction models to prospectively identify patients with dementia at highest risk for PPH. In subsequent grant proposals I will validate this risk- prediction model in other healthcare systems and prospectively pair the assessment tool with an evidence- based dementia intervention to reduce hospitalization.  My long-term career goals are to: (1) establish myself as independent investigator and national leader in geriatric mental health services research; (2) develop a programmatic line of funded health services research that develops risk-stratification models for late-life mental health and cognitive disorders; (3) translate knowledge from these research endeavors to improve the targeting and impact of future interventions research and health system delivery strategies; and (4) contribute broadly to the care of older adults by training and mentoring future clinical researchers in late-life mental health disorders. I am an Assistant Professor and geriatric psychiatrist at the University of Michigan, where I am also currently completing a MSc in Health and Healthcare Research, which provides an excellent background in health services research for clinicians. With this combination of clinical expertise and foundational training in health services research, I am uniquely qualified to undertake the advanced training activities outlined in this proposal, while UM affords the ideal environment in which to pursue this work. My primary mentor (Helen Kales, MD) and co-mentor (Frederic Blow, PhD) are national leaders in geriatric mental health who have used observational data to answer questions of national significance. My Advisory Panel includes Constantine Lyketsos, MD, MHS, an internationally-recognized expert in NPS and dementia care, and Kenneth Langa, MD, PhD, an internist, former Beeson Scholar, and renowned expert in using survey and secondary data to inform our understanding of dementia. Consultants include David Hanauer, MD, MS, an expert in bioinformatics and natural language processing, and Rodney Hayward, MD, a leader in risk assessment and intervention- targeting. My advisory team paired with resources of Michigan's Pepper Center, CTSA, and multi-disciplinary Institute for Healthcare Policy and Innovation make this the ideal environment in which to complete the proposed training activities. PUBLIC HEALTH RELEVANCE: Although hospitalization can negatively impact patients with dementia, we know very little about the specific risk factors associated with the chance of being hospitalized. It is important to understand what contributes to this risk, such as the behavior changes that accompany dementia, in order to identify those patients and caregivers that could benefit most from an intervention to avoid or reduce hospitalization. Given the rapidly rising numbers of patients with dementia, reducing potentially preventable hospitalization could have an enormous impact on public health.",Preventable Hospitalization in Dementia: The Impact of Neuropsychiatric Symptoms,9291398,K08AG048321,"['Address', 'Admission activity', 'Adult', 'Advisory Committees', 'Age', 'Aggressive behavior', 'Aging', 'Agitation', 'Antipsychotic Agents', 'Applications Grants', 'Assessment tool', 'Asthma', 'Attention', 'Benzodiazepines', 'Bioinformatics', 'Capsicum', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Code', 'Cognition Disorders', 'Communities', 'Community Psychiatry', 'Comorbidity', 'Data', 'Data Analyses', 'Delusions', 'Dementia', 'Development', 'Diagnosis', 'Distress', 'Doctor of Philosophy', 'Elderly', 'Electronic Health Record', 'Emergency Care', 'Environment', 'Foundations', 'Funding', 'Future', 'Geriatric Psychiatry', 'Geriatrics', 'Goals', 'Health', 'Health Care Research', 'Health Policy', 'Health Services Research', 'Health system', 'Healthcare Systems', 'Hospitalization', 'Individual', 'Institutes', 'Institutionalization', 'International', 'Internist', 'Intervention', 'Intervention Studies', 'Intervention Trial', 'Kale - dietary', 'Knowledge', 'Lead', 'Light', 'Literature', 'Location', 'Logistic Regressions', 'Logistics', 'Manuscripts', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Michigan', 'Modeling', 'Natural Language Processing', 'Outpatients', 'Patient Care', 'Patient risk', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Prevalence', 'Primary Health Care', 'Provider', 'Psychiatrist', 'Psychotic Disorders', 'Public Health', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Risk stratification', 'Rural', 'Signal Transduction', 'Sleeplessness', 'Source', 'Surveys', 'Symptoms', 'Training', 'Training Activity', 'Translating', 'Universities', 'Urinary tract infection', 'Validation', 'Veterans', 'Visit', 'Work', 'Writing', 'behavior change', 'career', 'case control', 'clinical care', 'cost', 'dementia care', 'design', 'effective intervention', 'evidence base', 'geriatric mental health', 'high risk', 'improved', 'innovation', 'leadership development', 'medication compliance', 'multidisciplinary', 'neuropsychiatric symptom', 'patient population', 'predictive modeling', 'professor', 'profiles in patients', 'programs', 'prospective', 'public health relevance', 'repository', 'skills', 'statistics', 'tool']",NIA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K08,2017,175103,641965656,-0.018233232462568888
"Towards automated phenotyping in epilepsy Over 5 million children and adults in the United States have had a diagnosis of epilepsy or a seizure disorder. However, treatment options for the epilepsies remain inadequate, because many patients suffer from uncontrolled seizures and from the negative side effects of treatment. A major obstacle to the faster development of new anti-convulsant therapies is the fact that rigorous preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). We propose to test if it is possible to perform objective, inexpensive and automated phenotyping of mice in various mouse models of acquired and genetic epilepsies. The approach rests on the recent recognition that mouse behaviors are structured in stereotyped modules at sub-second timescales that are arranged according to specific rules. These characteristic behavioral modules, and the transitions between them, can be identified without observer bias by combined 3D imaging and machine learning (ML) -assisted analytic methods. We propose to adopt this novel ML-assisted 3D video analysis technology to epilepsy research, in order to test if it can be used to identify mice with chronic temporal lobe epilepsy (TLE) during inter-ictal and ictal periods in two distinct experimental TLE models, and under various experimental conditions. In addition, we will also test whether the approach is able to automatically detect not only the overtly epileptic mice in a genetic model of severe childhood epilepsy (homozygous voltage-gated sodium channel β-subunit SCN1B-/- knock-out mice), but also distinguish the seemingly normal, non-epileptic, SCN1B+/- heterozygous mice from the wild-type controls. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user-independent, inexpensive analysis of acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will test if it is possible to objectively characterize epileptic phenotypes in mice using a breakthrough technology involving machine learning-assisted analysis of 3-dimensional video data of behavior. If successful, this innovative approach is expected to dramatically accelerate epilepsy research by enabling the objective, automated, inexpensive phenotyping of experimental animals to aid the testing of novel anticonvulsant therapies.",Towards automated phenotyping in epilepsy,9369284,R21NS102908,"['Adopted', 'Adult', 'Adverse effects', 'Animal Behavior', 'Animal Model', 'Animals', 'Anticonvulsants', 'Behavior', 'Behavioral', 'Characteristics', 'Child', 'Childhood', 'Chronic', 'Complex', 'Data', 'Development', 'Diagnosis', 'Electroencephalography', 'Epilepsy', 'Exhibits', 'Frequencies', 'Genetic', 'Genetic Models', 'Hippocampus (Brain)', 'Human', 'Human immunodeficiency virus test', 'Image', 'Knockout Mice', 'Machine Learning', 'Modeling', 'Monitor', 'Mus', 'Neurons', 'Observer Variation', 'Patients', 'Phenotype', 'Pilocarpine', 'Probability', 'Recurrence', 'Research', 'Rest', 'Seizures', 'Sodium Channel', 'Stereotyping', 'Structure', 'Syndrome', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Translational Research', 'United States', 'Wild Type Mouse', 'analytical method', 'base', 'cost', 'evidence base', 'high throughput analysis', 'innovation', 'kainate', 'learning strategy', 'mouse model', 'novel', 'novel therapeutics', 'pre-clinical', 'voltage']",NINDS,STANFORD UNIVERSITY,R21,2017,197528,560644462,-0.003683388826535375
"SWIFT-ActiveScreener: research and development of an intelligent web-based document screening system Project Summary More than 4,000 systematic reviews are performed each year in the fields of environmental health and evidence- based medicine, with each review requiring, on average, between six months to one year of effort to complete. In order to remain accurate, systematic reviews require regular updates after their initial publication, with most reviews out of date within five years. In the screening phase of systematic review, researchers use detailed inclusion/exclusion criteria to decide whether each article in a set of candidate citations is relevant to the research question under consideration. For each article considered, a researcher reads the title and abstract and evaluates its content with respect to the prespecified criteria. A typical review may require screening thousands or tens of thousands of articles in this manner. Under the assumption that it takes a skilled reviewer 30-90 seconds, on average, to screen a single abstract, dual-screening a set of 10,000 abstracts may require between 150 to 500 hours of labor. We have shown in previous work that automated machine learning methods for article prioritization can reduce by more than 50% the human effort required to screen articles for inclusion in a systematic review. Recently, we have further extended these methods and packaged them into a web-based, collaborative systematic review software application called SWIFT-Active Screener. Active Screener has been used successfully to reduce the effort required to screen articles for systematic reviews conducted at a variety of organizations including the National Institute of Environmental Health Science (NIEHS), the United States Environmental Protection Agency (EPA), the United States Department of Agriculture (USDA), The Endocrine Disruption Exchange (TEDX), and the Evidence Based Toxicology Collaboration (EBTC). These early adopters have provided us with an abundance of useful data and user feedback, and we have identified several areas where we can continue to improve our methods and software. Our goal for the current proposal is to conduct additional research and development to make significant improvements to SWIFT-Active Screener, including several innovations that will be necessary for commercial success. The research we propose encompasses three specific aims: (1) Investigate several improvements to statistical algorithms used for article prioritization and recall estimation. We will explore promising avenues for further improving the performance of our existing algorithms and address critical technical issues that limit the applicability of our current methods (Aim 1 – Improved Statistical Models). (2) Explore ways in which we can improve our models and methods to handle the scenario in which an existing systematic review is updated with new data several years after its initial publication (Aim 2 – New Methods for Systematic Review Updates). (3) Investigate several questions related to scaling the system to support hundreds to thousands of simultaneous screeners (Aim 3 - Software Engineering for Scalability, Usability and Full Text Extraction). Project Narrative Systematic review is a formal process used widely in evidence-based medicine and environmental health research to identify, assess, and integrate the primary scientific literature with the goal of answering a specific, targeted question in pursuit of the current scientific consensus. By conducting research and development to build a web-based, collaborative systematic review software application that uses machine learning to prioritize documents for screening, we will make an important contribution toward ongoing efforts to automate systematic review. These efforts will serve to make systematic reviews both more efficient to produce and less expensive to maintain, a result which will greatly accelerate the process by which scientific consensus is obtained in a variety of medical and health-related disciplines having great public significance.",SWIFT-ActiveScreener: research and development of an intelligent web-based document screening system,9467160,R43ES029001,"['Address', 'Algorithms', 'Area', 'Collaborations', 'Computer software', 'Consensus', 'Data', 'Discipline', 'Endocrine disruption', 'Environmental Health', 'Evidence Based Medicine', 'Exclusion Criteria', 'Feedback', 'Goals', 'Health', 'Hour', 'Human', 'Literature', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'National Institute of Environmental Health Sciences', 'Online Systems', 'Performance', 'Phase', 'Process', 'Publications', 'Research', 'Research Personnel', 'Software Engineering', 'Statistical Algorithm', 'Statistical Models', 'System', 'Text', 'Toxicology', 'United States Department of Agriculture', 'United States Environmental Protection Agency', 'Update', 'Work', 'evidence base', 'improved', 'innovation', 'learning strategy', 'research and development', 'screening', 'success', 'systematic review', 'usability']",NIEHS,"SCIOME, LLC",R43,2017,211900,2510992,0.0009182775197705518
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9320962,K01ES026833,"['Acute', 'Affect', 'Blood', 'Blood flow', 'Brain', 'Brain Injuries', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Healthcare', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Ruptured Aneurysm', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'public health relevance', 'standard of care', 'support tools', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2017,216241,558628098,-0.025432610564921375
"New Approach to US Elasticity Imaging Project Summary To more fully exploit the basic science of mechanobiology as it pertains to breast cancer progression, the medical imaging field continues to search for fast, safe, and effective elasticity imaging methods. In this project we propose a fundamentally new approach to ultrasonic elasticity imaging in which the weak forces applied to patient tissues and the measured displacements that result are used to train a numerical model specifically for that patient. This constitutive model is developed using finite-element methods and neural networks assembled in a unique configuration called the AutoProgressive (AutoP) Method. AutoP “learns” complete stress and strain properties directly from sparse force and displacement measurements and without a mathematical model. Using quasi-static stimuli, AutoP exploits the fact that each force-displacement estimate contains information about mechanical properties at all locations in the contiguous tissue. From measurement information and conservation laws, AutoP generates an informational model without the need to make assumptions about tissue linearity, isotropy, or other material properties normally required when constructing images that display tissue mechanical properties. Once an accurate material-property model is formed by AutoP, we adopt a separate rheological model (e.g., Kelvin Voigt) to form viscoelastic parameters for image display. The AutoP method employs beamformed RF-echo acquisitions from which point displacements are estimated, applied compressional force sensed at the transducer surface, and tissue shape.  No other imaging method is capable of estimating all relevant stress fields, which gives AutoP unique capabilities. AutoP estimates the mechanical properties that one strives to obtain from an inverse problem approach, but AutoP is not a mathematical inverse technique and hence does not suffer from nonunique solutions. Without the need to assume material properties, AutoP can (in principle) model tissue properties in three dimensions and in time following large deformations in highly-nonlinear, anisotropic media. This R21 proposal focuses on establishing the feasibility of the AutoP methodology for subsequent clinical trials under future funding. At the completion of this two-year project, we will demonstrate a new tool for medical imaging capable of exploring the mechanical properties of tissues over a very broad range of deformations. We specifically target ultrasonic methods and quasi-static force stimuli in this project. However AutoP could eventually be coupled to other imaging modalities (e.g., MRE, OCE) or dynamic force-stimulus methods.  The scientific premise underlying AutoP is that we already record all of the information needed to generate a very broad range of elasticity images. The key to unlocking this information is to set aside mathematical models in favor of data-driven informational models built using the unique machine learning abilities of the AutoP method. If successful, AutoP will have a major influence on medical elasticity imaging methods. Project Narrative: A new type of machine-learning method is proposed for elasticity imaging of patient tissues that offers the potential to minimize many current limitations. If we are successful in this development, ultrasonic elasticity imaging would significantly improve in its ability to accurately represent mechanical properties of breast tissues, without any changes in current instrumentation and without increasing cost to the healthcare system or adding risk to patients.",New Approach to US Elasticity Imaging,9385425,R21EB023402,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Basic Science', 'Behavior', 'Biological Neural Networks', 'Breast', 'Clinical', 'Clinical Trials', 'Code', 'Coupled', 'Data', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'Disease', 'Elasticity', 'Elements', 'Engineering', 'Environment', 'Feedback', 'Funding', 'Future', 'Goals', 'Healthcare Systems', 'Image', 'Inflammatory', 'Isotropy', 'Laws', 'Learning', 'Legal patent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammary Gland Parenchyma', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modulus', 'Patients', 'Procedures', 'Process', 'Property', 'Recording of previous events', 'Risk', 'Role', 'Scanning', 'Shapes', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Study Subject', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Model', 'Tissues', 'Training', 'Transducers', 'Ultrasonic Transducer', 'Ultrasonics', 'Writing', 'aged', 'base', 'breast imaging', 'cost', 'experience', 'healthy volunteer', 'human subject', 'imaging modality', 'imaging properties', 'improved', 'in vivo', 'information model', 'insight', 'instrumentation', 'learning strategy', 'malignant breast neoplasm', 'mathematical model', 'mechanical properties', 'model building', 'model development', 'novel strategies', 'object shape', 'processing speed', 'tool', 'tumor progression', 'viscoelasticity']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2017,220062,76545728,-0.028317958269150963
"Enabling value-based healthcare through automating risk assessment for episode-based care Project Summary Value-based healthcare implementation relies on understanding risk. 1 Early models, such as Medicare Advantage, use annual measures of risk under a risk adjustment factor (RAF) to offer financial incentive to payers and hospitals to work together. 2 More advanced models, such as bundled payments, target the periods of greatest quality variability, specifically episodes of care such as joint replacement, oncology diagnosis, and cardiac procedures. In these episodes, many types of providers, from hospitals to outpatient physical therapists, need to work together to reduce rates of complication and readmission. Risk levels are used to adjust payment for payer and providers and to determine which patients require additional resources in the hospital, clinic, or home. Unfortunately, existing risk models lack key features needed for episode-based care, which requires both financial alignment and accurate and immediate information to adjust clinical resources for a given case. 3 4 A better model would include all conditions relevant to an episode rather than just chronic conditions, addition of social determinants, and an automated approach to retrieve the information in hours rather than months. Thus, this Small Business Innovation Research (SBIR) Phase I program includes the following Specific Aims: 1. Create the phenotyping components required to define an accurate and comprehensive model  of episode-based risk, including: (i) extract clinical and social features from clinical data using  natural language processing (NLP), (ii) map concepts including social features to an ontology  that will support normalized data use, (iii) build a feature vector for each record that can be  used to feed a risk model that accounts for relevant clinical and social risk 2. Validate the phenotyping components using de-identified longitudinal clinical data for 10,000 patients In this research program, Phase I will tackle the most difficult challenges, including leveraging narrative text to recognize time-labeled social and clinical features influencing an episode of care. Success criteria will be accurate recognition of key underlying features that have not been available in risk models to date. Phase II will build upon the validated technology to create an episode-based risk model run on narrative and discrete clinical data and tested against actual patient outcomes. Success criteria will be a validated episode-based risk model to support value-based contracting and value-based clinical care. Project Narrative Advanced payment models in United States healthcare rely on accurate assessment of risk and quality. While quality has gained broad attention, risk models remain outdated and poorly suited to advanced payment models. CapsicoHealth proposes an effort to redefine risk models used for episode-based payments, using data sets across the continuum of care and clinical and social determinants of care that have previously been unavailable in computable form. If successful, this effort will impact financial and clinical approaches to value-based healthcare and significantly increase the chance that national efforts to improve cost and quality will be effective.",Enabling value-based healthcare through automating risk assessment for episode-based care,9464424,R43LM012798,"['Attention', 'Cardiac', 'Caring', 'Chronic', 'Clinic', 'Clinical', 'Clinical Data', 'Complication', 'Continuity of Patient Care', 'Contracts', 'Cost Control', 'Data', 'Data Collection', 'Data Quality', 'Data Set', 'Diagnosis', 'Foundations', 'Goals', 'Health Care Reform', 'Healthcare', 'Healthcare Systems', 'Home environment', 'Hospitals', 'Hour', 'Insurance', 'Label', 'Measurement', 'Measures', 'Medicare', 'Modeling', 'Natural Language Processing', 'Ontology', 'Outpatients', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Phenotype', 'Procedures', 'Provider', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Adjustment', 'Risk Assessment', 'Running', 'Small Business Innovation Research Grant', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'Work', 'base', 'care episode', 'clinical care', 'clinically relevant', 'concept mapping', 'cost', 'feeding', 'financial incentive', 'improved', 'interest', 'oncology', 'payment', 'physical therapist', 'programs', 'social', 'success', 'vector']",NLM,"CAPSICOHEALTH, INC.",R43,2017,222588,0,-0.015562963816337502
"Software for OCT Analysis of Vascular Stents Software for OCT Analysis of Vascular Stents PI: Ronny Shalev, PhD, Dyad Medical Summary Dyad Medical, Inc. will create intravascular OCT (IVOCT) software for clinical, live time determination of stent apposition (OCTivat-live, the live time OCT image visualization and analysis tool) and for offline analysis of stent implantation (OCTivat-stent). Every year, 100s of thousands of patients in the US are treated with intra- vascular stents creating an opportunity for both solutions. Although advancements such as drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent design parameters include drug, material (bioresorbable vs metal), polymer composition, coatings to stimulate cell coverage, etc. To opti- mize designs, sensitive, in vivo assessments are needed for preclinical and clinical evaluations. Intravascular OCT (IVOCT) is the lone imaging modality with the resolution and contrast to meet this challenge. The Core Lab at CWRU is the premiere site in the world for manual analysis of IVOCT image data. A cardiologist analyst takes 6-16 hrs to analyze manually a single stent, and despite training and quality assurance measures, inter- analyst variability can limit the power to determine changes between stent designs. Building upon work at CWRU, we will develop advanced, highly automated software to greatly speed analysis, improve reproducibil- ity, increase accuracy, and harmonize analysis. Software will reduce costs by decreasing manual labor, and with improved reproducibility, possibly enable the use of historical data, eliminating cost of a control arm. Re- garding live time analysis, rather than manually reviewing >500 images in a pullback, with fast software, it will be possible to present the number and location of malapposed struts in 3D, providing instant feedback to phy- sicians on the need for additional dilatation with a larger balloon or higher pressure. In addition, we will auto- matically determine stent and vessel area along the length of the pullback, allowing us to compute stent ex- pansion and eccentricity, quantitative measures related to successful stent deployment, the most important de- terminant of outcome. IVOCT could also play a role at patient follow up. If a stent is well covered, then long- term anti-platelet therapy might be unnecessary, minimizing bleeding risk. If a stent has many uncovered struts, a therapeutic might prevent stent thrombosis or stimulate healing. Project Narrative: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies and improved deployment for improved treatment of vascular dis- ease.",Software for OCT Analysis of Vascular Stents,9407267,R43HL137500,"['Agreement', 'Algorithms', 'Area', 'Blinded', 'Blood Vessels', 'Cells', 'Classification', 'Clinical', 'Clinical Trials', 'Code', 'Computer software', 'Data', 'Detection', 'Devices', 'Dilatation - action', 'Doctor of Philosophy', 'Feedback', 'Follow-Up Studies', 'Heart', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Implant', 'Institutes', 'International', 'Ions', 'Laboratories', 'Length', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Metals', 'Methods', 'Myocardial Ischemia', 'Needs Assessment', 'Outcome', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Play', 'Polymers', 'Process', 'Reproducibility', 'Research Personnel', 'Resolution', 'Risk', 'Role', 'Services', 'Site', 'Speed', 'Stents', 'Surrogate Markers', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Variant', 'Vascular Diseases', 'Work', 'arm', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'image visualization', 'imaging modality', 'implantation', 'improved', 'in vivo', 'personalized diagnostics', 'preclinical evaluation', 'pressure', 'prevent', 'prototype', 'quality assurance', 'research clinical testing', 'restenosis', 'statistics', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,"DYAD MEDICAL, INC.",R43,2017,224744,1085076,-0.014937613548212268
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9274155,R01AR068456,"['Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Bone structure', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cortical bone', 'cost', 'density', 'experience', 'fracture risk', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'population based', 'public health relevance', 'response', 'screening', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'tool', 'treatment response']",NIAMS,UNIVERSITY OF COLORADO DENVER,R01,2017,269514,292134808,0.003524713545440312
"Characterization of Thyroid Nodules by Quantitative Ultrasound Project Summary Thyroid cancer is the most-common endocrine malignancy. Its incidence has tripled in the last thirty years. Diagnosis of thyroid cancer is difficult because 50% of people older than 65 have at least 1 thyroid nodule, but only 10% of the nodules are cancerous. Approximately 1.6 billion dollars are spent annually in the US to detect thyroid cancer. Conventional ultrasound is used to identify nodules that warrant a needle biopsy. However, 65% of needle biopsies are negative for cancer and 30% are “indeterminate.” The indeterminate nodules are surgically removed for definitive diagnosis and 75% of them prove to be benign. Therefore, well more than 80% of initially presenting nodules undergo unnecessary biopsies and more than 20% of them also undergo subsequent unnecessary surgery procedures. Accordingly, the broad objective of the proposed study is to assess the feasibility of using quantitative-ultrasound (QUS) methods to distinguish cancerous from benign nodules reliably and thereby to reduce the enormous cost and risks associated with unnecessary biopsies and surgical excisions. The first aim of the project is to develop and asses the ability of QUS to distinguish cancerous from benign nodules and to compare the ability of QUS to the ability of conventional methods to select nodules that warrant biopsies; the second aim is to expand QUS methods by combining existing QUS measures developed by Riverside Research with measures derived from so-called B-flow- imaging (BFI) and shear-wave-elasticity (SWE) techniques developed by GE; the third aim is to formulate an objective basis for planning future, prospective studies to translate the findings of the present study to a commercial instrument that can bring QUS-based nodule evaluation into the clinic. To achieve these three aims, QUS performance in classifying cancerous and benign nodules will be compared to the performance of conventional ultrasound and the results of fine needle cytology, molecular marker analyses, and, in the cases of that undergo surgical excision, histology, will used as gold standards. Classification will be performed using standard, well understood, linear, and non-linear methods, such as linear-discriminant analysis and support- vector machines respectively. If feasibility is successfully demonstrated in the proposed project, and if the demonstration of feasibility ultimately leads to future incorporation into an instrument capable of real-time QUS analysis for reliable nodule evaluation, then a highly significant technological advance will be realized that can provide valuable, risk-reducing, cost-effective health-care benefits for patients presenting with thyroid nodules.   PROJECT NARRATIVE: Thyroid cancer rates have tripled in the last thirty years, but current methods of diagnosis are very inefficient. Far too many thyroid biopsies and surgeries are performed with >80% of biopsies and >25% of thyroid surgeries being performed on benign nodules. The advanced ultrasound methods to be evaluated in this proposal seek to drastically reduce the number of unnecessary biopsies and surgeries of benign thyroid nodules.",Characterization of Thyroid Nodules by Quantitative Ultrasound,9224641,R21CA212744,"['Achievement', 'Age', 'Architecture', 'Area', 'Asses', 'Benign', 'Biopsy', 'Breast Microcalcification', 'Calcified', 'Cancer Death Rates', 'Cancerous', 'Classification', 'Clinic', 'Clinical', 'Cytology', 'Cytology Histology', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Discriminant Analysis', 'Elasticity', 'Endocrine', 'Evaluation', 'Excision', 'Fine-needle biopsy', 'Foundations', 'Future', 'Goals', 'Gold', 'Healthcare', 'Histology', 'Image', 'In Situ', 'Incidence', 'Investigation', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measures', 'Methods', 'Molecular', 'Needle biopsy procedure', 'Needles', 'Nodule', 'Non-Malignant', 'Operative Surgical Procedures', 'Patient Care', 'Patients', 'Performance', 'Population', 'Probability', 'Procedures', 'Property', 'Prospective Studies', 'Prostate', 'ROC Curve', 'Research', 'Risk', 'Signal Transduction', 'Solid', 'Specificity', 'Techniques', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Time', 'Tissues', 'Training', 'Translating', 'Ultrasonography', 'United States', 'Unnecessary Surgery', 'base', 'calcification', 'cost', 'cost effective', 'design', 'elastography', 'improved', 'instrument', 'lymph nodes', 'molecular marker', 'novel', 'prevent', 'prospective', 'quantitative ultrasound', 'statistics']",NCI,BOSTON MEDICAL CENTER,R21,2017,274504,61416950,-0.0500487104513576
"Instrumental screening for dysphagia by combining high-resolution cervical auscultation with advanced data analysis tools to identify silent dysphagia and silent aspiration ABSTRACT Dysphagia (disordered swallowing) causes nearly 150,000 annual hospitalizations and over 220,000 additional hospital days, and prolongs hospital lengths of stay by 40%. Dysphagia risk is typically identified through subjective screening methods and those identified through screening undergo gold standard imaging testing such as videofluoroscopy (VF). However, screening methods over- or underestimate risk, and completely fail to identify patients with silent dysphagia (e.g., silent aspiration) that can cause pneumonia and other adverse events. Pre-emptive detection of silent or near-silent aspiration is essential. The long term goal is to develop an instrumental dysphagia screening approach based on high-resolution cervical auscultation (HRCA) in order to early predict dysphagia-related adverse events, and initiate intervention measures to mitigate them. The overall objective here is to develop accurate, advanced data analysis approaches to translate HRCA signals to swallowing events observed in VF images. Our strong preliminary data has led us to our central hypothesis: advanced data analytics tools are suitable approaches for the analysis of HRCA in order to automate dysphagia screening. The rationale is that a reliable, robust early-warning instrumental dysphagia screening approach will reduce adverse events in patients with silent aspiration/dysphagia, shorten length of stay and improve overall clinical outcomes. Guided by strong preliminary data, we will pursue the following three specific aims: (1) develop machine learning algorithms to differentiate HRCA signals produced by swallowing physiologic events from similar, non-swallow related signals produced during swallowing; (2) translate HRCA swallowing-signal signatures to actual swallow physiologic events to detect abnormal swallowing physiology; and (3) discriminate normal from abnormal airway protection and swallow physiology via machine-learning analysis of HRCA signals with similar accuracy as VF. Under the first aim, a machine learning approach will be used to detect pharyngeal swallowing events and differentiate them from speech, cough and other non- swallow events, with 90% accuracy, when compared to a human expert’s interpretation of our VF data sets. Under the second aim, objective swallowing physiology observations from VF will be matched to swallowing events observed with HRCA in order to show that abnormal swallow physiology and airway protection will produce distinctive HRCA signal signatures that predict the same events identified with VF. Under the third aim, analytical algorithms will be used to detect signs of disordered airway protection in HRCA signal signatures with 90% accuracy when compared to a human expert’s airway protection ratings from VF images. The approach is innovative, as it will produce analysis tools that will infer about dysphagia and aspiration based on the analysis of HRCA with unprecedented accuracy, before patients are placed in harm’s way. Our work is significant, because it will translate to an early-warning HRCA screening tool that predicts dysphagia- related adverse events in asymptomatic patients reducing medical adverse events, and length of stay. The proposed research is relevant to public health because dysphagia is related to nearly 150,000 annual hospitalizations and over 220,000 additional hospital days, it increases pneumonia incidence, prolongs hospital stays by 40% for patients with many diseases, and is prevalent in acute care hospitals and nursing homes. Choking (airway obstruction) and pneumonia due to aspiration (inhalation of swallowed food and liquids), are common results of dysphagia, and both are preventable when dysphagia is identified before patients are offered oral food, liquids or medications. The proposed research is relevant to the part of NIH’s mission that pertains to enhancing health, lengthening life and reducing illnesses, as we will develop new data analytics tools to be used along with high-resolution cervical auscultation in order to instrumentally screen for dysphagia and predict dysphagia-related adverse events before they can harm patients with dysphagia.",Instrumental screening for dysphagia by combining high-resolution cervical auscultation with advanced data analysis tools to identify silent dysphagia and silent aspiration,9355417,R01HD092239,"['Acute', 'Address', 'Admission activity', 'Adult', 'Adverse event', 'Algorithmic Analysis', 'Algorithms', 'Aspirate substance', 'Aspiration Pneumonia', 'Auscultation', 'Biomechanics', 'Breathing', 'Caring', 'Cervical', 'Choking', 'Clinical', 'Coughing', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Deglutition', 'Deglutition Disorders', 'Dehydration', 'Dementia', 'Detection', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Disabled Persons', 'Disease', 'Equipment', 'Event', 'Food', 'Goals', 'Gold', 'Group Homes', 'Head and Neck Cancer', 'Health', 'Hospital Nursing', 'Hospitalization', 'Hospitals', 'Human', 'Image', 'Impairment', 'Incidence', 'Intervention', 'Lead', 'Learning', 'Length of Stay', 'Life', 'Liquid substance', 'Machine Learning', 'Malnutrition', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monte Carlo Method', 'Morbidity - disease rate', 'Nature', 'Neurodegenerative Disorders', 'Nursing Homes', 'Oral', 'Outcome', 'Pathologic', 'Patient risk', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Physiological', 'Physiology', 'Pneumonia', 'Positioning Attribute', 'Public Health', 'Research', 'Resolution', 'Risk', 'Severities', 'Signal Transduction', 'Speech', 'Stroke', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Water', 'Work', 'airway obstruction', 'analytical tool', 'base', 'cancer therapy', 'clinical practice', 'clinically significant', 'image processing', 'improved', 'innovation', 'instrument', 'kinematics', 'mortality', 'patient safety', 'predictive signature', 'predictive tools', 'screening', 'tool', 'translational impact', 'vibration']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2017,302394,570146095,0.003078883493247137
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris�n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris�n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9264531,R01EY023279,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Categories', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Morphology', 'Nerve Fibers', 'Ophthalmoscopes', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'United States National Institutes of Health', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2017,339750,193405667,-0.0043559064542817594
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9260548,R01GM120033,"['Address', 'Algorithms', 'Alpha Cell', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cancer Etiology', 'Cardiovascular system', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical practice', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2017,356625,323604360,-0.0013986293307253622
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9360750,R01DE027027,"['Accounting', 'Affect', 'Algorithms', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,372360,135644722,-0.007480241397047244
"A platform for mining, visualization and design of microbial interaction networks Project Summary One of the burning questions in the study of the human microbiome is whether and how it is possible to design specific strategies for rebalancing the taxonomic and functional properties of human-associated microbial communities, triggering the transition from “disease states” to “healthy states”. While empirical studies provide strong support for the idea that we may be able to cure, or at least  treat, a number of diseases by simply transplanting microbiomes, or inducing changes through taxonomic or environmental perturbations, to date little mechanistic understanding exists on how microbial communities work, and on how to extend microbiome research from an empirical science to a systematic, quantitative field of biomedicine. We propose here to establish a computational platform--   a database (Aim 1) with fully integrated analytical software (Aims 2 and 3) --- developed for and with the cooperation of the scientific community. The resource goes beyond cataloguing microbial abundances under different condition; its aim is to enable an understanding of networks of interacting species and their condition-dependence, with the goal of eventually facilitating disease diagnosis and prognosis, and designing therapeutic strategies for microbiome intervention. Our project is centered around three key aims: 1.	The creation of a Microbial Interaction Network Database (MIND), a public resource that will collect data on inter-species interactions from metagenomic sequencing projects, computer simulations and direct experiments. This database will be accessed through a web-based platform complemented with tools for microbial interaction network analysis and visualization, akin to highly fruitful tools previously developed for the study of genetic networks; the database will also serve as the public repository of microbial networks associated with human diseases; 2.	The implementation of an integrated tool for simulation of interspecies interactions under different environments, based on genomic data and whole-cell models of metabolism; 3.	The implementation of new algorithms for microbial community analysis and engineering. These algorithms, including stoichiometric, machine-learning and statistical approaches will facilitate a “synthetic ecology” approach to help design strategies (e.g. microbial transplants or probiotic mixtures) for preventing and targeting microbiome-associated diseases. Our work will fill a major gap in current microbiome research, creating the first platform for global microbial interaction data integration, mining and computation. Project Narrative Among the major developments of the genomic revolution has been the ability to identify thousands of microbial species and strains living in communities in 5 major habitats in the human body, and the recognition that the relative abundances of these populations is strongly correlated with environment: disease state, diet, treatment protocol and so on. A major challenge in utilizing the deluge of health relevant data is structuring it into a database that facilitates understanding inter-microbial interactions in these communities. The aim of this proposal is to create a database and integrated computational platform, open to and contributed to by the research community, which will greatly accelerate the conversion of data into health related actionable knowledge.","A platform for mining, visualization and design of microbial interaction networks",9221662,R01GM121950,"['Affect', 'Algorithms', 'Cataloging', 'Catalogs', 'Cell model', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Development', 'Diet', 'Discipline', 'Disease', 'Ecology', 'Ecosystem', 'Empirical Research', 'Engineering', 'Environment', 'Evolution', 'Future', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Habitats', 'Health', 'Human', 'Human Biology', 'Human Microbiome', 'Human body', 'Imagery', 'Individual', 'Intervention', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Mediating', 'Metabolic', 'Metabolism', 'Metadata', 'Methods', 'Microbe', 'Mining', 'Nature', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Preventive Medicine', 'Probiotics', 'Property', 'Research', 'Resources', 'Science', 'Scientist', 'Structure', 'Taxonomy', 'Technology', 'Therapeutic', 'Time', 'Transplantation', 'Treatment Protocols', 'Work', 'base', 'computer framework', 'data integration', 'data to knowledge', 'design', 'disease diagnosis', 'experimental study', 'feeding', 'genome-wide', 'genomic data', 'human disease', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microbiota transplantation', 'microorganism interaction', 'novel diagnostics', 'novel therapeutics', 'open source', 'outcome forecast', 'prevent', 'repository', 'simulation', 'tool', 'user-friendly']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2017,377226,61050884,-0.02011656040006963
"Geometric Surrogates for Clinical Management of Abdominal Aortic Aneurysms ﻿    DESCRIPTION (provided by applicant): This proposal will investigate the following hypothesis: that the quantification of geometric surrogates, which predict the ensuing peak wall rupture risk index (PWRRI), will provide an improved estimate of aneurysm rupture risk compared to the clinical standard of maximum aneurysm diameter. We thus propose the highly innovative use of both radiological and non-radiological clinical imaging to develop a computational tool that can assess AAA risk of rupture with greater accuracy than the current clinical standard. Such a tool will allow the accurate quantification of individual AAA geometry to achieve the main goal of the study, which is to identify the patient-specific AAA geometry characteristics that are surrogates for patient-specific PWRRI. In the proposed approach, we will first compute a truly individualized PWRRI based on an innovative method called image-based Vascular Mechanical Characterization technology (iV-MeCh). The geometry characteristics highly correlated with PWRRI will be considered the surrogates of this biomechanics-based index. A second phase of the study will be the validation of the surrogates with actual clinical outcomes, which will yield the accurate predictors of rupture. This approach, devoid of complex finite element modeling and based on a fast, nearly automated computational tool for geometry quantification, would provide an exceptional rationale for the need for surgical intervention and be of major clinical significance. Therefore, the following specific aims are to be completed during the project period to address the aforementioned hypothesis: (1) Validate iV-MeCh for estimating patient-specific spatio-temporal AAA wall stress; (2) Calculate individual PWRRI using iV-MeCh for high and low risk of rupture AAA; (3) Identify the individual geometry characteristics that are surrogates of PWRRI; and (4) Assess the clinical significance of geometric surrogates for the prediction of AAA rupture risk. The primary outcome of this research will be the ability to disambiguate or demystify rupture risk in AAA for which the standard of care (maximum diameter) is not an accurate metric for assessing their at-risk condition. The geometric surrogates of PWRRI are hypothesized to reduce false positives and false negatives compared to the conventional maximum diameter cut-off for recommending elective repair. In addition, PWRRI is predicted by means of a new, novel technique (iV-MeCh), which estimates wall stress in aneurysms by means of non-radiological clinical imaging and without the use of constitutive soft tissue mechanics. PUBLIC HEALTH RELEVANCE: This award will enable the validation of computational tools for non-invasively predicting the at-risk condition of patients with abdominal aortic aneurysms (AAAs) based on the assessment of aneurysm geometry. This research is expected to impact the clinical management of AAA disease, as well as the pre-surgical planning capabilities of vascular and endovascular aneurysm repair.",Geometric Surrogates for Clinical Management of Abdominal Aortic Aneurysms,9250195,R01HL121293,"['Abdominal Aortic Aneurysm', 'Address', 'Aneurysm', 'Award', 'Biomechanics', 'Blood Vessels', 'Caliber', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Complex', 'Consent', 'Data', 'Development', 'Diagnosis', 'Disease', 'Electrocardiogram', 'Elements', 'Foundations', 'Geometry', 'Goals', 'Growth', 'Image', 'Individual', 'Intervention', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Motion', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Patients', 'Phase', 'Physiological', 'Property', 'Radiology Specialty', 'Records', 'Recruitment Activity', 'Research', 'Risk', 'Rupture', 'Ruptured Abdominal Aortic Aneurysm', 'Ruptured Aneurysm', 'Spatial Distribution', 'Stress', 'Surgeon', 'Surveillance Program', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Time', 'Validation', 'X-Ray Computed Tomography', 'base', 'clinical imaging', 'clinically significant', 'computerized tools', 'design', 'high risk', 'improved', 'indexing', 'individual patient', 'innovation', 'novel', 'pressure', 'primary outcome', 'prospective', 'public health relevance', 'radiologist', 'repaired', 'soft tissue', 'spatiotemporal', 'standard of care', 'tool']",NHLBI,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2017,398926,14847250,0.00486483354108296
"Antecedent Medical Conditions and Medications: Associations with the Risk and Prognosis ALS ﻿    DESCRIPTION (provided by applicant): ALS affects people in middle to late ages, during a time of life where it is common to suffer from more than one health problem, yet there is little understanding of the effect of chronic medical conditions and medication use on susceptibility to ALS. There is mounting concern and recent evidence that certain medical conditions and medications are associated with an increased risk of developing ALS, while other conditions and medications appear to be inversely associated with ALS risk. We propose to investigate the role of hyperlipidemia, diabetes, autoimmune diseases, as well as the drugs used to treat these disorders, as both risk and prognostic factors for ALS. This study has three specific aims: Aim 1, to investigate the association between antecedent medical conditions and the risk of developing ALS; Aim 2, to examine the relationship between certain classes of medication and the risk of developing ALS; and Aim 3, to determine whether medical conditions or medications present at diagnosis of ALS adversely or positively affect survival with ALS. We will assemble a retrospective cohort of Medicare beneficiaries who were continuously enrolled in fee-for-service Medicare (Parts A, B and D) during the years 2006 through 2014. To address aims 1 and 2, we will conduct a nested case-control study to identify newly diagnosed (incident) patients with ALS in this cohort between 2008 and 2014 using a modified version of the case definition algorithm used by the National ALS Registry. We expect to identify 11,000 incident ALS cases. Using incidence density sampling, ten age- and sex-matched controls will be randomly chosen for each case from among Medicare beneficiaries who entered the Medicare cohort in the same year as the case, but had who had no codes for ALS, MND or closely related conditions prior to their matched cases' diagnosis dates. We will use Medicare inpatient, outpatient, and laboratory health claims to document the occurrence of metabolic, cardiovascular, and autoimmune conditions among the study subjects both before and after the diagnosis of ALS. The availability of Part D (pharmaceutical) claims for Medicare beneficiaries from 2006 onward will provide the opportunity to examine the association of commonly used medications with the risk and prognosis of ALS. We will use conditional logistic regression analyses to identify premorbid medical conditions and medications associated with the risk of developing ALS. To address specific aim 3, we will link the data from our incident ALS case group to mortality data and conduct survival analyses to determine whether antecedent medical conditions and medications present at diagnosis are associated with either shortened or prolonged survival with ALS. We will use survival analysis to determine whether there is an association between these conditions/medications and survival with ALS. This study will contribute significantly to the understanding of the role that metabolic factors, hyperlipidemia, cardiovascular disease and autoimmunity play in the etiology and prognosis of ALS, and could lead to the development of new preventive or therapeutic interventions to prolong survival in ALS patients. PUBLIC HEALTH RELEVANCE: Amyotrophic lateral sclerosis (ALS: also known as Lou Gehrig's disease) is an adult-onset neuromuscular disorder that is the third most common neurodegenerative disease of aging (after Alzheimer's and Parkinson's diseases). It is critically important to identify modifiable risk factors present prior to diagnosis that affect the risk of developing ALS, and to also identify factors that are associated with the length of survival with this uniformly fatal disease. We hope that this study will identify modifiable risk factors that pu people at risk for ALS so that we can prevent this disabling disease, and we believe that studying the factors that influence length of survival with ALS will lead to the development of new preventive or therapeutic interventions to prolong survival among patients with ALS.",Antecedent Medical Conditions and Medications: Associations with the Risk and Prognosis ALS,9321614,R01TS000249,[' '],ATSDR,STANFORD UNIVERSITY,R01,2017,400000,560644462,-0.008223663954817712
"Developing Classification Criteria for the Uveitides ﻿    DESCRIPTION (provided by applicant): The uveitides are a collection of ~30 distinct diseases characterized by intraocular infection. Each disease has its own features, course, treatment, and prognosis. Traditionally, the uveitides have been grouped by the primary anatomic site of inflammation as anterior uveitis, intermediate uveitis, posterior uveitis, and panuveitis. However, there are substantial limitations to this ""lumping"" of diseases. For example, among the posterior uveitides, some (e.g. toxoplasmic retinitis and cytomegalovirus retinitis) are infectious and require treatment with antimicrobial/antiviral agents, some are chronic, presumed immune-mediated diseases that require immunosuppression (e.g. birdshot chorioretinitis, multifocal choroiditis, serpiginous choroiditis), and a few are self-limited, spontaneously-remitting diseases with a good prognosis (e.g. acute posterior multifocal placoid pigment epitheliopathy and multiple evanescent white dot syndrome). As such precise diagnosis is critical for research, including epidemiology, translational pathogenesis research, outcomes research, and disease specific clinical trials. Classification criteria are a type of ""diagnostic"" criteria used for reserch purposes. Although classification criteria seek to optimize sensitivity and specificity, when a trade-off is required, they emphasize specificity in order to ensure that a homogeneous group of patients is being studied. A precise phenotype is required particularly for genomic risk factor studies of complex disorders and translational pathogenesis research, as inclusion of other diseases with different risk factors and disease mechanisms would confound the results. Currently there are no widely-accepted and validated classification criteria for any of the uveitides. Preliminary data indicate ""fair to moderate"" agreement at best on the independent diagnosis of any one case by uveitis experts (κ's 0.27-0.40), but the ability of committees to reach agreement on the diagnosis of >98% of cases. The goal of the ""Developing Classification Criteria for the Uveitides"" project is for the Standardization of Uveitis Nomenclature (SUN) Working Group to develop classification criteria for the 25 leading uveitides using a formal, rigorous approach. There are 4 phases to the project: 1) informatics, to develop a standardized terminology; 2) case collection, to develop a preliminary database of ~250 cases of each disease; 3) case selection, to select at least 150-200 cases of each disease that are generally accepted to be the disease (using formal consensus techniques) from the preliminary database into a final database; and 4) data analysis, using machine learning approaches, of the final database to develop a parsimonious set of criteria for each disease that minimizes misclassification. The informatics and case collection phases of the Project are complete. The case selection phase is well underway and uses online voting and consensus conference calls to achieve supermajority acceptance on all cases included in the final database. The goals of this application are to complete case selection and data analysis and develop classification criteria for the 25 of the major uveitides. These results are crucial to future clinical research i the field of uveitis. PUBLIC HEALTH RELEVANCE:  Collectively, the uveitides are the 5th leading cause of blindness in the U.S., and the cost of treating them is estimated to be similar to that of treating diabetic retinopathy. Because uveitis occurs in all age groups, including children and working-age adults, there is a greater potential for years of vision lost than with age- related diseases. Clinical research in the field of uveitis has been hampered by diagnostic imprecision and a lack of widely-accepted and validated classification criteria, the development of which is the goal of this application; these criteria are needed urgently to advance epidemiology, genomic research, translational pathogenesis research, outcomes research, and disease-specific clinical trials.",Developing Classification Criteria for the Uveitides,9250167,R01EY026593,"['Acute', 'Adult', 'Affect', 'Age', 'Agreement', 'Anatomy', 'Anterior uveitis', 'Antiviral Agents', 'Blindness', 'Child', 'Choroiditis', 'Chronic', 'Classification', 'Clinical Research', 'Clinical Trials', 'Collection', 'Complex', 'Consensus', 'Cytomegalovirus Retinitis', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Enrollment', 'Ensure', 'Epidemiology', 'Future', 'Genomics', 'Goals', 'Immune', 'Immunosuppression', 'Infection', 'Inflammation', 'Informatics', 'Intermediate Uveitis', 'Machine Learning', 'Mediating', 'Nomenclature', 'Outcomes Research', 'Panuveitis', 'Pathogenesis', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Pigments', 'Posterior Uveitis', 'Publications', 'Research', 'Retinitis', 'Risk Factors', 'Sensitivity and Specificity', 'Specificity', 'Standardization', 'Syndrome', 'Techniques', 'Terminology', 'United States', 'Uveitis', 'Vision', 'Visual impairment', 'Voting', 'age group', 'age related', 'aging population', 'antimicrobial', 'birdshot chorioretinitis', 'cost', 'outcome forecast', 'public health relevance', 'symposium', 'tool', 'web page', 'working group']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2017,400107,415711940,-0.0021712629364851704
"Predicting Diabetic Retinopathy from Risk Factor Data and Digital Retinal Images Abstract Diabetic retinopathy is the leading cause of blindness among US adults between the ages of 20 and 74 years. Laser photocoagulation surgery has been established as an effective way of treating retinopathy if it is detected early. Yearly retinal screening examinations are a potent tool in the battle to reduce the incidence of blindness from diabetic retinopathy because they provide diabetic patients with timely diagnoses and consequently, the potential for timely treatment. Primary care safety net clinics provide monitoring and other services for diabetic patients but they are often not equipped to provide specialty care services such as retinal screenings. Access to specialists who can provide retinal screenings can be increased through the use of telemedicine, which has shown great promise as a means of screening for diabetic retinopathy in the US and internationally. A pilot study by Charles Drew University investigators had a total of 2,876 teleretinal screenings performed for diabetic retinopathy, with 2,732 unique diabetic patients from six South Los Angeles safety net clinics screened. The present study aims to build on this prior work by: (a) developing novel software that utilizes information from clinical records to detect latent diabetic retinopathy in diabetic patients who have not yet received an annual eye examination, and (b) devising methods to speed up the diabetic retinopathy detection process for diabetic patients who have had digital retinal images taken by partially automating the process using image processing and machine learning techniques. Specifically, we propose to: 1. Develop predictive models for diabetic retinopathy using risk factors collected from patient clinical records. 2. Develop predictive models for automated diabetic retinopathy assessment using a combination of patient  risk factor data and data from digital retinal images previously evaluated by experts. 3. Evaluate the predictive accuracy of: a) the models developed for specific aim 2, and, b) the assessments of  optometrist readers against standard of care dilated retinal examinations by board certified  ophthalmologists for 300 diabetic patients utilizing a new Los Angeles County reading center. 4. Create web-based software tools based on the predictive models developed in specific aim 1 that can be  used to initiate outreach to high-risk patients in under-resourced settings, boosting detection rates for those  patients who are most at risk for diabetic retinopathy. 5. Establish targeted outreach methods to promote screening for patients that the predictive models from  specific aim 1 identify as potentially having undetected diabetic retinopathy. Narrative Diabetic retinopathy is the leading cause of blindness among US adults between the ages of 20 and 74 years. Although previous studies within the US and internationally have shown that teleretinal screening can increase access to eye examinations for detecting retinopathy, few studies have focused on the US urban safety net, which has ophthalmic screening rates that are well below the US average and a preponderance of diabetic patients who are from ethnic minority groups. Building on a previous teleretinal screening study that assessed 2,732 South Los Angeles patients for retinopathy, this study deploys machine learning and image processing techniques to detect latent retinopathy in unscreened diabetic patients and partially automate the diabetic retinopathy detection process for teleretinal screening.",Predicting Diabetic Retinopathy from Risk Factor Data and Digital Retinal Images,9353867,R01LM012309,"['Address', 'Adult', 'Affect', 'Age', 'Alaska Native', 'American Indians', 'Asian Americans', 'Blindness', 'Blood Circulation', 'Blood Vessels', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Clinic', 'Clinical', 'Complications of Diabetes Mellitus', 'Computer software', 'County', 'Data', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Eye', 'Glucose', 'Health Care Reform', 'Health Insurance', 'Hispanics', 'Image', 'Incidence', 'International', 'Los Angeles', 'Machine Learning', 'Methods', 'Minority Groups', 'Modeling', 'Monitor', 'Not Hispanic or Latino', 'Online Systems', 'Operative Surgical Procedures', 'Ophthalmic examination and evaluation', 'Ophthalmologist', 'Optometrist', 'Patient risk', 'Patients', 'Pilot Projects', 'Population', 'Primary Health Care', 'Process', 'Protocols documentation', 'Publishing', 'Reader', 'Reading', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Retina', 'Retinal', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Rural', 'Services', 'Software Tools', 'Specialist', 'Speed', 'Techniques', 'Telemedicine', 'Time', 'United States', 'Universities', 'Work', 'aged', 'base', 'diabetic', 'diabetic patient', 'digital', 'digital imaging', 'disorder prevention', 'ethnic minority population', 'high risk', 'image processing', 'inner city', 'laser photocoagulation', 'medical specialties', 'medically underserved', 'mortality', 'novel', 'outreach', 'predictive modeling', 'primary care setting', 'racial minority', 'randomized trial', 'safety net', 'screening', 'standard of care', 'statistics', 'tool', 'transmission process', 'trend']",NLM,CHARLES R. DREW UNIVERSITY OF MED & SCI,R01,2017,479948,7479461,-0.0189190293103413
"Machine Learning for Identifying Adverse Drug Events ﻿    DESCRIPTION (provided by applicant): Because of the profound effect of adverse drug events (ADEs) on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post-marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA formed the Observational Medical Outcomes Partnership (OMOP) to develop and compare methods for identification of ADEs, and the FDA announced its Sentinel Initiative. Congress created the Reagan Udall Foundation (RUF) for the FDA in response to the FDA's own ""FDA Science and Mission at Risk"" report, and two years ago OMOP activities were incorporated into RUF. As the FDA moves forward with its development of Sentinel, including work on Mini-Sentinel, there is a need for researchers around the country to continue to develop better methods, and better evaluation methodologies for those methods. A robust research community working on algorithms for pharmacosurveillance, using electronic health records (EHRs) and claims databases will provide a substrate of ever-improving methods on which the nation's regulatory pharmacovigilance infrastructure can build. Indeed an important motivation of OMOP and Mini-Sentinel was to spur the development of such a community. Machine learning has attracted widespread attention across a range of disciplines for its ability to construct accurate predictive models. Therefore machine learning is especially appropriate for the problems of ADE identification and prediction: identifying ADEs from observational data, and predicting which patients are most at risk of suffering the identified ADE. Our current award has demonstrated the ability of machine learning to address both of these tasks. It has added to the existing evidence that consideration of temporal ordering of events, such as drug exposure and diagnoses, is critical for accuracy in identification and prediction of ADEs. The proposed work seeks to further improve upon these methods by building on recent advances in the field of machine learning, by our group and by others, in graphical model learning and in explicit modeling of irregularly-sampled temporal data. The latter is especially important because observational health databases, such as EHRs and claims databases, are not simple time series. Patients typically do not come into the clinic at regular intervals and have the same labs, vitals, and other measurements in lock step with one another. Building better ADE detection and prediction algorithms cannot be accomplished simply by machine learning research, even if that research is taking account of related work from relevant parts of computer science, statistics, biostatistics, epidemiology, pharmaco-epidemiology, and clinical research. Better methods are needed also for evaluation, that is, for estimating how well a new algorithm, or a new use of an existing algorithm, will perform at identifying ADEs associated with a new drug on the market, or at predicting which patients are most at risk of that ADE. More research and evaluation is also needed at the systems level: how can we best construct end-to-end pharmacovigilance systems that sit atop a large observational database and flag potential ADEs for human experts to further investigate? What kinds of information and statistics should such a system provide to the human experts?        This renewal will address the following aims: (1) improve upon machine learning methods for identification and prediction of ADEs, taking advantage of synergies between these two distinct tasks; (2) improve upon existing methods for evaluating ADE detection, building on advances in machine learning for information extraction from scientific literature; (3) improve upon existing methods for evaluating ADE prediction, building upon advances in machine learning for automated support of phenotyping and also building upon improved methods for efficiently obtaining expert labeling of borderline examples of a phenotype; and (4) use the methods developed in the first three aims to construct and evaluate an end-to-end pharmacosurveillance system integrated with the Marshfield Clinic EHR Data Warehouse. Machine learning plays a central and unifying role throughout all four aims. Our investigator team consists of machine learning researchers with experience in analysis of clinical, genomic, and natural language data (Page, Natarajan), a leading pharmaco-epidemiologist with expertise in building systems to efficiently obtain expert evaluation and labeling of phenotypes (Hansen), a leader in phenotyping from EHR data (Peissig), and an MD/PhD practicing physician with years of experience and leadership in the study of ADEs (Caldwell). In addition to building on results of the prior award, we will build on our experiences with OMOP, the International Warfarin Pharmacogenetics Consortium, the DARPA Machine Reading Program, and interactions with the FDA. PUBLIC HEALTH RELEVANCE: Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It also addresses the needs for improved evaluation and integrated systems approaches.",Machine Learning for Identifying Adverse Drug Events,9323511,R01GM097618,"['Address', 'Adverse drug effect', 'Adverse drug event', 'Algorithms', 'Attention', 'Award', 'Biometry', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Congresses', 'Country', 'Coxibs', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Discipline', 'Doctor of Philosophy', 'Drug Exposure', 'Early Diagnosis', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Evaluation Methodology', 'Event', 'Foundations', 'Genomics', 'Health', 'Human', 'Institute of Medicine (U.S.)', 'International', 'Label', 'Leadership', 'Learning', 'Life', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Markov Chains', 'Measurement', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Motivation', 'Myocardial Infarction', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenetics', 'Phenotype', 'Physicians', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Priority', 'Risk', 'Role', 'Safety', 'Sampling', 'Science', 'Sentinel', 'Series', 'Serious Adverse Event', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Wisconsin', 'Work', 'base', 'computer science', 'cost', 'data mining', 'experience', 'improved', 'interest', 'learning strategy', 'natural language', 'novel', 'novel therapeutics', 'patient safety', 'prediction algorithm', 'predictive modeling', 'programs', 'public health relevance', 'response', 'statistics', 'synergism']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2017,536041,338121506,-0.009181669640358605
"Machine learning of physiological variables to predict diagnose and treat cardiorespiratory instability Project Summary/Abstract: If one could accurately predict who, when and why patients develop cardiorespiratory instability (CRI), then effective preemptive treatments could be given to improve outcome and better use care resources. However, CRI is often unrecognized until it is well established and patients are more refractory to treatment, or progressed to organ injury. We have shown that an integrated monitoring system alert obtained from continuous noninvasively acquired monitoring parameters and coupled to a care algorithm improved step-down unit (SDU) patient outcomes. We also showed that advanced HR variability analysis (sample entropy) identified SDU patients at CRI risk within 2 minutes, and if monitored for 5 minutes differentiated between patients who would develop CRI or remain stable over the next 48 hours. We also applied machine learning (ML) modeling to our clinically-relevant porcine model of hemorrhagic shock to characterize responses to hypovolemia, hemorrhage, and resuscitation, predict which animals would or would not collapse during hypovolemia, and identify occult bleeding 5 minutes earlier than with traditional monitoring. We now propose to apply our work to vulnerable and invasively monitored ICU patients. We will develop multivariable models through ML data-driven classification techniques such as regression, Fourier and principal component analysis, artificial neural networks, random forest classification, etc. as well as more novel approaches (temporal rule learning developed by our team; Bayesian Aggregation) to predict CRI in ICU patients. We will first use our existing annotated high fidelity waveform MIMIC II clinical data set (4200 patients) to develop predictive models and differential signatures for various CRI drivers. We will also use our high-density data collection and processing platform (Bernoulli) to prospectively collect data from ICUs in three institutions: Univ. Pittsburgh (PITT), Univ. California (UC) Irvine and UC San Diego (initial algorithm development conducted at PITT and validated in the UC systems). We will identify the number and type of independent measures, sampling frequency, and lead time necessary to create robust algorithms to: 1) predict impending CRI, 2) select the most effective treatments, 3) monitor treatment response, and 4) determine when treatment has restored physiologic stability and can be stopped. We will also determine the smallest number and types of parameters coupled to the longest CRI lead time to achieve the above four targets with the best sensitivity and specificity (a concept we call Monitoring Parsimony).We will simultaneously iteratively design and test a graphical user interface (GUI) and clinical decision support system (CDSS) driven by these parsimoniously derived predictive smart alerts and functional hemodynamic monitoring treatment approaches in two human simulation environments (PITT & UC Irvine).We envision a basic monitoring surveillance that identifies patients most likely to develop CRI to apply focused clinician attention and targeted treatments to deliver highly personalized medical care. Public Health Narrative If one could accurately predict who, when and why patients develop shock then effective preemptive treatments could be given to improve outcome and more effectively use healthcare resources. But signs of shock often occur late once organ injury is already present. The purpose of this study is to first develop multivariable models through data-driven classification techniques to parsimoniously predict cardiovascular insufficiency, etiology and response to treatment. We will do this first in our existing MIMIC II clinical data sets of 4200 ICU patients as to timing and types of instability. Then we will prospectively collect real time high- density data on patients admitted to our trauma intensive care units of University of Pittsburgh, UC Irvine and UC San Diego. We will create and test in simulators of ICU care bedside user interfaces to drive recognition and treatment algorithms based on these models in all three medical centers.",Machine learning of physiological variables to predict diagnose and treat cardiorespiratory instability,9247214,R01GM117622,"['Acute', 'Algorithms', 'Animals', 'Attention', 'Biological Neural Networks', 'California', 'Cardiovascular system', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Complex', 'Coupled', 'Critical Illness', 'Data', 'Data Collection', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Entropy', 'Environment', 'Etiology', 'Family suidae', 'Frequencies', 'Future', 'Health', 'Healthcare', 'Hemorrhage', 'Hemorrhagic Shock', 'Homeostasis', 'Hour', 'Human', 'Hypovolemia', 'Individual', 'Injury', 'Institution', 'Intensive Care Units', 'Intervention', 'Lead', 'Learning', 'Libraries', 'Machine Learning', 'Measures', 'Mechanical ventilation', 'Medical', 'Medical center', 'Modeling', 'Monitor', 'Normal Range', 'Organ', 'Organ failure', 'Pathologic Processes', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Perioperative', 'Physiologic Monitoring', 'Physiological', 'Principal Component Analysis', 'Process', 'Protocols documentation', 'Public Health', 'Recommendation', 'Refractory', 'Resolution', 'Resources', 'Resuscitation', 'Risk', 'Running', 'Sampling', 'Sensitivity and Specificity', 'Sepsis', 'Shock', 'Signal Transduction', 'Specificity', 'Stream', 'Stress', 'System', 'Techniques', 'Testing', 'Time', 'Trauma', 'Triage', 'Universities', 'Validation', 'Variant', 'Weaning', 'Work', 'base', 'clinical care', 'clinically relevant', 'computerized data processing', 'cost', 'database structure', 'density', 'diagnostic accuracy', 'early onset', 'effective therapy', 'fitness', 'forest', 'graphical user interface', 'hemodynamics', 'high risk', 'improved', 'improved outcome', 'insight', 'iterative design', 'mortality', 'novel strategies', 'patient population', 'personalized medicine', 'predictive modeling', 'predictive tools', 'prospective', 'prototype', 'response', 'simulation', 'support tools', 'treatment response']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2017,598066,570146095,-0.014548840723242622
"Using Machine Learning to Predict Problematic Prescription Opioid Use and Opioid Overdose Problematic prescription opioid use, defined as nonmedical use, misuse, or abuse of opioid medications, is epidemic in the US. Prescription opioid overdose deaths more than quadrupled from 1999 to 2015. Efforts by health care systems and payers to combat the opioid epidemic are impeded by a lack of accurate and efficient methods to identify individuals most at risk for problematic opioid use and overdose, leading to broad interventions that are burdensome to patients and expensive for payers. Payers are currently defining high risk and targeting interventions (e.g. pharmacy lock-in programs) based on individual risk factors, such as high opioid dosage, identified in prior studies using traditional statistical approaches. However, these traditional approaches have significant limitations, especially when handling large datasets with numerous variables, multi-level interactions, and missing data. Moreover, the prior studies focused on identifying risk factors rather than predicting actual risk. Alternatively, machine learning is an advanced technique that handles complex interactions in large data, uncovers hidden patterns, and yields precise prediction algorithms that, in many cases, are superior to those developed using traditional methods. Machine learning is widely used in activities from fraud detection to cancer genomics, but has not yet been applied to address the opioid epidemic. Accordingly, the proposed study will apply machine learning to develop prediction algorithms that can more accurately identify patients at high risk of problematic opioid use and overdose using data sources that are readily available to payers and health care systems. The project will build on existing academic-state partnerships to apply novel machine learning approaches to administrative claims data for all Medicaid beneficiaries in Pennsylvania (PA) and Arizona (AZ). The project will also link Medicaid data in AZ to electronic health records to capture clinical information (e.g., lab results, pain severity) not available in administrative data, along with death certificate data on lethal overdose. These data, covering 2007-2016, will be used to achieve two specific aims: (1) to develop and validate two separate prediction algorithms to identify patients at risk of problematic opioid use and opioid overdose; (2) to compare the accuracy of a prediction algorithm that integrates clinical data with Medicaid claims versus a claims-based approach alone to identify patients at risk of problematic opioid use and opioid overdose. The machine learning approaches will include random forests and TreeNet with representative classification trees, and the predictive ability (e.g., misclassification rates) of these algorithms will be compared to traditional statistical models. Given the high prevalence of mental health/substance use disorders (~50%) and opioid utilization (>20%) among Medicaid enrollees and the lack of adequate prediction algorithms, Medicaid is an ideal setting for the proposed project. These analyses will provide the partnering Medicaid programs with valuable information and tools that they can apply to more precisely target interventions to prevent problematic opioid use and overdose. Prescription opioid overdose deaths quadrupled from 1999 to 2015, and drug overdose is now the leading cause of injury deaths among adults in the United States. This project will use innovative machine learning methods and readily available data for Medicaid beneficiaries in two states hard hit by the epidemic – Pennsylvania and Arizona – to develop algorithms to accurately predict who is at risk of problematic prescription opioid use and overdose. This information will empower health systems, payers, and policymakers to more effectively target interventions to prevent prescription opioid misuse and its consequences.",Using Machine Learning to Predict Problematic Prescription Opioid Use and Opioid Overdose,9421755,R01DA044985,"['Accident and Emergency department', 'Address', 'Adult', 'Alcohol or Other Drugs use', 'Algorithms', 'American', 'Arizona', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Data Set', 'Data Sources', 'Death Certificates', 'Detection', 'Dose', 'Electronic Health Record', 'Emergency department visit', 'Ensure', 'Epidemic', 'Fee-for-Service Plans', 'Fraud', 'Genomics', 'Health system', 'Healthcare Systems', 'High Prevalence', 'Hospitals', 'Individual', 'Injury', 'Inpatients', 'Intervention', 'Letters', 'Link', 'Logistic Regressions', 'Machine Learning', 'Managed Care', 'Medicaid', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Morphine', 'Opioid', 'Outcome', 'Overdose', 'Pain', 'Patients', 'Pattern', 'Pennsylvania', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Preclinical Drug Evaluation', 'Prevalence', 'Reporting', 'Research', 'Risk', 'Risk Factors', 'Severities', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'Substance Use Disorder', 'Techniques', 'Time', 'Trees', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Urine', 'Work', 'base', 'beneficiary', 'cancer genomics', 'clinical predictors', 'combat', 'design', 'dosage', 'forest', 'high risk', 'innovation', 'learning strategy', 'milligram', 'model building', 'nonmedical use', 'novel', 'opioid abuse', 'opioid use', 'overdose death', 'prediction algorithm', 'prescription opioid', 'prescription opioid misuse', 'prevent', 'programs', 'service utilization', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2017,601139,570146095,-0.005130443529411879
"Optical Body Composition and Health Assessment ﻿    DESCRIPTION (provided by applicant):1 Of all markers of human health, the most intuitive is body shape but based on quantitative evidence.  2 Anthropometry and regional composition measures such as waist circumference (WC), waist to hip ratio  3 (WHR), and visceral adipose tissue area (VAT) are better predictors of obesity-related diseases and mortality  4 risk than body mass index (BMI). Dual-energy X-ray absorptiometry (DXA) can quantify regional adiposity in  5 more detail than the above measures but is underutilized for many reasons including potential harm from  6 ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments  7 in the ""quantified self movement"" to better describe phenotypes of body shape and its relation to metabolic  8 risks. The candidate developed in this proposal is 3D optical whole body scanning. If successful, sophisticated  9 obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with 10 disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment 11 technology. Whole body 3D imaging technology is already so accessible that it can be done with video games 12 such as the Microsoft Xbox Kinect, and consumer cameras. 13 The long term goal of the Optical Body Shape and Health Assessment Study is 1) to provide phenotype 14 descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in 15 research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive 16 models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, 17 muscle mass, lean mass, and percent fat), and then show how our 3DO body composition estimates are 18 associated to important metabolic risk factors. Our central hypothesis is that 3DO measures of body 19 composition with shape classification better predict metabolic risk factors than anthropometry or DXA body 20 composition alone. Our specific aims are: 1. Identify the unique associations of body shape to body 21 composition indices in a population that represents the variance of sex, age, BMI, and ethnicity found 22 in the US population; 2. Describe the precision and accuracy of 3DO scans to monitor change in body 23 composition and metabolic health interventions; and 3. Estimate the level of association of 3DO to 24 common health indicators including metabolic risk factors by gender, race, age, and BMI. In an 25 exploratory aim, we investigate holistic, high-resolution descriptors of 3D body shape as direct 26 predictors of body composition and metabolic risk using statistical shape models and Latent Class 27 Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self- 28 assessment technologies that are capable of representing over 95% of the shape variance in the US 29 population, and how these models relate to important metabolic status and body composition. The positive 30 impact will be the immediate applicability to clinicians and individuals for personalized risk assessment. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because they have the potential to provide a better understanding of who is at high risk of metabolic diseases because of a poor metabolic profile. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Optical Body Composition and Health Assessment,9273519,R01DK109008,"['Adipose tissue', 'Adult', 'Age', 'Animals', 'Anorexia Nervosa', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Classification', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Devices', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Ethnic Origin', 'Fatty acid glycerol esters', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Individual', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Video Games', 'Visceral', 'Waist-Hip Ratio', 'bariatric surgery', 'base', 'clinical practice', 'cost', 'disorder prevention', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolic profile', 'metabolomics', 'mortality', 'muscle form', 'optical imaging', 'predictive modeling', 'public health relevance', 'sensor', 'sex', 'subcutaneous', 'tool', 'waist circumference', 'whole body imaging']",NIDDK,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2017,651796,685608202,0.017842522954837608
"Shape up! Kids Project Summary/Abstract Of all markers of pediatric health, the most intuitive is body shape. Human and animal studies indicate that weight loss/gain correlates closely with increasing/decreasing insulin sensitivity, respectively. Anthropometry and regional composition measures such as waist circumference, waist to hip ratio (WHR), and visceral adipose tissue area are better predictors of obesity-related diseases and mortality risk than pediatric body mass index Z-score. Dual-energy X-ray absorptiometry can quantify regional adiposity in more detail than these measures but is underutilized for many reasons including the sensitivity to children to ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments in optical technology to better describe phenotypes of pediatric body shape and its relation to metabolic risks (obesity, “failure to thrive”) and bone density and size. If successful, sophisticated obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment technology. The long term goal of the Shape Up! Kids Study is 1) to provide pediatric phenotype descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, muscle mass, lean mass, and percent fat) and bone mineral density (BMD) over a wide range of ages (5 to 18 years), weights and heights, stratified by sex, and ethnicity. Our central hypothesis is that optical estimates with shape classification of soft tissue composition and bone density better predict fracture and metabolic risk factors than anthropometry (WC, WHR, and BM) alone. The Investigators will highly leverage existing data from the National Health and Nutrition Examination Survey and Bone Mineral Density in Children Study. Our specific aims are: 1) Identify the unique associations of body shape to body composition and bone density indices in a pediatric population that represents the variance found in the US population, 2) Describe the precision and accuracy of optical scans to monitor change in body composition, bone density, 3) Estimate the level of association of optical scans to common health indicators including metabolic risk factors. Our exploratory aim is to investigate holistic, high-resolution descriptors of 3D body shape as direct predictors of body composition and metabolic risk using statistical shape models and Latent Class Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self-assessment technologies that are capable of representing over 95% of the shape variance in the US pediatric population, and to define how these models relate to important metabolic status indicators. The positive impact of these outcomes will be the immediate applicability to other researcher studies and clinicians using the automated tools and models developed here for 3D optical images. PROJECT NARRATIVE  The proposed research is relevant to public health because they have the potential to provide a better understanding of what children are at high risk of metabolic consequences of obesity. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults, and are becoming epidemic in children as well. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Shape up! Kids,9220287,R01DK111698,"['Adipose tissue', 'Adult', 'Age', 'Algorithms', 'Animals', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Surface', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Bone Density', 'Child', 'Childhood', 'Classification', 'Clinical', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Epidemiology', 'Ethnic Origin', 'Failure to Thrive', 'Fatty acid glycerol esters', 'Fracture', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Liver', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'Muscle', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Pediatric Radiology', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Factors', 'Safety', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Visceral', 'Waist-Hip Ratio', 'Weight', 'bone', 'clinical practice', 'cost', 'disorder prevention', 'handheld mobile device', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolomics', 'mortality', 'muscle form', 'optical imaging', 'predictive modeling', 'sensor', 'sex', 'soft tissue', 'subcutaneous', 'tool', 'waist circumference']",NIDDK,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2017,703842,685608202,0.021316360644854374
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,9357870,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Protein Hybridization', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2017,720717,46216755,-0.030429162375384178
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9352387,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Big Data', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Individual', 'Injury', 'Institution', 'Intuition', 'Leukocyte Chemotaxis', 'Lymphocyte Immunophenotypings', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Myocardial', 'Paper', 'Pathologic', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Sampling', 'Series', 'Staining method', 'Stains', 'Standardization', 'TNF gene', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'base', 'clinical diagnostics', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'human disease', 'improved', 'inquiry-based learning', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2017,782929,3808719,-0.0007807124647791958
"Transition from Risk Factors to Early HF: Prevalence, Pathogenesis, and Phenomics ﻿    DESCRIPTION (provided by applicant): Heart failure (HF) is a major public health problem: it affects >6 million people in the U.S., it is the #1 cause of hospitalization and readmission in older adults, and 5-year survival after HF hospitalization is a dismal 35%, regardless of underlying ejection fraction (EF). These statistics highlight the urgent need for prevention of HF and better understanding of how and why HF develops in high-risk individuals. However, a critical limitation of prior population-based studies is the ascertainment of incident HF based on hospitalizations for HF and/or signs of overt volume overload. Many older individuals may suffer from early HF: breathlessness, fatigue, and exercise intolerance (without overt volume overload) due to underlying cardiac structure/function abnormalities, typically with a preserved EF (i.e. early HFpEF). Thus, the current epidemiology of HF is most likely missing a major form of prevalent HF. In this ancillary study of the Multi-Ethnic Study of Atherosclerosis (MESA, Year-15 Exam, n=3500), we will define early HF in a contemporary, multi-ethnic, elderly cohort; we will utilize cutting- edge indices of cardiac mechanics and ventricular-arterial interactions, including Lagrangian strain and time- varying pressure-stress analyses; and we will perform novel phenomics analyses to better characterize the interplay of risk factors and cardiac structure/function abnormalities (i.e., multi-dimensional phenotypic signatures) as they relate to early and overt HF. The aims of our study are to: (1) determine the prevalence of early HF using a combination of validated symptom surveys, 6-minute walk test, NTproBNP, and echocardiography, with validation using cardiopulmonary exercise testing (CPEX); (2) better understand the pathophysiology of early HF, particularly HFpEF; and (3) delineate the key phenotypic signatures associated with early and overt HF. The proposed exam will include anthropometry, blood pressure, symptom surveys, functional status (6-minute walk test), physical activity, laboratory measures (NTproBNP, fasting glucose, renal function), and comprehensive echocardiography (with tissue Doppler and speckle-tracking at rest and during physiologic maneuvers) in all participants. In sub-samples we will also measure arterial tonometry, novel biomarkers, and fitness (CPEX). We will utilize the wealth of data collected during the 5 prior MESA exams to perform longitudinal analyses (including latent class trajectory and statistical learning analyses) to determine the extent to which risk factors are associated with early HF, particularly early HFpEF. By the end of our 4-year study, we will accomplish the following key goals, each of which will have a lasting impact on the field of HF: (1) we will establish the prevalence of early HF in the community; (2) we will have a standardized method for the screening/diagnosis of early HFpEF, validated by CPEX, and readily applicable to the clinical setting; (3) we will define novel mechanisms by which risk factors, alone and in combination, relate to abnormalities in cardiac mechanics and ventricular-arterial coupling in the general population; and (4) we will have defined phenotypic signatures of HF development that will inform future clinical trials for HF prevention and treatment. PUBLIC HEALTH RELEVANCE: Heart failure is a common, expensive, and deadly health problem, especially among the elderly. Unfortunately, once overt heart failure develops it is difficult to treat and results in poor outcomes. Therefore it is critical to determine the relationhip between risk factors and abnormalities in heart structure and function that lead to early forms of heart failure. This project aims to: (1) determine how common early heart failure is in the population; (2) better understand the mechanisms of early heart failure by studying the heart and blood vessels using imaging and laboratory tests; and (3) use ""big data"" techniques to harness the wealth of quantitative data we have collected to determine individuals at highest risk for the development of early heart failure.","Transition from Risk Factors to Early HF: Prevalence, Pathogenesis, and Phenomics",9313715,R01HL127028,"['Address', 'Adult', 'Affect', 'Age', 'Air Pollution', 'Ancillary Study', 'Anthropometry', 'Big Data', 'Biological Markers', 'Blood Pressure', 'Blood Vessels', 'Cardiac', 'Cardiac Output', 'Cardiopulmonary', 'Cardiovascular Abnormalities', 'Chronic Kidney Failure', 'Clinical', 'Clinical Trials', 'Code', 'Communities', 'Coronary', 'Coronary Arteriosclerosis', 'Coupling', 'Data', 'Development', 'Diabetes Mellitus', 'Diet', 'Dyspnea', 'EFRAC', 'Early Diagnosis', 'Echocardiography', 'Elderly', 'Electrocardiogram', 'Epidemiology', 'Ethnic Origin', 'Exercise stress test', 'Fatigue', 'Functional disorder', 'Future', 'Galectin 3', 'Gender', 'General Population', 'Goals', 'Health', 'Heart', 'Heart Atrium', 'Heart failure', 'Hospitalization', 'Hypertension', 'ICD-9', 'Image', 'Incidence', 'Individual', 'Laboratories', 'Lead', 'Left', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Multi-Ethnic Study of Atherosclerosis', 'Myocardial', 'Myocardial Infarction', 'Obesity', 'Outcome', 'Outpatients', 'Participant', 'Pathogenesis', 'Patients', 'Phenotype', 'Physical activity', 'Physiological', 'Population', 'Population Study', 'Prevalence', 'Prevention', 'Prevention strategy', 'Public Health', 'Race', 'Recruitment Activity', 'Renal function', 'Rest', 'Risk', 'Risk Factors', 'Sampling', 'Spirometry', 'Standardization', 'Stress', 'Structure', 'Surveys', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Validation', 'Ventricular', 'Walking', 'Weight', 'aged', 'arterial stiffness', 'arterial tonometry', 'base', 'brachial artery', 'clinical Diagnosis', 'cohort', 'design', 'endothelial dysfunction', 'epidemiology study', 'ethnic diversity', 'exercise intolerance', 'fasting glucose', 'fitness', 'functional status', 'high risk', 'indexing', 'longitudinal analysis', 'novel', 'novel marker', 'phenomics', 'population based', 'pressure', 'public health relevance', 'screening', 'statistics', 'trend']",NHLBI,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R01,2017,1338683,134382703,0.0069977856261783525
"Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination Project Summary / Abstract Between 1.6 and 3.8 million people each year suffer a mild TBI in the US alone. Reliable diagnosis and prompt treatments are vital to managing the often-serious short and long-term sequelae resulting from mild TBI. However, a reliable objective and accurate method for mild TBI diagnosis outside of a hospital setting, and in particular for determining RTP readiness, has eluded the clinical community. Current diagnosis and RTP assessments are based on patient symptoms, neurocognitive evaluations, and / or physical performance testing. Use of symptom scales are problematic for several reasons including subjectivity and reliability. Neurocognitive evaluations and physical tests (such as balance tests), although less subjective, require pre- injury baseline testing of subjects due to inherently large subject-to-subject variations in evaluation performances. Due to these reasons, current mild TBI diagnostic methods have limited applications and are not suitable for a significant majority of patients who suffer mild TBI. This project is aimed at developing an objective diagnosis of mild traumatic brain injury (mild TBI) based on physiologic changes in a patient after injury and providing a platform capable of RTP guidance. The method is based on quantification of well-known physiologic changes after a concussion, i.e. the impairment of autonomic function and altered cerebral blood flow (CBF) as measured with transcranial Doppler (TCD). The novelty of the proposed approach is the use of a recently-developed analytical machine learning framework for the analysis of the CBF velocity (CBFV) waveforms. In contrast to previous methods used before, the proposed approach utilizes the entire shape of the complex CBFV waveform, thus obtaining subtle changes in blood flow that are lost in other analysis methods. Additionally, comprehensive verification between our platform and MRI will be performed following injury resulting in the first scientific experiments of this kind. The ultimate goal of this Phase II SBIR is to commercialize an objective and accurate software algorithm for reliable diagnosis and management of sports concussions which does not currently exist. The outcome will be a software suite integrated into existing TCD and will be marketed to emergency departments, neurology clinics, and other healthcare providers involved in mild TBI diagnosis and RTP management. Project Narrative Traumatic brain injury (TBI) is a serious public health problem in the United States contributing to a substantial number of deaths and cases of permanent disability. Mild TBI concussions account for over 80% of all TBIs sustained and a major problem is the high rate of mis-diagnosis due to lack of objective measures and delayed onset of symptoms. This project aims to develop the first objective concussion evaluation method using a novel analysis platform that can obtain subtle, physiologic changes in cerebral hemodynamics. Successful completion of this project will result in a portable diagnostic device suitable for use in many scenarios where concussion diagnosis is inaccurate or unavailable today.",Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination,9323604,R44NS092209,"['Accident and Emergency department', 'Acute', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Area Under Curve', 'Assessment tool', 'Blood flow', 'Brain Concussion', 'Cerebrovascular Circulation', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Controlled Study', 'Core-Binding Factor', 'Data', 'Data Analytics', 'Data Collection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Evaluation', 'Functional disorder', 'Future', 'Goals', 'Gold', 'Guidelines', 'Health Personnel', 'Hospitals', 'Image', 'Impairment', 'Injury', 'Letters', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Modeling', 'Morphology', 'Neurocognitive', 'Neurologist', 'Neurology', 'Outcome', 'Patients', 'Pediatric Neurology', 'Performance', 'Persons', 'Phase', 'Physical Performance', 'Physicians', 'Physiological', 'Play', 'Public Health', 'Publications', 'Readiness', 'Recovery', 'Research', 'Resolution', 'Risk', 'Severities', 'Shapes', 'Site', 'Small Business Innovation Research Grant', 'Spin Labels', 'Sports', 'Sports Medicine', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Traumatic Brain Injury', 'Ultrasonography', 'United States', 'Variant', 'balance testing', 'base', 'brain health', 'cerebral hemodynamics', 'clinical Diagnosis', 'diagnostic accuracy', 'disability', 'experimental study', 'hemodynamics', 'high school', 'injured', 'innovation', 'mild traumatic brain injury', 'novel', 'pediatric department', 'performance tests', 'portability', 'prevent', 'programs', 'relating to nervous system', 'success', 'tool']",NINDS,"NEURAL ANALYTICS, INC.",R44,2017,1500000,699413,-0.0038214664943206408
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9106828,R01AR068456,"['Accounting', 'Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cost', 'density', 'experience', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'population based', 'public health relevance', 'response', 'screening', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2016,31678,685608202,0.003524713545440312
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9270103,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'education research', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2016,43143,338121506,-0.0001761296559152404
"Forecasting pulmonary inflammation from in vitro assay results for nanoparticles ﻿    DESCRIPTION (provided by applicant):  The rapidly developing field of nanotechnology shows promise by allowing designers to specifically select unique combinations of material properties as needed increasing the effectiveness of applications in medicine, coatings, lubrication, semiconductors, composites, and many others. These materials with their unique combinations of properties on exposure to humans may result in unanticipated hazards, however, putting workers in nanotechnology-related industries at risk. Traditional animal testing is expensive and too slow to evaluate potential risks for the current pace of new nanomaterial development. Both technology developers and regulators need more rapid methods to evaluate new nanomaterial configurations for their risk potential. Much hope is placed in high-throughput in vitro screening assays, but the relevance of these results to the potential for human disease or even the observed toxic effects in animal exposures is unclear. Some research has proposed Quantitative Structure Activity Relationships (QSARs) to predict in vitro nanomaterial toxicity in a few specific assays, but the applicability of these models to a wider group of materials, alternative in vitro assays, or in vivo toxicity has not been explored. If the primary exposure pathway for workers in the near term is inhalation, which in vitro assays will provide the most reliable risk information for that scenario? Two recently available data sources will permit this study to investigate this question: the Environmental Protection Agency's (EPA) ToxCast data for nanomaterials and the Nanomaterial Pulmonary Toxicity Database (NTDB), a collection of published peer reviewed studies observing pulmonary inflammation in rodents upon exposures to nanomaterials. This study will pursue the following specific aims: (1.) identify combinations of in vitro assay results that can reliably forecast the results of pulmonary inflammation results in rodents; (2.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to a wider array of in vitro toxicity assays; and (3.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to in vivo pulmonary inflammation results. This study will employ machine learning methods to cluster similar nanomaterials between the various in vitro and in vivo results, and to identify combinations of in vitro assays that rank order the toxicity of nanomaterials most similarly to pulmonary inflammation results in rodents considering also how changes in specific chemical and physical particle properties exacerbate or mitigate observed toxicity. This study addresses documented research needs in the National Occupational Research Agenda (NORA) cross- sector Nanotechnology program including specific goals in the Human Health and Informatics categories. Implementation complies with the Research to Practice (r2p) Initiative in its formulation, design, and implementation plan including industry an public outreach. The insight generated by this study will improve nanomaterial risk screening capabilities and focus attention and effort on those measurements and techniques proven to be most effective and reliable enabling better management and control of the risks faced by workers. PUBLIC HEALTH RELEVANCE:  Although toxicity risk information for nanoparticles is accumulating rapidly, the development of new nanomaterial configurations is proceeding too fast for our best risk assessment tools (i.e. animal testing) to keep up. The new availability of two large databases of in vitro assay results and pulmonary inflammation results in rodents will permit this study to investigate which in vitro assays provide the most predictive information about the results from in vivo exposures, and thus speed up the risk screening process for nanomaterials. The results of this study will have important implications for more quickly identifying new nanomaterial-related risks to workers.",Forecasting pulmonary inflammation from in vitro assay results for nanoparticles,9144793,R03OH010956,[' '],NIOSH,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R03,2016,66564,74382276,-0.006718192631447484
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,9103879,U54EB020405,"['Accelerometer', 'Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Big Data to Knowledge', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Mental Depression', 'Methods', 'Mission', 'Modality', 'Modeling', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Walking', 'Work', 'base', 'big biomedical data', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'experience', 'flexibility', 'health data', 'improved', 'improved outcome', 'industry partner', 'insight', 'massive open online courses', 'models and simulation', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'prevent', 'programs', 'public health relevance', 'reduce symptoms', 'role model', 'sensor', 'social', 'social model', 'tool', 'visiting scholar']",NIBIB,STANFORD UNIVERSITY,U54,2016,68981,560644462,0.0004879992821547506
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,9056632,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'education research', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2016,73173,338121506,-0.0001761296559152404
"Fracture Prediction by Machine Learning and 3D Finite Element Models from DXA ﻿    DESCRIPTION (provided by applicant): Osteoporosis is a disease characterized by loss of bone mass and structural deterioration leading to increased risk of fracture. Currently, osteoporosis is diagnosed by measurement of areal bone mineral density by dual- energy x-ray absorptiometry (DXA). However, the majority of fractures occur in both women and men who are not classified as osteoporotic by current DXA criteria (T-score = -2.5). As a 2-dimensional (2D) technology, DXA does not provide information about 3-dimensional (3D) bone structure, shape and geometry, which substantially contribute to bone strength and resistance to fracture. Finite element (FE) analysis of quantitative computed tomography (QCT) images can provide 3D structure and strength measurements but QCT is impractical for widespread clinical use because of high radiation exposure and expense. In contrast, DXA is widely available, inexpensive and has low radiation exposure. What is needed is a method by which DXA images can be used to generate 3D shape models that incorporate bone structure and geometry. However, fractures are complex events influenced by other factors including age, race, body mass index, risk of falls, and prior medical and fracture history. Even sophisticated measurements of bone density, structure, and strength may not be able to predict fractures accurately. Machine learning is an emerging field in which models are created by ""learning"" from previous data. These models can incorporate various factors and be used to classify or predict outcomes for new data. The overall hypothesis of this proposal is that advanced analyses of widely available DXA images that incorporate structural and strength information and statistical modeling using machine learning to incorporate additional risk factors will better identify patient at high risk of osteoporotic fracture. This hypothesis will be tested using QCT and DXA data from previous studies to generate 3D statistical shape models that describe variability in proximal femur morphology. By aligning 2D DXA images to the models, patient-specific 3D models will be reconstructed for quantitative analyses and combined with FE analysis to estimate bone strength. Machine learning models will be used to incorporate these novel measurements, demographics, and various risk factors for fracture to predict incident fractures in two very large, prospective studies. The ultimate goal of this proposal is to increase the diagnostic utility of DXA, a safe, non-invasive, and widely available technology, by applying novel image processing and statistical techniques to predict fractures more accurately. PUBLIC HEALTH RELEVANCE: Approximately 50% of women and 25% of men over age 50 are destined to suffer an osteoporotic fracture during their remaining lifetime. Unfortunately, the current standard for the diagnosis of osteoporosis, DXA, does not predict most fractures. This research will develop advanced analyses of DXA images and use machine learning to improve individualized fracture risk assessment.",Fracture Prediction by Machine Learning and 3D Finite Element Models from DXA,9068774,K99AR067883,"['3-Dimensional', 'Age', 'American', 'Body mass index', 'Bone Density', 'Cadaver', 'Characteristics', 'Clinical', 'Complex', 'Data', 'Data Set', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Epidemiology', 'Event', 'Femur', 'Finite Element Analysis', 'Fracture', 'Future', 'Geometry', 'Goals', 'Gold', 'Health', 'Height', 'Hip Fractures', 'Image', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Modeling', 'Morphology', 'Osteopenia', 'Osteoporosis', 'Osteoporotic', 'Outcome', 'Patients', 'Peripheral', 'Postmenopause', 'Prospective Studies', 'Race', 'Radiation', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Resistance', 'Risk', 'Risk Assessment', 'Risk Factors', 'Scanning', 'Shapes', 'Specimen', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Weight', 'Woman', 'X-Ray Computed Tomography', 'base', 'bone', 'bone geometry', 'bone mass', 'bone strength', 'cohort', 'demographics', 'density', 'diagnosis standard', 'fall risk', 'high risk', 'image processing', 'improved', 'in vivo', 'information model', 'learning strategy', 'men', 'novel', 'osteoporosis with pathological fracture', 'prospective', 'three dimensional structure', 'tool', 'two-dimensional']",NIAMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K99,2016,91800,558628098,0.009055327074050393
"Empiric Testing and enhancement of web-based abstract screening tool(Abstrackr) EMPIRICAL TESTING AND ENHANCEMENT OF WEB-BASED ABSTRACT SCREENING TOOL (ABSTRACKR)  In this year-long project, we aim to empirically assess the performance and efficiency of state-of-the-art information analysis technologies to assist the production of systematic reviews and meta-analyses that are increasingly being used as a foundation for evidence-based medicine and stakeholder-driven comparative effectiveness reviews. We have developed AbstrackrTM (hereon, Abstrackr), a human-guided computerized abstract screening tool that aims to reduce the need to perform a tedious but crucial step of manually screening many thousands of abstracts generated by literature searches in order to retrieve a small fraction potentially relevant for further analysis. Abstrackr makes use of machine learning techniques, and is offered as a free web-based tool that enables management of the screening process.  We also aim to revise the web-interface of Abstrackr to make it more intuitive, user friendly, and add documentation and functionalities requested by users; and to revise Abstrackr’s back-end, which includes the way the software parses and analyses citations, fits machine learning models, and makes computations, to make it more efficient. These revisions will ensure that the tool becomes more robust, and that it remains usable for larger projects and for many teams.  The proposed work will be carried out by the developers of Abstrackr, comprising a highly experienced team of systematic review investigators and computer scientists at Brown University and the University of Texas at Austin, who have been working together for at least seven years. We will pursue dissemination of the findings of this assessment and of the revised tool through numerous channels including, but not limited to publication, presentation at conferences, exploring interest in its wider adoption by the Agency for Healthcare Research and Quality Evidence-based Practice Center Program, Cochrane Collaboration, and other groups conducting systematic reviews. We will also continue to make all code available online. Our aims are to: Aim 1. Empirically measure the efficiency and accuracy of the prediction algorithms in Abstrackr in the computer-assisted semi-automated screening of citations for eligibility in systematic reviews. Aim 2. Improve and add to the functionality of the Web-based Abstrackr software, based in part on enhancements suggested by a panel of identified heavy users. Systematic reviewing is a scientific approach to objectively summarizing the effectiveness and safety of existing treatments for diseases, a prerequisite for informed healthcare decision-making and systematic reviewers must read many thousands of medical study abstracts, the vast majority of which are completely irrelevant to the review at hand. This is hugely laborious and time consuming. We propose to assess the performance and efficiency of a computerized system that automatically excludes a large number of the irrelevant abstracts, thereby accelerating the process and expediting the application of the systematic review findings to patient care, and to augment the functionality of its public implementation.",Empiric Testing and enhancement of web-based abstract screening tool(Abstrackr),9168247,R03HS024812,[' '],AHRQ,BROWN UNIVERSITY,R03,2016,99999,127562714,-0.000717052755650461
"Supporting Systematic Review Production with Article Similarity Network Visualization PROJECT SUMMARY Systematic reviews (SRs), or systematic reviews of literature, summarize evidence drawn from high quality studies, and are often the preferred source of evidence-based practice (EBP). However, conducting an SR is labor-intensive and time consuming, typically requiring several months to complete. It has been reported that more than ten thousands of SRs are needed to synthesize existing medical knowledge. An Article screening process is one of the most intensive and time consuming steps, which requires SR researchers to screen a large amount of references, ranging from hundreds to more than 10,000 articles, depending on the size of a SR. In the past 10 years, machine learning model training approaches24-29 were developed to accelerate the article selection process through automation. However, they are not widely used due to diffusion challenges.7,14 Major obstacles include 1) a training sample is required to generate the automation algorithm. If the training sample is biased, the article selection process will systematically fail; 2) the automation approach is not made available for non-computer science specialists, therefore SR researchers will not be able to “fine-tune” the automation algorithm for particular conditions in various SR topics; 3) As there is no global automation algorithm, the generalizability is significantly limited; 4) It is difficult to assess the actual workload saved, while finding every relevant article is required in SR. We propose a new approach to provide views of article relationships in an article network. This is different from other bibliometric networks constructing citation, co-author, or co-occurrence networks. Article network is a simple and logical concept: visualizing article relationships and distribution based on articles' similarities in titles, abstracts, keywords, publication types, etc. SR researchers can also alter the article distribution by adjusting the similarities. This approach does not aim to suggest an end-point of the screening process. Rather, it provides a view of distribution for included, excluded, and undecided articles. In the proposed research, we will integrate advanced techniques to sparsify article networks with mixed sparsification methods, and improve the quality and efficiency of large network visualization layouts by constructing a multi-level network structure and advanced force model. We aim to provide approaches to sparsify and visualize article networks with more than 10,000 articles. Our approach is highly generalizable that it can be used for any health science topics. By viewing the article distribution, SR researchers will be able to screen a large amount of literature more efficiently. This approach can be integrated into current SR technologies and used directly by SR researchers. The success of this project can support SR production on any health science topics, and thus streamline their ultimate application in EBP paradigms. PROJECT NARRATIVE Systematic reviews (SRs) provide the highest quality of research evidence for patient care. To accelerate the production of SRs, we will implement advanced visualization techniques to view article relationships and distribution with article networks and in a timely and human readable manner. The success of the project will support SR production and thus streamline their ultimate application to evidence-based practice.",Supporting Systematic Review Production with Article Similarity Network Visualization,9227858,R03HS025047,[' '],AHRQ,OHIO STATE UNIVERSITY,R03,2016,100000,241268189,-0.006114314712363797
"Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data DESCRIPTION (provided by applicant): In-hospital cardiac arrest (IHCA) is a significant public health problem, afflicting over 200,000 patients in the United States annually with a mortality rate of approximately 80%. The majority of these patients show signs of clinical deterioration in the hours before the event. This has led to the development of vital sign-based early warning scores designed to detect high-risk patients before IHCA to trigger life-saving interventions. However, the vast majority of these risk scores were created subjectively in individual hospitals and have shown limited accuracy for detecting adverse outcomes. Developing an accurate risk score to detect patients at highest risk of IHCA is essential to decreasing preventable in-hospital death. In my prior work, I completed several studies investigating the accuracy of vital signs for predicting IHCA. These studies, previous literature, and my preliminary data have resulted in the following conclusions: 1) statistically developed risk scores are more accurate than previously published risk scores, 2) multicenter data is needed to create the most accurate and generalizable risk score, 3) additional data, such as laboratory results, will likely improve the accuracy of risk scores, and 4) a cutting-edge method for developing prediction models, called machine learning, may result in more accurate risk scores. Importantly, significant improvement in accuracy leads to better identification of patients at highest risk of IHCA and decreased resource utilization. Therefore, in this grant proposal I aim to develop and validate IHCA prediction models using different statistical techniques in a multicenter database and then estimate the impact of the most accurate risk score using simulation studies. I will do this by firt developing prediction models using classic survival analysis methods (Aim 1a) and machine learning methods, such as neural networks and decision trees (Aim 1b). Then, I will compare the models I develop to the most accurate previously published risk scores in Aim 2. Finally, I will investigate the impact of the most accurate model from Aim 2 on patient outcomes using simulation modeling (Aim 3). Completion of this proposal will result in a validated IHCA risk score that can be implemented in the electronic health record to trigger life- saving interventions to decrease preventable in-hospital death. In addition, this career development award will provide critical data to inform future R01-level awards, including a clinical trial to investigate he impact of the developed prediction model on patient outcomes. I will complete this project under the direct supervision of my mentor (Dr. David Meltzer), co-mentor (Dr. Dana Edelson), and the rest of my advisory team (Drs. Jesse Hall, Robert Gibbons, and Michael Kattan). Together, this multidisciplinary team brings nationally renowned expertise in in-hospital cardiac arrest, outcomes research, critical care, and clinical prediction modeling. In addition, they serve as Chairs of the Section of Hospital Medicine (Dr. Meltzer), Section of Pulmonary and Critical Care (Dr. Hall), and Quantitative Health Sciences at the Cleveland Clinic (Dr. Kattan), and Directors of the Center for Health and the Social Sciences (Dr. Meltzer), Center for Health Statistics (Dr. Gibbons), and Clinical Research for the Emergency Resuscitation Center (Dr. Edelson). The mentorship, expertise, and resources that they provide will ensure my success as I grow into an independent physician-scientist. My career goal is to become an independent critical care outcomes researcher with a focus on developing prediction models for clinical deterioration that will improve patient outcomes. To accomplish this long-term goal, I have three short-term goals: (1) to gain expertise in the development and implementation of clinical prediction models, (2) to create an IHCA prediction model that will identify high-risk patients on the wards to trigger life-saving interventions, and (3) to gain expertise in simulation modeling in order to study the impact of the developed prediction model. To accomplish these goals, I will build upon the foundation I developed when earning my Master's Degree in Public Health and during my initial training in the PhD program in the Department of Health Studies. Although my training to date has provided me with a strong background in epidemiology and biostatistics, further advanced training in biostatistics is crucial for my development into a successful independent researcher. An integrated program of didactic coursework, seminars, research activities, and conference participation will span the duration of the award. By accomplishing my three short- term goals, I will develop unique skills that will allow me to become a successful independent researcher. Specifically, the expertise I will gain in prediction model development, implementation, and simulation modeling can be applied not only to IHCA research but also to other areas of critical care medicine. In addition, completion of these goals will result in a validated IHCA prediction model that I will study in future implementation and cost-effectiveness studies and will serve as a basis for future R01-level grant submissions. PUBLIC HEALTH RELEVANCE: Over 200,000 in-hospital cardiac arrests occur in the United States each year, and studies suggest that many of these events may be preventable if the clinical warning signs can be identified and acted upon quickly. However, the vast majority of tools used to identify patients at high risk of cardiac arrest were created subjectively and have limited accuracy. Development of a statistically derived risk tool is essential to detect at- risk patients accurately and early in order to provide the best opportunity to improve patient outcomes and reduce preventable in-hospital death.",Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data,8984911,K08HL121080,"['Adult', 'Advisory Committees', 'Applications Grants', 'Area', 'Award', 'Biological Neural Networks', 'Biometry', 'Brain', 'Case-Control Studies', 'Categories', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Critical Care', 'Data', 'Data Set', 'Databases', 'Decision Trees', 'Deterioration', 'Development', 'Diastolic blood pressure', 'Doctor of Philosophy', 'Early Diagnosis', 'Electronic Health Record', 'Emergency Situation', 'Ensure', 'Epidemiology', 'Event', 'Foundations', 'Frequencies', 'Future', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Heart Arrest', 'Hospitalization', 'Hospitals', 'Hour', 'Hylobates Genus', 'Individual', 'Intensive Care', 'Intervention', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Life', 'Literature', 'Lung', 'Machine Learning', 'Master&apos', 's Degree', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Outcome', 'Outcomes Research', 'Patient Discharge', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Procedures', 'Public Health', 'Publishing', 'Receiver Operating Characteristics', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Rest', 'Resuscitation', 'Risk', 'Scientist', 'Sensitivity and Specificity', 'Social Sciences', 'Statistical Methods', 'Statistical Models', 'Supervision', 'Survival Analysis', 'Techniques', 'Testing', 'Time', 'Training', 'Uncertainty', 'United States', 'Update', 'Validation', 'Work', 'adverse outcome', 'base', 'career', 'cost effectiveness', 'design', 'evidence base', 'high risk', 'improved', 'learning strategy', 'model development', 'models and simulation', 'mortality', 'multidisciplinary', 'programs', 'simulation', 'skills', 'statistics', 'success', 'symposium', 'tool', 'ward']",NHLBI,UNIVERSITY OF CHICAGO,K08,2016,163944,246330700,-0.01957622304176019
"Improving cancer family history collection through social networking and artificial intelligence PROJECT SUMMARY  The  activities  proposed  in  this  NCI  K07  application  are  designed  to  advance  the  career  development  and  research  independence  of  Dr.  Brandon  M.  Welch.  Family  health  history  (FHx)  is  one  of  the most important  resources available to help clinicians identify disease risks. By knowing a patient's FHx, clinicians can quickly  identify  disease risks and initiate risk-reducing strategies such as increased screening, prophylactic surgery,  risk-reducing  therapeutics,  and  lifestyle  changes.  FHx  is  also  the  foundation  of  genomic  medicine.  Unfortunately,  the  collection  and  use  of  FHx  by  patients  and  clinicians  is  suboptimal.  To  improve  the  collection and use of FHx among the general population, a better FHx tool that is easier and more convenient  to  use  than  current  FHx  tools  is  needed.  A  new  FHx  web  tool,  called  ​ItRunsInMyFamily.com,​  incorporates  artificial intelligence and social networking to improve user engagement with FHx collection.Utilizing artificial  intelligence  based  chat  entity  can  improve  the  collection  of  FHx  information  by  making  it  easier  and  more  engaging to record FHx information, likewise social networking allows users to tap into the collective wisdom  and  knowledge  of  the  family  to  correct  inaccuracies  and  overcome  gaps  in  FHx  knowledge.  This research  study  will  first  identify  enhancements  to  ​ItRunsInMyFamily.com  ​that  will  further  promote  user  engagement,  with  particular  focus  on  rural and underserved patients (Aim 1). We will then evaluate whether this new FHx  tool can improve collection of cancer FHx in comparison with current FHx tools (Aim 2). Finally, we will assess  the impact of ​ItRunsInMyFamily.com ​on the clinical settings (Aim 3). To implement the research plan, it will be  critical  to  apply,  skills  obtained  through  K  award  learning  objectives,  namely  clinical  oncology  (learning  objective  1),  iterative  patient-centered  design  (learning  objective  2),  and  health  technology  assessment  (learning  objective  3).  To  fulfill  these  learning  objectives,  an  interdisciplinary  group  of  mentors  will  direct  a  comprehensive training plan. The training plan includes coursework, seminars, workshops, journal clubs, and  conferences,  covering clinical oncology, patient engagement, health disparities, user-centered development,  human-computer  interaction,  clinical  research  methodologies,  health  technology  assessment,  and  ethical  conduct  of  research.  The  strong  support  of  an  excellent  team  of  mentors,  and  the  vast  resources  of  the  Medical  University  of  South  Carolina,  create  an  optimal  training  environment.  Collectively,  the  integrated  learning  objectives  and  research  plan  are  critical  to  establishing  a  successful,  innovative,  and  meaningful  academic career focused on developing patient-centric informatics tools for oncology.   PROJECT NARRATIVE Family health history (FHx) is one of the most important risk factors for cancer and the foundation of genomic medicine, but is under-utilized by patients and clinicians. By incorporating artificial intelligence and social networking into a FHx tool, it will lead to greater engagement with FHx collection. This research study will identify and incorporate features that promote user adoption, and evaluate its impact on FHx collection.  ",Improving cancer family history collection through social networking and artificial intelligence,9222377,K07CA211786,"['Adoption', 'Applied Skills', 'Area', 'Artificial Intelligence', 'Breast Cancer Patient', 'Cellular Phone', 'Client satisfaction', 'Clinical', 'Clinical Oncology', 'Clinical Research', 'Collection', 'Data', 'Development', 'Educational workshop', 'Environment', 'Ethics', 'Family', 'Family Cancer History', 'Family health status', 'Foundations', 'General Population', 'Genetic screening method', 'Genomic medicine', 'Goals', 'Health Technology', 'Human', 'Informatics', 'Internet', 'Journals', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Learning', 'Life', 'Malignant Neoplasms', 'Measures', 'Medical', 'Mentors', 'Methodology', 'Minority', 'Operative Surgical Procedures', 'Outcome', 'Patient Care', 'Patients', 'Provider', 'Qualitative Research', 'Randomized Controlled Trials', 'Recording of previous events', 'Reporting', 'Research', 'Research Methodology', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Rural', 'Rural Population', 'Social Network', 'South Carolina', 'Staging', 'Technology Assessment', 'Time', 'Training', 'Underserved Population', 'Universities', 'Workload', 'base', 'cancer risk', 'career', 'career development', 'clinical care', 'computer human interaction', 'design', 'disorder risk', 'health disparity', 'improved', 'innovation', 'next generation', 'oncology', 'patient oriented', 'personalized cancer care', 'prevent', 'prophylactic', 'research and development', 'research study', 'satisfaction', 'screening', 'symposium', 'therapeutic lifestyle change', 'tool', 'user centered design']",NCI,MEDICAL UNIVERSITY OF SOUTH CAROLINA,K07,2016,173453,136810522,-0.0013209338302383627
"Preventable Hospitalization in Dementia: The Impact of Neuropsychiatric Symptoms DESCRIPTION (provided by applicant): Older adults with dementia are at increased risk of hospitalization when compared to adults without dementia of similar age and medical comorbidity. The increased risk of hospitalization extends to potentially preventable hospitalization (PPH) for conditions such as a urinary tract infection or asthma exacerbation, suggesting difficulty in outpatient management of patients with dementia. Neuropsychiatric symptoms (NPS) of dementia such as agitation or delusions likely account for a significant amount of this risk, given their prevalence and potential to cause caregiver distress. While there are effective interventions for patients and caregivers to reduce NPS, the profile of patients that could benefit the most from intervention, therefore reducing their hospitalization risk, is unknown. Through the coordinated program of mentorship, didactics, and research that I propose, I will develop the advanced skills to derive and apply administrative, claims, and clinical encounter data to prospectively identify those patients with dementia at highest risk for hospitalization. Development of this patient-level risk phenotype means that future interventions to reduce hospitalization can then be prospectively matched to the patients most likely to benefit, a development of critical public health importance given both financial and geriatric work force constraints.  Over the next four years, my short-term training goals include: (1) address gaps in my formal research training, specifically: (a) to conduct observational analyses using large-scale claims and administrative data; (b) to derive clinical data from the electronic health record using natural language processing; and (c) to apply advanced methods of data analysis for risk prediction; (2) train in presentations, manuscript writing, and grantsmanship that culminate with a R01 proposal; (3) establish further connections with potential collaborators in the University of Michigan (UM) Pepper Center and broader community of aging researchers, national geriatrics and geriatric psychiatry communities, and the Beeson Scholar community; and (4) engage in leadership development with an emphasis on skills to lead a research team, mentor junior investigators, and communicate findings in research and clinical care settings.  These short-term goals will be paired with research aims that focus on elaborating the PPH risk profile for patients with dementia. Such research objectives can only be achieved when: (1) full clinical characteristics are available for the at-risk (i.e., non-hospitalized) population, includig (2) NPS data, which are rarely captured in standard administrative claims data. These criteria are uniquely met in the Veterans Affairs healthcare system, which has one of the nation's most advanced electronic health records (EHR). Using a national dementia case repository (N=269,565) from which I will draw matched cases (patients with dementia + PPH) and controls (non-hospitalized patients with dementia). Aim 1 will use claims and administrative data to explore patient, treatment, and facility risk factors associated with PPH. Aim 2 will use natural language processing to derive NPS from EHR clinical encounter notes and then characterize the association of NPS with PPH. Using the risk phenotype described in Aims 1 and 2, Aim 3 will develop logistic risk-prediction models to prospectively identify patients with dementia at highest risk for PPH. In subsequent grant proposals I will validate this risk- prediction model in other healthcare systems and prospectively pair the assessment tool with an evidence- based dementia intervention to reduce hospitalization.  My long-term career goals are to: (1) establish myself as independent investigator and national leader in geriatric mental health services research; (2) develop a programmatic line of funded health services research that develops risk-stratification models for late-life mental health and cognitive disorders; (3) translate knowledge from these research endeavors to improve the targeting and impact of future interventions research and health system delivery strategies; and (4) contribute broadly to the care of older adults by training and mentoring future clinical researchers in late-life mental health disorders. I am an Assistant Professor and geriatric psychiatrist at the University of Michigan, where I am also currently completing a MSc in Health and Healthcare Research, which provides an excellent background in health services research for clinicians. With this combination of clinical expertise and foundational training in health services research, I am uniquely qualified to undertake the advanced training activities outlined in this proposal, while UM affords the ideal environment in which to pursue this work. My primary mentor (Helen Kales, MD) and co-mentor (Frederic Blow, PhD) are national leaders in geriatric mental health who have used observational data to answer questions of national significance. My Advisory Panel includes Constantine Lyketsos, MD, MHS, an internationally-recognized expert in NPS and dementia care, and Kenneth Langa, MD, PhD, an internist, former Beeson Scholar, and renowned expert in using survey and secondary data to inform our understanding of dementia. Consultants include David Hanauer, MD, MS, an expert in bioinformatics and natural language processing, and Rodney Hayward, MD, a leader in risk assessment and intervention- targeting. My advisory team paired with resources of Michigan's Pepper Center, CTSA, and multi-disciplinary Institute for Healthcare Policy and Innovation make this the ideal environment in which to complete the proposed training activities. PUBLIC HEALTH RELEVANCE: Although hospitalization can negatively impact patients with dementia, we know very little about the specific risk factors associated with the chance of being hospitalized. It is important to understand what contributes to this risk, such as the behavior changes that accompany dementia, in order to identify those patients and caregivers that could benefit most from an intervention to avoid or reduce hospitalization. Given the rapidly rising numbers of patients with dementia, reducing potentially preventable hospitalization could have an enormous impact on public health.",Preventable Hospitalization in Dementia: The Impact of Neuropsychiatric Symptoms,9084484,K08AG048321,"['Accounting', 'Address', 'Adult', 'Advisory Committees', 'Age', 'Aggressive behavior', 'Aging', 'Agitation', 'Antipsychotic Agents', 'Applications Grants', 'Assessment tool', 'Asthma', 'Attention', 'Benzodiazepines', 'Bioinformatics', 'Capsicum', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Code', 'Cognition Disorders', 'Communities', 'Comorbidity', 'Data', 'Data Analyses', 'Delusions', 'Dementia', 'Development', 'Diagnosis', 'Distress', 'Doctor of Philosophy', 'Elderly', 'Electronic Health Record', 'Emergency Care', 'Environment', 'Foundations', 'Funding', 'Future', 'Geriatric Psychiatry', 'Geriatrics', 'Goals', 'Health', 'Health Care Research', 'Health Policy', 'Health Services Research', 'Health system', 'Healthcare Systems', 'Hospitalization', 'Individual', 'Institutes', 'Institutionalization', 'Internist', 'Intervention', 'Intervention Studies', 'Intervention Trial', 'Kale - dietary', 'Knowledge', 'Lead', 'Light', 'Literature', 'Location', 'Logistic Regressions', 'Logistics', 'Manuscripts', 'Medical', 'Mental Health', 'Mental Health Services', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Natural Language Processing', 'Outpatients', 'Patient Care', 'Patient risk', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Prevalence', 'Primary Health Care', 'Provider', 'Psychiatrist', 'Psychotic Disorders', 'Public Health', 'Qualifying', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Rural', 'Signal Transduction', 'Sleeplessness', 'Source', 'Stratification', 'Surveys', 'Symptoms', 'Training', 'Training Activity', 'Translating', 'Universities', 'Urinary tract infection', 'Validation', 'Veterans', 'Visit', 'Work', 'Writing', 'abstracting', 'behavior change', 'career', 'case control', 'clinical care', 'dementia care', 'design', 'effective intervention', 'evidence base', 'geriatric mental health', 'high risk', 'improved', 'innovation', 'leadership development', 'medication compliance', 'meetings', 'neuropsychiatric symptom', 'patient population', 'predictive modeling', 'professor', 'profiles in patients', 'programs', 'repository', 'skills', 'statistics', 'tool']",NIA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K08,2016,175103,641965656,-0.018233232462568888
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing. PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8998947,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'improved outcome', 'neovascular', 'novel', 'programs', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2016,180061,807432003,-0.012968159131565857
"Machine learning with generative mixture models for fetal monitoring DESCRIPTION (provided by applicant): For many years, there has been a concerted effort to automate the analysis of fetal heart rate (FHR) rhythms. However, despite significant advances in biomedical signal analysis, there has not been any significant improvement in automated decision support systems. FHR monitoring is now ubiquitous throughout delivery rooms, especially using the non-invasive Doppler monitor, but also using the fetal scalp electrode. Physician classification of fetal heart rate patterns is known to be a non-trivial problem because of significant inter and intra-observer variability of diagnosis. This has led to a marked increase in the number of caesarean deliveries, thereby increasing risk to the fetus and mother in many cases. This has further motivated the machine learning community to automate the classification procedure in the interest of accuracy and consistency as well as robustness with respect to noise. Usual approaches to this involve some type of supervised classification procedure, where the algorithm output on training data is compared with a ""gold-standard"" physician classification, followed by testing and validation on new datasets. However, since physician classification can be unreliable in the presence of the aforementioned diagnostic variability, as well as significant tracing noise, we propose the use of unsupervised algorithms to cluster FHR data records into clinically useful categories. We use nonparametric Bayes theory and Markov-time-dependence models for the evolution of feature sequences to propose methods that will achieve improved accuracy. The methods involve extraction of feature sequences from FHR time series data, which are modeled as samples from finite or infinite Dirichlet mixture models. We then use Gibbs sampling to obtain the cluster probabilities for each dataset. Clustering outcomes are compared against direct physician diagnosis and our current results are seen to be in broad agreement with them, while still giving new information on the character of different sub-groups of FHR records. With the proposed research, further gains in classification performance will be made. PUBLIC HEALTH RELEVANCE: Fetal heart rate monitoring is now commonly used during childbirth and, at present, physicians read and interpret these data to classify fetal heart rate patterns and make sure that the baby is not in distress during the course of labor. However, there is great variability in how individual doctors interpret the tracings and this has led increases in the number of caesarean deliveries, thereby potentially increasing risk to both mothers and babies. Thus there has been a concerted effort from the machine learning community to develop an accurate automatic reading and classification procedure so that correct interpretation of fetal heart rates during labor is more diagnostic and consistent.",Machine learning with generative mixture models for fetal monitoring,9018050,R21HD080025,"['Agreement', 'Algorithms', 'Apgar Score', 'Bayesian Method', 'Behavioral', 'Birth', 'Categories', 'Cesarean section', 'Childbirth', 'Classification', 'Clinical', 'Consensus', 'Data', 'Data Set', 'Decision Support Systems', 'Delivery Rooms', 'Dependence', 'Dependency', 'Diagnosis', 'Diagnostic', 'Distress', 'Electrodes', 'Evolution', 'Feedback', 'Fetal Heart', 'Fetal Heart Rate', 'Fetal Monitoring', 'Fetus', 'Freedom', 'Gold', 'Health', 'Individual', 'Intraobserver Variability', 'Joints', 'Knowledge', 'Label', 'Learning', 'Litigation', 'Machine Learning', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Monte Carlo Method', 'Mothers', 'Motivation', 'Noise', 'Outcome', 'Outcome Measure', 'Output', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Probability', 'Procedures', 'Process', 'Reading', 'Records', 'Research', 'Risk', 'Sampling', 'Scalp structure', 'Series', 'Signal Transduction', 'System', 'Testing', 'Time', 'Training', 'Umbilical cord structure', 'Uncertainty', 'Uterine Contraction', 'Validation', 'Work', 'base', 'cost', 'fetal', 'heart rate monitor', 'improved', 'interest', 'learning community', 'pressure', 'stem', 'theories', 'vector']",NICHD,STATE UNIVERSITY NEW YORK STONY BROOK,R21,2016,193120,77607041,-0.002039926777487037
"Calculation of Percent Body Fat by Analyzing Virtual Body Models ﻿    DESCRIPTION (provided by applicant):  Excess body fat is a key underlying factor in the development of numerous chronic diseases, including type II diabetes, heart disease, stroke, and cancer. The AMA recently declared that obesity, itself, is a disease. Most epidemiologic studies utilize Body Mass Index (BMI) to classify people as underweight, normal, overweight, or obese because it is a convenient and simple method that has been shown to correlate with disease risk. Since the majority of the health risks associated with obesity are more directly linked to an overabundance of body fat than weight, measuring body fat is essential for more precise guidelines. However, accurate methods of assessing body fat are expensive, inconvenient, and require immobile equipment. Consequently, the AMA has called for more cost effective and convenient methods to assess body composition to assist doctors in their assessment and treatment. Virtual modeling of humans in particular has provided ways to scan and analyze the body and its motion. Supervised Machine Learning (SML), a sub-field of artificial intelligence, has made great progress in taking measured data to infer new relationships. It is our belief that virtual modeling and SML can provide the techniques necessary to conveniently and accurately calculate the percentage of body fat (%BF) and to provide new tools in treating obesity based on body shapes. The project will develop a system that uses commercially available depth cameras such as the Microsoft Kinect(r) to capture the surface of the human body. This will be accomplished by developing a new algorithm to perform deformable registration of several RGB-Depth views of the body. A new algorithm that uses SML will be developed to calculate percentage body fat using the surface data. The system will be trained and validated by collecting data from a number of subjects. The surface captured will be used to explore the role of visual body representation in motivation and adherence. The developed systems can be implemented in clinical or personal settings and be utilized as a public health research tool and deployed widely given the low-cost of the hardware required. In addition to the immediate impact that the system will have on managing obesity, the project will have a broad impact on a number of areas. A large database of such shapes captured over time may lead to ways to predict how an individual's body shape will change given a particular intervention. Certain medical conditions that result in body shape change, such as those involving lymphatic circulations, may be diagnosed and tracked more easily. Growth patterns of children may be tracked by change of body shapes. Further research can be conducted to determine the effect of body shape on %BF using data mining techniques. PUBLIC HEALTH RELEVANCE: The project will develop a new method to capture the 3D surface and shape of a human body and a new method to use these data to calculate percent body fat. By making these tools widely available and economical, the proposed approach has the potential for major contributions in the assessment and treatment of obesity.",Calculation of Percent Body Fat by Analyzing Virtual Body Models,9099872,R21HL124443,"['Adherence', 'Age', 'Air', 'Algorithms', 'Area', 'Artificial Intelligence', 'Behavior Therapy', 'Belief', 'Body Composition', 'Body Size', 'Body Surface', 'Body Weight decreased', 'Body fat', 'Body mass index', 'Child', 'Chronic Disease', 'Client', 'Clinical', 'Clinical Research', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Epidemiologic Studies', 'Equipment', 'Fatty acid glycerol esters', 'Future', 'Goals', 'Growth', 'Guidelines', 'Health', 'Health Care Costs', 'Heart Diseases', 'Human', 'Human body', 'Imagery', 'Incentives', 'Individual', 'Intervention', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Motivation', 'Muscle', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Overweight', 'Participant', 'Patients', 'Pattern', 'Perception', 'Plethysmography', 'Public Health', 'Reporting', 'Research', 'Risk', 'Role', 'Scanning', 'Self Perception', 'Series', 'Shapes', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Underweight', 'Variant', 'Visual', 'Water', 'Weight', 'Weights and Measures', 'base', 'body density', 'body volume', 'cost', 'cost effective', 'data mining', 'density', 'disorder risk', 'lymphatic circulation', 'novel', 'novel strategies', 'obesity treatment', 'preference', 'public health research', 'reconstruction', 'sex', 'study population', 'tool', 'virtual', 'weight loss intervention']",NHLBI,GEORGE WASHINGTON UNIVERSITY,R21,2016,194340,86807134,0.009916107016058709
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9147611,K01ES026833,"['Affect', 'Blood', 'Blood flow', 'Brain', 'Brain Injuries', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Health', 'Healthcare', 'Hemorrhage', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Rupture', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'standard of care', 'support tools', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2016,216241,558628098,-0.025432610564921375
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9050682,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2016,339750,193405667,-0.0043559064542817594
"Using Meta-level Smartphone Data to Promote Early Intervention inSchizophrenia Project Summary ""Using Meta-level Smartphone Data to Promote Early Intervention in Schizophrenia”  Schizophrenia is one of the most debilitating disorders in the world today. It affects over 2.4 million adult Americans each year. NIMH director Dr. Thomas Insel has declared “The best chance for preventing serious functional disability among people with schizophrenia may be to intervene at the earliest stages of the disorder, at the first episode of psychosis or even before symptoms appear. However, to act before symptoms appear requires improved predictive capacity” (NIMH 2011 Budget). Creating tools to identify high-risk, `prodromal' individuals may be the single most important step towards developing effective interventions to reduce the duration of untreated psychosis (DUP), and thereby also reduce the morbidity and mortality associated with schizophrenia. Recent studies have shown that over 54% of individuals with schizophrenia are re-hospitalized within the first 12 months following their initial hospitalization. Even after the first hospitalization, preventing relapse and re-hospitalization may lessen the long-term severity of the illness. In this SBIR Phase I study, we propose to determine the feasibility of screening for prodromal individuals and individuals at high risk of relapse by applying interpretive algorithms to Passively Gathered Meta-level Smartphone Data (PGMSD). We hypothesize that PGMSD can effectively assist in screening for prodromal individuals who are progressing toward psychosis as well as for remotely assessing individuals at risk for relapse during the critical 12-month period following their first episode of psychosis (FEP).  In Phase I, we plan to recruit 70 individuals who have been or are being evaluated at the Prodromal clinics at Columbia, UCSD, and UCLA, where an estimated 70 to 90% of clients already own Smartphones. Data gathered may include: the frequency of telephone calls, emails, and texts, to assess within person changes in social connectedness; GPS, accelerometer data, to assess physical activity, isolation, and sleep patterns. In the past, several IRB-approved studies have used smartphones for gathering similar data from patients. Algorithms will be developed using several techniques including machine learning to convert the meta-level data into measures of social functioning, physical isolation, physical activity, and sleep/wake reversals. In addition to achieving technological success, our goal in Phase I is to provide evidence of our ability to use PGMSD algorithms to differentiating group means of participants who are controls, prodromal, or experiencing their FEP (SIPS 1 or 2; 3, 4, or 5; or 6).  In Phase II, we will further develop and validate these algorithms. If successful, the Phase II project will have a large and sustained impact as our algorithms will help (1) identify at-risk individuals who `are' or `are not' progressing toward conversion, (2) serve as an objective measure of treatment effectiveness; (3) give rise to clinical reports delivered to EHR systems that hold promise for preventing relapse during the critical 12 months after initial diagnosis, potentially reducing hospitalization and re-hospitalization rates. Project Narrative The proposed research protocol seeks to determine the feasibility of identifying individuals progressing toward a first psychotic episode or re-hospitalization by applying interpretive algorithms developed in part using machine learning to Passively Gathered Meta-level Smartphone Data (PGMSD) collected from the smartphones of 70 participants ages 18-30. If successful, the PGMSD-derived algorithms will assist in screening for prodromal individuals progressing toward psychosis as well as with remotely assessing individuals at risk for relapse during the critical 12-month period following their first episode of psychosis (FEP), potentially decrease hospitalization and re-hospitalization rates. This passive data gathering approach will augment existing active data collection approaches, aid clinicians in focusing on interpreting rather than gathering data from their clients, and could modify clinical paradigms by shifting treatment from individuals suffering from Schizophrenia to individuals who are at risk of developing psychosis with the goal of achieving `secondary' and eventually `primary' prevention.",Using Meta-level Smartphone Data to Promote Early Intervention inSchizophrenia,9201713,R43MH107097,"['Accelerometer', 'Adult', 'Affect', 'Age', 'Algorithms', 'American', 'Aphasia', 'Area', 'Behavior', 'Budgets', 'Cellular Phone', 'Client', 'Clinic', 'Clinical', 'Collection', 'Data', 'Data Collection', 'Databases', 'Diagnosis', 'Diagnostic and Statistical Manual of Mental Disorders', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Electronic Mail', 'Frequencies', 'Goals', 'Hospitalization', 'Impairment', 'Incipient Schizophrenia', 'Individual', 'Institutional Review Boards', 'Interview', 'Machine Learning', 'Measurement', 'Measures', 'Morbidity - disease rate', 'National Institute of Mental Health', 'Occupational', 'Participant', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Phase', 'Physical activity', 'Poverty', 'Primary Prevention', 'Privacy', 'Process', 'Protocols documentation', 'Psychotic Disorders', 'Recruitment Activity', 'Relapse', 'Reporting', 'Research', 'Resources', 'Risk', 'Role', 'Schizophrenia', 'Secondary Prevention', 'Series', 'Severity of illness', 'Signs and Symptoms', 'Sleep', 'Small Business Innovation Research Grant', 'Social Functioning', 'Speech', 'Staging', 'Structure', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Telephone', 'Text', 'Therapeutic', 'Thinking', 'Treatment Effectiveness', 'Universities', 'Work', 'effective intervention', 'experience', 'first episode psychosis', 'functional disability', 'functional status', 'high risk', 'improved', 'individualized medicine', 'information gathering', 'insight', 'mortality', 'outcome forecast', 'personalized medicine', 'phase 1 study', 'phase 2 study', 'prevent', 'programs', 'real world application', 'relapse risk', 'screening', 'social', 'success', 'tool', 'treatment strategy']",NIMH,"TELESAGE, INC.",R43,2016,366201,0,-0.005365825683213023
"Antecedent Medical Conditions and Medications: Associations with the Risk and Prognosis ALS ﻿    DESCRIPTION (provided by applicant): ALS affects people in middle to late ages, during a time of life where it is common to suffer from more than one health problem, yet there is little understanding of the effect of chronic medical conditions and medication use on susceptibility to ALS. There is mounting concern and recent evidence that certain medical conditions and medications are associated with an increased risk of developing ALS, while other conditions and medications appear to be inversely associated with ALS risk. We propose to investigate the role of hyperlipidemia, diabetes, autoimmune diseases, as well as the drugs used to treat these disorders, as both risk and prognostic factors for ALS. This study has three specific aims: Aim 1, to investigate the association between antecedent medical conditions and the risk of developing ALS; Aim 2, to examine the relationship between certain classes of medication and the risk of developing ALS; and Aim 3, to determine whether medical conditions or medications present at diagnosis of ALS adversely or positively affect survival with ALS. We will assemble a retrospective cohort of Medicare beneficiaries who were continuously enrolled in fee-for-service Medicare (Parts A, B and D) during the years 2006 through 2014. To address aims 1 and 2, we will conduct a nested case-control study to identify newly diagnosed (incident) patients with ALS in this cohort between 2008 and 2014 using a modified version of the case definition algorithm used by the National ALS Registry. We expect to identify 11,000 incident ALS cases. Using incidence density sampling, ten age- and sex-matched controls will be randomly chosen for each case from among Medicare beneficiaries who entered the Medicare cohort in the same year as the case, but had who had no codes for ALS, MND or closely related conditions prior to their matched cases' diagnosis dates. We will use Medicare inpatient, outpatient, and laboratory health claims to document the occurrence of metabolic, cardiovascular, and autoimmune conditions among the study subjects both before and after the diagnosis of ALS. The availability of Part D (pharmaceutical) claims for Medicare beneficiaries from 2006 onward will provide the opportunity to examine the association of commonly used medications with the risk and prognosis of ALS. We will use conditional logistic regression analyses to identify premorbid medical conditions and medications associated with the risk of developing ALS. To address specific aim 3, we will link the data from our incident ALS case group to mortality data and conduct survival analyses to determine whether antecedent medical conditions and medications present at diagnosis are associated with either shortened or prolonged survival with ALS. We will use survival analysis to determine whether there is an association between these conditions/medications and survival with ALS. This study will contribute significantly to the understanding of the role that metabolic factors, hyperlipidemia, cardiovascular disease and autoimmunity play in the etiology and prognosis of ALS, and could lead to the development of new preventive or therapeutic interventions to prolong survival in ALS patients. PUBLIC HEALTH RELEVANCE: Amyotrophic lateral sclerosis (ALS: also known as Lou Gehrig's disease) is an adult-onset neuromuscular disorder that is the third most common neurodegenerative disease of aging (after Alzheimer's and Parkinson's diseases). It is critically important to identify modifiable risk factors present prior to diagnosis that affect the risk of developing ALS, and to also identify factors that are associated with the length of survival with this uniformly fatal disease. We hope that this study will identify modifiable risk factors that pu people at risk for ALS so that we can prevent this disabling disease, and we believe that studying the factors that influence length of survival with ALS will lead to the development of new preventive or therapeutic interventions to prolong survival among patients with ALS.",Antecedent Medical Conditions and Medications: Associations with the Risk and Prognosis ALS,9143771,R01TS000249,[' '],ATSDR,STANFORD UNIVERSITY,R01,2016,400000,560644462,-0.008223663954817712
"Developing Classification Criteria for the Uveitides ﻿    DESCRIPTION (provided by applicant): The uveitides are a collection of ~30 distinct diseases characterized by intraocular infection. Each disease has its own features, course, treatment, and prognosis. Traditionally, the uveitides have been grouped by the primary anatomic site of inflammation as anterior uveitis, intermediate uveitis, posterior uveitis, and panuveitis. However, there are substantial limitations to this ""lumping"" of diseases. For example, among the posterior uveitides, some (e.g. toxoplasmic retinitis and cytomegalovirus retinitis) are infectious and require treatment with antimicrobial/antiviral agents, some are chronic, presumed immune-mediated diseases that require immunosuppression (e.g. birdshot chorioretinitis, multifocal choroiditis, serpiginous choroiditis), and a few are self-limited, spontaneously-remitting diseases with a good prognosis (e.g. acute posterior multifocal placoid pigment epitheliopathy and multiple evanescent white dot syndrome). As such precise diagnosis is critical for research, including epidemiology, translational pathogenesis research, outcomes research, and disease specific clinical trials. Classification criteria are a type of ""diagnostic"" criteria used for reserch purposes. Although classification criteria seek to optimize sensitivity and specificity, when a trade-off is required, they emphasize specificity in order to ensure that a homogeneous group of patients is being studied. A precise phenotype is required particularly for genomic risk factor studies of complex disorders and translational pathogenesis research, as inclusion of other diseases with different risk factors and disease mechanisms would confound the results. Currently there are no widely-accepted and validated classification criteria for any of the uveitides. Preliminary data indicate ""fair to moderate"" agreement at best on the independent diagnosis of any one case by uveitis experts (κ's 0.27-0.40), but the ability of committees to reach agreement on the diagnosis of >98% of cases. The goal of the ""Developing Classification Criteria for the Uveitides"" project is for the Standardization of Uveitis Nomenclature (SUN) Working Group to develop classification criteria for the 25 leading uveitides using a formal, rigorous approach. There are 4 phases to the project: 1) informatics, to develop a standardized terminology; 2) case collection, to develop a preliminary database of ~250 cases of each disease; 3) case selection, to select at least 150-200 cases of each disease that are generally accepted to be the disease (using formal consensus techniques) from the preliminary database into a final database; and 4) data analysis, using machine learning approaches, of the final database to develop a parsimonious set of criteria for each disease that minimizes misclassification. The informatics and case collection phases of the Project are complete. The case selection phase is well underway and uses online voting and consensus conference calls to achieve supermajority acceptance on all cases included in the final database. The goals of this application are to complete case selection and data analysis and develop classification criteria for the 25 of the major uveitides. These results are crucial to future clinical research i the field of uveitis.         PUBLIC HEALTH RELEVANCE:  Collectively, the uveitides are the 5th leading cause of blindness in the U.S., and the cost of treating them is estimated to be similar to that of treating diabetic retinopathy. Because uveitis occurs in all age groups, including children and working-age adults, there is a greater potential for years of vision lost than with age- related diseases. Clinical research in the field of uveitis has been hampered by diagnostic imprecision and a lack of widely-accepted and validated classification criteria, the development of which is the goal of this application; these criteria are needed urgently to advance epidemiology, genomic research, translational pathogenesis research, outcomes research, and disease-specific clinical trials.            ",Developing Classification Criteria for the Uveitides,9081760,R01EY026593,"['Acute', 'Adult', 'Affect', 'Age', 'Agreement', 'Anatomy', 'Anterior uveitis', 'Antiviral Agents', 'Blindness', 'Child', 'Choroiditis', 'Chronic', 'Classification', 'Clinical Research', 'Clinical Trials', 'Collection', 'Complex', 'Consensus', 'Cytomegalovirus Retinitis', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Enrollment', 'Ensure', 'Epidemiology', 'Future', 'Genomics', 'Goals', 'Immune', 'Immunosuppression', 'Infection', 'Inflammation', 'Informatics', 'Intermediate Uveitis', 'Machine Learning', 'Mediating', 'Nomenclature', 'Outcomes Research', 'Panuveitis', 'Pathogenesis', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Pigments', 'Population', 'Posterior Uveitis', 'Publications', 'Research', 'Retinitis', 'Risk Factors', 'Sensitivity and Specificity', 'Specificity', 'Standardization', 'Syndrome', 'Techniques', 'Terminology', 'Translational Research', 'United States', 'Uveitis', 'Vision', 'Visual impairment', 'Voting', 'Work', 'age group', 'age related', 'antimicrobial', 'birdshot chorioretinitis', 'cost', 'outcome forecast', 'public health relevance', 'symposium', 'tool', 'web page', 'working group']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2016,428590,415711940,-0.0021712629364851704
"Predicting Diabetic Retinopathy from Risk Factor Data and Digital Retinal Images Abstract Diabetic retinopathy is the leading cause of blindness among US adults between the ages of 20 and 74 years. Laser photocoagulation surgery has been established as an effective way of treating retinopathy if it is detected early. Yearly retinal screening examinations are a potent tool in the battle to reduce the incidence of blindness from diabetic retinopathy because they provide diabetic patients with timely diagnoses and consequently, the potential for timely treatment. Primary care safety net clinics provide monitoring and other services for diabetic patients but they are often not equipped to provide specialty care services such as retinal screenings. Access to specialists who can provide retinal screenings can be increased through the use of telemedicine, which has shown great promise as a means of screening for diabetic retinopathy in the US and internationally. A pilot study by Charles Drew University investigators had a total of 2,876 teleretinal screenings performed for diabetic retinopathy, with 2,732 unique diabetic patients from six South Los Angeles safety net clinics screened. The present study aims to build on this prior work by: (a) developing novel software that utilizes information from clinical records to detect latent diabetic retinopathy in diabetic patients who have not yet received an annual eye examination, and (b) devising methods to speed up the diabetic retinopathy detection process for diabetic patients who have had digital retinal images taken by partially automating the process using image processing and machine learning techniques. Specifically, we propose to: 1. Develop predictive models for diabetic retinopathy using risk factors collected from patient clinical records. 2. Develop predictive models for automated diabetic retinopathy assessment using a combination of patient  risk factor data and data from digital retinal images previously evaluated by experts. 3. Evaluate the predictive accuracy of: a) the models developed for specific aim 2, and, b) the assessments of  optometrist readers against standard of care dilated retinal examinations by board certified  ophthalmologists for 300 diabetic patients utilizing a new Los Angeles County reading center. 4. Create web-based software tools based on the predictive models developed in specific aim 1 that can be  used to initiate outreach to high-risk patients in under-resourced settings, boosting detection rates for those  patients who are most at risk for diabetic retinopathy. 5. Establish targeted outreach methods to promote screening for patients that the predictive models from  specific aim 1 identify as potentially having undetected diabetic retinopathy. Narrative Diabetic retinopathy is the leading cause of blindness among US adults between the ages of 20 and 74 years. Although previous studies within the US and internationally have shown that teleretinal screening can increase access to eye examinations for detecting retinopathy, few studies have focused on the US urban safety net, which has ophthalmic screening rates that are well below the US average and a preponderance of diabetic patients who are from ethnic minority groups. Building on a previous teleretinal screening study that assessed 2,732 South Los Angeles patients for retinopathy, this study deploys machine learning and image processing techniques to detect latent retinopathy in unscreened diabetic patients and partially automate the diabetic retinopathy detection process for teleretinal screening.",Predicting Diabetic Retinopathy from Risk Factor Data and Digital Retinal Images,9236094,R01LM012309,"['Address', 'Adult', 'Affect', 'Age', 'Alaska Native', 'American Indians', 'Asian Americans', 'Blindness', 'Blood Circulation', 'Blood Vessels', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Clinic', 'Clinical', 'Complications of Diabetes Mellitus', 'Computer software', 'County', 'Data', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Eye', 'Glucose', 'Health Care Reform', 'Health Insurance', 'Hispanics', 'Image', 'Incidence', 'Los Angeles', 'Machine Learning', 'Methods', 'Minority Groups', 'Modeling', 'Monitor', 'Not Hispanic or Latino', 'Online Systems', 'Operative Surgical Procedures', 'Ophthalmic examination and evaluation', 'Ophthalmologist', 'Optometrist', 'Patient risk', 'Patients', 'Pilot Projects', 'Population', 'Primary Health Care', 'Process', 'Publishing', 'Reader', 'Reading', 'Records', 'Reporting', 'Research Personnel', 'Retina', 'Retinal', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Rural', 'Services', 'Software Tools', 'Specialist', 'Speed', 'Techniques', 'Telemedicine', 'United States', 'Universities', 'Work', 'abstracting', 'aged', 'base', 'diabetic', 'diabetic patient', 'digital', 'digital imaging', 'disorder prevention', 'ethnic minority population', 'high risk', 'image processing', 'inner city', 'laser photocoagulation', 'medical specialties', 'medically underserved', 'mortality', 'novel', 'outreach', 'predictive modeling', 'primary care setting', 'racial minority', 'randomized trial', 'safety net', 'screening', 'standard of care', 'statistics', 'tool', 'transmission process', 'trend']",NLM,CHARLES R. DREW UNIVERSITY OF MED & SCI,R01,2016,449167,7479461,-0.0189190293103413
"Geometric Surrogates for Clinical Management of Abdominal Aortic Aneurysms ﻿    DESCRIPTION (provided by applicant): This proposal will investigate the following hypothesis: that the quantification of geometric surrogates, which predict the ensuing peak wall rupture risk index (PWRRI), will provide an improved estimate of aneurysm rupture risk compared to the clinical standard of maximum aneurysm diameter. We thus propose the highly innovative use of both radiological and non-radiological clinical imaging to develop a computational tool that can assess AAA risk of rupture with greater accuracy than the current clinical standard. Such a tool will allow the accurate quantification of individual AAA geometry to achieve the main goal of the study, which is to identify the patient-specific AAA geometry characteristics that are surrogates for patient-specific PWRRI. In the proposed approach, we will first compute a truly individualized PWRRI based on an innovative method called image-based Vascular Mechanical Characterization technology (iV-MeCh). The geometry characteristics highly correlated with PWRRI will be considered the surrogates of this biomechanics-based index. A second phase of the study will be the validation of the surrogates with actual clinical outcomes, which will yield the accurate predictors of rupture. This approach, devoid of complex finite element modeling and based on a fast, nearly automated computational tool for geometry quantification, would provide an exceptional rationale for the need for surgical intervention and be of major clinical significance. Therefore, the following specific aims are to be completed during the project period to address the aforementioned hypothesis: (1) Validate iV-MeCh for estimating patient-specific spatio-temporal AAA wall stress; (2) Calculate individual PWRRI using iV-MeCh for high and low risk of rupture AAA; (3) Identify the individual geometry characteristics that are surrogates of PWRRI; and (4) Assess the clinical significance of geometric surrogates for the prediction of AAA rupture risk. The primary outcome of this research will be the ability to disambiguate or demystify rupture risk in AAA for which the standard of care (maximum diameter) is not an accurate metric for assessing their at-risk condition. The geometric surrogates of PWRRI are hypothesized to reduce false positives and false negatives compared to the conventional maximum diameter cut-off for recommending elective repair. In addition, PWRRI is predicted by means of a new, novel technique (iV-MeCh), which estimates wall stress in aneurysms by means of non-radiological clinical imaging and without the use of constitutive soft tissue mechanics. PUBLIC HEALTH RELEVANCE: This award will enable the validation of computational tools for non-invasively predicting the at-risk condition of patients with abdominal aortic aneurysms (AAAs) based on the assessment of aneurysm geometry. This research is expected to impact the clinical management of AAA disease, as well as the pre-surgical planning capabilities of vascular and endovascular aneurysm repair.",Geometric Surrogates for Clinical Management of Abdominal Aortic Aneurysms,9041015,R01HL121293,"['Abdominal Aortic Aneurysm', 'Address', 'Aneurysm', 'Award', 'Biomechanics', 'Blood Vessels', 'Caliber', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Complex', 'Consent', 'Data', 'Development', 'Diagnosis', 'Disease', 'Electrocardiogram', 'Elements', 'Foundations', 'Geometry', 'Goals', 'Growth', 'Health', 'Image', 'Imaging Techniques', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Motion', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Patients', 'Phase', 'Physiological', 'Property', 'Records', 'Recruitment Activity', 'Research', 'Risk', 'Rupture', 'Ruptured Abdominal Aortic Aneurysm', 'Ruptured Aneurysm', 'Spatial Distribution', 'Staging', 'Stress', 'Surgeon', 'Surveillance Program', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Validation', 'X-Ray Computed Tomography', 'base', 'clinically significant', 'computerized tools', 'design', 'high risk', 'improved', 'indexing', 'individual patient', 'innovation', 'novel', 'pressure', 'primary outcome', 'prospective', 'radiologist', 'repaired', 'soft tissue', 'standard of care', 'tool']",NHLBI,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2016,474831,14847250,0.00486483354108296
"Machine Learning for Identifying Adverse Drug Events ﻿    DESCRIPTION (provided by applicant): Because of the profound effect of adverse drug events (ADEs) on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post-marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA formed the Observational Medical Outcomes Partnership (OMOP) to develop and compare methods for identification of ADEs, and the FDA announced its Sentinel Initiative. Congress created the Reagan Udall Foundation (RUF) for the FDA in response to the FDA's own ""FDA Science and Mission at Risk"" report, and two years ago OMOP activities were incorporated into RUF. As the FDA moves forward with its development of Sentinel, including work on Mini-Sentinel, there is a need for researchers around the country to continue to develop better methods, and better evaluation methodologies for those methods. A robust research community working on algorithms for pharmacosurveillance, using electronic health records (EHRs) and claims databases will provide a substrate of ever-improving methods on which the nation's regulatory pharmacovigilance infrastructure can build. Indeed an important motivation of OMOP and Mini-Sentinel was to spur the development of such a community. Machine learning has attracted widespread attention across a range of disciplines for its ability to construct accurate predictive models. Therefore machine learning is especially appropriate for the problems of ADE identification and prediction: identifying ADEs from observational data, and predicting which patients are most at risk of suffering the identified ADE. Our current award has demonstrated the ability of machine learning to address both of these tasks. It has added to the existing evidence that consideration of temporal ordering of events, such as drug exposure and diagnoses, is critical for accuracy in identification and prediction of ADEs. The proposed work seeks to further improve upon these methods by building on recent advances in the field of machine learning, by our group and by others, in graphical model learning and in explicit modeling of irregularly-sampled temporal data. The latter is especially important because observational health databases, such as EHRs and claims databases, are not simple time series. Patients typically do not come into the clinic at regular intervals and have the same labs, vitals, and other measurements in lock step with one another. Building better ADE detection and prediction algorithms cannot be accomplished simply by machine learning research, even if that research is taking account of related work from relevant parts of computer science, statistics, biostatistics, epidemiology, pharmaco-epidemiology, and clinical research. Better methods are needed also for evaluation, that is, for estimating how well a new algorithm, or a new use of an existing algorithm, will perform at identifying ADEs associated with a new drug on the market, or at predicting which patients are most at risk of that ADE. More research and evaluation is also needed at the systems level: how can we best construct end-to-end pharmacovigilance systems that sit atop a large observational database and flag potential ADEs for human experts to further investigate? What kinds of information and statistics should such a system provide to the human experts?        This renewal will address the following aims: (1) improve upon machine learning methods for identification and prediction of ADEs, taking advantage of synergies between these two distinct tasks; (2) improve upon existing methods for evaluating ADE detection, building on advances in machine learning for information extraction from scientific literature; (3) improve upon existing methods for evaluating ADE prediction, building upon advances in machine learning for automated support of phenotyping and also building upon improved methods for efficiently obtaining expert labeling of borderline examples of a phenotype; and (4) use the methods developed in the first three aims to construct and evaluate an end-to-end pharmacosurveillance system integrated with the Marshfield Clinic EHR Data Warehouse. Machine learning plays a central and unifying role throughout all four aims. Our investigator team consists of machine learning researchers with experience in analysis of clinical, genomic, and natural language data (Page, Natarajan), a leading pharmaco-epidemiologist with expertise in building systems to efficiently obtain expert evaluation and labeling of phenotypes (Hansen), a leader in phenotyping from EHR data (Peissig), and an MD/PhD practicing physician with years of experience and leadership in the study of ADEs (Caldwell). In addition to building on results of the prior award, we will build on our experiences with OMOP, the International Warfarin Pharmacogenetics Consortium, the DARPA Machine Reading Program, and interactions with the FDA. PUBLIC HEALTH RELEVANCE: Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It also addresses the needs for improved evaluation and integrated systems approaches.",Machine Learning for Identifying Adverse Drug Events,9145227,R01GM097618,"['Accounting', 'Address', 'Adverse drug event', 'Algorithms', 'Attention', 'Award', 'Biometry', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Congresses', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Discipline', 'Doctor of Philosophy', 'Drug Exposure', 'Early Diagnosis', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Evaluation Methodology', 'Evaluation Research', 'Event', 'Foundations', 'Genomics', 'Health', 'Human', 'Institute of Medicine (U.S.)', 'Label', 'Leadership', 'Learning', 'Life', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Markov Chains', 'Measurement', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Motivation', 'Myocardial Infarction', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Physicians', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Priority', 'Risk', 'Role', 'Safety', 'Sampling', 'Science', 'Sentinel', 'Series', 'Serious Adverse Event', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Wisconsin', 'Work', 'base', 'computer science', 'cost', 'data mining', 'experience', 'improved', 'inhibitor/antagonist', 'interest', 'international partnership', 'learning strategy', 'natural language', 'novel', 'novel therapeutics', 'patient safety', 'post-market', 'prediction algorithm', 'predictive modeling', 'programs', 'response', 'statistics']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2016,539889,338121506,-0.009181669640358605
"Machine learning of physiological variables to predict diagnose and treat cardiorespiratory instability Project Summary/Abstract: If one could accurately predict who, when and why patients develop cardiorespiratory instability (CRI), then effective preemptive treatments could be given to improve outcome and better use care resources. However, CRI is often unrecognized until it is well established and patients are more refractory to treatment, or progressed to organ injury. We have shown that an integrated monitoring system alert obtained from continuous noninvasively acquired monitoring parameters and coupled to a care algorithm improved step-down unit (SDU) patient outcomes. We also showed that advanced HR variability analysis (sample entropy) identified SDU patients at CRI risk within 2 minutes, and if monitored for 5 minutes differentiated between patients who would develop CRI or remain stable over the next 48 hours. We also applied machine learning (ML) modeling to our clinically-relevant porcine model of hemorrhagic shock to characterize responses to hypovolemia, hemorrhage, and resuscitation, predict which animals would or would not collapse during hypovolemia, and identify occult bleeding 5 minutes earlier than with traditional monitoring. We now propose to apply our work to vulnerable and invasively monitored ICU patients. We will develop multivariable models through ML data-driven classification techniques such as regression, Fourier and principal component analysis, artificial neural networks, random forest classification, etc. as well as more novel approaches (temporal rule learning developed by our team; Bayesian Aggregation) to predict CRI in ICU patients. We will first use our existing annotated high fidelity waveform MIMIC II clinical data set (4200 patients) to develop predictive models and differential signatures for various CRI drivers. We will also use our high-density data collection and processing platform (Bernoulli) to prospectively collect data from ICUs in three institutions: Univ. Pittsburgh (PITT), Univ. California (UC) Irvine and UC San Diego (initial algorithm development conducted at PITT and validated in the UC systems). We will identify the number and type of independent measures, sampling frequency, and lead time necessary to create robust algorithms to: 1) predict impending CRI, 2) select the most effective treatments, 3) monitor treatment response, and 4) determine when treatment has restored physiologic stability and can be stopped. We will also determine the smallest number and types of parameters coupled to the longest CRI lead time to achieve the above four targets with the best sensitivity and specificity (a concept we call Monitoring Parsimony).We will simultaneously iteratively design and test a graphical user interface (GUI) and clinical decision support system (CDSS) driven by these parsimoniously derived predictive smart alerts and functional hemodynamic monitoring treatment approaches in two human simulation environments (PITT & UC Irvine).We envision a basic monitoring surveillance that identifies patients most likely to develop CRI to apply focused clinician attention and targeted treatments to deliver highly personalized medical care. Public Health Narrative If one could accurately predict who, when and why patients develop shock then effective preemptive treatments could be given to improve outcome and more effectively use healthcare resources. But signs of shock often occur late once organ injury is already present. The purpose of this study is to first develop multivariable models through data-driven classification techniques to parsimoniously predict cardiovascular insufficiency, etiology and response to treatment. We will do this first in our existing MIMIC II clinical data sets of 4200 ICU patients as to timing and types of instability. Then we will prospectively collect real time high- density data on patients admitted to our trauma intensive care units of University of Pittsburgh, UC Irvine and UC San Diego. We will create and test in simulators of ICU care bedside user interfaces to drive recognition and treatment algorithms based on these models in all three medical centers.",Machine learning of physiological variables to predict diagnose and treat cardiorespiratory instability,9029396,R01GM117622,"['Accounting', 'Acute', 'Algorithms', 'Animals', 'Attention', 'Biological Neural Networks', 'California', 'Cardiovascular system', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Complex', 'Coupled', 'Critical Illness', 'Data', 'Data Collection', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Entropy', 'Environment', 'Etiology', 'Family suidae', 'Frequencies', 'Future', 'Health', 'Healthcare', 'Hemorrhage', 'Hemorrhagic Shock', 'Homeostasis', 'Hour', 'Human', 'Hypovolemia', 'Individual', 'Injury', 'Institution', 'Intensive Care Units', 'Intervention', 'Lead', 'Learning', 'Libraries', 'Machine Learning', 'Measures', 'Mechanical ventilation', 'Medical', 'Medical center', 'Modeling', 'Monitor', 'Normal Range', 'Organ', 'Organ failure', 'Pathologic Processes', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Physiologic Monitoring', 'Physiological', 'Principal Component Analysis', 'Process', 'Public Health', 'Recommendation', 'Refractory', 'Resolution', 'Resources', 'Resuscitation', 'Risk', 'Running', 'Sampling', 'Sensitivity and Specificity', 'Sepsis', 'Shock', 'Signal Transduction', 'Specificity', 'Stream', 'Stress', 'System', 'Techniques', 'Testing', 'Time', 'Trauma', 'Triage', 'Universities', 'Validation', 'Variant', 'Weaning', 'Work', 'abstracting', 'base', 'clinical care', 'clinically relevant', 'computerized data processing', 'cost', 'database structure', 'density', 'design', 'diagnostic accuracy', 'early onset', 'effective therapy', 'fitness', 'forest', 'graphical user interface', 'hemodynamics', 'high risk', 'improved', 'improved outcome', 'insight', 'iterative design', 'mortality', 'novel strategies', 'patient population', 'personalized medicine', 'predictive modeling', 'predictive tools', 'prospective', 'prototype', 'response', 'simulation', 'support tools', 'treatment response']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2016,662537,570146095,-0.014548840723242622
"Optical Body Composition and Health Assessment ﻿    DESCRIPTION (provided by applicant):1 Of all markers of human health, the most intuitive is body shape but based on quantitative evidence.  2 Anthropometry and regional composition measures such as waist circumference (WC), waist to hip ratio  3 (WHR), and visceral adipose tissue area (VAT) are better predictors of obesity-related diseases and mortality  4 risk than body mass index (BMI). Dual-energy X-ray absorptiometry (DXA) can quantify regional adiposity in  5 more detail than the above measures but is underutilized for many reasons including potential harm from  6 ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments  7 in the ""quantified self movement"" to better describe phenotypes of body shape and its relation to metabolic  8 risks. The candidate developed in this proposal is 3D optical whole body scanning. If successful, sophisticated  9 obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with 10 disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment 11 technology. Whole body 3D imaging technology is already so accessible that it can be done with video games 12 such as the Microsoft Xbox Kinect, and consumer cameras. 13 The long term goal of the Optical Body Shape and Health Assessment Study is 1) to provide phenotype 14 descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in 15 research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive 16 models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, 17 muscle mass, lean mass, and percent fat), and then show how our 3DO body composition estimates are 18 associated to important metabolic risk factors. Our central hypothesis is that 3DO measures of body 19 composition with shape classification better predict metabolic risk factors than anthropometry or DXA body 20 composition alone. Our specific aims are: 1. Identify the unique associations of body shape to body 21 composition indices in a population that represents the variance of sex, age, BMI, and ethnicity found 22 in the US population; 2. Describe the precision and accuracy of 3DO scans to monitor change in body 23 composition and metabolic health interventions; and 3. Estimate the level of association of 3DO to 24 common health indicators including metabolic risk factors by gender, race, age, and BMI. In an 25 exploratory aim, we investigate holistic, high-resolution descriptors of 3D body shape as direct 26 predictors of body composition and metabolic risk using statistical shape models and Latent Class 27 Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self- 28 assessment technologies that are capable of representing over 95% of the shape variance in the US 29 population, and how these models relate to important metabolic status and body composition. The positive 30 impact will be the immediate applicability to clinicians and individuals for personalized risk assessment.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because they have the potential to provide a better understanding of who is at high risk of metabolic diseases because of a poor metabolic profile. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.            ",Optical Body Composition and Health Assessment,9082891,R01DK109008,"['Adipose tissue', 'Adult', 'Age', 'Animals', 'Anorexia Nervosa', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Classification', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Devices', 'Diabetes Mellitus', 'Diagnosis', 'Dual-Energy X-Ray Absorptiometry', 'Ethnic Origin', 'Fatty acid glycerol esters', 'Gender', 'Glucose', 'Goals', 'Health', 'Hereditary Disease', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Individual', 'Insulin Resistance', 'International', 'Intervention', 'Ionizing radiation', 'Life Style', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'Video Games', 'Visceral', 'Waist-Hip Ratio', 'bariatric surgery', 'base', 'clinical practice', 'cost', 'disorder prevention', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolic profile', 'metabolomics', 'mortality', 'muscle form', 'optical imaging', 'predictive modeling', 'public health relevance', 'sensor', 'sex', 'subcutaneous', 'tool', 'waist circumference', 'whole body imaging']",NIDDK,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2016,706716,685608202,0.017842522954837608
"Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics Project Summary The presence of abnormal cell populations in patient samples is diagnostic for a variety of human diseases, especially leukemias and lymphomas. One of the main technologies used for cell-based diagnostic evaluation is flow cytometry, which employs fluorescent reagents to measure molecular characteristics of cell populations in complex mixtures. While cytometry evaluation is routinely used for the diagnosis of blood-borne malignancies, it could be more widely applied to the diagnosis of other diseases (e.g. asthma, allergy and autoimmunity) if it could be reproducibly used to interpret higher complexity staining panels and recognize more subtle cell population differences. Flow cytometry analysis is also widely used for single cell phenotyping in translational research studies to explore the mechanisms of normal and abnormal biological processes. More recently, the development of mass cytometry promises to further increase the application of single cell cytometry evaluation to understand a wide range of physiological, pathological and therapeutic processes. The current practice for cytometry data analysis relies on “manual gating” of two-dimensional data plots to identify cell subsets in complex mixtures. However, this process is subjective, labor intensive, and irreproducible making it difficult to deploy in multicenter translational research studies or clinical trials where protocol standardization and harmonization are essential. The goal of this project is to develop, validate and disseminate a user-friendly infrastructure for the computational analysis of cytometry data for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective and accurate analysis, through the following aims: Specific Aim 1 – Implement a novel computational infrastructure – FlowGate – for cytometry data analysis that includes visual analytics and machine learning; Specific Aim 2 – Assess the utility of FlowGate for cell population characterization in mechanistic translational research studies (T1); Specific Aim 3 – Assess the robustness and accuracy of FlowGate for clinical diagnostics in comparison with the current standard-of-care analysis of diagnostic cytometry data (T2); Specific Aim 4 – Develop training and educational resources and conduct directed outreach activities to stimulate adoption and use of the resulting FlowGate cyberinfrastructure. The project will have a major impact in advancing translational science by overcoming key hurdles for adoption of these computational methods by facilitating analysis pipeline optimization, providing intuitive user interfacing, and delivering directed training activities. The application of the developed computational infrastructure for improved diagnostics of AML and CLL will contribute to the new emphasis on precision medicine by more precisely quantifying the patient-specific characteristics of neoplastic and normal reactive cell populations. Although FlowGate will be developed by the UC San Diego, UC Irvine, and Stanford CTSAs, the resulting computational infrastructure will be made freely available to the entire research community. Project Narrative Flow cytometry analysis is widely used for single cell phenotyping in the translational research lab to explore the mechanisms of normal and abnormal biological processes and in the clinical diagnostic lab for the identification and classification of blood-borne malignancies. However, the current practice for cytometry data analysis using “manual gating” based on two-dimensional data plots is subjective, labor-intensive and unreliable, especially when using more complex high content staining panels. The goal of this project is to develop, validate and disseminate a user-friendly computational infrastructure for cytometry data analysis for both diagnostic and discovery applications that could help overcome the current limitations of manual analysis and provide for more efficient, objective, accurate, and reproducible analysis of cytometry data.",Transformative Computational Infrastructures for Cell-Based Biomarker Diagnostics,9215166,U01TR001801,"['Abnormal Cell', 'Acute leukemia', 'Adoption', 'Antiviral Therapy', 'Apoptosis', 'Asthma', 'Autoimmunity', 'Big Data', 'Biological Markers', 'Biological Phenomena', 'Biological Process', 'Blood', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Clinical trial protocol document', 'Collaborations', 'Communities', 'Complex', 'Complex Mixtures', 'Computer Analysis', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Flow Cytometry', 'Future', 'Goals', 'Hypersensitivity', 'Immunology', 'Immunophenotyping', 'Individual', 'Injury', 'Institution', 'Leukocyte Chemotaxis', 'Lymphocyte', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Methods', 'Mitogen-Activated Protein Kinases', 'Molecular', 'Monitor', 'Myocardial', 'Paper', 'Patient Care', 'Patients', 'Phenotype', 'Phosphorylation', 'Physiological', 'Population', 'Prevalence', 'Process', 'PubMed', 'Reagent', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Sampling', 'Series', 'Staining method', 'Stains', 'Standardization', 'TNF gene', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Training', 'Training Activity', 'Translational Research', 'Visual', 'base', 'computer infrastructure', 'cyber infrastructure', 'design', 'diagnostic biomarker', 'human disease', 'improved', 'insight', 'leukemia/lymphoma', 'malignant breast neoplasm', 'monocyte', 'neoplastic', 'novel', 'outcome forecast', 'outreach', 'precision medicine', 'prognostic', 'research study', 'response', 'specific biomarkers', 'standard of care', 'targeted treatment', 'tool', 'translational study', 'two-dimensional', 'user-friendly']",NCATS,"J. CRAIG VENTER INSTITUTE, INC.",U01,2016,855992,3808719,-0.0007807124647791958
"An Open Source Precision Medicine Platform for Cloud Operating Systems ﻿    DESCRIPTION (provided by applicant):  Rapid improvements in DNA sequencing and synthesis have the potential to usher in a new era of precision medicine. To realize this vision, however, we must re-imagine the computational and storage infrastructure used to manage and extract actionable results from the massive data sets made possible by widely available advances in DNA sequencing and synthetic biology. In conjunction with the Global Alliance for Genomics and Health (GA4GH), we propose to build the Arvados platform so that a new ecosystem of clinical decision support applications will be able to navigate petabytes of global biomedical data and search millions of genomes in real-time (seconds). Our team has a proven track record of commercial success and high impact scientific research. Commercialization of this free and open-source software (FOSS) platform, which will be greatly accelerated by this grant, will permit organizations to seamlessly span on-premise & hosted cloud- operating systems and vastly simplify data-management & computation, all while facilitating compliance with institutional policies and regulatory requirements.         PUBLIC HEALTH RELEVANCE:  The delivery of healthcare based on molecular data specific to an individual patient (i.e. precision medicine) will require the creation of a new ecosystem of Clinical Decision Support (CDS) applications. This work will provide a platform that will make the development of such applications faster, easier, and less expensive.        ",An Open Source Precision Medicine Platform for Cloud Operating Systems,9140741,R44GM109737,"['Address', 'Adopted', 'Big Data', 'Bioinformatics', 'Businesses', 'Capital', 'Clinical', 'Clinical Decision Support Systems', 'Collaborations', 'Communities', 'Computer software', 'Contractor', 'DNA Sequence', 'DNA biosynthesis', 'Data', 'Data Set', 'Databases', 'Development', 'Distributed Systems', 'Ecosystem', 'Feedback', 'Fostering', 'Funding', 'Galaxy', 'Genome', 'Genomics', 'Grant', 'Health', 'Healthcare', 'Human', 'Industry', 'Information Technology', 'Institutional Policy', 'International', 'Internet', 'Language', 'Length', 'Letters', 'Machine Learning', 'Maintenance', 'Manuscripts', 'Measures', 'Medicine', 'Memory', 'Molecular', 'Operating System', 'Phase', 'Policies', 'Production', 'Publications', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resources', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Source Code', 'System', 'Technology', 'Time', 'Training Support', 'Vision', 'Work', 'base', 'big biomedical data', 'cloud platform', 'commercialization', 'data management', 'genome sequencing', 'genomic data', 'health care delivery', 'individual patient', 'meetings', 'new technology', 'next generation sequencing', 'open source', 'operation', 'petabyte', 'portability', 'precision medicine', 'public health relevance', 'repository', 'screening', 'success', 'symposium', 'synthetic biology', 'terabyte', 'web services', 'whole genome']",NIGMS,"CUROVERSE, INC.",R44,2016,985339,0,-0.01818634540116937
"Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination Project Summary / Abstract Between 1.6 and 3.8 million people each year suffer a mild TBI in the US alone. Reliable diagnosis and prompt treatments are vital to managing the often-serious short and long-term sequelae resulting from mild TBI. However, a reliable objective and accurate method for mild TBI diagnosis outside of a hospital setting, and in particular for determining RTP readiness, has eluded the clinical community. Current diagnosis and RTP assessments are based on patient symptoms, neurocognitive evaluations, and / or physical performance testing. Use of symptom scales are problematic for several reasons including subjectivity and reliability. Neurocognitive evaluations and physical tests (such as balance tests), although less subjective, require pre- injury baseline testing of subjects due to inherently large subject-to-subject variations in evaluation performances. Due to these reasons, current mild TBI diagnostic methods have limited applications and are not suitable for a significant majority of patients who suffer mild TBI. This project is aimed at developing an objective diagnosis of mild traumatic brain injury (mild TBI) based on physiologic changes in a patient after injury and providing a platform capable of RTP guidance. The method is based on quantification of well-known physiologic changes after a concussion, i.e. the impairment of autonomic function and altered cerebral blood flow (CBF) as measured with transcranial Doppler (TCD). The novelty of the proposed approach is the use of a recently-developed analytical machine learning framework for the analysis of the CBF velocity (CBFV) waveforms. In contrast to previous methods used before, the proposed approach utilizes the entire shape of the complex CBFV waveform, thus obtaining subtle changes in blood flow that are lost in other analysis methods. Additionally, comprehensive verification between our platform and MRI will be performed following injury resulting in the first scientific experiments of this kind. The ultimate goal of this Phase II SBIR is to commercialize an objective and accurate software algorithm for reliable diagnosis and management of sports concussions which does not currently exist. The outcome will be a software suite integrated into existing TCD and will be marketed to emergency departments, neurology clinics, and other healthcare providers involved in mild TBI diagnosis and RTP management. Project Narrative Traumatic brain injury (TBI) is a serious public health problem in the United States contributing to a substantial number of deaths and cases of permanent disability. Mild TBI concussions account for over 80% of all TBIs sustained and a major problem is the high rate of mis-diagnosis due to lack of objective measures and delayed onset of symptoms. This project aims to develop the first objective concussion evaluation method using a novel analysis platform that can obtain subtle, physiologic changes in cerebral hemodynamics. Successful completion of this project will result in a portable diagnostic device suitable for use in many scenarios where concussion diagnosis is inaccurate or unavailable today.",Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination,9202982,R44NS092209,"['Accident and Emergency department', 'Accounting', 'Acute', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Area Under Curve', 'Assessment tool', 'Blood Flow Velocity', 'Blood flow', 'Brain Concussion', 'Cerebrovascular Circulation', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Controlled Study', 'Core-Binding Factor', 'Data', 'Data Analytics', 'Data Collection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Evaluation', 'Functional disorder', 'Future', 'Goals', 'Gold', 'Guidelines', 'Health Personnel', 'Hospitals', 'Image', 'Impairment', 'Injury', 'Letters', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Marketing', 'Measures', 'Methods', 'Modeling', 'Neurocognitive', 'Neurologist', 'Neurology', 'Outcome', 'Patients', 'Pediatric Neurology', 'Performance', 'Persons', 'Phase', 'Physical Performance', 'Physicians', 'Physiological', 'Play', 'Public Health', 'Publications', 'Readiness', 'Recovery', 'Research', 'Resolution', 'Risk', 'Severities', 'Shapes', 'Site', 'Small Business Innovation Research Grant', 'Spin Labels', 'Sports', 'Sports Medicine', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Traumatic Brain Injury', 'Ultrasonography', 'United States', 'Variant', 'abstracting', 'balance testing', 'base', 'brain health', 'cerebral hemodynamics', 'clinical Diagnosis', 'diagnostic accuracy', 'disability', 'hemodynamics', 'high school', 'injured', 'innovation', 'mild traumatic brain injury', 'novel', 'performance tests', 'prevent', 'programs', 'relating to nervous system', 'research study', 'success', 'tool']",NINDS,"NEURAL ANALYTICS, INC.",R44,2016,1500000,699413,-0.0038214664943206408
"Transition from Risk Factors to Early HF: Prevalence, Pathogenesis, and Phenomics ﻿    DESCRIPTION (provided by applicant): Heart failure (HF) is a major public health problem: it affects >6 million people in the U.S., it is the #1 cause of hospitalization and readmission in older adults, and 5-year survival after HF hospitalization is a dismal 35%, regardless of underlying ejection fraction (EF). These statistics highlight the urgent need for prevention of HF and better understanding of how and why HF develops in high-risk individuals. However, a critical limitation of prior population-based studies is the ascertainment of incident HF based on hospitalizations for HF and/or signs of overt volume overload. Many older individuals may suffer from early HF: breathlessness, fatigue, and exercise intolerance (without overt volume overload) due to underlying cardiac structure/function abnormalities, typically with a preserved EF (i.e. early HFpEF). Thus, the current epidemiology of HF is most likely missing a major form of prevalent HF. In this ancillary study of the Multi-Ethnic Study of Atherosclerosis (MESA, Year-15 Exam, n=3500), we will define early HF in a contemporary, multi-ethnic, elderly cohort; we will utilize cutting- edge indices of cardiac mechanics and ventricular-arterial interactions, including Lagrangian strain and time- varying pressure-stress analyses; and we will perform novel phenomics analyses to better characterize the interplay of risk factors and cardiac structure/function abnormalities (i.e., multi-dimensional phenotypic signatures) as they relate to early and overt HF. The aims of our study are to: (1) determine the prevalence of early HF using a combination of validated symptom surveys, 6-minute walk test, NTproBNP, and echocardiography, with validation using cardiopulmonary exercise testing (CPEX); (2) better understand the pathophysiology of early HF, particularly HFpEF; and (3) delineate the key phenotypic signatures associated with early and overt HF. The proposed exam will include anthropometry, blood pressure, symptom surveys, functional status (6-minute walk test), physical activity, laboratory measures (NTproBNP, fasting glucose, renal function), and comprehensive echocardiography (with tissue Doppler and speckle-tracking at rest and during physiologic maneuvers) in all participants. In sub-samples we will also measure arterial tonometry, novel biomarkers, and fitness (CPEX). We will utilize the wealth of data collected during the 5 prior MESA exams to perform longitudinal analyses (including latent class trajectory and statistical learning analyses) to determine the extent to which risk factors are associated with early HF, particularly early HFpEF. By the end of our 4-year study, we will accomplish the following key goals, each of which will have a lasting impact on the field of HF: (1) we will establish the prevalence of early HF in the community; (2) we will have a standardized method for the screening/diagnosis of early HFpEF, validated by CPEX, and readily applicable to the clinical setting; (3) we will define novel mechanisms by which risk factors, alone and in combination, relate to abnormalities in cardiac mechanics and ventricular-arterial coupling in the general population; and (4) we will have defined phenotypic signatures of HF development that will inform future clinical trials for HF prevention and treatment. PUBLIC HEALTH RELEVANCE: Heart failure is a common, expensive, and deadly health problem, especially among the elderly. Unfortunately, once overt heart failure develops it is difficult to treat and results in poor outcomes. Therefore it is critical to determine the relationhip between risk factors and abnormalities in heart structure and function that lead to early forms of heart failure. This project aims to: (1) determine how common early heart failure is in the population; (2) better understand the mechanisms of early heart failure by studying the heart and blood vessels using imaging and laboratory tests; and (3) use ""big data"" techniques to harness the wealth of quantitative data we have collected to determine individuals at highest risk for the development of early heart failure.","Transition from Risk Factors to Early HF: Prevalence, Pathogenesis, and Phenomics",9115219,R01HL127028,"['Address', 'Adult', 'Affect', 'Age', 'Air Pollution', 'Ancillary Study', 'Anthropometry', 'Atherosclerosis', 'Big Data', 'Biological Markers', 'Blood Pressure', 'Blood Vessels', 'Cardiac', 'Cardiac Output', 'Cardiopulmonary', 'Cardiovascular system', 'Chronic Kidney Failure', 'Clinical', 'Clinical Trials', 'Code', 'Communities', 'Coronary', 'Coronary Arteriosclerosis', 'Coupling', 'Data', 'Development', 'Diabetes Mellitus', 'Diet', 'Dyspnea', 'EFRAC', 'Early Diagnosis', 'Echocardiography', 'Elderly', 'Electrocardiogram', 'Epidemiologic Studies', 'Epidemiology', 'Ethnic Origin', 'Exercise stress test', 'Fatigue', 'Functional disorder', 'Future', 'Galectin 3', 'Gender', 'General Population', 'Goals', 'Health', 'Heart', 'Heart Atrium', 'Heart failure', 'Hospitalization', 'Hypertension', 'ICD-9', 'Image', 'Incidence', 'Individual', 'Laboratories', 'Lead', 'Left', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Myocardial', 'Myocardial Infarction', 'Obesity', 'Outcome', 'Outpatients', 'Participant', 'Pathogenesis', 'Patients', 'Phenotype', 'Physical activity', 'Physiological', 'Population', 'Prevalence', 'Prevention', 'Prevention strategy', 'Public Health', 'Race', 'Recruitment Activity', 'Renal function', 'Rest', 'Risk', 'Risk Factors', 'Sampling', 'Spirometry', 'Staging', 'Stress', 'Structure', 'Surveys', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Validation', 'Ventricular', 'Walking', 'Weight', 'aged', 'arterial stiffness', 'arterial tonometry', 'base', 'brachial artery', 'clinical Diagnosis', 'cohort', 'design', 'endothelial dysfunction', 'epidemiology study', 'ethnic diversity', 'exercise intolerance', 'fasting glucose', 'fitness', 'functional status', 'high risk', 'indexing', 'novel', 'novel marker', 'phenomics', 'population based', 'pressure', 'screening', 'statistics', 'trend']",NHLBI,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R01,2016,1900214,134382703,0.0069977856261783525
"Forecasting pulmonary inflammation from in vitro assay results for nanoparticles ﻿    DESCRIPTION (provided by applicant):  The rapidly developing field of nanotechnology shows promise by allowing designers to specifically select unique combinations of material properties as needed increasing the effectiveness of applications in medicine, coatings, lubrication, semiconductors, composites, and many others. These materials with their unique combinations of properties on exposure to humans may result in unanticipated hazards, however, putting workers in nanotechnology-related industries at risk. Traditional animal testing is expensive and too slow to evaluate potential risks for the current pace of new nanomaterial development. Both technology developers and regulators need more rapid methods to evaluate new nanomaterial configurations for their risk potential. Much hope is placed in high-throughput in vitro screening assays, but the relevance of these results to the potential for human disease or even the observed toxic effects in animal exposures is unclear. Some research has proposed Quantitative Structure Activity Relationships (QSARs) to predict in vitro nanomaterial toxicity in a few specific assays, but the applicability of these models to a wider group of materials, alternative in vitro assays, or in vivo toxicity has not been explored. If the primary exposure pathway for workers in the near term is inhalation, which in vitro assays will provide the most reliable risk information for that scenario? Two recently available data sources will permit this study to investigate this question: the Environmental Protection Agency's (EPA) ToxCast data for nanomaterials and the Nanomaterial Pulmonary Toxicity Database (NTDB), a collection of published peer reviewed studies observing pulmonary inflammation in rodents upon exposures to nanomaterials. This study will pursue the following specific aims: (1.) identify combinations of in vitro assay results that can reliably forecast the results of pulmonary inflammation results in rodents; (2.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to a wider array of in vitro toxicity assays; and (3.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to in vivo pulmonary inflammation results. This study will employ machine learning methods to cluster similar nanomaterials between the various in vitro and in vivo results, and to identify combinations of in vitro assays that rank order the toxicity of nanomaterials most similarly to pulmonary inflammation results in rodents considering also how changes in specific chemical and physical particle properties exacerbate or mitigate observed toxicity. This study addresses documented research needs in the National Occupational Research Agenda (NORA) cross- sector Nanotechnology program including specific goals in the Human Health and Informatics categories. Implementation complies with the Research to Practice (r2p) Initiative in its formulation, design, and implementation plan including industry an public outreach. The insight generated by this study will improve nanomaterial risk screening capabilities and focus attention and effort on those measurements and techniques proven to be most effective and reliable enabling better management and control of the risks faced by workers.         PUBLIC HEALTH RELEVANCE:  Although toxicity risk information for nanoparticles is accumulating rapidly, the development of new nanomaterial configurations is proceeding too fast for our best risk assessment tools (i.e. animal testing) to keep up. The new availability of two large databases of in vitro assay results and pulmonary inflammation results in rodents will permit this study to investigate which in vitro assays provide the most predictive information about the results from in vivo exposures, and thus speed up the risk screening process for nanomaterials. The results of this study will have important implications for more quickly identifying new nanomaterial-related risks to workers.            ",Forecasting pulmonary inflammation from in vitro assay results for nanoparticles,8953935,R03OH010956,[' '],NIOSH,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R03,2015,66904,74382276,-0.006718192631447484
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,8935802,U54EB020405,"['Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Outcome', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Science', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Visit', 'Walking', 'Work', 'base', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'health data', 'improved', 'industry partner', 'insight', 'models and simulation', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'prevent', 'programs', 'public health relevance', 'role model', 'sensor', 'social', 'social model', 'tool']",NIBIB,STANFORD UNIVERSITY,U54,2015,68981,560644462,0.0004879992821547506
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,8935748,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Research', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Scientist', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2015,73173,338121506,-0.0001761296559152404
"Fracture Prediction by Machine Learning and 3D Finite Element Models from DXA ﻿    DESCRIPTION (provided by applicant): Osteoporosis is a disease characterized by loss of bone mass and structural deterioration leading to increased risk of fracture. Currently, osteoporosis is diagnosed by measurement of areal bone mineral density by dual- energy x-ray absorptiometry (DXA). However, the majority of fractures occur in both women and men who are not classified as osteoporotic by current DXA criteria (T-score = -2.5). As a 2-dimensional (2D) technology, DXA does not provide information about 3-dimensional (3D) bone structure, shape and geometry, which substantially contribute to bone strength and resistance to fracture. Finite element (FE) analysis of quantitative computed tomography (QCT) images can provide 3D structure and strength measurements but QCT is impractical for widespread clinical use because of high radiation exposure and expense. In contrast, DXA is widely available, inexpensive and has low radiation exposure. What is needed is a method by which DXA images can be used to generate 3D shape models that incorporate bone structure and geometry. However, fractures are complex events influenced by other factors including age, race, body mass index, risk of falls, and prior medical and fracture history. Even sophisticated measurements of bone density, structure, and strength may not be able to predict fractures accurately. Machine learning is an emerging field in which models are created by ""learning"" from previous data. These models can incorporate various factors and be used to classify or predict outcomes for new data. The overall hypothesis of this proposal is that advanced analyses of widely available DXA images that incorporate structural and strength information and statistical modeling using machine learning to incorporate additional risk factors will better identify patient at high risk of osteoporotic fracture. This hypothesis will be tested using QCT and DXA data from previous studies to generate 3D statistical shape models that describe variability in proximal femur morphology. By aligning 2D DXA images to the models, patient-specific 3D models will be reconstructed for quantitative analyses and combined with FE analysis to estimate bone strength. Machine learning models will be used to incorporate these novel measurements, demographics, and various risk factors for fracture to predict incident fractures in two very large, prospective studies. The ultimate goal of this proposal is to increase the diagnostic utility of DXA, a safe, non-invasive, and widely available technology, by applying novel image processing and statistical techniques to predict fractures more accurately.         PUBLIC HEALTH RELEVANCE: Approximately 50% of women and 25% of men over age 50 are destined to suffer an osteoporotic fracture during their remaining lifetime. Unfortunately, the current standard for the diagnosis of osteoporosis, DXA, does not predict most fractures. This research will develop advanced analyses of DXA images and use machine learning to improve individualized fracture risk assessment.            ",Fracture Prediction by Machine Learning and 3D Finite Element Models from DXA,8869145,K99AR067883,"['3-Dimensional', 'Age', 'American', 'Body mass index', 'Bone Density', 'Cadaver', 'Characteristics', 'Clinical', 'Complex', 'Data', 'Data Set', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Epidemiology', 'Event', 'Femur', 'Finite Element Analysis', 'Fracture', 'Future', 'Geometry', 'Goals', 'Gold', 'Height', 'Hip Fractures', 'Image', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Modeling', 'Morphology', 'Osteopenia', 'Osteoporosis', 'Outcome', 'Patients', 'Peripheral', 'Postmenopause', 'Prospective Studies', 'Race', 'Radiation', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Resistance', 'Risk', 'Risk Assessment', 'Risk Factors', 'Scanning', 'Shapes', 'Specimen', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Weight', 'Woman', 'X-Ray Computed Tomography', 'base', 'bone', 'bone geometry', 'bone mass', 'bone strength', 'cohort', 'demographics', 'density', 'diagnosis standard', 'fall risk', 'high risk', 'image processing', 'improved', 'in vivo', 'information model', 'men', 'novel', 'osteoporosis with pathological fracture', 'prospective', 'public health relevance', 'three dimensional structure', 'tool', 'two-dimensional']",NIAMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K99,2015,91800,558628098,0.009055327074050393
"Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data DESCRIPTION (provided by applicant): In-hospital cardiac arrest (IHCA) is a significant public health problem, afflicting over 200,000 patients in the United States annually with a mortality rate of approximately 80%. The majority of these patients show signs of clinical deterioration in the hours before the event. This has led to the development of vital sign-based early warning scores designed to detect high-risk patients before IHCA to trigger life-saving interventions. However, the vast majority of these risk scores were created subjectively in individual hospitals and have shown limited accuracy for detecting adverse outcomes. Developing an accurate risk score to detect patients at highest risk of IHCA is essential to decreasing preventable in-hospital death. In my prior work, I completed several studies investigating the accuracy of vital signs for predicting IHCA. These studies, previous literature, and my preliminary data have resulted in the following conclusions: 1) statistically developed risk scores are more accurate than previously published risk scores, 2) multicenter data is needed to create the most accurate and generalizable risk score, 3) additional data, such as laboratory results, will likely improve the accuracy of risk scores, and 4) a cutting-edge method for developing prediction models, called machine learning, may result in more accurate risk scores. Importantly, significant improvement in accuracy leads to better identification of patients at highest risk of IHCA and decreased resource utilization. Therefore, in this grant proposal I aim to develop and validate IHCA prediction models using different statistical techniques in a multicenter database and then estimate the impact of the most accurate risk score using simulation studies. I will do this by firt developing prediction models using classic survival analysis methods (Aim 1a) and machine learning methods, such as neural networks and decision trees (Aim 1b). Then, I will compare the models I develop to the most accurate previously published risk scores in Aim 2. Finally, I will investigate the impact of the most accurate model from Aim 2 on patient outcomes using simulation modeling (Aim 3). Completion of this proposal will result in a validated IHCA risk score that can be implemented in the electronic health record to trigger life- saving interventions to decrease preventable in-hospital death. In addition, this career development award will provide critical data to inform future R01-level awards, including a clinical trial to investigate he impact of the developed prediction model on patient outcomes. I will complete this project under the direct supervision of my mentor (Dr. David Meltzer), co-mentor (Dr. Dana Edelson), and the rest of my advisory team (Drs. Jesse Hall, Robert Gibbons, and Michael Kattan). Together, this multidisciplinary team brings nationally renowned expertise in in-hospital cardiac arrest, outcomes research, critical care, and clinical prediction modeling. In addition, they serve as Chairs of the Section of Hospital Medicine (Dr. Meltzer), Section of Pulmonary and Critical Care (Dr. Hall), and Quantitative Health Sciences at the Cleveland Clinic (Dr. Kattan), and Directors of the Center for Health and the Social Sciences (Dr. Meltzer), Center for Health Statistics (Dr. Gibbons), and Clinical Research for the Emergency Resuscitation Center (Dr. Edelson). The mentorship, expertise, and resources that they provide will ensure my success as I grow into an independent physician-scientist. My career goal is to become an independent critical care outcomes researcher with a focus on developing prediction models for clinical deterioration that will improve patient outcomes. To accomplish this long-term goal, I have three short-term goals: (1) to gain expertise in the development and implementation of clinical prediction models, (2) to create an IHCA prediction model that will identify high-risk patients on the wards to trigger life-saving interventions, and (3) to gain expertise in simulation modeling in order to study the impact of the developed prediction model. To accomplish these goals, I will build upon the foundation I developed when earning my Master's Degree in Public Health and during my initial training in the PhD program in the Department of Health Studies. Although my training to date has provided me with a strong background in epidemiology and biostatistics, further advanced training in biostatistics is crucial for my development into a successful independent researcher. An integrated program of didactic coursework, seminars, research activities, and conference participation will span the duration of the award. By accomplishing my three short- term goals, I will develop unique skills that will allow me to become a successful independent researcher. Specifically, the expertise I will gain in prediction model development, implementation, and simulation modeling can be applied not only to IHCA research but also to other areas of critical care medicine. In addition, completion of these goals will result in a validated IHCA prediction model that I will study in future implementation and cost-effectiveness studies and will serve as a basis for future R01-level grant submissions. PUBLIC HEALTH RELEVANCE: Over 200,000 in-hospital cardiac arrests occur in the United States each year, and studies suggest that many of these events may be preventable if the clinical warning signs can be identified and acted upon quickly. However, the vast majority of tools used to identify patients at high risk of cardiac arrest were created subjectively and have limited accuracy. Development of a statistically derived risk tool is essential to detect at- risk patients accurately and early in order to provide the best opportunity to improve patient outcomes and reduce preventable in-hospital death.",Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data,8788442,K08HL121080,"['Adult', 'Applications Grants', 'Area', 'Award', 'Biological Neural Networks', 'Biometry', 'Brain', 'Case-Control Studies', 'Categories', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Critical Care', 'Data', 'Data Set', 'Databases', 'Decision Trees', 'Deterioration', 'Development', 'Diastolic blood pressure', 'Doctor of Philosophy', 'Early Diagnosis', 'Electronic Health Record', 'Emergency Situation', 'Ensure', 'Epidemiology', 'Event', 'Foundations', 'Frequencies', 'Future', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Heart Arrest', 'Hospitalization', 'Hospitals', 'Hour', 'Hylobates Genus', 'Individual', 'Intensive Care', 'Intervention', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Life', 'Literature', 'Lung', 'Machine Learning', 'Master&apos', 's Degree', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Outcome', 'Outcomes Research', 'Patient Discharge', 'Patient risk', 'Patients', 'Physicians', 'Procedures', 'Public Health', 'Publishing', 'Receiver Operating Characteristics', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Rest', 'Resuscitation', 'Risk', 'Scientist', 'Sensitivity and Specificity', 'Social Sciences', 'Statistical Methods', 'Statistical Models', 'Supervision', 'Survival Analysis', 'Techniques', 'Testing', 'Time', 'Training', 'Uncertainty', 'United States', 'Update', 'Validation', 'Work', 'adverse outcome', 'base', 'career', 'cost effectiveness', 'design', 'evidence base', 'high risk', 'improved', 'model development', 'models and simulation', 'mortality', 'multidisciplinary', 'programs', 'simulation', 'skills', 'statistics', 'success', 'symposium', 'tool', 'ward']",NHLBI,UNIVERSITY OF CHICAGO,K08,2015,129546,246330700,-0.01957622304176019
"Rapid Detection of Common Failure Modes for Knee Prosthetics ﻿    DESCRIPTION (provided by applicant):  Bruin Biometrics' proposes to develop the Joint Health Monitor (JHM), an innovative low risk device capable of detecting artificial joint implant failure prior to all currently available diagnostic devices. Artificial joint replacements have demonstrated excellent clinical performance. However, failures do occur due to a multitude of factors including, aseptic loosening, wear, dislocation, osteolysis, and adverse local tissue reactions (ALTR), including pseudotumors and extensive tissue damage. Recent catastrophic failures associated with specific implant designs, and increasing concern over the severe clinical consequences of ALTR, have raised the attention of both consumer advocacy groups and regulatory agencies, in the US and abroad. It is evident that current diagnostic tools have failed to predict early enough complications associated with some implant designs and/or patient's characteristics. Rather than be predictive, current diagnostic methods usually do not detect joint degradation until bone and tissue damage have already occurred, increasing morbidity, mortality and severity of revision surgeries. Bruin Biometrics has developed an innovative monitoring device that will allow effective monitoring of an artificial joint functionality and eary detection of at risk patients, implant designs and reduction of the number or at least the severity of revision surgeries. Early detection should also enable physicians to prescribe exercise regimens, dietary supplements, medication, early revision surgery or other measures to protect against further damage. Moreover, the existence of an effective monitoring device would provide invaluable feedback, enabling unprecedented quantification and evaluation of treatment efficacy including drugs. The objectives of this proposal are to demonstrate the technical feasibility of this device to detect specific failure modes. This will be accomplished using an in vitro test rig set up and an in vivo human subject pilot study. Our overall goal is to rapidly delier a wearable system capable of monitoring the status of artificial joints and provide surgeons with more accurate and earlier diagnoses.         PUBLIC HEALTH RELEVANCE:  Hip and Knee replacement procedures will continue to increase dramatically over the next twenty years and the rate of revision surgery is expected to remain stable around 17-18%. This will increase the burden on orthopaedic surgeons, operating room capacity, and healthcare cost. In 2007 dollars, this volume of total joint replacement would generate costs exceeding $100 billion, or 1% of the gross domestic product (GDP). If successful, the new monitoring device object of this proposal named ""Joint Health Monitor"" will have an immediate impact on managing joint degradation, reducing complicated revision surgeries and allowing more effective patient surveillance avoiding catastrophic failure; this in turn will increase patient confidence in regulatory agencies and industry.            ",Rapid Detection of Common Failure Modes for Knee Prosthetics,8906609,R43AR067048,"['Acoustics', 'Algorithms', 'Architecture', 'Arithmetic', 'Attention', 'Biometry', 'Bone Tissue', 'Characteristics', 'Classification', 'Clinical', 'Consumer Advocacy', 'Controlled Environment', 'Data', 'Degenerative polyarthritis', 'Dependence', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic radiologic examination', 'Discrimination', 'Dislocations', 'Early Diagnosis', 'Evaluation', 'Exercise', 'Failure', 'Feedback', 'Goals', 'Health', 'Health Care Costs', 'Hip region structure', 'Implant', 'In Vitro', 'Industry', 'Joints', 'Knee', 'Knee Prosthesis', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methodology', 'Methods', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Names', 'Operating Rooms', 'Operative Surgical Procedures', 'Orthopedics', 'Osteolysis', 'Outcome', 'Patient risk', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Pilot Projects', 'Procedures', 'Prosthesis', 'Radiation', 'Reaction', 'Regimen', 'Replacement Arthroplasty', 'Risk', 'Severities', 'Signal Transduction', 'Surgeon', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Treatment Efficacy', 'Trust', 'Visit', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'adverse outcome', 'attenuation', 'base', 'cohort', 'cost', 'design', 'dietary supplements', 'follow-up', 'hip replacement arthroplasty', 'human subject', 'in vitro testing', 'in vivo', 'innovation', 'knee replacement arthroplasty', 'monitoring device', 'mortality', 'public health relevance', 'rapid detection', 'sample fixation', 'tool']",NIAMS,"BRUIN BIOMETRICS, LLC",R43,2015,149685,0,-0.007631422555912821
"Preventable Hospitalization in Dementia: The Impact of Neuropsychiatric Symptoms DESCRIPTION (provided by applicant): Older adults with dementia are at increased risk of hospitalization when compared to adults without dementia of similar age and medical comorbidity. The increased risk of hospitalization extends to potentially preventable hospitalization (PPH) for conditions such as a urinary tract infection or asthma exacerbation, suggesting difficulty in outpatient management of patients with dementia. Neuropsychiatric symptoms (NPS) of dementia such as agitation or delusions likely account for a significant amount of this risk, given their prevalence and potential to cause caregiver distress. While there are effective interventions for patients and caregivers to reduce NPS, the profile of patients that could benefit the most from intervention, therefore reducing their hospitalization risk, is unknown. Through the coordinated program of mentorship, didactics, and research that I propose, I will develop the advanced skills to derive and apply administrative, claims, and clinical encounter data to prospectively identify those patients with dementia at highest risk for hospitalization. Development of this patient-level risk phenotype means that future interventions to reduce hospitalization can then be prospectively matched to the patients most likely to benefit, a development of critical public health importance given both financial and geriatric work force constraints.  Over the next four years, my short-term training goals include: (1) address gaps in my formal research training, specifically: (a) to conduct observational analyses using large-scale claims and administrative data; (b) to derive clinical data from the electronic health record using natural language processing; and (c) to apply advanced methods of data analysis for risk prediction; (2) train in presentations, manuscript writing, and grantsmanship that culminate with a R01 proposal; (3) establish further connections with potential collaborators in the University of Michigan (UM) Pepper Center and broader community of aging researchers, national geriatrics and geriatric psychiatry communities, and the Beeson Scholar community; and (4) engage in leadership development with an emphasis on skills to lead a research team, mentor junior investigators, and communicate findings in research and clinical care settings.  These short-term goals will be paired with research aims that focus on elaborating the PPH risk profile for patients with dementia. Such research objectives can only be achieved when: (1) full clinical characteristics are available for the at-risk (i.e., non-hospitalized) population, includig (2) NPS data, which are rarely captured in standard administrative claims data. These criteria are uniquely met in the Veterans Affairs healthcare system, which has one of the nation's most advanced electronic health records (EHR). Using a national dementia case repository (N=269,565) from which I will draw matched cases (patients with dementia + PPH) and controls (non-hospitalized patients with dementia). Aim 1 will use claims and administrative data to explore patient, treatment, and facility risk factors associated with PPH. Aim 2 will use natural language processing to derive NPS from EHR clinical encounter notes and then characterize the association of NPS with PPH. Using the risk phenotype described in Aims 1 and 2, Aim 3 will develop logistic risk-prediction models to prospectively identify patients with dementia at highest risk for PPH. In subsequent grant proposals I will validate this risk- prediction model in other healthcare systems and prospectively pair the assessment tool with an evidence- based dementia intervention to reduce hospitalization.  My long-term career goals are to: (1) establish myself as independent investigator and national leader in geriatric mental health services research; (2) develop a programmatic line of funded health services research that develops risk-stratification models for late-life mental health and cognitive disorders; (3) translate knowledge from these research endeavors to improve the targeting and impact of future interventions research and health system delivery strategies; and (4) contribute broadly to the care of older adults by training and mentoring future clinical researchers in late-life mental health disorders. I am an Assistant Professor and geriatric psychiatrist at the University of Michigan, where I am also currently completing a MSc in Health and Healthcare Research, which provides an excellent background in health services research for clinicians. With this combination of clinical expertise and foundational training in health services research, I am uniquely qualified to undertake the advanced training activities outlined in this proposal, while UM affords the ideal environment in which to pursue this work. My primary mentor (Helen Kales, MD) and co-mentor (Frederic Blow, PhD) are national leaders in geriatric mental health who have used observational data to answer questions of national significance. My Advisory Panel includes Constantine Lyketsos, MD, MHS, an internationally-recognized expert in NPS and dementia care, and Kenneth Langa, MD, PhD, an internist, former Beeson Scholar, and renowned expert in using survey and secondary data to inform our understanding of dementia. Consultants include David Hanauer, MD, MS, an expert in bioinformatics and natural language processing, and Rodney Hayward, MD, a leader in risk assessment and intervention- targeting. My advisory team paired with resources of Michigan's Pepper Center, CTSA, and multi-disciplinary Institute for Healthcare Policy and Innovation make this the ideal environment in which to complete the proposed training activities. PUBLIC HEALTH RELEVANCE: Although hospitalization can negatively impact patients with dementia, we know very little about the specific risk factors associated with the chance of being hospitalized. It is important to understand what contributes to this risk, such as the behavior changes that accompany dementia, in order to identify those patients and caregivers that could benefit most from an intervention to avoid or reduce hospitalization. Given the rapidly rising numbers of patients with dementia, reducing potentially preventable hospitalization could have an enormous impact on public health.",Preventable Hospitalization in Dementia: The Impact of Neuropsychiatric Symptoms,8911756,K08AG048321,"['Accounting', 'Address', 'Adult', 'Age', 'Aggressive behavior', 'Aging', 'Agitation', 'Antipsychotic Agents', 'Applications Grants', 'Asthma', 'Attention', 'Benzodiazepines', 'Bioinformatics', 'Capsicum', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Code', 'Cognition Disorders', 'Communities', 'Comorbidity', 'Data', 'Data Analyses', 'Delusions', 'Dementia', 'Development', 'Diagnosis', 'Distress', 'Doctor of Philosophy', 'Elderly', 'Electronic Health Record', 'Emergency Care', 'Environment', 'Foundations', 'Funding', 'Future', 'Geriatric Psychiatry', 'Geriatrics', 'Goals', 'Health', 'Health Policy', 'Health Services Research', 'Health system', 'Healthcare Systems', 'Hospitalization', 'Individual', 'Institutes', 'Institutionalization', 'Internist', 'Intervention', 'Intervention Studies', 'Intervention Trial', 'Kale - dietary', 'Knowledge', 'Lead', 'Leadership', 'Light', 'Literature', 'Location', 'Logistic Regressions', 'Logistics', 'Manuscripts', 'Medical', 'Mental Health', 'Mental Health Services', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Natural Language Processing', 'Outpatients', 'Patient Care', 'Patient risk', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Prevalence', 'Primary Health Care', 'Provider', 'Psychiatrist', 'Psychotic Disorders', 'Public Health', 'Qualifying', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Rural', 'Signal Transduction', 'Sleeplessness', 'Source', 'Stratification', 'Surveys', 'Symptoms', 'Training', 'Training Activity', 'Translating', 'Universities', 'Urinary tract infection', 'Validation', 'Veterans', 'Visit', 'Work', 'Writing', 'abstracting', 'behavior change', 'career', 'case control', 'clinical care', 'design', 'effective intervention', 'evidence base', 'geriatric mental health', 'high risk', 'improved', 'innovation', 'medication compliance', 'meetings', 'neuropsychiatry', 'patient population', 'predictive modeling', 'professor', 'programs', 'repository', 'skills', 'statistics', 'tool']",NIA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K08,2015,175103,641965656,-0.018233232462568888
"Novel whole-genome analysis methods for Alzheimer's risk prediction ﻿    DESCRIPTION (provided by applicant):  Late-onset Alzheimer's Disease (LOAD) affects millions of elderly people in the United States, yet there are no well-established clinical guidelines for assessing a person's relative risk. Accurate assessment of lifetime risk for LOAD would give high-risk individuals the opportunity to undergo regular biomarker screening for signs of disease and to modify environmental risk factors or participate in prospective clinical trials. This Phase I SBIR project aims to develop a risk prediction model for LOAD that meets or exceeds the accuracy standards established in 1998 by the Working Group for Biochemical and Molecular Markers of Alzheimer's Disease. The recent release of whole-genome sequence data from an extensively phenotyped cohort of the Alzheimer's Disease Neuroimaging Initiative creates a unique opportunity to develop the methodology needed to successfully construct such a risk prediction model. The Parabon team will undertake three specific aims in pursuit of the final goal of producing a risk prediction model that can be used in the clinic. First, a novel methodology will be created for analyzing whole-genome sequence data to discover common SNPs, rare variants, and epistatic interactions that significantly associate with LOAD endophenotypes, the specific physiological changes that underlie disease. This will require innovative algorithm and software development, particularly the implementation of multi-objective optimization in our existing evolutionary search algorithm for detecting epistasis. Second, the discovered significant variants will be built into risk prediction models for each endophenotype using state-of-the-art machine learning methods. These models will then be combined into a single predictive model for lifetime risk, which will be validated in an independent cohort from the Alzheimer's Disease Sequencing Project. Finally, to quantify the confidence associated with each prediction made by the model, algorithms and software for calculating confidence intervals will be developed and implemented. Each new prediction will be presented with a measure of confidence to enable clinicians to determine what, if any, intervention is necessary. When these aims have been completed, Parabon will have produced the first clinically relevant genetic risk prediction model for late-onset Alzheimer's Disease, as well as a suite of software that can be used in the development of other diagnostics. In Phase II, we will move beyond the ADNI-supplied endophenotypes, using image processing and deep learning to infer neuroimaging features most relevant to AD diagnoses, as well as work to validate the predictive models in a larger, more diverse cohort across multiple sites.         PUBLIC HEALTH RELEVANCE:  This Phase I SBIR aims to develop a highly accurate predictive model for lifetime risk of late-onset Alzheimer's Disease to enable early identification of high-risk individuals for participation in clinical trials and regular screening for signs of disease. In pursuit of this goal, the Parabon team will develop algorithms and software to build a novel methodology for the analysis of whole-genome sequence data and endophenotype measures from the Alzheimer's Disease Neuroimaging Initiative. This project will produce the first clinically relevant risk prediction model for late-onset Alzheimer's Disease and a suite of software that can be used for the production of diagnostics for other diseases.            ",Novel whole-genome analysis methods for Alzheimer's risk prediction,8904360,R43AG050366,"['Affect', 'Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Biochemical Markers', 'Biological Markers', 'Candidate Disease Gene', 'Cause of Death', 'Clinic', 'Clinical', 'Clinical Trials', 'Computer software', 'Confidence Intervals', 'Data', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Early identification', 'Elderly', 'Environmental Risk Factor', 'Etiology', 'Genetic', 'Genetic Epistasis', 'Genetic Risk', 'Genetic screening method', 'Goals', 'Guidelines', 'Heritability', 'Heterogeneity', 'Incidence', 'Individual', 'Intervention', 'Late Onset Alzheimer Disease', 'Learning', 'Life', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Physiological', 'Presenile Alzheimer Dementia', 'Production', 'Relative Risks', 'Reporting', 'Risk', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Site', 'Small Business Innovation Research Grant', 'Testing', 'United States', 'Validation', 'Variant', 'Work', 'base', 'clinically relevant', 'cohort', 'cost', 'disease diagnosis', 'endophenotype', 'genome analysis', 'genome sequencing', 'genome-wide', 'genome-wide analysis', 'high risk', 'image processing', 'imaging biomarker', 'improved', 'innovation', 'lifetime risk', 'meetings', 'molecular marker', 'neuroimaging', 'novel', 'predictive modeling', 'prospective', 'public health relevance', 'rare variant', 'screening', 'software development', 'working group']",NIA,"PARABON NANOLABS, INC.",R43,2015,179819,0,-0.06411506138542766
"Face De-Identification for Research and Clinical Use DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis. PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.",Face De-Identification for Research and Clinical Use,8908047,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Health', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'sex', 'social stigma', 'targeted imaging', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2015,193512,30434536,-0.054974920789662166
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing.         PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.                ",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8826350,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Outcome', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'neovascular', 'novel', 'programs', 'public health relevance', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2015,215393,807432003,-0.012968159131565857
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9044336,K01ES026833,"['Affect', 'Blood', 'Blood Vessels', 'Blood flow', 'Brain', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrum', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Health', 'Healthcare', 'Hemorrhage', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Rupture', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'injured', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'standard of care', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2015,216241,558628098,-0.025432610564921375
"Calculation of Percent Body Fat by Analyzing Virtual Body Models ﻿    DESCRIPTION (provided by applicant):  Excess body fat is a key underlying factor in the development of numerous chronic diseases, including type II diabetes, heart disease, stroke, and cancer. The AMA recently declared that obesity, itself, is a disease. Most epidemiologic studies utilize Body Mass Index (BMI) to classify people as underweight, normal, overweight, or obese because it is a convenient and simple method that has been shown to correlate with disease risk. Since the majority of the health risks associated with obesity are more directly linked to an overabundance of body fat than weight, measuring body fat is essential for more precise guidelines. However, accurate methods of assessing body fat are expensive, inconvenient, and require immobile equipment. Consequently, the AMA has called for more cost effective and convenient methods to assess body composition to assist doctors in their assessment and treatment. Virtual modeling of humans in particular has provided ways to scan and analyze the body and its motion. Supervised Machine Learning (SML), a sub-field of artificial intelligence, has made great progress in taking measured data to infer new relationships. It is our belief that virtual modeling and SML can provide the techniques necessary to conveniently and accurately calculate the percentage of body fat (%BF) and to provide new tools in treating obesity based on body shapes. The project will develop a system that uses commercially available depth cameras such as the Microsoft Kinect(r) to capture the surface of the human body. This will be accomplished by developing a new algorithm to perform deformable registration of several RGB-Depth views of the body. A new algorithm that uses SML will be developed to calculate percentage body fat using the surface data. The system will be trained and validated by collecting data from a number of subjects. The surface captured will be used to explore the role of visual body representation in motivation and adherence. The developed systems can be implemented in clinical or personal settings and be utilized as a public health research tool and deployed widely given the low-cost of the hardware required. In addition to the immediate impact that the system will have on managing obesity, the project will have a broad impact on a number of areas. A large database of such shapes captured over time may lead to ways to predict how an individual's body shape will change given a particular intervention. Certain medical conditions that result in body shape change, such as those involving lymphatic circulations, may be diagnosed and tracked more easily. Growth patterns of children may be tracked by change of body shapes. Further research can be conducted to determine the effect of body shape on %BF using data mining techniques.         PUBLIC HEALTH RELEVANCE: The project will develop a new method to capture the 3D surface and shape of a human body and a new method to use these data to calculate percent body fat. By making these tools widely available and economical, the proposed approach has the potential for major contributions in the assessment and treatment of obesity.        ",Calculation of Percent Body Fat by Analyzing Virtual Body Models,8970310,R21HL124443,"['Adherence', 'Age', 'Air', 'Algorithms', 'Area', 'Artificial Intelligence', 'Behavior Therapy', 'Belief', 'Body Composition', 'Body Size', 'Body Surface', 'Body Weight decreased', 'Body fat', 'Body mass index', 'Child', 'Chronic Disease', 'Client', 'Clinical', 'Clinical Research', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Epidemiologic Studies', 'Equipment', 'Fatty acid glycerol esters', 'Future', 'Goals', 'Growth', 'Guidelines', 'Health', 'Health Care Costs', 'Heart Diseases', 'Human', 'Human body', 'Imagery', 'Incentives', 'Individual', 'Intervention', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Motivation', 'Muscle', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Overweight', 'Participant', 'Patients', 'Pattern', 'Perception', 'Plethysmography', 'Population Study', 'Public Health', 'Reporting', 'Research', 'Risk', 'Role', 'Scanning', 'Self Perception', 'Series', 'Shapes', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Underweight', 'Variant', 'Visual', 'Water', 'Weight', 'Weights and Measures', 'base', 'body density', 'body volume', 'cost', 'cost effective', 'data mining', 'density', 'disorder risk', 'lymphatic circulation', 'novel', 'novel strategies', 'obesity treatment', 'preference', 'public health relevance', 'public health research', 'reconstruction', 'sex', 'tool', 'virtual', 'weight loss intervention']",NHLBI,GEORGE WASHINGTON UNIVERSITY,R21,2015,227680,86807134,0.009916107016058709
"Machine learning with generative mixture models for fetal monitoring     DESCRIPTION (provided by applicant): For many years, there has been a concerted effort to automate the analysis of fetal heart rate (FHR) rhythms. However, despite significant advances in biomedical signal analysis, there has not been any significant improvement in automated decision support systems. FHR monitoring is now ubiquitous throughout delivery rooms, especially using the non-invasive Doppler monitor, but also using the fetal scalp electrode. Physician classification of fetal heart rate patterns is known to be a non-trivial problem because of significant inter and intra-observer variability of diagnosis. This has led to a marked increase in the number of caesarean deliveries, thereby increasing risk to the fetus and mother in many cases. This has further motivated the machine learning community to automate the classification procedure in the interest of accuracy and consistency as well as robustness with respect to noise. Usual approaches to this involve some type of supervised classification procedure, where the algorithm output on training data is compared with a ""gold-standard"" physician classification, followed by testing and validation on new datasets. However, since physician classification can be unreliable in the presence of the aforementioned diagnostic variability, as well as significant tracing noise, we propose the use of unsupervised algorithms to cluster FHR data records into clinically useful categories. We use nonparametric Bayes theory and Markov-time-dependence models for the evolution of feature sequences to propose methods that will achieve improved accuracy. The methods involve extraction of feature sequences from FHR time series data, which are modeled as samples from finite or infinite Dirichlet mixture models. We then use Gibbs sampling to obtain the cluster probabilities for each dataset. Clustering outcomes are compared against direct physician diagnosis and our current results are seen to be in broad agreement with them, while still giving new information on the character of different sub-groups of FHR records. With the proposed research, further gains in classification performance will be made.         PUBLIC HEALTH RELEVANCE: Fetal heart rate monitoring is now commonly used during childbirth and, at present, physicians read and interpret these data to classify fetal heart rate patterns and make sure that the baby is not in distress during the course of labor. However, there is great variability in how individual doctors interpret the tracings and this has led increases in the number of caesarean deliveries, thereby potentially increasing risk to both mothers and babies. Thus there has been a concerted effort from the machine learning community to develop an accurate automatic reading and classification procedure so that correct interpretation of fetal heart rates during labor is more diagnostic and consistent.            ",Machine learning with generative mixture models for fetal monitoring,8816208,R21HD080025,"['Agreement', 'Algorithms', 'Apgar Score', 'Bayesian Method', 'Behavioral', 'Birth', 'Categories', 'Childbirth', 'Classification', 'Clinical', 'Communities', 'Consensus', 'Data', 'Data Set', 'Decision Support Systems', 'Delivery Rooms', 'Dependence', 'Dependency', 'Diagnosis', 'Diagnostic', 'Distress', 'Electrodes', 'Evolution', 'Feedback', 'Fetal Heart', 'Fetal Heart Rate', 'Fetal Monitoring', 'Fetus', 'Freedom', 'Gold', 'Individual', 'Intraobserver Variability', 'Joints', 'Knowledge', 'Label', 'Learning', 'Litigation', 'Machine Learning', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Monte Carlo Method', 'Mothers', 'Motivation', 'Noise', 'Outcome', 'Outcome Measure', 'Output', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Probability', 'Procedures', 'Process', 'Reading', 'Records', 'Research', 'Risk', 'Sampling', 'Scalp structure', 'Series', 'Signal Transduction', 'System', 'Testing', 'Time', 'Training', 'Umbilical cord structure', 'Uncertainty', 'Uterine Contraction', 'Validation', 'Work', 'base', 'cost', 'fetal', 'improved', 'interest', 'pressure', 'public health relevance', 'stem', 'theories', 'vector']",NICHD,STATE UNIVERSITY NEW YORK STONY BROOK,R21,2015,234571,77607041,-0.002039926777487037
"Novel Tree-based Statistical Methods for Cancer Risk Prediction     DESCRIPTION (provided by applicant): The contradiction of early cancer detection is that while some benefit others receive a detrimental diagnosis. A definitive example is mammography and ductal carcinoma in situ (DCIS), a noninvasive breast cancer. DCIS, which most frequently presents as a non-palpable lesion, was rarely detected before the advent of modern mammography. Since 1983 there has been a 290% increase in DCIS incidence in women under 50 and 500% in those over 50. Given that only 5-10% of DCIS cases progress to invasive cancer with a 10-year mortality rate of 1-2%, DCIS experts suggest breast conservation for the majority of patients. However, these women continue to be overtreated with mastectomy and radiation, at rates comparable to those with invasive cancer. The inability to discern those at low vs. high risk is due in part to non-reproducible study results as well as inadequate statistical methods for risk prediction and validation.  We have collected a population-based DCIS cohort with the goal of delineating those women least likely to recur with invasive cancer and, hence, appropriate candidates for less aggressive treatments. Recently we established risk indices and published the corresponding absolute risk estimates for type of recurrence. However, two features of the study design, namely the presence of competing risks and the use of a stratified case-cohort design, constrained us to using crude empirical methods for analysis and left us unable to validate the clinical utility of our models. The overarching goal of this proposal is to develop a unified, principled statistical framework for building, selecting, and evaluating clinically relevant risk indices, permitting refinement and validation of existing risk prediction models in our DCIS study as well as beyond.  We face multiple challenges including how to objectively build risk indices with relevant variables; how to estimate the corresponding risks (competing or not) in various subsample study designs; and, how to validate the resulting risk prediction models. Recently, we developed partDSA, a tree-based method which affords tremendous flexibility in building predictive models and provides an ideal foundation for developing a clinician- friendly tool for accurate stratification and risk prediction. In its curret form, partDSA is unable to estimate absolute risk in the presence of competing risks accounting for subsample study designs. Here we extend partDSA for such clinically relevant scenarios (Aim 1). We also propose aggregate learning for risk prediction to increase prediction accuracy and subsequently to build more stable but easily interpretable risk models (Aim 2). Finally, we propose the necessary methods for validating the resulting models (Aim 3).  Our proposal has two immediate public health benefits: first, these novel statistical methods will result in a clinician-friendly, publicly available tool for accurate risk prediction, stratification and validaion in numerous clinical settings; second, current DCIS risk models will be refined and validated with the expectation of better delineating those at low risk, hence strong candidates for conservative treatments including active surveillance.          Our proposal has two public health components: first, our novel statistical methods will provide a clinician- friendly, publicly available tool for accurate isk prediction, stratification and validation in numerous clinical settings; second, current ductal carcinoma in situ risk models will be refined and validated, helping facilitate the decision-making process faced by patients and their clinicians.            ",Novel Tree-based Statistical Methods for Cancer Risk Prediction,8844220,R01CA163687,"['Accounting', 'Anxiety', 'Breast', 'Carcinoma', 'Clinical', 'Code', 'Cohort Studies', 'Communities', 'Computer software', 'Decision Making', 'Diagnosis', 'Epidemiology', 'Face', 'Face Processing', 'Foundations', 'Goals', 'Health Benefit', 'Incidence', 'Individual', 'Intervention Studies', 'Label', 'Learning', 'Left', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Mastectomy', 'Measures', 'Methods', 'Modeling', 'Noninfiltrating Intraductal Carcinoma', 'Outcome', 'Patients', 'Performance', 'Public Health', 'Publishing', 'Radiation', 'Radiation therapy', 'Recurrence', 'Research Design', 'Risk', 'Risk Estimate', 'Screening for cancer', 'Statistical Methods', 'Stratification', 'Techniques', 'Trees', 'Validation', 'Woman', 'Work', 'anticancer research', 'base', 'breast lumpectomy', 'cancer risk', 'clinically relevant', 'cohort', 'design', 'expectation', 'experience', 'flexibility', 'high risk', 'indexing', 'loss of function', 'malignant breast neoplasm', 'model building', 'mortality', 'novel', 'open source', 'population based', 'predictive modeling', 'prevent', 'programs', 'research study', 'simulation', 'tool']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2015,324939,685608202,-0.0474938942903044
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8842639,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2015,332955,193405667,-0.0043559064542817594
"Antecedent Medical Conditions and Medications: Associations with the Risk and Prognosis ALS ﻿    DESCRIPTION (provided by applicant): ALS affects people in middle to late ages, during a time of life where it is common to suffer from more than one health problem, yet there is little understanding of the effect of chronic medical conditions and medication use on susceptibility to ALS. There is mounting concern and recent evidence that certain medical conditions and medications are associated with an increased risk of developing ALS, while other conditions and medications appear to be inversely associated with ALS risk. We propose to investigate the role of hyperlipidemia, diabetes, autoimmune diseases, as well as the drugs used to treat these disorders, as both risk and prognostic factors for ALS. This study has three specific aims: Aim 1, to investigate the association between antecedent medical conditions and the risk of developing ALS; Aim 2, to examine the relationship between certain classes of medication and the risk of developing ALS; and Aim 3, to determine whether medical conditions or medications present at diagnosis of ALS adversely or positively affect survival with ALS. We will assemble a retrospective cohort of Medicare beneficiaries who were continuously enrolled in fee-for-service Medicare (Parts A, B and D) during the years 2006 through 2014. To address aims 1 and 2, we will conduct a nested case-control study to identify newly diagnosed (incident) patients with ALS in this cohort between 2008 and 2014 using a modified version of the case definition algorithm used by the National ALS Registry. We expect to identify 11,000 incident ALS cases. Using incidence density sampling, ten age- and sex-matched controls will be randomly chosen for each case from among Medicare beneficiaries who entered the Medicare cohort in the same year as the case, but had who had no codes for ALS, MND or closely related conditions prior to their matched cases' diagnosis dates. We will use Medicare inpatient, outpatient, and laboratory health claims to document the occurrence of metabolic, cardiovascular, and autoimmune conditions among the study subjects both before and after the diagnosis of ALS. The availability of Part D (pharmaceutical) claims for Medicare beneficiaries from 2006 onward will provide the opportunity to examine the association of commonly used medications with the risk and prognosis of ALS. We will use conditional logistic regression analyses to identify premorbid medical conditions and medications associated with the risk of developing ALS. To address specific aim 3, we will link the data from our incident ALS case group to mortality data and conduct survival analyses to determine whether antecedent medical conditions and medications present at diagnosis are associated with either shortened or prolonged survival with ALS. We will use survival analysis to determine whether there is an association between these conditions/medications and survival with ALS. This study will contribute significantly to the understanding of the role that metabolic factors, hyperlipidemia, cardiovascular disease and autoimmunity play in the etiology and prognosis of ALS, and could lead to the development of new preventive or therapeutic interventions to prolong survival in ALS patients.         PUBLIC HEALTH RELEVANCE: Amyotrophic lateral sclerosis (ALS: also known as Lou Gehrig's disease) is an adult-onset neuromuscular disorder that is the third most common neurodegenerative disease of aging (after Alzheimer's and Parkinson's diseases). It is critically important to identify modifiable risk factors present prior to diagnosis that affect the risk of developing ALS, and to also identify factors that are associated with the length of survival with this uniformly fatal disease. We hope that this study will identify modifiable risk factors that pu people at risk for ALS so that we can prevent this disabling disease, and we believe that studying the factors that influence length of survival with ALS will lead to the development of new preventive or therapeutic interventions to prolong survival among patients with ALS.            ",Antecedent Medical Conditions and Medications: Associations with the Risk and Prognosis ALS,9048445,R01TS000249,[' '],ATSDR,STANFORD UNIVERSITY,R01,2015,400000,560644462,-0.008223663954817712
"Predicting Hip Fracture Using a Biomechanical Approach DESCRIPTION (provided by applicant): Hip fractures are a significant cause of disability and mortality in older persons. The most common tool for diagnosis of osteoporosis and prediction of fracture risk is bone mineral density (BMD) measured by dual- energy X-ray absorptiometry. Yet, up to half of individuals suffering a hip fracture do not have osteoporosis by BMD testing; thus alternative approaches to fracture risk assessment are needed. This underscores the importance of looking for additional contributors to fracture risk, such as reduced soft tissue thickness at the trochanter, which attenuates the fall forces that may lead to fracture. According to biomechanical principles, when the ratio of applied force to bone strength, (termed the 'Factor-of-Risk'), exceeds one, a fracture will occur. Two previous studies have examined the Factor-of-Risk along with trochanteric soft tissue thickness but had only small numbers of hip fractures, and conflicting results. To better understand the factors associated with hip fracture, we propose to use a biomechanical approach to assess hip fracture risk that includes both estimated forces applied to the hip during a sideways fall as well as the strength of the proximal femur. The specific goal is to investigate the contribution of trochanteric soft tissue thickness t hip fracture risk, and to include this in the biomechanical Factor-of-Risk model. We hypothesize these factors predict hip fracture, and further that the factor-of-risk prediction of hip fracture isk will prove better than BMD assessment alone and better than the World Health Organization FRAX tool. We will identify prospectively ascertained hip fracture cases from three cohorts (Framingham Study, MrOS, Rancho Bernardo Study) and from each cohort also select up to four sex- and age-matched (within 3-years) non-fracture cohort members as controls, using the case-cohort study design to increase efficiency. Soft tissue thickness in 2,435 individuals will be assess on whole body DXA scans obtained at the earliest time in each cohort before any subsequent hip fracture occurred. Relative risks will be assessed as odds ratios using conditional logistic regression. This study has potential to significantly alter the way hip fractue risk is currently being assessed, and thus how patients are selected for drug therapy. PUBLIC HEALTH RELEVANCE: The most common tool to diagnose osteoporosis/predict hip fracture risk is bone density testing, and yet, up to half of adults suffering a hip fracture do no have osteoporosis by this test; thus alternative approaches to fracture risk assessment are needed. We will investigate the role of trochanteric soft tissue thickness to hip fracture risk, an include this in the biomechanical Factor-of-Risk model, to examine if they will predict hip fracture and further do so better than currently available prediction tools, providing new public health insights",Predicting Hip Fracture Using a Biomechanical Approach,8829750,R01AR060816,"['Adrenal Cortex Hormones', 'Adult', 'Age', 'Area', 'Attention', 'Attenuated', 'Biomechanics', 'Bone Density', 'Clinical', 'Cohort Studies', 'Conflict (Psychology)', 'Data', 'Diagnosis', 'Dual-Energy X-Ray Absorptiometry', 'Elderly', 'Evaluation', 'Failure', 'Femur', 'Fracture', 'Goals', 'Gold', 'Health', 'Height', 'Hip Fractures', 'Hip region structure', 'Incidence', 'Individual', 'Lead', 'Logistic Regressions', 'Measurement', 'Measures', 'Menopause', 'Methods', 'Modeling', 'Odds Ratio', 'Osteoporosis', 'Patients', 'Pharmacotherapy', 'Predictive Value', 'Public Health', 'Publishing', 'Recording of previous events', 'Relative Risks', 'Research Design', 'Risk', 'Risk Assessment', 'Risk Factors', 'Role', 'Scanning', 'Smoking Status', 'Surface', 'Testing', 'Thick', 'Time', 'Trochanters', 'Weight', 'Woman', 'Work', 'World Health Organization', 'absorption', 'base', 'bone strength', 'cohort', 'diagnosis standard', 'disability', 'falls', 'hip bone', 'improved', 'insight', 'member', 'men', 'mortality', 'osteoporosis with pathological fracture', 'sex', 'soft tissue', 'tool']",NIAMS,HEBREW REHABILITATION CENTER FOR AGED,R01,2015,473892,10587954,-0.011922047005883209
"Geometric Surrogates for Clinical Management of Abdominal Aortic Aneurysms ﻿    DESCRIPTION (provided by applicant): This proposal will investigate the following hypothesis: that the quantification of geometric surrogates, which predict the ensuing peak wall rupture risk index (PWRRI), will provide an improved estimate of aneurysm rupture risk compared to the clinical standard of maximum aneurysm diameter. We thus propose the highly innovative use of both radiological and non-radiological clinical imaging to develop a computational tool that can assess AAA risk of rupture with greater accuracy than the current clinical standard. Such a tool will allow the accurate quantification of individual AAA geometry to achieve the main goal of the study, which is to identify the patient-specific AAA geometry characteristics that are surrogates for patient-specific PWRRI. In the proposed approach, we will first compute a truly individualized PWRRI based on an innovative method called image-based Vascular Mechanical Characterization technology (iV-MeCh). The geometry characteristics highly correlated with PWRRI will be considered the surrogates of this biomechanics-based index. A second phase of the study will be the validation of the surrogates with actual clinical outcomes, which will yield the accurate predictors of rupture. This approach, devoid of complex finite element modeling and based on a fast, nearly automated computational tool for geometry quantification, would provide an exceptional rationale for the need for surgical intervention and be of major clinical significance. Therefore, the following specific aims are to be completed during the project period to address the aforementioned hypothesis: (1) Validate iV-MeCh for estimating patient-specific spatio-temporal AAA wall stress; (2) Calculate individual PWRRI using iV-MeCh for high and low risk of rupture AAA; (3) Identify the individual geometry characteristics that are surrogates of PWRRI; and (4) Assess the clinical significance of geometric surrogates for the prediction of AAA rupture risk. The primary outcome of this research will be the ability to disambiguate or demystify rupture risk in AAA for which the standard of care (maximum diameter) is not an accurate metric for assessing their at-risk condition. The geometric surrogates of PWRRI are hypothesized to reduce false positives and false negatives compared to the conventional maximum diameter cut-off for recommending elective repair. In addition, PWRRI is predicted by means of a new, novel technique (iV-MeCh), which estimates wall stress in aneurysms by means of non-radiological clinical imaging and without the use of constitutive soft tissue mechanics.         PUBLIC HEALTH RELEVANCE: This award will enable the validation of computational tools for non-invasively predicting the at-risk condition of patients with abdominal aortic aneurysms (AAAs) based on the assessment of aneurysm geometry. This research is expected to impact the clinical management of AAA disease, as well as the pre-surgical planning capabilities of vascular and endovascular aneurysm repair.            ",Geometric Surrogates for Clinical Management of Abdominal Aortic Aneurysms,8888896,R01HL121293,"['Abdominal Aortic Aneurysm', 'Address', 'Aneurysm', 'Award', 'Biomechanics', 'Blood Vessels', 'Caliber', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Complex', 'Consent', 'Data', 'Development', 'Diagnosis', 'Disease', 'Electrocardiogram', 'Elements', 'Foundations', 'Geometry', 'Goals', 'Growth', 'Image', 'Imaging Techniques', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Motion', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Patients', 'Phase', 'Physiological', 'Property', 'Records', 'Recruitment Activity', 'Research', 'Risk', 'Rupture', 'Ruptured Abdominal Aortic Aneurysm', 'Ruptured Aneurysm', 'Spatial Distribution', 'Staging', 'Stress', 'Surgeon', 'Surveillance Program', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Validation', 'X-Ray Computed Tomography', 'base', 'clinically significant', 'computerized tools', 'design', 'high risk', 'improved', 'indexing', 'innovation', 'novel', 'pressure', 'primary outcome', 'prospective', 'public health relevance', 'radiologist', 'repaired', 'soft tissue', 'standard of care', 'tool']",NHLBI,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2015,514370,14847250,0.00486483354108296
"Machine Learning for Identifying Adverse Drug Events ﻿    DESCRIPTION (provided by applicant): Because of the profound effect of adverse drug events (ADEs) on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post-marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA formed the Observational Medical Outcomes Partnership (OMOP) to develop and compare methods for identification of ADEs, and the FDA announced its Sentinel Initiative. Congress created the Reagan Udall Foundation (RUF) for the FDA in response to the FDA's own ""FDA Science and Mission at Risk"" report, and two years ago OMOP activities were incorporated into RUF. As the FDA moves forward with its development of Sentinel, including work on Mini-Sentinel, there is a need for researchers around the country to continue to develop better methods, and better evaluation methodologies for those methods. A robust research community working on algorithms for pharmacosurveillance, using electronic health records (EHRs) and claims databases will provide a substrate of ever-improving methods on which the nation's regulatory pharmacovigilance infrastructure can build. Indeed an important motivation of OMOP and Mini-Sentinel was to spur the development of such a community. Machine learning has attracted widespread attention across a range of disciplines for its ability to construct accurate predictive models. Therefore machine learning is especially appropriate for the problems of ADE identification and prediction: identifying ADEs from observational data, and predicting which patients are most at risk of suffering the identified ADE. Our current award has demonstrated the ability of machine learning to address both of these tasks. It has added to the existing evidence that consideration of temporal ordering of events, such as drug exposure and diagnoses, is critical for accuracy in identification and prediction of ADEs. The proposed work seeks to further improve upon these methods by building on recent advances in the field of machine learning, by our group and by others, in graphical model learning and in explicit modeling of irregularly-sampled temporal data. The latter is especially important because observational health databases, such as EHRs and claims databases, are not simple time series. Patients typically do not come into the clinic at regular intervals and have the same labs, vitals, and other measurements in lock step with one another. Building better ADE detection and prediction algorithms cannot be accomplished simply by machine learning research, even if that research is taking account of related work from relevant parts of computer science, statistics, biostatistics, epidemiology, pharmaco-epidemiology, and clinical research. Better methods are needed also for evaluation, that is, for estimating how well a new algorithm, or a new use of an existing algorithm, will perform at identifying ADEs associated with a new drug on the market, or at predicting which patients are most at risk of that ADE. More research and evaluation is also needed at the systems level: how can we best construct end-to-end pharmacovigilance systems that sit atop a large observational database and flag potential ADEs for human experts to further investigate? What kinds of information and statistics should such a system provide to the human experts?        This renewal will address the following aims: (1) improve upon machine learning methods for identification and prediction of ADEs, taking advantage of synergies between these two distinct tasks; (2) improve upon existing methods for evaluating ADE detection, building on advances in machine learning for information extraction from scientific literature; (3) improve upon existing methods for evaluating ADE prediction, building upon advances in machine learning for automated support of phenotyping and also building upon improved methods for efficiently obtaining expert labeling of borderline examples of a phenotype; and (4) use the methods developed in the first three aims to construct and evaluate an end-to-end pharmacosurveillance system integrated with the Marshfield Clinic EHR Data Warehouse. Machine learning plays a central and unifying role throughout all four aims. Our investigator team consists of machine learning researchers with experience in analysis of clinical, genomic, and natural language data (Page, Natarajan), a leading pharmaco-epidemiologist with expertise in building systems to efficiently obtain expert evaluation and labeling of phenotypes (Hansen), a leader in phenotyping from EHR data (Peissig), and an MD/PhD practicing physician with years of experience and leadership in the study of ADEs (Caldwell). In addition to building on results of the prior award, we will build on our experiences with OMOP, the International Warfarin Pharmacogenetics Consortium, the DARPA Machine Reading Program, and interactions with the FDA.         PUBLIC HEALTH RELEVANCE: Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It also addresses the needs for improved evaluation and integrated systems approaches.            ",Machine Learning for Identifying Adverse Drug Events,8964138,R01GM097618,"['Accounting', 'Address', 'Adverse drug event', 'Algorithms', 'Attention', 'Award', 'Biometry', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Congresses', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Discipline', 'Doctor of Philosophy', 'Drug Exposure', 'Early Diagnosis', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Evaluation Methodology', 'Evaluation Research', 'Event', 'Foundations', 'Genomics', 'Health', 'Human', 'Institute of Medicine (U.S.)', 'International', 'Label', 'Leadership', 'Learning', 'Life', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Markov Chains', 'Measurement', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Motivation', 'Myocardial Infarction', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Physicians', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Priority', 'Risk', 'Role', 'Safety', 'Sampling', 'Science', 'Sentinel', 'Series', 'Serious Adverse Event', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Wisconsin', 'Work', 'base', 'computer science', 'cost', 'data mining', 'experience', 'improved', 'inhibitor/antagonist', 'interest', 'natural language', 'novel', 'patient safety', 'post-market', 'predictive modeling', 'programs', 'public health relevance', 'response', 'statistics']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2015,608132,338121506,-0.009181669640358605
"Transition from Risk Factors to Early HF: Prevalence, Pathogenesis, and Phenomics ﻿    DESCRIPTION (provided by applicant): Heart failure (HF) is a major public health problem: it affects >6 million people in the U.S., it is the #1 cause of hospitalization and readmission in older adults, and 5-year survival after HF hospitalization is a dismal 35%, regardless of underlying ejection fraction (EF). These statistics highlight the urgent need for prevention of HF and better understanding of how and why HF develops in high-risk individuals. However, a critical limitation of prior population-based studies is the ascertainment of incident HF based on hospitalizations for HF and/or signs of overt volume overload. Many older individuals may suffer from early HF: breathlessness, fatigue, and exercise intolerance (without overt volume overload) due to underlying cardiac structure/function abnormalities, typically with a preserved EF (i.e. early HFpEF). Thus, the current epidemiology of HF is most likely missing a major form of prevalent HF. In this ancillary study of the Multi-Ethnic Study of Atherosclerosis (MESA, Year-15 Exam, n=3500), we will define early HF in a contemporary, multi-ethnic, elderly cohort; we will utilize cutting- edge indices of cardiac mechanics and ventricular-arterial interactions, including Lagrangian strain and time- varying pressure-stress analyses; and we will perform novel phenomics analyses to better characterize the interplay of risk factors and cardiac structure/function abnormalities (i.e., multi-dimensional phenotypic signatures) as they relate to early and overt HF. The aims of our study are to: (1) determine the prevalence of early HF using a combination of validated symptom surveys, 6-minute walk test, NTproBNP, and echocardiography, with validation using cardiopulmonary exercise testing (CPEX); (2) better understand the pathophysiology of early HF, particularly HFpEF; and (3) delineate the key phenotypic signatures associated with early and overt HF. The proposed exam will include anthropometry, blood pressure, symptom surveys, functional status (6-minute walk test), physical activity, laboratory measures (NTproBNP, fasting glucose, renal function), and comprehensive echocardiography (with tissue Doppler and speckle-tracking at rest and during physiologic maneuvers) in all participants. In sub-samples we will also measure arterial tonometry, novel biomarkers, and fitness (CPEX). We will utilize the wealth of data collected during the 5 prior MESA exams to perform longitudinal analyses (including latent class trajectory and statistical learning analyses) to determine the extent to which risk factors are associated with early HF, particularly early HFpEF. By the end of our 4-year study, we will accomplish the following key goals, each of which will have a lasting impact on the field of HF: (1) we will establish the prevalence of early HF in the community; (2) we will have a standardized method for the screening/diagnosis of early HFpEF, validated by CPEX, and readily applicable to the clinical setting; (3) we will define novel mechanisms by which risk factors, alone and in combination, relate to abnormalities in cardiac mechanics and ventricular-arterial coupling in the general population; and (4) we will have defined phenotypic signatures of HF development that will inform future clinical trials for HF prevention and treatment.         PUBLIC HEALTH RELEVANCE: Heart failure is a common, expensive, and deadly health problem, especially among the elderly. Unfortunately, once overt heart failure develops it is difficult to treat and results in poor outcomes. Therefore it is critical to determine the relationhip between risk factors and abnormalities in heart structure and function that lead to early forms of heart failure. This project aims to: (1) determine how common early heart failure is in the population; (2) better understand the mechanisms of early heart failure by studying the heart and blood vessels using imaging and laboratory tests; and (3) use ""big data"" techniques to harness the wealth of quantitative data we have collected to determine individuals at highest risk for the development of early heart failure.                ","Transition from Risk Factors to Early HF: Prevalence, Pathogenesis, and Phenomics",8864355,R01HL127028,"['Address', 'Adult', 'Affect', 'Age', 'Air Pollution', 'Ancillary Study', 'Anthropometry', 'Atherosclerosis', 'Big Data', 'Biological Markers', 'Blood Pressure', 'Blood Vessels', 'Cardiac', 'Cardiac Output', 'Cardiopulmonary', 'Cardiovascular system', 'Chronic Kidney Failure', 'Clinical', 'Clinical Trials', 'Code', 'Communities', 'Coronary', 'Coronary Arteriosclerosis', 'Coupling', 'Data', 'Development', 'Diabetes Mellitus', 'Diet', 'Dyspnea', 'EFRAC', 'Early Diagnosis', 'Echocardiography', 'Elderly', 'Electrocardiogram', 'Epidemiologic Studies', 'Epidemiology', 'Ethnic Origin', 'Exercise', 'Exercise stress test', 'Fatigue', 'Functional disorder', 'Future', 'Galectin 3', 'Gender', 'General Population', 'Goals', 'Health', 'Heart', 'Heart Atrium', 'Heart failure', 'Hospitalization', 'Hypertension', 'ICD-9', 'Image', 'Incidence', 'Individual', 'Laboratories', 'Lead', 'Left', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Myocardial', 'Myocardial Infarction', 'Obesity', 'Outcome', 'Outpatients', 'Participant', 'Pathogenesis', 'Patients', 'Phenotype', 'Physical activity', 'Physiological', 'Population', 'Prevalence', 'Prevention', 'Prevention strategy', 'Public Health', 'Race', 'Recruitment Activity', 'Renal function', 'Rest', 'Risk', 'Risk Factors', 'Sampling', 'Spirometry', 'Staging', 'Stress', 'Structure', 'Surveys', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Validation', 'Ventricular', 'Walking', 'Weight', 'aged', 'arterial stiffness', 'arterial tonometry', 'base', 'brachial artery', 'clinical Diagnosis', 'cohort', 'design', 'endothelial dysfunction', 'epidemiology study', 'fasting glucose', 'fitness', 'functional status', 'high risk', 'indexing', 'novel', 'phenomics', 'population based', 'pressure', 'public health relevance', 'screening', 'statistics', 'trend']",NHLBI,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R01,2015,1974550,134382703,0.0069977856261783525
"The Cardiovascular Research Grid DESCRIPTION (provided by applicant):    The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinations of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotating ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and motion that can predict the early presence of developing heart disease in time for therapeutic intervention. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informatics system that allows clinical information to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG. RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8786588,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'High Performance Computing', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Ultrasonography', 'Work', 'base', 'cardiovascular imaging', 'cardiovascular visualization', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2015,2177431,807432003,0.005026015829359994
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,8774800,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Clinical Trials', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Research', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Scientist', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2014,73173,338121506,-0.0001761296559152404
"Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data     DESCRIPTION (provided by applicant): In-hospital cardiac arrest (IHCA) is a significant public health problem, afflicting over 200,000 patients in the United States annually with a mortality rate of approximately 80%. The majority of these patients show signs of clinical deterioration in the hours before the event. This has led to the development of vital sign-based early warning scores designed to detect high-risk patients before IHCA to trigger life-saving interventions. However, the vast majority of these risk scores were created subjectively in individual hospitals and have shown limited accuracy for detecting adverse outcomes. Developing an accurate risk score to detect patients at highest risk of IHCA is essential to decreasing preventable in-hospital death. In my prior work, I completed several studies investigating the accuracy of vital signs for predicting IHCA. These studies, previous literature, and my preliminary data have resulted in the following conclusions: 1) statistically developed risk scores are more accurate than previously published risk scores, 2) multicenter data is needed to create the most accurate and generalizable risk score, 3) additional data, such as laboratory results, will likely improve the accuracy of risk scores, and 4) a cutting-edge method for developing prediction models, called machine learning, may result in more accurate risk scores. Importantly, significant improvement in accuracy leads to better identification of patients at highest risk of IHCA and decreased resource utilization. Therefore, in this grant proposal I aim to develop and validate IHCA prediction models using different statistical techniques in a multicenter database and then estimate the impact of the most accurate risk score using simulation studies. I will do this by firt developing prediction models using classic survival analysis methods (Aim 1a) and machine learning methods, such as neural networks and decision trees (Aim 1b). Then, I will compare the models I develop to the most accurate previously published risk scores in Aim 2. Finally, I will investigate the impact of the most accurate model from Aim 2 on patient outcomes using simulation modeling (Aim 3). Completion of this proposal will result in a validated IHCA risk score that can be implemented in the electronic health record to trigger life- saving interventions to decrease preventable in-hospital death. In addition, this career development award will provide critical data to inform future R01-level awards, including a clinical trial to investigate he impact of the developed prediction model on patient outcomes. I will complete this project under the direct supervision of my mentor (Dr. David Meltzer), co-mentor (Dr. Dana Edelson), and the rest of my advisory team (Drs. Jesse Hall, Robert Gibbons, and Michael Kattan). Together, this multidisciplinary team brings nationally renowned expertise in in-hospital cardiac arrest, outcomes research, critical care, and clinical prediction modeling. In addition, they serve as Chairs of the Section of Hospital Medicine (Dr. Meltzer), Section of Pulmonary and Critical Care (Dr. Hall), and Quantitative Health Sciences at the Cleveland Clinic (Dr. Kattan), and Directors of the Center for Health and the Social Sciences (Dr. Meltzer), Center for Health Statistics (Dr. Gibbons), and Clinical Research for the Emergency Resuscitation Center (Dr. Edelson). The mentorship, expertise, and resources that they provide will ensure my success as I grow into an independent physician-scientist. My career goal is to become an independent critical care outcomes researcher with a focus on developing prediction models for clinical deterioration that will improve patient outcomes. To accomplish this long-term goal, I have three short-term goals: (1) to gain expertise in the development and implementation of clinical prediction models, (2) to create an IHCA prediction model that will identify high-risk patients on the wards to trigger life-saving interventions, and (3) to gain expertise in simulation modeling in order to study the impact of the developed prediction model. To accomplish these goals, I will build upon the foundation I developed when earning my Master's Degree in Public Health and during my initial training in the PhD program in the Department of Health Studies. Although my training to date has provided me with a strong background in epidemiology and biostatistics, further advanced training in biostatistics is crucial for my development into a successful independent researcher. An integrated program of didactic coursework, seminars, research activities, and conference participation will span the duration of the award. By accomplishing my three short- term goals, I will develop unique skills that will allow me to become a successful independent researcher. Specifically, the expertise I will gain in prediction model development, implementation, and simulation modeling can be applied not only to IHCA research but also to other areas of critical care medicine. In addition, completion of these goals will result in a validated IHCA prediction model that I will study in future implementation and cost-effectiveness studies and will serve as a basis for future R01-level grant submissions.         PUBLIC HEALTH RELEVANCE: Over 200,000 in-hospital cardiac arrests occur in the United States each year, and studies suggest that many of these events may be preventable if the clinical warning signs can be identified and acted upon quickly. However, the vast majority of tools used to identify patients at high risk of cardiac arrest were created subjectively and have limited accuracy. Development of a statistically derived risk tool is essential to detect at- risk patients accurately and early in order to provide the best opportunity to improve patient outcomes and reduce preventable in-hospital death.            ",Predicting In-hospital Cardiac Arrest Using Electronic Health Record Data,8617518,K08HL121080,"['Adult', 'Applications Grants', 'Area', 'Award', 'Biological Neural Networks', 'Biometry', 'Brain', 'Case-Control Studies', 'Categories', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Critical Care', 'Data', 'Data Set', 'Databases', 'Decision Trees', 'Deterioration', 'Development', 'Diastolic blood pressure', 'Doctor of Philosophy', 'Early Diagnosis', 'Electronic Health Record', 'Emergency Situation', 'Ensure', 'Epidemiology', 'Event', 'Foundations', 'Frequencies', 'Future', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Heart Arrest', 'Hospitalization', 'Hospitals', 'Hour', 'Hylobates Genus', 'Individual', 'Intensive Care', 'Intervention', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Life', 'Literature', 'Lung', 'Machine Learning', 'Master&apos', 's Degree', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Outcome', 'Outcomes Research', 'Patient Discharge', 'Patients', 'Physicians', 'Procedures', 'Public Health', 'Publishing', 'Receiver Operating Characteristics', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Rest', 'Resuscitation', 'Risk', 'Scientist', 'Sensitivity and Specificity', 'Social Sciences', 'Statistical Methods', 'Statistical Models', 'Supervision', 'Survival Analysis', 'Techniques', 'Testing', 'Time', 'Training', 'Uncertainty', 'United States', 'Update', 'Validation', 'Work', 'adverse outcome', 'base', 'career', 'cost effectiveness', 'design', 'evidence base', 'high risk', 'improved', 'model development', 'models and simulation', 'mortality', 'multidisciplinary', 'programs', 'public health relevance', 'simulation', 'skills', 'statistics', 'success', 'symposium', 'tool', 'ward']",NHLBI,UNIVERSITY OF CHICAGO,K08,2014,129546,246330700,-0.01957622304176019
"Family History, Genes, Environment and G X E Interaction in Predicting RA Risk DESCRIPTION (provided by applicant): Since receiving the K24 award, I have established a successful clinical research and training program in patient-oriented research (POR) in rheumatic disease with a focus on genetic, biomarker, and environmental risk factors for rheumatoid arthritis (RA) and systemic lupus erythematosus (SLE). I continue to have independent grant support, and have mentored 15 new clinical investigators who have published 25 peer- reviewed papers during the K24 period. Three mentees have received NIH K awards and one has received an NIH R01. With renewal of the K24, I would continue to have protected time to devote to this program that has a unique training environment and an array of important POR projects. Genetic and environmental epidemiology studies have produced convincing evidence for multiple alleles and exposures as RA risk factors. A strong gene-environment (GXE) interaction between HLA-DRB1 alleles and smoking has been demonstrated for risk of the immune phenotype of CCP positive RA but not CCP negative RA. As CCP antibodies occur years before RA onset, I hypothesize that this interaction induces anti-citrulline immunity, a critical step in RA pathogenesis. These findings emphasize the need to study genes, environment and immunity with careful phenotyping. Family history encompasses unmeasured genetic and environmental risk, yet is not measured accurately in other studies including those in my research portfolio. Specific aims are to: 1) Maintain and expand my clinical research training program by mentoring new clinical investigators in POR in rheumatic diseases; 2) Enrich my comprehensive POR program to study family history, genetic, and environmental predictors in the etiology of RA using a new collection of RA cases and controls from Partners HealthCare; 2a) Collect family history data and environmental exposure data concerning smoking and reproductive factors on 1,500 RA patients and 4,500 age- and gender-matched controls by utilizing natural language processing (NLP) queries of electronic medical records; 2b: Examine genetic risk factors, environmental risk factors and GXE in predicting immune phenotypes of RA: RA with and without CCP antibodies (CCP?), and RA with and without rheumatoid factor antibodies (RF?); and 2c: Apply this comprehensive risk model to RA cases and controls and to subsets of RA stratified by specific immune phenotypes and stratified by family history of RA and other autoimmune diseases. The proposed study will leverage the NIH funded Informatics for Integrating Biology and the Bedside study that used an advanced informatics infrastructure to extract clinical data on RA diagnostic features through database mining and NLP. A highly specific algorithm was used to identify RA cases and collect samples from cases and controls. The NLP techniques will be used to extract risk factor data from clinical notes. This proposal builds on my strong track record of POR, extending the work to add family history from a new case-control collection, validate data by patient interview, and develop predictive models for risk of RA that can be used to select high risk individuals for future RA prevention trials. Project Narrative  Innovative predictive modeling incorporating family history, genes, environmental exposures, and geneenvironment interactions, is a key step in the progress towards an RA prevention clinical trial.","Family History, Genes, Environment and G X E Interaction in Predicting RA Risk",8664806,K24AR052403,"['Age', 'Algorithms', 'Alleles', 'Antibodies', 'Autoantibodies', 'Autoimmune Diseases', 'Bioinformatics', 'Biology', 'Citrulline', 'Classification', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Collection', 'Computerized Medical Record', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Environment', 'Environmental Epidemiology', 'Environmental Exposure', 'Environmental Risk Factor', 'Epidemiologic Studies', 'Epidemiology', 'Etiology', 'Exogenous Hormone Therapy', 'Family', 'Family Study', 'Family history of', 'Female', 'First Degree Relative', 'Funding', 'Future', 'Gender', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Grant', 'HLA-DRB1', 'Healthcare', 'ICD-9', 'Immune', 'Immunity', 'Incidence', 'Individual', 'Informatics', 'Institution', 'Interview', 'K-Series Research Career Programs', 'Laboratories', 'Lead', 'Measures', 'Mentors', 'Meta-Analysis', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Mining', 'Modeling', 'Natural Language Processing', 'PTPN22 gene', 'Paper', 'Pathogenesis', 'Patients', 'Peer Review', 'Phenotype', 'Pollution', 'Prevention', 'Publishing', 'Recording of previous events', 'Records', 'Reproductive History', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Research Training', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatoid Factor', 'Risk', 'Risk Factors', 'STAT4 gene', 'Sampling', 'Siblings', 'Smoking', 'Sushi Domain', 'System', 'Systemic Lupus Erythematosus', 'TNF receptor-associated factor 1', 'Techniques', 'Text', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Woman', 'Work', 'abstracting', 'base', 'case control', 'cigarette smoking', 'cohort', 'cyclic citrullinated peptide', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic epidemiology', 'genetic risk factor', 'high risk', 'innovation', 'novel', 'patient oriented research', 'predictive modeling', 'prevention clinical trial', 'programs', 'research study', 'risk variant', 'sample collection', 'trafficking']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,K24,2014,157939,327644200,-0.015760633876868557
"The Cardiovascular Research Grid DESCRIPTION (provided by applicant):    The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinations of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotating ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and motion that can predict the early presence of developing heart disease in time for therapeutic intervention. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informatics system that allows clinical information to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG. RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8928685,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'High Performance Computing', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Ultrasonography', 'Work', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2014,159202,807432003,0.005026015829359994
"Preventable Hospitalization in Dementia: The Impact of Neuropsychiatric Symptoms     DESCRIPTION (provided by applicant): Older adults with dementia are at increased risk of hospitalization when compared to adults without dementia of similar age and medical comorbidity. The increased risk of hospitalization extends to potentially preventable hospitalization (PPH) for conditions such as a urinary tract infection or asthma exacerbation, suggesting difficulty in outpatient management of patients with dementia. Neuropsychiatric symptoms (NPS) of dementia such as agitation or delusions likely account for a significant amount of this risk, given their prevalence and potential to cause caregiver distress. While there are effective interventions for patients and caregivers to reduce NPS, the profile of patients that could benefit the most from intervention, therefore reducing their hospitalization risk, is unknown. Through the coordinated program of mentorship, didactics, and research that I propose, I will develop the advanced skills to derive and apply administrative, claims, and clinical encounter data to prospectively identify those patients with dementia at highest risk for hospitalization. Development of this patient-level risk phenotype means that future interventions to reduce hospitalization can then be prospectively matched to the patients most likely to benefit, a development of critical public health importance given both financial and geriatric work force constraints.  Over the next four years, my short-term training goals include: (1) address gaps in my formal research training, specifically: (a) to conduct observational analyses using large-scale claims and administrative data; (b) to derive clinical data from the electronic health record using natural language processing; and (c) to apply advanced methods of data analysis for risk prediction; (2) train in presentations, manuscript writing, and grantsmanship that culminate with a R01 proposal; (3) establish further connections with potential collaborators in the University of Michigan (UM) Pepper Center and broader community of aging researchers, national geriatrics and geriatric psychiatry communities, and the Beeson Scholar community; and (4) engage in leadership development with an emphasis on skills to lead a research team, mentor junior investigators, and communicate findings in research and clinical care settings.  These short-term goals will be paired with research aims that focus on elaborating the PPH risk profile for patients with dementia. Such research objectives can only be achieved when: (1) full clinical characteristics are available for the at-risk (i.e., non-hospitalized) population, includig (2) NPS data, which are rarely captured in standard administrative claims data. These criteria are uniquely met in the Veterans Affairs healthcare system, which has one of the nation's most advanced electronic health records (EHR). Using a national dementia case repository (N=269,565) from which I will draw matched cases (patients with dementia + PPH) and controls (non-hospitalized patients with dementia). Aim 1 will use claims and administrative data to explore patient, treatment, and facility risk factors associated with PPH. Aim 2 will use natural language processing to derive NPS from EHR clinical encounter notes and then characterize the association of NPS with PPH. Using the risk phenotype described in Aims 1 and 2, Aim 3 will develop logistic risk-prediction models to prospectively identify patients with dementia at highest risk for PPH. In subsequent grant proposals I will validate this risk- prediction model in other healthcare systems and prospectively pair the assessment tool with an evidence- based dementia intervention to reduce hospitalization.  My long-term career goals are to: (1) establish myself as independent investigator and national leader in geriatric mental health services research; (2) develop a programmatic line of funded health services research that develops risk-stratification models for late-life mental health and cognitive disorders; (3) translate knowledge from these research endeavors to improve the targeting and impact of future interventions research and health system delivery strategies; and (4) contribute broadly to the care of older adults by training and mentoring future clinical researchers in late-life mental health disorders. I am an Assistant Professor and geriatric psychiatrist at the University of Michigan, where I am also currently completing a MSc in Health and Healthcare Research, which provides an excellent background in health services research for clinicians. With this combination of clinical expertise and foundational training in health services research, I am uniquely qualified to undertake the advanced training activities outlined in this proposal, while UM affords the ideal environment in which to pursue this work. My primary mentor (Helen Kales, MD) and co-mentor (Frederic Blow, PhD) are national leaders in geriatric mental health who have used observational data to answer questions of national significance. My Advisory Panel includes Constantine Lyketsos, MD, MHS, an internationally-recognized expert in NPS and dementia care, and Kenneth Langa, MD, PhD, an internist, former Beeson Scholar, and renowned expert in using survey and secondary data to inform our understanding of dementia. Consultants include David Hanauer, MD, MS, an expert in bioinformatics and natural language processing, and Rodney Hayward, MD, a leader in risk assessment and intervention- targeting. My advisory team paired with resources of Michigan's Pepper Center, CTSA, and multi-disciplinary Institute for Healthcare Policy and Innovation make this the ideal environment in which to complete the proposed training activities.         PUBLIC HEALTH RELEVANCE: Although hospitalization can negatively impact patients with dementia, we know very little about the specific risk factors associated with the chance of being hospitalized. It is important to understand what contributes to this risk, such as the behavior changes that accompany dementia, in order to identify those patients and caregivers that could benefit most from an intervention to avoid or reduce hospitalization. Given the rapidly rising numbers of patients with dementia, reducing potentially preventable hospitalization could have an enormous impact on public health.            ",Preventable Hospitalization in Dementia: The Impact of Neuropsychiatric Symptoms,8769634,K08AG048321,"['Accounting', 'Address', 'Adult', 'Age', 'Aggressive behavior', 'Aging', 'Agitation', 'Antipsychotic Agents', 'Applications Grants', 'Asthma', 'Attention', 'Benzodiazepines', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Code', 'Cognition Disorders', 'Communities', 'Comorbidity', 'Data', 'Data Analyses', 'Delusions', 'Dementia', 'Development', 'Diagnosis', 'Distress', 'Doctor of Philosophy', 'Elderly', 'Electronic Health Record', 'Emergency Care', 'Environment', 'Foundations', 'Funding', 'Future', 'Geriatric Psychiatry', 'Geriatrics', 'Goals', 'Health', 'Health Policy', 'Health Services Research', 'Health system', 'Healthcare Systems', 'Hospitalization', 'Individual', 'Institutes', 'Institutionalization', 'Internist', 'Intervention', 'Intervention Studies', 'Intervention Trial', 'Kale - dietary', 'Knowledge', 'Lead', 'Leadership', 'Light', 'Literature', 'Location', 'Logistic Regressions', 'Logistics', 'Manuscripts', 'Medical', 'Mental Health', 'Mental Health Services', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Natural Language Processing', 'Outpatients', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Prevalence', 'Primary Health Care', 'Provider', 'Psychiatrist', 'Psychotic Disorders', 'Public Health', 'Qualifying', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Rural', 'Signal Transduction', 'Sleeplessness', 'Source', 'Stratification', 'Surveys', 'Symptoms', 'Training', 'Training Activity', 'Translating', 'Universities', 'Urinary tract infection', 'Validation', 'Veterans', 'Visit', 'Work', 'Writing', 'abstracting', 'behavior change', 'career', 'case control', 'clinical care', 'design', 'effective intervention', 'evidence base', 'geriatric mental health', 'high risk', 'improved', 'innovation', 'medication compliance', 'meetings', 'neuropsychiatry', 'patient population', 'professor', 'programs', 'public health relevance', 'repository', 'skills', 'statistics', 'tool']",NIA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K08,2014,175103,641965656,-0.018233232462568888
"Face De-Identification for Research and Clinical Use     DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis.         PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.            ",Face De-Identification for Research and Clinical Use,8772435,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'public health relevance', 'sex', 'social stigma', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2014,194915,30434536,-0.054974920789662166
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,8775015,U54EB020405,"['Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Outcome', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Science', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Visit', 'Walking', 'Work', 'base', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'improved', 'industry partner', 'insight', 'models and simulation', 'next generation', 'novel', 'novel strategies', 'prevent', 'programs', 'public health relevance', 'role model', 'sensor', 'social', 'social model', 'tool']",NIBIB,STANFORD UNIVERSITY,U54,2014,209258,560644462,0.0004879992821547506
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence  Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.  Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8669161,R00LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'screening', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2014,212994,570146095,-0.00846018583035409
"Novel Tree-based Statistical Methods for Cancer Risk Prediction     DESCRIPTION (provided by applicant): The contradiction of early cancer detection is that while some benefit others receive a detrimental diagnosis. A definitive example is mammography and ductal carcinoma in situ (DCIS), a noninvasive breast cancer. DCIS, which most frequently presents as a non-palpable lesion, was rarely detected before the advent of modern mammography. Since 1983 there has been a 290% increase in DCIS incidence in women under 50 and 500% in those over 50. Given that only 5-10% of DCIS cases progress to invasive cancer with a 10-year mortality rate of 1-2%, DCIS experts suggest breast conservation for the majority of patients. However, these women continue to be overtreated with mastectomy and radiation, at rates comparable to those with invasive cancer. The inability to discern those at low vs. high risk is due in part to non-reproducible study results as well as inadequate statistical methods for risk prediction and validation.  We have collected a population-based DCIS cohort with the goal of delineating those women least likely to recur with invasive cancer and, hence, appropriate candidates for less aggressive treatments. Recently we established risk indices and published the corresponding absolute risk estimates for type of recurrence. However, two features of the study design, namely the presence of competing risks and the use of a stratified case-cohort design, constrained us to using crude empirical methods for analysis and left us unable to validate the clinical utility of our models. The overarching goal of this proposal is to develop a unified, principled statistical framework for building, selecting, and evaluating clinically relevant risk indices, permitting refinement and validation of existing risk prediction models in our DCIS study as well as beyond.  We face multiple challenges including how to objectively build risk indices with relevant variables; how to estimate the corresponding risks (competing or not) in various subsample study designs; and, how to validate the resulting risk prediction models. Recently, we developed partDSA, a tree-based method which affords tremendous flexibility in building predictive models and provides an ideal foundation for developing a clinician- friendly tool for accurate stratification and risk prediction. In its curret form, partDSA is unable to estimate absolute risk in the presence of competing risks accounting for subsample study designs. Here we extend partDSA for such clinically relevant scenarios (Aim 1). We also propose aggregate learning for risk prediction to increase prediction accuracy and subsequently to build more stable but easily interpretable risk models (Aim 2). Finally, we propose the necessary methods for validating the resulting models (Aim 3).  Our proposal has two immediate public health benefits: first, these novel statistical methods will result in a clinician-friendly, publicly available tool for accurate risk prediction, stratification and validaion in numerous clinical settings; second, current DCIS risk models will be refined and validated with the expectation of better delineating those at low risk, hence strong candidates for conservative treatments including active surveillance.          Our proposal has two public health components: first, our novel statistical methods will provide a clinician- friendly, publicly available tool for accurate isk prediction, stratification and validation in numerous clinical settings; second, current ductal carcinoma in situ risk models will be refined and validated, helping facilitate the decision-making process faced by patients and their clinicians.            ",Novel Tree-based Statistical Methods for Cancer Risk Prediction,8658404,R01CA163687,"['Accounting', 'Anxiety', 'Breast', 'Carcinoma', 'Clinical', 'Code', 'Cohort Studies', 'Communities', 'Computer software', 'Decision Making', 'Diagnosis', 'Epidemiology', 'Face', 'Face Processing', 'Foundations', 'Goals', 'Health Benefit', 'Incidence', 'Individual', 'Intervention Studies', 'Label', 'Learning', 'Left', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Mastectomy', 'Measures', 'Methods', 'Modeling', 'Noninfiltrating Intraductal Carcinoma', 'Outcome', 'Patients', 'Performance', 'Public Health', 'Publishing', 'Radiation', 'Radiation therapy', 'Recurrence', 'Research Design', 'Risk', 'Risk Estimate', 'Screening for cancer', 'Statistical Methods', 'Stratification', 'Techniques', 'Trees', 'Validation', 'Woman', 'Work', 'anticancer research', 'base', 'breast lumpectomy', 'cancer risk', 'clinically relevant', 'cohort', 'design', 'expectation', 'experience', 'flexibility', 'high risk', 'indexing', 'loss of function', 'malignant breast neoplasm', 'mortality', 'novel', 'open source', 'population based', 'predictive modeling', 'prevent', 'programs', 'research study', 'simulation', 'tool']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2014,314257,685608202,-0.0474938942903044
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8652462,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2014,332955,193405667,-0.0043559064542817594
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.        Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8704932,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild cognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'screening', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2014,338287,507546965,-0.031925684024689566
"A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI     DESCRIPTION (provided by applicant): A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI NeuroEnabling Technologies, Inc. RESEARCH & RELATED Other Project Information 7. PROJECT SUMMARY Of the approximately 10 million people in the US living with paralysis, 15,000 are the result of spinal cord injury each year. The first year of care can range from $322,000-$986,000, with lifetime costs of $1.4-4M for someone injured at 25 years of age. In addition to potentially devastating sensorimotor disturbances, there is a huge financial cost, estimated to be $13.55B in medical care, therapy, and lost productivity nationwide. Until very recently, the recovery from spinal cord injury (SCI) was bleak, with little hope of restoring motor function. To address this we have demonstrated that the physiological state of the spinal circuitry of rats and cats can be modulated with epidural stimulation to generate voluntary limb motor function over a range of speeds, loads, and directions, a finding we have extended to humans. Three years post-injury, a motor complete spinal cord injured human subject was implanted with an epidural electrode array over the lumbosacral spinal cord. In less than one month after implantation, the subject could stand independently, and after 7 months of daily epidural stimulation and motor training, voluntary control of both legs was evident in the presence of epidural stimulation, whereas complete paralysis remained in absence of epidural stimulation. We will advance these discoveries with the use of non-invasive stimulation of the lumbosacral cord to improve lower limb function following SCI. Central to this proposal is our discovery of a painless electrical multi-channel (stimulation of multiple parts of the spinal cord) theranostic tool that can be applied to the surface of the skin, termed transcutaneous spinal cord electrical stimulation (TESCS), bypassing the need for a surgically-implanted electrode array. In the first phase of this proposal we will demonstrate proof-of-principle that stimulation of the lumbosacral spinal cord can assess spared spinal motor function by: 1) Testing responses to transcutaneous electrical stimulation in subjects with spinal cord injury; and 2) defining the operational parameters of electrical stimulation that that are most effective using a machine-learning protocol, and 3) produce a multi-channel commercial prototype. This commercial product will undergo testing similar to the proof-of- principle device. This device will then be tested in subjects with cervicothoracic spinal cord injury and evaluated with a machine-learning protocol. This Phase I proposal will deliver a device that can painlessly and non-invasively aid in the assessment and recovery of SCI by delivering a specific electrical stimulation paradigm to the lumbosacral cord that improves use of the lower limbs.         PUBLIC HEALTH RELEVANCE: A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI NeuroEnabling Technologies, Inc. PROJECT NARRATIVE It now seems possible to apply three interventions: transcutaneous stimulation, administration of pharmacological agents, and motor training, to assess and enable the excitability of spared neural circuits in humans with a thoracic spinal cord injury (SCI), thus enabling these individuals to regain use of their legs. This enabling effect is similar to that observed with improved postura and locomotor function after a mid-thoracic SCI in which epidural stimulation was used. We will build and demonstrate a multi-channel transcutaneous electrical spinal cord stimulation theranostic tool that we propose will allow assessment and enabling of lower limb function following a cervicothoracic spinal cord injury.                ",A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI,8735147,R43EB018232,"['Address', 'Age-Years', 'Algorithms', 'American', 'Ankle', 'Bypass', 'Caring', 'Cervical', 'Cervical spinal cord injury', 'Chest', 'Chronic', 'Clinic', 'Clinical', 'Clinical Trials', 'Data', 'Devices', 'Diagnosis', 'Diagnostic', 'Electric Stimulation', 'Electrodes', 'Enrollment', 'Evaluation', 'Felis catus', 'Financial cost', 'Goals', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Joints', 'Knee', 'Leg', 'Life', 'Limb structure', 'Lower Extremity', 'Lumbar spinal cord structure', 'Machine Learning', 'Measurement', 'Medical', 'Modality', 'Motor', 'Movement', 'Nervous System Physiology', 'Neurologic', 'Neurostimulation procedures of spinal cord tissue', 'Outpatients', 'Painless', 'Paralysed', 'Paraplegia', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Productivity', 'Protocols documentation', 'Rattus', 'Recovery', 'Residual state', 'Site', 'Skin', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord Part', 'Spinal Injuries', 'Spinal cord injury', 'Spinal cord injury patients', 'Stroke', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Transcutaneous Electric Nerve Stimulation', 'Translating', 'Upper Extremity', 'Weight-Bearing state', 'design', 'human subject', 'human subject protection', 'implantation', 'improved', 'improved functioning', 'injured', 'life time cost', 'meetings', 'motor control', 'motor function improvement', 'neural circuit', 'neuroregulation', 'prototype', 'public health relevance', 'response', 'theranostics', 'tool', 'transcutaneous stimulation']",NIBIB,"NEUROENABLING TECHNOLOGIES, INC.",R43,2014,346207,0,-0.015997513051176093
"Predicting Hip Fracture Using a Biomechanical Approach     DESCRIPTION (provided by applicant): Hip fractures are a significant cause of disability and mortality in older persons. The most common tool for diagnosis of osteoporosis and prediction of fracture risk is bone mineral density (BMD) measured by dual- energy X-ray absorptiometry. Yet, up to half of individuals suffering a hip fracture do not have osteoporosis by BMD testing; thus alternative approaches to fracture risk assessment are needed. This underscores the importance of looking for additional contributors to fracture risk, such as reduced soft tissue thickness at the trochanter, which attenuates the fall forces that may lead to fracture. According to biomechanical principles, when the ratio of applied force to bone strength, (termed the 'Factor-of-Risk'), exceeds one, a fracture will occur. Two previous studies have examined the Factor-of-Risk along with trochanteric soft tissue thickness but had only small numbers of hip fractures, and conflicting results. To better understand the factors associated with hip fracture, we propose to use a biomechanical approach to assess hip fracture risk that includes both estimated forces applied to the hip during a sideways fall as well as the strength of the proximal femur. The specific goal is to investigate the contribution of trochanteric soft tissue thickness t hip fracture risk, and to include this in the biomechanical Factor-of-Risk model. We hypothesize these factors predict hip fracture, and further that the factor-of-risk prediction of hip fracture isk will prove better than BMD assessment alone and better than the World Health Organization FRAX tool. We will identify prospectively ascertained hip fracture cases from three cohorts (Framingham Study, MrOS, Rancho Bernardo Study) and from each cohort also select up to four sex- and age-matched (within 3-years) non-fracture cohort members as controls, using the case-cohort study design to increase efficiency. Soft tissue thickness in 2,435 individuals will be assess on whole body DXA scans obtained at the earliest time in each cohort before any subsequent hip fracture occurred. Relative risks will be assessed as odds ratios using conditional logistic regression. This study has potential to significantly alter the way hip fractue risk is currently being assessed, and thus how patients are selected for drug therapy.         PUBLIC HEALTH RELEVANCE: The most common tool to diagnose osteoporosis/predict hip fracture risk is bone density testing, and yet, up to half of adults suffering a hip fracture do no have osteoporosis by this test; thus alternative approaches to fracture risk assessment are needed. We will investigate the role of trochanteric soft tissue thickness to hip fracture risk, an include this in the biomechanical Factor-of-Risk model, to examine if they will predict hip fracture and further do so better than currently available prediction tools, providing new public health insights            ",Predicting Hip Fracture Using a Biomechanical Approach,8628044,R01AR060816,"['Adrenal Cortex Hormones', 'Adult', 'Age', 'Area', 'Attention', 'Attenuated', 'Biomechanics', 'Bone Density', 'Clinical', 'Cohort Studies', 'Conflict (Psychology)', 'Data', 'Diagnosis', 'Dual-Energy X-Ray Absorptiometry', 'Elderly', 'Evaluation', 'Failure', 'Femur', 'Fracture', 'Goals', 'Gold', 'Height', 'Hip Fractures', 'Hip region structure', 'Incidence', 'Individual', 'Lead', 'Logistic Regressions', 'Measurement', 'Measures', 'Menopause', 'Methods', 'Modeling', 'Odds Ratio', 'Osteoporosis', 'Patients', 'Pharmacotherapy', 'Predictive Value', 'Public Health', 'Publishing', 'Recording of previous events', 'Relative Risks', 'Research Design', 'Risk', 'Risk Assessment', 'Risk Factors', 'Role', 'Scanning', 'Smoking Status', 'Surface', 'Testing', 'Thick', 'Time', 'Trochanters', 'Weight', 'Woman', 'Work', 'World Health Organization', 'absorption', 'base', 'bone strength', 'cohort', 'diagnosis standard', 'disability', 'falls', 'hip bone', 'improved', 'insight', 'member', 'men', 'mortality', 'osteoporosis with pathological fracture', 'public health relevance', 'sex', 'soft tissue', 'tool']",NIAMS,HEBREW REHABILITATION CENTER FOR AGED,R01,2014,477496,10587954,-0.011922047005883209
"Computer-aided detection of non-calcified plaques in coronary CT angiograms   Cardiovascular disease is the leading cause of death in both men and women in the United States. Over 16 million Americans have coronary heart disease (CHD), causing about 0.5 million deaths each year. The most common CHD is coronary artery disease which is mainly caused by atherosclerosis. Clinical evidence in recent years shows that noncalcified plaques (NCPs) are more vulnerable to rupture than calcified plaques. Plaque rupture and the thrombosis that follows is the main cause of acute myocardial infarction. Multidetector coronary CT angiography (cCTA) has the potential to help clinicians in early detection and in quantification of NCPs. cCTA may thus be useful for CHD detection, risk stratification, monitoring, and evaluation of the effectiveness of risk reduction treatment. However, many of these potential applications have not been utilized clinically.  The goal of this project is to develop a computer-aided detection (CADe) system to serve as a second reader for assisting clinicians in detection and quantification of NCPs in cCTA exams. Our specific aims are to (1) develop machine learning methods for detection of NCPs causing stenosis and/or positive remodeling along coronary arteries, and (2) evaluate the effect of CADe on radiologists' detection of NCPs on cCTA by observer ROC study. To achieve these aims, we will collect a database of cCTA cases for training and testing the CADe system, define the search space by designing 3D multiscale coronary artery response enhancement, segmentation, and dynamic balloon vessel tracking methods, develop a unique vessel- stitching method to automatically identify the best-quality phase for each individual artery segment from all available phases in prospectively or retrospectively gated cCTA exams, develop innovative vessel-sector- profile analysis and vessel lumen analysis to detect NCPs that cause stenosis or positive remodeling, estimate the total NCP volume, and explore calibration method to quantify plaque density by phantom studies. To demonstrate the usefulness of CADe, a preclinical reader study will be conducted to compare radiologists' detection accuracy of NCPs with and without CADe.  The major innovations of this project include (1) being the first CADe system to automatically detect non-calcified plaques including those cause positive remodeling or stenosis in cCTA, (2) development of new machine learning techniques including the vessel-stitching method, vessel-sector-profile analysis, multiscale enhancement response, and dynamic balloon tracking specifically suited for coronary arterial trees, and (3) conducting the first ROC study to evaluate the effect of CADe on radiologists' detection of NCPs.  Narrative:  Cardiovascular disease is the leading cause of death in both men and women in the United States. If the proposed CADe system is successfully developed, it will (1) provide an accurate, efficient, and consistent tool to assist clinicians in detecting and quantifying non-calcified plaques (NCP) including those causing positive remodeling and/or stenosis for an individual patient, (2) help clinicians estimate the total NCP burden and study its significance, in analogy to that of the total calcium score, which may lead to improved clinical management of the vulnerable plaques, and (3) accelerate studies to develop new treatment options of coronary heart disease by providing a monitoring tool of treatment response. The proposed CADe system can thus serve as a foundation for these broader future applications and improve the efficacy of cCTA. Improved detection and management of NCPs may reduce the risk of myocardial infarctions and will have strong and long-lasting impact on health care.",Computer-aided detection of non-calcified plaques in coronary CT angiograms,8586273,R01HL106545,"['Acute myocardial infarction', 'American', 'Angiography', 'Arterial Fatty Streak', 'Arteries', 'Atherosclerosis', 'Calcified', 'Calcium', 'Calibration', 'Cardiovascular Diseases', 'Catheters', 'Cause of Death', 'Cessation of life', 'Clinical', 'Clinical Management', 'Computer Vision Systems', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Coronary heart disease', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Dose', 'Early Diagnosis', 'Effectiveness', 'Electrocardiogram', 'Evaluation', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Image', 'Imagery', 'Individual', 'Lead', 'Machine Learning', 'Methods', 'Modality', 'Monitor', 'Myocardial Infarction', 'Patients', 'Performance', 'Phase', 'Procedures', 'Radiation', 'Reader', 'Receiver Operating Characteristics', 'Recording of previous events', 'Resolution', 'Risk', 'Risk Reduction', 'Rupture', 'Scanning', 'Stenosis', 'Stratification', 'System', 'Techniques', 'Testing', 'Thrombosis', 'Time', 'Training', 'Trees', 'Ultrasonography', 'United States', 'Visual', 'Woman', 'computer aided detection', 'density', 'design', 'detector', 'improved', 'innovation', 'men', 'pre-clinical', 'prospective', 'radiologist', 'response', 'tool', 'treatment response', 'virtual']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2014,610289,641965656,-0.03754459249344003
"Efficient patient-specific cell generation by image-guidance    DESCRIPTION (provided by applicant): This fast-track proposal applies advanced kinetic image pattern recognition (KIPR) technologies to predict induced pluripotent stem cell (iPSC) reprogramming colonies' differentiation outcomes for significantly improved yield and robustness of differentiation protocols. The objectives of the proposed tool are 1) Teaching: creation of scores for induced colony differentiation outcome prediction by machine learning; 2) Reprogramming: optimal reprogramming harvest time determination by continuous colony score monitoring; 3) Differentiation: selection of colonies with the highest prediction scores for differentiation at the reprogramming harvest time; 4) Differentiation: cell cluster quality control by continuous monitoring during differentiation. The specific aims of this fast-track proposal are Phase I: 1) Extend SVCell for the prediction of induced colony differentiation outcomes ; 2) Validate that prediction of colony differentiation outcomes can improve the yield of CM differentiation. Phase II: 1) Validate that the integrated system can be taught to be robust and high yielding for a diverse set of human fibroblast input samples and different reprogramming / differentiation protocols; 2) Integrate SVCell with a state-of-the-art continuous cell imaging and culture system to create a prototype patient-specific cell generation system; 3) Validate the integrated system as a patient-specific cell generation product. The ultimate goal of this fast-track proposal is to develop and validate an image-guided efficient patient-specific cardiomyocyte generation system. This will be achieved by integrating our established SVCell software containing advanced KIPR technologies with a live cell imaging technology to synthesize state-of-the-art cell fate control protocols against iPSC. Patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. Successful development of the patient-specific cell generation system of this proposal could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.        Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.         ",Efficient patient-specific cell generation by image-guidance,8697110,R44HL106863,"['Biotechnology', 'Brain Diseases', 'Cardiac Myocytes', 'Cell Culture System', 'Cell Differentiation process', 'Cell Fate Control', 'Cells', 'Cellular Morphology', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Fibroblasts', 'Generations', 'Goals', 'Government', 'Harvest', 'Health', 'Healthcare', 'Heart', 'Human', 'Image', 'Imaging technology', 'Institutes', 'Kinetics', 'Life', 'Machine Learning', 'Medicine', 'Metric', 'Monitor', 'Outcome', 'Patients', 'Pattern Recognition', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Production', 'Protocols documentation', 'Quality Control', 'Sampling', 'Staging', 'Staining method', 'Stains', 'Stem cells', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Work', 'alanine aminopeptidase', 'base', 'cell type', 'cellular imaging', 'cost', 'cost effectiveness', 'disease diagnosis', 'drug discovery', 'drug testing', 'human embryonic stem cell', 'improved', 'induced pluripotent stem cell', 'patient population', 'prototype', 'stem cell technology', 'tool', 'usability']",NHLBI,"DRVISION TECHNOLOGIES, LLC",R44,2014,976531,1296025,-0.02372790149618907
"The Cardiovascular Research Grid DESCRIPTION (provided by applicant):    The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinations of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotating ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and motion that can predict the early presence of developing heart disease in time for therapeutic intervention. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informatics system that allows clinical information to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG.  RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8588958,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'High Performance Computing', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Ultrasonography', 'Work', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2014,2177431,807432003,0.005026015829359994
"Family History, Genes, Environment and G X E Interaction in Predicting RA Risk DESCRIPTION (provided by applicant): Since receiving the K24 award, I have established a successful clinical research and training program in patient-oriented research (POR) in rheumatic disease with a focus on genetic, biomarker, and environmental risk factors for rheumatoid arthritis (RA) and systemic lupus erythematosus (SLE). I continue to have independent grant support, and have mentored 15 new clinical investigators who have published 25 peer- reviewed papers during the K24 period. Three mentees have received NIH K awards and one has received an NIH R01. With renewal of the K24, I would continue to have protected time to devote to this program that has a unique training environment and an array of important POR projects. Genetic and environmental epidemiology studies have produced convincing evidence for multiple alleles and exposures as RA risk factors. A strong gene-environment (GXE) interaction between HLA-DRB1 alleles and smoking has been demonstrated for risk of the immune phenotype of CCP positive RA but not CCP negative RA. As CCP antibodies occur years before RA onset, I hypothesize that this interaction induces anti-citrulline immunity, a critical step in RA pathogenesis. These findings emphasize the need to study genes, environment and immunity with careful phenotyping. Family history encompasses unmeasured genetic and environmental risk, yet is not measured accurately in other studies including those in my research portfolio. Specific aims are to: 1) Maintain and expand my clinical research training program by mentoring new clinical investigators in POR in rheumatic diseases; 2) Enrich my comprehensive POR program to study family history, genetic, and environmental predictors in the etiology of RA using a new collection of RA cases and controls from Partners HealthCare; 2a) Collect family history data and environmental exposure data concerning smoking and reproductive factors on 1,500 RA patients and 4,500 age- and gender-matched controls by utilizing natural language processing (NLP) queries of electronic medical records; 2b: Examine genetic risk factors, environmental risk factors and GXE in predicting immune phenotypes of RA: RA with and without CCP antibodies (CCP?), and RA with and without rheumatoid factor antibodies (RF?); and 2c: Apply this comprehensive risk model to RA cases and controls and to subsets of RA stratified by specific immune phenotypes and stratified by family history of RA and other autoimmune diseases. The proposed study will leverage the NIH funded Informatics for Integrating Biology and the Bedside study that used an advanced informatics infrastructure to extract clinical data on RA diagnostic features through database mining and NLP. A highly specific algorithm was used to identify RA cases and collect samples from cases and controls. The NLP techniques will be used to extract risk factor data from clinical notes. This proposal builds on my strong track record of POR, extending the work to add family history from a new case-control collection, validate data by patient interview, and develop predictive models for risk of RA that can be used to select high risk individuals for future RA prevention trials. Project Narrative  Innovative predictive modeling incorporating family history, genes, environmental exposures, and geneenvironment interactions, is a key step in the progress towards an RA prevention clinical trial.","Family History, Genes, Environment and G X E Interaction in Predicting RA Risk",8485543,K24AR052403,"['Age', 'Algorithms', 'Alleles', 'Antibodies', 'Autoantibodies', 'Autoimmune Diseases', 'Bioinformatics', 'Biology', 'Citrulline', 'Classification', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Collection', 'Computerized Medical Record', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Environment', 'Environmental Epidemiology', 'Environmental Exposure', 'Environmental Risk Factor', 'Epidemiologic Studies', 'Epidemiology', 'Etiology', 'Exogenous Hormone Therapy', 'Family', 'Family Study', 'Family history of', 'Female', 'First Degree Relative', 'Funding', 'Future', 'Gender', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Grant', 'HLA-DRB1', 'Healthcare', 'ICD-9', 'Immune', 'Immunity', 'Incidence', 'Individual', 'Informatics', 'Institution', 'Interview', 'K-Series Research Career Programs', 'Laboratories', 'Lead', 'Measures', 'Mentors', 'Meta-Analysis', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Mining', 'Modeling', 'Natural Language Processing', 'PTPN22 gene', 'Paper', 'Pathogenesis', 'Patients', 'Peer Review', 'Phenotype', 'Pollution', 'Prevention', 'Publishing', 'Recording of previous events', 'Records', 'Reproductive History', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Research Training', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatoid Factor', 'Risk', 'Risk Factors', 'STAT4 gene', 'Sampling', 'Siblings', 'Smoking', 'Sushi Domain', 'System', 'Systemic Lupus Erythematosus', 'TNF receptor-associated factor 1', 'Techniques', 'Text', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Woman', 'Work', 'abstracting', 'base', 'case control', 'cigarette smoking', 'cohort', 'cyclic citrullinated peptide', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic epidemiology', 'genetic risk factor', 'high risk', 'innovation', 'novel', 'patient oriented research', 'predictive modeling', 'prevention clinical trial', 'programs', 'research study', 'sample collection', 'trafficking']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,K24,2013,157939,327644200,-0.015760633876868557
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence  Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.  Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8484438,R00LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'screening', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2013,202118,570146095,-0.00846018583035409
"Cumulative Glycemic Burden and Cardiovascular Disease Risk in Type 2 Diabetes    DESCRIPTION (provided by applicant): We seek to provide evidence that prolonged, continuous, tight glycemic control, initiated when type 2 diabetes (DM) is first diagnosed and maintained throughout patients' DM lifetime, can reduce the risk of cardiovascular disease (CVD). Current recommendations on care for persons with DM include tight glycated hemoglobin (A1C) control (<7%) as a means to reduce risk of CVD and other complications. Recent studies raised questions about this recommendation by failing to demonstrate that tight A1C control provides CV benefit in persons with DM, but these studies could not account for glycemic control prior to trial initiation. Other research supports the benefit of tight glycemic control over time, and suggests that even moderately elevated A1C levels in the 'normal' range indicate long-term CVD risk. To address these seemingly contradictory perspectives on how to optimize DM care, we propose to test the hypothesis that tight glycemic control does indeed reduce CVD risk, if begun early and continued throughout the course of DM. We will also assess whether cumulative glycemic burden over time, predict long-term CVD risk better than current A1C level or mean A1C over time, and to identify threshold levels of cumulative glycemic burden at which CVD risk becomes markedly elevated, among persons with DM. We will conduct the proposed analyses using data from the Kaiser Permanente Northwest Diabetes Registry. Since 1988, KPNW has developed and maintained this highly specific, sensitive, data-rich registry of members with DM; as of December 2009, it contained data on >70,000 persons. Among adults who joined the registry in 1995-2010, we will identify individuals who experienced a CVD event and match them to 5 controls who did not. We will then conduct multivariate logistic regression analyses of the extent to which A1C, mean A1C, and cumulative A1C burden predict time until first CVD event, and describe differences in the odds of CVD from date of DM diagnosis through 2010, to identify cut-points (of A1C, mean A1C over time, and cumulative glycemic burden levels) where CVD risk increases. The clinical application of such findings would lie in proving what has long been suspected - that cumulative glycemic burden is a critical CVD risk factor - thus providing critical support for the importance of initiating tight glycemic control immediately upon DM diagnosis and maintaining such control rigorously. No previous studies have evaluated cumulative glycemic burden as an indicator of CVD risk in DM, alone or in comparison to mean A1C over time, despite cumulative burden's biological plausibility as a CVD risk factor. The proposed work builds on our previous development of methods for measuring cumulative glycemic burden.        This study will use existing data on Kaiser Permanente Northwest members with diabetes from 1995- 2010 to assess whether control of high blood sugar, if begun early and continued over time, reduces cardiovascular disease risk. We will use a novel measure of high blood sugar, glycemic burden, which accounts for how high blood sugar is and how long it has been high. Our results would show the importance of treating blood sugar aggressively immediately upon diabetes diagnosis and maintaining such aggressive treatment rigorously.            ",Cumulative Glycemic Burden and Cardiovascular Disease Risk in Type 2 Diabetes,8394918,R21DK091773,"['Accounting', 'Address', 'Adult', 'Atherosclerosis', 'Biological', 'Blood Glucose', 'Cardiovascular Diseases', 'Caring', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Coupled', 'Data', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Digestive System Disorders', 'Epidemiology', 'Evaluation Studies', 'Event', 'Future', 'Glycosylated Hemoglobin', 'Goals', 'Heart', 'Hyperglycemia', 'Individual', 'Kidney Diseases', 'Lead', 'Logistic Regressions', 'Measurement', 'Measures', 'Methods', 'Myocardial Infarction', 'Negative Finding', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Range', 'Obesity', 'Outcome', 'Patients', 'Persons', 'Recommendation', 'Registries', 'Regression Analysis', 'Research Support', 'Risk', 'Risk Factors', 'Risk Reduction', 'Role', 'Sample Size', 'Specific qualifier value', 'Testing', 'Therapeutic', 'Time', 'United Kingdom', 'Work', 'burden of illness', 'cardiovascular disorder risk', 'clinical application', 'clinical practice', 'experience', 'follow-up', 'glycemic control', 'heart disease risk', 'innovation', 'member', 'method development', 'mortality', 'novel', 'patient registry', 'prevention evaluation', 'prospective', 'response']",NIDDK,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2013,228705,111231681,-0.006216225399684215
"Novel Tree-based Statistical Methods for Cancer Risk Prediction     DESCRIPTION (provided by applicant): The contradiction of early cancer detection is that while some benefit others receive a detrimental diagnosis. A definitive example is mammography and ductal carcinoma in situ (DCIS), a noninvasive breast cancer. DCIS, which most frequently presents as a non-palpable lesion, was rarely detected before the advent of modern mammography. Since 1983 there has been a 290% increase in DCIS incidence in women under 50 and 500% in those over 50. Given that only 5-10% of DCIS cases progress to invasive cancer with a 10-year mortality rate of 1-2%, DCIS experts suggest breast conservation for the majority of patients. However, these women continue to be overtreated with mastectomy and radiation, at rates comparable to those with invasive cancer. The inability to discern those at low vs. high risk is due in part to non-reproducible study results as well as inadequate statistical methods for risk prediction and validation.  We have collected a population-based DCIS cohort with the goal of delineating those women least likely to recur with invasive cancer and, hence, appropriate candidates for less aggressive treatments. Recently we established risk indices and published the corresponding absolute risk estimates for type of recurrence. However, two features of the study design, namely the presence of competing risks and the use of a stratified case-cohort design, constrained us to using crude empirical methods for analysis and left us unable to validate the clinical utility of our models. The overarching goal of this proposal is to develop a unified, principled statistical framework for building, selecting, and evaluating clinically relevant risk indices, permitting refinement and validation of existing risk prediction models in our DCIS study as well as beyond.  We face multiple challenges including how to objectively build risk indices with relevant variables; how to estimate the corresponding risks (competing or not) in various subsample study designs; and, how to validate the resulting risk prediction models. Recently, we developed partDSA, a tree-based method which affords tremendous flexibility in building predictive models and provides an ideal foundation for developing a clinician- friendly tool for accurate stratification and risk prediction. In its curret form, partDSA is unable to estimate absolute risk in the presence of competing risks accounting for subsample study designs. Here we extend partDSA for such clinically relevant scenarios (Aim 1). We also propose aggregate learning for risk prediction to increase prediction accuracy and subsequently to build more stable but easily interpretable risk models (Aim 2). Finally, we propose the necessary methods for validating the resulting models (Aim 3).  Our proposal has two immediate public health benefits: first, these novel statistical methods will result in a clinician-friendly, publicly available tool for accurate risk prediction, stratification and validaion in numerous clinical settings; second, current DCIS risk models will be refined and validated with the expectation of better delineating those at low risk, hence strong candidates for conservative treatments including active surveillance.          Our proposal has two public health components: first, our novel statistical methods will provide a clinician- friendly, publicly available tool for accurate isk prediction, stratification and validation in numerous clinical settings; second, current ductal carcinoma in situ risk models will be refined and validated, helping facilitate the decision-making process faced by patients and their clinicians.            ",Novel Tree-based Statistical Methods for Cancer Risk Prediction,8508207,R01CA163687,"['Accounting', 'Anxiety', 'Breast', 'Carcinoma', 'Clinical', 'Code', 'Cohort Studies', 'Communities', 'Computer software', 'Decision Making', 'Diagnosis', 'Epidemiology', 'Face', 'Face Processing', 'Foundations', 'Goals', 'Health Benefit', 'Incidence', 'Individual', 'Intervention Studies', 'Label', 'Learning', 'Left', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Mastectomy', 'Measures', 'Methods', 'Modeling', 'Noninfiltrating Intraductal Carcinoma', 'Outcome', 'Patients', 'Performance', 'Public Health', 'Publishing', 'Radiation', 'Radiation therapy', 'Recurrence', 'Research Design', 'Risk', 'Risk Estimate', 'Screening for cancer', 'Statistical Methods', 'Stratification', 'Techniques', 'Trees', 'Validation', 'Woman', 'Work', 'anticancer research', 'base', 'breast lumpectomy', 'cancer risk', 'clinically relevant', 'cohort', 'design', 'expectation', 'experience', 'flexibility', 'high risk', 'indexing', 'loss of function', 'malignant breast neoplasm', 'mortality', 'novel', 'open source', 'population based', 'predictive modeling', 'prevent', 'programs', 'research study', 'simulation', 'tool']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2013,302880,685608202,-0.0474938942903044
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.        Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8514601,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild cognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'screening', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2013,328871,507546965,-0.031925684024689566
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8477880,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2013,339750,193405667,-0.0043559064542817594
"A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI  A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI NeuroEnabling Technologies, Inc. RESEARCH & RELATED Other Project Information 7. PROJECT SUMMARY Of the approximately 10 million people in the US living with paralysis, 15,000 are the result of spinal cord injury each year. The first year of care can range from $322,000-$986,000, with lifetime costs of $1.4-4M for someone injured at 25 years of age. In addition to potentially devastating sensorimotor disturbances, there is a huge financial cost, estimated to be $13.55B in medical care, therapy, and lost productivity nationwide. Until very recently, the recovery from spinal cord injury (SCI) was bleak, with little hope of restoring motor function. To address this we have demonstrated that the physiological state of the spinal circuitry of rats and cats can be modulated with epidural stimulation to generate voluntary limb motor function over a range of speeds, loads, and directions, a finding we have extended to humans. Three years post-injury, a motor complete spinal cord injured human subject was implanted with an epidural electrode array over the lumbosacral spinal cord. In less than one month after implantation, the subject could stand independently, and after 7 months of daily epidural stimulation and motor training, voluntary control of both legs was evident in the presence of epidural stimulation, whereas complete paralysis remained in absence of epidural stimulation. We will advance these discoveries with the use of non-invasive stimulation of the lumbosacral cord to improve lower limb function following SCI. Central to this proposal is our discovery of a painless electrical multi-channel (stimulation of multiple parts of the spinal cord) theranostic tool that can be applied to the surface of the skin, termed transcutaneous spinal cord electrical stimulation (TESCS), bypassing the need for a surgically-implanted electrode array. In the first phase of this proposal we will demonstrate proof-of-principle that stimulation of the lumbosacral spinal cord can assess spared spinal motor function by: 1) Testing responses to transcutaneous electrical stimulation in subjects with spinal cord injury; and 2) defining the operational parameters of electrical stimulation that that are most effective using a machine-learning protocol, and 3) produce a multi-channel commercial prototype. This commercial product will undergo testing similar to the proof-of- principle device. This device will then be tested in subjects with cervicothoracic spinal cord injury and evaluated with a machine-learning protocol. This Phase I proposal will deliver a device that can painlessly and non-invasively aid in the assessment and recovery of SCI by delivering a specific electrical stimulation paradigm to the lumbosacral cord that improves use of the lower limbs. PUBLIC HEALTH RELEVANCE: A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI NeuroEnabling Technologies, Inc. PROJECT NARRATIVE It now seems possible to apply three interventions: transcutaneous stimulation, administration of pharmacological agents, and motor training, to assess and enable the excitability of spared neural circuits in humans with a thoracic spinal cord injury (SCI), thus enabling these individuals to regain use of their legs. This enabling effect is similar to that observed with improved postura and locomotor function after a mid-thoracic SCI in which epidural stimulation was used. We will build and demonstrate a multi-channel transcutaneous electrical spinal cord stimulation theranostic tool that we propose will allow assessment and enabling of lower limb function following a cervicothoracic spinal cord injury.                ",A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI,8648234,R43EB018232,"['Address', 'Age-Years', 'Algorithms', 'American', 'Ankle', 'Bypass', 'Caring', 'Cervical', 'Cervical spinal cord injury', 'Chest', 'Chronic', 'Clinic', 'Clinical', 'Clinical Trials', 'Data', 'Devices', 'Diagnosis', 'Diagnostic', 'Electric Stimulation', 'Electrodes', 'Enrollment', 'Evaluation', 'Felis catus', 'Financial cost', 'Goals', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Joints', 'Knee', 'Leg', 'Life', 'Limb structure', 'Lower Extremity', 'Lumbar spinal cord structure', 'Machine Learning', 'Measurement', 'Medical', 'Modality', 'Motor', 'Movement', 'Nervous System Physiology', 'Neurologic', 'Neurostimulation procedures of spinal cord tissue', 'Outpatients', 'Painless', 'Paralysed', 'Paraplegia', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Productivity', 'Protocols documentation', 'Rattus', 'Recovery', 'Residual state', 'Site', 'Skin', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord Part', 'Spinal Injuries', 'Spinal cord injury', 'Spinal cord injury patients', 'Stroke', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Transcutaneous Electric Nerve Stimulation', 'Translating', 'Upper Extremity', 'Weight-Bearing state', 'design', 'human subject', 'human subject protection', 'implantation', 'improved', 'improved functioning', 'injured', 'life time cost', 'meetings', 'motor control', 'motor function improvement', 'neural circuit', 'neuroregulation', 'prototype', 'public health relevance', 'response', 'theranostics', 'tool', 'transcutaneous stimulation']",NIBIB,"NEUROENABLING TECHNOLOGIES, INC.",R43,2013,346207,0,-0.015897549546552446
"Computer-aided detection of non-calcified plaques in coronary CT angiograms   Cardiovascular disease is the leading cause of death in both men and women in the United States. Over 16 million Americans have coronary heart disease (CHD), causing about 0.5 million deaths each year. The most common CHD is coronary artery disease which is mainly caused by atherosclerosis. Clinical evidence in recent years shows that noncalcified plaques (NCPs) are more vulnerable to rupture than calcified plaques. Plaque rupture and the thrombosis that follows is the main cause of acute myocardial infarction. Multidetector coronary CT angiography (cCTA) has the potential to help clinicians in early detection and in quantification of NCPs. cCTA may thus be useful for CHD detection, risk stratification, monitoring, and evaluation of the effectiveness of risk reduction treatment. However, many of these potential applications have not been utilized clinically.  The goal of this project is to develop a computer-aided detection (CADe) system to serve as a second reader for assisting clinicians in detection and quantification of NCPs in cCTA exams. Our specific aims are to (1) develop machine learning methods for detection of NCPs causing stenosis and/or positive remodeling along coronary arteries, and (2) evaluate the effect of CADe on radiologists' detection of NCPs on cCTA by observer ROC study. To achieve these aims, we will collect a database of cCTA cases for training and testing the CADe system, define the search space by designing 3D multiscale coronary artery response enhancement, segmentation, and dynamic balloon vessel tracking methods, develop a unique vessel- stitching method to automatically identify the best-quality phase for each individual artery segment from all available phases in prospectively or retrospectively gated cCTA exams, develop innovative vessel-sector- profile analysis and vessel lumen analysis to detect NCPs that cause stenosis or positive remodeling, estimate the total NCP volume, and explore calibration method to quantify plaque density by phantom studies. To demonstrate the usefulness of CADe, a preclinical reader study will be conducted to compare radiologists' detection accuracy of NCPs with and without CADe.  The major innovations of this project include (1) being the first CADe system to automatically detect non-calcified plaques including those cause positive remodeling or stenosis in cCTA, (2) development of new machine learning techniques including the vessel-stitching method, vessel-sector-profile analysis, multiscale enhancement response, and dynamic balloon tracking specifically suited for coronary arterial trees, and (3) conducting the first ROC study to evaluate the effect of CADe on radiologists' detection of NCPs.  Narrative:  Cardiovascular disease is the leading cause of death in both men and women in the United States. If the proposed CADe system is successfully developed, it will (1) provide an accurate, efficient, and consistent tool to assist clinicians in detecting and quantifying non-calcified plaques (NCP) including those causing positive remodeling and/or stenosis for an individual patient, (2) help clinicians estimate the total NCP burden and study its significance, in analogy to that of the total calcium score, which may lead to improved clinical management of the vulnerable plaques, and (3) accelerate studies to develop new treatment options of coronary heart disease by providing a monitoring tool of treatment response. The proposed CADe system can thus serve as a foundation for these broader future applications and improve the efficacy of cCTA. Improved detection and management of NCPs may reduce the risk of myocardial infarctions and will have strong and long-lasting impact on health care.",Computer-aided detection of non-calcified plaques in coronary CT angiograms,8392109,R01HL106545,"['Acute myocardial infarction', 'American', 'Angiography', 'Arterial Fatty Streak', 'Arteries', 'Atherosclerosis', 'Calcified', 'Calcium', 'Calibration', 'Cardiovascular Diseases', 'Catheters', 'Cause of Death', 'Cessation of life', 'Clinical', 'Clinical Management', 'Computer Vision Systems', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Coronary heart disease', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Dose', 'Early Diagnosis', 'Effectiveness', 'Electrocardiogram', 'Evaluation', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Image', 'Imagery', 'Individual', 'Lead', 'Machine Learning', 'Methods', 'Modality', 'Monitor', 'Myocardial Infarction', 'Patients', 'Performance', 'Phase', 'Procedures', 'Radiation', 'Reader', 'Receiver Operating Characteristics', 'Recording of previous events', 'Resolution', 'Risk', 'Risk Reduction', 'Rupture', 'Scanning', 'Stenosis', 'Stratification', 'System', 'Techniques', 'Testing', 'Thrombosis', 'Time', 'Training', 'Trees', 'Ultrasonography', 'United States', 'Visual', 'Woman', 'computer aided detection', 'density', 'design', 'detector', 'improved', 'innovation', 'men', 'pre-clinical', 'prospective', 'radiologist', 'response', 'tool', 'treatment response', 'virtual']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2013,552793,641965656,-0.03754459249344003
"Predicting Hip Fracture Using a Biomechanical Approach     DESCRIPTION (provided by applicant): Hip fractures are a significant cause of disability and mortality in older persons. The most common tool for diagnosis of osteoporosis and prediction of fracture risk is bone mineral density (BMD) measured by dual- energy X-ray absorptiometry. Yet, up to half of individuals suffering a hip fracture do not have osteoporosis by BMD testing; thus alternative approaches to fracture risk assessment are needed. This underscores the importance of looking for additional contributors to fracture risk, such as reduced soft tissue thickness at the trochanter, which attenuates the fall forces that may lead to fracture. According to biomechanical principles, when the ratio of applied force to bone strength, (termed the 'Factor-of-Risk'), exceeds one, a fracture will occur. Two previous studies have examined the Factor-of-Risk along with trochanteric soft tissue thickness but had only small numbers of hip fractures, and conflicting results. To better understand the factors associated with hip fracture, we propose to use a biomechanical approach to assess hip fracture risk that includes both estimated forces applied to the hip during a sideways fall as well as the strength of the proximal femur. The specific goal is to investigate the contribution of trochanteric soft tissue thickness t hip fracture risk, and to include this in the biomechanical Factor-of-Risk model. We hypothesize these factors predict hip fracture, and further that the factor-of-risk prediction of hip fracture isk will prove better than BMD assessment alone and better than the World Health Organization FRAX tool. We will identify prospectively ascertained hip fracture cases from three cohorts (Framingham Study, MrOS, Rancho Bernardo Study) and from each cohort also select up to four sex- and age-matched (within 3-years) non-fracture cohort members as controls, using the case-cohort study design to increase efficiency. Soft tissue thickness in 2,435 individuals will be assess on whole body DXA scans obtained at the earliest time in each cohort before any subsequent hip fracture occurred. Relative risks will be assessed as odds ratios using conditional logistic regression. This study has potential to significantly alter the way hip fractue risk is currently being assessed, and thus how patients are selected for drug therapy.         PUBLIC HEALTH RELEVANCE: The most common tool to diagnose osteoporosis/predict hip fracture risk is bone density testing, and yet, up to half of adults suffering a hip fracture do no have osteoporosis by this test; thus alternative approaches to fracture risk assessment are needed. We will investigate the role of trochanteric soft tissue thickness to hip fracture risk, an include this in the biomechanical Factor-of-Risk model, to examine if they will predict hip fracture and further do so better than currently available prediction tools, providing new public health insights            ",Predicting Hip Fracture Using a Biomechanical Approach,8503790,R01AR060816,"['Adrenal Cortex Hormones', 'Adult', 'Age', 'Area', 'Attention', 'Attenuated', 'Biomechanics', 'Bone Density', 'Clinical', 'Cohort Studies', 'Conflict (Psychology)', 'Data', 'Diagnosis', 'Dual-Energy X-Ray Absorptiometry', 'Elderly', 'Evaluation', 'Failure', 'Femur', 'Fracture', 'Goals', 'Gold', 'Height', 'Hip Fractures', 'Hip region structure', 'Incidence', 'Individual', 'Lead', 'Logistic Regressions', 'Measurement', 'Measures', 'Menopause', 'Methods', 'Modeling', 'Odds Ratio', 'Osteoporosis', 'Patients', 'Pharmacotherapy', 'Predictive Value', 'Public Health', 'Publishing', 'Recording of previous events', 'Relative Risks', 'Research Design', 'Risk', 'Risk Assessment', 'Risk Factors', 'Role', 'Scanning', 'Smoking Status', 'Surface', 'Testing', 'Thick', 'Time', 'Trochanters', 'Weight', 'Woman', 'Work', 'World Health Organization', 'absorption', 'base', 'bone strength', 'cohort', 'diagnosis standard', 'disability', 'falls', 'hip bone', 'improved', 'insight', 'member', 'men', 'mortality', 'osteoporosis with pathological fracture', 'public health relevance', 'sex', 'soft tissue', 'tool']",NIAMS,HEBREW REHABILITATION CENTER FOR AGED,R01,2013,586894,10587954,-0.011922047005883209
"Efficient patient-specific cell generation by image-guidance    DESCRIPTION (provided by applicant): This fast-track proposal applies advanced kinetic image pattern recognition (KIPR) technologies to predict induced pluripotent stem cell (iPSC) reprogramming colonies' differentiation outcomes for significantly improved yield and robustness of differentiation protocols. The objectives of the proposed tool are 1) Teaching: creation of scores for induced colony differentiation outcome prediction by machine learning; 2) Reprogramming: optimal reprogramming harvest time determination by continuous colony score monitoring; 3) Differentiation: selection of colonies with the highest prediction scores for differentiation at the reprogramming harvest time; 4) Differentiation: cell cluster quality control by continuous monitoring during differentiation. The specific aims of this fast-track proposal are Phase I: 1) Extend SVCell for the prediction of induced colony differentiation outcomes ; 2) Validate that prediction of colony differentiation outcomes can improve the yield of CM differentiation. Phase II: 1) Validate that the integrated system can be taught to be robust and high yielding for a diverse set of human fibroblast input samples and different reprogramming / differentiation protocols; 2) Integrate SVCell with a state-of-the-art continuous cell imaging and culture system to create a prototype patient-specific cell generation system; 3) Validate the integrated system as a patient-specific cell generation product. The ultimate goal of this fast-track proposal is to develop and validate an image-guided efficient patient-specific cardiomyocyte generation system. This will be achieved by integrating our established SVCell software containing advanced KIPR technologies with a live cell imaging technology to synthesize state-of-the-art cell fate control protocols against iPSC. Patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. Successful development of the patient-specific cell generation system of this proposal could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.        Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.         ",Efficient patient-specific cell generation by image-guidance,8509778,R44HL106863,"['Biotechnology', 'Brain Diseases', 'Cardiac Myocytes', 'Cell Culture System', 'Cell Differentiation process', 'Cell Fate Control', 'Cells', 'Cellular Morphology', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Fibroblasts', 'Generations', 'Goals', 'Government', 'Harvest', 'Health', 'Healthcare', 'Heart', 'Human', 'Image', 'Imaging technology', 'Institutes', 'Kinetics', 'Life', 'Machine Learning', 'Medicine', 'Metric', 'Monitor', 'Outcome', 'Patients', 'Pattern Recognition', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Production', 'Protocols documentation', 'Quality Control', 'Sampling', 'Staging', 'Staining method', 'Stains', 'Stem cells', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Work', 'alanine aminopeptidase', 'base', 'cell type', 'cellular imaging', 'cost', 'cost effectiveness', 'disease diagnosis', 'drug discovery', 'drug testing', 'human embryonic stem cell', 'improved', 'induced pluripotent stem cell', 'patient population', 'prototype', 'stem cell technology', 'tool', 'usability']",NHLBI,"DRVISION TECHNOLOGIES, LLC",R44,2013,983515,1296025,-0.02372790149618907
"The Cardiovascular Research Grid DESCRIPTION (provided by applicant):    The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinations of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotating ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and motion that can predict the early presence of developing heart disease in time for therapeutic intervention. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informatics system that allows clinical information to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG.  RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8424997,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'High Performance Computing', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Ultrasonography', 'Work', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2013,2177404,807432003,0.005026015829359994
"Mitigating risk in a closed loop system by exercise detection and miniaturization No abstract available PUBLIC HEALTH RELEVANCE: In the US, approximately 1 million people have been diagnosed with type 1 diabetes. Diabetes is the leading cause of blindness, kidney failure, and non-traumatic amputation. Improving blood glucose control with a miniaturized closed loop (automated) system for use within real world situations including those in which patients move about freely and exercise, as proposed here, will decrease the risk of hypoglycemia and the risk of complications that can be debilitating, such as eye disease, and life-threatening, such as heart attacks. Such benefits will improve the quality of life for the individual with diabetes and reduce the cost to society as a whole.            ",Mitigating risk in a closed loop system by exercise detection and miniaturization,8639368,DP3DK101044,"['Address', 'Adult', 'Algorithms', 'Amputation', 'Artificial Pancreas', 'Bicycling', 'Blindness', 'Blood Glucose', 'Car Phone', 'Catheters', 'Clinical', 'Clinical Research', 'Communication', 'Controlled Study', 'Data', 'Detection', 'Devices', 'Diabetes Mellitus', 'Diagnosis', 'Emotions', 'Engineering', 'Event', 'Exercise', 'Eye diseases', 'Frequencies', 'Generations', 'Glucagon', 'Glucose', 'Heart Rate', 'Home environment', 'Hormonal', 'Hormones', 'Hour', 'Hypoglycemia', 'Individual', 'Infusion procedures', 'Inpatients', 'Insulin', 'Insulin-Dependent Diabetes Mellitus', 'Kidney Failure', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Metabolism', 'Methods', 'Miniaturization', 'Modeling', 'Modification', 'Monitor', 'Muscle', 'Myocardial Infarction', 'Outpatients', 'Patients', 'Performance', 'Persons', 'Power Sources', 'Pump', 'Quality of life', 'Risk', 'Risk Factors', 'Running', 'Severities', 'Simulate', 'Societies', 'Study Subject', 'System', 'Techniques', 'Technology', 'Telephone', 'Testing', 'Training', 'Update', 'Work', 'base', 'blood glucose regulation', 'cost', 'design', 'glucose sensor', 'glucose uptake', 'improved', 'insulin sensitivity', 'miniaturize', 'public health relevance', 'response', 'sensor', 'simulation', 'strength training', 'success', 'usability']",NIDDK,OREGON HEALTH & SCIENCE UNIVERSITY,DP3,2013,2943303,304670088,-0.0034888498501235935
"Family History, Genes, Environment and G X E Interaction in Predicting RA Risk DESCRIPTION (provided by applicant): Since receiving the K24 award, I have established a successful clinical research and training program in patient-oriented research (POR) in rheumatic disease with a focus on genetic, biomarker, and environmental risk factors for rheumatoid arthritis (RA) and systemic lupus erythematosus (SLE). I continue to have independent grant support, and have mentored 15 new clinical investigators who have published 25 peer- reviewed papers during the K24 period. Three mentees have received NIH K awards and one has received an NIH R01. With renewal of the K24, I would continue to have protected time to devote to this program that has a unique training environment and an array of important POR projects. Genetic and environmental epidemiology studies have produced convincing evidence for multiple alleles and exposures as RA risk factors. A strong gene-environment (GXE) interaction between HLA-DRB1 alleles and smoking has been demonstrated for risk of the immune phenotype of CCP positive RA but not CCP negative RA. As CCP antibodies occur years before RA onset, I hypothesize that this interaction induces anti-citrulline immunity, a critical step in RA pathogenesis. These findings emphasize the need to study genes, environment and immunity with careful phenotyping. Family history encompasses unmeasured genetic and environmental risk, yet is not measured accurately in other studies including those in my research portfolio. Specific aims are to: 1) Maintain and expand my clinical research training program by mentoring new clinical investigators in POR in rheumatic diseases; 2) Enrich my comprehensive POR program to study family history, genetic, and environmental predictors in the etiology of RA using a new collection of RA cases and controls from Partners HealthCare; 2a) Collect family history data and environmental exposure data concerning smoking and reproductive factors on 1,500 RA patients and 4,500 age- and gender-matched controls by utilizing natural language processing (NLP) queries of electronic medical records; 2b: Examine genetic risk factors, environmental risk factors and GXE in predicting immune phenotypes of RA: RA with and without CCP antibodies (CCP?), and RA with and without rheumatoid factor antibodies (RF?); and 2c: Apply this comprehensive risk model to RA cases and controls and to subsets of RA stratified by specific immune phenotypes and stratified by family history of RA and other autoimmune diseases. The proposed study will leverage the NIH funded Informatics for Integrating Biology and the Bedside study that used an advanced informatics infrastructure to extract clinical data on RA diagnostic features through database mining and NLP. A highly specific algorithm was used to identify RA cases and collect samples from cases and controls. The NLP techniques will be used to extract risk factor data from clinical notes. This proposal builds on my strong track record of POR, extending the work to add family history from a new case-control collection, validate data by patient interview, and develop predictive models for risk of RA that can be used to select high risk individuals for future RA prevention trials. Project Narrative  Innovative predictive modeling incorporating family history, genes, environmental exposures, and gene-  environment interactions, is a key step in the progress towards an RA prevention clinical trial.","Family History, Genes, Environment and G X E Interaction in Predicting RA Risk",8288292,K24AR052403,"['ARHGEF5 gene', 'Address', 'Age', 'Air Pollution', 'Algorithms', 'Alleles', 'Antibodies', 'Antigens', 'Area', 'Autoantibodies', 'Autoimmune Diseases', 'Behavioral', 'Bioinformatics', 'Biological Markers', 'Biology', 'Body mass index', 'Breathing', 'Calibration', 'Candidate Disease Gene', 'Case-Control Studies', 'Cigarette', 'Citrulline', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Cohort Studies', 'Collection', 'Computerized Medical Record', 'Cox Proportional Hazards Models', 'DNA', 'DNA Markers', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Environment', 'Environmental Epidemiology', 'Environmental Exposure', 'Environmental Risk Factor', 'Epidemiologic Studies', 'Epidemiologist', 'Epidemiology', 'Epitopes', 'Etiology', 'Exposure to', 'Family', 'Family Study', 'Family history of', 'Female', 'First Degree Relative', 'Funding', 'Future', 'Gender', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic Variation', 'Genotype', 'Grant', 'HLA-DR4 Antigen', 'HLA-DRB1', 'Healthcare', 'Heterogeneity', 'Hormonal', 'Hormones', 'Human Genome', 'ICD-9', 'Immune', 'Immunity', 'Immunologist', 'Incidence', 'Individual', 'Inflammatory', 'Informatics', 'Institution', 'Interdisciplinary Study', 'Interview', 'K-Series Research Career Programs', 'Laboratories', 'Lead', 'Life', 'Link', 'Logistic Models', 'Logistic Regressions', 'Lung', 'Measures', 'Menopausal Status', 'Mentors', 'Meta-Analysis', 'Methods', 'Methotrexate', 'Mid-Career Clinical Scientist Award (K24)', 'Minerals', 'Mining', 'Modeling', 'Modification', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Notification', 'Occupational', 'PTPN22 gene', 'Paper', 'Particulate', 'Particulate Matter', 'Pathogenesis', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Phenotype', 'Physicians', 'Pollution', 'Population', 'Predisposition', 'Prevention', 'Prevention strategy', 'Principal Investigator', 'Publishing', 'Race', 'Recording of previous events', 'Records', 'Reproductive History', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Research Training', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatoid Factor', 'Risk', 'Risk Factors', 'STAT4 gene', 'Sampling', 'Siblings', 'Signs and Symptoms', 'Single Nucleotide Polymorphism', 'Smoking', 'Socioeconomic Status', 'Statistical Methods', 'Stratification', 'Subgroup', 'Surface', 'Sushi Domain', 'Sweden', 'Symptoms', 'System', 'Systemic Lupus Erythematosus', 'TNF receptor-associated factor 1', 'Techniques', 'Testing', 'Text', 'Time', 'Toxic Environmental Substances', 'Training', 'Training Programs', 'Travel', 'Tumor Necrosis Factor-alpha', 'United States', 'United States National Institutes of Health', 'Variant', 'Woman', 'Work', 'abstracting', 'adalimumab', 'base', 'case control', 'cigarette smoking', 'cohort', 'cost effective', 'cyclic citrullinated peptide', 'cytokine', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic analysis', 'genetic association', 'genetic epidemiology', 'genetic risk factor', 'genetic technology', 'genetic variant', 'genome wide association study', 'high risk', 'improved', 'inclusion criteria', 'infliximab', 'innovation', 'insight', 'meetings', 'men', 'multidisciplinary', 'novel', 'parity', 'patient oriented research', 'pre-clinical', 'predictive modeling', 'prevent', 'prevention clinical trial', 'programs', 'reproductive', 'research study', 'response', 'sample collection', 'sex', 'toxin metabolism', 'trafficking', 'treatment response', 'tumor necrosis factor-alpha inhibitor']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,K24,2012,157939,327644200,-0.016028628519662386
"Machine Learning Tools for Prognostication in Melanoma    DESCRIPTION (provided by applicant): The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.  Cutaneous melanoma is the sixth most common cancer in the United States, and its incidence rate is increasing faster than any other cancer. Nearly 69,000 new cases are expected be diagnosed in this country in 2010. While thin melanomas are typically cured with excision alone, thicker melanomas have a greater tendency to metastasize to the regional lymph nodes.  A diagnosis of Stage III melanoma is made if there is spread to the regional lymph nodes. Unfortunately, there is marked diversity in the natural history of Stage III melanoma, and outcomes within this group are extremely heterogeneous, with 5- year survival rates ranging from 23% to 87%. Similarly, treatment options range from intensive forms of systemic therapy to observation. Understanding patients' differences in clinical outcome is critical not only for calibrating therapeutic intensity to metastatic risk but also in the design and analysis of clinical trials.  There is a real void of reliable prognostic tools for Stage III melanoma. Based on novel machine learning approaches, the purpose of this study will be to develop and validate a reliable and individualized tool for prognostication of Stage III melanoma patients that can be used in the clinical setting.        The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.         ",Machine Learning Tools for Prognostication in Melanoma,8335369,R21CA152775,"['Address', 'American Joint Committee on Cancer', 'Cancer Prognosis', 'Classification', 'Clinical', 'Clinical Trials', 'Complex', 'Country', 'Cutaneous Melanoma', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Pathway', 'Dose', 'Evaluation', 'Excision', 'Heterogeneity', 'Incidence', 'Individual', 'Interferons', 'Logic', 'Lymph Node Dissections', 'Machine Learning', 'Malignant Neoplasms', 'Metastatic to', 'Methodology', 'Methods', 'Michigan', 'Modeling', 'Multivariate Analysis', 'Natural History', 'Neoplasm Metastasis', 'Nodal', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Proportional Hazards Models', 'Publications', 'Reporting', 'Risk', 'Sentinel Lymph Node Biopsy', 'Staging', 'Statistical Methods', 'Subgroup', 'Survival Rate', 'Systemic Therapy', 'Therapeutic', 'Thick', 'Trees', 'United States', 'Universities', 'Validation', 'advanced disease', 'base', 'cancer risk', 'clinical decision-making', 'design', 'editorial', 'flexibility', 'forest', 'hazard', 'lymph nodes', 'melanoma', 'minimally invasive', 'novel', 'outcome forecast', 'prognostic', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2012,159977,641965656,-0.024866169658442107
"Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements    DESCRIPTION (provided by applicant): Thyroid nodules are present in a large fraction of healthy individuals. Between 4% and 7% of the United States adult population has palpable thyroid nodules, and up to 50% of American women older than age 50 have nodules that can be depicted on ultrasound. The vast majority (>95%) of thyroid nodules are benign. However, cancer risk increases with male gender, nodule size, extremes of age (< 30 and > 60 years), underlying autoimmune disease, nodule growth, personal or family history of thyroid cancer, and radiation exposure. Ultrasound imaging and Fine Needle Aspiration Biopsy (FNAB) remain the mainstays of thyroid nodule evaluation. Unfortunately, 25% of patients who ultimately undergo FNAB of a thyroid nodule have indeterminate cytology. Many of these patients will require at least partial thyroidectomy purely for the purpose of obtaining a definitive diagnosis. Given that only 30% of these will ultimately prove to be malignant on surgical pathology, the majority of these lobectomies could potentially be avoided if better non-invasive methods existed to evaluate indeterminate nodules. Electrical Impedance Scanning (EIS) has been previously investigated for non-invasive evaluation of thyroid nodules. The overall diagnostic accuracy of EIS was encouraging but not sufficient for routine clinical use. We have developed a modified approach termed here Resonance Electrical Impedance Spectroscopy (REIS) that should have substantially higher sensitivity and specificity for this very purpose. When using REIS technology to examine the breast, we obtained initial results that are significantly better in all respects than those obtained with traditional EIS. We believe that REIS technology will similarly improve the assessment of thyroid nodules. REIS hold promise as a reproducible modality for the risk stratification of the many patients with indeterminate thyroid nodules. It is a new non- invasive modality that may help reduce the number of diagnostic lobectomies and would be welcomed by patients with non-diagnostic FNA results. The purpose of this application is to design, assemble, and test in a preliminary clinical study a unique REIS based device for the assessment of thyroid nodules.      PUBLIC HEALTH RELEVANCE: We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.           Project narrative:  We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.",Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements,8207850,R21CA154262,"['Address', 'Adult', 'Age', 'American', 'Aspirate substance', 'Autoimmune Diseases', 'Benign', 'Biopsy', 'Breast', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Consent', 'Cytology', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Endocrine', 'Endocrinologist', 'Evaluation', 'Excision', 'Family history of', 'Fine needle aspiration biopsy', 'Follicular thyroid carcinoma', 'Frequencies', 'Gender', 'General Anesthesia', 'Growth', 'Human', 'Image', 'Incidence', 'Individual', 'Lesion', 'Lobectomy', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measurement', 'Measures', 'Methods', 'Modality', 'Neck', 'Nodule', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Palpable', 'Papillary', 'Papillary Carcinoma', 'Participant', 'Patients', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Procedures', 'Prospective Studies', 'Protocols documentation', 'Publishing', 'Radiation', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Spectrum Analysis', 'Stratification', 'Surgeon', 'Surgical Pathology', 'System', 'Techniques', 'Technology', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Thyroidectomy', 'Triage', 'Ultrasonography', 'United States', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer risk', 'clinical practice', 'design', 'diagnostic accuracy', 'electric impedance', 'imaging modality', 'improved', 'male', 'malignant breast neoplasm', 'men', 'older women', 'phase change', 'prospective', 'prototype', 'public health relevance', 'radiologist', 'tool', 'web site']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2012,164756,570146095,-0.04755440647489828
"Longitudinal Assessment of Fall Risk    DESCRIPTION (provided by applicant): Falling is not a normal part of the aging process and yet 1/3 to 1/2 of adults 65 years and older sustain at least one fall annually. Older adults are hospitalized for fall related injuries five times more often than from injuries from other causes contributing to a cost of $19 billion for nonfatal falls in the United States. Projected for the increasing aging population in the year 2020, it is expected that the costs related to falls will reach a staggering 54.9 billion dollars. Current research and clinical practice guidelines focus on multifactorial fall risk assessments as the critical deterrent to falls in the elderly. A primary factor within these assessments is activity of daily living performance of the individual elder. While current standardized clinical balance assessment tools have been proven effective for predicting fall risk, the tests are most commonly performed in the clinical environment and at isolated times during an individual's day. The goal of this application is to develop and validate a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. Such a device: - will allow early detection of risk of falling, when therapeutic interventions are most efficient - will provide real-time feedback about activity pattern - will provide feedback about compliance with interventions and effectiveness of interventions - will be incorporated into conventional footwear and require no extra effort to operate - can be used in research, clinical and potentially in consumer applications The development of the ALARM system will be addressed in three specific aims:  Specific Aims 1: Develop a pattern recognition method that will improve recognition accuracy for activities of interest (such as walking and stepping up) by reducing the range of variation from current 76%- 100% to 9911%. Specific Aim 2: Collect data using the ALARM device on a group of elderly adults during clinical tests. Specific Aim 3: Develop algorithms for automatic assessment of risk of falling. In this Aim we will develop signal processing algorithms that automatically evaluate metrics indicative of the risk of falling in each activity of interest (e.g. duration of swing and stance phase during walking). Specific Aim 4: Validate the ALARM device in a double-blind unrestricted free living study. This set of Specific Aims will validate lead to creation of a unique wearable device capable of objective characterization of risk of falling.        This application aims at development of a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. In our previous research we have shown that major activities and posture allocations such as standing, sitting, walking, etc. can be recognized with high degree of accuracy (76%-100%) by a wearable device incorporated into conventional footwear. We also have shown that sensor signals captured by the wearable shoe device during activities such as walking are well- correlated with the risk of falling (with numerical estimates of risk obtained through signal processing being directly proportional to the normalized scores from the clinical tests). The goal of this application is to develop and validate a novel wearable device (ALARM) for longitudinal assessment of risk of falling.         ",Longitudinal Assessment of Fall Risk,8339885,R21EB013183,"['Acceleration', 'Activities of Daily Living', 'Address', 'Adult', 'Aging-Related Process', 'Algorithms', 'Classification', 'Clinical', 'Clinical Practice Guideline', 'Communities', 'Comparative Study', 'Computational algorithm', 'Computers', 'Data', 'Data Set', 'Development', 'Devices', 'Double-Blind Method', 'Early Diagnosis', 'Effectiveness of Interventions', 'Elderly', 'Engineering', 'Environment', 'Equilibrium', 'Evaluation', 'Feasibility Studies', 'Feedback', 'Goals', 'Heel', 'Individual', 'Injury', 'Intervention', 'Laboratories', 'Lead', 'Life', 'Machine Learning', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Metric', 'Monitor', 'Neural Network Simulation', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Posture', 'Process', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Series', 'Shoes', 'Signal Transduction', 'System', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'United States', 'Validation', 'Variant', 'Walking', 'aging population', 'base', 'computerized data processing', 'cost', 'fall risk', 'falls', 'human old age (65+)', 'improved', 'interest', 'novel', 'pressure', 'sensor', 'tool', 'volunteer']",NIBIB,UNIVERSITY OF ALABAMA IN TUSCALOOSA,R21,2012,185300,5620537,-0.0072192863526132755
"Cumulative Glycemic Burden and Cardiovascular Disease Risk in Type 2 Diabetes    DESCRIPTION (provided by applicant): We seek to provide evidence that prolonged, continuous, tight glycemic control, initiated when type 2 diabetes (DM) is first diagnosed and maintained throughout patients' DM lifetime, can reduce the risk of cardiovascular disease (CVD). Current recommendations on care for persons with DM include tight glycated hemoglobin (A1C) control (<7%) as a means to reduce risk of CVD and other complications. Recent studies raised questions about this recommendation by failing to demonstrate that tight A1C control provides CV benefit in persons with DM, but these studies could not account for glycemic control prior to trial initiation. Other research supports the benefit of tight glycemic control over time, and suggests that even moderately elevated A1C levels in the 'normal' range indicate long-term CVD risk. To address these seemingly contradictory perspectives on how to optimize DM care, we propose to test the hypothesis that tight glycemic control does indeed reduce CVD risk, if begun early and continued throughout the course of DM. We will also assess whether cumulative glycemic burden over time, predict long-term CVD risk better than current A1C level or mean A1C over time, and to identify threshold levels of cumulative glycemic burden at which CVD risk becomes markedly elevated, among persons with DM. We will conduct the proposed analyses using data from the Kaiser Permanente Northwest Diabetes Registry. Since 1988, KPNW has developed and maintained this highly specific, sensitive, data-rich registry of members with DM; as of December 2009, it contained data on >70,000 persons. Among adults who joined the registry in 1995-2010, we will identify individuals who experienced a CVD event and match them to 5 controls who did not. We will then conduct multivariate logistic regression analyses of the extent to which A1C, mean A1C, and cumulative A1C burden predict time until first CVD event, and describe differences in the odds of CVD from date of DM diagnosis through 2010, to identify cut-points (of A1C, mean A1C over time, and cumulative glycemic burden levels) where CVD risk increases. The clinical application of such findings would lie in proving what has long been suspected - that cumulative glycemic burden is a critical CVD risk factor - thus providing critical support for the importance of initiating tight glycemic control immediately upon DM diagnosis and maintaining such control rigorously. No previous studies have evaluated cumulative glycemic burden as an indicator of CVD risk in DM, alone or in comparison to mean A1C over time, despite cumulative burden's biological plausibility as a CVD risk factor. The proposed work builds on our previous development of methods for measuring cumulative glycemic burden.      PUBLIC HEALTH RELEVANCE: This study will use existing data on Kaiser Permanente Northwest members with diabetes from 1995- 2010 to assess whether control of high blood sugar, if begun early and continued over time, reduces cardiovascular disease risk. We will use a novel measure of high blood sugar, glycemic burden, which accounts for how high blood sugar is and how long it has been high. Our results would show the importance of treating blood sugar aggressively immediately upon diabetes diagnosis and maintaining such aggressive treatment rigorously.              This study will use existing data on Kaiser Permanente Northwest members with diabetes from 1995- 2010 to assess whether control of high blood sugar, if begun early and continued over time, reduces cardiovascular disease risk. We will use a novel measure of high blood sugar, glycemic burden, which accounts for how high blood sugar is and how long it has been high. Our results would show the importance of treating blood sugar aggressively immediately upon diabetes diagnosis and maintaining such aggressive treatment rigorously.            ",Cumulative Glycemic Burden and Cardiovascular Disease Risk in Type 2 Diabetes,8233903,R21DK091773,"['Accounting', 'Address', 'Adult', 'Atherosclerosis', 'Biological', 'Blood Glucose', 'Cardiovascular Diseases', 'Caring', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Coupled', 'Data', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Digestive System Disorders', 'Epidemiology', 'Evaluation Studies', 'Event', 'Future', 'Glycosylated Hemoglobin', 'Goals', 'Heart', 'Hyperglycemia', 'Individual', 'Kidney Diseases', 'Lead', 'Logistic Regressions', 'Measurement', 'Measures', 'Methods', 'Myocardial Infarction', 'Negative Finding', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Range', 'Obesity', 'Outcome', 'Patients', 'Persons', 'Recommendation', 'Registries', 'Regression Analysis', 'Research Support', 'Risk', 'Risk Factors', 'Risk Reduction', 'Role', 'Sample Size', 'Specific qualifier value', 'Testing', 'Therapeutic', 'Time', 'United Kingdom', 'Work', 'burden of illness', 'cardiovascular disorder risk', 'clinical application', 'clinical practice', 'experience', 'follow-up', 'glycemic control', 'heart disease risk', 'innovation', 'member', 'method development', 'mortality', 'novel', 'patient registry', 'prevention evaluation', 'prospective', 'response']",NIDDK,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2012,197500,111231681,-0.007347334773739506
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.           Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8320160,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'metagenome', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2012,204974,2836411,-0.017295793934812717
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence  Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.  Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8471822,R00LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Screening procedure', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2012,224100,570146095,-0.00846018583035409
"Ontology-based Information Network to Support Vaccine Research  Project Summary (Abstract):  Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.  Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,8311060,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Semantics', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'abstracting', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2012,264994,641965656,-0.00514632052973126
"Novel Tree-based Statistical Methods for Cancer Risk Prediction     DESCRIPTION (provided by applicant): The contradiction of early cancer detection is that while some benefit others receive a detrimental diagnosis. A definitive example is mammography and ductal carcinoma in situ (DCIS), a noninvasive breast cancer. DCIS, which most frequently presents as a non-palpable lesion, was rarely detected before the advent of modern mammography. Since 1983 there has been a 290% increase in DCIS incidence in women under 50 and 500% in those over 50. Given that only 5-10% of DCIS cases progress to invasive cancer with a 10-year mortality rate of 1-2%, DCIS experts suggest breast conservation for the majority of patients. However, these women continue to be overtreated with mastectomy and radiation, at rates comparable to those with invasive cancer. The inability to discern those at low vs. high risk is due in part to non-reproducible study results as well as inadequate statistical methods for risk prediction and validation.  We have collected a population-based DCIS cohort with the goal of delineating those women least likely to recur with invasive cancer and, hence, appropriate candidates for less aggressive treatments. Recently we established risk indices and published the corresponding absolute risk estimates for type of recurrence. However, two features of the study design, namely the presence of competing risks and the use of a stratified case-cohort design, constrained us to using crude empirical methods for analysis and left us unable to validate the clinical utility of our models. The overarching goal of this proposal is to develop a unified, principled statistical framework for building, selecting, and evaluating clinically relevant risk indices, permitting refinement and validation of existing risk prediction models in our DCIS study as well as beyond.  We face multiple challenges including how to objectively build risk indices with relevant variables; how to estimate the corresponding risks (competing or not) in various subsample study designs; and, how to validate the resulting risk prediction models. Recently, we developed partDSA, a tree-based method which affords tremendous flexibility in building predictive models and provides an ideal foundation for developing a clinician- friendly tool for accurate stratification and risk prediction. In its curret form, partDSA is unable to estimate absolute risk in the presence of competing risks accounting for subsample study designs. Here we extend partDSA for such clinically relevant scenarios (Aim 1). We also propose aggregate learning for risk prediction to increase prediction accuracy and subsequently to build more stable but easily interpretable risk models (Aim 2). Finally, we propose the necessary methods for validating the resulting models (Aim 3).  Our proposal has two immediate public health benefits: first, these novel statistical methods will result in a clinician-friendly, publicly available tool for accurate risk prediction, stratification and validaion in numerous clinical settings; second, current DCIS risk models will be refined and validated with the expectation of better delineating those at low risk, hence strong candidates for conservative treatments including active surveillance.        PUBLIC HEALTH RELEVANCE: Our proposal has two public health components: first, our novel statistical methods will provide a clinician- friendly, publicly available tool for accurate isk prediction, stratification and validation in numerous clinical settings; second, current ductal carcinoma in situ risk models will be refined and validated, helping facilitate the decision-making process faced by patients and their clinicians.              Our proposal has two public health components: first, our novel statistical methods will provide a clinician- friendly, publicly available tool for accurate isk prediction, stratification and validation in numerous clinical settings; second, current ductal carcinoma in situ risk models will be refined and validated, helping facilitate the decision-making process faced by patients and their clinicians.            ",Novel Tree-based Statistical Methods for Cancer Risk Prediction,8373032,R01CA163687,"['Accounting', 'Anxiety', 'Breast', 'Carcinoma', 'Clinical', 'Code', 'Cohort Studies', 'Communities', 'Computer software', 'Decision Making', 'Diagnosis', 'Epidemiology', 'Face', 'Face Processing', 'Foundations', 'Goals', 'Health Benefit', 'Incidence', 'Individual', 'Intervention Studies', 'Label', 'Learning', 'Left', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Mastectomy', 'Measures', 'Methods', 'Modeling', 'Noninfiltrating Intraductal Carcinoma', 'Outcome', 'Patients', 'Performance', 'Public Health', 'Publishing', 'Radiation', 'Radiation therapy', 'Recurrence', 'Research Design', 'Risk', 'Risk Estimate', 'Screening for cancer', 'Statistical Methods', 'Stratification', 'Techniques', 'Trees', 'Validation', 'Woman', 'Work', 'anticancer research', 'base', 'breast lumpectomy', 'cancer risk', 'clinically relevant', 'cohort', 'design', 'expectation', 'experience', 'flexibility', 'high risk', 'indexing', 'loss of function', 'malignant breast neoplasm', 'mortality', 'novel', 'open source', 'population based', 'predictive modeling', 'prevent', 'programs', 'research study', 'simulation', 'tool']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2012,335601,685608202,-0.04023653915906452
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.        Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8294581,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Screening procedure', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild neurocognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2012,348750,507546965,-0.031925684024689566
"FT-IR Microscopy of Mineral Structure    DESCRIPTION (provided by applicant): Osteoporosis is responsible for approximately 1.5 million fractures in the US per year, with 300,000 of these fractures occurring at the hip at a cost exceeding $17 billion. The NIH Consensus conference and the World Health Organization defined osteoporosis as ""...compromised bone strength predisposing to an increased risk of fracture"". A variety of genetic and environmental factors, as well as bone properties (geometric and material), contribute to the bone loss that is associated with osteoporosis, but the question remains as to which factors primarily contribute to fracture risk. While reduced bone mineral density (BMD) relative to young individuals is routinely used clinically to predict fracture risk, BMD is not a strong predictor, with the majority of fractures occurring in patients with BMD's above the osteoporotic threshold. We have recently shown by multiple logistic regression analysis that specific mineral and matrix properties assessed by Fourier transform infrared spectroscopic imaging (FTIRI) are predictive of fracture in postmenopausal women, while BMD is not significantly associated with fracture incidence. In a limited number of samples we have also shown that these FTIR parameters are correlated with nanomechanical properties. We hypothesize that variation in crystallinity (XST) and collagen maturity (XLR) partially explains the difference in incidence of fractures in individuals with similar BMDs. We further hypothesize that heterogeneity in these parameters is an additional determinant of fracture incidence, especially in trabecular bone. In the proposed studies we will test 4 hypotheses. 1) For any subject, FTIRI data obtained in the cortical and cancellous bone of the iliac crest (generally a non-fracturing site) is representative of that from sites that fracture (subtrochanter/greater trochanter). Further, the data are independent of the size of the biopsy as long as cortical and cancellous bone areas are included. This will be tested using multiple biopsies from cadavers and from clinic patients with fractures. Measures will include micro-CT analysis of BMD and architecture, and FTIRI. 2) Decreased heterogeneity in FTIRI mineral and matrix properties, in addition to increased XST and XLR, are predictive of fracture in humans. This will be tested by extending our logistic regression to heterogeneity parameters. Variation in tissue properties with age will be studied in patients with idiopathic juvenile osteoporosis. Tissue mechanical properties will be correlated with FTIRI data. 3) An anabolic agent (PTH) can restore mechanical properties, and the XST, XLR, and mineral and matrix heterogeneity in animal models as well as in osteoporotic humans. This will be tested by analyses of pre- and post- treatment human biopsies and by analyses in a sheep model. 4) XLR, which is altered in osteoporosis, is related to collagen orientation. As part of our continued parameter validation, this will be tested by comparing FTIRI and second harmonic heneration microscopy data. Testing of these four hypotheses will provide new insights into the efficacy of therapies and contribute to the understanding of factors leading to fracture.      PUBLIC HEALTH RELEVANCE: The objective of this continuing investigation is to discover what changes in bone properties cause a bone in a person with osteoporosis to break; we have suggestive evidence that changes in the structure and composition of the bone composite (mineral and matrix) put bones at risk of breaking during normal activities of daily life. Correlations are sought between spatial variation in parameters obtained by vibrational spectroscopy and mechanical properties. This information should lead to improved diagnosis and new approaches to prevention and treatment of osteoporosis, the ""silent epidemic"".              The objective of this continuing investigation is to discover what changes in bone properties cause a bone in a person with osteoporosis to break; we have suggestive evidence that changes in the structure and composition of the bone composite (mineral and matrix) put bones at risk of breaking during normal activities of daily life. Correlations are sought between spatial variation in parameters obtained by vibrational spectroscopy and mechanical properties. This information should lead to improved diagnosis and new approaches to prevention and treatment of osteoporosis, the ""silent epidemic"".",FT-IR Microscopy of Mineral Structure,8303017,R01AR041325,"['Acids', 'Activities of Daily Living', 'Adolescent', 'Adult', 'Aftercare', 'Age', 'Alendronate', 'Amides', 'Anabolic Agents', 'Animal Model', 'Architecture', 'Area', 'Biopsy', 'Bone Density', 'Cadaver', 'Carbonates', 'Clinic', 'Collagen', 'Consensus', 'Data', 'Data Sources', 'Diagnosis', 'Environmental Risk Factor', 'Epidemic', 'Estrogens', 'Fourier Transform', 'Fracture', 'Funding', 'Generations', 'Genetic', 'Heterogeneity', 'Hip Fractures', 'Hip region structure', 'Hospitals', 'Human', 'Image', 'Incidence', 'Individual', 'Investigation', 'Lead', 'Logistic Regressions', 'Measures', 'Mechanics', 'Microscopy', 'Minerals', 'Modeling', 'New York', 'Osteon', 'Osteoporosis', 'Patients', 'Pattern', 'Persons', 'Postmenopause', 'Presbyterian Church', 'Prevention approach', 'Property', 'Puberty', 'Raloxifene', 'Regression Analysis', 'Relative (related person)', 'Reporting', 'Risk', 'Sampling', 'Sheep', 'Site', 'Spectroscopy, Fourier Transform Infrared', 'Spectrum Analysis', 'Structure', 'Structure of greater trochanter of femur', 'Techniques', 'Testing', 'Tissues', 'Treatment Efficacy', 'United States National Institutes of Health', 'Validation', 'Variant', 'Weight', 'Woman', 'World Health Organization', 'X ray diffraction analysis', 'X-Ray Diffraction', 'animal tissue', 'bone', 'bone loss', 'bone quality', 'bone strength', 'cost', 'crosslink', 'improved', 'inorganic phosphate', 'insight', 'nano', 'nanomechanical', 'nonhuman primate', 'novel strategies', 'public health relevance', 'repaired', 'second harmonic', 'skeletal', 'spectroscopic imaging', 'substantia spongiosa', 'symposium', 'young adult']",NIAMS,HOSPITAL FOR SPECIAL SURGERY,R01,2012,477294,9232826,0.00025195659949128974
"Computer-aided detection of non-calcified plaques in coronary CT angiograms   Cardiovascular disease is the leading cause of death in both men and women in the United States. Over 16 million Americans have coronary heart disease (CHD), causing about 0.5 million deaths each year. The most common CHD is coronary artery disease which is mainly caused by atherosclerosis. Clinical evidence in recent years shows that noncalcified plaques (NCPs) are more vulnerable to rupture than calcified plaques. Plaque rupture and the thrombosis that follows is the main cause of acute myocardial infarction. Multidetector coronary CT angiography (cCTA) has the potential to help clinicians in early detection and in quantification of NCPs. cCTA may thus be useful for CHD detection, risk stratification, monitoring, and evaluation of the effectiveness of risk reduction treatment. However, many of these potential applications have not been utilized clinically.  The goal of this project is to develop a computer-aided detection (CADe) system to serve as a second reader for assisting clinicians in detection and quantification of NCPs in cCTA exams. Our specific aims are to (1) develop machine learning methods for detection of NCPs causing stenosis and/or positive remodeling along coronary arteries, and (2) evaluate the effect of CADe on radiologists' detection of NCPs on cCTA by observer ROC study. To achieve these aims, we will collect a database of cCTA cases for training and testing the CADe system, define the search space by designing 3D multiscale coronary artery response enhancement, segmentation, and dynamic balloon vessel tracking methods, develop a unique vessel- stitching method to automatically identify the best-quality phase for each individual artery segment from all available phases in prospectively or retrospectively gated cCTA exams, develop innovative vessel-sector- profile analysis and vessel lumen analysis to detect NCPs that cause stenosis or positive remodeling, estimate the total NCP volume, and explore calibration method to quantify plaque density by phantom studies. To demonstrate the usefulness of CADe, a preclinical reader study will be conducted to compare radiologists' detection accuracy of NCPs with and without CADe.  The major innovations of this project include (1) being the first CADe system to automatically detect non-calcified plaques including those cause positive remodeling or stenosis in cCTA, (2) development of new machine learning techniques including the vessel-stitching method, vessel-sector-profile analysis, multiscale enhancement response, and dynamic balloon tracking specifically suited for coronary arterial trees, and (3) conducting the first ROC study to evaluate the effect of CADe on radiologists' detection of NCPs.  Narrative:  Cardiovascular disease is the leading cause of death in both men and women in the United States. If the proposed CADe system is successfully developed, it will (1) provide an accurate, efficient, and consistent tool to assist clinicians in detecting and quantifying non-calcified plaques (NCP) including those causing positive remodeling and/or stenosis for an individual patient, (2) help clinicians estimate the total NCP burden and study its significance, in analogy to that of the total calcium score, which may lead to improved clinical management of the vulnerable plaques, and (3) accelerate studies to develop new treatment options of coronary heart disease by providing a monitoring tool of treatment response. The proposed CADe system can thus serve as a foundation for these broader future applications and improve the efficacy of cCTA. Improved detection and management of NCPs may reduce the risk of myocardial infarctions and will have strong and long-lasting impact on health care.",Computer-aided detection of non-calcified plaques in coronary CT angiograms,8206668,R01HL106545,"['Acute myocardial infarction', 'American', 'Angiography', 'Arterial Fatty Streak', 'Arteries', 'Atherosclerosis', 'Calcified', 'Calcium', 'Calibration', 'Cardiovascular Diseases', 'Catheters', 'Cause of Death', 'Cessation of life', 'Clinical', 'Clinical Management', 'Computer Vision Systems', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Coronary heart disease', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Dose', 'Early Diagnosis', 'Effectiveness', 'Electrocardiogram', 'Evaluation', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Image', 'Imagery', 'Individual', 'Lead', 'Machine Learning', 'Methods', 'Modality', 'Monitor', 'Myocardial Infarction', 'Patients', 'Performance', 'Phase', 'Procedures', 'Radiation', 'Reader', 'Receiver Operating Characteristics', 'Recording of previous events', 'Resolution', 'Risk', 'Risk Reduction', 'Rupture', 'Scanning', 'Stenosis', 'Stratification', 'System', 'Techniques', 'Testing', 'Thrombosis', 'Time', 'Training', 'Trees', 'Ultrasonography', 'United States', 'Visual', 'Woman', 'computer aided detection', 'density', 'design', 'detector', 'improved', 'innovation', 'men', 'pre-clinical', 'prospective', 'radiologist', 'response', 'tool', 'treatment response', 'virtual']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2012,585438,641965656,-0.03754459249344003
"Efficient patient-specific cell generation by image-guidance    DESCRIPTION (provided by applicant): This fast-track proposal applies advanced kinetic image pattern recognition (KIPR) technologies to predict induced pluripotent stem cell (iPSC) reprogramming colonies' differentiation outcomes for significantly improved yield and robustness of differentiation protocols. The objectives of the proposed tool are 1) Teaching: creation of scores for induced colony differentiation outcome prediction by machine learning; 2) Reprogramming: optimal reprogramming harvest time determination by continuous colony score monitoring; 3) Differentiation: selection of colonies with the highest prediction scores for differentiation at the reprogramming harvest time; 4) Differentiation: cell cluster quality control by continuous monitoring during differentiation. The specific aims of this fast-track proposal are Phase I: 1) Extend SVCell for the prediction of induced colony differentiation outcomes ; 2) Validate that prediction of colony differentiation outcomes can improve the yield of CM differentiation. Phase II: 1) Validate that the integrated system can be taught to be robust and high yielding for a diverse set of human fibroblast input samples and different reprogramming / differentiation protocols; 2) Integrate SVCell with a state-of-the-art continuous cell imaging and culture system to create a prototype patient-specific cell generation system; 3) Validate the integrated system as a patient-specific cell generation product. The ultimate goal of this fast-track proposal is to develop and validate an image-guided efficient patient-specific cardiomyocyte generation system. This will be achieved by integrating our established SVCell software containing advanced KIPR technologies with a live cell imaging technology to synthesize state-of-the-art cell fate control protocols against iPSC. Patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. Successful development of the patient-specific cell generation system of this proposal could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.        Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.         ",Efficient patient-specific cell generation by image-guidance,8392472,R44HL106863,"['Biotechnology', 'Brain Diseases', 'Cardiac Myocytes', 'Cell Culture System', 'Cell Differentiation process', 'Cell Fate Control', 'Cells', 'Cellular Morphology', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Fibroblasts', 'Generations', 'Goals', 'Government', 'Harvest', 'Health', 'Healthcare', 'Heart', 'Human', 'Image', 'Imaging technology', 'Institutes', 'Kinetics', 'Life', 'Machine Learning', 'Medicine', 'Metric', 'Monitor', 'Outcome', 'Patients', 'Pattern Recognition', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Production', 'Protocols documentation', 'Quality Control', 'Sampling', 'Staging', 'Staining method', 'Stains', 'Stem cells', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Work', 'alanine aminopeptidase', 'base', 'cell type', 'cellular imaging', 'cost', 'cost effectiveness', 'disease diagnosis', 'drug discovery', 'drug testing', 'human embryonic stem cell', 'improved', 'induced pluripotent stem cell', 'patient population', 'prototype', 'stem cell technology', 'tool', 'usability']",NHLBI,"DRVISION TECHNOLOGIES, LLC",R44,2012,987686,1296025,-0.02372790149618907
"The Cardiovascular Research Grid    DESCRIPTION (provided by applicant):       The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinafions of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotafing ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and mofion that can predict the early presence of developing heart disease in fime for therapeufic intervenfion. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informafics system that allows clinical informafion to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG.  RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease. (End of Abstract)          The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store,  manage, and analyze data on the structure and function of the cardiovascular system in health and disease.  The CVRG Project has developed and deployed unique technology that is now being used in a broad range  of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to  explore and analvze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8240702,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Time', 'Ultrasonography', 'Work', 'abstracting', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2012,2194299,807432003,0.007232657738557765
"Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence    DESCRIPTION (provided by applicant): Translation of biomedical research into practice depends in part on the production of quality systematic reviews that synthesize available evidence. Unfortunately, about 20% of reviews are never completed. Of those that reach fruition, the average time to completion may be 2.4 years, with a reported maximum of 9 years. A major bottleneck occurs when teammates screen studies. In the first step, they independently identify provisionally eligible studies by reading the same set of perhaps thousands of titles and abstracts. To date, researchers have used supervised machine learning (ML) methods in an attempt to automate identification of eligible randomized controlled trials (RCTs). However, finding nonrandomized (NR) studies for inclusion in systematic reviews has yet to be addressed. This is an important problem because RCTs may be unlikely or even unethical for some research questions. Hypotheses. It is broadly hypothesized that (a) methods based on natural language processing and ML can be used to automatically identify topically relevant studies with a mix of NR designs eligible for inclusion in systematic reviews; and (b) machine performance can consistently reach current human standards with respect to identifying eligible studies. Aims. This research has three aims: (1) Compare the language that biomedical researchers use to describe their NR study designs with existing relevant vocabularies. Develop complementary terminologies for overlooked NR study designs to improve coverage of important vocabularies. Develop and validate a standalone terminology to support librarians who add free-text terms to expert searches. (2) Develop and compare procedures based on natural language processing and supervised ML methods to identify provisionally eligible NR studies that are topically relevant from a set of citations, including titles, abstracts, and metadata. Use terms for NR study designs to improve classification. (3) Generalize procedures developed under Aims 1 and 2 to select topically relevant studies with a mix of designs for provisional inclusion in several types of systematic reviews. Use contextual information in segments of full texts tagged for location to enrich feature vectors. Methods. Reference standards will be built from studies in published Cochrane reviews. Features will be extracted from citations and regions of full texts. Additionally, feature vectors will be enriched with terms for designs that researchers use in combination with terms extracted from major vocabularies. Model performance will be compared with respect to several measures, including mean recall and precision, for 10-fold cross-validations and validations on held-out test sets. Significance. The proposed research is significant because it will help support translation of biomedical research to improve human health. Moreover, developing procedures to identify NR studies is essential for the expeditious translation of a very large body of research.           Translation of biomedical research helps to improve public health by delivering the best available evidence to clinicians. This process depends in part on the production of systematic reviews of research. Computerized procedures will be developed to reduce the labor associated with screening nonrandomized studies for inclusion in reviews.",Screening Nonrandomized Studies for Inclusion in Systematic Reviews of Evidence,8190163,K99LM010943,"['Address', 'Biomedical Research', 'Classification', 'Health', 'Human', 'Language', 'Librarians', 'Location', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Performance', 'Procedures', 'Process', 'Production', 'Public Health', 'Publishing', 'Randomized Controlled Trials', 'Reading', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Screening procedure', 'Terminology', 'Testing', 'Text', 'Time', 'Translations', 'Validation', 'Vocabulary', 'abstracting', 'base', 'computerized', 'design', 'improved', 'research to practice', 'systematic review', 'vector']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2011,89802,570146095,-0.009153381179117168
"Semi-Automated Abstract Screening for Comparative Effectiveness Reviews    DESCRIPTION (provided by applicant): In this three-year project, we aim to apply state-of-the-art information analysis technologies to assist the production of systematic reviews and meta-analyses that are increasingly being used as a foundation for evidence-based medicine (EBM) and comparative effectiveness reviews. We plan to develop a human guided computerized abstract screening tool to greatly reduce the need to perform a tedious but crucial step of manually screening many thousands of abstracts generated by literature searches in order to retrieve a small fraction potentially relevant for further analysis. This tool will combine proven machine learning techniques with a new open source tool that enables management of the screening process. This new technology will enable investigators to screen abstracts in a small fraction of the time compared to the current manual process. It will reduce the time and cost of producing systematic reviews, provide clear documentation of the process and potentially perform the task more accurately. With the acceptance of EBM and increasing demands for systematic reviews, there is a great need for tools to assist in generating new systematic reviews and in updating them. This need cannot be more pressing. The recent passage of the American Recovery and Reinvestment Act and the $1.1 billion allocated for comparative effectiveness research have created an unprecedented need for systematic reviews and opportunities to improve the methodologies and efficiency of their conduct.   We herein propose the development of novel, open-source software to help systematic reviewers better   cope with these torrents of data. The research and development of this tool will be carried out by a highly experienced team of systematic review investigators with computer scientists at Tufts University who began to collaborate last year as a result of Tufts being awarded one of the NIH Clinical Translational Science Awards (CTSA). We will pursue dissemination of the new technology through numerous channels including, but not limited to publication, presentation at conferences, exploring interest in its adoption by the Agency for Healthcare Research and Quality (AHRQ) Evidence-based Practice Center (EPC) Program, Cochrane Collaboration, CTSA network, and other groups conducting systematic reviews, and production of tutorial material. Our aims are:   1. Conduct research to design and implement a semi-automated system using machine learning and   information retrieval methods to identify relevant abstracts in order to improve the accuracy and efficiency of systematic reviews.   2. Develop Abstrackr, an open-source system with a Graphical User Interface (GUI) for screening abstracts, that applies the methods developed in Aim 1 to automatically exclude irrelevant abstracts/articles.   3. Evaluate the performance of the active learning model developed in Aim 1 and the functionality of   Abstrackr developed in Aim 2 through application to a collection of manually screened datasets of   biomedical abstracts that will subsequently be made publicly available for use as a repository to spur   research in the machine learning and information retrieval communities.           Systematic reviewing is a scientific approach to objectively summarizing the effectiveness and safety of existing treatments for diseases, a prerequisite for informed healthcare decision-making. Systematic reviewers must read many thousands of medical study abstracts, the vast majority of which are completely irrelevant to the review at hand. This is hugely laborious and time consuming. We propose to build a computerized system that automatically excludes a large number of the irrelevant abstracts, thereby accelerating the process and expediting the application of the systematic review findings to patient care.",Semi-Automated Abstract Screening for Comparative Effectiveness Reviews,8115129,R01HS018494,[' '],AHRQ,TUFTS MEDICAL CENTER,R01,2011,136978,17640378,9.299361217135076e-06
"Family History, Genes, Environment and G X E Interaction in Predicting RA Risk    DESCRIPTION (provided by applicant): Since receiving the K24 award, I have established a successful clinical research and training program in patient-oriented research (POR) in rheumatic disease with a focus on genetic, biomarker, and environmental risk factors for rheumatoid arthritis (RA) and systemic lupus erythematosus (SLE). I continue to have independent grant support, and have mentored 15 new clinical investigators who have published 25 peer- reviewed papers during the K24 period. Three mentees have received NIH K awards and one has received an NIH R01. With renewal of the K24, I would continue to have protected time to devote to this program that has a unique training environment and an array of important POR projects. Genetic and environmental epidemiology studies have produced convincing evidence for multiple alleles and exposures as RA risk factors. A strong gene-environment (GXE) interaction between HLA-DRB1 alleles and smoking has been demonstrated for risk of the immune phenotype of CCP positive RA but not CCP negative RA. As CCP antibodies occur years before RA onset, I hypothesize that this interaction induces anti-citrulline immunity, a critical step in RA pathogenesis. These findings emphasize the need to study genes, environment and immunity with careful phenotyping. Family history encompasses unmeasured genetic and environmental risk, yet is not measured accurately in other studies including those in my research portfolio. Specific aims are to: 1) Maintain and expand my clinical research training program by mentoring new clinical investigators in POR in rheumatic diseases; 2) Enrich my comprehensive POR program to study family history, genetic, and environmental predictors in the etiology of RA using a new collection of RA cases and controls from Partners HealthCare; 2a) Collect family history data and environmental exposure data concerning smoking and reproductive factors on 1,500 RA patients and 4,500 age- and gender-matched controls by utilizing natural language processing (NLP) queries of electronic medical records; 2b: Examine genetic risk factors, environmental risk factors and GXE in predicting immune phenotypes of RA: RA with and without CCP antibodies (CCP?), and RA with and without rheumatoid factor antibodies (RF?); and 2c: Apply this comprehensive risk model to RA cases and controls and to subsets of RA stratified by specific immune phenotypes and stratified by family history of RA and other autoimmune diseases. The proposed study will leverage the NIH funded Informatics for Integrating Biology and the Bedside study that used an advanced informatics infrastructure to extract clinical data on RA diagnostic features through database mining and NLP. A highly specific algorithm was used to identify RA cases and collect samples from cases and controls. The NLP techniques will be used to extract risk factor data from clinical notes. This proposal builds on my strong track record of POR, extending the work to add family history from a new case-control collection, validate data by patient interview, and develop predictive models for risk of RA that can be used to select high risk individuals for future RA prevention trials.             Project Narrative  Innovative predictive modeling incorporating family history, genes, environmental exposures, and gene-  environment interactions, is a key step in the progress towards an RA prevention clinical trial.","Family History, Genes, Environment and G X E Interaction in Predicting RA Risk",8078134,K24AR052403,"['ARHGEF5 gene', 'Address', 'Age', 'Air Pollution', 'Algorithms', 'Alleles', 'Antibodies', 'Antigens', 'Area', 'Autoantibodies', 'Autoimmune Diseases', 'Behavioral', 'Bioinformatics', 'Biological Markers', 'Biology', 'Body mass index', 'Breathing', 'Calibration', 'Candidate Disease Gene', 'Case-Control Studies', 'Cigarette', 'Citrulline', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Cohort Studies', 'Collection', 'Computerized Medical Record', 'Cox Proportional Hazards Models', 'DNA', 'DNA Markers', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Environment', 'Environmental Epidemiology', 'Environmental Exposure', 'Environmental Risk Factor', 'Epidemiologic Studies', 'Epidemiologist', 'Epidemiology', 'Epitopes', 'Etiology', 'Exposure to', 'Family', 'Family Study', 'Family history of', 'Female', 'First Degree Relative', 'Funding', 'Future', 'Gender', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic Variation', 'Genotype', 'Grant', 'HLA-DR4 Antigen', 'HLA-DRB1', 'Healthcare', 'Heterogeneity', 'Hormonal', 'Hormones', 'Human Genome', 'ICD-9', 'Immune', 'Immunity', 'Immunologist', 'Incidence', 'Individual', 'Inflammatory', 'Informatics', 'Institution', 'Interdisciplinary Study', 'Interview', 'K-Series Research Career Programs', 'Laboratories', 'Lead', 'Life', 'Link', 'Logistic Models', 'Logistic Regressions', 'Lung', 'Measures', 'Menopausal Status', 'Mentors', 'Meta-Analysis', 'Methods', 'Methotrexate', 'Mid-Career Clinical Scientist Award (K24)', 'Minerals', 'Mining', 'Modeling', 'Modification', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Notification', 'Occupational', 'PTPN22 gene', 'Paper', 'Particulate', 'Particulate Matter', 'Pathogenesis', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Phenotype', 'Physicians', 'Pollution', 'Population', 'Predisposition', 'Prevention', 'Prevention strategy', 'Principal Investigator', 'Publishing', 'Race', 'Recording of previous events', 'Records', 'Reproductive History', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Research Training', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatoid Factor', 'Risk', 'Risk Factors', 'STAT4 gene', 'Sampling', 'Siblings', 'Signs and Symptoms', 'Single Nucleotide Polymorphism', 'Smoking', 'Socioeconomic Status', 'Statistical Methods', 'Stratification', 'Subgroup', 'Surface', 'Sushi Domain', 'Sweden', 'Symptoms', 'System', 'Systemic Lupus Erythematosus', 'TNF receptor-associated factor 1', 'Techniques', 'Testing', 'Text', 'Time', 'Toxic Environmental Substances', 'Training', 'Training Programs', 'Travel', 'Tumor Necrosis Factor-alpha', 'United States', 'United States National Institutes of Health', 'Variant', 'Woman', 'Work', 'abstracting', 'adalimumab', 'base', 'case control', 'cigarette smoking', 'cohort', 'cost effective', 'cyclic citrullinated peptide', 'cytokine', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic analysis', 'genetic association', 'genetic epidemiology', 'genetic risk factor', 'genetic technology', 'genetic variant', 'genome wide association study', 'high risk', 'improved', 'inclusion criteria', 'infliximab', 'innovation', 'insight', 'meetings', 'men', 'multidisciplinary', 'novel', 'parity', 'patient oriented research', 'pre-clinical', 'predictive modeling', 'prevent', 'prevention clinical trial', 'programs', 'reproductive', 'research study', 'response', 'sample collection', 'sex', 'toxin metabolism', 'trafficking', 'treatment response', 'tumor necrosis factor-alpha inhibitor']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,K24,2011,157939,327644200,-0.016028628519662386
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.      PUBLIC HEALTH RELEVANCE:    Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.                 Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8192895,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2011,180669,2836411,-0.012819243672969648
"Outcomes of Bariatric Surgery among Patients with Bipolar Disorder    DESCRIPTION (provided by applicant): The overarching goal of this proposal is to determine how bariatric surgery affects psychiatric and metabolic outcomes among patients with bipolar disorder (BD). BD patients are at increased risk of obesity and suffer increased rates of obesity-related comorbidities. They have an estimated 25 years life lost, largely due to cardiovascular disease. There is an urgent need for knowledge about how best to treat obesity and mitigate associated comorbidities among bipolar disorder patients. Bariatric surgery is the most effective treatment for morbid obesity. Although BD patients suffer disproportionately from obesity, there is virtually no published data on how bariatric surgery affects psychiatric or metabolic course in this population. We propose a retrospective cohort study to examine psychiatric and metabolic outcomes during up to 3 years follow-up among all H100,000 morbidly obese adult patients (2000 BD, 13,000 major depressive disorder, 85,000 neither affective disorder) age 18-69 in Kaiser Permanente Northern California, between 2006 and 2009. Within the cohort, 5149 patients (171 BD, 1999 major depressive disorder, 2979 neither affective disorder) underwent bariatric surgery during the study period. We propose three aims: (1) Determine if predictors of referral to bariatric surgery, and of undergoing bariatric surgery, differ by affective disorder diagnosis (BD, major depressive disorder, neither); (2) Among n=2000 morbidly obese bipolar disorder patients who meet criteria for bariatric surgery, determine if bariatric surgery affects psychiatric course (risk of psychiatric hospitalization, outpatient psychiatric utilization); and (3) Among n=5149 patients who underwent bariatric surgery (171 BD, 1999 major depression, 2979 neither affective disorder), determine if affective disorder is associated with weight loss and metabolic outcomes (diabetes, hypertension, dyslipidemia). We will employ longitudinal data representation from the counterfactual statistical framework. Multiple linear regression will be employed for linear outcomes (weight loss, number of outpatient visits), and multiple logistic regression will be employed for dichotomous outcomes. This study will be the first to present data on outcomes of bariatric surgery among bipolar disorder patients. Current, there are no BD-specific data on which to base clinic decision making in this population. As the excess mortality in BD is largely due to cardiovascular disease, this study will provide essential information to guide clinical decision making for morbidly obese BD patients and their physicians.      PUBLIC HEALTH RELEVANCE: People with bipolar disorder suffer higher risk of obesity and associated diseases such as diabetes and cardiovascular disease. We propose to study how the most effective obesity therapy, bariatric surgery, affects psychiatric course, weight loss, and improvement in obesity-associated diseases (diabetes, hypertension, high cholesterol) among bipolar disorder patients. Ours will be the first study of bariatric surgery outcomes in bipolar disorder, and will provided much-needed information to help bipolar disorder patients and their physicians make decisions about treatment options for morbid obesity.           People with bipolar disorder suffer higher risk of obesity and associated diseases such as diabetes and cardiovascular disease. We propose to study how the most effective obesity therapy, bariatric surgery, affects psychiatric course, weight loss, and improvement in obesity-associated diseases (diabetes, hypertension, high cholesterol) among bipolar disorder patients. Ours will be the first study of bariatric surgery outcomes in bipolar disorder, and will provided much-needed information to help bipolar disorder patients and their physicians make decisions about treatment options for morbid obesity.         ",Outcomes of Bariatric Surgery among Patients with Bipolar Disorder,8177335,R21MH094908,"['Adult', 'Affect', 'Age', 'Behavioral', 'Bipolar Disorder', 'Body Weight decreased', 'California', 'Cardiovascular Diseases', 'Cholesterol', 'Clinic', 'Cohort Studies', 'Comorbidity', 'Data', 'Decision Making', 'Diabetes Mellitus', 'Diagnosis', 'Dyslipidemias', 'Excess Mortality', 'General Population', 'Goals', 'High Prevalence', 'Hospitalization', 'Hypertension', 'Knowledge', 'Life Style', 'Light', 'Linear Regressions', 'Logistic Regressions', 'Major Depressive Disorder', 'Metabolic', 'Mood Disorders', 'Morbid Obesity', 'Obesity', 'Obesity associated disease', 'Operative Surgical Procedures', 'Outcome', 'Outpatients', 'Patients', 'Physicians', 'Population', 'Prevalence', 'Procedures', 'Publishing', 'Resolution', 'Risk', 'Symptoms', 'Visit', 'Weight', 'bariatric surgery', 'base', 'blood pressure regulation', 'clinical decision-making', 'cohort', 'diabetes control', 'effective therapy', 'evidence base', 'follow-up', 'high risk', 'meetings', 'mortality', 'obesity risk', 'programs', 'psychologic', 'success', 'weight loss intervention', 'years of life lost']",NIMH,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2011,189399,111231681,-0.01158171840942231
"Machine Learning Tools for Prognostication in Melanoma    DESCRIPTION (provided by applicant): The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.  Cutaneous melanoma is the sixth most common cancer in the United States, and its incidence rate is increasing faster than any other cancer. Nearly 69,000 new cases are expected be diagnosed in this country in 2010. While thin melanomas are typically cured with excision alone, thicker melanomas have a greater tendency to metastasize to the regional lymph nodes.  A diagnosis of Stage III melanoma is made if there is spread to the regional lymph nodes. Unfortunately, there is marked diversity in the natural history of Stage III melanoma, and outcomes within this group are extremely heterogeneous, with 5- year survival rates ranging from 23% to 87%. Similarly, treatment options range from intensive forms of systemic therapy to observation. Understanding patients' differences in clinical outcome is critical not only for calibrating therapeutic intensity to metastatic risk but also in the design and analysis of clinical trials.  There is a real void of reliable prognostic tools for Stage III melanoma. Based on novel machine learning approaches, the purpose of this study will be to develop and validate a reliable and individualized tool for prognostication of Stage III melanoma patients that can be used in the clinical setting.      PUBLIC HEALTH RELEVANCE: The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.           The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.         ",Machine Learning Tools for Prognostication in Melanoma,8114413,R21CA152775,"['Address', 'American Joint Committee on Cancer', 'Cancer Prognosis', 'Classification', 'Clinical', 'Clinical Trials', 'Complex', 'Country', 'Cutaneous Melanoma', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Pathway', 'Dose', 'Evaluation', 'Excision', 'Heterogeneity', 'Incidence', 'Individual', 'Interferons', 'Logic', 'Lymph Node Dissections', 'Machine Learning', 'Malignant Neoplasms', 'Metastatic to', 'Methodology', 'Methods', 'Michigan', 'Modeling', 'Multivariate Analysis', 'Natural History', 'Neoplasm Metastasis', 'Nodal', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Proportional Hazards Models', 'Publications', 'Reporting', 'Risk', 'Sentinel Lymph Node Biopsy', 'Staging', 'Statistical Methods', 'Subgroup', 'Survival Rate', 'Systemic Therapy', 'Therapeutic', 'Thick', 'Trees', 'United States', 'Universities', 'Validation', 'advanced disease', 'base', 'cancer risk', 'clinical decision-making', 'design', 'editorial', 'flexibility', 'forest', 'hazard', 'lymph nodes', 'melanoma', 'minimally invasive', 'novel', 'outcome forecast', 'prognostic', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2011,193798,641965656,-0.020728836271671363
"Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements    DESCRIPTION (provided by applicant): Thyroid nodules are present in a large fraction of healthy individuals. Between 4% and 7% of the United States adult population has palpable thyroid nodules, and up to 50% of American women older than age 50 have nodules that can be depicted on ultrasound. The vast majority (>95%) of thyroid nodules are benign. However, cancer risk increases with male gender, nodule size, extremes of age (< 30 and > 60 years), underlying autoimmune disease, nodule growth, personal or family history of thyroid cancer, and radiation exposure. Ultrasound imaging and Fine Needle Aspiration Biopsy (FNAB) remain the mainstays of thyroid nodule evaluation. Unfortunately, 25% of patients who ultimately undergo FNAB of a thyroid nodule have indeterminate cytology. Many of these patients will require at least partial thyroidectomy purely for the purpose of obtaining a definitive diagnosis. Given that only 30% of these will ultimately prove to be malignant on surgical pathology, the majority of these lobectomies could potentially be avoided if better non-invasive methods existed to evaluate indeterminate nodules. Electrical Impedance Scanning (EIS) has been previously investigated for non-invasive evaluation of thyroid nodules. The overall diagnostic accuracy of EIS was encouraging but not sufficient for routine clinical use. We have developed a modified approach termed here Resonance Electrical Impedance Spectroscopy (REIS) that should have substantially higher sensitivity and specificity for this very purpose. When using REIS technology to examine the breast, we obtained initial results that are significantly better in all respects than those obtained with traditional EIS. We believe that REIS technology will similarly improve the assessment of thyroid nodules. REIS hold promise as a reproducible modality for the risk stratification of the many patients with indeterminate thyroid nodules. It is a new non- invasive modality that may help reduce the number of diagnostic lobectomies and would be welcomed by patients with non-diagnostic FNA results. The purpose of this application is to design, assemble, and test in a preliminary clinical study a unique REIS based device for the assessment of thyroid nodules.      PUBLIC HEALTH RELEVANCE: We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.           We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.         ",Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements,8015458,R21CA154262,"['Address', 'Adult', 'Age', 'American', 'Aspirate substance', 'Autoimmune Diseases', 'Benign', 'Biopsy', 'Breast', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Consent', 'Cytology', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Endocrine', 'Endocrinologist', 'Evaluation', 'Excision', 'Family history of', 'Fine needle aspiration biopsy', 'Follicular thyroid carcinoma', 'Frequencies', 'Gender', 'General Anesthesia', 'Growth', 'Human', 'Image', 'Incidence', 'Individual', 'Lesion', 'Lobectomy', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measurement', 'Measures', 'Methods', 'Modality', 'Neck', 'Nodule', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Palpable', 'Papillary', 'Papillary Carcinoma', 'Participant', 'Patients', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Procedures', 'Prospective Studies', 'Protocols documentation', 'Publishing', 'Radiation', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Spectrum Analysis', 'Stratification', 'Surgeon', 'Surgical Pathology', 'System', 'Techniques', 'Technology', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Thyroidectomy', 'Triage', 'Ultrasonography', 'United States', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer risk', 'clinical practice', 'design', 'diagnostic accuracy', 'electric impedance', 'imaging modality', 'improved', 'male', 'malignant breast neoplasm', 'men', 'older women', 'phase change', 'prospective', 'prototype', 'radiologist', 'tool', 'web site']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2011,195019,570146095,-0.04761564126362081
"Longitudinal Assessment of Fall Risk    DESCRIPTION (provided by applicant): Falling is not a normal part of the aging process and yet 1/3 to 1/2 of adults 65 years and older sustain at least one fall annually. Older adults are hospitalized for fall related injuries five times more often than from injuries from other causes contributing to a cost of $19 billion for nonfatal falls in the United States. Projected for the increasing aging population in the year 2020, it is expected that the costs related to falls will reach a staggering 54.9 billion dollars. Current research and clinical practice guidelines focus on multifactorial fall risk assessments as the critical deterrent to falls in the elderly. A primary factor within these assessments is activity of daily living performance of the individual elder. While current standardized clinical balance assessment tools have been proven effective for predicting fall risk, the tests are most commonly performed in the clinical environment and at isolated times during an individual's day. The goal of this application is to develop and validate a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. Such a device: - will allow early detection of risk of falling, when therapeutic interventions are most efficient - will provide real-time feedback about activity pattern - will provide feedback about compliance with interventions and effectiveness of interventions - will be incorporated into conventional footwear and require no extra effort to operate - can be used in research, clinical and potentially in consumer applications The development of the ALARM system will be addressed in three specific aims:  Specific Aims 1: Develop a pattern recognition method that will improve recognition accuracy for activities of interest (such as walking and stepping up) by reducing the range of variation from current 76%- 100% to 9911%. Specific Aim 2: Collect data using the ALARM device on a group of elderly adults during clinical tests. Specific Aim 3: Develop algorithms for automatic assessment of risk of falling. In this Aim we will develop signal processing algorithms that automatically evaluate metrics indicative of the risk of falling in each activity of interest (e.g. duration of swing and stance phase during walking). Specific Aim 4: Validate the ALARM device in a double-blind unrestricted free living study. This set of Specific Aims will validate lead to creation of a unique wearable device capable of objective characterization of risk of falling.      PUBLIC HEALTH RELEVANCE: This application aims at development of a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. In our previous research we have shown that major activities and posture allocations such as standing, sitting, walking, etc. can be recognized with high degree of accuracy (76%-100%) by a wearable device incorporated into conventional footwear. We also have shown that sensor signals captured by the wearable shoe device during activities such as walking are well- correlated with the risk of falling (with numerical estimates of risk obtained through signal processing being directly proportional to the normalized scores from the clinical tests). The goal of this application is to develop and validate a novel wearable device (ALARM) for longitudinal assessment of risk of falling.           This application aims at development of a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. In our previous research we have shown that major activities and posture allocations such as standing, sitting, walking, etc. can be recognized with high degree of accuracy (76%-100%) by a wearable device incorporated into conventional footwear. We also have shown that sensor signals captured by the wearable shoe device during activities such as walking are well- correlated with the risk of falling (with numerical estimates of risk obtained through signal processing being directly proportional to the normalized scores from the clinical tests). The goal of this application is to develop and validate a novel wearable device (ALARM) for longitudinal assessment of risk of falling.         ",Longitudinal Assessment of Fall Risk,8240357,R21EB013183,"['Acceleration', 'Activities of Daily Living', 'Address', 'Adult', 'Aging-Related Process', 'Algorithms', 'Classification', 'Clinical', 'Clinical Practice Guideline', 'Communities', 'Comparative Study', 'Computational algorithm', 'Computers', 'Data', 'Data Set', 'Development', 'Devices', 'Double-Blind Method', 'Early Diagnosis', 'Effectiveness of Interventions', 'Elderly', 'Engineering', 'Environment', 'Equilibrium', 'Evaluation', 'Feasibility Studies', 'Feedback', 'Goals', 'Heel', 'Individual', 'Injury', 'Intervention', 'Laboratories', 'Lead', 'Life', 'Machine Learning', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Metric', 'Monitor', 'Neural Network Simulation', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Posture', 'Process', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Series', 'Shoes', 'Signal Transduction', 'System', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'United States', 'Validation', 'Variant', 'Walking', 'aging population', 'base', 'computerized data processing', 'cost', 'fall risk', 'falls', 'human old age (65+)', 'improved', 'interest', 'novel', 'pressure', 'sensor', 'tool', 'volunteer']",NIBIB,UNIVERSITY OF ALABAMA IN TUSCALOOSA,R21,2011,228569,5620537,-0.006935088895023847
"Statistical Model Building for High Dimensional Biomedical Data    DESCRIPTION (provided by applicant):  Typical of current large-scale biomedical data is the feature of small number of observed samples and the widely observed sample heterogeneity. Identifying differentially expressed genes related to the sample phenotye (e.g., cancer disease development) and predicting sample phenotype based on the gene expressions are some central research questions in the microarray data analysis. Most existing statistical methods have ignored sample heterogeneity and thus loss power.       This project proposes to develop novel statistical methods that explicitly address the small sample size and sampe heterogeneity issues, and can be applied very generally. The usefulness of these methods will be shown with the large-scale biomedical data originating from the lung and kidney transplant research projects. The transplant projects aimed to improve the molecular diagnosis and therapy of lung/kidney allograft rejection by identifying molecular biomarkers to predict the allograft rejection for critical early treatment and rapid, noninvasive, and economical testing.       The specific aims are 1) Develop novel statistical methods for differential gene expression detection that explicitly model sample heterogeneity. 2) Develop novel statistical methods for classifying high-dimensional biomedical data and incorporating sample heterogeneity. 3) Develop novel statistical methods for jointly analyzing a set of genes (e.g., genes in a pathway). 4) Use the developed models and methods to answer research questions relevant to public health in the lung and kidney transplant projects; and implement and validate the proposed methods in user-friendly and well-documented software, and distribute them to the scientific community at no charge.       It is very important to identify new biomarkers of allograft rejection in lung and kidney transplant recipients. The rapid and reliable detection and prediction of rejection in easily obtainable body fluids may allow the rapid advancement of clinical interventional trials. We propose to study novel methods for analyzing the large-scale biomedical data to realize their full potential of molecular diagnosis and prognosis of transplant rejection prediction for critical early treatment.          n/a",Statistical Model Building for High Dimensional Biomedical Data,8079474,R01GM083345,"['Address', 'Adopted', 'Algorithms', 'Biological Markers', 'Body Fluids', 'Cations', 'Characteristics', 'Charge', 'Clinical', 'Collection', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early treatment', 'Effectiveness', 'Experimental Designs', 'Gene Expression', 'Genes', 'Genomics', 'Graft Rejection', 'Heterogeneity', 'Individual', 'Internet', 'Joints', 'Kidney Transplantation', 'Least-Squares Analysis', 'Literature', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Minnesota', 'Modeling', 'Molecular', 'Molecular Diagnosis', 'Oncogene Activation', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Phenotype', 'Principal Component Analysis', 'Probability', 'Procedures', 'Public Health', 'Relative (related person)', 'Research', 'Research Project Grants', 'Research Proposals', 'Resources', 'Sample Size', 'Sampling', 'Silicon Dioxide', 'Statistical Methods', 'Statistical Models', 'Technology', 'Testing', 'Tissue-Specific Gene Expression', 'Transplant Recipients', 'Transplantation', 'Universities', 'Ursidae Family', 'Work', 'allograft rejection', 'base', 'biobank', 'cancer microarray', 'cancer type', 'design', 'improved', 'interest', 'kidney allograft', 'method development', 'novel', 'outcome forecast', 'predictive modeling', 'simulation', 'software development', 'sound', 'theories', 'transplant database', 'user friendly software', 'user-friendly']",NIGMS,UNIVERSITY OF MINNESOTA,R01,2011,250488,340417756,-0.02976512538204035
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,8120230,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Semantics', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2011,264994,641965656,-0.005979215401124838
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.      PUBLIC HEALTH RELEVANCE: Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.           Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8116342,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Screening procedure', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild neurocognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2011,324000,507546965,-0.03904650044797146
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.           Project Narrative The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.",Scalable Learning with Ensemble Techniques and Parallel Computing,8045486,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Biological Sciences', 'Biomedical Research', 'Classification', 'Communication', 'Communities', 'Community Financing', 'Companions', 'Complex', 'Computer software', 'Consult', 'Crowding', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Health', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'new technology', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2011,374673,0,0.009198295264734811
"Efficient patient-specific cell generation by image-guidance    DESCRIPTION (provided by applicant): This fast-track proposal applies advanced kinetic image pattern recognition (KIPR) technologies to predict induced pluripotent stem cell (iPSC) reprogramming colonies' differentiation outcomes for significantly improved yield and robustness of differentiation protocols. The objectives of the proposed tool are 1) Teaching: creation of scores for induced colony differentiation outcome prediction by machine learning; 2) Reprogramming: optimal reprogramming harvest time determination by continuous colony score monitoring; 3) Differentiation: selection of colonies with the highest prediction scores for differentiation at the reprogramming harvest time; 4) Differentiation: cell cluster quality control by continuous monitoring during differentiation. The specific aims of this fast-track proposal are Phase I: 1) Extend SVCell for the prediction of induced colony differentiation outcomes ; 2) Validate that prediction of colony differentiation outcomes can improve the yield of CM differentiation. Phase II: 1) Validate that the integrated system can be taught to be robust and high yielding for a diverse set of human fibroblast input samples and different reprogramming / differentiation protocols; 2) Integrate SVCell with a state-of-the-art continuous cell imaging and culture system to create a prototype patient-specific cell generation system; 3) Validate the integrated system as a patient-specific cell generation product. The ultimate goal of this fast-track proposal is to develop and validate an image-guided efficient patient-specific cardiomyocyte generation system. This will be achieved by integrating our established SVCell software containing advanced KIPR technologies with a live cell imaging technology to synthesize state-of-the-art cell fate control protocols against iPSC. Patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. Successful development of the patient-specific cell generation system of this proposal could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.      PUBLIC HEALTH RELEVANCE: Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.           Image-guided efficient patient-specific cell generation systems could ""personalize"" medicine by reprogramming patient-specific cells and directing their differentiation to specific lineages (e.g. heart, brain) for disease diagnosis and personalized drug testing. This could catalyze personalized medicine and revolutionize health care in both diagnosis and therapy.         ",Efficient patient-specific cell generation by image-guidance,8058635,R44HL106863,"['Biotechnology', 'Brain Diseases', 'Cardiac Myocytes', 'Cell Culture System', 'Cell Differentiation process', 'Cell Fate Control', 'Cells', 'Cellular Morphology', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Fibroblasts', 'Generations', 'Goals', 'Government', 'Harvest', 'Health', 'Healthcare', 'Heart', 'Human', 'Image', 'Imaging technology', 'Institutes', 'Kinetics', 'Life', 'Machine Learning', 'Medicine', 'Metric', 'Monitor', 'Outcome', 'Patients', 'Pattern Recognition', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Production', 'Protocols documentation', 'Quality Control', 'Sampling', 'Staging', 'Staining method', 'Stains', 'Stem cells', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Work', 'alanine aminopeptidase', 'base', 'cell type', 'cellular imaging', 'cost', 'cost effectiveness', 'disease diagnosis', 'drug discovery', 'drug testing', 'human embryonic stem cell', 'improved', 'induced pluripotent stem cell', 'patient population', 'prototype', 'stem cell technology', 'tool', 'usability']",NHLBI,"DRVISION TECHNOLOGIES, LLC",R44,2011,374865,1296025,-0.025180528743941794
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,8139155,R44RR024094,"['AIDS/HIV problem', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cell physiology', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2011,449663,0,-0.021636774845924675
"Computer-aided detection of non-calcified plaques in coronary CT angiograms    DESCRIPTION (provided by applicant):  Cardiovascular disease is the leading cause of death in both men and women in the United States. Over 16 million Americans have coronary heart disease (CHD), causing about 0.5 million deaths each year. The most common CHD is coronary artery disease which is mainly caused by atherosclerosis. Clinical evidence in recent years shows that noncalcified plaques (NCPs) are more vulnerable to rupture than calcified plaques. Plaque rupture and the thrombosis that follows is the main cause of acute myocardial infarction. Multidetector coronary CT angiography (cCTA) has the potential to help clinicians in early detection and in quantification of NCPs. cCTA may thus be useful for CHD detection, risk stratification, monitoring, and evaluation of the effectiveness of risk reduction treatment. However, many of these potential applications have not been utilized clinically.  The goal of this project is to develop a computer-aided detection (CADe) system to serve as a second reader for assisting clinicians in detection and quantification of NCPs in cCTA exams. Our specific aims are to (1) develop machine learning methods for detection of NCPs causing stenosis and/or positive remodeling along coronary arteries, and (2) evaluate the effect of CADe on radiologists' detection of NCPs on cCTA by observer ROC study. To achieve these aims, we will collect a database of cCTA cases for training and testing the CADe system, define the search space by designing 3D multiscale coronary artery response enhancement, segmentation, and dynamic balloon vessel tracking methods, develop a unique vessel- stitching method to automatically identify the best-quality phase for each individual artery segment from all available phases in prospectively or retrospectively gated cCTA exams, develop innovative vessel-sector- profile analysis and vessel lumen analysis to detect NCPs that cause stenosis or positive remodeling, estimate the total NCP volume, and explore calibration method to quantify plaque density by phantom studies. To demonstrate the usefulness of CADe, a preclinical reader study will be conducted to compare radiologists' detection accuracy of NCPs with and without CADe.  The major innovations of this project include (1) being the first CADe system to automatically detect non-calcified plaques including those cause positive remodeling or stenosis in cCTA, (2) development of new machine learning techniques including the vessel-stitching method, vessel-sector-profile analysis, multiscale enhancement response, and dynamic balloon tracking specifically suited for coronary arterial trees, and (3) conducting the first ROC study to evaluate the effect of CADe on radiologists' detection of NCPs.      PUBLIC HEALTH RELEVANCE: Cardiovascular disease is the leading cause of death in both men and women in the United States. If the proposed CADe system is successfully developed, it will (1) provide an accurate, efficient, and consistent tool to assist clinicians in detecting and quantifying non-calcified plaques (NCP) including those causing positive remodeling and/or stenosis for an individual patient, (2) help clinicians estimate the total NCP burden and study its significance, in analogy to that of the total calcium score, which may lead to improved clinical management of the vulnerable plaques, and (3) accelerate studies to develop new treatment options of coronary heart disease by providing a monitoring tool of treatment response. The proposed CADe system can thus serve as a foundation for these broader future applications and improve the efficacy of cCTA. Improved detection and management of NCPs may reduce the risk of myocardial infarctions and will have strong and long-lasting impact on health care.           Cardiovascular disease is the leading cause of death in both men and women in the United States. If the proposed CADe system is successfully developed, it will (1) provide an accurate, efficient, and consistent tool to assist clinicians in detecting and quantifying non-calcified plaques (NCP) including those causing positive remodeling and/or stenosis for an individual patient, (2) help clinicians estimate the total NCP burden and study its significance, in analogy to that of the total calcium score, which may lead to improved clinical management of the vulnerable plaques, and (3) accelerate studies to develop new treatment options of coronary heart disease by providing a monitoring tool of treatment response. The proposed CADe system can thus serve as a foundation for these broader future applications and improve the efficacy of cCTA. Improved detection and management of NCPs may reduce the risk of myocardial infarctions and will have strong and long-lasting impact on health care.         ",Computer-aided detection of non-calcified plaques in coronary CT angiograms,8032999,R01HL106545,"['Acute myocardial infarction', 'American', 'Angiography', 'Arterial Fatty Streak', 'Arteries', 'Atherosclerosis', 'Calcified', 'Calcium', 'Calibration', 'Cardiovascular Diseases', 'Catheters', 'Cause of Death', 'Cessation of life', 'Clinical', 'Clinical Management', 'Computer Assisted', 'Computer Vision Systems', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Coronary heart disease', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Dose', 'Early Diagnosis', 'Effectiveness', 'Electrocardiogram', 'Evaluation', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Image', 'Imagery', 'Individual', 'Lead', 'Machine Learning', 'Methods', 'Modality', 'Monitor', 'Myocardial Infarction', 'Patients', 'Performance', 'Phase', 'Procedures', 'Radiation', 'Reader', 'Receiver Operating Characteristics', 'Recording of previous events', 'Resolution', 'Risk', 'Risk Reduction', 'Rupture', 'Scanning', 'Stenosis', 'Stratification', 'System', 'Techniques', 'Testing', 'Thrombosis', 'Time', 'Training', 'Trees', 'Ultrasonography', 'United States', 'Visual', 'Woman', 'density', 'design', 'detector', 'improved', 'innovation', 'men', 'pre-clinical', 'prospective', 'radiologist', 'response', 'tool', 'treatment response', 'virtual']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2011,583681,641965656,-0.029391739080180456
"FT-IR Microscopy of Mineral Structure    DESCRIPTION (provided by applicant): Osteoporosis is responsible for approximately 1.5 million fractures in the US per year, with 300,000 of these fractures occurring at the hip at a cost exceeding $17 billion. The NIH Consensus conference and the World Health Organization defined osteoporosis as ""...compromised bone strength predisposing to an increased risk of fracture"". A variety of genetic and environmental factors, as well as bone properties (geometric and material), contribute to the bone loss that is associated with osteoporosis, but the question remains as to which factors primarily contribute to fracture risk. While reduced bone mineral density (BMD) relative to young individuals is routinely used clinically to predict fracture risk, BMD is not a strong predictor, with the majority of fractures occurring in patients with BMD's above the osteoporotic threshold. We have recently shown by multiple logistic regression analysis that specific mineral and matrix properties assessed by Fourier transform infrared spectroscopic imaging (FTIRI) are predictive of fracture in postmenopausal women, while BMD is not significantly associated with fracture incidence. In a limited number of samples we have also shown that these FTIR parameters are correlated with nanomechanical properties. We hypothesize that variation in crystallinity (XST) and collagen maturity (XLR) partially explains the difference in incidence of fractures in individuals with similar BMDs. We further hypothesize that heterogeneity in these parameters is an additional determinant of fracture incidence, especially in trabecular bone. In the proposed studies we will test 4 hypotheses. 1) For any subject, FTIRI data obtained in the cortical and cancellous bone of the iliac crest (generally a non-fracturing site) is representative of that from sites that fracture (subtrochanter/greater trochanter). Further, the data are independent of the size of the biopsy as long as cortical and cancellous bone areas are included. This will be tested using multiple biopsies from cadavers and from clinic patients with fractures. Measures will include micro-CT analysis of BMD and architecture, and FTIRI. 2) Decreased heterogeneity in FTIRI mineral and matrix properties, in addition to increased XST and XLR, are predictive of fracture in humans. This will be tested by extending our logistic regression to heterogeneity parameters. Variation in tissue properties with age will be studied in patients with idiopathic juvenile osteoporosis. Tissue mechanical properties will be correlated with FTIRI data. 3) An anabolic agent (PTH) can restore mechanical properties, and the XST, XLR, and mineral and matrix heterogeneity in animal models as well as in osteoporotic humans. This will be tested by analyses of pre- and post- treatment human biopsies and by analyses in a sheep model. 4) XLR, which is altered in osteoporosis, is related to collagen orientation. As part of our continued parameter validation, this will be tested by comparing FTIRI and second harmonic heneration microscopy data. Testing of these four hypotheses will provide new insights into the efficacy of therapies and contribute to the understanding of factors leading to fracture.      PUBLIC HEALTH RELEVANCE: The objective of this continuing investigation is to discover what changes in bone properties cause a bone in a person with osteoporosis to break; we have suggestive evidence that changes in the structure and composition of the bone composite (mineral and matrix) put bones at risk of breaking during normal activities of daily life. Correlations are sought between spatial variation in parameters obtained by vibrational spectroscopy and mechanical properties. This information should lead to improved diagnosis and new approaches to prevention and treatment of osteoporosis, the ""silent epidemic"".              The objective of this continuing investigation is to discover what changes in bone properties cause a bone in a person with osteoporosis to break; we have suggestive evidence that changes in the structure and composition of the bone composite (mineral and matrix) put bones at risk of breaking during normal activities of daily life. Correlations are sought between spatial variation in parameters obtained by vibrational spectroscopy and mechanical properties. This information should lead to improved diagnosis and new approaches to prevention and treatment of osteoporosis, the ""silent epidemic"".",FT-IR Microscopy of Mineral Structure,8077418,R01AR041325,"['Acids', 'Activities of Daily Living', 'Adolescent', 'Adult', 'Aftercare', 'Age', 'Alendronate', 'Amides', 'Anabolic Agents', 'Animal Model', 'Architecture', 'Area', 'Biopsy', 'Bone Density', 'Cadaver', 'Carbonates', 'Clinic', 'Collagen', 'Consensus', 'Data', 'Data Sources', 'Diagnosis', 'Environmental Risk Factor', 'Epidemic', 'Estrogens', 'Fourier Transform', 'Fracture', 'Funding', 'Generations', 'Genetic', 'Heterogeneity', 'Hip Fractures', 'Hip region structure', 'Hospitals', 'Human', 'Image', 'Incidence', 'Individual', 'Investigation', 'Lead', 'Logistic Regressions', 'Measures', 'Mechanics', 'Microscopy', 'Minerals', 'Modeling', 'New York', 'Osteon', 'Osteoporosis', 'Patients', 'Pattern', 'Persons', 'Postmenopause', 'Presbyterian Church', 'Prevention approach', 'Property', 'Puberty', 'Raloxifene', 'Regression Analysis', 'Relative (related person)', 'Reporting', 'Risk', 'Sampling', 'Sheep', 'Site', 'Spectroscopy, Fourier Transform Infrared', 'Spectrum Analysis', 'Structure', 'Structure of greater trochanter of femur', 'Techniques', 'Testing', 'Tissues', 'Treatment Efficacy', 'United States National Institutes of Health', 'Validation', 'Variant', 'Weight', 'Woman', 'World Health Organization', 'X ray diffraction analysis', 'X-Ray Diffraction', 'animal tissue', 'bone', 'bone loss', 'bone quality', 'bone strength', 'cost', 'crosslink', 'improved', 'inorganic phosphate', 'insight', 'nano', 'nanomechanical', 'nonhuman primate', 'novel strategies', 'public health relevance', 'repaired', 'second harmonic', 'skeletal', 'spectroscopic imaging', 'substantia spongiosa', 'symposium', 'young adult']",NIAMS,HOSPITAL FOR SPECIAL SURGERY,R01,2011,673979,9232826,0.00025195659949128974
"The Cardiovascular Research Grid    DESCRIPTION (provided by applicant):       The Cardiovascular Research Grid (CVRG) Project is an R24 resource supporting the informatics needs of the cardiovascular (CV) research community. The CVRG Project has developed and deployed unique core technology for management and analysis of CV data that is being used in a broad range of Driving Biomedical Projects (DBFs). This includes: a) tools for storing and managing different types of biomedical data; b) methods for securing the data; c) tools for querying combinafions of these data so that users may mine their data for new knowledge; d) new statistical learning methods for biomarker discovery; e) novel tools that analyze image data on heart shape and motion to discover biomarkers that are indicative of disease; f) tools for managing, analyzing, and annotafing ECG data. All of these tools are documented and freely available from the CVRG website and Wiki. In this renewal, we propose a set of new projects that will enhance the capability of our users to explore and analyze their data to understand the cause and treatment of heart disease. Each project is motivated directly by the needs of one or more of our DBFs. Project 1 will develop and apply new algorithms for discovering changes in heart shape and mofion that can predict the early presence of developing heart disease in fime for therapeufic intervenfion. Project 2 will create data management systems for storing CV image data collected in large, multi-center clinical research studies, and for performing quality control operations that assure the integrity of that data. Project 3 will develop a complete infrastructure for managing and analyzing ECG data. Project 4 will develop a comprehensive clinical informafics system that allows clinical informafion to be linked with biomedical data collected from subjects. Project 5 will develop tools by which non-expert users can quickly assemble new procedures for analyzing their data. Project 6 will put in place a project management structure that will assure successful operation of the CVRG.  RELEVANCE: The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store, manage, and analyze data on the structure and function of the cardiovascular system in health and disease. The CVRG Project has developed and deployed unique technology that is now being used in a broad range of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to explore and analyze their data to understand the cause and treatment of heart disease. (End of Abstract)          The Cardiovascular Research Grid (CVRG) Project is a national resource providing the capability to store,  manage, and analyze data on the structure and function of the cardiovascular system in health and disease.  The CVRG Project has developed and deployed unique technology that is now being used in a broad range  of studies. In this renewal, we propose to develop new tools that will enhance the ability of researchers to  explore and analvze their data to understand the cause and treatment of heart disease.",The Cardiovascular Research Grid,8017600,R24HL085343,"['Address', 'Algorithms', 'Archives', 'Atlases', 'Automobile Driving', 'Biological Markers', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Research', 'Common Data Element', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Discrimination', 'Disease', 'Electrocardiogram', 'Health', 'Health Insurance Portability and Accountability Act', 'Heart', 'Heart Diseases', 'Hybrids', 'Image', 'Image Analysis', 'Informatics', 'Information Management', 'Institutional Review Boards', 'International', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Monoclonal Antibody R24', 'Motion', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Policies', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Shapes', 'Site', 'Speed', 'Structure', 'System', 'Systems Integration', 'Technology', 'Testing', 'Time', 'Ultrasonography', 'Work', 'abstracting', 'base', 'cardiovascular imaging', 'cluster computing', 'computational anatomy', 'computerized data processing', 'data integration', 'data integrity', 'data management', 'data modeling', 'disease phenotype', 'flexibility', 'imaging informatics', 'insight', 'interdisciplinary collaboration', 'neuroimaging', 'new technology', 'novel', 'operation', 'performance site', 'rapid technique', 'research study', 'technology development', 'tool', 'validation studies', 'web site', 'wiki', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2011,2241978,807432003,0.007232657738557765
"Category Learning in Dynamic Environments    DESCRIPTION (provided by applicant): On completion of training, the candidate will pursue a first tier university professorship or a position at a government research institution, and investigate human learning and decision making. His goal is to ultimately shed light on how the brain supports these behaviors to inform both clinical and neuroscientific applications. To this end, the candidate brings to bear powerful eye tracking techniques for measuring information processing of categories. The proposed research examines the interplay between the structure of the learning task and how people attend to features in the task environment. By examining such variables, the work will narrow the gap between tasks of the real world and those that are studied in the area of categories and concepts-an area that concerns the core cognitive process by which people conceive of distinct things as belonging to the same class. The proposal explores whether the effect of learning task on category representation is mediated by interplay between task dynamics and learners' sampling of the environment. To understand the interplay between task, eye movements, and concept representation, the proposal will incorporate modern reinforcement learning techniques from the machine learning literature into a category learning model. Reinforcement learning has been used to model eye movements in other areas including reading and problem solving. Neuroscientific work has found circuits linking the basal ganglia through dopamine with the frontal cortex that appear to operate according to reinforcement learning processes (Frank and Glaus, 2006). Moreover, Yechiam, et al. (2005) showed that the parameters in reinforcement learning models appear to map to specific clinical populations as they performed in a simple gambling task. Instead of gambling tasks, or artificial category learning tasks, the goal of the proposed work is to move towards tasks that might help to understand real world behaviors and their causes. The new category-reinforcement learning model proposed here will be applied first to the candidate's existing eye movement data, a rich data set on learners' attention to category information as they learn in standard tasks. Then, the model will be applied to the proposed behavioral experiments investigating the role of task dynamics on learners' sampling behavior. PUBLIC HEALTH RELEVANCE: The proposed research will improve our understanding of the cognitive processes having to do with learning and attention. By exploring learning tasks that are more like those experienced in the real world, the research can improve the applicability of cognitive models for diagnosing and devising treatments for deficits from ADHD, Autism, Asperger's, Huntington's disease, Parkinson's disease.           n/a",Category Learning in Dynamic Environments,7760038,F32HD057695,"['Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Clinical', 'Cognitive', 'Data', 'Data Set', 'Decision Making', 'Diagnosis', 'Dopamine', 'Environment', 'Eye', 'Eye Movements', 'Gambling', 'Goals', 'Government', 'Human', 'Huntington Disease', 'Institution', 'Learning', 'Light', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Modeling', 'Parkinson Disease', 'Population', 'Positioning Attribute', 'Problem Solving', 'Process', 'Psychological reinforcement', 'Reading', 'Research', 'Role', 'Sampling', 'Structure', 'Techniques', 'Training', 'Universities', 'Ursidae Family', 'Work', 'experience', 'frontal lobe', 'improved', 'information processing', 'public health relevance', 'research study']",NICHD,"UNIVERSITY OF TEXAS, AUSTIN",F32,2010,54367,91740242,-0.020050230279164537
"Family History, Genes, Environment and G X E Interaction in Predicting RA Risk    DESCRIPTION (provided by applicant): Since receiving the K24 award, I have established a successful clinical research and training program in patient-oriented research (POR) in rheumatic disease with a focus on genetic, biomarker, and environmental risk factors for rheumatoid arthritis (RA) and systemic lupus erythematosus (SLE). I continue to have independent grant support, and have mentored 15 new clinical investigators who have published 25 peer- reviewed papers during the K24 period. Three mentees have received NIH K awards and one has received an NIH R01. With renewal of the K24, I would continue to have protected time to devote to this program that has a unique training environment and an array of important POR projects. Genetic and environmental epidemiology studies have produced convincing evidence for multiple alleles and exposures as RA risk factors. A strong gene-environment (GXE) interaction between HLA-DRB1 alleles and smoking has been demonstrated for risk of the immune phenotype of CCP positive RA but not CCP negative RA. As CCP antibodies occur years before RA onset, I hypothesize that this interaction induces anti-citrulline immunity, a critical step in RA pathogenesis. These findings emphasize the need to study genes, environment and immunity with careful phenotyping. Family history encompasses unmeasured genetic and environmental risk, yet is not measured accurately in other studies including those in my research portfolio. Specific aims are to: 1) Maintain and expand my clinical research training program by mentoring new clinical investigators in POR in rheumatic diseases; 2) Enrich my comprehensive POR program to study family history, genetic, and environmental predictors in the etiology of RA using a new collection of RA cases and controls from Partners HealthCare; 2a) Collect family history data and environmental exposure data concerning smoking and reproductive factors on 1,500 RA patients and 4,500 age- and gender-matched controls by utilizing natural language processing (NLP) queries of electronic medical records; 2b: Examine genetic risk factors, environmental risk factors and GXE in predicting immune phenotypes of RA: RA with and without CCP antibodies (CCP?), and RA with and without rheumatoid factor antibodies (RF?); and 2c: Apply this comprehensive risk model to RA cases and controls and to subsets of RA stratified by specific immune phenotypes and stratified by family history of RA and other autoimmune diseases. The proposed study will leverage the NIH funded Informatics for Integrating Biology and the Bedside study that used an advanced informatics infrastructure to extract clinical data on RA diagnostic features through database mining and NLP. A highly specific algorithm was used to identify RA cases and collect samples from cases and controls. The NLP techniques will be used to extract risk factor data from clinical notes. This proposal builds on my strong track record of POR, extending the work to add family history from a new case-control collection, validate data by patient interview, and develop predictive models for risk of RA that can be used to select high risk individuals for future RA prevention trials.             Project Narrative  Innovative predictive modeling incorporating family history, genes, environmental exposures, and gene,environment interactions, is a key step in the progress towards an RA prevention clinical trial.","Family History, Genes, Environment and G X E Interaction in Predicting RA Risk",7892091,K24AR052403,"['ARHGEF5 gene', 'Address', 'Age', 'Air Pollution', 'Algorithms', 'Alleles', 'Antibodies', 'Antigens', 'Area', 'Autoantibodies', 'Autoimmune Diseases', 'Behavioral', 'Bioinformatics', 'Biological Markers', 'Biology', 'Body mass index', 'Breathing', 'Calibration', 'Candidate Disease Gene', 'Case-Control Studies', 'Cigarette', 'Citrulline', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Cohort Studies', 'Collection', 'Computerized Medical Record', 'Cox Proportional Hazards Models', 'DNA', 'DNA Markers', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Environment', 'Environmental Epidemiology', 'Environmental Exposure', 'Environmental Risk Factor', 'Epidemiologic Studies', 'Epidemiologist', 'Epidemiology', 'Epitopes', 'Etiology', 'Exposure to', 'Family', 'Family history of', 'Female', 'First Degree Relative', 'Funding', 'Future', 'Gender', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic Variation', 'Genotype', 'Grant', 'HLA-DR4 Antigen', 'HLA-DRB1', 'Healthcare', 'Heterogeneity', 'Hormonal', 'Hormones', 'Human Genome', 'ICD-9', 'Immune', 'Immunity', 'Immunologist', 'Incidence', 'Individual', 'Inflammatory', 'Informatics', 'Institution', 'Interdisciplinary Study', 'Interview', 'K-Series Research Career Programs', 'Laboratories', 'Lead', 'Life', 'Link', 'Logistic Models', 'Logistic Regressions', 'Lung', 'Measures', 'Menopausal Status', 'Mentors', 'Meta-Analysis', 'Methods', 'Methotrexate', 'Mid-Career Clinical Scientist Award (K24)', 'Minerals', 'Mining', 'Modeling', 'Modification', 'Natural Language Processing', 'Notification', 'Occupational', 'PTPN22 gene', 'Paper', 'Particulate', 'Particulate Matter', 'Pathogenesis', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Phenotype', 'Physicians', 'Pollution', 'Population', 'Predisposition', 'Prevention', 'Prevention strategy', 'Principal Investigator', 'Publishing', 'Race', 'Records', 'Reproductive History', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Research Training', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatoid Factor', 'Risk', 'Risk Factors', 'STAT4 gene', 'Sampling', 'Siblings', 'Signs and Symptoms', 'Single Nucleotide Polymorphism', 'Smoke', 'Smoking', 'Socioeconomic Status', 'Statistical Methods', 'Stratification', 'Subgroup', 'Surface', 'Sushi Domain', 'Sweden', 'Symptoms', 'System', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Text', 'Time', 'Toxic Environmental Substances', 'Training', 'Training Programs', 'Travel', 'Tumor Necrosis Factor-alpha', 'United States National Institutes of Health', 'Variant', 'Woman', 'Work', 'abstracting', 'adalimumab', 'base', 'case control', 'cigarette smoking', 'cohort', 'cost', 'cyclic citrullinated peptide', 'cytokine', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic analysis', 'genetic association', 'genetic risk factor', 'genetic technology', 'genetic variant', 'genome wide association study', 'high risk', 'improved', 'inclusion criteria', 'infliximab', 'innovation', 'insight', 'meetings', 'men', 'multidisciplinary', 'novel', 'parity', 'patient oriented research', 'pre-clinical', 'predictive modeling', 'prevent', 'prevention clinical trial', 'programs', 'reproductive', 'research study', 'response', 'sample collection', 'sex', 'toxin metabolism', 'trafficking', 'treatment response', 'tumor necrosis factor-alpha inhibitor']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,K24,2010,154689,327644200,-0.016028628519662386
"Clinical Validation of BCT - Phase II    DESCRIPTION (provided by applicant):  Fracture risk assessment is integral to the diagnosis and management of osteoporosis, a devastating clinical condition of which over 40 million Americans are at risk. Due to limitations in areal BMD measures obtained from 2D DXA scans - the current clinical standard for diagnosis of osteoporosis - it has recently become clear that those at risk of osteoporotic fracture need to be better identified. A 3D biomechanics-based technique, which we term Biomechanical Computed Tomography (BCT), addresses this need through a combination of engineering finite element analysis, 3D quantitative computed tomography (QCT), and bone fracture biomechanics. The main outcome parameter of BCT is an estimate of the biomechanical risk of a bone fracture that accounts for such factors as the patient's 3D bone geometry and distribution of bone density, body-weight, height, trochanteric soft tissue thickness (for hip fractures), muscle moment arm (for spine), and the age-related risk of sustaining an overload event (such as a fall or lifting of a heavy object with back bent). In the larger context of translating BCT to clinical practice, we seek in this Phase II SBIR project to test the overall hypothesis that BCT is a better predictor of osteoporotic fracture than is areal BMD, for both hip and spine fracture and for both women and men. In Phase I of this project, we successfully applied this technique to explain observed age-related trends in hip fracture rates. For Phase II, we plan in our first Aim to refine our BCT technique to produce a fully automated, highly reliable and highly accurate software suite with the capability to analyze CT scans acquired for any medical test with coverage of the hip and/or spine without an external calibration phantom. For Aim 2, in order to ensure optimal prediction of clinical fractures, we will further refine our overall BCT process by calibrating results from the two cohorts (the Mayo Clinic cohort of 750 men and women in Rochester MN, and the MrOS cohort of 3,500 men in six U.S. locations). Issues to be resolved in this calibration process include determining optimal methods for measuring soft tissue thickness, muscle moment arms, and spine loading. This analysis will also enable us to calibrate our function for age- related risk of sustaining an overload event, which may depend on both fracture type (hip vs. spine) and sex. In Aim 3, we will compile normative data for BCT outcomes, critical information for interpretation of clinical results. Having refined and calibrated the overall BCT technique and identified the most successful BCT predictors of clinical fracture in the Mayo and MrOS cohorts, we will proceed in Aim 4 to test the validity of these predictors in a fully prospective manner, without any further modification of the BCT technique. For this, we will analyze the AGES cohort of 5,500 women and men in Reykjavik, Iceland, for incident hip and spine fracture. Taken together, this multi-cohort international validation study will provide new insight into osteoporotic fracture etiology, important advancements for the BCT method, and a thorough evaluation of BCT clinical performance. This project should therefore have a significant impact on osteoporosis research and clinical practice. PUBLIC HEALTH RELEVANCE: Statement of Relevance This project will provide clinical validation to Biomechanical Computed Tomography, a promising clinical alternative to DXA for the diagnosis of osteoporosis. Successful translation of BCT to clinical practice has the potential to greatly improve non-invasive assessment of fracture risk, which would represent an important advance in the preventative care and treatment of osteoporosis.           Statement of Relevance This project will provide clinical validation to Biomechanical Computed Tomography, a promising clinical alternative to DXA for the diagnosis of osteoporosis. Successful translation of BCT to clinical practice has the potential to greatly improve non-invasive assessment of fracture risk, which would represent an important advance in the preventative care and treatment of osteoporosis.",Clinical Validation of BCT - Phase II,8040218,R44AR052234,"['Accounting', 'Address', 'American', 'Automation', 'Back', 'Biomechanics', 'Body Weight', 'Bone Density', 'Cadaver', 'Calibration', 'Caring', 'Clinic', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Diagnosis', 'Diagnostic', 'Disincentive', 'Dual-Energy X-Ray Absorptiometry', 'Engineering', 'Ensure', 'Etiology', 'Evaluation', 'Event', 'Finite Element Analysis', 'Fracture', 'Goals', 'Healthcare', 'Height', 'Hip Fractures', 'Hip region structure', 'Iceland', 'International', 'Lifting', 'Location', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Medicare', 'Methods', 'Modality', 'Modeling', 'Modification', 'Muscle', 'Nature', 'Osteoporosis', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Research', 'Risk', 'Risk Assessment', 'Scanning', 'Small Business Innovation Research Grant', 'Spinal Curvatures', 'Structure', 'Techniques', 'Testing', 'Thick', 'Translating', 'Translations', 'Validation', 'Vertebral column', 'Woman', 'X-Ray Computed Tomography', 'age related', 'arm', 'base', 'bone', 'bone geometry', 'bone strength', 'clinical application', 'clinical practice', 'cohort', 'cost', 'density', 'design', 'diagnosis standard', 'fall risk', 'falls', 'high risk', 'image processing', 'improved', 'insight', 'men', 'muscle form', 'osteoporosis with pathological fracture', 'phase 1 study', 'prospective', 'public health relevance', 'sex', 'soft tissue', 'spine bone structure', 'trend', 'validation studies']",NIAMS,"O. N. DIAGNOSTICS, LLC",R44,2010,194177,647058,-0.00032128399297758645
"Statistical Model Building for High Dimensional Biomedical Data    DESCRIPTION (provided by applicant):  Typical of current large-scale biomedical data is the feature of small number of observed samples and the widely observed sample heterogeneity. Identifying differentially expressed genes related to the sample phenotye (e.g., cancer disease development) and predicting sample phenotype based on the gene expressions are some central research questions in the microarray data analysis. Most existing statistical methods have ignored sample heterogeneity and thus loss power.       This project proposes to develop novel statistical methods that explicitly address the small sample size and sampe heterogeneity issues, and can be applied very generally. The usefulness of these methods will be shown with the large-scale biomedical data originating from the lung and kidney transplant research projects. The transplant projects aimed to improve the molecular diagnosis and therapy of lung/kidney allograft rejection by identifying molecular biomarkers to predict the allograft rejection for critical early treatment and rapid, noninvasive, and economical testing.       The specific aims are 1) Develop novel statistical methods for differential gene expression detection that explicitly model sample heterogeneity. 2) Develop novel statistical methods for classifying high-dimensional biomedical data and incorporating sample heterogeneity. 3) Develop novel statistical methods for jointly analyzing a set of genes (e.g., genes in a pathway). 4) Use the developed models and methods to answer research questions relevant to public health in the lung and kidney transplant projects; and implement and validate the proposed methods in user-friendly and well-documented software, and distribute them to the scientific community at no charge.       It is very important to identify new biomarkers of allograft rejection in lung and kidney transplant recipients. The rapid and reliable detection and prediction of rejection in easily obtainable body fluids may allow the rapid advancement of clinical interventional trials. We propose to study novel methods for analyzing the large-scale biomedical data to realize their full potential of molecular diagnosis and prognosis of transplant rejection prediction for critical early treatment.          n/a",Statistical Model Building for High Dimensional Biomedical Data,7858165,R01GM083345,"['Address', 'Adopted', 'Algorithms', 'Biological Markers', 'Body Fluids', 'Cations', 'Characteristics', 'Charge', 'Clinical', 'Collection', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early treatment', 'Effectiveness', 'Experimental Designs', 'Gene Expression', 'Genes', 'Genomics', 'Graft Rejection', 'Heterogeneity', 'Individual', 'Internet', 'Joints', 'Kidney Transplantation', 'Least-Squares Analysis', 'Literature', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Minnesota', 'Modeling', 'Molecular', 'Molecular Diagnosis', 'Oncogene Activation', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Phenotype', 'Principal Component Analysis', 'Probability', 'Procedures', 'Public Health', 'Relative (related person)', 'Research', 'Research Project Grants', 'Research Proposals', 'Resources', 'Sample Size', 'Sampling', 'Silicon Dioxide', 'Statistical Methods', 'Statistical Models', 'Technology', 'Testing', 'Tissue-Specific Gene Expression', 'Transplant Recipients', 'Transplantation', 'Universities', 'Ursidae Family', 'Work', 'allograft rejection', 'base', 'biobank', 'cancer microarray', 'cancer type', 'design', 'improved', 'interest', 'kidney allograft', 'method development', 'novel', 'outcome forecast', 'predictive modeling', 'simulation', 'software development', 'sound', 'theories', 'transplant database', 'user friendly software', 'user-friendly']",NIGMS,UNIVERSITY OF MINNESOTA,R01,2010,253269,340417756,-0.02976512538204035
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,7935464,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2010,267671,641965656,-0.005979215401124838
"Clinical Validation of BCT - Phase II    DESCRIPTION (provided by applicant):  Fracture risk assessment is integral to the diagnosis and management of osteoporosis, a devastating clinical condition of which over 40 million Americans are at risk. Due to limitations in areal BMD measures obtained from 2D DXA scans - the current clinical standard for diagnosis of osteoporosis - it has recently become clear that those at risk of osteoporotic fracture need to be better identified. A 3D biomechanics-based technique, which we term Biomechanical Computed Tomography (BCT), addresses this need through a combination of engineering finite element analysis, 3D quantitative computed tomography (QCT), and bone fracture biomechanics. The main outcome parameter of BCT is an estimate of the biomechanical risk of a bone fracture that accounts for such factors as the patient's 3D bone geometry and distribution of bone density, body-weight, height, trochanteric soft tissue thickness (for hip fractures), muscle moment arm (for spine), and the age-related risk of sustaining an overload event (such as a fall or lifting of a heavy object with back bent). In the larger context of translating BCT to clinical practice, we seek in this Phase II SBIR project to test the overall hypothesis that BCT is a better predictor of osteoporotic fracture than is areal BMD, for both hip and spine fracture and for both women and men. In Phase I of this project, we successfully applied this technique to explain observed age-related trends in hip fracture rates. For Phase II, we plan in our first Aim to refine our BCT technique to produce a fully automated, highly reliable and highly accurate software suite with the capability to analyze CT scans acquired for any medical test with coverage of the hip and/or spine without an external calibration phantom. For Aim 2, in order to ensure optimal prediction of clinical fractures, we will further refine our overall BCT process by calibrating results from the two cohorts (the Mayo Clinic cohort of 750 men and women in Rochester MN, and the MrOS cohort of 3,500 men in six U.S. locations). Issues to be resolved in this calibration process include determining optimal methods for measuring soft tissue thickness, muscle moment arms, and spine loading. This analysis will also enable us to calibrate our function for age- related risk of sustaining an overload event, which may depend on both fracture type (hip vs. spine) and sex. In Aim 3, we will compile normative data for BCT outcomes, critical information for interpretation of clinical results. Having refined and calibrated the overall BCT technique and identified the most successful BCT predictors of clinical fracture in the Mayo and MrOS cohorts, we will proceed in Aim 4 to test the validity of these predictors in a fully prospective manner, without any further modification of the BCT technique. For this, we will analyze the AGES cohort of 5,500 women and men in Reykjavik, Iceland, for incident hip and spine fracture. Taken together, this multi-cohort international validation study will provide new insight into osteoporotic fracture etiology, important advancements for the BCT method, and a thorough evaluation of BCT clinical performance. This project should therefore have a significant impact on osteoporosis research and clinical practice. PUBLIC HEALTH RELEVANCE: Statement of Relevance This project will provide clinical validation to Biomechanical Computed Tomography, a promising clinical alternative to DXA for the diagnosis of osteoporosis. Successful translation of BCT to clinical practice has the potential to greatly improve non-invasive assessment of fracture risk, which would represent an important advance in the preventative care and treatment of osteoporosis.           Statement of Relevance This project will provide clinical validation to Biomechanical Computed Tomography, a promising clinical alternative to DXA for the diagnosis of osteoporosis. Successful translation of BCT to clinical practice has the potential to greatly improve non-invasive assessment of fracture risk, which would represent an important advance in the preventative care and treatment of osteoporosis.",Clinical Validation of BCT - Phase II,7937846,R44AR052234,"['Accounting', 'Address', 'American', 'Automation', 'Back', 'Biomechanics', 'Body Weight', 'Bone Density', 'Cadaver', 'Calibration', 'Caring', 'Clinic', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Diagnosis', 'Diagnostic', 'Disincentive', 'Dual-Energy X-Ray Absorptiometry', 'Engineering', 'Ensure', 'Etiology', 'Evaluation', 'Event', 'Finite Element Analysis', 'Fracture', 'Goals', 'Healthcare', 'Height', 'Hip Fractures', 'Hip region structure', 'Iceland', 'International', 'Lifting', 'Location', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Medicare', 'Methods', 'Modality', 'Modeling', 'Modification', 'Muscle', 'Nature', 'Osteoporosis', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Research', 'Risk', 'Risk Assessment', 'Scanning', 'Small Business Innovation Research Grant', 'Spinal Curvatures', 'Structure', 'Techniques', 'Testing', 'Thick', 'Translating', 'Translations', 'Validation', 'Vertebral column', 'Woman', 'X-Ray Computed Tomography', 'age related', 'arm', 'base', 'bone', 'bone geometry', 'bone strength', 'clinical application', 'clinical practice', 'cohort', 'cost', 'density', 'design', 'diagnosis standard', 'fall risk', 'falls', 'high risk', 'image processing', 'improved', 'insight', 'men', 'muscle form', 'osteoporosis with pathological fracture', 'phase 1 study', 'prospective', 'public health relevance', 'sex', 'soft tissue', 'spine bone structure', 'trend', 'validation studies']",NIAMS,"O. N. DIAGNOSTICS, LLC",R44,2010,343961,647058,-0.00032128399297758645
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,8013208,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2010,376899,0,0.00980899073694706
"COMPUTATIONAL THINKING - Combining multiple types of reasoning to infer plausible In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING - Combining multiple types of reasoning to infer plausible,8170612,76201000023C,"['Caring', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Face', 'Family', 'Funding', 'Goals', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Medical Informatics', 'Patients', 'Population', 'Process', 'Research', 'Research Personnel', 'Research Project Grants', 'System', 'Thinking', 'biomedical scientist', 'flexibility', 'innovation', 'novel strategies', 'prototype', 'rapid growth']",NLM,"CYCORP, INC.",N03,2010,377967,0,-0.0072823318003847155
"COMPUTTIONAL THINKING-An Evidence-Based, Open-Database Approach to Diagnostic Dec In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a","COMPUTTIONAL THINKING-An Evidence-Based, Open-Database Approach to Diagnostic Dec",8173645,76201000026C,"['Caring', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Complement', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Face', 'Family', 'Funding', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Memory', 'Patients', 'Population', 'Prevention', 'Research', 'Research Personnel', 'Research Project Grants', 'Solutions', 'Speed', 'System', 'Thinking', 'biomedical scientist', 'cost effectiveness', 'design', 'evidence base', 'flexibility', 'improved', 'innovation', 'novel strategies', 'rapid growth']",NLM,"SIMULCONSULT, INC.",N03,2010,377991,0,-0.007179108731010926
"Semi-Automated Abstract Screening for Comparative Effectiveness Reviews    DESCRIPTION (provided by applicant): In this three-year project, we aim to apply state-of-the-art information analysis technologies to assist the production of systematic reviews and meta-analyses that are increasingly being used as a foundation for evidence-based medicine (EBM) and comparative effectiveness reviews. We plan to develop a human guided computerized abstract screening tool to greatly reduce the need to perform a tedious but crucial step of manually screening many thousands of abstracts generated by literature searches in order to retrieve a small fraction potentially relevant for further analysis. This tool will combine proven machine learning techniques with a new open source tool that enables management of the screening process. This new technology will enable investigators to screen abstracts in a small fraction of the time compared to the current manual process. It will reduce the time and cost of producing systematic reviews, provide clear documentation of the process and potentially perform the task more accurately. With the acceptance of EBM and increasing demands for systematic reviews, there is a great need for tools to assist in generating new systematic reviews and in updating them. This need cannot be more pressing. The recent passage of the American Recovery and Reinvestment Act and the $1.1 billion allocated for comparative effectiveness research have created an unprecedented need for systematic reviews and opportunities to improve the methodologies and efficiency of their conduct.   We herein propose the development of novel, open-source software to help systematic reviewers better   cope with these torrents of data. The research and development of this tool will be carried out by a highly experienced team of systematic review investigators with computer scientists at Tufts University who began to collaborate last year as a result of Tufts being awarded one of the NIH Clinical Translational Science Awards (CTSA). We will pursue dissemination of the new technology through numerous channels including, but not limited to publication, presentation at conferences, exploring interest in its adoption by the Agency for Healthcare Research and Quality (AHRQ) Evidence-based Practice Center (EPC) Program, Cochrane Collaboration, CTSA network, and other groups conducting systematic reviews, and production of tutorial material. Our aims are:   1. Conduct research to design and implement a semi-automated system using machine learning and   information retrieval methods to identify relevant abstracts in order to improve the accuracy and efficiency of systematic reviews.   2. Develop Abstrackr, an open-source system with a Graphical User Interface (GUI) for screening abstracts, that applies the methods developed in Aim 1 to automatically exclude irrelevant abstracts/articles.   3. Evaluate the performance of the active learning model developed in Aim 1 and the functionality of   Abstrackr developed in Aim 2 through application to a collection of manually screened datasets of   biomedical abstracts that will subsequently be made publicly available for use as a repository to spur   research in the machine learning and information retrieval communities.           Systematic reviewing is a scientific approach to objectively summarizing the effectiveness and safety of existing treatments for diseases, a prerequisite for informed healthcare decision-making. Systematic reviewers must read many thousands of medical study abstracts, the vast majority of which are completely irrelevant to the review at hand. This is hugely laborious and time consuming. We propose to build a computerized system that automatically excludes a large number of the irrelevant abstracts, thereby accelerating the process and expediting the application of the systematic review findings to patient care.",Semi-Automated Abstract Screening for Comparative Effectiveness Reviews,7933715,R01HS018494,[' '],AHRQ,TUFTS MEDICAL CENTER,R01,2010,388462,17640378,9.299361217135076e-06
"Accessible Handling of Misclassified or Missing Binary Variables in CER Studies    DESCRIPTION (provided by applicant): Common but often overlooked threats to the validity of comparative effectiveness research (CER) studies include the misclassification or missingness of binary variables that are crucial to the ultimate analysis of the data. These variables potentially include the outcome of interest in standard or repeated measures logistic regression models, the factor (exposure) of interest, or an important confounder of the association under study. This proposal seeks to facilitate the investigation of the resulting biases to which a given CER analysis may be subject, and to provide study design-based remedial measures via which validity can be restored. The focus is upon statistical methods for conducting sensitivity analyses, as well as methods designed to make efficient use of supplemental data sources. The latter include validation data (in the case of misclassification), and so-called reassessment data (in the case of potentially informative missingness). A primary consideration throughout includes the incorporation of subject-specific covariates into the model of interest, as well as into models for the underlying misclassification or missingness process. Another primary goal is to establish a relatively consistent likelihood-based framework for all proposed analyses incorporating supplemental data, and to provide user-friendly programs utilizing common statistical software in order to make the methods broadly and readily accessible to those conducting CER. While not limited to specific applications, the proposed research draws motivation from and lends itself to illustration via two real-world studies. The first is the HIV Epidemiology Research Study (HERS), an observational cohort study in which the binary diagnosis of bacterial vaginosis was made at repeated visits via both error-prone and sophisticated assay techniques. The second is an emergency department-based ophthalmologic study in which non-dilated ocular fundus photography will be used for diagnosing serious ocular conditions, and will be compared against existing standard diagnostic methods. Both studies involve internal validation data to facilitate corrections for misclassification based on a fallible diagnostic method, and both are also subject to missing outcome and/or predictor data.      PUBLIC HEALTH RELEVANCE: The goal of this project is to provide statistical methods to aid comparative effectiveness research (CER) investigators with common problems encountered in data analysis. The problems upon which the project focuses come about when binary (""yes/no"") data are subject to being incorrectly measured (misclassified), or when they are sometimes not observed (missing) for reasons that might relate to information about subjects in the study. The intention is to provide CER investigators with methods that are relatively easy to use, yet effective and powerful for combating these challenges to valid data analysis.           PROJECT NARRATIVE The goal of this project is to provide statistical methods to aid comparative effectiveness research (CER) investigators with common problems encountered in data analysis. The problems upon which the project focuses come about when binary (""yes/no"") data are subject to being incorrectly measured (misclassified), or when they are sometimes not observed (missing) for reasons that might relate to information about subjects in the study. The intention is to provide CER investigators with methods that are relatively easy to use, yet effective and powerful for combating these challenges to valid data analysis.",Accessible Handling of Misclassified or Missing Binary Variables in CER Studies,8037394,RC4NR012527,"['Accident and Emergency department', 'Address', 'Bacterial Vaginosis', 'Biological Assay', 'Clinical', 'Cohort Studies', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Data Sources', 'Diagnosis', 'Diagnostic Procedure', 'Epidemiologic Studies', 'Epidemiology', 'Equation', 'Fostering', 'Fundus photography', 'Goals', 'HIV', 'Intention', 'Investigation', 'Literature', 'Logistic Regressions', 'Measures', 'Methods', 'Modeling', 'Motivation', 'Outcome', 'Participant', 'Process', 'Research', 'Research Design', 'Research Personnel', 'Resource Allocation', 'Sampling', 'Series', 'Statistical Methods', 'Techniques', 'Time', 'Validation', 'Visit', 'abstracting', 'analytical method', 'base', 'case control', 'combat', 'comparative effectiveness', 'cost', 'design', 'effectiveness research', 'interest', 'programs', 'research study', 'user-friendly']",NINR,EMORY UNIVERSITY,RC4,2010,441691,507546965,-0.003399000876739144
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,7999420,R44RR024094,"['Acquired Immunodeficiency Syndrome', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'HIV', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2010,449663,0,-0.021636774845924675
"Integrated Cardio-Renal Risk Prediction Models in Type 1 Diabetes    DESCRIPTION (provided by applicant):  This application addresses broad Challenge Area (03) Biomarker Discovery and Validation, and the specific Challenge Topic that this application addresses is: 03-DK-101 Discovery of biomarkers for disease risk, progression or response to therapy in diseases of interest to NIDDK. The Challenge: Despite tremendous progress in treatment, patients with type 1 diabetes continue to die 15 years earlier, experience excess morbidity and have medical costs over 10 times higher than the general population. The risk of coronary artery disease and diabetic nephropathy is still greatly increased and responsible for 80% of deaths in these patients. Diabetic nephropathy and coronary artery disease are intertwined, suggesting common pathways, and yet current risk prediction is inadequate. Study Rationale: Nearly 25% of T1D patients develop end-stage renal disease. The conventional theory is that the sequence of events leading to diabetic nephropathy begins from microalbuminuria, progressing to overt proteinuria and eventual end-stage renal disease. Primary prevention with ACE/ARB treatment usually begins when persistent microalbuminuria is found. However, recent prospective studies using serial measurements of kidney function estimated from serum cystatin C have changed this paradigm by demonstrating that decline in glomerular filtration may begin in the absence of microalbuminuria or continue despite remission of microalbuminuria. By their mid 40's, over 70% of men and 50% of women with type 1 diabetes develop coronary artery calcification (CAC) - a marker of significant atherosclerotic plaque burden. Cardiovascular disease is particularly prevalent among patients with renal disease, but most cardiac events occur in patients with normal albumin excretion rates. Evidence has accumulated that diabetic nephropathy and CAC are parallel, rather than sequential, complications of type 1 diabetes, sharing a number of important predictors. Accurate prediction of the individual's global cardio-renal risk is needed to guide treatment choices. As a result, there is a recognized need for better risk partitioning, either from the discovery of additional biomarkers or the application of superior methods for discrimination of disease states. Our Approach: We are proposing to use the biobank of 652 adults with type 1 diabetes who have been thoroughly genotyped and prospectively followed for development of diabetic nephropathy and coronary artery disease by the Coronary Artery Calcification in Type 1 Diabetes study (CACTI, R01 HL61753, 1999- 2009) to develop and validate integrated biomarker prediction models for cardio-renal complications in type 1 diabetes. Our study aims are the investigation of biomarkers within the well-characterized CACTI cohort for 1) early progressive renal function decline, 2) the presence and progression of coronary artery calcium, and the 3) development of combined renal and cardiovascular disease burden. Renal disease and coronary artery disease (CAD) are the leading causes of death among adults with type 1 diabetes, but traditional screening tests (urinary albumin and serum creatinine) for renal disease are inadequate, and traditional CAD risk factors (dyslipidemia, hypertension, smoking, obesity) do not fully explain the increased burden of disease associated with type 1 diabetes. Renal and cardiovascular complications are intertwined, suggesting shared pathways. Increased systemic inflammation is present in type 1 diabetes and inflammatory mediators such as uric acid, vitamin D and bone metabolism markers have been suggested to play a role in both renal and cardiovascular diseases. As a result, it is of critical public health importance to discover and validate new biomarkers for cardio-renal disease among adults with type 1 diabetes.       PUBLIC HEALTH RELEVANCE:  Renal disease and coronary artery disease (CAD) are the leading causes of death among adults with type 1 diabetes, but traditional screening tests (urinary albumin and serum creatinine) for renal disease are inadequate, and traditional CAD risk factors (dyslipidemia, hypertension, smoking, obesity) do not fully explain the increased burden of disease associated with type 1 diabetes. Renal and cardiovascular complications are intertwined, suggesting shared pathways. Increased systemic inflammation is present in type 1 diabetes and inflammatory mediators such as uric acid, vitamin D and bone metabolism markers have been suggested to play a role in both renal and cardiovascular diseases. As a result, it is of critical public health importance to discover and validate new biomarkers for cardio-renal disease among adults with type 1 diabetes.          Project Narrative  Renal disease and coronary artery disease (CAD) are the leading causes of death among adults with type 1 diabetes, but traditional screening tests (urinary albumin and serum creatinine) for renal disease are inadequate, and traditional CAD risk factors (dyslipidemia, hypertension, smoking, obesity) do not fully explain the increased burden of disease associated with type 1 diabetes. Renal and cardiovascular complications are intertwined, suggesting shared pathways. Increased systemic inflammation is present in type 1 diabetes, and inflammatory mediators such as uric acid, vitamin D and bone metabolism markers have been suggested to play a role in both renal and cardiovascular diseases. As a result, it is of critical public health importance to discover and validate new biomarkers for cardio-renal disease among adults with type 1 diabetes.",Integrated Cardio-Renal Risk Prediction Models in Type 1 Diabetes,7829755,RC1DK086958,"['Address', 'Adult', 'Age', 'Albumins', 'Albuminuria', 'Area', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Biological Markers', 'Biological Neural Networks', 'Blood', 'C-reactive protein', 'Calcium', 'Candidate Disease Gene', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cause of Death', 'Cessation of life', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Creatinine', 'Data', 'Development', 'Diabetes Mellitus', 'Diabetic Nephropathy', 'Discrimination', 'Disease', 'Disease remission', 'Dyslipidemias', 'End stage renal failure', 'Estradiol', 'Event', 'Excretory function', 'General Population', 'Genes', 'Genetic Markers', 'Genetic Polymorphism', 'Genotype', 'Glomerular Filtration Rate', 'Glycosylated hemoglobin A', 'Goals', 'High Density Lipoprotein Cholesterol', 'Homocysteine', 'Homocystine', 'Hypertension', 'Hyperuricemia', 'IL6 gene', 'Individual', 'Inflammation', 'Inflammation Mediators', 'Inflammatory', 'Insulin-Dependent Diabetes Mellitus', 'Interleukin 2 Receptor', 'Interleukin-18', 'Investigation', 'Kidney', 'Kidney Diseases', 'Measurement', 'Medical', 'Methods', 'Microalbuminuria', 'Modeling', 'Morbidity - disease rate', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Obesity', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Phenotype', 'Play', 'Primary Prevention', 'Prospective Studies', 'Proteinuria', 'Public Health', 'Renal function', 'Risk', 'Risk Factors', 'Role', 'Screening procedure', 'Serum', 'Serum Albumin', 'Sex Hormone-Binding Globulin', 'Smoke', 'Smoking', 'Staging', 'Techniques', 'Testing', 'Testosterone', 'Time', 'Tumor necrosis factor receptor 11b', 'Uric Acid', 'Validation', 'Vitamin D', 'Vitamin D Deficiency', 'Woman', 'adaptive immunity', 'adiponectin', 'base', 'biobank', 'bone metabolism', 'burden of illness', 'calcification', 'chemokine', 'cohort', 'coronary artery calcification', 'cost', 'cytokine', 'disorder risk', 'early experience', 'follow-up', 'genome wide association study', 'glomerular filtration', 'inflammatory marker', 'interest', 'lipoprotein-associated phospholipase A(2)', 'men', 'novel', 'post gamma-globulins', 'predictive modeling', 'public health relevance', 'response', 'statistics', 'theories', 'urinary']",NIDDK,UNIVERSITY OF COLORADO DENVER,RC1,2010,496938,292134808,-0.01866692019999147
"FT-IR Microscopy of Mineral Structure    DESCRIPTION (provided by applicant): Osteoporosis is responsible for approximately 1.5 million fractures in the US per year, with 300,000 of these fractures occurring at the hip at a cost exceeding $17 billion. The NIH Consensus conference and the World Health Organization defined osteoporosis as ""...compromised bone strength predisposing to an increased risk of fracture"". A variety of genetic and environmental factors, as well as bone properties (geometric and material), contribute to the bone loss that is associated with osteoporosis, but the question remains as to which factors primarily contribute to fracture risk. While reduced bone mineral density (BMD) relative to young individuals is routinely used clinically to predict fracture risk, BMD is not a strong predictor, with the majority of fractures occurring in patients with BMD's above the osteoporotic threshold. We have recently shown by multiple logistic regression analysis that specific mineral and matrix properties assessed by Fourier transform infrared spectroscopic imaging (FTIRI) are predictive of fracture in postmenopausal women, while BMD is not significantly associated with fracture incidence. In a limited number of samples we have also shown that these FTIR parameters are correlated with nanomechanical properties. We hypothesize that variation in crystallinity (XST) and collagen maturity (XLR) partially explains the difference in incidence of fractures in individuals with similar BMDs. We further hypothesize that heterogeneity in these parameters is an additional determinant of fracture incidence, especially in trabecular bone. In the proposed studies we will test 4 hypotheses. 1) For any subject, FTIRI data obtained in the cortical and cancellous bone of the iliac crest (generally a non-fracturing site) is representative of that from sites that fracture (subtrochanter/greater trochanter). Further, the data are independent of the size of the biopsy as long as cortical and cancellous bone areas are included. This will be tested using multiple biopsies from cadavers and from clinic patients with fractures. Measures will include micro-CT analysis of BMD and architecture, and FTIRI. 2) Decreased heterogeneity in FTIRI mineral and matrix properties, in addition to increased XST and XLR, are predictive of fracture in humans. This will be tested by extending our logistic regression to heterogeneity parameters. Variation in tissue properties with age will be studied in patients with idiopathic juvenile osteoporosis. Tissue mechanical properties will be correlated with FTIRI data. 3) An anabolic agent (PTH) can restore mechanical properties, and the XST, XLR, and mineral and matrix heterogeneity in animal models as well as in osteoporotic humans. This will be tested by analyses of pre- and post- treatment human biopsies and by analyses in a sheep model. 4) XLR, which is altered in osteoporosis, is related to collagen orientation. As part of our continued parameter validation, this will be tested by comparing FTIRI and second harmonic heneration microscopy data. Testing of these four hypotheses will provide new insights into the efficacy of therapies and contribute to the understanding of factors leading to fracture.      PUBLIC HEALTH RELEVANCE: The objective of this continuing investigation is to discover what changes in bone properties cause a bone in a person with osteoporosis to break; we have suggestive evidence that changes in the structure and composition of the bone composite (mineral and matrix) put bones at risk of breaking during normal activities of daily life. Correlations are sought between spatial variation in parameters obtained by vibrational spectroscopy and mechanical properties. This information should lead to improved diagnosis and new approaches to prevention and treatment of osteoporosis, the ""silent epidemic"".              The objective of this continuing investigation is to discover what changes in bone properties cause a bone in a person with osteoporosis to break; we have suggestive evidence that changes in the structure and composition of the bone composite (mineral and matrix) put bones at risk of breaking during normal activities of daily life. Correlations are sought between spatial variation in parameters obtained by vibrational spectroscopy and mechanical properties. This information should lead to improved diagnosis and new approaches to prevention and treatment of osteoporosis, the ""silent epidemic"".",FT-IR Microscopy of Mineral Structure,7884955,R01AR041325,"['Acids', 'Activities of Daily Living', 'Adolescent', 'Adult', 'Aftercare', 'Age', 'Alendronate', 'Amides', 'Anabolic Agents', 'Animal Model', 'Architecture', 'Area', 'Biopsy', 'Bone Density', 'Cadaver', 'Carbonates', 'Clinic', 'Collagen', 'Consensus', 'Data', 'Data Sources', 'Diagnosis', 'Environmental Risk Factor', 'Epidemic', 'Estrogens', 'Fourier Transform', 'Fracture', 'Funding', 'Generations', 'Genetic', 'Heterogeneity', 'Hip Fractures', 'Hip region structure', 'Hospitals', 'Human', 'Image', 'Incidence', 'Individual', 'Investigation', 'Lead', 'Logistic Regressions', 'Measures', 'Mechanics', 'Microscopy', 'Minerals', 'Modeling', 'New York', 'Osteon', 'Osteoporosis', 'Patients', 'Pattern', 'Persons', 'Postmenopause', 'Presbyterian Church', 'Prevention approach', 'Property', 'Puberty', 'Raloxifene', 'Regression Analysis', 'Relative (related person)', 'Reporting', 'Risk', 'Sampling', 'Sheep', 'Site', 'Spectroscopy, Fourier Transform Infrared', 'Spectrum Analysis', 'Structure', 'Structure of greater trochanter of femur', 'Techniques', 'Testing', 'Tissues', 'Treatment Efficacy', 'United States National Institutes of Health', 'Validation', 'Variant', 'Weight', 'Woman', 'World Health Organization', 'X ray diffraction analysis', 'X-Ray Diffraction', 'animal tissue', 'bone', 'bone loss', 'bone quality', 'bone strength', 'cost', 'crosslink', 'improved', 'inorganic phosphate', 'insight', 'nano', 'nanomechanical', 'nonhuman primate', 'novel strategies', 'public health relevance', 'repaired', 'second harmonic', 'skeletal', 'spectroscopic imaging', 'substantia spongiosa', 'symposium', 'young adult']",NIAMS,HOSPITAL FOR SPECIAL SURGERY,R01,2010,772801,9232826,0.00025195659949128974
"Robust Classification Methods for Categorical Regression    DESCRIPTION (provided by applicant): Improving statistical methods to provide better classification performance and new analytical capabilities for categorical regression would be invaluable to the medical and health care research communities. Categorical regression models (e.g., binary logistic, multinomial logistic) are used extensively to identify patterns of alcohol-related symptoms, screen for disorders, and assess policies. In addition, such models are used extensively in other areas of research such as mental illness, cancer, traumatic injuries, and AIDS-related pathologies. However, many such models are developed with inadequate support to fully analyze and exploit the intrinsically probabilistic nature of their results. This is of critical importance as health researchers, clinicians, and administrators are often faced with classification decisions using categorical regression models to identify unacceptable risks, adequate outcomes, and acceptable guidelines for screening, diagnoses, treatment, and quality of care. Commercially available statistical software does not offer sophisticated methods for robust estimation of posterior probabilities in the presence of model misspecification, missing covariates, and nonignorable missing data generating processes. Such robust missing data handling methods provide natural mechanisms for dealing with verification bias and modeling correlated, longitudinal, or survey data with complex sampling designs. Moreover, commercially available statistical software does not provide automated methods for using estimated posterior probabilities to make optimal classification decisions with respect to different optimality criteria. In particular, automated features such as optimizing multiple decision criteria (allocation rules) that trade off specificity against sensitivity, decision threshold confidence intervals, statistical tests for evaluating correct specification of posterior probabilities, statistical tests for comparing competing classifier thresholds, and methods for multi-outcome classification and inference are not readily available. Phase II research will extend Phase I findings for binary logistic regression to develop and implement automated robust classification methods for multinomial logistic regression modeling, which also applies to the larger class of nonlinear categorical regression models that output posterior probabilities. The Phase II software prototype will provide: 1) new user-selectable robust decision threshold estimators, 2) robust confidence intervals on decision threshold estimators, 3) new classifier threshold comparison tests, 4) new outcome probability specification tests, 5) efficient missing data handling methods in the presence of nonignorable nonresponse data, and 6) second-order analytic and simulation-based Bayesian methods for improved small sample and rare event outcome probability estimation. These new methodologies will be integrated into a prototype user-friendly software package, evaluated with extensive simulation studies, and then applied to real world classification problems encountered in: alcohol, mental illness (depression, bipolar, schizophrenia), cancer (prostate), trauma (emergency room), and infectious disease (AIDS) through collaborations with domain experts in those respective fields. In summary, Phase II research will establish the essential technical foundation for Phase III commercialization with the objective of providing a suite of new classification analysis methods as an advanced statistical tool that improves epidemiologic, clinical, and public health research.                 n/a",Robust Classification Methods for Categorical Regression,7917387,R44CA139607,"['Accident and Emergency department', 'Achievement', 'Address', 'Administrator', 'Agreement', 'Alcohols', 'Algorithms', 'Area', 'Bayesian Method', 'Behavior', 'Bipolar Depression', 'Classification', 'Clinical', 'Clinical Investigator', 'Collaborations', 'Communicable Diseases', 'Communities', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Analyses', 'Data Set', 'Decision Analysis', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Empirical Research', 'Engineering', 'Epidemiologic Studies', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Foundations', 'Goals', 'Guidelines', 'Health', 'Health Services Research', 'Healthcare', 'Industry', 'Information Resources Management', 'Injury', 'Jordan', 'Journals', 'Knowledge', 'Literature', 'Logistic Regressions', 'Logistics', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Outcome', 'Output', 'Pathology', 'Pattern', 'Peer Review', 'Performance', 'Phase', 'Policies', 'Preparation', 'Probability', 'Process', 'Publishing', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Risk', 'Robin bird', 'Sampling', 'Schizophrenia', 'Screening procedure', 'Sensitivity and Specificity', 'Simulate', 'Software Tools', 'Specific qualifier value', 'Specificity', 'Statistical Methods', 'Surveys', 'Symptoms', 'Technology', 'Testing', 'Trauma', 'anticancer research', 'base', 'commercialization', 'computerized data processing', 'density', 'design', 'graphical user interface', 'improved', 'innovation', 'phase 1 study', 'phase 2 study', 'prototype', 'public health research', 'simulation', 'software development', 'theories', 'tool', 'user friendly software']",NCI,MARTINGALE RESEARCH CORPORATION,R44,2010,990520,0,0.002447155616848203
"Clinical Validation of BCT - Phase II    DESCRIPTION (provided by applicant):  Fracture risk assessment is integral to the diagnosis and management of osteoporosis, a devastating clinical condition of which over 40 million Americans are at risk. Due to limitations in areal BMD measures obtained from 2D DXA scans - the current clinical standard for diagnosis of osteoporosis - it has recently become clear that those at risk of osteoporotic fracture need to be better identified. A 3D biomechanics-based technique, which we term Biomechanical Computed Tomography (BCT), addresses this need through a combination of engineering finite element analysis, 3D quantitative computed tomography (QCT), and bone fracture biomechanics. The main outcome parameter of BCT is an estimate of the biomechanical risk of a bone fracture that accounts for such factors as the patient's 3D bone geometry and distribution of bone density, body-weight, height, trochanteric soft tissue thickness (for hip fractures), muscle moment arm (for spine), and the age-related risk of sustaining an overload event (such as a fall or lifting of a heavy object with back bent). In the larger context of translating BCT to clinical practice, we seek in this Phase II SBIR project to test the overall hypothesis that BCT is a better predictor of osteoporotic fracture than is areal BMD, for both hip and spine fracture and for both women and men. In Phase I of this project, we successfully applied this technique to explain observed age-related trends in hip fracture rates. For Phase II, we plan in our first Aim to refine our BCT technique to produce a fully automated, highly reliable and highly accurate software suite with the capability to analyze CT scans acquired for any medical test with coverage of the hip and/or spine without an external calibration phantom. For Aim 2, in order to ensure optimal prediction of clinical fractures, we will further refine our overall BCT process by calibrating results from the two cohorts (the Mayo Clinic cohort of 750 men and women in Rochester MN, and the MrOS cohort of 3,500 men in six U.S. locations). Issues to be resolved in this calibration process include determining optimal methods for measuring soft tissue thickness, muscle moment arms, and spine loading. This analysis will also enable us to calibrate our function for age- related risk of sustaining an overload event, which may depend on both fracture type (hip vs. spine) and sex. In Aim 3, we will compile normative data for BCT outcomes, critical information for interpretation of clinical results. Having refined and calibrated the overall BCT technique and identified the most successful BCT predictors of clinical fracture in the Mayo and MrOS cohorts, we will proceed in Aim 4 to test the validity of these predictors in a fully prospective manner, without any further modification of the BCT technique. For this, we will analyze the AGES cohort of 5,500 women and men in Reykjavik, Iceland, for incident hip and spine fracture. Taken together, this multi-cohort international validation study will provide new insight into osteoporotic fracture etiology, important advancements for the BCT method, and a thorough evaluation of BCT clinical performance. This project should therefore have a significant impact on osteoporosis research and clinical practice. PUBLIC HEALTH RELEVANCE: Statement of Relevance This project will provide clinical validation to Biomechanical Computed Tomography, a promising clinical alternative to DXA for the diagnosis of osteoporosis. Successful translation of BCT to clinical practice has the potential to greatly improve non-invasive assessment of fracture risk, which would represent an important advance in the preventative care and treatment of osteoporosis.           Statement of Relevance This project will provide clinical validation to Biomechanical Computed Tomography, a promising clinical alternative to DXA for the diagnosis of osteoporosis. Successful translation of BCT to clinical practice has the potential to greatly improve non-invasive assessment of fracture risk, which would represent an important advance in the preventative care and treatment of osteoporosis.",Clinical Validation of BCT - Phase II,7612453,R44AR052234,"['Accounting', 'Address', 'American', 'Automation', 'Back', 'Biomechanics', 'Body Weight', 'Bone Density', 'Cadaver', 'Calibration', 'Caring', 'Clinic', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Diagnosis', 'Diagnostic', 'Disincentive', 'Dual-Energy X-Ray Absorptiometry', 'Engineering', 'Ensure', 'Etiology', 'Evaluation', 'Event', 'Finite Element Analysis', 'Fracture', 'Goals', 'Healthcare', 'Height', 'Hip Fractures', 'Hip region structure', 'Iceland', 'International', 'Lifting', 'Location', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Medicare', 'Methods', 'Modality', 'Modeling', 'Modification', 'Muscle', 'Nature', 'Osteoporosis', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Process', 'Research', 'Risk', 'Risk Assessment', 'Scanning', 'Small Business Innovation Research Grant', 'Spinal Curvatures', 'Structure', 'Techniques', 'Testing', 'Thick', 'Translating', 'Translations', 'Upper arm', 'Validation', 'Vertebral column', 'Woman', 'X-Ray Computed Tomography', 'age related', 'base', 'bone', 'bone geometry', 'bone strength', 'clinical application', 'clinical practice', 'cohort', 'cost', 'density', 'design', 'diagnosis standard', 'falls', 'high risk', 'image processing', 'improved', 'insight', 'men', 'muscle form', 'osteoporosis with pathological fracture', 'prospective', 'public health relevance', 'sex', 'soft tissue', 'spine bone structure', 'trend', 'validation studies']",NIAMS,"O. N. DIAGNOSTICS, LLC",R44,2009,3501,647058,-0.00032128399297758645
"Category Learning in Dynamic Environments    DESCRIPTION (provided by applicant): On completion of training, the candidate will pursue a first tier university professorship or a position at a government research institution, and investigate human learning and decision making. His goal is to ultimately shed light on how the brain supports these behaviors to inform both clinical and neuroscientific applications. To this end, the candidate brings to bear powerful eye tracking techniques for measuring information processing of categories. The proposed research examines the interplay between the structure of the learning task and how people attend to features in the task environment. By examining such variables, the work will narrow the gap between tasks of the real world and those that are studied in the area of categories and concepts-an area that concerns the core cognitive process by which people conceive of distinct things as belonging to the same class. The proposal explores whether the effect of learning task on category representation is mediated by interplay between task dynamics and learners' sampling of the environment. To understand the interplay between task, eye movements, and concept representation, the proposal will incorporate modern reinforcement learning techniques from the machine learning literature into a category learning model. Reinforcement learning has been used to model eye movements in other areas including reading and problem solving. Neuroscientific work has found circuits linking the basal ganglia through dopamine with the frontal cortex that appear to operate according to reinforcement learning processes (Frank and Glaus, 2006). Moreover, Yechiam, et al. (2005) showed that the parameters in reinforcement learning models appear to map to specific clinical populations as they performed in a simple gambling task. Instead of gambling tasks, or artificial category learning tasks, the goal of the proposed work is to move towards tasks that might help to understand real world behaviors and their causes. The new category-reinforcement learning model proposed here will be applied first to the candidate's existing eye movement data, a rich data set on learners' attention to category information as they learn in standard tasks. Then, the model will be applied to the proposed behavioral experiments investigating the role of task dynamics on learners' sampling behavior. PUBLIC HEALTH RELEVANCE: The proposed research will improve our understanding of the cognitive processes having to do with learning and attention. By exploring learning tasks that are more like those experienced in the real world, the research can improve the applicability of cognitive models for diagnosing and devising treatments for deficits from ADHD, Autism, Asperger's, Huntington's disease, Parkinson's disease.           n/a",Category Learning in Dynamic Environments,7581008,F32HD057695,"['Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Clinical', 'Cognitive', 'Data', 'Data Set', 'Decision Making', 'Diagnosis', 'Dopamine', 'Environment', 'Eye', 'Eye Movements', 'Gambling', 'Goals', 'Government', 'Human', 'Huntington Disease', 'Institution', 'Learning', 'Light', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Modeling', 'Parkinson Disease', 'Population', 'Positioning Attribute', 'Problem Solving', 'Process', 'Psychological reinforcement', 'Reading', 'Research', 'Role', 'Sampling', 'Structure', 'Techniques', 'Training', 'Universities', 'Ursidae Family', 'Work', 'experience', 'frontal lobe', 'improved', 'information processing', 'public health relevance', 'research study']",NICHD,"UNIVERSITY OF TEXAS, AUSTIN",F32,2009,51103,91740242,-0.020050230279164537
"Statistical Model Building for High Dimensional Biomedical Data    DESCRIPTION (provided by applicant):  Typical of current large-scale biomedical data is the feature of small number of observed samples and the widely observed sample heterogeneity. Identifying differentially expressed genes related to the sample phenotye (e.g., cancer disease development) and predicting sample phenotype based on the gene expressions are some central research questions in the microarray data analysis. Most existing statistical methods have ignored sample heterogeneity and thus loss power.       This project proposes to develop novel statistical methods that explicitly address the small sample size and sampe heterogeneity issues, and can be applied very generally. The usefulness of these methods will be shown with the large-scale biomedical data originating from the lung and kidney transplant research projects. The transplant projects aimed to improve the molecular diagnosis and therapy of lung/kidney allograft rejection by identifying molecular biomarkers to predict the allograft rejection for critical early treatment and rapid, noninvasive, and economical testing.       The specific aims are 1) Develop novel statistical methods for differential gene expression detection that explicitly model sample heterogeneity. 2) Develop novel statistical methods for classifying high-dimensional biomedical data and incorporating sample heterogeneity. 3) Develop novel statistical methods for jointly analyzing a set of genes (e.g., genes in a pathway). 4) Use the developed models and methods to answer research questions relevant to public health in the lung and kidney transplant projects; and implement and validate the proposed methods in user-friendly and well-documented software, and distribute them to the scientific community at no charge.       It is very important to identify new biomarkers of allograft rejection in lung and kidney transplant recipients. The rapid and reliable detection and prediction of rejection in easily obtainable body fluids may allow the rapid advancement of clinical interventional trials. We propose to study novel methods for analyzing the large-scale biomedical data to realize their full potential of molecular diagnosis and prognosis of transplant rejection prediction for critical early treatment.          n/a",Statistical Model Building for High Dimensional Biomedical Data,7666186,R01GM083345,"['Address', 'Adopted', 'Algorithms', 'Allografting', 'Biological Markers', 'Body Fluids', 'Cations', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Collection', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early treatment', 'Effectiveness', 'Experimental Designs', 'Gene Expression', 'Genes', 'Genomics', 'Graft Rejection', 'Heterogeneity', 'Individual', 'Internet', 'Joints', 'Kidney Transplantation', 'Least-Squares Analysis', 'Literature', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Minnesota', 'Modeling', 'Molecular', 'Molecular Diagnosis', 'Oncogene Activation', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Phenotype', 'Principal Component Analysis', 'Probability', 'Procedures', 'Public Health', 'Relative (related person)', 'Research', 'Research Project Grants', 'Research Proposals', 'Resources', 'Sample Size', 'Sampling', 'Silicon Dioxide', 'Statistical Methods', 'Statistical Models', 'Technology', 'Testing', 'Tissue-Specific Gene Expression', 'Transplant Recipients', 'Transplantation', 'Universities', 'Ursidae Family', 'Work', 'base', 'biobank', 'cancer microarray', 'cancer type', 'design', 'improved', 'interest', 'kidney allograft', 'method development', 'novel', 'outcome forecast', 'predictive modeling', 'simulation', 'software development', 'sound', 'theories', 'transplant database', 'user friendly software', 'user-friendly']",NIGMS,UNIVERSITY OF MINNESOTA,R01,2009,256073,340417756,-0.02976512538204035
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,7735790,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2009,270375,641965656,-0.005979215401124838
"Semi-Automated Abstract Screening for Comparative Effectiveness Reviews    DESCRIPTION (provided by applicant): In this three-year project, we aim to apply state-of-the-art information analysis technologies to assist the production of systematic reviews and meta-analyses that are increasingly being used as a foundation for evidence-based medicine (EBM) and comparative effectiveness reviews. We plan to develop a human guided computerized abstract screening tool to greatly reduce the need to perform a tedious but crucial step of manually screening many thousands of abstracts generated by literature searches in order to retrieve a small fraction potentially relevant for further analysis. This tool will combine proven machine learning techniques with a new open source tool that enables management of the screening process. This new technology will enable investigators to screen abstracts in a small fraction of the time compared to the current manual process. It will reduce the time and cost of producing systematic reviews, provide clear documentation of the process and potentially perform the task more accurately. With the acceptance of EBM and increasing demands for systematic reviews, there is a great need for tools to assist in generating new systematic reviews and in updating them. This need cannot be more pressing. The recent passage of the American Recovery and Reinvestment Act and the $1.1 billion allocated for comparative effectiveness research have created an unprecedented need for systematic reviews and opportunities to improve the methodologies and efficiency of their conduct.   We herein propose the development of novel, open-source software to help systematic reviewers better   cope with these torrents of data. The research and development of this tool will be carried out by a highly experienced team of systematic review investigators with computer scientists at Tufts University who began to collaborate last year as a result of Tufts being awarded one of the NIH Clinical Translational Science Awards (CTSA). We will pursue dissemination of the new technology through numerous channels including, but not limited to publication, presentation at conferences, exploring interest in its adoption by the Agency for Healthcare Research and Quality (AHRQ) Evidence-based Practice Center (EPC) Program, Cochrane Collaboration, CTSA network, and other groups conducting systematic reviews, and production of tutorial material. Our aims are:   1. Conduct research to design and implement a semi-automated system using machine learning and   information retrieval methods to identify relevant abstracts in order to improve the accuracy and efficiency of systematic reviews.   2. Develop Abstrackr, an open-source system with a Graphical User Interface (GUI) for screening abstracts, that applies the methods developed in Aim 1 to automatically exclude irrelevant abstracts/articles.   3. Evaluate the performance of the active learning model developed in Aim 1 and the functionality of   Abstrackr developed in Aim 2 through application to a collection of manually screened datasets of   biomedical abstracts that will subsequently be made publicly available for use as a repository to spur   research in the machine learning and information retrieval communities.           Systematic reviewing is a scientific approach to objectively summarizing the effectiveness and safety of existing treatments for diseases, a prerequisite for informed healthcare decision-making. Systematic reviewers must read many thousands of medical study abstracts, the vast majority of which are completely irrelevant to the review at hand. This is hugely laborious and time consuming. We propose to build a computerized system that automatically excludes a large number of the irrelevant abstracts, thereby accelerating the process and expediting the application of the systematic review findings to patient care.",Semi-Automated Abstract Screening for Comparative Effectiveness Reviews,7786337,R01HS018494,[' '],AHRQ,TUFTS MEDICAL CENTER,R01,2009,362692,17640378,9.299361217135076e-06
"Robust Classification Methods for Categorical Regression    DESCRIPTION (provided by applicant): Improving statistical methods to provide better classification performance and new analytical capabilities for categorical regression would be invaluable to the medical and health care research communities. Categorical regression models (e.g., binary logistic, multinomial logistic) are used extensively to identify patterns of alcohol-related symptoms, screen for disorders, and assess policies. In addition, such models are used extensively in other areas of research such as mental illness, cancer, traumatic injuries, and AIDS-related pathologies. However, many such models are developed with inadequate support to fully analyze and exploit the intrinsically probabilistic nature of their results. This is of critical importance as health researchers, clinicians, and administrators are often faced with classification decisions using categorical regression models to identify unacceptable risks, adequate outcomes, and acceptable guidelines for screening, diagnoses, treatment, and quality of care. Commercially available statistical software does not offer sophisticated methods for robust estimation of posterior probabilities in the presence of model misspecification, missing covariates, and nonignorable missing data generating processes. Such robust missing data handling methods provide natural mechanisms for dealing with verification bias and modeling correlated, longitudinal, or survey data with complex sampling designs. Moreover, commercially available statistical software does not provide automated methods for using estimated posterior probabilities to make optimal classification decisions with respect to different optimality criteria. In particular, automated features such as optimizing multiple decision criteria (allocation rules) that trade off specificity against sensitivity, decision threshold confidence intervals, statistical tests for evaluating correct specification of posterior probabilities, statistical tests for comparing competing classifier thresholds, and methods for multi-outcome classification and inference are not readily available. Phase II research will extend Phase I findings for binary logistic regression to develop and implement automated robust classification methods for multinomial logistic regression modeling, which also applies to the larger class of nonlinear categorical regression models that output posterior probabilities. The Phase II software prototype will provide: 1) new user-selectable robust decision threshold estimators, 2) robust confidence intervals on decision threshold estimators, 3) new classifier threshold comparison tests, 4) new outcome probability specification tests, 5) efficient missing data handling methods in the presence of nonignorable nonresponse data, and 6) second-order analytic and simulation-based Bayesian methods for improved small sample and rare event outcome probability estimation. These new methodologies will be integrated into a prototype user-friendly software package, evaluated with extensive simulation studies, and then applied to real world classification problems encountered in: alcohol, mental illness (depression, bipolar, schizophrenia), cancer (prostate), trauma (emergency room), and infectious disease (AIDS) through collaborations with domain experts in those respective fields. In summary, Phase II research will establish the essential technical foundation for Phase III commercialization with the objective of providing a suite of new classification analysis methods as an advanced statistical tool that improves epidemiologic, clinical, and public health research.                 n/a",Robust Classification Methods for Categorical Regression,7686932,R44CA139607,"['Accident and Emergency department', 'Achievement', 'Address', 'Administrator', 'Agreement', 'Alcohols', 'Algorithms', 'Area', 'Bayesian Method', 'Behavior', 'Bipolar Depression', 'Classification', 'Clinical', 'Clinical Investigator', 'Collaborations', 'Communicable Diseases', 'Communities', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Analyses', 'Data Set', 'Decision Analysis', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Empirical Research', 'Engineering', 'Epidemiologic Studies', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Foundations', 'Goals', 'Guidelines', 'Health', 'Health Services Research', 'Healthcare', 'Industry', 'Information Resources Management', 'Injury', 'Jordan', 'Journals', 'Knowledge', 'Literature', 'Logistic Regressions', 'Logistics', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Outcome', 'Output', 'Pathology', 'Pattern', 'Peer Review', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Policies', 'Preparation', 'Probability', 'Process', 'Publishing', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Risk', 'Robin bird', 'Sampling', 'Schizophrenia', 'Screening procedure', 'Sensitivity and Specificity', 'Simulate', 'Software Tools', 'Specific qualifier value', 'Specificity', 'Statistical Methods', 'Surveys', 'Symptoms', 'Technology', 'Testing', 'Trauma', 'anticancer research', 'base', 'commercialization', 'computerized data processing', 'density', 'design', 'graphical user interface', 'improved', 'innovation', 'prototype', 'public health research', 'simulation', 'software development', 'theories', 'tool', 'user friendly software']",NCI,MARTINGALE RESEARCH CORPORATION,R44,2009,957937,0,0.002447155616848203
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7433144,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Class', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Computers', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Numbers', 'Performance', 'Personal Satisfaction', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Public Health', 'Randomized', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Today', 'Training', 'Voting', 'Work', 'base', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSIGHTFUL CORPORATION,R44,2008,25548,0,0.00980899073694706
"Category Learning in Dynamic Environments    DESCRIPTION (provided by applicant): On completion of training, the candidate will pursue a first tier university professorship or a position at a government research institution, and investigate human learning and decision making. His goal is to ultimately shed light on how the brain supports these behaviors to inform both clinical and neuroscientific applications. To this end, the candidate brings to bear powerful eye tracking techniques for measuring information processing of categories. The proposed research examines the interplay between the structure of the learning task and how people attend to features in the task environment. By examining such variables, the work will narrow the gap between tasks of the real world and those that are studied in the area of categories and concepts-an area that concerns the core cognitive process by which people conceive of distinct things as belonging to the same class. The proposal explores whether the effect of learning task on category representation is mediated by interplay between task dynamics and learners' sampling of the environment. To understand the interplay between task, eye movements, and concept representation, the proposal will incorporate modern reinforcement learning techniques from the machine learning literature into a category learning model. Reinforcement learning has been used to model eye movements in other areas including reading and problem solving. Neuroscientific work has found circuits linking the basal ganglia through dopamine with the frontal cortex that appear to operate according to reinforcement learning processes (Frank and Glaus, 2006). Moreover, Yechiam, et al. (2005) showed that the parameters in reinforcement learning models appear to map to specific clinical populations as they performed in a simple gambling task. Instead of gambling tasks, or artificial category learning tasks, the goal of the proposed work is to move towards tasks that might help to understand real world behaviors and their causes. The new category-reinforcement learning model proposed here will be applied first to the candidate's existing eye movement data, a rich data set on learners' attention to category information as they learn in standard tasks. Then, the model will be applied to the proposed behavioral experiments investigating the role of task dynamics on learners' sampling behavior. PUBLIC HEALTH RELEVANCE: The proposed research will improve our understanding of the cognitive processes having to do with learning and attention. By exploring learning tasks that are more like those experienced in the real world, the research can improve the applicability of cognitive models for diagnosing and devising treatments for deficits from ADHD, Autism, Asperger's, Huntington's disease, Parkinson's disease.           n/a",Category Learning in Dynamic Environments,7408288,F32HD057695,"['Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Class', 'Clinical', 'Cognitive', 'Computer information processing', 'Data', 'Data Set', 'Decision Making', 'Diagnosis', 'Dopamine', 'Environment', 'Eye', 'Eye Movements', 'Gambling', 'Goals', 'Government', 'Human', 'Huntington Disease', 'Institution', 'Learning', 'Light', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Modeling', 'Parkinson Disease', 'Population', 'Positioning Attribute', 'Problem Solving', 'Process', 'Psychological reinforcement', 'Public Health', 'Reading', 'Research', 'Role', 'Sampling', 'Standards of Weights and Measures', 'Structure', 'Techniques', 'Training', 'Universities', 'Ursidae Family', 'Work', 'concept', 'experience', 'frontal lobe', 'improved', 'research study']",NICHD,"UNIVERSITY OF TEXAS, AUSTIN",F32,2008,48739,91740242,-0.020050230279164537
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7688793,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2008,58299,570146095,0.008071639465398402
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): The proposed Clinical Cytometry Analysis Software Project described in this grant application is designed to create a new, more efficient and effective way of analyzing cells for the presence of cancer, HIV/AIDS and other disease, using a fully automated software system. Using modern data mining techniques (pattern recognition, feature recognition, image analysis) we will design software which will analyze data (the cell samples from patients) at a much faster rate and with fewer false positives and negatives than the manual method now in use. Objectives: Assemble and validate algorithms in software that can automatically classify regions of interest in flow cytometry data. We will demonstrate that the particular populations required by our use cases can be validly, rigorously and repeatably identified automatically. Develop and validate graphical and statistical results that satisfy FDA requirements for medical device software, simplify regulatory compliance by the clinical user, and automatically deliver analysis results to diagnostic expert systems and/or LIMS systems. Satisfy the  translational medicine  goals outlined in the NIH Roadmap. This software will bring the clinician streamlined testing currently only available in research labs. Methods: Four use cases have been selected, one employing synthetic data and three clinical data; Leukemia/Lymphoma test, Analysis of longitudinal Graft vs. Host Disease (GvHD) in bone marrow transplant specimens for predictive markers and HIV/AIDS - Gag-specific T cell cytokine response profile assay. For each we have access to a substantial body of existing data, analyzed by experts. Beginning with the autogating routines in our own FlowJo software, we will test and expand the application of Magnetic gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural and Support Vector Machines (SVM). Using a sampling of human operators to establish a control range, we will test each of these five techniques against the four use cases in cooperation with our collaborators. Events in the manually classified samples are given a weighted score based on the frequency with which they are included by all the operators. A single operator's score or the gating algorithm's score is compared with the cumulative score of the expert group and a match rating is computed. Additional validation techniques include combinatory validation on internal measures with respect to Pareto optimality, and Predictive Power/Stability self consistency checks using resampled or perturbed data measured with external indices such as the adjusted Rand index and the Variation of Information index.  PUBLIC HEALTH RELEVANCE: By eliminating the operator's time, we estimate that the cost of clinical flow cytometry analysis can be reduced to half the current figure while delivering the results much faster. By eliminating the subjectivity and human error of manually created regions and reducing the range of variability of the so created, there would result fewer false positives and false negatives, improving the clinical outcome for those patients needing therapy but undetected by current methods. An order of magnitude increase in speed means faster therapeutic intervention.  A less expensive test improves outcome by making the test accessible to more patients.          n/a",Clinical Cytometry Analysis Software with Automated Gating,7482923,R43RR024094,"['AIDS/HIV problem', 'Algorithms', 'Applications Grants', 'B-Lymphocytes', 'Biological Assay', 'Biological Neural Networks', 'Bone Marrow Transplantation', 'Cells', 'Characteristics', 'Class', 'Classification', 'Clinical', 'Clinical Data', 'Cluster Analysis', 'Complex', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cytometry', 'Data', 'Data Analyses', 'Data Files', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Educational process of instructing', 'Environment', 'Evaluation', 'Event', 'Expert Systems', 'Facility Construction Funding Category', 'Flow Cytometry', 'Frequencies', 'Funding', 'Future', 'Gagging', 'Generations', 'Goals', 'Grant', 'Graph', 'Human', 'Image Analysis', 'Individual', 'Instruction', 'Knowledge', 'Legal patent', 'Life Cycle Stages', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Noise', 'Numbers', 'Outcome', 'Output', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Population', 'Probability', 'Process', 'Public Health', 'Publishing', 'Range', 'Rate', 'Regulation', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Scientist', 'Score', 'Software Design', 'Software Engineering', 'Software Tools', 'Solutions', 'Specific qualifier value', 'Specimen', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'T-Lymphocyte', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tube', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Voting', 'Weight', 'base', 'clinical Diagnosis', 'commercialization', 'cost', 'cytokine', 'data mining', 'design', 'improved', 'indexing', 'innovation', 'interest', 'leukemia/lymphoma', 'novel', 'predictive modeling', 'relating to nervous system', 'research study', 'response', 'software systems', 'statistics', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R43,2008,100854,0,-0.02531634649021918
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7748401,R44GM083965,"['Learning', 'Techniques', 'parallel computing']",NIGMS,INSILICOS,R44,2008,143361,0,0.00980899073694706
"Statistical Model Building for High Dimensional Biomedical Data    DESCRIPTION (provided by applicant):  Typical of current large-scale biomedical data is the feature of small number of observed samples and the widely observed sample heterogeneity. Identifying differentially expressed genes related to the sample phenotye (e.g., cancer disease development) and predicting sample phenotype based on the gene expressions are some central research questions in the microarray data analysis. Most existing statistical methods have ignored sample heterogeneity and thus loss power.       This project proposes to develop novel statistical methods that explicitly address the small sample size and sampe heterogeneity issues, and can be applied very generally. The usefulness of these methods will be shown with the large-scale biomedical data originating from the lung and kidney transplant research projects. The transplant projects aimed to improve the molecular diagnosis and therapy of lung/kidney allograft rejection by identifying molecular biomarkers to predict the allograft rejection for critical early treatment and rapid, noninvasive, and economical testing.       The specific aims are 1) Develop novel statistical methods for differential gene expression detection that explicitly model sample heterogeneity. 2) Develop novel statistical methods for classifying high-dimensional biomedical data and incorporating sample heterogeneity. 3) Develop novel statistical methods for jointly analyzing a set of genes (e.g., genes in a pathway). 4) Use the developed models and methods to answer research questions relevant to public health in the lung and kidney transplant projects; and implement and validate the proposed methods in user-friendly and well-documented software, and distribute them to the scientific community at no charge.       It is very important to identify new biomarkers of allograft rejection in lung and kidney transplant recipients. The rapid and reliable detection and prediction of rejection in easily obtainable body fluids may allow the rapid advancement of clinical interventional trials. We propose to study novel methods for analyzing the large-scale biomedical data to realize their full potential of molecular diagnosis and prognosis of transplant rejection prediction for critical early treatment.          n/a",Statistical Model Building for High Dimensional Biomedical Data,7386333,R01GM083345,"['Address', 'Adopted', 'Algorithms', 'Allografting', 'Biological Markers', 'Body Fluids', 'Cations', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Collection', 'Communities', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Early treatment', 'Effectiveness', 'Experimental Designs', 'Gene Expression', 'Genes', 'Genomics', 'Graft Rejection', 'Heterogeneity', 'Individual', 'Internet', 'Joints', 'Kidney Transplantation', 'Least-Squares Analysis', 'Literature', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Minnesota', 'Modeling', 'Molecular', 'Molecular Diagnosis', 'None or Not Applicable', 'Numbers', 'Oncogene Activation', 'Outcome', 'Outcome Measure', 'Pathway interactions', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Principal Component Analysis', 'Probability', 'Procedures', 'Public Health', 'Purpose', 'Relative (related person)', 'Research', 'Research Project Grants', 'Research Proposals', 'Resources', 'Sample Size', 'Sampling', 'Silicon Dioxide', 'Statistical Methods', 'Statistical Models', 'Technology', 'Testing', 'Tissue-Specific Gene Expression', 'Transplant Recipients', 'Transplantation', 'Universities', 'Ursidae Family', 'Work', 'base', 'cancer microarray', 'cancer type', 'design', 'desire', 'improved', 'interest', 'kidney allograft', 'method development', 'novel', 'outcome forecast', 'predictive modeling', 'simulation', 'software development', 'sound', 'theories', 'user friendly software', 'user-friendly']",NIGMS,UNIVERSITY OF MINNESOTA,R01,2008,255036,340417756,-0.02976512538204035
"Robust computational framework for predictive ADME-Tox modeling    DESCRIPTION (provided by applicant):    This proposal seeks to establish a universally applicable and robust predictive ADME-Tox modeling framework based on rigorous Quantitative Structure Activity/Property Relationships (QSAR/QSPR) modeling. The framework has been refined in the course of many years of our research in the areas of QSPR methodology development and application to experimental datasets that led to novel analytical approaches, descriptors, model validation schemes, overall QSPR workflow design, and multiple end-point studies. This proposal focuses on the design of optimized QSPR protocols for the development of reliable predictors of critically important ADME-Tox properties. The ADME properties will include, but not limited to, water solubility, membrane permeability, P450 metabolism inhibition and induction, metabolic stability, human intestinal absorption, bioavailability, transporters and PK data; a variety of toxicological end-points vital to human health will be explored; they are available from recent initiatives on development and standardization of toxicity data, such as the US FDA, NIEHS, and EPA DSS-Tox and other database projects. The ultimate goal of this project is sharing both modeling software and specialized predictors with the research community via a web-based Predictive ADME-Tox Portal. The project objectives will be achieved via concurrent development of QSPR methodology (Specific Aim 1), building highly predictive, robust QSPR models of known ADME-Tox properties (Specific Aim 2), and the deployment of both modeling software and individual predictors via a specialized web-portal (Specific Aim 3). To achieve the goals of this project focusing on the development and delivery of specialized tools and rigorous predictors, we have assembled a research team of mostly senior investigators with complimentary skills and track records of accomplishment in the areas of computational drug discovery, experimental toxicology, statistical modeling, and software development and integration; two of the team members have had recent industrial experience before transitioning to academia. To the best of our knowledge, the results of this proposal will lead to the first publicly available in silico ADME-Tox modeling framework and predictors that can be used by the research community to analyze any set of chemicals (i.e., virtual and real compound sets). The framework will have a significant impact on compound prioritization, chemical library design, and candidate selection for preclinical and clinical development.            n/a",Robust computational framework for predictive ADME-Tox modeling,7433931,R21GM076059,"['Academia', 'Acute', 'Address', 'Area', 'Biological Availability', 'Cardiotoxicity', 'Cell Membrane Permeability', 'Chemicals', 'Chronic', 'Clinical', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Consensus', 'Cytochrome P450', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Drug Kinetics', 'End Point', 'Ensure', 'Environment', 'Goals', 'Health', 'Hepatotoxicity', 'Human', 'Individual', 'Internet', 'Intestinal Absorption', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Letters', 'Lung', 'Machine Learning', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Organ', 'Pharmacologic Substance', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Scheme', 'Scientist', 'Screening procedure', 'Secure', 'Source', 'Specialist', 'Standardization', 'Standards of Weights and Measures', 'Statistical Models', 'Statistically Significant', 'Structure', 'Students', 'Techniques', 'Technology', 'Testing', 'Toxic effect', 'Toxicology', 'Training', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'carcinogenicity', 'career', 'cluster computing', 'combinatorial', 'computer framework', 'data mining', 'design', 'drug discovery', 'experience', 'genotoxicity', 'innovation', 'knowledge of results', 'member', 'method development', 'neurotoxicity', 'novel', 'open source', 'pre-clinical', 'programs', 'protocol development', 'reproductive', 'skills', 'small molecule libraries', 'software development', 'tool', 'virtual', 'water solubility']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2008,322087,511185245,-0.015588056225584776
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7458835,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2008,503603,570146095,0.008071639465398402
"Robust Classification Methods for Categorical Regression    DESCRIPTION (provided by applicant): Improving statistical methods to provide better classification performance and new analytical capabilities for categorical regression would be invaluable to the medical and health care research communities. Categorical regression models (e.g., binary logistic, multinomial logistic) are used extensively to identify patterns of alcohol-related symptoms, screen for disorders, and assess policies. In addition, such models are used extensively in other areas of research such as mental illness, cancer, traumatic injuries, and AIDS-related pathologies. However, many such models are developed with inadequate support to fully analyze and exploit the intrinsically probabilistic nature of their results. This is of critical importance as health researchers, clinicians, and administrators are often faced with classification decisions using categorical regression models to identify unacceptable risks, adequate outcomes, and acceptable guidelines for screening, diagnoses, treatment, and quality of care. Commercially available statistical software does not offer sophisticated methods for robust estimation of posterior probabilities in the presence of model misspecification, missing covariates, and nonignorable missing data generating processes. Such robust missing data handling methods provide natural mechanisms for dealing with verification bias and modeling correlated, longitudinal, or survey data with complex sampling designs. Moreover, commercially available statistical software does not provide automated methods for using estimated posterior probabilities to make optimal classification decisions with respect to different optimality criteria. In particular, automated features such as optimizing multiple decision criteria (allocation rules) that trade off specificity against sensitivity, decision threshold confidence intervals, statistical tests for evaluating correct specification of posterior probabilities, statistical tests for comparing competing classifier thresholds, and methods for multi-outcome classification and inference are not readily available. Phase II research will extend Phase I findings for binary logistic regression to develop and implement automated robust classification methods for multinomial logistic regression modeling, which also applies to the larger class of nonlinear categorical regression models that output posterior probabilities. The Phase II software prototype will provide: 1) new user-selectable robust decision threshold estimators, 2) robust confidence intervals on decision threshold estimators, 3) new classifier threshold comparison tests, 4) new outcome probability specification tests, 5) efficient missing data handling methods in the presence of nonignorable nonresponse data, and 6) second-order analytic and simulation-based Bayesian methods for improved small sample and rare event outcome probability estimation. These new methodologies will be integrated into a prototype user-friendly software package, evaluated with extensive simulation studies, and then applied to real world classification problems encountered in: alcohol, mental illness (depression, bipolar, schizophrenia), cancer (prostate), trauma (emergency room), and infectious disease (AIDS) through collaborations with domain experts in those respective fields. In summary, Phase II research will establish the essential technical foundation for Phase III commercialization with the objective of providing a suite of new classification analysis methods as an advanced statistical tool that improves epidemiologic, clinical, and public health research.                 n/a",Robust Classification Methods for Categorical Regression,7395177,R44CA139607,"['Accident and Emergency department', 'Achievement', 'Address', 'Administrator', 'Agreement', 'Alcohols', 'Algorithms', 'Area', 'Bayesian Method', 'Behavior', 'Bipolar Depression', 'Class', 'Classification', 'Clinical', 'Clinical Investigator', 'Collaborations', 'Communicable Diseases', 'Communities', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Analyses', 'Data Set', 'Decision Analysis', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Disease regression', 'Empirical Research', 'Engineering', 'Epidemiologic Studies', 'Epidemiologist', 'Evaluation', 'Event', 'Foundations', 'Goals', 'Guidelines', 'Health', 'Health Services Research', 'Healthcare', 'Industry', 'Information Resources Management', 'Injury', 'Jordan', 'Journals', 'Knowledge', 'Literature', 'Logistic Regressions', 'Logistics', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Outcome', 'Output', 'Pathology', 'Pattern', 'Peer Review', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Policies', 'Preparation', 'Probability', 'Process', 'Public Health', 'Publishing', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Risk', 'Robin bird', 'Sampling', 'Schizophrenia', 'Screening procedure', 'Sensitivity and Specificity', 'Simulate', 'Software Tools', 'Specific qualifier value', 'Specificity', 'Standards of Weights and Measures', 'Statistical Methods', 'Surveys', 'Symptoms', 'Technology', 'Testing', 'Trauma', 'anticancer research', 'base', 'commercialization', 'computerized data processing', 'density', 'design', 'graphical user interface', 'improved', 'innovation', 'prototype', 'simulation', 'software development', 'theories', 'tool', 'user friendly software']",NCI,MARTINGALE RESEARCH CORPORATION,R44,2008,857168,0,0.002447155616848203
"Systems analysis of oxygen regulation in Halobacterium    DESCRIPTION (provided by applicant): To withstand environmental onslaught, biological systems mount global programs to coordinate the induction of protection and repair mechanisms. This proposal poses the hypothesis that the transcriptional networks underlying such responses to diverse stressors are interrelated. Halobacterium, a halophilic archaeon, has been chosen as a model for this study because it routinely negotiates an array of adverse conditions in its extreme environment, including anoxia, metal stress, and radiation damage. This proposal will investigate the inter-relationship of these responses using global approaches. Given that basal genetic information processing pathways in Halobacterium are mediated by eukaryotic-like proteins, findings from this study will have a direct impact on understanding how complex eukaryotic organisms elicit orthogonal responses in disease-perturbed or infection states. Specifically, I will (1) Characterize key transcriptional regulators responsible for mediating responses to fluctuating oxygen concentrations and identify regulons under their direct and indirect control; (2) Through statistical analysis of integrated datasets, evaluate the extent of cross-regulation of the anoxic response with other environmental perturbations; (3) Experimentally test new hypotheses generated by statistical analysis. These proposed experiments are expected to result in a transcriptional network model that addresses how organisms maintain homeostasis despite stress.           n/a",Systems analysis of oxygen regulation in Halobacterium,7261251,F32GM078980,"['Address', 'Aerobic', 'Algorithms', 'Anoxia', 'Archaea', 'Behavioral', 'Binding Sites', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Phenomena', 'Cells', 'Collection', 'Complex', 'Computer software', 'Condition', 'Couples', 'Data', 'Data Set', 'Defect', 'Disease', 'Electrophoretic Mobility Shift Assay', 'Environment', 'Equilibrium', 'Experimental Designs', 'Face', 'Facility Construction Funding Category', 'Fellowship', 'Gene Targeting', 'Genes', 'Genetic Information Processing Pathway', 'Genome', 'Goals', 'Growth', 'Halobacterium', 'Homeostasis', 'Hydrogen Peroxide', 'Individual', 'Infection', 'Information Systems', 'Knock-out', 'Laboratories', 'Learning', 'Light', 'Localized', 'Machine Learning', 'Manuscripts', 'Maps', 'Mediating', 'Mediation', 'Metals', 'Modeling', 'Molecular Biology', 'Mutate', 'Names', 'Organism', 'Oxidation-Reduction', 'Oxidative Stress', 'Oxygen', 'Oxygen measurement, partial pressure, arterial', 'Play', 'Preparation', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Radiation', 'Regulation', 'Regulator Genes', 'Regulon', 'Relative (related person)', 'Role', 'Stress', 'Study models', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Testing', 'Time', 'TimeLine', 'Training', 'Transcription Initiation Site', 'Transcriptional Regulation', 'Work', 'biological adaptation to stress', 'cell injury', 'chromatin immunoprecipitation', 'halobacteria', 'high throughput screening', 'in vivo', 'insight', 'metal poisoning', 'mutant', 'network models', 'novel', 'programs', 'repaired', 'research study', 'response', 'stressor', 'transcription factor']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,F32,2007,48796,10159852,-0.015355429903864768
"Utility of Trans Telephonic Monitoring in the Detection of Silent Arrhythmias    DESCRIPTION (provided by applicant): The primary aim of this feasibility study is to determine if a Cardiac Arrhythmia Trans telephonic EKG monitoring system (CAT) can be used to detect asymptomatic or ""silent"" arrhythmias in patients greater than or equal to 65 years of age with a history of hypertension (HTN) and heart failure (HF) and characterize their onset, frequency, and duration. The secondary aim is to examine the association between silent arrhythmias and quality of life (QoL). Atrial fibrillation (AF) is the most common arrhythmia and its prevalence increases with age, HTN, and HF. It also has a profound impact on QoL. Whether silent or symptomatic, AF can result in stroke. Detection of silent arrhythmias, especially silent AF, could prompt the initiation of anticoagulation that would decrease the occurrence of stroke, which is the third leading cause of death in the US. As treatment for HTN and HF continue to improve, combined with increased life expectancy, early arrhythmia identification strategies are urgently needed to predict who is at the highest risk for silent arrhythmias. Standard methods for detecting AF include 12-lead EKGs, 24-hour Holter recorders (HM) and non-auto-triggered memory loop recorders (MLR). MLRs are unable to automatically detect and capture silent arrhythmias since they require patient activation during symptoms. Auto-triggered MLRs (AT-MLR) have recently become available which automatically record arrhythmias, with or without associated symptoms, and the stored EKG data can then be transmitted trans telephonically (via phone) to a central monitoring station. A recently completed retrospective analysis has shown that AT-MLRs produced a higher yield of diagnostic events and an earlier time to diagnosis of silent arrhythmias as compared to HM or MLR. This study proposes a single-center, prospective consecutive series of 100 patients using a 14-day CAT monitoring period. At baseline and 6 months, cardiac clinical characteristics and risk factors will be collected from patients via physical exam and chart review, and the SF-36v2(TM) will be administered to determine if differences exist in perceived QoL in patients with silent AF. Information regarding AF frequency and duration will be quantified using the University of Toronto Atrial Fibrillation Scale (AFSS). Spearman's correlation will be used to assess the association between AF and changes in SF-36v2(TM) QoL scores between baseline and 6 months. The relationship between AF, demographic, and clinical characteristics will be determined using logistic regression analysis. All significant univariate variables will be entered into a multivariate logistic regression model. The results of this feasibility study could potentially justify development of a new screening mechanism for silent AF. If this study proves successful, a larger trial will be proposed to explore specific clinical variables, EKG characteristics, and treatment strategies to improve clinical care and QoL.           n/a",Utility of Trans Telephonic Monitoring in the Detection of Silent Arrhythmias,7244448,R03NR010001,"['Age', 'Age-Years', 'Anticoagulation', 'Arrhythmia', 'Atrial Fibrillation', 'Benign', 'Cardiac', 'Caring', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Chronic', 'Classification', 'Clinical', 'Condition', 'Data', 'Detection', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Dizziness', 'Ectopic beats', 'Elderly', 'Electric Countershock', 'Electrocardiogram', 'Event', 'Feasibility Studies', 'Frequencies', 'Goals', 'Grant', 'Health Promotion', 'Healthcare', 'Heart', 'Heart Atrium', 'Heart failure', 'Hour', 'Hypertension', 'Individual', 'Lead', 'Length', 'Life', 'Life Expectancy', 'Logistic Regressions', 'Logistics', 'Longevity', 'Mechanics', 'Memory', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Palpitations', 'Patients', 'Perceived quality of life', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Populations at Risk', 'Prevalence', 'Purpose', 'Quality of life', 'Rate', 'Recording of previous events', 'Regression Analysis', 'Reporting', 'Research', 'Risk', 'Risk Factors', 'Score', 'Screening procedure', 'Series', 'Shock', 'Sinus', 'Standards of Weights and Measures', 'Stroke', 'Symptoms', 'System', 'Technology', 'Telemedicine', 'Telephone', 'Time', 'Unconscious State', 'Universities', 'Ventricular', 'Ventricular Tachycardia', 'clinically significant', 'compare effectiveness', 'day', 'design', 'disorder prevention', 'ethnic minority population', 'experience', 'heart rhythm', 'hypertension treatment', 'improved', 'older patient', 'prospective']",NINR,COLUMBIA UNIVERSITY HEALTH SCIENCES,R03,2007,78166,558628098,-0.06100433235751802
"Developing computerized tools for cryosurgery planning    DESCRIPTION (provided by applicant):    Cryosurgery has been known as an invasive surgical technique since 1961, when Cooper and Lee invented the first cryoprobe. In the 1990s, new developments in Joule-Thomson cooling (the cooling effect associated with a sudden relief of a pressurized gas) led to a dramatic decrease in the size of cryoprobes and an increase in the number of cryoprobes that could be used simultaneously. A dozen or more cryoprobes operating simultaneously in a single prostate cryosurgery is already common practice. If localized effectively, one of the primary benefits of using a large number of miniaturized cryoprobes is superior control over the freezing process.   Currently, the process of selecting the correct placement of the cryoprobes for a specific procedure is an art held by the cryosurgeon, based on the surgeon's own experience and rules of thumb. Cryoprobes are typically operated in a trial-and-error fashion, until the entire target volume is thought to be frozen. Currently, there are no means to determine the optimal locations for the cryoprobes. Suboptimal cryoprobe localization may leave regions in the target volume unfrozen, may lead to cryoinjury of healthy surrounding tissues, may require an unnecessarily large number of cryoprobes, may increase the duration of the surgical procedure, and may increase the likelihood of post cryosurgery complications, all of which affect the quality and cost of the medical treatment. Computerized planning tools would help to alleviate these difficulties.   The ""cryoheater,"" a new device for cryosurgery control has recently been presented by the research team. The cryoheater is a temperature controlled electrical heater. In broad terms, cryoheaters can dramatically increase the ability to control the shape and size of the frozen region, however, to achieve the full benefits of cryoheaters, computerized planning tools for cryoheater localization are necessary.   Our goal is to develop computerized planning tools for cryosurgery that are suitable for all available cooling techniques. The proposed research includes: (1) Development of an efficient numerical scheme for bioheat transfer simulations of cyroprocedures, (2) Development of an efficient optimization technique based on a force-field analogy. (3) Development of knowledge-based optimization techniques. (4) Experimental verification of the planning tool.       Besides planning, another important application of the proposed tool is the training of cryosurgeons. The proposed tool will provide cryosurgeons with the ability to visualize the 3D volumetric nature of the freezing process.   Likewise, it will allow the surgeon to explore the performance of various configurations of cryoprobes and cryoheaters, and observe the defects that would result from each. Such visualization capabilities will provide surgeons with insights into the physics of cryosurgery that are difficult to obtain from physical experiments or surgical practice.         n/a",Developing computerized tools for cryosurgery planning,7210691,R01EB003563,"['Affect', 'Arts', 'Biological', 'Catheters', 'Computational Technique', 'Condition', 'Cool-X-A', 'Cryosurgery', 'Defect', 'Depth', 'Development', 'Devices', 'Europe', 'Feasibility Studies', 'Freezing', 'Frequencies', 'Furuncles', 'Gases', 'Goals', 'Heating', 'Imagery', 'Imaging Device', 'Invasive', 'Lasers', 'Lead', 'Learning', 'Left', 'Liquid substance', 'Localized', 'Location', 'Machine Learning', 'Medical', 'Methods', 'Modems', 'Nature', 'Nitrogen', 'Numbers', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Performance', 'Physics', 'Placement', 'Procedures', 'Process', 'Prostate', 'Publishing', 'Purpose', 'Radio', 'Reporting', 'Research', 'Research Proposals', 'Scheme', 'Shapes', 'Simulate', 'Solutions', 'Source', 'Surgeon', 'Techniques', 'Temperature', 'Thermal Ablation Therapy', 'Thinking', 'Thumb structure', 'Time', 'Tissues', 'Training', 'Ultrasonography', 'Urethra', 'base', 'clinical application', 'computerized', 'computerized tools', 'cost', 'experience', 'insight', 'knowledge base', 'miniaturize', 'research study', 'simulation', 'size', 'thermal seeds', 'three-dimensional modeling', 'tool']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2007,87443,30434536,-0.013652723374442014
"Least Angle Regression    DESCRIPTION (provided by applicant): This SBIR project aims to produce superior methods and software for classification and regression when there are many potential predictor variables to choose from. The methods should (1) produce stable results, where small changes in the data do not produce major changes in the variables selected or in model predictions; (2) produce accurate predictions; (3) facilitate scientific interpretation, by selecting a smaller subset of predictors which provide the best predictions; (4) allow continuous and categorical variables; and (5) support linear regression, logistic regression (predicting a binary outcome), survival analysis, and other types of regression. This project is based on least angle regression, which unifies and provides a fast implementation for a number of modern regression techniques. Least angle regression has great potential, but currently available software is limited in scope and robustness. The outcome of this project should be software which is more robust and widely applicable. This software would apply broadly, including to medical diagnosis, detecting cancer, feature selection in microarrays, and modeling patient characteristics like blood pressure. Phase I work demonstrates feasibility by extending least angle work in three key directions-categorical predictors, logistic regression, and a numerically-accurate implementation. Phase II goals include extensions to other types of explanatory variables (e.g. polynomial or spline functions, and interactions between variables), to survival and other additional regression models, and to handle missing data and massive data sets. This proposed software will enable medical researchers to obtain high prediction accuracy, and obtain stable and interpretable results, in high-dimensional situations. Predicting outcomes based on covariates, determining which covariates most affect outcomes, and adjusting treatment effects estimates for covariates, are among the most important problems in biostatistics. Prediction and feature selection are particularly difficult when there are more possible features than samples; gene microarrays and protein mass spectrometry are extreme examples of this, producing thousands to millions of measurements per sample. LARS excels at feature selection; the proposed software should enable medical researchers to obtain stable and interpretable models with better prediction accuracy in high-dimensional situations.             n/a",Least Angle Regression,7293630,R44GM074313,"['Affect', 'Algorithms', 'Biometry', 'Blood Pressure', 'Case Study', 'Cations', 'Characteristics', 'Classification', 'Computer software', 'Consult', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease regression', 'Future', 'Genes', 'Goals', 'Healthcare', 'Lasso', 'Libraries', 'Linear Models', 'Logistic Regressions', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measurement', 'Medical', 'Methods', 'Microarray Analysis', 'Mind', 'Modeling', 'Non-linear Models', 'Numbers', 'Outcome', 'Output', 'Patients', 'Personal Satisfaction', 'Phase', 'Procedures', 'Process', 'Protein Microchips', 'Proteome', 'Proteomics', 'Research Personnel', 'Sampling', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Survival Analysis', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Work', 'base', 'design', 'falls', 'graphical user interface', 'improved', 'interest', 'prototype', 'statistics', 'tool', 'treatment effect', 'ward']",NIGMS,INSIGHTFUL CORPORATION,R44,2007,158481,0,-0.002294021863055454
"Least Angle Regression    DESCRIPTION (provided by applicant): This SBIR project aims to produce superior methods and software for classification and regression when there are many potential predictor variables to choose from. The methods should (1) produce stable results, where small changes in the data do not produce major changes in the variables selected or in model predictions; (2) produce accurate predictions; (3) facilitate scientific interpretation, by selecting a smaller subset of predictors which provide the best predictions; (4) allow continuous and categorical variables; and (5) support linear regression, logistic regression (predicting a binary outcome), survival analysis, and other types of regression. This project is based on least angle regression, which unifies and provides a fast implementation for a number of modern regression techniques. Least angle regression has great potential, but currently available software is limited in scope and robustness. The outcome of this project should be software which is more robust and widely applicable. This software would apply broadly, including to medical diagnosis, detecting cancer, feature selection in microarrays, and modeling patient characteristics like blood pressure. Phase I work demonstrates feasibility by extending least angle work in three key directions-categorical predictors, logistic regression, and a numerically-accurate implementation. Phase II goals include extensions to other types of explanatory variables (e.g. polynomial or spline functions, and interactions between variables), to survival and other additional regression models, and to handle missing data and massive data sets. This proposed software will enable medical researchers to obtain high prediction accuracy, and obtain stable and interpretable results, in high-dimensional situations. Predicting outcomes based on covariates, determining which covariates most affect outcomes, and adjusting treatment effects estimates for covariates, are among the most important problems in biostatistics. Prediction and feature selection are particularly difficult when there are more possible features than samples; gene microarrays and protein mass spectrometry are extreme examples of this, producing thousands to millions of measurements per sample. LARS excels at feature selection; the proposed software should enable medical researchers to obtain stable and interpretable models with better prediction accuracy in high-dimensional situations.             n/a",Least Angle Regression,7748342,R44GM074313,"['Affect', 'Algorithms', 'Biometry', 'Blood Pressure', 'Case Study', 'Characteristics', 'Classification', 'Computer software', 'Consult', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease regression', 'Future', 'Genes', 'Goals', 'Healthcare', 'Lasso', 'Libraries', 'Linear Models', 'Logistic Regressions', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measurement', 'Medical', 'Methods', 'Microarray Analysis', 'Mind', 'Modeling', 'Non-linear Models', 'Numbers', 'Outcome', 'Output', 'Patients', 'Personal Satisfaction', 'Phase', 'Procedures', 'Process', 'Protein Microchips', 'Proteome', 'Proteomics', 'Research Personnel', 'Sampling', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Survival Analysis', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Work', 'base', 'design', 'falls', 'graphical user interface', 'improved', 'interest', 'prototype', 'statistics', 'tool', 'treatment effect', 'ward']",NIGMS,INSILICOS,R44,2007,168203,0,-0.002294021863055454
"Computer Assisted Trauma Triage (CATT)    DESCRIPTION (provided by applicant): Rapid and accurate triage is essential when dealing with acutely injured persons. To that end, a number of trauma triage decision aids have been proposed. Unfortunately, mistriage rates for trauma patients remain high, due in part to aids that lack precision or discrimination, are not used, or are misused or misapplied. Improving the trauma triage process is an important problem because doing so improves trauma triage outcomes by optimizing access to and utilization of specialized resources as well as reducing morbidity and mortality. A promising method for improving this process is to integrate machine learning algorithms as a rapid and accurate clinical decision support technique. Machine learning techniques have been used to develop rules to diagnosis myocardial infarction and to provide rapid and accurate decision support in nonmedical settings. They have also been used to predict mortality following injury. Furthermore, using machine learning algorithms for clinical decision support employs highly accurate predictive models to counter the previously mentioned pitfalls of existing trauma decision aids in the following ways: (1) collecting relevant readily available clinical information, (2) choosing the most accurate predictive model for the situation at hand, and (3) utilizing computational speed and power to optimize predictive accuracy. The goal of this AREA proposal is to test the feasibility of machine learning-based predictive modeling techniques to support trauma triage. We plan to use well-established predictive model development and evaluation techniques to: (1) Compare the existing American College of Surgeons trauma triage decision aid to four different machine learning predictive modeling techniques; (2) Compare the performance of four different machine learning predictive modeling techniques with and without a novel measure of change in physiological status; and (3) Compare the performance of full machine learning models to those derived using information gathered as a byproduct of the workflow. Models will predict persons with severe injury or need for specialized trauma resources. Successful integration of machine learning algorithms is a first step toward developing an adaptive computer assisted trauma triage system that not only helps clinicians make better decisions but also facilitates rapid access to specialized resources.           n/a",Computer Assisted Trauma Triage (CATT),7252385,R15GM080697,"['Accident and Emergency department', 'Acute myocardial infarction', 'Address', 'Admission activity', 'Adult', 'Algorithms', 'American College of Surgeons', 'Caring', 'Cause of Death', 'Cessation of life', 'Clinical', 'Computer Assisted', 'Data', 'Decision Aid', 'Decision Making', 'Decision Support Techniques', 'Development', 'Diagnosis', 'Discrimination', 'Evaluation', 'Future', 'Goals', 'Guidelines', 'Hand', 'Health', 'Healthcare', 'Hospital Records', 'Hour', 'Injury', 'Injury Severity Score', 'Intensive Care Units', 'Interdisciplinary Study', 'Logistic Regressions', 'Machine Learning', 'Measures', 'Medical Informatics', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Numbers', 'Operating Rooms', 'Outcome', 'Patients', 'Performance', 'Personal Satisfaction', 'Persons', 'Physiological', 'Process', 'Publishing', 'Rate', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Speed', 'Support of Research', 'System', 'Techniques', 'Testing', 'Translating', 'Trauma', 'Triage', 'Work', 'base', 'clinically relevant', 'disability', 'improved', 'information gathering', 'injured', 'innovation', 'model development', 'mortality', 'novel', 'predictive modeling', 'prospective', 'statistics', 'success', 'tool']",NIGMS,UNIVERSITY OF CENTRAL FLORIDA,R15,2007,216300,16827427,-0.0024349320068735897
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7214118,R42ES013321,"['Accounting', 'Animals', 'Architecture', 'Biological Assay', 'Biological Neural Networks', 'Chemicals', 'Clinical', 'Clinical Trials', 'Computer Simulation', 'Computer software', 'Contracts', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Drug Formulations', 'Drug Industry', 'Drug toxicity', 'End Point', 'Expert Systems', 'Funding', 'Future', 'Fuzzy Logic', 'Gene Expression', 'Guidelines', 'Health Care Costs', 'Hepatotoxicity', 'Investments', 'Learning', 'Liver', 'Marketing', 'Methods', 'Network-based', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Process', 'Proteomics', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Rate', 'Relative (related person)', 'Reliance', 'Research', 'Research Personnel', 'Screening procedure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Training', 'Validation', 'base', 'computational chemistry', 'cost', 'data acquisition', 'design', 'highly advanced system', 'improved', 'innovation', 'knowledge base', 'metabolomics', 'quantum', 'serial analysis of gene expression', 'subtraction hybridization', 'tool']",NIEHS,"YAHSGS, LLC",R42,2007,257269,0,-0.01719272887686888
MACE - Michigan Alliance for Cheminformatic Exploration No abstract available n/a,MACE - Michigan Alliance for Cheminformatic Exploration,7472717,P20HG003890,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Michigan', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,UNIVERSITY OF MICHIGAN,P20,2007,271370,0,0.009939542682106554
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7186695,R01NS051826,"['Accounting', 'Adult', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Anatomic structures', 'Anatomy', 'Area', 'Atlases', 'Back', 'Biomechanics', 'Boston', 'Brain', 'Caring', 'Class', 'Classification', 'Clinical assessments', 'Clutterings', 'Collaborations', 'Competence', 'Computer Simulation', 'Computer Vision Systems', 'Computing Methodologies', 'Corpus Callosum', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diffuse Pattern', 'Discipline of obstetrics', 'Disease', 'Disease Progression', 'Effectiveness', 'Effectiveness of Interventions', 'Electroencephalography', 'Elements', 'Ensure', 'Evaluation', 'Evolution', 'Fetal Growth Retardation', 'General Hospitals', 'Genetic Markers', 'Goals', 'Gold', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Incidence', 'Individual', 'Infant', 'Intervention', 'Intuition', 'Invasive', 'Knowledge', 'Label', 'Learning', 'Learning Disabilities', 'Link', 'Localized', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphologic artifacts', 'Morphology', 'Motivation', 'Neonatal', 'Neuroanatomy', 'Neurosciences', 'Neurosurgeon', 'Noise', 'Normal Range', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Pediatric Hospitals', 'Population', 'Population Characteristics', 'Population Study', 'Positioning Attribute', 'Premature Infant', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Property', 'Psyche structure', 'Range', 'Rate', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Resolution', 'Rest', 'Role', 'Scanning', 'Schizophrenia', 'Shapes', 'Site', 'Specificity', 'Staging', 'Standards of Weights and Measures', 'Statistical Distributions', 'Statistical Models', 'Statistical Study', 'Statistically Significant', 'Structure', 'Surface', 'Surgeon', 'Surgical Instruments', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Tweens', 'Universities', 'Validation', 'Variant', 'Washington', 'Woman', 'base', 'cohort', 'computer studies', 'computerized tools', 'desire', 'deviant', 'disease classification', 'expectation', 'feeding', 'healthy aging', 'imaging Segmentation', 'improved', 'instrument', 'interest', 'mortality', 'neonate', 'nervous system disorder', 'neuroimaging', 'neurosurgery', 'normal aging', 'novel', 'programs', 'radiologist', 'reconstruction', 'relating to nervous system', 'research clinical testing', 'response', 'shape analysis', 'statistics', 'tool', 'tumor']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2007,282619,113554200,-0.0008324920652620788
"Robust computational framework for predictive ADME-Tox modeling    DESCRIPTION (provided by applicant):    This proposal seeks to establish a universally applicable and robust predictive ADME-Tox modeling framework based on rigorous Quantitative Structure Activity/Property Relationships (QSAR/QSPR) modeling. The framework has been refined in the course of many years of our research in the areas of QSPR methodology development and application to experimental datasets that led to novel analytical approaches, descriptors, model validation schemes, overall QSPR workflow design, and multiple end-point studies. This proposal focuses on the design of optimized QSPR protocols for the development of reliable predictors of critically important ADME-Tox properties. The ADME properties will include, but not limited to, water solubility, membrane permeability, P450 metabolism inhibition and induction, metabolic stability, human intestinal absorption, bioavailability, transporters and PK data; a variety of toxicological end-points vital to human health will be explored; they are available from recent initiatives on development and standardization of toxicity data, such as the US FDA, NIEHS, and EPA DSS-Tox and other database projects. The ultimate goal of this project is sharing both modeling software and specialized predictors with the research community via a web-based Predictive ADME-Tox Portal. The project objectives will be achieved via concurrent development of QSPR methodology (Specific Aim 1), building highly predictive, robust QSPR models of known ADME-Tox properties (Specific Aim 2), and the deployment of both modeling software and individual predictors via a specialized web-portal (Specific Aim 3). To achieve the goals of this project focusing on the development and delivery of specialized tools and rigorous predictors, we have assembled a research team of mostly senior investigators with complimentary skills and track records of accomplishment in the areas of computational drug discovery, experimental toxicology, statistical modeling, and software development and integration; two of the team members have had recent industrial experience before transitioning to academia. To the best of our knowledge, the results of this proposal will lead to the first publicly available in silico ADME-Tox modeling framework and predictors that can be used by the research community to analyze any set of chemicals (i.e., virtual and real compound sets). The framework will have a significant impact on compound prioritization, chemical library design, and candidate selection for preclinical and clinical development.            n/a",Robust computational framework for predictive ADME-Tox modeling,7244058,R21GM076059,"['Academia', 'Acute', 'Address', 'Area', 'Biological Availability', 'Cardiotoxicity', 'Cell Membrane Permeability', 'Chemicals', 'Chronic', 'Clinical', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Consensus', 'Cytochrome P450', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Drug Kinetics', 'End Point', 'Ensure', 'Environment', 'Goals', 'Health', 'Hepatotoxicity', 'Human', 'Individual', 'Internet', 'Intestinal Absorption', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Letters', 'Lung', 'Machine Learning', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Organ', 'Pharmacologic Substance', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Scheme', 'Scientist', 'Screening procedure', 'Secure', 'Source', 'Specialist', 'Standardization', 'Standards of Weights and Measures', 'Statistical Models', 'Statistically Significant', 'Structure', 'Students', 'Techniques', 'Technology', 'Testing', 'Toxic effect', 'Toxicology', 'Training', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'carcinogenicity', 'career', 'cluster computing', 'combinatorial', 'computer framework', 'data mining', 'design', 'drug discovery', 'experience', 'genotoxicity', 'innovation', 'knowledge of results', 'member', 'method development', 'neurotoxicity', 'novel', 'open source', 'pre-clinical', 'programs', 'protocol development', 'reproductive', 'skills', 'small molecule libraries', 'software development', 'tool', 'virtual', 'water solubility']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2007,328325,511185245,-0.015588056225584776
Comparative and Web-Enabled Virtual Screening No abstract available n/a,Comparative and Web-Enabled Virtual Screening,7472716,P20HG003900,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'comparative', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project', 'virtual', 'web-enabled']",NHGRI,NORTH CAROLINA STATE UNIVERSITY RALEIGH,P20,2007,363833,32532200,-0.03297847964678437
The RPI Exploratory Center for Cheminformatics (RMI) No abstract available n/a,The RPI Exploratory Center for Cheminformatics (RMI),7472067,P20HG003899,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,RENSSELAER POLYTECHNIC INSTITUTE,P20,2007,364010,12471676,0.006077510747772253
Carolina Exploratory Center for Cheminformatics Research No abstract available n/a,Carolina Exploratory Center for Cheminformatics Research,7472715,P20HG003898,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,P20,2007,373960,511185245,0.006077510747772253
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7284239,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2007,588968,570146095,0.008071639465398402
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,7287568,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2006,38558,0,-0.01626455020978512
"Longitudinal Psychometric Investigation of the WISDM Tobacco Dependence Measure    DESCRIPTION (provided by applicant): Description: The construct of nicotine dependence (ND) is assumed to underlie tobacco addiction but there is a notable lack of consensus about the nature and optimal measurement of ND. In applied research, ND is often assumed to be a dimensional, trait-like condition with varying degrees of severity although some studies use categorical or discrete diagnostic conceptualizations of ND as found in the DSM-IV diagnosis of Nicotine Dependence. There is increasing evidence that ND is multidimensional. Only recently have psychometrically sound, theoretically-based, multidimensional measures of ND been developed, such as the Wisconsin Inventory of Smoking Dependence Motives (WISDM). The WISDM measures thirteen smoking dependence motives that are hypothesized to influence dependence processes such as inability to quit, nicotine withdrawal, and relapse. The WISDM subscales reflect a variety of theory-based internal factors (e.g., tolerance) and external factors (e.g., social and environmental goads to smoke) that permit investigation of different smoking motives in clinical and experimental contexts. The primary aim of this study is to investigate the nature of ND by assessing measurement and structural invariance across gender and racial/ethnic groups and time as well as investigating the predictive, concurrent, convergent, and discriminant validity of WISDM subscales. This will be accomplished by conducting a series of secondary analyses on datasets from two observational studies and two smoking cessation clinical trials that administered the WISDM to culturally diverse smokers (White, African American, and Hispanic). Latent variable (e.g., multigroup confirmatory factor analyses) and other models will test for invariance of key model parameters (e.g., factor covariances) across gender and racial/ethnic groups as a means of evaluating similarity of multidimensional models across the groups. Validity analyses will include multivariate linear and logistic regression models as well as latent variable modeling that will allow complex tests of individual WISDM dimensions or sets of dimensions in relation to smoking and relapse. Observed measures such as cigarettes smoked per day, latency between first cigarette and regular use of cigarettes, and end-of- treatment cessation success will be related to WISDM measures in these validity analyses. The goal of all of these analyses is to characterize dimensions that represent core features of ND that influence smoking behavior as well as cessation and relapse. Lay Description: This study will investigate how various theoretical dimensions of nicotine dependence, as measured by the 13-factor Wisconsin Inventory of Smoking Dependence Motives, relate to one another and to important smoking- and cessation-related outcomes and whether these relations are consistent across gender and racial/ethnic groups.           n/a",Longitudinal Psychometric Investigation of the WISDM Tobacco Dependence Measure,7226812,R03CA126406,"['clinical research', 'ethnic group', 'measurement', 'model', 'nicotine', 'psychometrics', 'sex', 'smoking', 'smoking cessation', 'tobacco']",NCI,UNIVERSITY OF WISCONSIN MADISON,R03,2006,76953,0,-0.004656944858852568
"Utility of Trans Telephonic Monitoring in the Detection of Silent Arrhythmias    DESCRIPTION (provided by applicant): The primary aim of this feasibility study is to determine if a Cardiac Arrhythmia Trans telephonic EKG monitoring system (CAT) can be used to detect asymptomatic or ""silent"" arrhythmias in patients greater than or equal to 65 years of age with a history of hypertension (HTN) and heart failure (HF) and characterize their onset, frequency, and duration. The secondary aim is to examine the association between silent arrhythmias and quality of life (QoL). Atrial fibrillation (AF) is the most common arrhythmia and its prevalence increases with age, HTN, and HF. It also has a profound impact on QoL. Whether silent or symptomatic, AF can result in stroke. Detection of silent arrhythmias, especially silent AF, could prompt the initiation of anticoagulation that would decrease the occurrence of stroke, which is the third leading cause of death in the US. As treatment for HTN and HF continue to improve, combined with increased life expectancy, early arrhythmia identification strategies are urgently needed to predict who is at the highest risk for silent arrhythmias. Standard methods for detecting AF include 12-lead EKGs, 24-hour Holter recorders (HM) and non-auto-triggered memory loop recorders (MLR). MLRs are unable to automatically detect and capture silent arrhythmias since they require patient activation during symptoms. Auto-triggered MLRs (AT-MLR) have recently become available which automatically record arrhythmias, with or without associated symptoms, and the stored EKG data can then be transmitted trans telephonically (via phone) to a central monitoring station. A recently completed retrospective analysis has shown that AT-MLRs produced a higher yield of diagnostic events and an earlier time to diagnosis of silent arrhythmias as compared to HM or MLR. This study proposes a single-center, prospective consecutive series of 100 patients using a 14-day CAT monitoring period. At baseline and 6 months, cardiac clinical characteristics and risk factors will be collected from patients via physical exam and chart review, and the SF-36v2(TM) will be administered to determine if differences exist in perceived QoL in patients with silent AF. Information regarding AF frequency and duration will be quantified using the University of Toronto Atrial Fibrillation Scale (AFSS). Spearman's correlation will be used to assess the association between AF and changes in SF-36v2(TM) QoL scores between baseline and 6 months. The relationship between AF, demographic, and clinical characteristics will be determined using logistic regression analysis. All significant univariate variables will be entered into a multivariate logistic regression model. The results of this feasibility study could potentially justify development of a new screening mechanism for silent AF. If this study proves successful, a larger trial will be proposed to explore specific clinical variables, EKG characteristics, and treatment strategies to improve clinical care and QoL.           n/a",Utility of Trans Telephonic Monitoring in the Detection of Silent Arrhythmias,7132412,R03NR010001,"['arrhythmia', 'clinical research']",NINR,COLUMBIA UNIVERSITY HEALTH SCIENCES,R03,2006,80500,558628098,-0.06100433235751802
"Detection of chewing and swallowing to estimate eating patterns and energy intake DESCRIPTION (provided by applicant):    The prevalence of obesity in developed countries is increasing at an alarming rate. Obesity contributes to an increased risk of heart disease, hypertension, diabetes, and some cancers and is now considered a risk factor for cardiovascular disease. The objective of this research is to investigate application of novel noninvasive devices and pattern recognition methods to perform studies of human food intake behavior and produce objective estimates of volumetric and caloric food intake that will be relevant for identifying effective measures to treat or prevent diseases like obesity. Such devices and methods could extend our understanding of causes of obesity, and the monitoring devices created in this study could be used for monitoring of obese patients and as a part of a therapy potentially improve quality of life and decrease the morbidity and mortality associated with obesity. The goal of this study is to design and perform a pilot investigation which will provide preliminary data that objective observations of mastication (chewing) and deglutition (swallowing) by a wearable, non-intrusive monitoring device can provide statistically reliable estimates of eating habits by providing objective measures of delution frequency, duration of mastication and identifying periods of food intake with sufficient sensitivity and specificity.  The aims of the proposed research include design of the wearable sensors and associated signal processing methods; development of pattern recognition methodologies that will automatically detect instances of delution and mastication from sensor recordings; development of pattern recognition methods to automatically identify periods of food intake based on detected chewing and swallowing; and to validate these device and methodologies on a group of human subjects. Modern methods of computational intelligence such as artificial neural networks and fuzzy logic will be used along with statistical methods to achieve the highest 'accuracy of pattern recognition. n/a",Detection of chewing and swallowing to estimate eating patterns and energy intake,7140644,R21HL083052,"['artificial intelligence', 'behavior test', 'bioenergetics', 'bioengineering /biomedical engineering', 'biomedical automation', 'biomedical equipment development', 'biosensor device', 'biotechnology', 'caloric dietary content', 'calorimetry', 'clinical biomedical equipment', 'clinical research', 'computer program /software', 'disease /disorder prevention /control', 'human morbidity', 'human subject', 'mastication', 'noninvasive diagnosis', 'nutrient intake activity', 'nutrition related tag', 'obesity', 'portable biomedical equipment', 'quality of life', 'statistics /biometry', 'swallowing']",NHLBI,CLARKSON UNIVERSITY,R21,2006,182119,0,0.010005187852688507
"Least Angle Regression    DESCRIPTION (provided by applicant): This SBIR project aims to produce superior methods and software for classification and regression when there are many potential predictor variables to choose from. The methods should (1) produce stable results, where small changes in the data do not produce major changes in the variables selected or in model predictions; (2) produce accurate predictions; (3) facilitate scientific interpretation, by selecting a smaller subset of predictors which provide the best predictions; (4) allow continuous and categorical variables; and (5) support linear regression, logistic regression (predicting a binary outcome), survival analysis, and other types of regression. This project is based on least angle regression, which unifies and provides a fast implementation for a number of modern regression techniques. Least angle regression has great potential, but currently available software is limited in scope and robustness. The outcome of this project should be software which is more robust and widely applicable. This software would apply broadly, including to medical diagnosis, detecting cancer, feature selection in microarrays, and modeling patient characteristics like blood pressure. Phase I work demonstrates feasibility by extending least angle work in three key directions-categorical predictors, logistic regression, and a numerically-accurate implementation. Phase II goals include extensions to other types of explanatory variables (e.g. polynomial or spline functions, and interactions between variables), to survival and other additional regression models, and to handle missing data and massive data sets. This proposed software will enable medical researchers to obtain high prediction accuracy, and obtain stable and interpretable results, in high-dimensional situations. Predicting outcomes based on covariates, determining which covariates most affect outcomes, and adjusting treatment effects estimates for covariates, are among the most important problems in biostatistics. Prediction and feature selection are particularly difficult when there are more possible features than samples; gene microarrays and protein mass spectrometry are extreme examples of this, producing thousands to millions of measurements per sample. LARS excels at feature selection; the proposed software should enable medical researchers to obtain stable and interpretable models with better prediction accuracy in high-dimensional situations.             n/a",Least Angle Regression,7219604,R44GM074313,"['computer human interaction', 'computer program /software', 'data management', 'handbook', 'mathematical model', 'mathematics', 'method development', 'microarray technology', 'model design /development', 'statistics /biometry']",NIGMS,INSIGHTFUL CORPORATION,R44,2006,374846,0,-0.002294021863055454
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7125135,R42ES013321,"['artificial intelligence', 'chemical structure function', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug discovery /isolation', 'drug screening /evaluation', 'functional /structural genomics', 'hepatotoxin', 'microarray technology', 'toxicant screening']",NIEHS,"YAHSGS, LLC",R42,2006,387181,0,-0.01719272887686888
"Environmental Risk Factors and Canine Malignant Lymphoma DESCRIPTION (provided by applicant):    The incidence of human non-Hodgkin's lymphoma (NHL) in the US has nearly doubled over the previous 30 years. Epidemiologic research has evaluated a variety of factors potentially associated with risk of NHL but results have been inconsistent and cannot explain the dramatic increase in incidence. Several epidemiologic studies in humans have suggested that exposure to household environmental tobacco smoke (ETS), lawn care herbicides, and pesticides such as those contained in flea control products may plausibly increase risk of NHL, but these relationships have not been well evaluated. Epidemiologic studies of companion animals offer a complementary means by which to identify risk factors for cancers of relevance to both animals and humans. Because canine malignant lymphoma (CML) has been established as a model for NHL and domestic dogs share their living environment with their human owners, a study of environmental exposures and CML provides a unique opportunity to evaluate factors that may potentially relate to NHL. The proposed case-control study will use hospital records to identify cases of CML and 2 control groups of dogs, one consisting of dogs with benign tumors and one consisting of dog with non-cancer chronic diseases, seen at the Foster Hospital at Tufts University between 2000 and 2005. Owners of CML cases and controls will be sent a questionnaire to assess household ETS, use of flea control products, lawn care herbicides and other factors prior to diagnosis. Multivariate logistic regression will then be used to evaluate the relationship between environmental exposures and risk of CML. In addition, because the methods used in epidemiologic studies of companion animals are not well established, the proposed project will also include a validation study of ETS exposure measurement, and evaluate if owner characteristics are associated with likelihood of returning a mailed questionnaire. Owners of 1000 dogs presenting to Foster Hospital over a two-month period will be asked to complete a questionnaire measuring demographic and environmental factors, and to provide a urine sample from their dog. Urine samples from approximately 130 dogs will be assayed for level of cotinine, a metabolite of nicotine well established as a biologic marker for ETS exposure, and cotinine levels will be compared with level of household smoking reported by questionnaire. One year later, a second questionnaire will be mailed to all participants, and characteristics of respondent and non-respondent owners will be compared. Any differences will then be taken into consideration in the calculation of relative risks using a novel form of sensitivity analysis to produce more accurate estimates of the association between environmental exposures and risk of CML. Because dogs and their human owners share a common environment within the household, results from this study will have direct relevance to the on-going effort to identify factors that may increase risk of human NHL. n/a",Environmental Risk Factors and Canine Malignant Lymphoma,6931858,R03CA103513,"['cancer risk', 'clinical research', 'disease /disorder model', 'disease /disorder proneness /risk', 'dogs', 'environmental exposure', 'herbicides', 'human subject', 'lymphoma', 'neoplasm /cancer epidemiology', 'nicotine', 'nonHodgkin&apos', 's lymphoma', 'passive smoking', 'pesticide biological effect', 'pesticide residues', 'pesticides', 'questionnaires', 'veterinary medicine']",NCI,UNIVERSITY OF MASSACHUSETTS AMHERST,R03,2005,76639,35034877,-0.008855215606235681
"Least Angle Regression DESCRIPTION (provided by applicant): This SBIR project aims to produce superior methods and software for classification and regression when there are many potential predictor variables to choose from. The methods should (1) produce stable results, where small changes in the data do to produce major changes in the variables selected or in model predictions, (2) produce accurate predictions, (3) facilitate scientific interpretation, by selecting a smaller subset of predictors which provide the best predictions, (4) allow continuous and categorical variables, and (5) support linear regression, logistic regression (predicting a binary outcome), survival analysis, and other types of regression. This project is based on least angle regression, which unifies and provides a fast implementation for a number of modern regression techniques. Least angle regression has great potential, but the state of the art is limited to linear regression with continuous or binary variables, and uses numerically-unstable calculations. The outcome of this project should be software which is more robust and widely applicable. This software would apply broadly, including to medical diagnosis, detecting cancer, feature selection in microarrays, and modeling patient characteristics like blood pressure.  Phase I work will demonstrate feasibility by extending least angle work in three key directions-categorical predictors, logistic regression, and a numerically-accurate implementation. Phase II will extend the work to other types of explanatory variables (e.g. polynomial or spline functions, and interactions between variables), and to survival and other additional regression models. This proposed software will enable medical researchers to obtain high prediction accuracy, and obtain stable and interpretable results, in high-dimensional situations. n/a",Least Angle Regression,6933500,R43GM074313,"['clinical research', 'computational biology', 'computer graphics /printing', 'computer human interaction', 'computer program /software', 'data collection methodology /evaluation', 'data quality /integrity', 'human data', 'mathematical model', 'model design /development', 'statistics /biometry', 'technology /technique development']",NIGMS,INSIGHTFUL CORPORATION,R43,2005,99685,0,-0.0017160387083692984
"Perception and Inter-Observer Variability in Mammography DESCRIPTION (provided by applicant):    Inter-observer variability in mammogram reading has been well documented in the literature. Various factors have been used to explain this variability; among them, the most significant are related to the management of perceived findings.  However, the nature of this inter-observer variability has not been explored. Namely, were the lesions that were consistently reported by the radiologists any different from the ones that yield disagreement? Furthermore, could these differences be quantitatively assessed? Moreover, were these differences in any way related with the experience level of the observer? In addition, the interpretation of perceived findings is closely related with the visual search strategy used to scan the breast tissue, because observers compare perceived findings with the background, in order to determine their uniqueness. Hence, what is the effect of visual search strategy on inter-observer variability? Can this effect be modeled using Artificial Neural Networks (ANNs)? Can inferences be made regarding the observers' decision patterns by analyzing the results of simulations run on the ANNs?  The work described here aims at answering these questions. We will use spatial frequency analysis to characterize the areas on mammogram cases where mammographers, chest radiologists with experience reading mammograms and radiology residents at the end of their mammography rotation, indicate the presence of a finding, or fail to do so. We will assess inter-observer agreement, as well as intra- and inter-group agreement for the various groups of observers. In addition, we will train artificial neural networks to represent each observer, in such a way that by changing the nature of the features input to the ANNs we will be able to simulate how such changes would have affected the actual observer. We will assess the effects on inter-observer variability of changing the search strategy used by the observer to sample the breast tissue. In our setting, the inter-observer variability will be assessed by comparing the outputs of the ANNs that represent each observer. In addition, the changes in sampling strategy will correspond to actual possible strategies for the human observers themselves. n/a",Perception and Inter-Observer Variability in Mammography,6924688,R21CA100107,"['artificial intelligence', 'bioimaging /biomedical imaging', 'breast neoplasm /cancer diagnosis', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'human data', 'human therapy evaluation', 'mammography', 'visual perception']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2005,167063,570146095,-0.042719422683645675
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7052491,R42ES013321,"['artificial intelligence', 'chemical structure function', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug discovery /isolation', 'drug screening /evaluation', 'functional /structural genomics', 'hepatotoxin', 'microarray technology', 'toxicant screening']",NIEHS,"YAHSGS, LLC",R42,2005,180862,0,-0.01719272887686888
"Detection of chewing and swallowing to estimate eating patterns and energy intake DESCRIPTION (provided by applicant):    The prevalence of obesity in developed countries is increasing at an alarming rate. Obesity contributes to an increased risk of heart disease, hypertension, diabetes, and some cancers and is now considered a risk factor for cardiovascular disease. The objective of this research is to investigate application of novel noninvasive devices and pattern recognition methods to perform studies of human food intake behavior and produce objective estimates of volumetric and caloric food intake that will be relevant for identifying effective measures to treat or prevent diseases like obesity. Such devices and methods could extend our understanding of causes of obesity, and the monitoring devices created in this study could be used for monitoring of obese patients and as a part of a therapy potentially improve quality of life and decrease the morbidity and mortality associated with obesity. The goal of this study is to design and perform a pilot investigation which will provide preliminary data that objective observations of mastication (chewing) and deglutition (swallowing) by a wearable, non-intrusive monitoring device can provide statistically reliable estimates of eating habits by providing objective measures of delution frequency, duration of mastication and identifying periods of food intake with sufficient sensitivity and specificity.  The aims of the proposed research include design of the wearable sensors and associated signal processing methods; development of pattern recognition methodologies that will automatically detect instances of delution and mastication from sensor recordings; development of pattern recognition methods to automatically identify periods of food intake based on detected chewing and swallowing; and to validate these device and methodologies on a group of human subjects. Modern methods of computational intelligence such as artificial neural networks and fuzzy logic will be used along with statistical methods to achieve the highest 'accuracy of pattern recognition. n/a",Detection of chewing and swallowing to estimate eating patterns and energy intake,7022662,R21HL083052,"['artificial intelligence', 'behavior test', 'bioenergetics', 'bioengineering /biomedical engineering', 'biomedical automation', 'biomedical equipment development', 'biosensor device', 'biotechnology', 'caloric dietary content', 'calorimetry', 'clinical biomedical equipment', 'clinical research', 'computer program /software', 'disease /disorder prevention /control', 'human morbidity', 'human subject', 'mastication', 'noninvasive diagnosis', 'nutrient intake activity', 'nutrition related tag', 'obesity', 'portable biomedical equipment', 'quality of life', 'statistics /biometry', 'swallowing']",NHLBI,CLARKSON UNIVERSITY,R21,2005,217756,0,0.010005187852688507
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6910621,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2005,245768,0,-0.01626455020978512
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6850134,R01AR042739,"['artificial intelligence', 'bone density', 'bone fracture', 'clinical research', 'computer assisted diagnosis', 'densitometry', 'diagnosis design /evaluation', 'disease /disorder proneness /risk', 'hip', 'human subject', 'information systems', 'limbs', 'mathematical model', 'noninvasive diagnosis', 'osteoporosis', 'photon absorptiometry', 'radiography', 'spine', 'women&apos', 's health']",NIAMS,UNIVERSITY OF CHICAGO,R01,2005,297104,246330700,0.0014688858959332844
"Environmental Risk Factors and Canine Malignant Lymphoma DESCRIPTION (provided by applicant):    The incidence of human non-Hodgkin's lymphoma (NHL) in the US has nearly doubled over the previous 30 years. Epidemiologic research has evaluated a variety of factors potentially associated with risk of NHL but results have been inconsistent and cannot explain the dramatic increase in incidence. Several epidemiologic studies in humans have suggested that exposure to household environmental tobacco smoke (ETS), lawn care herbicides, and pesticides such as those contained in flea control products may plausibly increase risk of NHL, but these relationships have not been well evaluated. Epidemiologic studies of companion animals offer a complementary means by which to identify risk factors for cancers of relevance to both animals and humans. Because canine malignant lymphoma (CML) has been established as a model for NHL and domestic dogs share their living environment with their human owners, a study of environmental exposures and CML provides a unique opportunity to evaluate factors that may potentially relate to NHL. The proposed case-control study will use hospital records to identify cases of CML and 2 control groups of dogs, one consisting of dogs with benign tumors and one consisting of dog with non-cancer chronic diseases, seen at the Foster Hospital at Tufts University between 2000 and 2005. Owners of CML cases and controls will be sent a questionnaire to assess household ETS, use of flea control products, lawn care herbicides and other factors prior to diagnosis. Multivariate logistic regression will then be used to evaluate the relationship between environmental exposures and risk of CML. In addition, because the methods used in epidemiologic studies of companion animals are not well established, the proposed project will also include a validation study of ETS exposure measurement, and evaluate if owner characteristics are associated with likelihood of returning a mailed questionnaire. Owners of 1000 dogs presenting to Foster Hospital over a two-month period will be asked to complete a questionnaire measuring demographic and environmental factors, and to provide a urine sample from their dog. Urine samples from approximately 130 dogs will be assayed for level of cotinine, a metabolite of nicotine well established as a biologic marker for ETS exposure, and cotinine levels will be compared with level of household smoking reported by questionnaire. One year later, a second questionnaire will be mailed to all participants, and characteristics of respondent and non-respondent owners will be compared. Any differences will then be taken into consideration in the calculation of relative risks using a novel form of sensitivity analysis to produce more accurate estimates of the association between environmental exposures and risk of CML. Because dogs and their human owners share a common environment within the household, results from this study will have direct relevance to the on-going effort to identify factors that may increase risk of human NHL. n/a",Environmental Risk Factors and Canine Malignant Lymphoma,6795262,R03CA103513,"['cancer risk', 'clinical research', 'disease /disorder model', 'disease /disorder proneness /risk', 'dogs', 'environmental exposure', 'herbicides', 'human subject', 'lymphoma', 'neoplasm /cancer epidemiology', 'nicotine', 'nonHodgkin&apos', 's lymphoma', 'passive smoking', 'pesticide biological effect', 'pesticide residues', 'pesticides', 'questionnaires', 'veterinary medicine']",NCI,UNIVERSITY OF MASSACHUSETTS AMHERST,R03,2004,76639,35034877,-0.008855215606235681
"Tree Ensemble Regression and Classification Methods    DESCRIPTION (provided by applicant):    This SBIR aims to produce next generation classification and regression software based upon ensembles of decision trees: bagging, random forests, and boosting. The prediction accuracy of these methods has caused much excitement in the machine learning community, and both challenges and complements the data modeling culture prevalent among biostatisticians. Recent research extends the methodology to likelihood based methods used in biostatistics, leading to models for survival data and generalized forest models. Generalized forest models extend regression forests in the same way that generalized linear models extend linear models.      This software would apply broadly, including to medical diagnosis, prognostic modeling, and detecting cancer; and for modeling patient characteristics like blood pressure, discrete responses in clinical trials, and count data.      Phase I work will prototype software for survival data, and investigate the performance of ensemble methods on simulated and real data. For survival applications, we will assess out-of-bag estimates of performance, and investigate measures of variable importance and graphics that help clinicians understand the results. Experience writing prototypes and using them on data will lead to a preliminary software design that serves as the foundation of Phase II work.      Phase II will expand upon this work to create commercial software. We will research and implement algorithms for a wider range of applications including generalized forest models, classification, and least squares regression. We will also implement robust loss criteria that enable good performance on noisy data, and make adaptations to handle large data sets.      This proposed software will enable medical researchers to obtain high prediction accuracy, and complement traditional tools like discriminant analysis, linear and logistic regression models, and the Cox model.         n/a",Tree Ensemble Regression and Classification Methods,6832086,R43CA105724,"['clinical research', 'computer assisted medical decision making', 'computer graphics /printing', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'human data', 'mathematical model', 'method development', 'model design /development', 'neoplasm /cancer classification /staging', 'neoplasm /cancer diagnosis', 'neoplasm /cancer remission /regression', 'prognosis', 'statistics /biometry']",NCI,INSIGHTFUL CORPORATION,R43,2004,99937,0,-7.425214890176503e-05
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6849505,R01AR042739,"['artificial intelligence', 'bone density', 'bone fracture', 'clinical research', 'computer assisted diagnosis', 'densitometry', 'diagnosis design /evaluation', 'disease /disorder proneness /risk', 'hip', 'human subject', 'information systems', 'limbs', 'mathematical model', 'noninvasive diagnosis', 'osteoporosis', 'photon absorptiometry', 'radiography', 'spine', 'women&apos', 's health']",NIAMS,UNIVERSITY OF CHICAGO,R01,2004,105415,246330700,0.0014688858959332844
"Perception and Inter-Observer Variability in Mammography DESCRIPTION (provided by applicant):    Inter-observer variability in mammogram reading has been well documented in the literature. Various factors have been used to explain this variability; among them, the most significant are related to the management of perceived findings.  However, the nature of this inter-observer variability has not been explored. Namely, were the lesions that were consistently reported by the radiologists any different from the ones that yield disagreement? Furthermore, could these differences be quantitatively assessed? Moreover, were these differences in any way related with the experience level of the observer? In addition, the interpretation of perceived findings is closely related with the visual search strategy used to scan the breast tissue, because observers compare perceived findings with the background, in order to determine their uniqueness. Hence, what is the effect of visual search strategy on inter-observer variability? Can this effect be modeled using Artificial Neural Networks (ANNs)? Can inferences be made regarding the observers' decision patterns by analyzing the results of simulations run on the ANNs?  The work described here aims at answering these questions. We will use spatial frequency analysis to characterize the areas on mammogram cases where mammographers, chest radiologists with experience reading mammograms and radiology residents at the end of their mammography rotation, indicate the presence of a finding, or fail to do so. We will assess inter-observer agreement, as well as intra- and inter-group agreement for the various groups of observers. In addition, we will train artificial neural networks to represent each observer, in such a way that by changing the nature of the features input to the ANNs we will be able to simulate how such changes would have affected the actual observer. We will assess the effects on inter-observer variability of changing the search strategy used by the observer to sample the breast tissue. In our setting, the inter-observer variability will be assessed by comparing the outputs of the ANNs that represent each observer. In addition, the changes in sampling strategy will correspond to actual possible strategies for the human observers themselves. n/a",Perception and Inter-Observer Variability in Mammography,6821032,R21CA100107,"['artificial intelligence', 'bioimaging /biomedical imaging', 'breast neoplasm /cancer diagnosis', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'human data', 'human therapy evaluation', 'mammography', 'visual perception']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2004,153968,570146095,-0.042719422683645675
"Use of Microarray Test Data for Toxicogenomic Prediction    DESCRIPTION (provided by applicant):    This project bridges the understanding between physical and chemical principles and genomic/proteomic response by integrating three independent parallel toxicity prediction tools. Each uses computational neural networks (CNNs) and wavelets to rapidly and accurately make pharmaceutical/chemical toxicity predictions. A CNN-based Quantitative Structure-Activity Relationship (QSAR) module makes toxicological predictions based only on structure-activity analyses; a second CNN/wavelet module makes independent toxicogenomic predictions using microarray data; and a third CNN/wavelet module makes toxicogenomic predictions using Massively Parallel Signature Sequencing (MPSS) data. This multi-intelligent, three-module approach provides crosschecks to reduce false positives and false negatives while substantially increasing confidence in predictions relative to current computer-based toxicity prediction techniques. The resulting product could potentially become a primary tool used by (a) human health researchers, b) pharmaceutical companies for screening drugs early during development, c) companies designing/developing new chemicals and chemically treated materials, and (d) government organizations (e.g., military) for mission-related chemical deployments. Public benefits include reduced health and environmental risks (e.g., 4 out of 5 chemicals in use today have inadequate testing); reduced reliance on animal testing; and reduced time and cost required to bring new pharmaceuticals and chemicals into beneficial medical and commercial use.            n/a",Use of Microarray Test Data for Toxicogenomic Prediction,6743871,R41ES013321,"['computational neuroscience', 'computer data analysis', 'evaluation /testing', 'method development', 'microarray technology', 'polymerase chain reaction', 'toxicant screening', 'toxicology']",NIEHS,"YAHSGS, LLC",R41,2004,211770,0,-0.016011953574426432
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6774688,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2004,242058,0,-0.01626455020978512
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6701378,R01AR042739,"['artificial intelligence', 'bone density', 'bone fracture', 'clinical research', 'computer assisted diagnosis', 'densitometry', 'diagnosis design /evaluation', 'disease /disorder proneness /risk', 'hip', 'human subject', 'information systems', 'limbs', 'mathematical model', 'noninvasive diagnosis', 'osteoporosis', 'photon absorptiometry', 'radiography', 'spine', 'women&apos', 's health']",NIAMS,UNIVERSITY OF CHICAGO,R01,2004,297104,246330700,0.0014688858959332844
"Development of Ultrasonic Appratus for Dental Diagnosis DESCRIPTION: An ultrasonic diagnostic apparatus has been proposed for Dental applications in determining tooth pathologies such as demineralization/caries, hidden fractures, and formation of abscesses. The equipment adopts a piezoelectric and laser optic hybrid transduction system for interrogation of teeth. Ultrasonic responses of the tooth structure will be analyzed by a pattern recognition expert system (artificial intelligence) to determine the diagnosis of the tooth inspected. The proposed research will eventually help to reduce the use of harmful X-ray radiation in Dental clinics and contribute to artificial intelligence based diagnosis. The proposed concept has been successfully demonstrated in the previous Phase I study. In this Phase II study, instrumentation for clinical data collection using a combination of conventional piezoelectric and new laser-based ultrasonic technologies will be developed and optimized; an artificial intelligence based diagnostic function will be developed using clinical data and implemented using embedded computing; numerical simulations will be used to enhance diagnostic function development; and finally, initial clinical trials will be conducted to demonstrate the performance of the prototype equipment. The ultrasonic apparatus for Dental diagnosis outlined in this application is a first application of AI-based NDE in Dentistry. The research concept may also extend to periodontal and craniofacial applications. n/a",Development of Ultrasonic Appratus for Dental Diagnosis,6777482,R44DE014270,"['artificial intelligence', 'biomedical equipment development', 'clinical research', 'clinical trials', 'dental disorder diagnosis', 'dental structure', 'dentistry', 'diagnosis design /evaluation', 'human subject', 'patient oriented research', 'tooth', 'tooth surface']",NIDCR,AAC INTERNATIONAL,R44,2004,367866,0,-0.004389830083823959
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6702676,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2003,205127,246330700,0.0014688858959332844
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6617187,R01EY014162,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' diagnosis design /evaluation', ' eye disorder diagnosis', ' eye refractometry', ' human data', ' image processing', ' ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2003,241570,0,-0.01626455020978512
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6628097,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2003,297104,246330700,0.0014688858959332844
"Development of Ultrasonic Appratus for Dental Diagnosis DESCRIPTION: An ultrasonic diagnostic apparatus has been proposed for Dental applications in determining tooth pathologies such as demineralization/caries, hidden fractures, and formation of abscesses. The equipment adopts a piezoelectric and laser optic hybrid transduction system for interrogation of teeth. Ultrasonic responses of the tooth structure will be analyzed by a pattern recognition expert system (artificial intelligence) to determine the diagnosis of the tooth inspected. The proposed research will eventually help to reduce the use of harmful X-ray radiation in Dental clinics and contribute to artificial intelligence based diagnosis. The proposed concept has been successfully demonstrated in the previous Phase I study. In this Phase II study, instrumentation for clinical data collection using a combination of conventional piezoelectric and new laser-based ultrasonic technologies will be developed and optimized; an artificial intelligence based diagnostic function will be developed using clinical data and implemented using embedded computing; numerical simulations will be used to enhance diagnostic function development; and finally, initial clinical trials will be conducted to demonstrate the performance of the prototype equipment. The ultrasonic apparatus for Dental diagnosis outlined in this application is a first application of AI-based NDE in Dentistry. The research concept may also extend to periodontal and craniofacial applications. n/a",Development of Ultrasonic Appratus for Dental Diagnosis,6691772,R44DE014270,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' clinical trials', ' dental disorder diagnosis', ' dental structure', ' dentistry', ' diagnosis design /evaluation', ' human subject', ' patient oriented research', ' tooth', ' tooth surface']",NIDCR,AAC INTERNATIONAL,R44,2003,382129,0,-0.004389830083823959
"KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY  The proposed work extends previous research performed by this                                                                     investigator in the field of knowledge-based systems for the analysis of             histopathologic material, mainly neoplastic tissue; and mostly focusing on           adenocarcinoma of the prostate. The present application concerns the creation        of methods for the definition and analysis of novel histopathologic features         predominantly derived from nuclear image data, with the objective of defining        ""prototype identities."" According to the investigator, these are fundamental         complexes of histologic features unique to individual tissue samples, or small       groups of such samples, that should convey useful predictive value for               individual patients. Many of these features are not normally discernable to the      eye, even to the experienced observer. They encompass a large number of primary      and derived nuclear morphometric measures, including what are referred to as         ""weak features,"" that is those that have not in the past shown strong                correlative utility by standard statistical measures. Derived measures include       feature and heterogeneity profiles. These data will form the inputs to a logic       network (""inference network"") designed to perform an identification process and      ultimately to generate the prototype identities.                                                                                                                          n/a",KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6626641,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' human tissue', ' hyperplasia', ' image processing', ' information system analysis', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2003,482862,161094826,-0.026256450790101363
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6558149,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2002,10000,246330700,0.0014688858959332844
"Automated PCR Pathogen Detection and Quantification  DESCRIPTION (provided by applicant):  We will develop software for automated pathogen detection and quantification using data from PCR experiments. Automated pathogen detection using data from a PCR experiment requires software to determine whether DNA from the pathogen is present or absent in a sample. We will develop a pattern-matching algorithm to mathematically analyze PCR amplification data. We will optimize the algorithm against a data set of at least 5000 PCR reactions (including a significant set of data gathered during the anthrax attack) to determine its efficacy and limitations. We expect the pathogen detection algorithms to distinguish positives samples from negative samples in more than 98% of the samples, to find inconclusive results in less than 1% of the samples, and to incorrectly classify less than 1% of the samples. We will also develop software to perform automated melting curve analysis of samples that our detection algorithm has determined to be positive or inconclusive. The melting profile of the probes is a property of the assay, and it can be used for secondary confirmation of a pathogen by comparing the profile of the unknown samples to the profile of the assay's positive controls. We will develop algorithms to automatically determine whether the melting profile of the sample and controls match. With melting analysis confirmation, the failure rate of the final detection algorithm should be less than 0.5%.   Automated pathogen quantification requires software to determine the number of copies of a pathogen's DNA in a sample. We will develop discrete dynamical models of PCR for quantification. We will optimize these methods against a large data set of PCR reactions with dilution series. We will systematically determine the features of the models that provide information and the features that can be ignored. We will measure efficacy by comparing computed DNA copy numbers against the known concentrations (as specified by experimenters), and against each other. We will use the most effective model (or models) in the software we produce.   n/a",Automated PCR Pathogen Detection and Quantification,6555484,R43AI052944,"['artificial intelligence', ' bioterrorism /chemical warfare', ' communicable disease diagnosis', ' computer program /software', ' computer system design /evaluation', ' microorganism', ' nucleic acid denaturation', ' nucleic acid quantitation /detection', ' phase change', ' polymerase chain reaction']",NIAID,IDAHO TECHNOLOGY,R43,2002,100000,0,-0.013739946911372442
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6497411,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2002,297104,246330700,0.0014688858959332844
"THE EFFECTS OF RETAINED LEAD BULLETS ON BODY LEAD BURDEN Numerous case reports have demonstrated lead poisoning with potentially fatal consequences can result from retained lead projectiles following firearm injuries.  To assess the impact of retained projectiles on subsequent lead exposure, one cannot rely on self-selected cases presenting with symptoms of lead intoxication.  The long-term goal of this project is to reduce the morbidity associated with body lead burden as a result of retained bullets from firearm injuries.  The proposed investigation seeks to identify risk factors of elevated blood lead levels for individuals with retained lead bullets, establish appropriate protocols for lead testing, develop indications for bullet removal and provide guidelines for the appropriate management of fragments not removed. The study design included follow-up of 300 patients with retained lead bullets/bullet fragments presenting for acute care of firearm injury at large publicly owned Level 1 Trauma Center.  A baseline blood level is measured as soon after patient stabilization as possible and repeated at intervals of 3, 6 and 12 months.  Medical history regarding prior firearms injuries and other retained projectiles is taken, along with a screening and risk factor questionnaire to determine other sources of lead (occupational/recreational) to which the patient might have been or at present be exposed.  The patient will have K- shell X ray florescence determination of bone lead in the tibia and calcaneus in order to determine past lead exposure not revealed by medical history and risk factor questionnairer.  Multivariate models of blood level are made for each patient visit using risk factor and bone lead concentration data.  Determinations will be made if changes in blood lead, adjusted for risk factors and bone lead concentration, from one 3 month period to the next can be significantly predicted by the coded location and fragmentation data of projectiles and presence or absence of fractures.  The variables of location, fragmentation, fracture and total time during which the projectile was retained in the body will be tested using logistic regression.  This will determine odds ratios of elevated lead at various concentrations (greater than 15 mug/dL, greater than 25  mug/dL, greater than 40 mug/dL, etc.) due to these factors.  Data will also be analyzed in the framework of the general linear model (GML), with a repeated measure design.  Principal interest will be in increasing trend of blood level as a function of fragmentation location, fracture and duration variables.  n/a",THE EFFECTS OF RETAINED LEAD BULLETS ON BODY LEAD BURDEN,6525222,R01ES010166,"['X ray', ' blood chemistry', ' clinical research', ' environmental exposure', ' foreign body reaction', ' human morbidity', ' human subject', ' injury', ' lead', ' lead poisoning', ' longitudinal human study', ' outcomes research', ' questionnaires', ' radiofluorescent probe', ' statistics /biometry']",NIEHS,CHARLES R. DREW UNIVERSITY OF MED & SCI,R01,2002,377463,7479461,-4.783142587571971e-05
"KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY  The proposed work extends previous research performed by this                                                                     investigator in the field of knowledge-based systems for the analysis of             histopathologic material, mainly neoplastic tissue; and mostly focusing on           adenocarcinoma of the prostate. The present application concerns the creation        of methods for the definition and analysis of novel histopathologic features         predominantly derived from nuclear image data, with the objective of defining        ""prototype identities."" According to the investigator, these are fundamental         complexes of histologic features unique to individual tissue samples, or small       groups of such samples, that should convey useful predictive value for               individual patients. Many of these features are not normally discernable to the      eye, even to the experienced observer. They encompass a large number of primary      and derived nuclear morphometric measures, including what are referred to as         ""weak features,"" that is those that have not in the past shown strong                correlative utility by standard statistical measures. Derived measures include       feature and heterogeneity profiles. These data will form the inputs to a logic       network (""inference network"") designed to perform an identification process and      ultimately to generate the prototype identities.                                                                                                                          n/a",KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6489213,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' human tissue', ' hyperplasia', ' image processing', ' information system analysis', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2002,474210,161094826,-0.026256450790101363
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6487190,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2001,10000,246330700,0.0014688858959332844
"Development of Ultrasonic Apparatus for Dental Diagnosis   DESCRIPTION: Ultrasonic diagnostic apparatus has been proposed (Phases 1 and 2)      for Dental applications in determining tooth pathologies such as                     demineralization, caries, fractures, abscesses, and tooth wear. The equipment        adopts piezoelectric and optic hybrid transduction system for interrogation on       teeth. Ultrasonic responses of the tooth structure will then be analyzed by a        pattern recognition expert system (artificial intelligence) to determine the         diagnosis of the tooth inspected. The proposed research will eventually help to      reduce the use of harmful X-ray radiation in Dental clinic and also contribute       to artificial intelligence based diagnosis. In the Phase 1 research, tooth           specimens will be collected from local Dental clinics; demonstration                 instrumentation will be constructed; ultrasonic testing will be conducted on         the tooth specimens in vitro; and finally, the test data will be analyzed to         show the potential for Dental pathology identification. The feasibility of the       proposed research concept will be demonstrated, if: 1) meaningful ultrasonic         tests can be conducted using the simple piezo-/opto-ultrasonic system on the         tooth specimens collected; 2) various Dental pathologies in the tooth specimens      may be characterized by using wave pattern of the ultrasonic responses; and 3)       by identifying particular features of an ultrasonic wave pattern, the actual         tooth pathology may be recognized.                                                   PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                          n/a",Development of Ultrasonic Apparatus for Dental Diagnosis,6402448,R43DE014270,"['artificial intelligence', ' biomedical equipment development', ' dental disorder diagnosis', ' dental structure', ' dentistry', ' diagnosis design /evaluation', ' tooth', ' tooth surface']",NIDCR,AAC INTERNATIONAL,R43,2001,100000,0,-0.0014739045443741658
"Educational Tools for Neuroscience   DESCRIPTION (provided by applicant): SHAI proposes to bring two instructional        technologies together to compliment neuroscience lectures and distance               learning. Specifically we want to embed Computer Simulations of experiments and      the chemical, genetic, and physiological systems that underlie them within an        Intelligent Tutoring System. Simulations are excellent tools for revealing the       structure and dynamics of systems to students. They can also serve as a basis        of interactive experiments where students can ""discover"" the answers to              questions. Intelligent Tutoring Systems (ITS) are an emerging educational            technology based on artificial intelligence research. They play the role of          tutor, in that they guide students with appropriate information or                   demonstrations when they are having difficulty with a lesson. They also              adaptively plan the presentation of new lessons based on evaluations of a            student's past performance and knowledge level. The objective of this phase I        proposal is to develop a prototype of NeuroTutor, a simulation-based ITS to          provide students with individualized instruction in a simulation centered            environment. Steps to reaching this objective include designing a curriculum,        developing instructional, presentations and support, developing appropriate          methods for Student Modeling and Diagnosis, and implementing a limited               prototype.                                                                           PROPOSED COMMERCIAL APPLICATION:  This project has a sizeable commercialization potential.  Medical schools and university  neuroscience courses from a significant market.  Moreover the technologies to be   developed are transferable to other domains in the natural and social sciences, business  and medicine.  The technologies used are appropriate for use in distance learning programs,  and can be used by individuals to educate themselves.                                                                                     n/a",Educational Tools for Neuroscience,6403961,R43MH065842,"['computer assisted instruction', ' computer simulation', ' educational resource design /development', ' interactive multimedia', ' neurobiology', ' science education']",NIMH,"STOTTLER HENKE ASSOCIATES, INC.",R43,2001,100000,0,-0.004388614391060157
"PERCEPTION OF RISK AND BEHAVIOR IN THE ELDERLY   DESCRIPTION (Adapted from the Applicant's Abstract): This application was            initially submitted as an R29 FIRST Award, and is being re-submitted as an R01       in response to Program Announcement, PA-97-065 (NIA) entitled, ""Social               Cognition and Aging.""                                                                 The goal of this project is to determine how individual risk perceptions             influence health behaviors among the near-elderly (51-61) and decisions              regarding wealth holdings among the elderly (70+). Among the near-elderly, the       following health behaviors will be studied: the use of preventive services           (mammography, prostate screening, and cholesterol screening), weight loss and        exercise. The preventive services are designed to reduce mortality from cancer       and heart disease. Weight loss and exercise are both preventive measures as          well as mitigators of harm that results from health shocks. Expanding the use        of these preventive and mitigating measures are important to reduce morbidity        and mortality from heart disease and cancer. Among the elderly, the behavior of      interest relates to asset accumulation/dissaving, specifically focusing on           housing decisions. The specific decisions will be selling a house, and changes       in housing wealth holdings. The two decisions will be analyzed because housing       assets likely have fewer measurement errors, and because housing is the major        component of wealth for most elderly persons. Housing decisions are important        from a policy perspective because they may represent precautionary savings to        finance long-term care, a substantial risk the elderly face.                                                                                                              The proposed conceptual model is an extension of the common Bayesian learning        model whereby prior risk perceptions are updated on the basis of information.        Our model holds that updated risk perceptions, in turn, influence behavior.          Risk perceptions will be estimated as enodogenous explanatory variables              simultaneously with health behaviors among the near-elderly and housing              decisions among the elderly. The panel structure of the data bases to be used        (4 waves of Health and Retirement Study; 3 waves of Asset and Health Dynamics        Among the Oldest Old) will allow for the modeling of behaviors in time 3 or 4        as a function of changes in risk perceptions regarding longevity and of needing      nursing home care between waves 1 and 2 and 1 and 3.                                                                                                                      n/a",PERCEPTION OF RISK AND BEHAVIOR IN THE ELDERLY,6372233,R01AG015868,"['behavioral /social science research tag', ' cholesterol', ' clinical research', ' disease /disorder proneness /risk', ' exercise', ' health behavior', ' health care service utilization', ' human middle age (35-64)', ' human subject', ' mammography', ' perception', ' prevention', ' prostate', ' socioeconomics', ' weight loss']",NIA,DUKE UNIVERSITY,R01,2001,181196,607172798,-0.02265683583807233
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6333620,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2001,297104,246330700,0.0014688858959332844
"THE EFFECTS OF RETAINED LEAD BULLETS ON BODY LEAD BURDEN Numerous case reports have demonstrated lead poisoning with potentially fatal consequences can result from retained lead projectiles following firearm injuries.  To assess the impact of retained projectiles on subsequent lead exposure, one cannot rely on self-selected cases presenting with symptoms of lead intoxication.  The long-term goal of this project is to reduce the morbidity associated with body lead burden as a result of retained bullets from firearm injuries.  The proposed investigation seeks to identify risk factors of elevated blood lead levels for individuals with retained lead bullets, establish appropriate protocols for lead testing, develop indications for bullet removal and provide guidelines for the appropriate management of fragments not removed. The study design included follow-up of 300 patients with retained lead bullets/bullet fragments presenting for acute care of firearm injury at large publicly owned Level 1 Trauma Center.  A baseline blood level is measured as soon after patient stabilization as possible and repeated at intervals of 3, 6 and 12 months.  Medical history regarding prior firearms injuries and other retained projectiles is taken, along with a screening and risk factor questionnaire to determine other sources of lead (occupational/recreational) to which the patient might have been or at present be exposed.  The patient will have K- shell X ray florescence determination of bone lead in the tibia and calcaneus in order to determine past lead exposure not revealed by medical history and risk factor questionnairer.  Multivariate models of blood level are made for each patient visit using risk factor and bone lead concentration data.  Determinations will be made if changes in blood lead, adjusted for risk factors and bone lead concentration, from one 3 month period to the next can be significantly predicted by the coded location and fragmentation data of projectiles and presence or absence of fractures.  The variables of location, fragmentation, fracture and total time during which the projectile was retained in the body will be tested using logistic regression.  This will determine odds ratios of elevated lead at various concentrations (greater than 15 mug/dL, greater than 25  mug/dL, greater than 40 mug/dL, etc.) due to these factors.  Data will also be analyzed in the framework of the general linear model (GML), with a repeated measure design.  Principal interest will be in increasing trend of blood level as a function of fragmentation location, fracture and duration variables.  n/a",THE EFFECTS OF RETAINED LEAD BULLETS ON BODY LEAD BURDEN,6382333,R01ES010166,"['X ray', ' blood chemistry', ' clinical research', ' environmental exposure', ' foreign body reaction', ' human morbidity', ' human subject', ' injury', ' lead', ' lead poisoning', ' longitudinal human study', ' outcomes research', ' questionnaires', ' radiofluorescent probe', ' statistics /biometry']",NIEHS,CHARLES R. DREW UNIVERSITY OF MED & SCI,R01,2001,460035,7479461,-4.783142587571971e-05
"KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY  The proposed work extends previous research performed by this                                                                     investigator in the field of knowledge-based systems for the analysis of             histopathologic material, mainly neoplastic tissue; and mostly focusing on           adenocarcinoma of the prostate. The present application concerns the creation        of methods for the definition and analysis of novel histopathologic features         predominantly derived from nuclear image data, with the objective of defining        ""prototype identities."" According to the investigator, these are fundamental         complexes of histologic features unique to individual tissue samples, or small       groups of such samples, that should convey useful predictive value for               individual patients. Many of these features are not normally discernable to the      eye, even to the experienced observer. They encompass a large number of primary      and derived nuclear morphometric measures, including what are referred to as         ""weak features,"" that is those that have not in the past shown strong                correlative utility by standard statistical measures. Derived measures include       feature and heterogeneity profiles. These data will form the inputs to a logic       network (""inference network"") designed to perform an identification process and      ultimately to generate the prototype identities.                                                                                                                          n/a",KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6286183,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' human tissue', ' hyperplasia', ' image processing', ' information system analysis', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2001,465813,161094826,-0.026256450790101363
"COMMUNITY-SITE CORONARY RISK CONTROL IN BLACK FAMILIES This study tests the effectiveness of Neighborhood Health Worker/Nurse           Case Management compared with usual care (referral to usual primary care         source) for the management of coronary heart disease risk factors in             African American siblings of persons with premature coronary disease.            Index patients with documented coronary disease prior to 60 years of age         will be recruited from 7 Baltimore hospitals to identify 480 siblings            to be screened to identify those with a criterion risk factor (LDL-              cholesterol greater than 130 mg/dl, blood pressure greater than 140/90           mmHg, and/or cigarette smoking) (n=433).  Eligible siblings are those            between 30 and 60 years of age with no known coronary disease.  Siblings         with criterion risk factors after screening will be randomly assigned            by family to receive care in the community by a case management team             consisting of a Neighborhood Health Worked guided by a nurse and                 cardiologist, or to receive usual care.  Siblings will be followed one           year after screening to determine the proportion in each group who meet          goal levels of blood pressure, LDL-cholesterol, dietary fat, physical            activity, and smoking cessation.  The study builds on prior work in both         the African American community and in siblings that shows that 1.) nurse         managed care produces more successful risk reduction, 2.) African                Americans accept care in the community and from Neighborhood Health              Workers, and 3.) sociocultural models of care are more likely to be              successful in high risk African American families.  The goal is to               increase the proportion of high risk siblings who achieve goals based            on national guidelines.  This is one of the first studies to empirically         examine a combination of community intervention for multiple risk factor         reduction using indigenous workers and approaches which address the              needs of individuals with a documented family history of premature               coronary heart disease.  Analysis will include the test of proportions           achieving goals and multiple logistic regression analysis predicting             favorable change, adjusted for intra-family clustering of baseline risk          factors.                                                                          n/a",COMMUNITY-SITE CORONARY RISK CONTROL IN BLACK FAMILIES,6389706,R01HL058625,"['African American', ' blood lipoprotein', ' blood pressure', ' body physical activity', ' cardiovascular disorder prevention', ' cholesterol', ' clinical research', ' community health services', ' coronary disorder', ' diabetes mellitus', ' diet therapy', ' dietary lipid', ' disease /disorder proneness /risk', ' health care referral /consultation', ' health care service availability', ' health services research tag', ' human subject', ' human therapy evaluation', ' nutrition related tag', ' siblings', ' smoking cessation']",NHLBI,JOHNS HOPKINS UNIVERSITY,R01,2001,471244,807432003,-0.006716836320083817
"COMMUNITY-SITE CORONARY RISK CONTROL IN BLACK FAMILIES This study tests the effectiveness of Neighborhood Health Worker/Nurse           Case Management compared with usual care (referral to usual primary care         source) for the management of coronary heart disease risk factors in             African American siblings of persons with premature coronary disease.            Index patients with documented coronary disease prior to 60 years of age         will be recruited from 7 Baltimore hospitals to identify 480 siblings            to be screened to identify those with a criterion risk factor (LDL-              cholesterol greater than 130 mg/dl, blood pressure greater than 140/90           mmHg, and/or cigarette smoking) (n=433).  Eligible siblings are those            between 30 and 60 years of age with no known coronary disease.  Siblings         with criterion risk factors after screening will be randomly assigned            by family to receive care in the community by a case management team             consisting of a Neighborhood Health Worked guided by a nurse and                 cardiologist, or to receive usual care.  Siblings will be followed one           year after screening to determine the proportion in each group who meet          goal levels of blood pressure, LDL-cholesterol, dietary fat, physical            activity, and smoking cessation.  The study builds on prior work in both         the African American community and in siblings that shows that 1.) nurse         managed care produces more successful risk reduction, 2.) African                Americans accept care in the community and from Neighborhood Health              Workers, and 3.) sociocultural models of care are more likely to be              successful in high risk African American families.  The goal is to               increase the proportion of high risk siblings who achieve goals based            on national guidelines.  This is one of the first studies to empirically         examine a combination of community intervention for multiple risk factor         reduction using indigenous workers and approaches which address the              needs of individuals with a documented family history of premature               coronary heart disease.  Analysis will include the test of proportions           achieving goals and multiple logistic regression analysis predicting             favorable change, adjusted for intra-family clustering of baseline risk          factors.                                                                          n/a",COMMUNITY-SITE CORONARY RISK CONTROL IN BLACK FAMILIES,6322626,R18HL058625,"['African American', ' blood lipoprotein', ' blood pressure', ' body physical activity', ' cardiovascular disorder prevention', ' cholesterol', ' clinical research', ' community health services', ' coronary disorder', ' diabetes mellitus', ' diet therapy', ' dietary lipid', ' disease /disorder proneness /risk', ' health care referral /consultation', ' health care service availability', ' health services research tag', ' human subject', ' human therapy evaluation', ' nutrition related tag', ' siblings', ' smoking cessation']",NHLBI,JOHNS HOPKINS UNIVERSITY,R18,2000,16710,807432003,-0.006716836320083817
"MODEL BASED INTERPRETATION OF INTRACARDIAC ELECTROGRAMS Catheter ablation is a medical procedure that involves the destruction of        small volumes of heart tissue with radiofrequency energy.  To be                 successful, catheter ablation requires precise localization of the tissue        to be destroyed. To accomplish this in a typical ablation procedure, five        catheters containing a total of 19 electrode pairs are utilized to record        potentials (called electrograms) from spatially distinct locations within        the heart throughout the cardiac cycle. Experienced cardiologists                interpret the electrograms to locate the conduction pathways responsible         for the arrhythmia. The pathways are destroyed by applications of                radiofrequency energy, thus treating the arrhythmia.                                                                                                              Ablation procedures are performed by highly trained and experienced              cardiology sub-specialists yet the massive amount of data produced during        these procedures creates a data overload problem that can impede the             performance of even the best practitioners. This may be evidenced by (1)         overlooking important signal features, (2) misinterpreting the signals,          and (3) misinterpreting catheter locations in the heart, all of which may        lead to increased procedure duration and/or applications of radiofrequency       energy to the wrong part of the heart.                                                                                                                            The purpose of this project is to develop a model-based system for               interpreting intracardiac electrograms in near real-time. The system is          intended to assist physicians in ""making sense"" of the enormous amounts of       data recorded during a cardiac electrophysiology study. New computer             algorithms for reasoning about the time- and space-varying nature of             intracardiac electrograms from underlying causal models of the heart will        be developed. The models can be represented as a graph of nodes connected        by arcs. The nodes represent specific an atomic regions of the heart while       the arcs represent the connections between the regions.                                                                                                           The analytic approach will be a variation of the hypothesize-and-test            paradigm. The control loop will be based on the ""tracking"" concept whereby       models will be tracked as long as the data supports the model. Rule-based        knowledge will be utilized to generate models based on the observed data.        The output of the system will be a series of ladder diagrams describing          the data. In the event that the data admits more than a single explanatory       model, ladder diagrams will be generated for all created models.                                                                                                  This proposal is an extension of the applicant's graduate and post-              doctoral project, which used the same approach to the simpler domain of          the interpretation of the body-surface electrocardiogram. The domain of          this proposal is more complex because it adds reasoning with a more              detailed three dimensional cardiac model to the temporal reasoning               required for previous work. Also, this domain requires the ability to            account for simultaneous activation of the heart at multiple locations,          which was performed at a rudimentary level in the previous work.                                                                                                  This project is important for three reasons: (1) it offers new knowledge-        based algorithms for reasoning about time- and space-varying data, (2) a         comprehensive and extensible model of the cardiac conduction will be             created that incorporates the spatial resolution necessary for                   interpreting intracardiac electrograms, and (3) a software tool such the         one proposed may help clinicians improve the quality of health care.              n/a",MODEL BASED INTERPRETATION OF INTRACARDIAC ELECTROGRAMS,6126011,R29LM006004,"['arrhythmia', ' artificial intelligence', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' electrocardiography', ' heart catheterization', ' heart conduction system', ' human data', ' interactive multimedia', ' mathematical model', ' model design /development']",NLM,SOUTHWEST RESEARCH INSTITUTE,R29,2000,149839,0,-0.011518915269244217
"PERCEPTION OF RISK AND BEHAVIOR IN THE ELDERLY   DESCRIPTION (Adapted from the Applicant's Abstract): This application was            initially submitted as an R29 FIRST Award, and is being re-submitted as an R01       in response to Program Announcement, PA-97-065 (NIA) entitled, ""Social               Cognition and Aging.""                                                                 The goal of this project is to determine how individual risk perceptions             influence health behaviors among the near-elderly (51-61) and decisions              regarding wealth holdings among the elderly (70+). Among the near-elderly, the       following health behaviors will be studied: the use of preventive services           (mammography, prostate screening, and cholesterol screening), weight loss and        exercise. The preventive services are designed to reduce mortality from cancer       and heart disease. Weight loss and exercise are both preventive measures as          well as mitigators of harm that results from health shocks. Expanding the use        of these preventive and mitigating measures are important to reduce morbidity        and mortality from heart disease and cancer. Among the elderly, the behavior of      interest relates to asset accumulation/dissaving, specifically focusing on           housing decisions. The specific decisions will be selling a house, and changes       in housing wealth holdings. The two decisions will be analyzed because housing       assets likely have fewer measurement errors, and because housing is the major        component of wealth for most elderly persons. Housing decisions are important        from a policy perspective because they may represent precautionary savings to        finance long-term care, a substantial risk the elderly face.                                                                                                              The proposed conceptual model is an extension of the common Bayesian learning        model whereby prior risk perceptions are updated on the basis of information.        Our model holds that updated risk perceptions, in turn, influence behavior.          Risk perceptions will be estimated as enodogenous explanatory variables              simultaneously with health behaviors among the near-elderly and housing              decisions among the elderly. The panel structure of the data bases to be used        (4 waves of Health and Retirement Study; 3 waves of Asset and Health Dynamics        Among the Oldest Old) will allow for the modeling of behaviors in time 3 or 4        as a function of changes in risk perceptions regarding longevity and of needing      nursing home care between waves 1 and 2 and 1 and 3.                                                                                                                      n/a",PERCEPTION OF RISK AND BEHAVIOR IN THE ELDERLY,6169107,R01AG015868,"['behavioral /social science research tag', ' cholesterol', ' clinical research', ' disease /disorder proneness /risk', ' exercise', ' health behavior', ' health care service utilization', ' human middle age (35-64)', ' human subject', ' mammography', ' perception', ' prevention', ' prostate', ' socioeconomics', ' weight loss']",NIA,DUKE UNIVERSITY,R01,2000,178725,607172798,-0.02265683583807233
"CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI DESCRIPTION (Adapted from the Investigator's Abstract): Bold steps must be       taken to advance our understanding of the genetic and associated co-             variates affecting the inheritance of complex diseases. To that end, this        proposal will develop improved quantitative methods to detect genetic            factors contributing to increased susceptibility to complex disorders and        implement these methods in software for distribution to the research             community.                                                                                                                                                        The methods will concentrate on the use of classification techniques             applied to allele sharing data and other risk factors which affect the           trait. Allele sharing methods for mapping genes will be extended to              include the classification methods known as latent class models, cluster         analysis, and artificial neural networks, as well as a novel use of              logistic regression Co-variates such as gender, parental diagnosis, or           other concomitant factors will be systematically studied through                 applications to both stimulated and existing data sets. An additional goal       is to determine the optimal distribution of relative pairs (e.g. siblings,       first cousins) for these methods. Of great importance to this proposal is        the development of well-documented, user-friendly software and                   documentation which will be distributed to the scientific community via          the Internet. Existing software developed by the PI will be extensively          expanded for latent class models. Existing cluster analysis software will        be modified and combined for ease of use.                                                                                                                         This proposal consists of theoretical exploration, computer simulation,          data analysis, and software development. First, solutions of theoretical         questions relating to classification techniques will be pursued; second,         adaptation of computer programs to implement the analytic methods, and           investigation into alternative research strategies will be accomplished.         The new strategies will be applied to stimulated data, and finally, to           existing data sets of pedigrees in which a complex trait has been                diagnosed. Findings from this research may contribute to the ability to          locate susceptibility loci in complex traits and to the clarification of         those etiological mechanisms responsible for susceptibility.                      n/a",CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI,6168495,R01AA012239,"['alleles', ' analytical method', ' artificial intelligence', ' biomedical resource', ' computer program /software', ' computer simulation', ' data collection methodology /evaluation', ' disease /disorder classification', ' disease /disorder etiology', ' family genetics', ' gene environment interaction', ' gene expression', ' genetic disorder', ' genetic disorder diagnosis', ' genetic mapping', ' genetic markers', ' genetic susceptibility', ' human data', ' mathematical model', ' model design /development', ' quantitative trait loci', ' statistics /biometry']",NIAAA,WASHINGTON UNIVERSITY,R01,2000,180260,533594881,-0.015944626924305986
"NEW ROC METHODOLOGY TO ASSESS DIAGNOSTIC ACCURACY DESCRIPTION (Adapted from Applicant's Abstract):  Receiver Operating             Characteristic (ROC) analysis is recognized widely as the best way of            measuring and specifying the accuracies of diagnostic procedures, because it     is able to distinguish between actual differences in discrimination              capacity, on one hand, and apparent differences that are due only to             decision-threshold effects, on the other.  Key methodological needs remain       to be satisfied before ROC analysis can address all of the practically           important situations that arise in diagnostic applications, however.  This       project employs signal detection theory and computer simulation to address       several of those needs, by:  (1) refining and continuing distribution of         software developed previously by the applicants for fitting ROC curves and       for testing the statistical significance of differences between ROC curve        estimates; (2) developing and evaluating new algorithms for ROC                  curve-Fitting and statistical testing, based on their recently-developed         ""proper"" binormal model, that should provide more meaningful results in          experimental situations that involve small samples of cases; (3)                 investigating the usefulness of a form of ROC methodology that is based on       mixture distributions in order to rduce the need for diagnostic truth in ROC     experiments; (4) investigating the effect of case-saple difficulty on the        statistical power tests for differences between ROC curves, in order to          determine the optimal difficulty of cases that shouldbe studied on rank          diagnostic systems; and (5) developing methods for training artificial           neural networks (ANNs) to maximize diagnostic accuracy in terms of ROC           analysis and signal detection theory.                                             n/a",NEW ROC METHODOLOGY TO ASSESS DIAGNOSTIC ACCURACY,6181168,R01GM057622,"['artificial intelligence', ' computer assisted diagnosis', ' computer system design /evaluation', ' method development', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R01,2000,218176,246330700,-0.014747759675246132
"THE EFFECTS OF RETAINED LEAD BULLETS ON BODY LEAD BURDEN Numerous case reports have demonstrated lead poisoning with potentially fatal consequences can result from retained lead projectiles following firearm injuries.  To assess the impact of retained projectiles on subsequent lead exposure, one cannot rely on self-selected cases presenting with symptoms of lead intoxication.  The long-term goal of this project is to reduce the morbidity associated with body lead burden as a result of retained bullets from firearm injuries.  The proposed investigation seeks to identify risk factors of elevated blood lead levels for individuals with retained lead bullets, establish appropriate protocols for lead testing, develop indications for bullet removal and provide guidelines for the appropriate management of fragments not removed. The study design included follow-up of 300 patients with retained lead bullets/bullet fragments presenting for acute care of firearm injury at large publicly owned Level 1 Trauma Center.  A baseline blood level is measured as soon after patient stabilization as possible and repeated at intervals of 3, 6 and 12 months.  Medical history regarding prior firearms injuries and other retained projectiles is taken, along with a screening and risk factor questionnaire to determine other sources of lead (occupational/recreational) to which the patient might have been or at present be exposed.  The patient will have K- shell X ray florescence determination of bone lead in the tibia and calcaneus in order to determine past lead exposure not revealed by medical history and risk factor questionnairer.  Multivariate models of blood level are made for each patient visit using risk factor and bone lead concentration data.  Determinations will be made if changes in blood lead, adjusted for risk factors and bone lead concentration, from one 3 month period to the next can be significantly predicted by the coded location and fragmentation data of projectiles and presence or absence of fractures.  The variables of location, fragmentation, fracture and total time during which the projectile was retained in the body will be tested using logistic regression.  This will determine odds ratios of elevated lead at various concentrations (greater than 15 mug/dL, greater than 25  mug/dL, greater than 40 mug/dL, etc.) due to these factors.  Data will also be analyzed in the framework of the general linear model (GML), with a repeated measure design.  Principal interest will be in increasing trend of blood level as a function of fragmentation location, fracture and duration variables.  n/a",THE EFFECTS OF RETAINED LEAD BULLETS ON BODY LEAD BURDEN,6195278,R01ES010166,"['X ray', ' blood chemistry', ' clinical research', ' environmental exposure', ' foreign body reaction', ' human morbidity', ' human subject', ' injury', ' lead', ' lead poisoning', ' longitudinal human study', ' outcomes research', ' questionnaires', ' radiofluorescent probe', ' statistics /biometry']",NIEHS,CHARLES R. DREW UNIVERSITY OF MED & SCI,R01,2000,448771,7479461,-4.783142587571971e-05
"COMMUNITY-SITE CORONARY RISK CONTROL IN BLACK FAMILIES This study tests the effectiveness of Neighborhood Health Worker/Nurse           Case Management compared with usual care (referral to usual primary care         source) for the management of coronary heart disease risk factors in             African American siblings of persons with premature coronary disease.            Index patients with documented coronary disease prior to 60 years of age         will be recruited from 7 Baltimore hospitals to identify 480 siblings            to be screened to identify those with a criterion risk factor (LDL-              cholesterol greater than 130 mg/dl, blood pressure greater than 140/90           mmHg, and/or cigarette smoking) (n=433).  Eligible siblings are those            between 30 and 60 years of age with no known coronary disease.  Siblings         with criterion risk factors after screening will be randomly assigned            by family to receive care in the community by a case management team             consisting of a Neighborhood Health Worked guided by a nurse and                 cardiologist, or to receive usual care.  Siblings will be followed one           year after screening to determine the proportion in each group who meet          goal levels of blood pressure, LDL-cholesterol, dietary fat, physical            activity, and smoking cessation.  The study builds on prior work in both         the African American community and in siblings that shows that 1.) nurse         managed care produces more successful risk reduction, 2.) African                Americans accept care in the community and from Neighborhood Health              Workers, and 3.) sociocultural models of care are more likely to be              successful in high risk African American families.  The goal is to               increase the proportion of high risk siblings who achieve goals based            on national guidelines.  This is one of the first studies to empirically         examine a combination of community intervention for multiple risk factor         reduction using indigenous workers and approaches which address the              needs of individuals with a documented family history of premature               coronary heart disease.  Analysis will include the test of proportions           achieving goals and multiple logistic regression analysis predicting             favorable change, adjusted for intra-family clustering of baseline risk          factors.                                                                          n/a",COMMUNITY-SITE CORONARY RISK CONTROL IN BLACK FAMILIES,6184421,R18HL058625,"['African American', ' blood lipoprotein', ' blood pressure', ' body physical activity', ' cardiovascular disorder prevention', ' cholesterol', ' clinical research', ' community health services', ' coronary disorder', ' diabetes mellitus', ' diet therapy', ' dietary lipid', ' disease /disorder proneness /risk', ' health care referral /consultation', ' health care service availability', ' health services research tag', ' human subject', ' human therapy evaluation', ' nutrition related tag', ' siblings', ' smoking cessation']",NHLBI,JOHNS HOPKINS UNIVERSITY,R18,2000,566543,807432003,-0.006716836320083817
