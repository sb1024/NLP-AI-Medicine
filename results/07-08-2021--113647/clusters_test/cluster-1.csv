text,title,id,project_number,terms,administration,organization,mechanism,year,cost,funding
"Deep learning for renal tumor characterization Our long-term objective is to develop deep learning techniques capable of predicting characteristics and treatment response or response to surveillance to assist clinical decision- making in renal tumors that are potential candidates for ablation therapy, biopsy, active surveillance or surgical resection. An increasing number of renal tumors are being diagnosed, due in part to incidental detection from the increased use of cross-sectional imaging. Although partial nephrectomy is still considered the primary treatment for small renal masses, percutaneous ablation is increasingly performed as a therapeutic, nephron-sparing approach. One challenge for interventional radiologists and urologists who manage these patients is selection for therapy, since the average rate of progression is slow for small renal tumors and metastasis rarely occurs. A technique that could distinguish indolent tumors from those will progress based on data from the imaging methods used to detect and delineate renal masses would enable early triage to observation versus invasive treatment. Deep learning, a type of machine learning technique which takes raw images as input, and applies many layers of transformations to calculate an output signal, has already led to breakthroughs in other areas of image recognition, and is increasingly used for medical image analysis. However, its application in the field of interventional radiology is currently limited. Furthermore, no study in the literature has applied deep learning to kidney lesion segmentation and characteristics/outcome prediction. In this project, we propose to develop novel deep learning architectures based on routine MR imaging that allow for accurate renal mass segmentation and prediction of characteristics and outcome in renal tumors. Using data from four independent cohorts, we will use our deep learning architectures to predict (1) benign versus malignant histology (2) growth rate in stage 1a renal cell carcinoma (3) SSIGN score in clear cell renal cell carcinoma and (4) clinical endpoints. We will integrate segmentation and classification into one net that suitable for clinical application. In addition, we will compare results with those of experts and traditional machine learning approaches. The inability to determine aggressiveness of renal tumors based on pretreatment imaging makes it challenging for urologists or interventional radiologists to select appropriate patients for active surveillance versus therapy with nephrectomy or ablation. Our research project uses deep learning to distinguish renal mass from normal tissue and predict characteristics, treatment response or response to surveillance in renal tumors. By using a multi-institutional patient cohort and conventional MR imaging sequences, we will demonstrate the generalizability and broad applicability of our algorithm. Our models have the potential to help guide clinical management of patients with renal tumors.",Deep learning for renal tumor characterization,10116348,R03CA249554,"['3-Dimensional', 'Ablation', 'Algorithms', 'Architecture', 'Area', 'Benign', 'Biopsy', 'Characteristics', 'Classification', 'Clear cell renal cell carcinoma', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Dropout', 'Ensure', 'Excision', 'Future', 'Growth', 'Histology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Intervention', 'Interventional radiology', 'Kidney', 'Kidney Neoplasms', 'Learning', 'Lesion', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Medical Imaging', 'Metastatic Neoplasm to the Kidney', 'Modeling', 'Nephrectomy', 'Nephrons', 'Neural Network Simulation', 'Normal tissue morphology', 'Oncology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient imaging', 'Patients', 'Performance', 'Process', 'Renal Cell Carcinoma', 'Renal Mass', 'Research Project Grants', 'Selection for Treatments', 'Signal Transduction', 'Techniques', 'Therapeutic', 'Training', 'Triage', 'Update', 'Urologist', 'Weight', 'base', 'cancer imaging', 'clinical application', 'clinical decision-making', 'cohort', 'deep learning', 'deep neural network', 'design', 'imaging modality', 'improved', 'interest', 'learning network', 'novel', 'outcome prediction', 'predictive modeling', 'radiologist', 'radiomics', 'random forest', 'treatment response', 'tumor']",NCI,RHODE ISLAND HOSPITAL,R03,2021,80500,37921345
"Generation of parametric images for FDG PET using dual-time-point scans Project Summary/Abstract Positron emission tomography combined with computed tomography (PET/CT) using the radiolabeled tracer 2- deoxy-2-(18F)fluoro-D-glucose (FDG) has become a standard imaging tool for cancer patient management. The semi-quantitative parameter standardized uptake value (SUV) is routinely used in clinical for tumor uptake quantification, which is computed on the static PET image acquired at a certain time (typically 60 min) post tracer injection for a short interval (typically 5-15 min). However, the quantification accuracy of SUV from a single PET scan suffers from the variabilities of tracer plasma clearance and acquisition start time. The dual- time-point FDG PET imaging has been intensively investigated and used in both clinical and research studies, typically one scan at 60 min and the other at 120 min, showing the potential to enhance the diagnostic accuracy of FDG PET by differentiating malignancy from inflammation and normal tissue. However, the current clinical dual-time-point FDG PET studies use the relative SUV change between two scans as the quantification index, which cannot eliminate the variations in tracer plasma clearance. Meanwhile, the dual-time-point protocol has not been optimized and standardized currently, leading to conflicting results. The fully-quantitative parameter, tracer net uptake rate constant Ki, is the most accurate parameter to quantify FDG PET, which is calculated using dynamic imaging with compartmental modeling. Ki is independent on the plasma clearance or acquisition start time. However, the long and complex acquisition protocol (typically at least 60 min), which requires dynamic scanning and sequential arterial blood sampling (or image-derived blood activity) used as input function from the time of injection, limits its application in clinical practice. Meanwhile, generation of the parametric Ki image, which can provide additional heterogeneity information for FDG PET, is challenging clinically using voxel-by-voxel compartmental modeling due to the computational cost and being sensitive to noise using non-linear least squares. The graphical Patlak plot, can be used for simplified Ki calculation and Ki image generation by voxel-by-voxel fitting. However, it still needs dynamic scanning starting from 15-30 min after injection and input function from the time of injection. The aims of this proposal are 1) to optimize the dual-time-point protocol for accurate Ki quantification using Patlak plot without the need for individual patient's input function, and 2) to generate high-quality low-noise dual-time-point Ki images using novel techniques based on deep learning. Upon the success of this project, our proposed approach can obtain reliable tumor Ki quantification and parametric Ki image ""for free"" without adding any additional complexity on the existing dual- time-point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology. We expect the translation of this approach to clinical investigation to be fast, as this is a post-processing approach and is based on data already acquired using clinically used protocol without imposing additional burden to technologists. Project Narrative For FDG PET imaging, we propose to develop a novel and simple approach of quantifying tumor Ki and generating parametric Ki image ""for free"" without adding any additional complexity on the existing dual-time- point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology.",Generation of parametric images for FDG PET using dual-time-point scans,10117077,R03EB027864,"['Blood', 'Blood specimen', 'Cancer Patient', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Data', 'Diagnosis', 'Generations', 'Glucose', 'Heterogeneity', 'Image', 'Imaging Device', 'Inflammation', 'Injections', 'Label', 'Least-Squares Analysis', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Noise', 'Normal tissue morphology', 'Oncology', 'Patients', 'Plasma', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation exposure', 'Radiolabeled', 'Scanning', 'Standardization', 'Techniques', 'Time', 'Tracer', 'Training', 'Translations', 'Variant', 'X-Ray Computed Tomography', 'attenuation', 'base', 'clinical investigation', 'clinical practice', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'diagnostic accuracy', 'image reconstruction', 'improved', 'indexing', 'individual patient', 'innovation', 'novel', 'parametric imaging', 'population based', 'research study', 'simulation', 'success', 'tumor', 'uptake']",NIBIB,YALE UNIVERSITY,R03,2021,83750,550947887
"Generalizable Deep Learning Networks for Dual-tracer Amyloid/Tau PET/MRI Imaging of Alzheimer's Disease Project Summary  Alzheimer’s Disease (AD) is a devastating neurodegenerative disorder and a major public health crisis, currently affecting over 5.8 million Americans and expected to rise as the population ages. Positron emission tomography (PET) imaging can identify the hallmark proteinopathies of AD, including amyloid protein plaques and neurofibrillary tangles (composed primarily of tau protein) accumulating in the brain. While there is evident need for more PET neuroimaging, for example, to elucidate the sequence of amyloid and tau deposition in preclinical AD, its increased utility in longitudinal imaging studies with large study populations is limited by recruitment and cost. In particular, making multiple visits to the scanning site will be difficult for participants living far away, and the high cost of injected radiotracers will limit the scalability of PET studies.  In this project we propose using deep learning-based convolutional neural networks (CNNs) to enhance ultra-low-dose amyloid and tau PET for imaging AD. Our specific aims are (1) to validate the diagnostic value of the CNNs in actual ultra-low-dose amyloid and tau imaging sessions, with the injected dose as low as 1% of the original, and with actual ultra-low-dose data, to validate simulations for use in subsequent aims and future studies; (2) to apply the ultra-low-dose CNN to data collected on other PET systems and tracers, in order to demonstrate the CNN’s generalizability; and (3) to evaluate the value of deep learning-aided ultra-low-dose amyloid and tau PET for tracking cognitive decline in a preclinical AD population.  The innovation of this work lies in using multimodal imaging in addition to advanced machine learning techniques to enable acquisition of diagnostic-level PET images at extremely low dose levels. Performing actual ultra-low-dose PET acquisitions is also highly novel in itself. The outcome of this proposal is removing the limiting factors to large-scale clinical longitudinal imaging, shortening acquisitions spanning multiple days and visits to several hours in one visit with a successive ultra-low-dose and full-dose dual-tracer scan protocol. Significant dose reduction can also be achieved, allowing for more frequent amyloid/tau PET scanning. This flexibility will not only increase the utility of PET, aid longitudinal studies in dementia, but enable future comprehensive imaging of multiple PET-based biomarkers as these tracers are being developed. Project Narrative  More frequent PET scans can be used for dementia, a major cause of deaths in the United States, to understand the pathogenesis of the brain proteinopathies involved, to identify at-risk individuals, and to provide outcome markers for clinical trials of anti-amyloid/tau therapies; but recruitment for studies, cost, and radiation dose to the scanned participant are critical factors limiting its use. This work aims to train versatile deep learning-based neural networks which can produce diagnostic-level images from ultra-low-dose (as low as 1%) amyloid and tau PET acquisitions. Our study will provide flexibility in recruitment (running ultra-low-dose and full-dose scans in succession for dual-tracer studies), reduce the cost for radiotracer use, and reduce the dose in scanned participants, a “win-win” for researchers and patients.",Generalizable Deep Learning Networks for Dual-tracer Amyloid/Tau PET/MRI Imaging of Alzheimer's Disease,10214874,K99AG068310,"['Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease pathology', 'American', 'Amyloid', 'Amyloid Proteins', 'Biological Markers', 'Brain', 'Cause of Death', 'Cerebrum', 'Clinical', 'Clinical Markers', 'Clinical Trials', 'Cognitive', 'Data', 'Dementia', 'Deposition', 'Diagnostic', 'Dose', 'Drowning', 'Early Diagnosis', 'Evaluation', 'Follow-Up Studies', 'Future', 'Hour', 'Image', 'Impaired cognition', 'Individual', 'Injections', 'Investigative Techniques', 'Longitudinal Studies', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Modeling', 'Multimodal Imaging', 'Neurodegenerative Disorders', 'Neurofibrillary Tangles', 'Outcome', 'Participant', 'Pathogenesis', 'Patient Recruitments', 'Patients', 'Performance', 'Population', 'Positron-Emission Tomography', 'Proteins', 'Protocols documentation', 'Public Health', 'Radiation Dose Unit', 'Radioactivity', 'Reading', 'Research Design', 'Research Personnel', 'Risk', 'Running', 'Scanning', 'Schedule', 'Signal Transduction', 'Site', 'System', 'Techniques', 'Testing', 'Tracer', 'Training', 'United States', 'Visit', 'Vulnerable Populations', 'Work', 'apolipoprotein E-4', 'base', 'clinical application', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'flexibility', 'imaging agent', 'imaging study', 'innovation', 'learning network', 'longitudinal positron emission tomography', 'machine learning method', 'mild cognitive impairment', 'multimodality', 'neuroimaging', 'novel', 'pre-clinical', 'radiotracer', 'recruit', 'research study', 'serial imaging', 'sex', 'simulation', 'study population', 'tau Proteins', 'theories', 'uptake']",NIA,STANFORD UNIVERSITY,K99,2021,100863,560644462
"Fast motion-robust fetal neuroimaging with MRI PROJECT SUMMARY/ABSTRACT Fetal-brain magnetic resonance imaging (MRI) has become an invaluable tool for studying the early development of the brain and can resolve diagnostic ambiguities that may remain after routine ultrasound exams. Unfortunately, high levels of fetal and maternal motion (1) limit fetal MRI to rapid two-dimensional (2D) sequences and frequently introduce dramatic artifacts such as (2) image misorientation relative to the standard sagittal, coronal, axial planes needed for clinical assessment and (3) partial to complete signal loss. These factors lead to the inefficient practice of repeating ~30 s stack-of-slices acquisitions until motion-free images have been obtained. Throughout the session, technologists manually adjust the orientation of scans in response to motion, and about 38% of datasets are typically discarded. Thus, subject motion is the fundamental impediment to reaping the full benefits of MRI for answering clinical and investigational questions in the fetus. The overarching goal of this project is to overcome the challenges posed by motion by exploiting innovations in deep learning, which have enabled image-analysis algorithms with unprecedented speed and reliability. We propose to integrate these into the MRI acquisition pipeline to unlock the potential of fetal MRI. We will develop practical pulse-sequence technology for automated and dynamically motion-corrected fetal neuroimaging without the need for external hardware or calibration. We hypothesize that this will radically improve the quality and success rates of clinical and research studies, while dramatically reducing patient discomfort and cost. We propose as Aim 1 to eradicate (2) the vulnerability of acquisitions to image-brain misorientation with rapid, automated prescription of standard anatomical planes. In Aim 2, we propose to address (3) motion during the scan with real-time correction of fetal-head motion. An anatomical stack-of-slices acquisition will be interleaved with volumetric navigators. These will be used to measure motion as it happens in the scanner and to adaptively update the slice tilt/position. We propose as Aim 3 to develop a 3D radial sequence and estimate motion between subsets of radial spokes for real-time self-navigation. Adaptively updating the orientation of spokes and selectively re-acquiring corrupted subsets at the end of the scan will enable 3D imaging of the fetal brain (1). Since the applicant has a physics background, the proposed training program at MIT and HMS will focus on deep learning and fetal development/neuroscience during the K99 phase to develop the skills needed for transitioning to independence in the R00 phase. The applicant’s goal is to become a fetal image acquisition and analysis scientist acting as bridge between deep learning, MRI and clinical fetal-imaging applications to shift the boundaries of what is currently possible with state-of-the-art technology. Fulfilling the research aims will promote this, as it will result in a practical framework for automation and motion correction, applicable to a wide variety of fetal neuroimaging sequences. PROJECT NARRATIVE Subject motion is the fundamental impediment to reaping the full benefits of fetal-brain magnetic resonance imaging, as it frequently produces images with dramatic artifacts. The goal of this project is to exploit innovations in deep learning and integrate them into the acquisition pipeline to overcome the challenges posed by motion in fetal neuroimaging studies. This will be achieved by using fast, automated scan prescription of standard anatomical planes and by adaptively updating the acquisition as motion happens in the scanner, based on sub-second navigator scans interleaved with the imaging sequence.",Fast motion-robust fetal neuroimaging with MRI,10197182,K99HD101553,"['3-Dimensional', 'Address', 'Algorithmic Analysis', 'Amniotic Fluid', 'Anatomy', 'Automation', 'Brain', 'Brain imaging', 'Calibration', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Data Set', 'Development', 'Diagnostic', 'Echo-Planar Imaging', 'Fetal Development', 'Fetus', 'Geometry', 'Goals', 'Head', 'Image', 'Individual', 'Label', 'Lead', 'Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Masks', 'Measures', 'Morphologic artifacts', 'Motion', 'Neurosciences', 'Patients', 'Phase', 'Physics', 'Physiologic pulse', 'Population', 'Positioning Attribute', 'Radial', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Sampling', 'Scanning', 'Scientist', 'Signal Transduction', 'Slice', 'Speed', 'Technology', 'Thick', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Training Programs', 'Translating', 'Ultrasonography', 'Update', 'Work', 'base', 'clinical investigation', 'convolutional neural network', 'cost', 'deep learning', 'echo detection', 'experience', 'fetal', 'image archival system', 'improved', 'innovation', 'interest', 'neuroimaging', 'novel', 'prospective', 'radiologist', 'reconstruction', 'repaired', 'research study', 'response', 'skills', 'success', 'tool', 'two-dimensional']",NICHD,MASSACHUSETTS GENERAL HOSPITAL,K99,2021,109671,551214295
"Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images ABSTRACT The goal of this R03 Small Grant Program for NIDDK is to provide additional funding for Dr. Kline to expand upon his work on his K award and apply his expertise to new image acquisitions and problems related to renal imaging. Dr. Kline’s work has piqued the interest of many internal and external investigators and has led to recent collaborations with Drs. Rule, Denic, and Kim. Together with Dr. Erickson, this new research team has prepared this R03 proposal which takes advantage of the unique expertise of each team member. The focus of this proposal is to bridge the gap between microscopic observations and those assessable non-invasively by radiological imaging. To do this, we have established a unique dataset of renal CT imaging data and corresponding biopsy measured nephron densities. We have also generated a large database of gold-standard segmentation data of kidneys, cortical regions, and medullary pyramids. Using this existing data, we propose to: (i) develop tools for segmentation of kidneys, segmentation of individual medullary pyramids, and imputing missing parts of the kidneys outside of the imaged field-of-view in the CT image, and (ii) to establish imaging biomarkers of early CKD, and correlate macroscopic imaging findings to underlying microscopic structure. This research will be facilitated by Mayo Clinic’s outstanding clinical and research environment dedicated to improving patient care, as well as the Aging Kidney Anatomy Study (PI: Rule), which led to the generation of this unique and well characterized dataset. Dr. Kline’s background in imaging technologies and image processing makes him particularly well suited to perform this research. In addition to the above aims, near the end of this research project Dr. Kline will submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of renal imaging biomarkers. Obtaining this R03 Award will greatly facilitate Dr. Kline’s transition into a prosperous independent researcher focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. Narrative Non-invasive methods for characterizing micro-structural changes of the kidney during aging as well as in health and disease are currently not possible. This research program proposes to use our existing database of renal imaging and renal biopsy data to bridge the gap between macroscopic radiological findings on computed tomography images to those assessable in microscopic images of renal biopsies. This program will develop new automated methods for performing measurements on the images, as well as use machine/deep learning methods to search for new imaging biomarkers that relate to nephron density and size, as well as establish their usefulness for early chronic kidney disease detection and transplant planning.",Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images,10224190,R03DK125632,"['Abdomen', 'Affect', 'Aging', 'Albuminuria', 'Anatomy', 'Area', 'Arteries', 'Artificial Intelligence', 'Autosomal Dominant Polycystic Kidney', 'Award', 'Biopsy', 'Chronic Kidney Failure', 'Clinic', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrosis', 'Funding', 'Generations', 'Goals', 'Gold', 'Grant', 'Health', 'Hepatic Cyst', 'Hour', 'Hypertension', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'K-Series Research Career Programs', 'Kidney', 'Kidney Diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Microscopic', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrons', 'Organ', 'Outcome', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Polycystic Kidney Diseases', 'Radiologic Finding', 'Renal Blood Flow', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Scanning', 'Semantics', 'Services', 'Stenosis', 'Structure', 'Surveys', 'Techniques', 'Technology', 'Time', 'Transplantation', 'Tubular formation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'automated analysis', 'automated image analysis', 'automated segmentation', 'base', 'clinical decision-making', 'clinical practice', 'deep learning', 'density', 'early detection biomarkers', 'graft failure', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'interstitial', 'kidney biopsy', 'learning strategy', 'living kidney donor', 'member', 'microscopic imaging', 'non-invasive imaging', 'novel', 'novel imaging technology', 'personalized decision', 'precision medicine', 'prognostic value', 'programs', 'radiological imaging', 'research clinical testing', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,R03,2021,119250,276703803
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,10054168,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Height', 'Human', 'Image', 'Image Analysis', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Visualization', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'detection sensitivity', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'screening guidelines', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,120631,551214295
"Super-Resolution Tau PET Imaging for Alzheimer's Disease PROJECT SUMMARY Preclinical Alzheimer’s disease (the presymptomatic phase of Alzheimer’s disease) is characterized by pathophysiological changes without measurable cognitive decline and begins decades before the onset of cognitive symptoms. Preclinical Alzheimer’s disease research is in pressing need of new biomarker endpoints to enable disease monitoring before traditional cognitive endpoints are measurable. The overarching research objectives of this R03 Small Project Grant are to develop a super-resolution (SR) positron emission tomography (PET) imaging framework for tau (a pathophysiological hallmark of Alzheimer’s disease) and to assess the clinical utility of localized outcome measures obtained from SR PET images. Studies show that tau pathology in the medial temporal lobe is an important marker of cognitive decline in Alzheimer’s disease. Cohorts focused on preclinical Alzheimer’s now incorporate serialized 18F-flortaucipir PET scans for longitudinal tracking of tau accumulation in key anatomical regions-of-interest (ROIs). The quantitative accuracy of tau PET, however, is degraded by the limited spatial resolution capabilities of PET, which lead to inter-ROI spillover and partial volume effects. The problem is further compounded in studies spanning several decades, many of which were commenced on legacy scanners with even lower resolution capabilities than the current state of the art. Additionally, many longitudinal studies began on older scanners and later transitioned to newer models posing a multi-scanner data harmonization challenge. The proposed SR framework will perform a mapping from a low- resolution scanner’s image domain to a high-resolution scanner’s image domain and enable PET resolution recovery and data harmonization. Underlying the proposed framework is a neural network model that can be adversarially trained in self-supervised mode without requiring paired input/output image samples for training. This critical feature ensures practical clinical utility of the method as the need for paired low-resolution and high- resolution datasets from the same subject with similar tracer dose and scan settings is a major barrier for the clinical translatability of simpler supervised alternatives for SR. The proposed network, although trained using unpaired clinical data, receives guidance from an ancillary neural network separately pretrained using paired simulation datasets. For this purpose, we will synthesize paired low- and high-resolution images from a series of digital tau phantoms that will be created for this project. Training and validation of the self-supervised SR framework will be performed via secondary use of de-identified 18F-flortaucipir PET scans from the Harvard Aging Brain Study, a longitudinal cohort focused on preclinical Alzheimer’s disease. We will evaluate SR performance using a variety of image quality metrics. To assess the clinical utility of localized super-resolution measures, we will perform cross-sectional statistical power analyses that estimate sample sizes per arm needed to power clinical trials. Accurate localized measures of tau generated by this project could enable early diagnosis of Alzheimer’s disease and facilitate ongoing clinical trials by reducing sample sizes required for a given effect size. PROJECT NARRATIVE The objective of this R03 Small Project Grant is to develop methods for generating high-resolution images of abnormal tau protein tangles, which are a hallmark of Alzheimer’s disease. This will be achieved by building a self-supervised super-resolution framework based on a deep neural network for positron emission tomography (PET) imaging of tau. The proposed imaging technique can facilitate early diagnosis and accurate monitoring of Alzheimer’s disease.",Super-Resolution Tau PET Imaging for Alzheimer's Disease,10118776,R03AG070750,"['Address', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease diagnosis', 'Anatomy', 'Artificial Intelligence', 'Binding', 'Biological Markers', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cognitive', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Disease Progression', 'Dose', 'Early Diagnosis', 'Early Intervention', 'Ensure', 'Evaluation', 'Funding Opportunities', 'Future', 'Goals', 'Grant', 'Image', 'Imaging Techniques', 'Impaired cognition', 'Lead', 'Longitudinal Studies', 'Longitudinal cohort', 'Longitudinal cohort study', 'Measurable', 'Measures', 'Medial', 'Memory impairment', 'Methods', 'Modeling', 'Monitor', 'Names', 'Neural Network Simulation', 'Neurobehavioral Manifestations', 'Neurofibrillary Tangles', 'Outcome Measure', 'Output', 'Pathology', 'Performance', 'Phase', 'Positron-Emission Tomography', 'Recovery', 'Research', 'Resolution', 'Sample Size', 'Sampling', 'Scanning', 'Series', 'Statistical Data Interpretation', 'Supervision', 'Surrogate Markers', 'Techniques', 'Technology', 'Temporal Lobe', 'Tracer', 'Training', 'Treatment Efficacy', 'Validation', 'aging brain', 'arm', 'base', 'clinically translatable', 'cohort', 'data harmonization', 'deep learning', 'deep neural network', 'digital', 'drug development', 'high resolution imaging', 'high risk', 'human subject', 'improved', 'in vivo', 'innovation', 'interest', 'neural network', 'neural network architecture', 'neuroimaging', 'neuroimaging marker', 'novel', 'power analysis', 'pre-clinical', 'radioligand', 'radiotracer', 'rate of change', 'response', 'simulation', 'tau Proteins', 'tau aggregation', 'tau mutation']",NIA,UNIVERSITY OF MASSACHUSETTS LOWELL,R03,2021,151980,7208224
"Enabling Kinematic Joint Profiling Using MRI Project Summary We propose a technical feasibility study seeking to develop methods for quantitative kinematic proﬁling of moving joints using magnetic resonance imaging (MRI). In the context of this study, a kinematic proﬁle is deﬁned as a collection of joint characteristics computed and tracked during the course of movement. This project is motivated by the hypothesis that such proﬁling of moving joints can highlight dysfunction, treatment progress, and point towards favorable (or unfavorable) surgical interventions. At a high level, it is envisioned that the proposed kinematic proﬁles could ﬁt into clinical management workﬂows much in the same way as blood biomarker panels.  While kinematic imaging of joints can be performed using plain-ﬁlm (PF) X-ray, computed tomography (CT), and ultrasound (US) methods, MRI is the gold-standard for advanced orthopedic assessment and is an appealing option for accessory kinematic analysis. A set of relatively fast kinematic proﬁling acquisitions could feasibly be added to routine orthopedic MRI exams, thereby providing optimal diagnostic imaging in both static and kinematic contexts within a single visit.  Though several preliminary studies have hinted at the potential diagnostic value of kinematic imaging data, such data is difﬁcult to interpret and cannot easily be quantiﬁed or captured in clinical records. In this study, we seek to establish fundamental methods that can provide simple and easily digestible kinematic imaging reports with data acquired in a short scan interval using conventional clinical MRI equipment.  As a preliminary feasibility investigation of these methods, kinematic imaging of the wrist will be studied. Dysfunction of the scaphoid and lunate bones in the wrist is a well-studied kinematic problem of diagnostic signiﬁcance. Novel 4D zero-echo-time MRI of the wrist will be used to capture the kinematic imaging using for proﬁling of the scaphoid-lunate mechanics during two established wrist movement patterns.  The goal of this project is to establish and demonstrate methodological components required for MRI kinematic proﬁling. Data collection on a modest-sized cohort of 100 healthy control subjects is proposed for this purpose. Novel MRI pulse-sequence and post-processing development components are introduced and tasked for analysis of this normative data. Using the acquired MRI data, kinematic parameters for each dynamic dataset will be extracted and curated into a multi-parametric proﬁle for each subject.  Aim 2 of the study proposes the use of external sensor motion capture methods to validate the MRI-based kinematic parameter measurements on 50% of the study cohort.  Finally, Aim 3 of the study seeks to use machine-learning clustering approaches to develop a kinematic proﬁle normalization procedure using the acquired control dataset. Such normalization is a crucial milestone in the translation of kinematic proﬁling to the clinic and will establish a baseline for future translational studies of symptomatic cohorts. Project Narrative We seek to develop and demonstrate fundamental methods in quantitative kinematic proﬁling using clinical diagnostic imaging equipment. This technical development project is constructed under the hypothesis that such proﬁling of moving joints can highlight dysfunction, treatment progress, and point towards favorable (or unfavorable) surgical interventions. Using currently available advanced magnetic resonance imaging technology, data collected from a controlled subject cohort will be used to develop and test the proposed kinematic proﬁling technology on the moving wrist.",Enabling Kinematic Joint Profiling Using MRI,10107769,R21AR075327,"['3-Dimensional', 'Age', 'Algorithms', 'Anatomy', 'Biological Process', 'Biomechanics', 'Blood', 'Blood flow', 'Cardiovascular system', 'Cartilage', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Data', 'Data Collection', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Imaging', 'Disease', 'Equipment', 'Feasibility Studies', 'Film', 'Functional Imaging', 'Functional disorder', 'Future', 'Geometry', 'Goals', 'Gold', 'Hand', 'Image', 'Imaging technology', 'Investigation', 'Joints', 'Ligaments', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Orthopedics', 'Patient risk', 'Patients', 'Pattern', 'Physiologic pulse', 'Physiological', 'Population Control', 'Positioning Attribute', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Protocols documentation', 'Records', 'Reporting', 'Resolution', 'Rest', 'Rewards', 'Roentgen Rays', 'Scanning', 'Scaphoid bone', 'Semilunar Bone', 'Series', 'Structure', 'Surgeon', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Ultrasonography', 'Upper Extremity', 'Visit', 'Work', 'Wrist', 'Wrist joint', 'X-Ray Computed Tomography', 'base', 'biomarker panel', 'blood perfusion', 'bone', 'clinical diagnostics', 'clinical practice', 'cohort', 'heart function', 'high resolution imaging', 'human subject', 'image registration', 'imaging Segmentation', 'imaging modality', 'interest', 'joint mobilization', 'kinematics', 'motion sensor', 'novel', 'radiologist', 'soft tissue', 'task analysis', 'tool', 'translational study', 'volunteer', 'water diffusion']",NIAMS,MEDICAL COLLEGE OF WISCONSIN,R21,2021,152064,122662885
"Deep Learning Assessment of the Right Ventricle: Function, Etiology, and Prognosis ABSTRACT Heart failure imposes a tremendous burden of morbidity and mortality, costing the United States in excess of $31 billion annually. An increasingly recognized major determinant of outcomes in heart failure is right ventricular (RV) dysfunction. However, the nature and character of RV contribution to cardiovascular outcomes remains poorly understood, largely due to the imprecision of imaging and interpretation of RV morphology and function. Echocardiography, with its high temporal resolution and low cost of acquisition, serves as frontline cardiovascular imaging and a mainstay in approaches to assessing RV morphology and function. However, echocardiographic imaging of the RV is limited by factors that include technical variation in image acquisition and heterogeneity in image assessment as well as overall interpretation. We postulate that deep learning based phenotyping can offer the ability to not only more precisely characterize RV function but also classify RV imaging phenotypes according to etiologic disease states and, even further, refine prognostic evaluations of future cardiovascular risk. Therefore, in Aim 1, we will use video-based deep learning segmentation models to assess RV function, evaluate its cross-sectional relation with a range of expert-measured parameters, and examine its variation in the context of patient characteristics derived from large hospital-based cohorts. In Aim 2, we will use video-based deep learning models to produce imaging-based classification of RV disease and assess the ability of unsupervised approaches to classify RV dysfunction into various categories of disease etiology. In Aim 3, we will use models developed in part from training in Aims 1 and 2 to predict major cardiovascular outcomes including heart failure in addition to coronary artery disease, stroke, and cardiovascular death in both hospital- based and community-based cohorts. The overarching goal of this proposal is to improve the precision and standardization of RV phenotyping and determine the extent to which deep learning models can augment human assessment of the RV. This research will be accomplished in the setting of a comprehensive career development program designed to provide the candidate with the skills needed to become an independent physician-scientist in cardiovascular medicine and translational imaging science. An advisory committee of established scientists/mentors in the fields of cardiac imaging, deep learning, data science, and translational science will guide the candidate in his transition to scientific independence over the course of the award period. PUBLIC HEALTH RELEVANCE STATEMENT Heart failure imposes a tremendous morbidity and mortality burden, costing the U.S. healthcare system over $31 billion per year. An under-recognized and yet important contributor to heart failure outcomes is right ventricular dysfunction, which remains understudied due to technical issues that have historically challenged conventional approaches to cardiovascular imaging. We will examine how deep learning models can precisely evaluate right ventricular function – and enable earlier, more accurate assessments of its contributions to cardiovascular risk.","Deep Learning Assessment of the Right Ventricle: Function, Etiology, and Prognosis",10185865,K99HL157421,"['Address', 'Advisory Committees', 'Architecture', 'Arrhythmogenic Right Ventricular Dysplasia', 'Award', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Cohort Studies', 'Communities', 'Computer Vision Systems', 'Coronary Arteriosclerosis', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Diagnosis', 'Disease', 'Disease Outcome', 'Dissection', 'Early Diagnosis', 'Echocardiography', 'Engineering', 'Epidemiology', 'Etiology', 'Evaluation', 'Framingham Heart Study', 'Future', 'Goals', 'Health system', 'Healthcare', 'Healthcare Systems', 'Heart failure', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Medicine', 'Mentors', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Motion', 'Multi-Ethnic Study of Atherosclerosis', 'Nature', 'Outcome', 'Participant', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physicians', 'Program Development', 'Prospective cohort', 'Pulmonary Embolism', 'Research', 'Research Personnel', 'Right Ventricular Dysfunction', 'Right Ventricular Function', 'Right ventricular structure', 'Risk', 'Risk Factors', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Standardization', 'Stroke', 'Techniques', 'Training', 'Translational Research', 'United States', 'Validation', 'Variant', 'Ventricular', 'base', 'cardiovascular imaging', 'cardiovascular risk factor', 'career', 'career development', 'cohort', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'hands on research', 'healthcare community', 'heart imaging', 'improved', 'mortality', 'neural network', 'neural network architecture', 'novel', 'outcome forecast', 'outcome prediction', 'performance tests', 'population based', 'predictive modeling', 'prognostic', 'programs', 'public health relevance', 'pulmonary arterial hypertension', 'skills', 'spatiotemporal', 'statistics', 'study population', 'success', 'temporal measurement']",NHLBI,CEDARS-SINAI MEDICAL CENTER,K99,2021,154780,90419233
"Development of an artificial intelligence-driven, imaging-based platform for pretreatment identification of extranodal extension in head and neck cancer Project Summary. The goal of this project is to develop, optimize, and evaluate an artificial intelligence (AI)- driven, medical imaging platform that utilizes computed tomography (CT) imaging to identify the presence of extranodal extension (ENE) in head and neck squamous cell carcinoma (HNSCC). HNSCC is a debilitating disease with significant patient-related morbidity related to the disease itself and its management, which is complex and consists of a combination of surgery, radiation, and chemotherapy. A key factor in determining proper HNSCC management is the presence of ENE, which occurs when tumor infiltrates through the capsule of an involved lymph node into the surrounding tissue. ENE is both an important prognostic factor and an indication for adjuvant treatment escalation with the addition of chemotherapy to radiation following surgery. This “trimodality therapy” is problematic, as it is associated with increased treatment-related morbidity and healthcare costs, but no improvement in disease control compared to upfront chemoradiation alone. The challenge is that ENE can only be definitively diagnosed pathologically after surgery, and pretreatment radiographic ENE identification has proven unreliable for even expert diagnosticians, leading to high rates of trimodality therapy and suboptimal treatment outcomes. In HNSCC management there is a critical need for improved pretreatment ENE identification to 1) select appropriate patients for surgery to avoid the excess morbidity and costs of trimodality therapy, 2) risk-stratify patients optimally, and 3) select appropriate patients for treatment de-escalation or intensification clinical trials. In recent years, Deep learning, a subtype of machine learning, under the umbrella of AI, has generated breakthroughs in computerized medical image analysis, at times outperforming human experts and discovering patterns hidden to the naked eye. While AI is poised to transform the fields of cancer imaging and personalized cancer care, there remain significant barriers to clinical implementation. The hypothesis of this project is that AI can be used to successfully identify HNSCC ENE on pretreatment imaging in retrospective and prospective patient cohorts and to develop a platform for lymph node auto-segmentation that will promote clinical utility of the platform. This hypothesis will be tested by rigorous optimization and evaluation of a deep learning ENE identification platform. Specifically, the platform will be validated for accuracy, sensitivity, specificity, and discriminatory performance on two heterogeneous retrospective datasets and two prospective cohorts derived from institutional and national Phase II clinical trials for HNSCC patients. The platform will then be directly compared with head and neck radiologists to determine if radiologist performance can be augmented with AI. In parallel, AI will be utilized to develop an auto-segmentation platform for tumor and lymph nodes, which will 1) improve the platform's clinical impact and 2) provide a valuable tool for treatment planning and future imaging-based research for HNSCC patients. 1 Project Narrative Identification of extranodal extension (ENE) for head and neck cancer in the pretreatment setting would be extremely useful in selecting the optimal treatment strategy for patients. Currently, ENE can only be definitively diagnosed pathologically after surgery, and pretreatment radiographic ENE prediction has proven unreliable for expert diagnosticians. This project uses artificial intelligence to identify ENE pretreatment on Computed Tomography, with the goal of developing a clinically usable tool to help patients with newly diagnosed head and neck cancers and their physicians choose the most effective treatment strategy that minimizes the risk of side effects.","Development of an artificial intelligence-driven, imaging-based platform for pretreatment identification of extranodal extension in head and neck cancer",10105483,K08DE030216,"['Adjuvant', 'Algorithms', 'Artificial Intelligence', 'Biopsy', 'Clinic', 'Clinical', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Enrollment', 'Evaluation', 'Extranodal', 'Eye', 'Foundations', 'Future', 'Geography', 'Goals', 'Head', 'Head and Neck Cancer', 'Head and Neck Squamous Cell Carcinoma', 'Head and neck structure', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Institution', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Medical Imaging', 'Morbidity - disease rate', 'Neck Dissection', 'Newly Diagnosed', 'Operative Surgical Procedures', 'Output', 'Pathologic', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phase II Clinical Trials', 'Physicians', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Prognostic Factor', 'Prospective cohort', 'Radiation', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Scientist', 'Sensitivity and Specificity', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'cancer imaging', 'capsule', 'chemoradiation', 'chemotherapy', 'clinical implementation', 'cohort', 'computerized', 'cost', 'deep learning', 'design', 'disorder control', 'effective therapy', 'heuristics', 'imaging platform', 'improved', 'insight', 'interest', 'lymph nodes', 'neural network', 'neural network architecture', 'novel', 'optimal treatments', 'patient stratification', 'personalized cancer care', 'phase II trial', 'prediction algorithm', 'prospective', 'prospective test', 'radiologist', 'radiomics', 'risk minimization', 'side effect', 'success', 'therapy development', 'tool', 'treatment planning', 'treatment strategy', 'tumor']",NIDCR,BRIGHAM AND WOMEN'S HOSPITAL,K08,2021,168240,327644200
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,10077550,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2021,190362,2135841
"Content-based MR-TRUS Fusion without Tracking There are about 3 million American men living with prostate cancer, the second leading cause of cancer death for men in the United States. If the prostate cancer is caught early before it spreads to other parts of the body, by active monitoring or treatment, most men will not die from it. Nevertheless, 22% to 47% of the patients with negative biopsies but elevated prostate-specific antigen levels may still harbor malignant tumors, which can be life threatening and could have been missed by the commonly used ultrasound guided random biopsy. By contrast, fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted biopsies has shown to significantly improve the cancer detection rate. However, MR-TRUS fusion itself is very challenging due to the difficulties in directly registering images of these two very different modalities in different dimensions. To bypass the difficult registration problems, the existing fusion techniques require the use of specialized expensive and cumbersome hardware tracking devices, which increases cost and elongates procedures. More importantly, due to a number of factors such as patient movement, respiratory motion and ultrasound transducer pressure change, prostate motion can happen during a procedure and cause the images to be misaligned. Timely noticing and correcting such motion require great skill and knowledge of radiological imaging, where studies show a steep learning curve for mastering fusion systems. Failing in image registration and motion compensation renders the fusion guided biopsy performing no differently than random biopsy. To address the fundamental cause of the problems, the goal of this project is to create enabling technology of MR- TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs. Recent advancement in machine learning, especially deep learning, has provided us new tools and new angles to tackle this challenging problem. This project aims for directly fusing 2D TRUS frames with 3D MR volume by developing novel deep learning methods for image reconstruction and registration. The proposed methods are designed to exploit both population and patient specific imaging information to accurately align images. As all learning-based image registration methods try to better use population knowledge to improve the registration performance, few of them have been able to efficiently use patient specific information, which can be essential to obtain robust and accurate performance. Upon successful completion, the innovation created from the project will disrupt the common perception that hardware tracking has to be used for multimodal image fusion-guided interventions and alleviate the demand on physicians’ experience and skill in image analysis and fusion to help obtain consistent results. This project will lead to the development of novel prostate biopsy systems and will also impact a range of other image fusion based interventional guidance technologies. Fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted prostate biopsies can significantly improve the detection of aggressive cancer. The goal of this project is to create enabling technology of MR-TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs.",Content-based MR-TRUS Fusion without Tracking,10140348,R21EB028001,"['3-Dimensional', 'Address', 'American', 'Area', 'Biopsy', 'Body part', 'Bypass', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Cyst', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'E-learning', 'Early Diagnosis', 'Electromagnetics', 'Financial compensation', 'Foundations', 'Future', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Intelligence', 'Intervention', 'Kidney', 'Knowledge', 'Learning', 'Life', 'Liver', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Manuals', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Multimodal Imaging', 'PSA level', 'Patients', 'Perception', 'Performance', 'Physicians', 'Population', 'Pressure Transducers', 'Procedures', 'Prostate', 'Psychological Transfer', 'Research', 'Retrospective Studies', 'Risk Assessment', 'Slice', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Thinness', 'Time', 'Training', 'Transrectal Ultrasound', 'Ultrasonic Transducer', 'Ultrasonography', 'United States', 'base', 'calcification', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'experience', 'image reconstruction', 'image registration', 'imaging modality', 'imaging study', 'improved', 'innovation', 'learning strategy', 'men', 'next generation', 'novel', 'patient population', 'population based', 'prostate biopsy', 'radiological imaging', 'reconstruction', 'research clinical testing', 'respiratory', 'skills', 'tool']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R21,2021,192513,12471676
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for training—a typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training data—a typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,10116379,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2021,195000,135644722
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10226322,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data repository', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2021,220287,570146095
"Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging PROJECT SUMMARY/ABSTRACT There has been significant work in creating tools that leverage computer vision algorithms to automate medical image analysis. Most of these algorithms have been developed for natural images, which are usually single static images that can be treated individually. However, medical images are usually part of a study that may include various views and orientations that are considered together with other clinical data when making a diagnosis. Three dimensional convolution neural networks (CNN) can address this issue in part when images are evenly spaced, but many medical imaging modalities such as ultrasound (US), fluoroscopy, and biopsy imaging have variable orientations and irregular spacing. Graph convolutional networks (GCN) have the potential to address this issue as they generalize the assumptions of CNNs to work on arbitrarily structured graphs. Automatic thyroid nodule detection in ultrasound (US) is one application that such a graph-based approach could have a large impact. The thyroid cancer incidence rate has tripled in the past thirty years, with an estimated cost of $18-21 billon in 2019. US is the imaging modality of choice, which consists of multiple 2D images of different locations and orientations. US readings are often vague and subjective in nature, which has resulted in a steady increase in the number of biopsies performed over the past 20 years. It is estimated that about one-third of all thyroid biopsy procedures performed in the United States are medically unnecessary, leading to the unmet need for noninvasive diagnostic tests that can reliably identify which nodules require a biopsy. The research objective of this R21 is to develop a new graph-based approach to leverage spatial information contained within imaging studies that will be combined with biomarkers and other known risk factors. Our graph model will enable more complete detection of thyroid cancer, as well as the prediction of future cancer aggression, both with spatially localized explanations. GCN features will be used to predict voxel-level cancer suspicion, thereby enabling a novel method for performing “imaging biopsy.” Finally, voxel-level suspicion maps will be aggregated into patient-level quantitative imaging biomarkers and combined with clinical data to create a multimodal nomogram for performing risk stratification. PROJECT NARRATIVE Medical image analysis plays an important role in computer aided detection and diagnosis, but usually focuses on individual images in isolation. Graph convolutional networks have the ability to utilize the relationships be- tween images in a study to aggregate information and make a more accurate evaluation. The focus of this project is to implement a graph-based approach for distinguishing indolent from aggressive thyroid cancer, thus pre- venting patients from receiving unnecessary treatment and incurring associated negative functional outcomes.",Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging,10110934,R21EB030691,"['3-Dimensional', 'Address', 'Age', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Attention', 'Biological Markers', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Diagnostic tests', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fluoroscopy', 'Functional disorder', 'Future', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'Indolent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Manuals', 'Maps', 'Medical', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Nodule', 'Nomograms', 'Pathology', 'Patient risk', 'Patients', 'Pattern', 'Physiological', 'Play', 'Probability', 'Procedures', 'Protocols documentation', 'Reading', 'Research', 'Risk', 'Risk Factors', 'Risk stratification', 'Role', 'Savings', 'Series', 'Signal Transduction', 'Structure', 'Techniques', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Tweens', 'Ultrasonography', 'United States', 'Work', 'base', 'body system', 'cancer imaging', 'cancer risk', 'clinical imaging', 'clinically significant', 'computer aided detection', 'convolutional neural network', 'cost estimate', 'deep learning', 'detection platform', 'functional outcomes', 'image registration', 'imaging biomarker', 'imaging modality', 'imaging study', 'innovation', 'mortality', 'multimodality', 'network models', 'noninvasive diagnosis', 'novel', 'patient stratification', 'predictive modeling', 'prevent', 'quantitative imaging', 'radiologist', 'tool', 'treatment planning', 'unnecessary treatment', 'ward']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,224566,673201228
"FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring Project Abstract/Summary Ultra-low dose CT, defined as sub-millisievert (sub-mSv) imaging of the entire chest, abdomen or pelvis, is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, photon starvation and electronic noise make imaging at such dose levels challenging. Photon starvation refers to the number of transmitted photons. When no photons are transmitted, the measurement is essentially useless. If few photons are transmitted, the measurement carries information, but its interpretation and value are confounded by electronic noise. Solutions with encouraging results have been offered for sub-mSv chest imaging, but these are not widely available and not easily generalizable across anatomical sites, vendors and scanner models. We propose a novel, robust solution for ultra-low dose CT that will overcome these issues. We refer to our solution as FAIR-CT, which stands for Finite-Angle Integrated-Ray CT. FAIR-CT operates under the principle that photon starvation and the confounding effect of electronic noise are best handled by avoiding them, which is made possible by increasing the data integration time during the source-detector rotation. FAIR-CT data strongly deviate from the classical CT data model and share the streak artifact problem of sparse view sampling. FAIR-CT data acquisition also affects azimuthal resolution. We anticipate that these issues can be suitably handled using advanced image reconstruction techniques. Once available, FAIR-CT will allow improvements in longitudinal monitoring of patients with chronic diseases such as COPD, urolithiasis and diabetes, thereby reducing mortality and co-morbidities. FAIR-CT will also allow advancing cancer therapy treatments by enabling adjustments in radiation therapy plans between dose fractions without increasing CT radiation exposure, and by facilitating early detection of inflammations in drug-based therapies. To bring FAIR-CT towards fruition, we will work on two specific aims: (1) Creation of a comprehensive collection of FAIR-CT data sets enabling rigorous development, validation and evaluation of image reconstruction algorithms; (2) Development, validation and evaluation of advanced image reconstruction algorithms. The FAIR-CT data sets will involve the utilization of state-of-the-art scanners and include real patient data synthesized from high dose scans acquired for standard of care. Two complementary image reconstruction approaches will be investigated. Namely, model-based iterative reconstruction with non-linear forward model and dedicated compressed sensing regularization; and deep learning-based refinement of FBP reconstructions using target images with task-adapted image quality. Image quality evaluation will account for critical biological variables and involve objective metrics such as structure similarity and contrast-to-noise ratio for clinically-proven lesions, as well as task-based performance metrics involving human readers. Ultra-low dose X-ray computed tomography is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, physics-related challenges and impractical solutions make this concept unavailable for everyday clinical use. We will develop a novel solution that is practical and can quickly be brought to clinical practice.",FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring,10158473,R21EB029179,"['Abdomen', 'Academia', 'Advanced Malignant Neoplasm', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Body mass index', 'Chest', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Clinical', 'Collection', 'Computers', 'Cystic Fibrosis', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Dose', 'Early Diagnosis', 'Epidemic', 'Evaluation', 'Fruit', 'Goals', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Industry', 'Inflammation', 'Inflammatory Bowel Diseases', 'Lesion', 'Malignant Neoplasms', 'Measurement', 'Metabolic Diseases', 'Modeling', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Noise', 'Obesity', 'Patient Monitoring', 'Patients', 'Pelvis', 'Performance', 'Pharmaceutical Preparations', 'Photons', 'Physics', 'Polycystic Kidney Diseases', 'Process', 'Pulmonary Inflammation', 'Radiation exposure', 'Radiation therapy', 'Radiology Specialty', 'Reader', 'Research', 'Resolution', 'Rotation', 'Sampling', 'Scanning', 'Source', 'Starvation', 'Structure', 'Techniques', 'Technology', 'Time', 'Validation', 'Vendor', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer risk', 'cancer therapy', 'clinical practice', 'clinical translation', 'clinically translatable', 'comorbidity', 'data acquisition', 'data integration', 'data modeling', 'data sharing', 'deep learning', 'detector', 'expectation', 'image reconstruction', 'improved', 'low dose computed tomography', 'mortality', 'novel', 'reconstruction', 'sex', 'side effect', 'standard of care', 'targeted imaging', 'urolithiasis']",NIBIB,UNIVERSITY OF UTAH,R21,2021,227282,228951281
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,10170765,R21EB025621,"['Abdomen', 'Acoustics', 'Adult', 'Age', 'Anatomy', 'Area', 'Award', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Evaluation', 'Excision', 'Family suidae', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Measurement', 'Metals', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translations', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization', 'Work', 'algorithm training', 'base', 'convolutional neural network', 'cost', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'metallicity', 'obese patients', 'obese person', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2021,235027,807432003
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,R21EY032567,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2021,242250,685608202
"Reading workstation for clinical contrast echocardiography Proposal Summary There is increasing appreciation of a syndrome in which patients female patients, present with chest pain due to myocardial ischemia and have a normal or near normal coronary angiogram. Termed coronary microvascular dysfunction (MVD) this disorder is not benign with cardiovascular event rates similar to those with established coronary artery disease. Clinical tools are therefore needed to both identify MVD patients and better understand the mechanisms causing myocardial ischemia. There is evidence that myocardial contrast echocardiography (MCE) provides incremental information in the evaluation of patients with coronary artery disease, myocardial viability, or diseases of the microvasculature. Despite data demonstrating the diagnostic and prognostic benefit of MCE in evaluating patients with MVD, its clinical use has been limited to only a handful of experts in the field, because there are currently no widely available clinical tools to support MCE quantitative analysis and interpretation. The overall aim of this Phase I proposal is to provide clinicians with a new tool to evaluate the myocardial flow-function relationship that is critical to identifying patients with MVD by using echocardiography. We will develop clinical software that can rapidly process MCE data into a standardized, quantitative and easy- to- interpret format. In Aim 1, the power of image averaging and computer aided assessment of radial wall thickening will be used to enhance the current standard of care which relies solely on readers' visual estimation of segmental function. An algorithm will be developed to rearrange the order of images so that images representing the same phase of the cardiac cycle are grouped together. Functional analysis will then be developed using computer-aided tracings of epicardial and endocardial borders. In Aim 2, a software module for quantitative analysis of real-time MCE perfusion will be developed that will incorporate statistical confidence, derived from the performance of image processing algorithms to inform the interpreter about the data strength. Machine learning will be utilized to train and deploy a neural network for the pixel-by-pixel assessment of myocardial perfusion. In Aim 3, we will combine myocardial perfusion and function modules into a novel, perfusion-function mode of imaging (PF-mode). This new mode will be applied to an archival sample of clinically diagnosed MVD cases to demonstrate the feasibility to detect abnormalities in the myocardial flow-function relationship. The composite PF-mode will include a cine-loop rendered for one cardiac cycle where parametric images (perfusion) are superimposed over averaged ultrasound images with an overlay of graphic representation of wall thickness (function). This novel mode of imaging provides the means to diagnose MVD in a single clinical study. Project Narrative Project Title: Reading workstation for clinical contrast echocardiography Despite a wealth of evidence that myocardial contrast echocardiography imaging of myocardial perfusion provides incremental information in the evaluation of patients with diseases of the myocardial microvasculature (MVD), its clinical use has been limited to only a handful of experts in the field. In this proposal, we have created a multidisciplinary partnership between physicians-scientists and engineers with the overall aim to address this clinical gap that exists between a proven echocardiographic technique and the technology necessary to enable widespread adoption of MCE clinically. We will develop a software program enabling a new method for evaluating the myocardial flow-function relationship using echocardiography that will enable the identification of MVD using MCE studies at the level of expert readers.",Reading workstation for clinical contrast echocardiography,10155647,R43HL152939,"['Address', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Apical', 'Benign', 'Blood', 'Blood Flow Velocity', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular system', 'Chest Pain', 'Classification', 'Clinical', 'Clinical Research', 'Clip', 'Code', 'Color', 'Computer Assisted', 'Computer software', 'Computers', 'Contrast Echocardiography', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Echocardiography', 'Engineering', 'Evaluation', 'Event', 'Eye', 'Female', 'Guidelines', 'Image', 'Imaging Techniques', 'Machine Learning', 'Mechanics', 'Medical', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Myocardial', 'Myocardial Ischemia', 'Myocardial perfusion', 'Names', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Physicians', 'Process', 'Radial', 'Reader', 'Reading', 'Recommendation', 'Rest', 'Scientist', 'Side', 'Societies', 'Software Engineering', 'Standardization', 'Stress', 'Syndrome', 'Techniques', 'Technology', 'Thick', 'Time', 'Training', 'Ultrasonography', 'Vendor', 'Visual', 'arteriole', 'base', 'clinical Diagnosis', 'endothelial dysfunction', 'image processing', 'imaging software', 'indexing', 'multidisciplinary', 'neural network', 'novel', 'parametric imaging', 'perfusion imaging', 'prognostic', 'programs', 'sample archive', 'single photon emission computed tomography', 'standard of care', 'tool', 'user-friendly']",NHLBI,"NARNAR, LLC",R43,2021,252399,0
"Multi-atlas and whole body radiomics approaches for image-guided treatment of gynecologic cancers ABSTRACT  Gynecologic cancers are among the leading causes of cancer death in women worldwide. These patients typically are socioeconomically disadvantaged, with poor access to screening and vaccination. Consequently, they often present with locoregionally advanced disease, for which pelvic radiotherapy (RT) with concurrent cisplatin (i.e., chemoradiotherapy) is the standard of care. This treatment is limited, however, by high rates of treatment failure. Intensifying treatment through the delivery of chemotherapy doublets, either concurrently or as adjuvant therapy following chemoradiotherapy, is a promising strategy to improve outcomes. However, the delivery of intensive chemotherapy is complicated by high rates of gastrointestinal and hematologic toxicity. Strategies to reduce toxicity while increasing efficacy of chemoradiotherapy are needed.  Standard pelvic RT techniques encompass large volumes of normal tissue including bowel, bone marrow, bone, bladder, and rectum, leading to preventable radiation-induced toxicity. Image-guided radiation therapy (IGRT) can improve target localization and dosimetry, optimizing target dose while minimizing dose to surrounding normal tissues. However, IGRT can be highly resource intensive, and comparative effectiveness trials have been lacking. For this reason, there is considerable controversy as to the utility of IG-IMRT in this disease. Our research group has been at the forefront of developing novel, cost-effective IGRT approaches with wide potential to facilitate better delivery of concurrent and/or adjuvant chemotherapy.  Previously we have found that radiation-induced injury to hematopoietically active bone marrow is a critical determinant of tolerance to intensive chemotherapy. Using machine learning methods, we recently developed a multi-atlas-based IGRT method that can predict canonical distributions of active bone marrow, which can obviate the need for positron emission tomography (PET) in settings where this technology is unavailable or unaffordable. The proposed new research will study the ability of multi-atlas-based IGRT to reduce hematologic toxicity and improve chemotherapy delivery compared to standard treatment, using data from 450 patients enrolled to a randomized phase III trial (NRG-GY006). Furthermore, we will use serial whole body PET/CT to study the impact of radiation dose and chemotherapy intensity on the compensatory hematopoietic response, and have developed novel whole body radiomics biomarkers to quantify the inflammatory state, which we hypothesize can influence patients' outcomes and tolerance to chemotherapy.  The new research extends our work associated with a current R01 grant (1R01CA197059-01) to conduct correlative science associated with the GY006 trial. The overarching goal of this research line is to augment the therapeutic ratio of chemoradiotherapy for pelvic cancers using advanced image-guided radiation techniques. If successful, this research would significantly alter the approach to the treatment of many pelvic malignancies for which chemoradiotherapy is standard. PROJECT NARRATIVE In this study, we will test the ability of a novel method called multi-atlas-based image guided radiation therapy (IGRT) to reduce acute hematologic toxicity and improve chemotherapy delivery compared to conventional RT, which could obviate the need for expensive functional imaging in socioeconomically disadvantaged and resource constrained populations, such as patients with gynecologic cancers. In addition, we will use serial positron emission tomography to study effects of chemotherapy and radiation on the subacute compensatory hematopoietic response, and will seek to develop and validate novel whole body radiomics models of the inflammatory state as predictive biomarkers for gynecologic cancers. We are in an optimal situation to conduct impactful and innovative research in the context of an ongoing phase III cooperative group randomized registration trial (NRG GY006), affording us the opportunity to conduct rigorous correlative science on a large sample with high data quality, quality assurance, and carefully controlled treatment effects.",Multi-atlas and whole body radiomics approaches for image-guided treatment of gynecologic cancers,10108128,R01CA255780,"['Acute', 'Adjuvant Chemotherapy', 'Adjuvant Therapy', 'Aftercare', 'Aging', 'Atlases', 'Biological Markers', 'Bladder', 'Bone Marrow', 'Cancer Etiology', 'Cancer Patient', 'Cessation of life', 'Chemotherapy and/or radiation', 'Cisplatin', 'Consumption', 'Data', 'Dependence', 'Disease', 'Distant', 'Dose', 'Effectiveness', 'Enrollment', 'Functional Imaging', 'Goals', 'Grant', 'Hematology', 'Hematopoiesis', 'Hematopoietic', 'Inflammatory', 'Injury', 'Intensity-Modulated Radiotherapy', 'Intestines', 'Malignant Female Reproductive System Neoplasm', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Neck', 'Normal tissue morphology', 'Organ', 'Outcome', 'Patient Selection', 'Patient-Focused Outcomes', 'Patients', 'Pelvic Cancer', 'Pelvis', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Positron-Emission Tomography', 'Predictive Factor', 'Process', 'Radiation', 'Radiation Dose Unit', 'Radiation therapy', 'Randomized', 'Rectum', 'Recurrence', 'Research', 'Resources', 'Sampling', 'Science', 'Site', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Toxic effect', 'Treatment Failure', 'Treatment outcome', 'Triapine', 'Vaccination', 'Woman', 'Work', 'advanced disease', 'base', 'bone', 'chemoradiation', 'chemotherapy', 'comparative effectiveness trial', 'cost', 'cost effective', 'data quality', 'dosimetry', 'fluorodeoxyglucose positron emission tomography', 'gastrointestinal', 'image guided', 'image guided radiation therapy', 'image-guided radiation', 'imaging approach', 'imaging biomarker', 'improved', 'improved outcome', 'innovation', 'machine learning method', 'mortality', 'novel', 'personalized medicine', 'phase III trial', 'predictive marker', 'quality assurance', 'radiation-induced injury', 'radiomics', 'recruit', 'response', 'screening', 'socioeconomic disadvantage', 'standard care', 'standard of care', 'tool', 'treatment effect', 'trial design', 'whole body imaging']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,276286,524978793
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10162472,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2021,283097,807432003
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876,338121506
"Assessment of ultrasound features of knee osteoarthritis in a population-based community cohort Project summary Our long-term goal is to demonstrate the utility of ultrasound for OA assessment, standardize its acquisition and scoring, and promote increased uptake of US for use in clinical, research, and trial settings. Knee osteoarthritis (KOA) is highly prevalent and frequently debilitating. Development of potential treatments has been hampered by the heterogenous nature of this common chronic condition, which is characterized by a number of subgroups, or phenotypes, with different underlying pathophysiological mechanisms. Imaging, genetics, biochemical biomarkers, and other features can be used to characterize phenotypes, but variations in data types can make it difficult to harmonize definitions. While radiography is widely used in KOA imaging, it is limited in its ability to assess early disease (when interventions are most likely to succeed) and is insensitive to change. Ultrasound (US) is a widely accessible, time-efficient and cost-effective imaging modality that can provide detailed and reliable information about all joint tissues (e.g., cartilage, meniscus, synovium, bone), and could therefore inform phenotypes in KOA (e.g., by presence of synovitis, effusion, cartilage damage, calcium crystal deposition, and popliteal cysts). Use of US is currently limited by the lack of systematically performed studies in well-characterized non-clinical populations. To address this gap and further the use of this advantageous imaging modality for KOA, we will obtain standardized US and radiography in the population- based Johnston County Health Study (JoCoHS), the new enrollment phase of the 25+ year Johnston County OA Project which includes white, African American, and Hispanic men and women aged 35-70, to achieve three aims. In Aim 1, we will determine the population prevalence (n~3000) of knee US features including cartilage and meniscal damage, synovitis/effusion, calcium crystal deposition, popliteal cysts and osteophytes overall and in key subgroups by age, sex, race/ethnicity, and symptom status. Aim 2 will allow quantification of the associations between these US features and radiographic findings and symptom scores overall and in key subgroups (e.g., those with and without radiographic KOA, by sex, by race/ethnicity). For Aim 3, we will apply novel machine learning methodologies (e.g., Direction-projection-permutation [DiProPerm] hypothesis testing, Joint and Individual Variation [JIVE], and Distance-Weighted Discrimination [DWD]) to a) develop an overall US score for symptomatic KOA and b) identify the contribution of US variables to phenotypes relevant to KOA based on general health, physical activity, and functional assessments. This study is a crucial step to establish the foundation for US as an assessment tool for clinical use, research, and clinical trials in KOA, providing unique population-based cross-sectional data regarding the utility of US and forming the basis for future longitudinal work evaluating its value and performance characteristics related to incident and progressive KOA. Project narrative Osteoarthritis is an enormous and increasing public health problem that, like many other chronic conditions, is not a single disease but a heterogeneous condition consisting of multiple subgroups, or phenotypes, with differing underlying mechanisms. Ultrasound is an accessible, time-efficient, and cost-effective imaging modality that provides invaluable data about all joint tissues involved in osteoarthritis and has the potential to identify important phenotypes. The proposed work is relevant to the NIAMS mission and represents a crucial step to establish the foundation for ultrasound as an assessment tool for use in clinics, research, and clinical trials in osteoarthritis.",Assessment of ultrasound features of knee osteoarthritis in a population-based community cohort,10158441,R01AR077060,"['Address', 'African American', 'Age', 'Area', 'Assessment tool', 'Bilateral', 'Biochemical', 'Biological Markers', 'Bone Spur', 'Calcium', 'Cartilage', 'Categories', 'Characteristics', 'Chronic', 'Claustrophobias', 'Clinic', 'Clinical', 'Clinical Assessment Tool', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Communities', 'County', 'Crystal Formation', 'Crystallization', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Discrimination', 'Disease', 'Enrollment', 'Ethnic Origin', 'Etiology', 'Foundations', 'Future', 'General Population', 'Goals', 'Health', 'Hispanics', 'Image', 'Implant', 'Individual', 'Infrastructure', 'Intervention', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Meniscus structure of joint', 'Methodology', 'Mission', 'Modality', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Nature', 'Outcome', 'Pain', 'Participant', 'Pathology', 'Performance', 'Phase', 'Phenotype', 'Physical activity', 'Popliteal Cyst', 'Population', 'Population Study', 'Prevalence', 'Public Health', 'Race', 'Receiver Operating Characteristics', 'Research', 'Risk Factors', 'Sex Differences', 'Specialist', 'Standardization', 'Subgroup', 'Symptoms', 'Syndrome', 'Synovial Membrane', 'Synovitis', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Variant', 'Woman', 'Work', 'aged', 'base', 'bone', 'cohort', 'cost', 'cost effective', 'effusion', 'follow-up', 'imaging genetics', 'imaging modality', 'individual variation', 'interest', 'men', 'novel', 'point of care', 'population based', 'recruit', 'rheumatologist', 'sex', 'uptake']",NIAMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,331837,511185245
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that “big data” clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,10165820,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Comparative Effectiveness Research', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data repository', 'clinical decision support', 'clinical imaging', 'cohort', 'cost', 'deep learning', 'diagnosis standard', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'informatics tool', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2021,345325,560644462
"Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity PROJECT SUMMARY The long-term goal of this project is to determine whether optical coherence tomography (OCT) and OCT angiography (OCTA) might lead more accurate and objective diagnosis, earlier intervention, and improved outcomes in retinopathy of prematurity (ROP). International consensus and National Institute of Health (NIH) funded clinical trials over the last 30 years have defined the phenotypic classifications, natural history, prognosis, and management of ROP. However, it is well established that due to the subjectivity of the ophthalmoscopic examination, and systematic bias between examiners, there is significant variation in treatment of the most severe forms of ROP in the real world. This leads to both under-treatment (and poor outcomes due to retinal detachment) and over-treatment (exposing neonates to the ocular and systemic risks of treatment). Roughly 20,000 babies per year develop retinal detachments (RD) due to ROP and there is strong evidence that most of these are preventable. In adult retinal vascular diseases, most notably diabetic retinopathy (DR), OCT and OCTA can detect and quantify disease features such as diabetic macular edema (DME) and retinal neovascularization (NV) before they are noted clinically, enabling earlier treatment and reducing the risk of blindness from RD. However, evaluating the use of this technology in neonates requires high speed and portable technology, and the commercially available handheld OCTs are too slow for ultra-widefield (UWF) OCT and OCTA imaging. Several groups (including our own) have published preliminary results using prototype 100 to 200 kHz swept- source (SS) OCT systems, however consistent data acquisition remains challenging due to the lack of fixation and subsequent motion in an awake neonate, which has limited the evaluation of the potential benefits of the technology in this population. Recently, there has been much interest in using artificial intelligence (AI) (specifically deep learning), which relies on high speed graphics processing units (GPUs) to provide real time OCT image processing, segmentation, and tracking. This application addresses 2 fundamental gaps in knowledge: (1) Can we overcome the technical challenges through the development of a faster ultrawide-field view SS-OCT system coupled with a GPU-enabled DL software system to enable consistent data acquisition in neonates? (2) Would quantitative objective metrics of ROP improve objectivity of ROP diagnosis and detect subclinical signs of disease progression which may enable earlier intervention and improved outcomes in the future. By leveraging our institution’s OCT, AI, and ROP expertise, we will address these questions in three specific aims: (1) Develop an ultra-high speed, handheld, panoramic ultra-widefield OCT/OCTA system. (2) Develop real time GPU accelerated intelligent image acquisition software. (3) Evaluate the clinical significance OCT derived biomarkers. Successful translation of this technology to the ROP population could improve the accuracy and objectivity of ROP diagnosis, and lead to earlier intervention and improved outcomes in patients with severe ROP. PROJECT NARRATIVE Optical Coherence Tomography (OCT) and OCT angiography (OCTA) have proven the ability to detect subclinical disease, provide quantitative evaluation of disease progression, and improve outcomes in the leading causes of blindness in adults, age-related macular degeneration and diabetic retinopathy. Technological and practical limitations have limited the application of this technology in routine use for non-sedated children undergoing routine screening for retinopathy of prematurity (ROP), the leading cause of blindness in children. The proposed project will develop an ultra-high speed, handheld OCT system with graphics processing unit (GPU) enabled real-time processing to improve the feasibility of panoramic ultra-widefield OCT/OCTA imaging in non-sedated neonates and evaluate the clinical utility of OCT-derived biomarkers in ROP.",Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity,10198930,R01HD107494,"['Address', 'Adult', 'Aftercare', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Artificial Intelligence', 'Biological Markers', 'Blindness', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Trials', 'Computer software', 'Consensus', 'Coupled', 'Cross-Sectional Studies', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Disease Progression', 'Dyes', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Evaluation', 'Eye', 'Fluorescein Angiography', 'Funding', 'Fundus', 'Future', 'Goals', 'Image', 'Image Analysis', 'Injections', 'Institution', 'Intelligence', 'International', 'Knowledge', 'Lasers', 'Lead', 'Length', 'Longitudinal Studies', 'Measurement', 'Medical Imaging', 'Methods', 'Monitor', 'Morphologic artifacts', 'Motion', 'Natural History', 'Neonatal', 'Ophthalmic examination and evaluation', 'Ophthalmoscopes', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Peripheral', 'Phenotype', 'Pilot Projects', 'Population', 'Primary Health Care', 'Publishing', 'Quantitative Evaluations', 'Retina', 'Retinal Detachment', 'Retinal Neovascularization', 'Retinopathy of Prematurity', 'Risk', 'Scanning', 'Severities', 'Severity of illness', 'Source', 'Speed', 'Structure', 'System', 'Systematic Bias', 'Technology', 'Testing', 'Time', 'Translations', 'United States National Institutes of Health', 'Variant', 'Vascular Diseases', 'Visualization', 'accurate diagnosis', 'arm', 'awake', 'base', 'blind', 'clinical Diagnosis', 'clinically significant', 'data acquisition', 'deep learning', 'design', 'diabetic', 'disease classification', 'disorder of macula of retina', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'instrument', 'interest', 'lens', 'macular edema', 'neonate', 'neovascularization', 'novel', 'outcome forecast', 'overtreatment', 'parallel computer', 'portability', 'prototype', 'real-time images', 'research clinical testing', 'routine screening', 'sample fixation', 'software systems', 'standard of care', 'treatment response', 'treatment risk']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,377300,304670088
"Robot-Assisted 3D ICE Catheter for Cardiac Ablation ABSTRACT  Although the cardiac ablation procedure for atrial fibrillation has a wide adoption rate, it also has a high recurrence of arrhythmia primarily due to the creation of suboptimal lesions. The procedure is also associated with complications including cardiac perforation, tamponade, atrio-esophageal fistulas and thrombus. Repeated and prolonged X-ray exposure for the clinician can also lead to enhanced risk of cancer. A fluoroless approach using intracardiac echocardiography (ICE) is becoming a more widely adopted imaging option due to the absence of ionizing radiation and the possibility of real-time monitoring of the created lesions. However, the ICE- guided approach suffers from significant shortcomings, which include poor dexterity of the ICE catheter, difficulty in simultaneously manipulating the ICE and ablation catheters, unintuitive image orientation and noisy image quality. There is therefore an unmet need to overcome these shortcomings of the ICE-guided approach to enable better lesion creation and reduced complications associated with the cardiac ablation procedure. The long-term goal of this research is to develop robotic technologies, control and machine learning algorithms to enable ICE- guided cardiac ablation procedures. The objective is to develop a novel robotic manipulator, a steerable ICE catheter, and machine learning and control algorithms to manipulate the ICE catheter and monitor the created lesions in real-time. The rationale that underlies the proposed research is that the robot-assisted steerable ICE catheter with the catheter tracking algorithms will enable simultaneous manipulation of the ICE and ablation catheters. Further, the machine learning algorithms to monitor therapy will reduce the risk of complications, while ensuring the creation of necrotic lesions, thereby reducing the recurrence of AF. In this proposal, we plan to pursue the following specific aims: 1) Design, develop, and model a steerable 3D ICE catheter with enhanced dexterity. 2) Design and develop a robotic manipulator and associated control algorithms to allow for precise manipulation of the ICE catheter. 3) Develop machine-learning and vision-based algorithms integrated with a navigation system for tracking the ablation catheter, and monitoring therapy. 4) Validate the robotic ICE system in heart phantom and porcine models. The proposed research is significant since it will allow for better therapeutic outcomes by reducing recurrence rates and complications associated with cardiac ablation, and avoiding exposure of the patient and clinical care team to X-ray radiation. The proposed research is innovative in that it builds on state-of-the-art robotics technology, machine learning and vision algorithms to enable fluoroless ICE- guided cardiac ablation procedures. PROJECT NARRATIVE  The proposed study addresses an important and under-investigated area of treating atrial fibrillation using a completely fluoroless approach with ICE imaging. The proposed research is significant since it will allow for better therapeutic outcomes by reducing recurrence rates and complications associated with cardiac ablation, and avoiding exposure of the patient and clinical care team to X-ray radiation.",Robot-Assisted 3D ICE Catheter for Cardiac Ablation,10187566,R01EB028278,"['3-Dimensional', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Anatomy', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Canada', 'Cardiac', 'Cardiac ablation', 'Catheters', 'Computer Vision Systems', 'Computer software', 'Coupling', 'Diagnosis', 'Early Diagnosis', 'Echocardiography', 'Ensure', 'Esophageal Fistula', 'Family suidae', 'Fluoroscopy', 'Goals', 'Grant', 'Heart', 'Heart Atrium', 'Hospitals', 'Image', 'Intuition', 'Ionizing radiation', 'Lead', 'Lesion', 'Machine Learning', 'Manuals', 'Maps', 'Medical', 'Microbubbles', 'Modeling', 'Monitor', 'Myocardium', 'Navigation System', 'Necrotic Lesion', 'Ontario', 'Operative Surgical Procedures', 'Patient Care', 'Patients', 'Perforation', 'Performance', 'Positioning Attribute', 'Procedures', 'Pulmonary veins', 'Radial', 'Recurrence', 'Research', 'Research Personnel', 'Risk', 'Robot', 'Robotics', 'Roentgen Rays', 'Surgical Instruments', 'System', 'Technology', 'Thrombus', 'Time', 'Ultrasonography', 'United States', 'Universities', 'Vision', 'Woman', 'Work', 'base', 'cancer risk', 'clinical care', 'convolutional neural network', 'deep learning algorithm', 'design', 'dexterity', 'image guided', 'innovation', 'instrument', 'kinematics', 'light weight', 'machine learning algorithm', 'machine vision', 'novel', 'radio frequency', 'real time monitoring', 'robot assistance', 'therapy outcome', 'time use']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,379119,327644200
"Robust quantitative MR imaging markers of response to therapy in Crohn’s Disease Project Summary: Crohn's disease (CD) is a chronic inflammatory disease of the gastrointestinal tract that has a prevalence of over 800,000 in the US alone. The economic impact is disproportionally high because it affects primarily young individuals. The characteristic periods of remission and relapse necessitate frequent hospitalizations. There has been a recent shift in clinical practice from a reactive to a proactive CD treatment strategy, recently coined as “treat-to-target”, where patients are treated to achieve not only an initial response-to-therapy, but also longer clinical remissions and improved mucosal healing. However, this approach requires the regular assessment of disease activity using objective markers enabling treatments to be tailored to the individual patient. Therefore, there is an unmet need for new tools to improve diagnostic accuracy, to quantify disease burden, and to monitor treatment efficacy. Our application in response to PAR-19-056, “Robust quantitative MR imaging markers of response to therapy in Crohn's disease” is aimed at developing and evaluating noninvasive, contrast and radiation-free quantitative imaging markers for assessing disease activity and for monitoring response to therapy. Currently available non-contrast MR imaging (MRI) sequences such as diffusion-weighted MRI (DW-MRI) and the calculated apparent diffusion coefficient (ADC) maps are attractive but limited in providing robust and reproducible markers. Different imaging protocols or different scanners result in different ADC values. Our primary goal is to develop robust and reliable quantitative DW-MR imaging markers for the non-contrast and non-invasive assessment of CD. The proposed novel MRI acquisition and model fitting techniques will provide measurements of slow and fast diffusion as well as fraction of fast diffusion, as highly accurate, quantitative biomarkers for cell proliferation, density and size, and tissue perfusion—all indices that characterize the extent of disease activity (i.e., inflammation) in the tissue micro-structure of the bowel. To achieve this goal, we will first develop and implement an advanced distortion and motion corrected (DiMoCo) DW-MRI technique and a spatially constrained probabilistic intravoxel incoherent motion (SPIM) model to compute robust and reproducible markers. Next, we will reduce the imaging time with estimated x4 acceleration with an accelerated image acquisition and a new, advanced deep learning-based parameter estimation technique. The proposed imaging techniques and software tools will provide robust quantitative markers, thereby enabling the accurate assessment of CD activity and response to therapy. They will also reduce the need for invasive endoscopy procedures as well as the total number of other tests typically ordered for monitoring disease, effectively reducing both the disease burden and the overall cost of healthcare. Another important goal is to develop and broadly disseminate open source software that will enable the standardized evaluation of other diseases presently evaluated with DW-MRI that would benefit from the advanced diagnostic and assessment capabilities of the proposed DiMoCo SPIM-DW-MRI technique. Project Narrative: Crohn's disease (CD) is a chronic inflammatory disease of the gastrointestinal tract that impacts over 800,000 patients in the US alone, where characteristic periods of remission and relapse necessitate frequent, costly hospitalizations and symptoms such as bloody diarrhea, abdominal pain, general malaise, and fever significantly compromise quality of life. There is a need for new tools aimed at the reliable assessment of disease activity by using objective markers to improve diagnostic accuracy, quantify disease burden, and monitor treatment efficacy, enabling subsequent treatments tailored to the individual patient's disease profile. The primary objective of this project is three-fold: First, to develop and validate a novel, noninvasive, contrast- and radiation-free quantitative MR imaging and image analysis technique, i.e., DiMoCo-SPIM that will generate robust and reproducible imaging markers from DW-MRI that will enable clinicians to more accurately assess bowel inflammation and response to therapy; second, to develop a machine learning technique that reduces the imaging time (x4 acceleration); and third, to make image analysis software developed in this proposal available in multiple clinical domains that presently evaluate various diseases with MRI and would benefit from the improved diagnostic and assessment capabilities of this computationally-driven technique.",Robust quantitative MR imaging markers of response to therapy in Crohn’s Disease,10121764,R01DK125561,"['Abdominal Pain', 'Acceleration', 'Adult', 'Affect', 'Aftercare', 'Biological', 'Biological Markers', 'Brain', 'Cell Proliferation', 'Characteristics', 'Child', 'Clinical', 'Clinical Markers', 'Coin', 'Computer software', 'Contrast Media', 'Crohn&apos', 's disease', 'Deposition', 'Diagnostic', 'Diffusion', 'Digestive System Disorders', 'Disease', 'Disease Management', 'Disease remission', 'Endoscopy', 'Estimation Techniques', 'Evaluation', 'Fever', 'Gadolinium', 'Goals', 'Health Care Costs', 'Hemorrhagic colitis', 'Hospital Costs', 'Hospitalization', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Immunomodulators', 'Individual', 'Inflammation', 'Intestines', 'Ionizing radiation', 'Laboratory Markers', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malaise', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Mucous Membrane', 'Operative Surgical Procedures', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Perfusion', 'Pharmaceutical Preparations', 'Physiological', 'Predisposition', 'Prevalence', 'Procedures', 'Protocols documentation', 'Quality of life', 'Radiation', 'Relapse', 'Reporting', 'Reproducibility', 'Respiration', 'Safety', 'Software Tools', 'Standardization', 'Structure', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'base', 'burden of illness', 'cell motility', 'chronic inflammatory disease', 'clinical decision-making', 'clinical practice', 'clinical remission', 'contrast enhanced', 'deep learning', 'density', 'diagnostic accuracy', 'diffusion weighted', 'economic impact', 'healing', 'imaging biomarker', 'imaging modality', 'imaging software', 'improved', 'indexing', 'individual patient', 'individualized medicine', 'molecular marker', 'novel', 'open source', 'quantitative imaging', 'response', 'response biomarker', 'soft tissue', 'software development', 'success', 'tool', 'treatment strategy', 'water diffusion']",NIDDK,BOSTON CHILDREN'S HOSPITAL,R01,2021,391320,209484975
"Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK) PROJECT SUMMARY  Contemporary ocular surgeries are performed by skilled surgeons through operating microscopes, utilizing freehand techniques and manually operated precision micro-instruments, where the outcomes are often limited by the surgeon's skill levels and experiences. To overcome these human factors, we have assembled an interdisciplinary team including a clinician-scientist and eye surgeon, an optical device scientist and medical robotic engineers to translate existing and developing technologies in our laboratories into precision, “deep- learning” artificial intelligence (AI) guided robotic ocular surgical devices for precise automated Deep Anterior Lamellar Keratoplasty (AUTO-DALK).  DALK is a highly attractive treatment of corneal disease with normally functioning endothelium. However, the procedure is unusually challenging from a technical perspective and time-consuming, limiting its acceptance among corneal surgeons. The most challenging aspect of the procedure is related to the delamination of stroma from Descemet's membrane (DM). A procedure, commonly called “Big Bubble” is used to separate stroma from DM using deep intrastromal pneumatic injection. However, even experienced surgeons have difficulty precisely placing the injection. The most common complication of DALK is the excessive depth of the needle insertion resulting in Descemet's membrane perforation requiring conversion to full-thickness penetrating keratoplasty with its much longer recovery period and a higher risk of graft failure from rejection. The reported rates of Descemet's membrane perforation for beginner and experienced surgeons are 31.8% and 11.7% respectively. In addition, interface haze between the donor and recipient cornea is a common problem caused by the insufficient depth of needle insertion and failure to remove the host stromal tissue, which results in loss of postoperative visual acuity. These problems relate directly to the inability of the current surgical practice to precisely assess the depth of the tooltips inside the cornea layer in real-time.  Here we will build upon our previous and ongoing work in robust fiber optic common-path optical coherence tomography (CP-OCT) and AI-guide system based on convolutional neural network (CNN) robotic microsurgical tools that enable clinicians to precisely guide surgical tools at micron scale. The proposed AUTO- DALK surgical tool system is capable of one-dimensional real-time depth tracking, motion compensation, and detection of early instrument contact with tissue, which enables clinicians to perform DALK precisely and safely. The tool will be built on a handheld platform that will consist of CP-OCT probe, trephine and microinjector that allows precise and safe removal of the anterior section of cornea down to DM  We hypothesize that AI-OCT providing intelligent visualization and depth controlled optimal cornea cutting and tissue tracking will perform the task of DALK with better accuracy and efficiency over the manually performed trephine cutting and “Big Bubble” pneumodissection. Project Narrative  This proposal addresses fundamental limitations in current corneal transplant surgery by developing an artificial intelligence guided compact robotic surgical tool that could empower corneal surgeons to achieve difficult surgical objectives, reduce intraoperative complications, and improve clinical outcomes when performing Deep Anterior Lamellar Keratoplasty (DALK). Further, these capabilities are broadly applicable in other microsurgical problems, and the tools will enable further advances both for ophthalmology and for other microsurgical disciplines.",Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK),10100636,R01EY032127,"['Accounting', 'Address', 'Adrenal Cortex Hormones', 'Animal Model', 'Anterior', 'Artificial Intelligence', 'Blindness', 'Blunt Trauma', 'Burr hole procedure', 'Cadaver', 'Clinical', 'Complication', 'Consumption', 'Cornea', 'Corneal Diseases', 'Corneal Opacity', 'Corneal dystrophy', 'Data', 'Descemet&apos', 's membrane', 'Devices', 'Dimensions', 'Discipline', 'Distal', 'Drops', 'Early Diagnosis', 'Endophthalmitis', 'Endothelial Cells', 'Endothelium', 'Engineering', 'Ensure', 'Epithelial', 'Excision', 'Expert Systems', 'Eye', 'Eye Surgeon', 'Failure', 'Fiber Optics', 'Financial compensation', 'Geometry', 'Glaucoma', 'Goals', 'Graft Survival', 'Hemorrhage', 'Human', 'Image', 'Immune', 'Incidence', 'Infection', 'Injections', 'Intelligence', 'Intraoperative Complications', 'Iris', 'Keratoconus', 'Keratoplasty', 'Laboratories', 'Lamellar Keratoplasty', 'Lead', 'Manuals', 'Mechanics', 'Medical', 'Microscope', 'Modeling', 'Motion', 'Movement', 'Needles', 'Ocular Hypertension', 'Operative Surgical Procedures', 'Ophthalmology', 'Optical Coherence Tomography', 'Optics', 'Oryctolagus cuniculus', 'Outcome', 'Pathological Dilatation', 'Patients', 'Penetrating Keratoplasty', 'Perforation', 'Performance', 'Postoperative Complications', 'Postoperative Period', 'Procedures', 'Ptosis', 'Recovery', 'Repeat Surgery', 'Reporting', 'Research Personnel', 'Risk', 'Robotics', 'Rupture', 'Safety', 'Scientist', 'Secondary to', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Systems Development', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Topical Corticosteroids', 'Translating', 'Transplantation Surgery', 'Trauma', 'Validation', 'Visual', 'Visual Acuity', 'Visualization', 'Work', 'base', 'convolutional neural network', 'corneal scar', 'curative treatments', 'deep learning', 'design', 'experience', 'graft failure', 'high risk', 'iatrogenic injury', 'improved', 'in vivo', 'instrument', 'interest', 'novel', 'phantom model', 'photonics', 'preservation', 'prototype', 'sensor', 'skills', 'surgery outcome', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,409997,807432003
"Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization Project Summary Prostate cancer (PCa) is the most diagnosed form of non-cutaneous cancer in US men. The selection of patients who require immediate treatment from those suitable for active surveillance currently relies on non- specific and inaccurate measurements. A method that allows clinicians to more confidently discriminate clinically relevant from non-life-threatening tumors is needed to improve patient management. Multiparametric magnetic resonance imaging (mpMRI) is the preferred non-invasive imaging modality for characterizing primary PCa. However, its accuracy for detecting clinically significant PCa is variable. We propose to address this limitation by combining mpMRI with positron emission tomography (PET) with a PCa-specific radiotracer and using advanced multimodal machine learning models (i.e. radiomics and deep learning) to characterize tumor aggressiveness based on the imaging data. Recently, scanners capable of simultaneous PET and MR data acquisition in human subjects have become commercially available. An integrated MR-PET scanner is the ideal tool for comparing MR and PET derived image features to identify those that provide complementary information and build a hybrid PET-mpMRI model that most accurately identifies clinically significant tumors. While this novel technology allows the acquisition of perfectly coregistered complementary anatomical, functional and metabolic data in a single imaging session, a new challenge needs to first be addressed to obtain quantitatively accurate PET data. In an integrated MR-PET scanner, the information needed for PET attenuation correction (AC) has to be derived from the MR data and the methods currently available for this task are inadequate for advanced quantitative studies. We have formed an academic-industrial partnership to accelerate the translation of multimodal MR-PET machine learning approaches into PCa research and clinical applications by addressing the AC challenge and validating machine learning models for detecting clinically significant disease against gold standard histopathology in patients undergoing radical prostatectomy. Specifically, we will: (1) Develop and validate an MR-based approach for obtaining quantitatively accurate PET data. We hypothesize that attenuation maps as accurate as those obtained using a 511 keV transmission source – the true gold standard for PET AC – will be obtained; (2) Identify the multimodal radiomics model that most accurately predicts PCa aggressiveness. We hypothesize that the diagnostic accuracy of this approach will be superior to that offered by the stand-alone modalities; (3) Evaluate radiomics and deep learning approaches for predicting pPCa aggressiveness. We hypothesize that machine learning approaches will achieve a higher predictive accuracy when applied to data acquired simultaneously than sequentially. Project narrative A better method to non-invasively characterize primary prostate cancer is needed to improve patient management. Extracting additional information from multimodality quantitative MR-PET data using machine learning approaches is expected to result in better diagnostic performance. In this work, we propose to accelerate the translation of quantitative MR-PET to prostate cancer research and clinical applications. In particular, we will develop and validate an MR-based attenuation correction approach to guarantee that quantitatively accurate PET data are obtained in an integrated MR-PET scanner and then use machine learning approaches to characterize the aggressiveness of the tumors in patients undergoing radical prostatectomy.",Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization,10114224,R01CA218187,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Biopsy', 'Cancer Death Rates', 'Cancer Patient', 'Classification', 'Computer software', 'Data', 'Data Set', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Early treatment', 'FOLH1 gene', 'Gold', 'Guidelines', 'Hand', 'Histopathology', 'Hybrids', 'Image', 'Individual', 'Interobserver Variability', 'Kinetics', 'Lesion', 'Life Expectancy', 'Ligands', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Maps', 'Measurement', 'Meta-Analysis', 'Metabolic', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Morphology', 'PSA level', 'Patient Selection', 'Patients', 'Pelvis', 'Performance', 'Phenotype', 'Physiological', 'Positron-Emission Tomography', 'Prostate', 'Quality of life', 'Radical Prostatectomy', 'Reproducibility', 'Risk', 'Scanning', 'Source', 'Testing', 'Time', 'Translations', 'Work', 'anticancer research', 'attenuation', 'base', 'bone imaging', 'cancer classification', 'cancer imaging', 'clinical application', 'clinically relevant', 'clinically significant', 'data acquisition', 'deep learning', 'diagnostic accuracy', 'human subject', 'imaging modality', 'improved', 'industry partner', 'men', 'multimodal data', 'multimodality', 'new technology', 'non-invasive imaging', 'radiologist', 'radiomics', 'radiotracer', 'tool', 'transmission process', 'tumor']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,414490,551214295
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",10075930,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Reference Standards', 'Research', 'Risk', 'Risk stratification', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'diagnostic technologies', 'disorder subtype', 'elastography', 'hepatocellular injury', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,448421,551214295
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164,641965656
"Multi-Task MR Simulation for Abdominal Radiation Treatment Planning The accuracy of radiation treatment planning (RTP) heavily influences the effectiveness of external beam radiotherapy (EBRT). Individualized RTP begins with a “simulation”, in which the patient in a treatment position is commonly scanned using computed tomography (CT) to define the treatment target and organs at risk (OARs). When soft-tissue contrast is inadequate to support accurate target and OAR delineation in CT based RTP, conservatively large treatment margins are used to avoid a geometric miss. The crude treatment prevents delivering sufficient radiation dose to the tumor without exceeding the tolerance of surrounding normal tissues. Magnetic resonance (MR) can be used as a simulation platform complementary to CT for improved soft-tissue conspicuity. Yet, such a complicated, costly and tedious multi-modal RTP workflow along with unavoidable systematic MR-CT co-registration errors has limited its applications in EBRT, especially at the abdominal site whereby anatomies are highly mobile. Over the past few years, there is a keen interest in the integration of MR alone into RTP and even the therapy workflow (i.e. MR-guided radiotherapy, MRgRT). The abdomen poses critical challenges to MR simulation. Current MR imaging sequences are suboptimal to produce motion-free images and resolve respiratory motion. MR data processing for abdominal RTP is underdeveloped. Contouring of target and OARs typically relies on manual, tedious procedures that are time-consuming and variation-prone. In this proposal, we will substantially improve the MR acquisition and automated multi-organ segmentation, so the potential of MR as a simulation modality can be fully unleashed for abdominal EBRT. Three specific aims will be completed. In Aim 1, we will develop and validate a standalone multi-task MR (MT-MR) sequence dedicated to abdominal MR simulation. In Aim 2, we will develop an MT-MR simulation based multi-organ auto- segmentation tool. In Aim 3, we will optimize a deep learning-based dose prediction model and assess the effectiveness of the MT-MR based RTP workflow in adaptive stereotactic body radiotherapy planning of pancreatic cancer patients. Successful completion of the project will significantly promote the clinical adoption of MR simulation for abdominal RTP, which will improve treatment precision and outcomes. Moreover, the developed techniques will open the door to future studies aiming at optimizations in both cancer diagnosis and radiotherapy. Imaging is essential for precise radiation treatment planning. MR based planning is challenging in the abdomen whereby anatomies are highly mobile. We will substantially improve the MR acquisition and automated multi- organ segmentation, so the potential of MR as an imaging-based planning modality can be fully unleashed for abdominal radiation treatment.",Multi-Task MR Simulation for Abdominal Radiation Treatment Planning,10331615,R01EB029088,"['3-Dimensional', 'Abdomen', 'Address', 'Adoption', 'Anatomy', 'Breathing', 'Clinical', 'Consumption', 'Data', 'Data Collection', 'Detection', 'Development', 'Dose', 'Effectiveness', 'Fatty acid glycerol esters', 'Future', 'Geometry', 'Goals', 'Image', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Modality', 'Motion', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pancreas', 'Patients', 'Phase', 'Positioning Attribute', 'Precision therapeutics', 'Procedures', 'Protocols documentation', 'Protons', 'Radiation Dose Unit', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Site', 'Solid', 'Spatial Distribution', 'Study Subject', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Tissues', 'Variant', 'Water', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'cancer diagnosis', 'cancer radiation therapy', 'computerized data processing', 'contrast imaging', 'cost', 'deep learning', 'density', 'experience', 'image processing', 'image reconstruction', 'improved', 'interest', 'learning strategy', 'multimodality', 'multitask', 'novel', 'pancreatic cancer patients', 'predictive modeling', 'prevent', 'respiratory', 'simulation', 'soft tissue', 'standard of care', 'success', 'tool', 'treatment planning', 'tumor']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,507076,324592664
"Nonlinear performance analysis and prediction for robust low dose lung CT 1 PROJECT SUMMARY / ABSTRACT  2 Nonlinear algorithms such as model-based reconstruction (MBR) and deep learning (DL) reconstruction have  3 sparked tremendous research interest in recent years. Compared to traditional linear approaches, the nonline-  4 arity of these algorithm transcends traditional signal-to-noise requirement and offer flexibility to draw information  5 from a variety of sources (e.g., statistical model, prior image, dictionary, training data). MBR has enabled numer-  6 ous advancements including low-dose CT and advanced scanning protocols. Deep learning algorithms are rap-  7 idly emerging and have demonstrated superior dose vs. image quality tradeoffs in research settings. However,  8 widespread clinical adoption of nonlinear algorithms has been impeded by the lack of a lack of systematic, quan-  9 titative methods for performance analysis. Nonlinear methods come with numerous dependencies on the imag- 10 ing techniques, the imaging target, and the prior information, and the data itself. The relationship between these 11 dependencies and image quality is often opaque. Furthermore, improper selection of algorithmic parameters can 12 lead to erroneous features (e.g., smaller lesions, texture) in the reconstruction. Therefore, methods to quantify 13 and predict performance permit efficient and quantifiable performance evaluation to provide the robust control 14 and understanding of imaging output necessary for reliable clinical application and regulatory oversight. 15 We propose to establish a robust, predictive framework for performance assessment and optimization that can 16 be generalized to any reconstruction method. We quantify performance in turns of the perturbation response and 17 covariance as a function of imaging techniques, system configurations, patient anatomy, and, importantly, the 18 perturbation itself. The perturbation response quantifies the appearance (e.g., biases, blurs, distortions), and, 19 together with the covariance, allows the computation of more complex metrics such as task-based performance 20 and radiomic measures including size, shape, and texture information. We illustrate utility of the approach in lung 21 imaging with the following specific aims: Aim 1: Develop a lesion library and generate perturbations encom- 22 passing clinically relevant features. We will extract lesions from public databases and develop methods lesion 23 emulation in for realistic CT simulation and physical data via 3D printing technology. Aim 2: Develop a gener- 24 alized prediction framework for perturbation response and covariance. Using analytical and neural network 25 modeling, we will establish a framework that predicts perturbation response and covariance across imaging 26 scenarios for classes of algorithms with increasing data-dependence including MBR with a Huber penalty, MBR 27 with dictionary regularization, and a deep learning reconstructor. Aim 3: Develop assessment and optimiza- 28 tion strategies to drive robust, low dose lung screening CT methods. We will optimize and adapt nonlinear 29 algorithms and protocols for lung cancer screening to achieve faithful representations of clinical features. This 30 work has the potential to drive much-needed quantitative assessment standards that directly relate image quality 31 to diagnostic performance and optimal strategies for robust, reliable clinical deployment of nonlinear algorithms. 32 PROJECT NARRATIVE Major research efforts have been devoted to the development of nonlinear reconstruction algorithms – from model-based reconstruction to deep learning, these algorithms have demonstrated many advantages such as improved image quality, reduced radiation dose, and additional diagnostic information that are not achievable with traditional linear reconstructions. However, only a disproportionately small number has reach the clinic due to the lack of a predictive image quality analysis framework to quantify diagnostic performance, control algorithm behavior, and ensure consistent performance for robust clinical deployment. The propose effort use a combination of analytic and machine learning approaches to drive much-needed quantitative assessment standards that directly relate image quality to diagnostic performance and establish optimal strategies for robust, reliable clinical deployment of nonlinear algorithms.",Nonlinear performance analysis and prediction for robust low dose lung CT,10121056,R01CA249538,"['3D Print', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Appearance', 'Beauty', 'Behavior', 'Biological Models', 'Clinic', 'Clinical', 'Complex', 'Data', 'Databases', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Dictionary', 'Digital Libraries', 'Dimensions', 'Dose', 'Ensure', 'Evaluation', 'Genes', 'Image', 'Image Analysis', 'Imaging Techniques', 'Lead', 'Lesion', 'Libraries', 'Lung', 'Lung CAT Scan', 'Lung nodule', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Nodule', 'Noise', 'Non-linear Models', 'Outcome', 'Output', 'Patients', 'Performance', 'Play', 'Predictive Analytics', 'Property', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Role', 'Sampling', 'Scanning', 'Scheme', 'Shapes', 'Signal Transduction', 'Source', 'Statistical Models', 'System', 'Techniques', 'Technology', 'Texture', 'Training', 'Transcend', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinical translation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'exhaustion', 'flexibility', 'imaging system', 'improved', 'insight', 'interest', 'low dose computed tomography', 'lung cancer screening', 'machine learning method', 'neural network', 'novel', 'predicting response', 'quantitative imaging', 'radiomics', 'reconstruction', 'response', 'screening', 'shape analysis', 'simulation', 'success', 'targeted imaging']",NCI,JOHNS HOPKINS UNIVERSITY,R01,2021,512567,807432003
"Advancing MRI technology for early diagnosis of liver metastases Abstract Liver is commonly involved in metastatic disease in colorectal cancer (CRC) and knowledge about the presence and location of these tumors affects treatment decisions. In patients with CRC, surgical or ablative treatment of liver metastases improves overall survival. Early diagnosis of colorectal metastases (i.e. while lesions are small) is expected to improve treatment outcomes by increasing the number of subjects that can undergo surgical resection or by identifying subjects early on, when non-surgical options are an alternative treatment. Magnetic Resonance Imaging (MRI) is regarded as the most effective imaging modality for the detection and characterization of liver neoplasms; T2-weighted (T2w) and T1-weighted (T1w) images - combined with administration of a gadolinium chelate agent and multi-phase dynamic contrast enhancement (DCE) - are the foundational acquisitions used for the detection and characterization of liver tumors. However, challenges remain for the detection and characterization of small lesions due to factors including inadequate spatial resolution, partial volume effects, physiological motion, and variations in timing of contrast arrival in DCE imaging. In this academic-industrial partnership the scientific and engineering teams at the University of Arizona and Siemens Medical Solutions are coming together to develop robust radial MRI techniques for T2w/T2 mapping and DCE imaging of the liver to improve detection and characterization of small tumors with the goal of bringing these techniques to routine clinical practice. The proposed work is based on a radial turbo spin- echo technique pioneered by the team at the University of Arizona for abdominal imaging and a radial stack-of-stars technique with continuous acquisition for DCE imaging. The specific aims of the partnership are: Aim 1: To develop radial T2w acquisition and reconstruction techniques with efficient full coverage of the liver for small tumor detection and accurate T2 quantification for tumor characterization. Aim 2: To implement a self-navigated 3D radial stack-of-stars technique for continuous acquisition of DCE data and retrospective reconstruction of the dynamic phases. Aim 3: To conduct a clinical evaluation of the techniques from Aims 1 and 2 against conventional T2w and DCE techniques. Aim 4: To streamline translation of the new radial methods to the clinic by developing a computationally efficient reconstruction pipeline. The endpoints of our study include technical advances in MRI acquisitions that markedly overcome limitations of current liver MRI for the diagnosis of early metastases. We expect our proposal to yield technology improvements that will increase precision of care and outcomes in patients with metastatic malignancies, in particular those with colorectal cancer. Project Narrative Liver metastases are common in colorectal cancer and knowledge of number, location and size impacts precision of therapy, survival and overall costs. Magnetic Resonance Imaging (MRI) is commonly used for evaluating liver metastases but detection and diagnosis of small tumors remains challenging. Our proposal is based on a collaborative integrated team of university scientists, clinician-scientists and industry engineers to develop and clinically trial new MRI technology that overcomes limitations related to imaging small liver tumors in patients.",Advancing MRI technology for early diagnosis of liver metastases,10063981,R01CA245920,"['3-Dimensional', 'Abdomen', 'Accounting', 'Adopted', 'Affect', 'Algorithms', 'Arizona', 'Benign', 'Breathing', 'Cessation of life', 'Chelating Agents', 'Clinic', 'Clinical', 'Clinical Trials', 'Colorectal', 'Colorectal Cancer', 'Country', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Drops', 'Early Diagnosis', 'Engineering', 'Excision', 'Foundations', 'Gadolinium', 'Goals', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Incidence', 'Industry', 'Knowledge', 'Lesion', 'Life', 'Liver', 'Liver neoplasms', 'Location', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medical', 'Metastatic Neoplasm to the Liver', 'Methods', 'Motion', 'Neoplasm Metastasis', 'Operative Surgical Procedures', 'Outcome', 'Patient Selection', 'Patients', 'Phase', 'Physiological', 'Population', 'Precision therapeutics', 'Radial', 'Reproducibility', 'Research', 'Resectable', 'Resolution', 'Scanning', 'Scheme', 'Scientist', 'Sensitivity and Specificity', 'Techniques', 'Technology', 'Test Result', 'Translations', 'Treatment outcome', 'Universities', 'Unresectable', 'Variant', 'Work', 'accurate diagnosis', 'alternative treatment', 'base', 'cancer imaging', 'care outcomes', 'clinical practice', 'clinical translation', 'colon cancer patients', 'contrast enhanced', 'contrast imaging', 'cost', 'data acquisition', 'deep neural network', 'design', 'diagnostic accuracy', 'flexibility', 'image processing', 'image reconstruction', 'imaging modality', 'improved', 'industry partner', 'liver imaging', 'new technology', 'next generation', 'novel', 'personalized care', 'reconstruction', 'research clinical testing', 'soft tissue', 'spatiotemporal', 'tumor', 'tumor specificity']",NCI,UNIVERSITY OF ARIZONA,R01,2021,536670,161094826
"Development of next generation 2HG and metabolic MR imaging for precision oncology of mutant IDH and wildtype glioma patients 7. Project Summary/Abstract Gliomas are rarely curable tumors with a low survival rate of 36% at five-years that is well below the average survival rate of 67.2% across all cancers, according to SEER and CBTRUS. Malignant brain tumors cause an average of 20 years of potential life lost (YPLL) for individuals diagnosed as adults, which exceeds most common cancers. Survival and YPLL have not improved for gliomas similarly to other cancers and progress is desperately needed. The lack of improvement in patient outcomes is not due to lack of new discoveries, but due to limited success in translating this knowledge into clinical benefit. Important discoveries have been made over the last decade regarding key molecular mechanisms involved in glioma initiation and growth, which have been incorporated in the latest WHO classification. IDH mutation is the primary event in glioma initiation and has become a paradigm shift in the treatment of glioma. Neuro-oncology experts (SNO, EANO) agree that brain imaging can accelerate clinical trials of targeted therapies and mandated the development of molecular imaging for highly specific and sensitive glioma imaging. The long-term goal of our research is the development of non-invasive molecular imaging methods that can be used clinically in cancer patients. IDH mutations are frequent in glioma and produce high levels of the oncometabolite 2-hydroxyglutarate (2HG) that can be imaged as a biomarker for diagnosis, prognosis, prediction, guidance of surgery and radiation, response to chemotherapy and targeted treatments. The objective of this application is to develop fast high resolution whole brain quantitative 2HG and metabolic imaging for diagnosis, treatment guidance and monitoring of mutant IDH and wildtype glioma. The central hypothesis of our proposal is that advancing next generation 2HG and metabolic imaging will enable precision oncology and accelerate clinical translation of novel targeted therapies to improve outcomes in mutant IDH and wildtype glioma patients. Three specific aims will be performed for this: 1) develop fast high-resolution whole-brain clinically robust 2HG and metabolic imaging, 2) improve sensitivity, precision, accuracy and workflow of 2HG and metabolic imaging, and 3) clinical translation of next generation 2HG and metabolic imaging in glioma patients. There are strong rationales for the proposed research: 1) there is no alternative in vivo imaging method specific for IDH mutations, 2) 2HG imaging is completely non-invasive, can be repeated safe without any radiation, can provide results fast and cost effective, 3) provides comprehensive evaluation of the entire tumor and healthy brain without the sampling bias of biopsies, 4) it can be performed pre-surgically and in tumors that cannot be operated. The approach is innovative because it employs the first available whole brain 2HG imaging method, which will be accelerated by compressed sensing, novel shim hardware to improve data quality, and transformed in a high throughput automated tool by deep learning. The contribution of the proposed research will be significant because it will provide clinicians with a user-friendly and precise tool for diagnostic, guiding and monitoring of glioma patients. 8. Project Narrative The proposed research is relevant to public health because it will advance the capabilities of clinical MR scanners to image specific molecular signatures of primary brain tumors. The new features will provide rapid scanning, improved data quality, and automated data analytics for clinical use. This would enable precision oncology in patients with mutant IDH glioma tumors for early diagnosis, treatment planning, and clinical translation of targeted therapies. Hence, this research is relevant to NCI’s mission to advance diagnosis and treatment of cancer.",Development of next generation 2HG and metabolic MR imaging for precision oncology of mutant IDH and wildtype glioma patients,10099509,R01CA255479,"['3-Dimensional', 'Adult', 'Age', 'Big Data', 'Biological Markers', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Cancer Etiology', 'Cancer Patient', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Trials', 'Computer software', 'Cross-Sectional Studies', 'Data Analytics', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Early Diagnosis', 'Enzymes', 'Epigenetic Process', 'Evaluation', 'Event', 'Gene Expression', 'Generations', 'Glioma', 'Goals', 'Gold', 'Growth', 'Image', 'Imaging Device', 'Immune response', 'Individual', 'Isocitrate Dehydrogenase', 'Joints', 'Knowledge', 'Life', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Maps', 'Metabolic', 'Methods', 'Mission', 'Modification', 'Molecular', 'Molecular Profiling', 'Monitor', 'Motion', 'Mutation', 'Noise', 'Oncogenic', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Primary Brain Neoplasms', 'Public Health', 'Quantitative Evaluations', 'Radiation', 'Research', 'Resolution', 'SKIL gene', 'Sampling Biases', 'Scanning', 'Signal Transduction', 'Survival Rate', 'Testing', 'Therapeutic', 'Time', 'Translating', 'Tumor Burden', 'Update', 'Vaccines', 'Work', 'analysis pipeline', 'artificial neural network', 'base', 'cancer imaging', 'cancer therapy', 'chemoradiation', 'chemotherapy', 'clinical phenotype', 'clinical translation', 'cost effective', 'data quality', 'deep learning', 'denoising', 'first-in-human', 'imaging agent', 'imaging biomarker', 'imaging modality', 'improved', 'improved outcome', 'in vivo', 'in vivo imaging', 'inhibitor/antagonist', 'innovation', 'magnetic resonance spectroscopic imaging', 'metabolic imaging', 'molecular imaging', 'molecular marker', 'mutant', 'nervous system disorder', 'neuro-oncology', 'new therapeutic target', 'next generation', 'novel', 'outcome forecast', 'patient population', 'precision oncology', 'predicting response', 'radiation response', 'reconstruction', 'success', 'targeted therapy trials', 'targeted treatment', 'tool', 'treatment planning', 'treatment response', 'tumor', 'usability', 'user-friendly']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,569946,551214295
"Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues Summary Fast, accurate, and scalable testing has been recognized unanimously as crucial for mitigating the impact of COVID-19 and future pandemics. We propose a technology that allows rapid (~2 minutes) testing for SARS CoV-2. Our technology combines novel label-free imaging and dedicated deep-learning algorithms to detect and classify viral populations in exhaled air. If successful, this project will result in a device based on quantitative phase imaging and integrated AI tools, which will detect the unlabeled virus acquired by the patient’s breath condensed on a microscope slide. Toward this goal, we will advance Spatial Light Interference Microscopy (SLIM), an ultrasensitive label-free imaging technique, proven to measure structures down to the sub-nanometer scale. SLIM was developed in the PI’s Lab at UIUC, its original publication received 490 citations to date, and has been commercialized by Phi Optics (Research Park, UIUC), with sales across the world in both academia and industry. Applying the computed fluorescence maps back to the QPI data, we propose to measure nanoscale features of viral particles, with high specificity, minimal preparation time, and independent of clinical infrastructure. As a result, the new technology will eventually be ideal for point-of-care settings, surveillance screening and as a home monitoring device. We anticipate that our approach will be scalable to other viruses, with new imaging and training data. Narrative We propose a breath test using label-free imaging and AI: an individual exhales on a microscope slide, which is fed into a SLIM microscope equipped with a computer that runs deep-learning pre-trained algorithms for SARS CoV-2 identification. The result is displayed in real time, with the entire procedure requiring < 2min.",Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues,10249738,R01CA238191,"['2019-nCoV', 'Academia', 'Air', 'Artificial Intelligence', 'Back', 'Bedside Testings', 'Biology', 'Breath Tests', 'COVID-19', 'COVID-19 testing', 'Cancer Prognosis', 'Chemicals', 'Classification', 'Clinical', 'Clinical Microbiology', 'Computer software', 'Computers', 'Data', 'Devices', 'Exhalation', 'Fluorescence', 'Fluorescence Microscopy', 'Future', 'Glass', 'Goals', 'Histopathology', 'Home environment', 'Image', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Industry', 'Influenza', 'Infrastructure', 'Interference Microscopy', 'Label', 'Light', 'Maps', 'Measures', 'Microscope', 'Modification', 'Morphologic artifacts', 'Nature', 'Optics', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Phototoxicity', 'Population', 'Preparation', 'Procedures', 'Publications', 'Research', 'Running', 'Sales', 'Slide', 'Specificity', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Tissue Stains', 'Training', 'Viral', 'Virus', 'Virus Diseases', 'algorithm training', 'base', 'clinical infrastructure', 'coronavirus disease', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'imaging system', 'instrument', 'monitoring device', 'nanoscale', 'new technology', 'novel', 'operation', 'pandemic disease', 'particle', 'point of care', 'prototype', 'screening', 'tool']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2021,576268,76545728
"Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients ABSTRACT The prevalence of obesity in the United States has risen to record levels over the past 40 years, putting strain on the healthcare system and creating difficult challenges for medical imaging. We propose to overcome the challenges that obesity poses to ultrasound imaging by (1) developing novel image-quality improvement techniques, and (2) implementing them on pulse-echo ultrasound imaging systems to yield high-quality images of the liver. Ultrasound imaging is uniquely affected by the presence of additional connective tissue and thick subcutaneous fat layers in overweight and obese patients; these additional subcutaneous layers greatly exacerbate reverberation and phase-aberration of the acoustic wave, leading to high levels of clutter, degraded resolution, and overall poor-quality ultrasound images. Our proposed methods will determine the local speed-of-sound in abdominal tissue layers and use this information to accomplish distributed phase-aberration correction. We also apply machine learning techniques to model and suppress the effects of reverberation clutter and speckle noise. The combination of these techniques is expected to achieve significant improvements in liver image quality. These image-quality improvement methods will be implemented on a real-time ultrasound scanner and will be evaluated in clinical imaging tasks of overweight and obese patients undergoing ultrasound surveillance of hepatocellular carcinoma. Successful development of the proposed technology will not only enable high-quality ultrasound imaging of the liver in otherwise difficult-to-image overweight and obese patients, but also facilitate improved image quality across nearly all ultrasound imaging applications, for all populations. NARRATIVE This proposal aims to develop and test several new techniques to overcome the current limitations of ultrasound to make high-quality images in overweight and obese individuals. These novel ultrasound techniques will be initially applied to improve liver imaging in overweight and obese patients in a pilot study, though the benefits of this new high-quality imaging technology will extend to all other areas of clinical ultrasound imaging.",Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients,10236260,R01EB027100,"['Abdomen', 'Acoustics', 'Affect', 'American', 'Architecture', 'Area', 'Attenuated', 'Cardiac', 'Cirrhosis', 'Clinical', 'Computer software', 'Connective Tissue', 'Data', 'Development', 'Diffuse', 'Disease', 'Fatty acid glycerol esters', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Image', 'Imaging technology', 'Lesion', 'Liver', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Noise', 'Obesity', 'Output', 'Overweight', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Resolution', 'Risk Factors', 'Signal Transduction', 'Source', 'Speed', 'Subcutaneous Tissue', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thyroid Gland', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Weight', 'clinical imaging', 'elastography', 'epidemiology study', 'fetal', 'high body mass index', 'imaging system', 'improved', 'in vivo', 'liver imaging', 'neural network', 'novel', 'obese patients', 'obese person', 'patient population', 'prototype', 'radio frequency', 'simulation', 'sound', 'subcutaneous']",NIBIB,STANFORD UNIVERSITY,R01,2021,585234,560644462
"Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo 1 Dermatologists rely on visual (clinical widefield) and dermoscopic examination of skin lesions to guide the need  2 for biopsy. With this approach, sensitivity is high, but specificity tends to be quite variable and lower, resulting  3 in millions of biopsies of benign lesions every year. To improve specificity, several optical technologies are  4 being developed to noninvasively detect skin cancer. Of these, reflectance confocal microscopy (RCM) is the  5 furthest advanced in clinical utility, proven for diagnosing skin cancers with high sensitivity and specificity.  6 RCM imaging, guided by dermoscopy, detects skin cancers with 2 times superior specificity, and reduces the  7 benign-to-malignant biopsy rate by 2 times, compared to that with dermoscopy alone. In 2016, the Centers for  8 Medicare and Medicaid Services granted current procedural terminology (CPT) reimbursement codes for RCM  9 imaging of skin. RCM imaging combined with dermoscopy is now advancing into clinical practice, sparing pa- 10 tients from unnecessary biopsies of benign lesions. However, toward widespread acceptance and adoption, a 11 key challenge is that clinical widefield examination, dermoscopy and RCM imaging are currently performed as 12 three separate procedures with separate devices. Clinicians do not precisely know the location of RCM imag- 13 es relative to the surrounding contextual lesion morphology that is seen with clinical widefield examination and 14 dermoscopy, resulting in lower and more variable diagnostic accuracy (particularly, sensitivity, positive and 15 negative predictive values). We propose a novel solution: (i) a new objective lens with an integrated micro- 16 camera, to deliver a concurrent widefield image of the skin surface surrounding the location of RCM imaging; 17 (ii) a new software algorithm for widefield image-based tracking of the location of RCM images within a dermoscopic 18 field of view; (iii) a new diagnostic approach that will proactively use widefield imaging to locate RCM images in 19 dermoscopic images. We intend to deliver this integrated widefield clinical, dermoscopic and RCM imaging ap- 20 proach into the clinic, toward a new standard for more accurate, consistent and faster RCM imaging to guide 21 patient care. Preliminary studies with a “mock” objective lens and micro-camera on a bench-top set-up 22 demonstrated excellent optical sectioning (~2 µm) and resolution (~1 µm) for RCM imaging, and accurate and 23 repeatable location of RCM fields-of-view within the widefield image. RCM images showed excellent cellular 24 and morphologic detail in vivo. Our specific aims are (1) to develop a handheld reflectance confocal micro- 25 scope with integrated widefield camera; (2) to develop image processing algorithms for real-time widefield im- 26 aging-guided tracking of RCM image locations within dermoscopic fields; (3) to test and validate performance 27 on 100 patients. Although our proposition is for skin lesions, the research will surely have wider impact for 28 imaging in other settings, particularly, with miniaturized confocal microscopes and endoscopes, which have 29 very small fields-of-view. We are a highly synergistic team from Montana State University, Memorial Sloan 30 Kettering Cancer Center, Northeastern University and Caliber Imaging and Diagnostics (formerly, Lucid Inc.). RELEVANCE TO PUBLIC HEALTH Clinical examination and dermoscopy combined with reflectance confocal microscopy (RCM) imaging is a newly emerging optical imaging procedure that can noninvasively guide diagnosis of skin cancers, and reduce the need for biopsy. However, clinical examination, dermoscopy and RCM imaging are currently performed as three separate procedures with separate devices, limiting effectiveness and impact. We propose a device to combine the three into a single procedure, which will help dermatologists and patients by making the skin examinations quicker, more accurate and more consistent, expanding the impact of this proven approach.",Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo,10127641,R01EB028752,"['Address', 'Adoption', 'Affordable Care Act', 'Aging', 'Algorithmic Software', 'Algorithms', 'Benign', 'Biopsy', 'Caliber', 'Cancer Center', 'Categories', 'Cellular Morphology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Current Procedural Terminology', 'Dermatologist', 'Dermatology', 'Dermis', 'Dermoscopy', 'Devices', 'Diagnosis', 'Diagnostic', 'Drops', 'Effectiveness', 'Endoscopes', 'Engineering', 'Epidermis', 'Grant', 'Head and neck structure', 'Image', 'Imaging Techniques', 'Lesion', 'Lesion by Morphology', 'Letters', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medicaid services', 'Medicare/Medicaid', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopic', 'Montana', 'Morphology', 'Optics', 'Oral', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sensitivity and Specificity', 'Site', 'Skin', 'Skin Cancer', 'Specificity', 'Surface', 'Technology', 'Testing', 'Time', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Visual', 'base', 'blind', 'cancer diagnosis', 'clinical examination', 'clinical practice', 'cost', 'design', 'design and construction', 'diagnostic accuracy', 'gastrointestinal', 'image guided', 'image processing', 'image registration', 'improved', 'in vivo', 'innovation', 'instrument', 'instrumentation', 'interest', 'lens', 'medical specialties', 'microscopic imaging', 'miniaturize', 'novel', 'novel diagnostics', 'optical imaging', 'prospective test', 'reflectance confocal microscopy', 'response', 'routine practice', 'skin lesion', 'volunteer']",NIBIB,MONTANA STATE UNIVERSITY - BOZEMAN,R01,2021,589357,20627506
"MR Fingerprinting for Epilepsy Abstract Epilepsy affects 65 million people worldwide; approximately 30% of them do not respond to medications but can be cured by surgery. Focal cortical dysplasia (FCD), a major pathology for medically intractable epilepsies, is frequently missed by visual analysis of the conventional MRI, making surgical treatment very difficult. We propose to develop a novel quantitative MRI acquisition and analysis framework specific for epilepsy patients, which could provide more sensitive and specific measures of brain structure, thereby improving FCD detection and subtype prediction. To this end, the quantitative framework will be developed and validated in three steps: (1) Develop high-resolution Magnetic Resonance Fingerprinting (MRF) scan that allows simultaneous quantification of multiple tissue property maps efficiently, accurately and precisely. These quantitative maps have shown to be more sensitive and specific on detecting and characterizing subtle signal abnormalities. (2) Develop image post-processing methods to analyze quantitative maps, which will provide quantitative measurements that highlight additional morphological features, such as gray-white boundary blurring, abnormal cortical thickness and folding. (3) Develop machine-learning-based feature screening and prediction tools to characterize group-level features differentiating FCD subtypes, and predict individual-level FCD location and subtyping. Because detection and subtype prediction of FCD are both associated with seizure outcomes, epileptologists can use this tool to provide more personalized and customized counseling. The result of our proposed work promises a paradigm shift by converting the current standard-care of visual/qualitative MRI review to a quantitative framework, including data acquisition, post-processing and decision support tool, that would eventually lead to better treatment planning, reduction in unnecessary pre-surgical evaluation tests (especially invasive evaluation), and improved post-operative seizure outcomes in patients with devastating and disabling medically intractable epilepsy. The quantitative nature of our acquisition/analysis methods also makes it possible to be uniformly adopted by other centers with high consistency. Project Narrative Epilepsy affects 65 million people worldwide; approximately 30% of them do not respond to medications but can be cured by surgery. Focal cortical dysplasia, a major pathology for medically intractable epilepsies, are frequently missed by visual analysis of the conventional MRI, making surgical treatment very difficult. Here we propose to develop and validate novel, noninvasive and quantitative MRI acquisition and post-processing techniques, in order to guide epilepsy surgery and make more patients seizure-free.",MR Fingerprinting for Epilepsy,10075326,R01NS109439,"['3-Dimensional', 'Adopted', 'Affect', 'Brain', 'Case Study', 'Cellular Structures', 'Characteristics', 'Classification', 'Clinical', 'Complement', 'Cortical Dysplasia', 'Counseling', 'Custom', 'Cytology', 'Data', 'Detection', 'Development', 'Diagnosis', 'Electroencephalography', 'Epilepsy', 'Evaluation', 'Fingerprint', 'Gold', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Intractable Epilepsy', 'Lead', 'Lesion', 'Location', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Masks', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Morphology', 'Nature', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Postoperative Period', 'Property', 'Protocols documentation', 'Protons', 'Publishing', 'Resolution', 'Scanning', 'Seizures', 'Sensitivity and Specificity', 'Signal Transduction', 'Structure', 'Surface', 'T2 weighted imaging', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Validation', 'Visual', 'Work', 'base', 'brain malformation', 'cohort', 'data acquisition', 'density', 'design', 'evaluation/testing', 'imaging modality', 'improved', 'nervous system disorder', 'non-invasive imaging', 'novel', 'predictive modeling', 'screening', 'standard care', 'support tools', 'tool', 'treatment planning']",NINDS,CASE WESTERN RESERVE UNIVERSITY,R01,2021,595629,197030888
"Motion-Resolved, Comprehensive Quantitative Tissue Characterization Using MR Multitasking PROJECT SUMMARY  Quantitative magnetic resonance imaging (MRI) measures tissue parameters such as T1, T2, T2*, and diffusion to detect subtle differences in tissue states (such as microstructure, diffuse fibrosis, edema, hemorrhage, and iron content) from neurological, oncological, and cardiovascular diseases. Because each parameter offers complementary tissue information, multiparameter mapping is very promising for risk assessment, early detection, accurate staging, and treatment monitoring of disease. However, quantitative MRI is typically very time consuming and difficult to perform. Each parameter is typically measured from its own series of images, so measuring multiple parameters leads to long, inefficient scanning sessions. Furthermore, cardiac and breathing motion creates misalignment between images, causing additional problems.  The standard approach to motion is to either remove it (e.g., ask the patient to hold their breath) or to synchronize image acquisition with it (e.g., using electrocardiography (ECG) to monitor cardiac motion). This approach makes scan times even longer, limits imaging to patients who can repeatedly perform long breath holds (which is difficult for aging or weak patients) and who have predictable cardiac motion (which is not true of patients with cardiac arrhythmias). Furthermore, these methods are often unreliable and difficult to perform.  This project is to develop and validate a new technology, MR Multitasking, to perform multiple simultaneous measurements in a single, push-button scan that is both comfortable for patients and simple for technologists to perform. MR Multitasking redesigns quantitative MRI around the concept of images as functions of many time dimensions, each corresponding to a different dynamic process (e.g., motion, T1, T2, T2*, and diffusion), and then uses mathematical models called low-rank tensors to perform fast, multidimensional imaging. This allows continuous acquisition of imaging data even while the subject is moving, providing motion-resolved parameter maps without breath holding or motion synchronization. We will scan healthy subjects, liver patients, prostate cancer patients, and cardiovascular patients to develop and validate this technology and use artificial intelligence to quickly reconstruct images from the collected data. The resulting tool will be applicable to any organ system, offering clinicians and investigators a valuable tool to answer a wide range of biomedical questions. PROJECT NARRATIVE  This project is to develop and validate a one-stop, push-button solution for comprehensive, motion- resolved quantitative magnetic resonance imaging (MRI). This will be accomplished by cultivating a new technology, MR Multitasking, which can measure multiple tissue biomarkers in a single scan, even in moving organs. The resulting technology will be applicable to any organ system, offering clinicians and investigators a valuable tool to diagnose, monitor, and study a wide range of diseases.","Motion-Resolved, Comprehensive Quantitative Tissue Characterization Using MR Multitasking",10084899,R01EB028146,"['Address', 'Aging', 'Algorithms', 'Arrhythmia', 'Artificial Intelligence', 'Blood flow', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Collection', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Diffuse', 'Diffusion', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Electrocardiogram', 'Fibrosis', 'Hemorrhage', 'Image', 'Iron', 'Joints', 'Lead', 'Lipids', 'Liver', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetism', 'Malignant neoplasm of prostate', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Nature', 'Neurologic', 'Organ', 'Patients', 'Physiological', 'Positioning Attribute', 'Predisposition', 'Process', 'Property', 'Recovery', 'Reproducibility', 'Research', 'Research Personnel', 'Respiration', 'Risk Assessment', 'Scanning', 'Series', 'Signal Transduction', 'Source', 'Staging', 'System', 'Technology', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Validation', 'body system', 'deep learning', 'heart motion', 'image reconstruction', 'magnetic field', 'magnetohydrodynamic', 'mathematical model', 'multitask', 'new technology', 'prospective', 'quantitative imaging', 'reconstruction', 'respiratory', 'time use', 'tissue biomarkers', 'tool']",NIBIB,CEDARS-SINAI MEDICAL CENTER,R01,2021,616003,90419233
"Quantification of Liver Fibrosis with MRI and Deep Learning Project Summary/Abstract  Chronic liver disease (CLD) is a common cause of morbidity and mortality in the U.S. and throughout the world. In 2017, CLD had an age-adjusted death rate of 10.9/100,000 total population and an estimated lifetime cost of fatty liver disease alone in the U.S. of ~$222 billion. Liver fibrosis (LF) is the most important and only histologic feature known to predict outcomes from CLD. The current standard for assessing LF is biopsy, which is costly, prone to sampling error, and invasive with poor patient acceptance. Thus, there is an urgent unmet need for noninvasive, highly accurate and precise diagnostic technologies for detection and quantification of LF. Our overarching objective is to apply Deep Learning (DL) methods using conventional non-elastographic magnetic resonance (MR) images, MR elastography (MRE), and clinical data to accurately detect and measure LF in children and adults with CLD, using biopsy-derived histologic data as the reference standard. In this project, we will dedicate our efforts to accomplishing the following specific aims. In Aim 1, we will develop and validate a DL framework to accurately segment liver and spleen in order to extract radiomic (gray-scale signal intensity distribution, shape and morphology, volumetry, and inter-voxel signal intensity pattern and texture) and deep features (complex abstractions of patterns non-linearly constructed throughout the transformation estimated by data-driven DL training procedures) from conventional multiparametric MRI. These features allow detection of liver and spleen structural abnormalities/tissue aberrations. In Aim 2, we will develop and validate an “ensemble” DL model (LFNet) to predict biopsy-derived LF stage and LF percentage using the integration of conventional multimodal MRI radiomic and deep features, MRE data, as well as clinical data. In Aim 3, we will develop and validate a DL model (LSNet) to quantify MRE-derived liver stiffness (LS) using conventional multiparametric MRI radiomic and deep features as well as clinical data. The proposed models will help physicians to more accurately detect and follow CLD by 1) quantifying LS from conventional MR imaging without the need for MRE; and, more importantly, 2) predicting histologic LF stage and LF percentage without the need for biopsy, while avoiding inter- radiologist variability, reducing radiologist workload, and ultimately reducing healthcare costs. We will validate the models using both internal and independent external data from various scanners and sites. The techniques we develop are expected to improve medical diagnosis and prognostication in the same way as DL has revolutionized other fields. This study will significantly impact public health because it will allow physicians and researchers to more accurately diagnose and quantify CLD and LF as well as permit more frequent assessments in a noninvasive, patient-centric manner, thus potentially improving patient outcomes while lowering healthcare costs. The techniques we develop also can be readily extended for the prediction of other important liver-related clinical outcomes, including impending complications such as portal hypertension, time to liver transplant/transplant listing, and mortality risk, among others. Project Narrative  Chronic liver disease (CLD) is a common cause of illness and death worldwide, and it is a significant healthcare and financial burden. Liver fibrosis (LF) is a measurable feature of CLD that is important to assess the severity of disease, evaluate for progression and therapy response, and predict outcomes. We propose to apply artificial intelligence methods to noninvasive conventional magnetic resonance images and readily- available clinical data for accurate detection and quantification of LF, thus significantly impacting public health by facilitating personalized therapies without the need for liver biopsy, improved outcomes, and lower healthcare costs.",Quantification of Liver Fibrosis with MRI and Deep Learning,10096229,R01EB030582,"['Address', 'Adult', 'Age', 'American', 'Appearance', 'Artificial Intelligence', 'Bilirubin', 'Biopsy', 'Body mass index', 'Cessation of life', 'Characteristics', 'Child', 'Childhood', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Complex', 'Computer-Assisted Diagnosis', 'Crowding', 'Data', 'Data Set', 'Databases', 'Death Rate', 'Decision Making', 'Descriptor', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Evaluation', 'Eye', 'Fatty Liver', 'Financial Hardship', 'Goals', 'Health Care Costs', 'Health Expenditures', 'Healthcare', 'Histologic', 'Human', 'Image', 'Individual', 'Institution', 'Laboratories', 'Length of Stay', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Magnetic Resonance Elastography', 'Magnetic Resonance Imaging', 'Maps', 'Mathematics', 'Measurable', 'Measures', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Population', 'Portal Hypertension', 'Procedures', 'Property', 'Public Health', 'Reference Standards', 'Research', 'Research Personnel', 'Residual state', 'Risk', 'Risk Factors', 'Running', 'Sampling Errors', 'Series', 'Severity of illness', 'Shapes', 'Signal Transduction', 'Site', 'Spleen', 'Staging', 'Structural defect', 'Techniques', 'Testing', 'Texture', 'Time', 'Tissues', 'Training', 'Transplantation', 'Vendor', 'Viral hepatitis', 'Visual', 'Workload', 'accurate diagnosis', 'accurate diagnostics', 'chronic liver disease', 'classification algorithm', 'clinical risk', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'diagnostic technologies', 'elastography', 'hospital readmission', 'hospitalization rates', 'improved', 'improved outcome', 'learning strategy', 'life time cost', 'liver biopsy', 'liver transplantation', 'mortality', 'mortality risk', 'multimodality', 'multitask', 'non-linear transformation', 'outcome prediction', 'personalized diagnostics', 'personalized medicine', 'predictive modeling', 'prognostic', 'radiologist', 'radiomics', 'response', 'sex']",NIBIB,CINCINNATI CHILDRENS HOSP MED CTR,R01,2021,628266,168440418
"Application of Advanced Quantitative Methods to Schizophrenia Research PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found a decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Prefrontal white matter is among the areas usually involved. Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities, suggesting that abnormalities causing diminished FA are subtle, and that postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a FIC/NIMH collaboration with the Macedonian Academy of Sciences and Arts, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the spatial orientation of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high- resolution images of Bielschowsky stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This technique yields clear images of individual axons that can be traced and measured in 3 dimensions. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin- related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models in three multi-omics data fusion approaches to combine different types of high-dimensional data, including those produced by Aims 1 and 2, with known structural properties of axons and myelin in white matter, in order to build a model or detect novel dependencies of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. NARRATIVE Our ongoing research in North Macedonia and at Columbia University / New York State Psychiatric Institute has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale to study schizophrenia.",Application of Advanced Quantitative Methods to Schizophrenia Research,10099068,R01MH125030,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Antibodies', 'Architecture', 'Area', 'Arts', 'Autopsy', 'Axon', 'Biochemical', 'Biochemistry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Clinical', 'Collaborations', 'Collection', 'Confocal Microscopy', 'Consensus', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Electron Microscope', 'Electron Microscopy', 'Electrons', 'Evaluation', 'Face', 'Fiber', 'Forensic Medicine', 'Genetic Transcription', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Individual', 'Institutes', 'Interviewer', 'Knowledge', 'Label', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofibrillary Tangles', 'Neurofilament Proteins', 'New York', 'Oligodendroglia', 'Online Systems', 'Optic Nerve', 'Paraffin', 'Pathologist', 'Pharmaceutical Preparations', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Psychiatrist', 'Psychologist', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Schizophrenia', 'Science', 'Shotguns', 'Silver Staining', 'Space Perception', 'Stains', 'Structure', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Toxicology', 'Training', 'Transcript', 'Triad Acrylic Resin', 'Universities', 'Variant', 'Visualization', 'base', 'cognitive function', 'cohort', 'data archive', 'data fusion', 'deep neural network', 'density', 'design', 'diffusion anisotropy', 'high resolution imaging', 'histological studies', 'imaging study', 'innovation', 'instrument', 'interest', 'microscopic imaging', 'multidimensional data', 'multiple omics', 'network models', 'novel', 'precursor cell', 'psychologic', 'reconstruction', 'sex', 'symposium', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2021,641403,68331629
"Development and Validation of Radiation-Free Pediatric Renal Function Quantification Project Abstract Motivation: Chronic kidney disease (CKD) affects more than 500 million people. Children commonly develop CKD from urinary obstructive diseases and nephrotoxic therapies, and then suffer severe growth failure,  hypertension, cardiovascular risks, and neurocognitive deficits, and eventually end-stage kidney disease. Accurate renal function quantification will improve clinical management of hydronephrosis (1 in 100 babies) and  dosing/selection of chemotherapeutic regimens in oncology patients. Glomerular filtration rate (GFR), the biomarker of renal function, is derived from blood or urine tests. These tests only provide global GFR and are limited in accuracy, especially in children, and even more so in children with cancer. MRI offers superb anatomic delineation without ionizing radiation, and is thus ideal for pediatric kidney imaging. However, MRI has not been widely adopted for pediatric renal function evaluation due to lack of reliability and cumbersome workflow. These hurdles stem from the fact that the critical components required for global and regional GFR calculation, including high spatiotemporal resolution, plasma flow and arterial input function, are difficult to obtain, and that accurate image segmentation of kidneys (cortex and medulla) is labor intensive. Additionally, although the same contrast agent injection can be used for obstruction evaluation, certain areas of the kidney suffer from significant signal loss using standard MRI acquisition techniques due to high contrast agent concentrations. This project addresses these major challenges for automated comprehensive renal function evaluation in children. Approach: The project has three development aims, which are validated by clinical studies. Aim 1 will enable novel free-breathing time-resolved 3D dynamic contrast enhanced MRI that simultaneously provides accurate GFR calculation and renal plasma flow. This is achieved by incorporating self-navigated motion compensation, fast acquisition with parallel imaging and compressed sensing, and phase-contrast flow imaging. The second aim is to develop multiple new image analysis methods to extract GFR and renal plasma flow (RPF) that  leverage novel flow data of Aim 1, as well as automated new machine-learning image processing techniques for the segmentation of kidneys and ultimately global and regional GFR calculation. In Aim 3, we will develop and integrate ultrashort-echo-time techniques to address the MRI signal loss due to T2* effects from high contrast concentration for patients with obstruction, and further incorporate motion compensation and accelerated  imaging methods to enable time-resolved high-resolution dynamic MRI for contrast washout kinetics analysis in the same MR exam. Aim 4 will determine the performance of these methods in a clinical setting. Significance: This work will lead to robust, automated comprehensive pediatric renal MRI for safer and more accurate renal function evaluation in children. The techniques will facilitate widespread application in the com- munity setting and permit robust evaluation of renal function, for both children and adults. Project Narrative Kidney diseases in children often stem from blockages of the urinary tract or toxicity from medications, such as antibiotics or chemotherapies. Kidney function quantification is crucial for clinical management of these children. This work will develop accurate and automated pediatric MRI for quantification of kidney function and diagnosis of urinary tract obstruction.",Development and Validation of Radiation-Free Pediatric Renal Function Quantification,10105323,R01EB026136,"['3-Dimensional', '4D Imaging', 'Address', 'Adopted', 'Adult', 'Affect', 'Anatomy', 'Antibiotics', 'Area', 'Biological Markers', 'Blood', 'Blood flow', 'Breathing', 'Cardiac Output', 'Child', 'Childhood', 'Chronic Kidney Failure', 'Clinical', 'Clinical Management', 'Clinical Research', 'Cone', 'Consumption', 'Contrast Media', 'Data', 'Development', 'Diagnosis', 'Disease', 'Dose', 'Drug Kinetics', 'End stage renal failure', 'Evaluation', 'Evolution', 'Failure', 'Financial compensation', 'Functional Magnetic Resonance Imaging', 'Glomerular Filtration Rate', 'Gold', 'Growth', 'Hydronephrosis', 'Hypertension', 'Image', 'Image Analysis', 'Injections', 'Ionizing radiation', 'Kidney', 'Kidney Diseases', 'Kinetics', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Malignant Childhood Neoplasm', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Motion', 'Motivation', 'Neurocognitive Deficit', 'Obstruction', 'Oncology', 'Patients', 'Performance', 'Perfusion', 'Pharmaceutical Preparations', 'Phase', 'Plasma', 'Protocols documentation', 'Radiation', 'Reflux', 'Regimen', 'Renal Blood Flow', 'Renal Plasma Flow', 'Renal function', 'Reproducibility', 'Resolution', 'Signal Transduction', 'Techniques', 'Testing', 'Time', 'Toxic effect', 'Urinary tract', 'Urine', 'Validation', 'Venous', 'Work', 'antimicrobial drug', 'automated analysis', 'base', 'cardiovascular risk factor', 'chemotherapeutic agent', 'chemotherapy', 'community setting', 'computerized data processing', 'contrast enhanced', 'data acquisition', 'experience', 'image processing', 'imaging Segmentation', 'imaging modality', 'improved', 'kidney cortex', 'kidney imaging', 'loss of function', 'nephrotoxicity', 'novel', 'novel strategies', 'pressure', 'reconstruction', 'recruit', 'spatiotemporal', 'stem', 'urinary', 'urinary tract obstruction', 'urologic']",NIBIB,STANFORD UNIVERSITY,R01,2021,645115,560644462
"Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance PROGRAM SUMMARY Radiological imaging is often the first step of the diagnostic pathway for many devastating diseases; thus, an erroneous assessment of “normal” can lead to death. Whereas a grayscale object in an image can be described by its first-order image statistics—such as contrast, spatial frequency, position, entropy, and orientation—none of these dimensions, by itself, indicates abnormal vs normal radiological findings. We are a highly diverse team proposing an empirical approach to determine the mixtures of the first-order statistics—the “visual textures”— that radiology experts explicitly and implicitly use to identify the locations of potential abnormalities in medical images. Our innovative approach does not rely on assumptions about which textures may or may not be im- portant to abnormality detection. Instead, we will track the oculomotor behavior of expert radiologists to deter- mine their conscious and unconscious targeting choices, and thus ascertain which textures are empirically in- formative. The ability of expert radiologists to rapidly find abnormalities suggests that they may be able to first identify them in their retinal periphery. Peripheral visual analysis skills are therefore potentially critical to radio- logic performance, despite being understudied. We will measure these skills and leverage the results to develop perceptual learning heuristics to improve peripheral abnormality texture detection. By comparing novices to ex- perts we will determine whether the first are inexpert due to a lack of sensitivity to diagnostically relevant textures (texture informativeness), or to a lack of knowledge about which textures are abnormal, or to a combined lack of both sensitivity and knowledge. Radiology also requires the acquisition of oculomotor skills through practice and optimization. Radiologic expertise thus changes the oculomotor system in predictable and detectable ways, in much the same way that an athlete’s body and brain change as a function of expertise acquisition in their sport. We will therefore analyze both the consistency between experts’ fixation choices in medical images, and the eye movement performance characteristics of experts vs novice radiologists, to create an objective oculomotor bi- omarker of radiological expertise. The differences between novices and experts will train a deep learning (DL) system, which will have human visual and oculomotor performance characteristics. Training the DL with the abnormalities identified by a panel of expert radiologists will allow it to pinpoint the possible solutions in the manner of a simulated human radiologist performing at peak accuracy, precision, and speed. The resulting rank- ordered list of possible optimal and suboptimal image-reading strategies will serve as a benchmarking tool to quantify the performance of actual clinicians and residents who read the same images, rested vs fatigued. Meas- uring the effects of both training and fatigue on radiology expertise will be a major interdisciplinary cross-cutting advance in performance assessment. Our proposal to quantify fatigue in terms of erosion of expertise represents a transformational advance towards objective fitness-for-duty and expertise measures in medicine and beyond. PROJECT NARRATIVE There are 25-32 million perceptual errors in radiological case studies worldwide each year, contributing to med- ical error, the third most common cause of death in the US. We seek to reduce detection errors in radiology with four innovations: (1) we will empirically and objectively determine the visual textures used by expert radiologists to identify abnormalities within medical images; (2) we will determine the ways in which expert radiologists use their eyes, and especially their peripheral vision, to scan images and target informative regions; (3) we will de- velop a perceptual learning paradigm to optimally train residents in both texture perception and oculomotor per- formance domains; and (4) we will construct a deep learning model bestowed with simulated human visual and oculomotor capabilities, to create a normative model of human radiological expertise. The combined results from these studies will quantify peak expert performance and be employed to track and enhance individual expertise acquisition during radiology training; thus, the proposed research will help reduce medical error and moreover provide objective fitness-for-duty measurement tools—based on quantified biomarkers—to evaluate and ame- liorate the effects of fatigue on radiologic performance.",Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance,10220201,R01CA258021,"['Assessment tool', 'Benchmarking', 'Biological Markers', 'Brain', 'COVID-19', 'Cancer Detection', 'Case Study', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical/Radiologic', 'Collection', 'Conscious', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Diagnostic', 'Dimensions', 'Disease', 'Elements', 'Ensure', 'Entropy', 'Exposure to', 'Eye', 'Eye Movements', 'Fatigue', 'Film', 'Foundations', 'Frequencies', 'Human', 'Image', 'Incentives', 'Individual', 'Instruction', 'Knowledge', 'Lead', 'Learning', 'Location', 'Measurement', 'Measures', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Modeling', 'Nature', 'North America', 'Outcome', 'Participant', 'Pathway interactions', 'Perception', 'Perceptual learning', 'Performance', 'Peripheral', 'Positioning Attribute', 'Radiologic Finding', 'Radiology Specialty', 'Reading', 'Research', 'Residencies', 'Resolution', 'Rest', 'Retina', 'Scanning', 'Societies', 'Speed', 'Sports', 'Stress', 'System', 'Testing', 'Texture', 'Thoracic Radiography', 'Time', 'Training', 'Unconscious State', 'Vision', 'Visual', 'Workload', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cancer imaging', 'cohort', 'deep learning', 'design', 'experience', 'fitness', 'heuristics', 'human error', 'human model', 'improved', 'innovation', 'learning network', 'lung imaging', 'meetings', 'novel', 'oculomotor', 'oculomotor behavior', 'pandemic disease', 'patient safety', 'programs', 'radiological imaging', 'radiologist', 'sample fixation', 'shift work', 'skills', 'statistics', 'tool', 'tool development']",NCI,SUNY DOWNSTATE MEDICAL CENTER,R01,2021,646124,27165390
"Comprehensive characterization of coronary atherosclerotic disease using photon-counting-detector dual-source CT and its impact on patient management PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) remains the main cause of morbidity and mortality in the United States. Cardiac CT provides fast non-invasive assessment of CAD with a high sensitivity and negative predictive value – provided that the lumen can be visualized. However, heavily calcified or stented coronary segments are non- assessable, precluding non-invasive diagnosis of flow-limiting coronary plaques in an estimated 2 million U.S. adults. In addition, the spatial resolution of state-of-the-art CT systems is insufficient for robust visualization of features associated with high risk plaques. Further, while CT can quantitatively evaluate the impact of obstructive CAD on myocardial function using dynamic perfusion imaging, this requires relatively high patient radiation doses, which has limited widespread adoption. Considering the high personal and societal cost of CAD, robust, accurate, non-invasive imaging of calcified and stented coronary arteries, high-risk plaque features, and myocardial perfusion defects in a single, low-radiation-dose exam is critically needed. Built by Siemens Healthcare, a first-of-its-kind, whole-body, photon-counting-detector (PCD) CT system was installed in 2014 at the Mayo Clinic. With support from NIH award EB016966, we showed that the increased iodine contrast-to-noise ratio, decreased electronic noise, spectral imaging capabilities, and improved spatial resolution of PCD-CT relative to commercial CT enabled us to accurately measure increased vasa vasorum density in injured swine carotid arterial walls, demonstrating the exceptional potential of PCD-CT in vascular imaging. Because this system lacks cardiac imaging capabilities, our objective is to develop and validate a PCD dual-source (DS) CT system and novel imaging algorithms to accurately assess CAD in humans, especially in patients with heavily calcified, stented, or high-risk plaques, and to identify patients with myocardial perfusion defects. Our premise is that the established benefits of PCD-CT, used with a DS geometry and advanced noise reduction and material decomposition algorithms, can meet these objectives. Our proposal is significant in many ways: the technology developments will benefit all of CT imaging; robust, accurate, non-invasive imaging of calcified and stented coronary arteries, high-risk plaque features, and myocardial perfusion defects in a single, low-radiation-dose exam will obviate the need for additional imaging, reducing the overall time and cost to comprehensively evaluate CAD and its clinical significance. To extend the demonstrated benefits of PCDs to cardiac CT will require numerous physics, engineering, and algorithm innovations, including novel noise reduction and material decomposition algorithms using energy, spatial and temporal domain redundancies, as well as deep learning. These advances will culminate in a large clinical study to demonstrate not merely that the images are “better,” as is so often done, but that PCD-DSCT provides clinically-significant improvements in the diagnosis and management of patients with suspected CAD. PROJECT NARRATIVE This project will develop a new type of cardiac computed tomography (CT) scanner that is able to comprehensively assess coronary artery disease in humans. This technology, known as photon-counting- detector dual-source CT, is capable of exceptional spatial and temporal resolution, multi-energy spectral imaging and reduced radiation doses, allowing it to image the coronary artery and myocardium with unparalleled quality. This will enable comprehensive assessment of coronary artery anatomy and myocardial function from a single imaging exam, reducing time to diagnosis and cost, while also improving patient diagnosis and management.",Comprehensive characterization of coronary atherosclerotic disease using photon-counting-detector dual-source CT and its impact on patient management,10150846,R01EB028590,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Anatomy', 'Award', 'Blood Vessels', 'Cardiac', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computed Tomography Scanners', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Defect', 'Diagnosis', 'Diagnostic', 'Dose', 'Engineering', 'Equipment', 'Family suidae', 'Geometry', 'Goals', 'Healthcare', 'Heart failure', 'Human', 'Image', 'Individual', 'Iodine', 'Lesion', 'Low Dose Radiation', 'Magnetic Resonance Imaging', 'Measures', 'Modeling', 'Morbidity - disease rate', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Noise', 'Patients', 'Perfusion', 'Physics', 'Physiological', 'Predictive Value', 'Radiation', 'Radiation Dose Unit', 'Reproducibility', 'Resolution', 'Signal Transduction', 'Societies', 'Source', 'Specimen', 'Stents', 'Sudden Death', 'System', 'Techniques', 'Technology', 'Time', 'Translating', 'United States', 'United States National Institutes of Health', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'algorithm development', 'calcification', 'clinically significant', 'coronary plaque', 'cost', 'deep learning', 'density', 'design', 'detector', 'heart imaging', 'heart motion', 'high risk', 'human subject', 'imaging capabilities', 'improved', 'industry partner', 'injured', 'innovation', 'mortality', 'non-invasive imaging', 'noninvasive diagnosis', 'novel', 'perfusion imaging', 'photon-counting detector', 'routine practice', 'single photon emission computed tomography', 'societal costs', 'spectral energy', 'spectrograph', 'technology development', 'temporal measurement', 'vasa vasorum']",NIBIB,MAYO CLINIC ROCHESTER,R01,2021,657862,276703803
"Automatic Quantification and Labeling of Cerebral Microbleeds, Oxygen Saturation and Sources of Abnormal Susceptibility ABSTRACT The detection, localization and quantification of cerebral microbleeds (CMBs) plays an important role in diagnosing and establishing appropriate treatment plans in neurodegenerative diseases specifically in vascular dementia (VaD). To date, evaluating CMBs is time consuming, inaccurate and sometimes not possible. We propose to mitigate these problems by developing our software, “qSPIN”, that will provide fast and easy-to-use methods for: 1) automatic identification of CMBs and veins, 2) automatic quantification of CMBs, 3) automatic quantification of oxygen saturation in veins, and 4) creation of a user-friendly software for the practicing radiologist. Recent developments in MRI have provided a new means by which to study the role of CMBs and venous abnormalities in neurological diseases such as Alzheimer’s Disease (AD), VaD, stroke and traumatic brain injury (TBI). Susceptibility weighted imaging (SWI) has proven to be a powerful tool by which to detect CMBs and quantitative susceptibility mapping (QSM) can be used to measure changes in oxygen saturation. Knowing how many CMBs there are can predict the onset of VaD, determine whether anti-platelet therapy in stroke should be used, and correlate with neuropsychological outcome for patients with TBI. Our recent version of multi-echo SWI makes it possible to obtain both an arteriogram and a venogram simultaneously. Oxygen saturation can also be used to monitor perfusion changes and extend the window of treatment in stroke.  Currently, most radiologists and technologists do not have time to perform such detailed quantitative processing and thus it is not being done clinically. Our qSPIN software will provide this quantitative data. With the number, size, and location of CMBs or venous abnormalities, a better diagnosis would be possible. Our group is uniquely positioned to address this problem having developed many of these techniques. The novelty of our approach is the marriage of SWI, QSM, STAGE and deep learning techniques to detect these vascular and functional abnormalities. To accomplish the goals of this proposal, we will develop user friendly software that incorporates all imaging information from SWI and QSM to label CMBs. We will also provide the location of the CMBs in Talairach coordinates using a template dataset. In the end, we will have a complete picture of the prevalence of CMBs, abnormal oxygen saturation and their locations in patients with neurodegenerative disease that will improve diagnosis and potentially change their treatment. PROJECT NARRATIVE There is a huge demand today for a comprehensive analysis of diseases with cerebral microbleeds, abnormal oxygen saturation and thrombosis such as vascular dementia. The quantification of these features will have major ramifications for the diagnosis and treatment of dementia as well hypertension, stroke and traumatic brain injury all of which can lead to dementia. Therefore, our major objective in this application is to design and develop advanced image processing software that can rapidly and accurately identify and quantify the presence of cerebral microbleeds and changes in oxygen saturation in dementia and related diseases.","Automatic Quantification and Labeling of Cerebral Microbleeds, Oxygen Saturation and Sources of Abnormal Susceptibility",10101667,R44HL145826,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Arteriogram', 'Arteriosclerosis', 'Basal Ganglia', 'Blood Vessels', 'Brain', 'Brain hemorrhage', 'Businesses', 'Cerebral Amyloid Angiopathy', 'Cerebral hemisphere hemorrhage', 'Clinical', 'Computer software', 'Consumption', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Diagnosis', 'Diffuse Axonal Injury', 'Disease', 'Feedback', 'Goals', 'Hemorrhage', 'Hypertension', 'Image', 'Image Analysis', 'Impaired cognition', 'Infarction', 'Iron', 'Label', 'Lead', 'Link', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Marriage', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Multiple Sclerosis', 'Neurodegenerative Disorders', 'Neuropsychology', 'Outcome', 'Oxygen', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Play', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Protocols documentation', 'Protons', 'Published Comment', 'Reporting', 'Role', 'Sampling', 'Site', 'Source', 'Spatial Distribution', 'Stroke', 'TBI Patients', 'Techniques', 'Testing', 'Thalamic structure', 'Thrombosis', 'Time', 'Training', 'Traumatic Brain Injury', 'Vascular Dementia', 'Veins', 'Venous', 'base', 'cerebral microbleeds', 'cerebral vein', 'computerized data processing', 'contrast imaging', 'deep learning', 'density', 'design', 'image processing', 'improved', 'innovation', 'mild traumatic brain injury', 'nervous system disorder', 'neurovascular', 'prototype', 'quantitative imaging', 'radiologist', 'stroke risk', 'tool', 'treatment planning', 'user friendly software']",NHLBI,"MAGNETIC RESONANCE INNOVATIONS, INC.",R44,2021,667050,667050
"Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction Nuclear medicine imaging in children has been shown to have significant clinical value across all organ systems. In providing this significant benefit it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that of adults, owing to their higher tissue sensitivity and longer potential lifespan. The governing principle of this project will be to minimize radiation dose while methodically ensuring that lesion detection performance is fully preserved. This will be accomplished by using validations based on both numerical and physician observers measuring performance in tasks that emulate those performed clinically. We will employ two approaches in tandem to enable lowering dose while maintaining performance. First, we will use advanced image reconstruction and processing techniques. Corrections for various forms of image quality degradation will be incorporated in the reconstruction, and deep learning (DL) will be used for post-reconstruction denoising. Second, we will develop methods to correct for both body and respiratory motion, which degrade diagnostic accuracy. Correcting for body and respiratory motion will allow dose to be reduced without loss of image quality and will also offer a technological alternative to using sedation or even general anesthesia to minimize motion when imaging children. For this investigation we have selected 99mTc-labeled dimercaptosuccinic acid (DMSA) renal imaging as a testbed to demonstrate our approaches. Damage to the renal cortex resulting from infection of the kidneys is a critical issue in children, including newborns and toddlers. DMSA SPECT is the “gold-standard” in the evaluation of pyelonephritis and renal scarring post- infection. The concepts we will demonstrate for reduction of radiation dose and correction of motion with DMSA will be translatable to other SPECT (and PET) studies in pediatric imaging and beyond.  Our Specific Aims are: 1. Establish infrastructure for investigating and evaluating advanced reconstruction and motion correction; 2. Determine the extent of radiation dose reduction to pediatric patients through improved reconstruction and DL denoising while maintaining optimal full-dose lesion detection accuracy; 3. Develop data-driven and depth-sensing camera methods for body and respiratory motion estimation and correction; and 4. Conduct numerical and physician observer studies to validate the level of dose reduction enabled by DL denoising and motion correction. Narrative  In nuclear medicine imaging, it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that in adults, owing to their higher tissue sensitivity and longer potential lifespan. Correcting for body and respiratory motion occurring during imaging will improve the quality of the formed three-dimensional images of the patient by reducing blurring and image artifacts and offer a technological alternative to using sedation or even general anesthesia to reduce motion when imaging children, which can bear health risks of its own. We propose an advanced reconstruction methodology which would enable reduction in the amount of activity administered and compensate for patient motion during imaging.",Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction,10168531,R01EB029315,"['3-Dimensional', 'Adult', 'Algorithms', 'American', 'Area', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'DMSA', 'Data', 'Databases', 'Detection', 'Development', 'Discipline of Nuclear Medicine', 'Dose', 'Enhancing Lesion', 'Ensure', 'European', 'Evaluation', 'Freedom', 'Gaussian model', 'General Anesthesia', 'Gold', 'Guidelines', 'Health', 'Hybrids', 'Image', 'Imaging problem', 'Infection', 'Infrastructure', 'Investigation', 'Kidney', 'Label', 'Lesion', 'Longevity', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Morphologic artifacts', 'Motion', 'Newborn Infant', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Population', 'Positron-Emission Tomography', 'Procedures', 'Pyelonephritis', 'ROC Curve', 'Radiation Dose Unit', 'Respiration', 'Risk', 'Scheme', 'Sedation procedure', 'Societies', 'Statistical Study', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Tissues', 'Toddler', 'Ursidae Family', 'Validation', 'base', 'body system', 'cardiac single photon emission computed tomography', 'clinically significant', 'deep learning', 'denoising', 'denoising deep learning', 'diagnostic accuracy', 'image processing', 'image reconstruction', 'improved', 'innovation', 'kidney cortex', 'kidney infection', 'molecular imaging', 'pediatric patients', 'preservation', 'reconstruction', 'renal scarring', 'respiratory', 'response', 'single photon emission computed tomography']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2021,724046,294146927
"High-definition, wide field of view corneal imaging The cornea is the primary focusing structure of our visual system. Infections and diseases in the tissue can impair vision and lead to blindness, even in eyes with intact neurosensory function. Corneal disease is one of the leading causes of visual deficiency and blindness in the world. Tissue evaluation is an important step for assessing the health of the donor cornea and its appropriateness for different types of placement, yet this process suffers from high subjectivity. High-definition corneal imaging is needed to assist in selection of the most appropriate tissue for transplant. Progress on this front would greatly serve public need, as the cornea is the most commonly transplanted tissue worldwide, with nearly 185,000 transplants annually. Thus, a more sensitive and quantitative method for objective evaluation of tissue at eye banks is needed. We have developed a 3D high-definition imaging instrument based on Gabor-Domain Optical Coherence Microscopy (GDOCM). Our SBIR Phase I research successfully accomplished all Aims and demonstrated the feasibility of quantitative assessment of corneal tissue over a large field of view with GDOCM. Our Phase I results demonstrated that GDOCM has the following key advantages over existing corneal imaging techniques, which include specular and confocal microscopy: 1) improved accuracy of tissue qualification with 4-10x increase in field of view that reduces sampling error – this will provides a truer assessment of the overall tissue characteristics; 2) ability to simultaneously measure corneal thickness, quantify endothelial cell density, and identify morphological variations due to corneal disease – this will lead to complete corneal evaluation in a single instrument; 3) leveraging machine learning innovations to minimize variability induced by users – this will result in a more objective evaluation; 4) enhanced 3D cellular-level imaging of thin translucent endothelial cells – this will enable a detailed understanding of cell viability. The results of the proposed Phase studies II will demonstrate that GDOCM can provide high-definition, 3D visualization of corneal structures with immediate commercial application for qualification of donor tissue in eye banks, and with a path to in vivo clinical imaging of patients with corneal disease. Current corneal evaluation methods employed at eye banks have limited field of view and/or insufficient resolution, and their results suffer from high subjectivity. We propose to commercialize a Gabor-domain optical coherence microscope to enable non-invasive, high-definition, wide field of view imaging in 3D for eye banks.","High-definition, wide field of view corneal imaging",10172909,R44EY028827,"['3-Dimensional', 'Address', 'Area', 'Assessment tool', 'Blindness', 'Cell Count', 'Cell Density', 'Cell Survival', 'Cell Viability Process', 'Cellular Morphology', 'Characteristics', 'Clinic', 'Confocal Microscopy', 'Cornea', 'Corneal Diseases', 'Disease', 'Endothelial Cells', 'Evaluation', 'Eye', 'Eye Banks', 'Goals', 'Gold', 'Grant', 'Health', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Industry', 'Infection', 'Innovation Corps', 'International', 'Lead', 'Legal patent', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Ophthalmology', 'Optics', 'Organ Transplantation', 'Patient imaging', 'Phase', 'Positioning Attribute', 'Process', 'Research', 'Resolution', 'Rights', 'Sampling', 'Sampling Errors', 'Small Business Innovation Research Grant', 'Standardization', 'Structure', 'Technology', 'Thick', 'Thinness', 'Time', 'Tissue Donors', 'Tissue Transplantation', 'Tissues', 'Training', 'Transplantation', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visual', 'Visual impairment', 'Visual system structure', 'Visualization software', 'base', 'clinical development', 'clinical imaging', 'commercial application', 'density', 'image processing', 'improved', 'in vivo', 'in vivo regeneration', 'innovation', 'instrument', 'instrumentation', 'microscopic imaging', 'multidisciplinary', 'neurosensory', 'novel', 'phase 2 study', 'programs', 'prototype', 'screening', 'three-dimensional visualization', 'tool', 'trend']",NEI,LIGHTOPTECH CORPORATION,R44,2021,741958,974517
"Noninvasive Testing of Coronary Microvascular Reactivity Using High-resolution Free-breathing MRI PROJECT SUMMARY It was long taken for granted that obstructive coronary artery disease (CAD) is the primary driver of angina and major adverse cardiac events. However, recent landmark studies have shown that up to 50% of the patients referred for diagnostic testing have ischemia with no obstructive CAD (INOCA). A large proportion of INOCA patients have coronary microvascular dysfunction (CMD), which even in the absence of flow-limiting stenoses can lead to myocardial ischemia and carries a high risk of adverse events. The reference standard for assessment of CMD is the functional coronary reactivity (CR) test, which is invasive. Despite key studies showing value of stratifying therapy based on CR testing, the practical utility of CR testing in the INOCA population is limited by its invasive nature, which carries serious risks even at experienced centers. Hence, a noninvasive approach that can detect and stage the severity of CMD would be invaluable for managing INOCA patients. Driven by this unmet need, prior studies have employed imaging approaches to index myocardial perfusion reserve (MPR) against CR; however, the association shown to date between MPR and CR impairment has been weak, likely due to the suboptimal sensitivity of MPR to subendocardial myocardial blood flow (MBF) deficits which is a hallmark of CMD. Studies using invasive microsphere-based methods have established a stress subendocardial-to-subepicardial (endo-epi) MBF gradient of larger than 1.0 in healthy animals, and shown that it decreases well below 1 under abnormally elevated microvascular resistance. However, noninvasive detection of endo-epi MBF gradients using existing imaging strategies is challenging because of the need to resolve MBF transmurally. We have developed new MRI strategies aimed at overcoming key barriers for accurate evaluation of endo-epi MBF gradients and applied them in preliminary animal and patient studies. Based on our preliminary data, we hypothesize that in the setting of CMD, impaired microvascular CR manifests as a stress-induced endo- epi MBF gradient, and the magnitude of this gradient significantly correlates with CMD severity. To test this hypothesis, we propose 3 specific aims. In Aim 1, we will develop a free-breathing artifact-free MRI technique optimized for high-resolution imaging of endo-epi MBF gradients, combined with a machine learning approach for fully-automated objective quantification of MBF gradients. In Aim 2, we will test the hypothesis that CMD severity can be staged on the basis of MRI-derived stress MBF gradient in a pig model of CMD. In Aim 3, we will test the hypothesis that CMD severity in INOCA patients is highly correlated with MRI-derived stress MBF gradient. This project brings together multiple interdisciplinary investigators with a strong collective track record in developing cardiac imaging strategies to advance a noninvasive approach for determining CMD severity based on the MRI-derived stress MBF gradient. Hence the proposal is a major step towards improving the management of INOCA patients and towards imaging-guided evaluation of novel therapies aimed at CMD. PROJECT NARRATIVE Recent landmark studies have provided evidence that “small vessel” coronary dysfunction in patients with otherwise normal coronary arteries is a major cause of heart disease and can lead to poor health outcomes including heart failure. This research proposal seeks to develop a noninvasive approach for diagnosis and monitoring of small-vessel coronary dysfunction by developing innovative and reliable magnetic resonance imaging strategies. Our proposal has the potential to improve patient care in this population by providing a noninvasive alternative to the established invasive testing procedure, which carries a risk of complications and is only available at highly specialized medical centers.",Noninvasive Testing of Coronary Microvascular Reactivity Using High-resolution Free-breathing MRI,10217254,R01HL153430,"['Animals', 'Blood flow', 'Breathing', 'Cardiac', 'Clinical', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Vessels', 'Coronary artery', 'Data', 'Detection', 'Diagnosis', 'Diagnostic tests', 'Diet', 'Echocardiography', 'Endothelium', 'Evaluation', 'Event', 'Family suidae', 'Functional disorder', 'Funding', 'Health', 'Heart Diseases', 'Heart failure', 'Heterogeneity', 'Hypertrophy', 'Image', 'Impairment', 'Ischemia', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Medical center', 'Methods', 'Microcirculation', 'Microspheres', 'Microvascular Dysfunction', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Myocardial', 'Myocardial Ischemia', 'Myocardial perfusion', 'Nature', 'Non-Invasive Cancer Detection', 'Outcome', 'Patient Care', 'Patient imaging', 'Patients', 'Performance', 'Physiologic pulse', 'Physiology', 'Population', 'Positron-Emission Tomography', 'Procedures', 'Quality of life', 'Reference Standards', 'Research Personnel', 'Research Proposals', 'Resistance', 'Resolution', 'Risk', 'Scanning', 'Severities', 'Staging', 'Stress', 'Systole', 'Techniques', 'Testing', 'Vasodilator Agents', 'adverse event risk', 'base', 'dieting', 'experience', 'heart imaging', 'high resolution imaging', 'high risk', 'image guided', 'image reconstruction', 'imaging approach', 'improved', 'indexing', 'innovation', 'novel', 'novel therapeutics', 'outcome forecast', 'perfusion imaging', 'personalized medicine', 'recruit', 'sequence learning']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2021,760832,90419233
"Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT PROJECT SUMMARY Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before heart attacks occur and is currently used to predict risk in millions of patients annually. Under the current grant, we have established a unique collaborative multicenter registry including over 23,000 imaging datasets (REFINE SPECT) with both prognostic (major adverse cardiovascular events) and diagnostic (invasive catheterization) outcomes. Using this registry, we have demonstrated that a combination of MPS image analysis and artificial intelligence (AI) tools achieved superior predictive performance compared to visual assessment by experienced readers or current state-of-the-art quantitative techniques. In the renewal, we plan to expand REFINE SPECT with now-available enhanced datasets (adding CT and myocardial blood flow information) and leverage latest AI advances to provide a personalized decision support tool for patient-specific cardiovascular risk assessment and estimation of benefit from revascularization following MPS. The overall aim is to optimize the clinical capabilities of MPS in risk prediction and treatment guidance by integrating all available imaging and clinical data with state-of-the-art AI methods. For this work, we propose the following 3 specific aims: (1) To expand and enhance our REFINE SPECT registry including CT and MPS flow data, (2) To develop fully automated techniques for all MPS and CT image analysis, (3) To apply explainable deep learning time-to-event AI models for optimal prediction of MACE and benefit from revascularization from all image and clinical data. This work will result in an immediately deployable clinical tool, which will optimally predict risk of adverse events and establish the relative benefits from specific therapies, beyond what is possible by subjective visual analysis and mental integration of all imaging (MPS, CT, flow), and clinical data by physicians. Such quantitative integrative methods are not yet available, leaving the current practice for assessing risk and recommending therapy highly subjective. The precise quantitative results will be presented to clinicians in easy to understand terms (e.g., % risk per year, or relative risk of one therapy vs. the alternative) for a specific patient. Additionally, our methods to make AI conclusions more tangible will improve adoption of this technology. All results will be derived fully automatically thus eliminating any variability. Our approach will fit into current MPS practice and will be immediately translatable to clinics worldwide. Most importantly, this research will allow patients to benefit from increased precision and accuracy in risk assessment, thereby optimizing the use of imaging in guiding patient management decisions and ultimately improving outcomes. PROJECT NARRATIVE Myocardial perfusion imaging with SPECT is often used to predict who is at risk of heart attack and should undergo treatment such as coronary bypass or stenting; however, physicians read images visually and report results with wide variability. With the latest artificial intelligence tools and new types of imaging (including CT and fast SPECT scans), the investigators propose to develop and validate an automated clinical tool to optimize risk prediction and objectively establish the relative benefit of a specific therapy. This new tool will consider all available patient images and other relevant information to provide a personalized explanation and precise calculation of risk and potential benefits from therapy for each patient.",Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT,10110023,R01HL089765,"['Adoption', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blood', 'Blood flow', 'Calcium', 'Cardiovascular system', 'Catheterization', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Data', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'Country', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Deposition', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Event', 'Grant', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Injections', 'International', 'Joints', 'Maps', 'Measures', 'Methods', 'Modeling', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Outcome', 'Patient imaging', 'Patients', 'Perception', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Positron-Emission Tomography', 'Psyche structure', 'Public Health', 'Reader', 'Recommendation', 'Registries', 'Relative Risks', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Scanning', 'Site', 'Statistical Models', 'Stents', 'Stress', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Visual', 'Work', 'X-Ray Computed Tomography', 'adverse event risk', 'attenuation', 'cardiovascular risk factor', 'clinically relevant', 'deep learning', 'experience', 'improved', 'improved outcome', 'multidisciplinary', 'next generation', 'non-invasive imaging', 'novel', 'perfusion imaging', 'personalized decision', 'prognostic', 'radiotracer', 'relating to nervous system', 'single photon emission computed tomography', 'support tools', 'time use', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2021,777637,90419233
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",10139080,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'innovation', 'machine learning method', 'myocardial injury', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2021,790095,550947887
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,10136081,R01HL150394,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'detection test', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,821265,685608202
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,10150910,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2021,984177,1011405
"Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. Annually, malaria affects more than 200 million people and claims the lives of over 440,000 people worldwide, mostly African children. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM and incorrect treatment. An accurate means to confirm the presence of CM or to investigate for a non-malarial illness is critically needed to improve outcomes. Since Malarial retinopathy (MR) is greater than 90% specific and sensitive to the presence of CM once clinically diagnosed, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. VisionQuest Biomedical and its collaborators have assembled a team of inter-disciplinary scientists with considerable experience in automated retinal image analysis, clinical ophthalmology with specialized research in malarial retinopathy (MR), and cerebral malaria diagnosis (CM). This team will develop and test ASPIRE, a system for detection of MR consisting of automated MR detection software integrated with a low-cost and portable retinal camera. Our proposed ASPIRE system will augment, not replace, the current CM diagnostic standard; increasing the accuracy of CM diagnoses, leading to a smaller number of false positive outcomes. In Phases I and II, the research team at VisionQuest Biomedical developed the automated MR detection software and interfaced it with a handheld retinal camera. The resulting clinical prototype of ASPIRE was tested onsite in a health-clinic in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In Phase II-B, the MR detection system will be refined, productized, and the resulting commercial prototype will be validated on prospective datasets. We will accomplish this through three specific aims. In the first aim, the software system for MR detection will be adapted and improved to work with low-cost and portable iNview camera. In the second aim, we will refine iNview’s driver-software and integrate the camera with MR detection software to produce the first commercial prototype. The third aim will focus on collecting the retinal image data for algorithm testing as well as for validating the commercial prototype in an observational clinical study to be conducted at nine clinical sites in Malawi, Uganda, and Zambia in Africa. Narrative Cerebral malaria is a life-threatening clinical syndrome associated with malarial infection, which affects about 200 million people annually and claims the lives of over 440,000 people worldwide, mostly African children. The presence of malarial retinopathy can provide additional insight and improve the diagnostic accuracy of CM. This project proposes the development of a fully-automated malaria retinopathy detection system consisting of a low-cost retinal camera and automatic malaria retinopathy detection software.",Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria,10074515,R44AI112164,"['5 year old', 'Address', 'Affect', 'Africa', 'African', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'Caring', 'Cellular Phone', 'Cerebral Malaria', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Country', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Enrollment', 'Expert Systems', 'Foundations', 'Goals', 'Grant', 'Health', 'Health Personnel', 'Healthcare', 'Image Analysis', 'Incidence', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Medicine', 'Ophthalmologist', 'Ophthalmology', 'Ophthalmoscopy', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Poison', 'Predictive Value', 'Price', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Safety', 'Scientist', 'Seasons', 'Series', 'Site', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Test Result', 'Testing', 'Uganda', 'Validation', 'Work', 'Zambia', 'base', 'clinical Diagnosis', 'clinical research site', 'cost', 'cost effectiveness', 'design', 'detection platform', 'diagnostic accuracy', 'experience', 'imaging capabilities', 'improved', 'improved outcome', 'innovation', 'insight', 'malaria infection', 'mortality', 'performance site', 'portability', 'programs', 'prospective', 'prototype', 'research study', 'response', 'retinal imaging', 'screening', 'smartphone Application', 'software development', 'software systems', 'success', 'usability']",NIAID,VISIONQUEST BIOMEDICAL INC,R44,2021,1000000,1989109
"Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT) ABSTRACT: The intersection of healthcare and biomedical research is at an inflection point with the convergence of the digital revolution, advances in imaging, nanotechnology, big data science, and precision or personalized medicine. There is a wealth of meaningful, but complex information that could be extracted from imaging data but is not optimally utilized for patient care. Cancer care exemplifies the current challenges which include early detection, accurate distinction of pre- neoplastic and neoplastic lesions, prediction of tumor aggressiveness, determining infiltrative tumor margins during surgical treatment, tracking tumor evolution/ metastasis pattern, recurrence, and potential acquired resistance to treatments over time. Major strides have been made in the personalization of cancer therapies such as immunotherapy, but the availability of specific, relevant, and timely medical data and information is of critical importance to realizing the full potential of precision medicine. Nowhere is this more acutely evident than during interventions in the operating and procedure rooms. Novel methods of image guidance, data integration, information extraction, and knowledge transfer are needed to enable clinicians to fully leverage the information available, especially before, during and after invasive procedures. We are excited to re-submit a proposal for a new P41 biomedical resource center (BTRC) called Advanced Technologies for NCIGT(AT-NCIGT) with 3 TRDs, 10 new collaborative and 10 new service projects, all of which aim to investigate develop and disseminate new technologies for image guided therapy (IGT). The 3 components are Imaging Cancer Heterogeneity for IGT, Deep Learning for IGT and Intraoperative devices for IGT. These new technologies alone and in combinations will allow for greater understanding of disease state, treatment guidance, integration/navigation and in-vivo monitoring of tissue responses and improve the precision of invasive procedures. Thus the overall goal of this proposal is to investigate, develop and disseminate novel technologies for extracting new tissue characteristics (technology research and development core TRD 1: Imaging cancer heterogeneity; analyze them and make them available through state-of-the-art algorithmic and data curation approaches (Deep Learning TRD 2); and enable precise tissue sampling surgical navigation and in-vivo tissue response through the results of novel Intraoperative devices (Intraoperative devices for IGT: TRD 3). In order to effectively disseminate all this new knowledge we have 10 new collaborative and 10 new service projects and will share these novel tools through our established mechanisms, from current BTRC- National Center for Image Guided Therapy (NCIGT), which continues to be dedicated to the innovating for IGT into interventional radiology, surgery, radiation oncology, and procedure-based medicine. Project Narrative The Advanced Technologies-National Center for Image guided Therapy (AT-NCIGT) is a research and technology center with the mission of advancing patient care, by developing novel innovative tools for image guided Therapy (IGT). The three technologies encompass Imaging Cancer Heterogeneity, Deep learning and Intraoperative devices for image guided therapy which will be investigated both individually and in cross TR &D combinations. We will disseminate all technologies through a national network of collaborators, making these discoveries available to the larger medical community.",Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT),10090279,P41EB028741,"['3-Dimensional', 'Acute', 'Algorithms', 'Architecture', 'Atlas of Cancer Mortality in the United States', 'Augmented Reality', 'Biomedical Research', 'Biopsy Specimen', 'Blood', 'Brain', 'Brain Neoplasms', 'Cells', 'Characteristics', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Conventional Surgery', 'Data', 'Development', 'Devices', 'Diffusion', 'Discipline', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Evolution', 'Foundations', 'Goals', 'Health Care Research', 'Heterogeneity', 'Histopathology', 'Image', 'Imaging Device', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Information Retrieval', 'Infrastructure', 'Intervention', 'Interventional radiology', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Lung', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant neoplasm of prostate', 'Mass Spectrum Analysis', 'Medical', 'Medicine', 'Metabolic Marker', 'Metabolism', 'Metadata', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphology', 'Nanotechnology', 'Navigation System', 'Needles', 'Neoplasm Metastasis', 'Operating Rooms', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Pattern', 'Physiologic pulse', 'Procedures', 'Prostate', 'Radiation Oncology', 'Recurrence', 'Research', 'Resistance', 'Resolution', 'Retrieval', 'Risk Assessment', 'Sampling', 'Services', 'Signal Transduction', 'Source', 'Specimen', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Supervision', 'T2 weighted imaging', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Visualization', 'base', 'big-data science', 'biomedical resource', 'brain surgery', 'cancer care', 'cancer heterogeneity', 'cancer imaging', 'cancer therapy', 'data curation', 'data integration', 'deep learning', 'design', 'digital', 'image guided', 'image guided therapy', 'image registration', 'imaging modality', 'improved', 'in vivo', 'in vivo monitoring', 'innovation', 'ion mobility', 'learning strategy', 'machine learning algorithm', 'mass spectrometer', 'metabolic imaging', 'microdevice', 'neoplastic', 'new technology', 'novel', 'novel strategies', 'overtreatment', 'personalized cancer therapy', 'personalized medicine', 'precision medicine', 'prostate biopsy', 'protocol development', 'response', 'surgery outcome', 'technology research and development', 'tissue oxygenation', 'tool', 'trait', 'tumor', 'tumor heterogeneity', 'tumor hypoxia']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2021,1527478,327644200
"Web-based Automated Imaging Differentiation of Parkinsonism SUMMARY Across the globe, there has been a considerable growth in the number of people diagnosed with Parkinsonism. Estimates indicate that from 1990 to 2015 the number of Parkinsonism diagnoses doubled, with more than 6 million people currently carrying the diagnosis, and by year 2040, 12 and 14.2 million people will be diagnosed with Parkinsonism. Parkinson’s disease (PD), multiple system atrophy Parkinsonian variant (MSAp), and progressive supranuclear palsy (PSP) are neurodegenerative forms of Parkinsonism, which can be difficult to diagnose as they share similar motor and non-motor features, and they each have an increased chance of developing dementia. In the first five years of a PD diagnosis, about 58% of PD are misdiagnosed, and of these misdiagnoses about half have either MSA or PSP. Since PD, MSAp, and PSP require unique treatment plans and different medications, and clinical trials testing new medications require the correct diagnosis, there is an urgent need for both clinic ready and clinical-trial ready markers for differential diagnosis of PD, MSAp, and PSP. Over the past decade, we have developed diffusion imaging as an innovative biomarker for differentiating PD, MSAp, and PSP. In this proposal, we will leverage our extensive experience to create a web-based software tool that can process diffusion imaging data from anywhere in the world. We will disseminate and test the tool in the largest prospective cohort of participants with Parkinsonism (PD, MSAp, PSP), working closely with the Parkinson Study Group. The reason to test this in the Parkinson Study Group network, is because they are the community that evaluates Phase II and Phase III clinical trials in Parkinsonism. This web-based software tool will be capable of reading raw diffusion imaging data, performing quality assurance procedures, analyzing the data using a validated pipeline, and providing imaging metrics and diagnostic probability. We will test the performance of the wAID-P by enrolling 315 total subjects (105 PD, 105 MSAp, 105 PSP) across 21 sites in the Parkinson Study Group. Each site will perform imaging, clinical scales, diagnosis, and will upload the data to the web-based software tool. The clinical diagnosis will be blinded to the diagnostic algorithm and the imaging diagnosis will be compared to the movement disorders trained neurologist diagnosis. We will also enroll a portion of the cohort into a brain bank to ascertain pathological confirmation and to test the algorithm against cases with post-mortem diagnoses. The final outcome will be to disseminate a validated diagnostic algorithm to the Parkinson neurological and radiological community and to make it available to all on a website. NARRATIVE In this proposal, we will be developing, disseminating, and evaluating a web-based software tool that can perform MRI analyses for the diagnostic accuracy of Parkinsonism. Our goal is to leverage our years of experience and algorithm development, to test a prospective cohort of Parkinson’s disease, Multiple System Atrophy, and Progressive Supranuclear Palsy. We expect that at the end of the project, we will have validated a web-based software tool that can use MRIs from different vendors to read, analyze, and predict the diagnosis of different forms of Parkinsonism.",Web-based Automated Imaging Differentiation of Parkinsonism,10106864,U01NS119562,"['Algorithms', 'American', 'Area Under Curve', 'Autopsy', 'Biological Markers', 'Blinded', 'Brain', 'Clinic', 'Clinical', 'Clinical Trials', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Dementia', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Enrollment', 'Goals', 'Growth', 'Health', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Modeling', 'Motor', 'Movement Disorders', 'Multiple System Atrophy', 'Nerve Degeneration', 'Neurologic', 'Neurologist', 'Online Systems', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Participant', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Probability', 'Procedures', 'Process', 'Progressive Supranuclear Palsy', 'Prospective cohort', 'Protocols documentation', 'Radiology Specialty', 'Reading', 'Research Personnel', 'Risk', 'Secure', 'Signal Transduction', 'Site', 'Software Tools', 'System', 'Techniques', 'Testing', 'TimeLine', 'Tissues', 'Training', 'Translating', 'Validation', 'Variant', 'Vendor', 'Water', 'accurate diagnosis', 'algorithm development', 'atypical parkinsonism', 'clinical Diagnosis', 'cohort', 'data exchange', 'diagnostic accuracy', 'diagnostic biomarker', 'disease diagnosis', 'dopamine transporter', 'experience', 'imaging biomarker', 'improved', 'indexing', 'individualized medicine', 'innovation', 'outcome forecast', 'performance tests', 'programs', 'quality assurance', 'support vector machine', 'tool', 'treatment planning', 'web site']",NINDS,UNIVERSITY OF FLORIDA,U01,2021,1553260,188894159
