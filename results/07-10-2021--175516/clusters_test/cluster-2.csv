text,title,id,project_number,terms,administration,organization,mechanism,year,cost,funding
"A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration PROJECT SUMMARY Age-related macular degeneration (AMD), in the dry or wet form, is the leading cause of vision loss in the developed countries. The Age-Related Eye Disease Study (AREDS) showed that specific antioxidant vitamin supplementation reduces the risk of progression from intermediate stages to late AMD and maintains visual acuity in approximately 25% of patients. While treatment of wet AMD with Intraocular injections can be effective in maintaining vision, such treatments are costly and may be associated with significant cardiovascular risks, or even progression of dry AMD. Hence, it is critical to identify patients at the earlier stages. Unfortunately, there is no effective, automated screening tool to accomplish this, and the patients themselves may be asymptomatic. The goal of this SBIR Direct-to-Phase II proposal is to provide such tool. We have demonstrated the feasibility of AMD screening software ‘iPredictTM’ by successfully identifying 98.1% of individuals with early or intermediate stage AMD. iPredictTM also successfully predicted which individuals would develop late AMD within one year with 87.8% accuracy and two years with 88.4% accuracy. iPredictTM has prototype components for image analysis and machine learning. We also developed a HIPAA compliant telemedicine platform which will enable iPredictTM to perform large-scale screening from remote and rural areas. In order to bring the product to market, these components need to be integrated and tested which is the aim of our proposed Direct-to-Phase II proposal. We aim to develop the finished product which will be ready for the market. We also aim to evaluate the efficacy of iPredictTM in a clinical setup. The AMD preventative market is estimated around $5.4 billion in the U.S. alone. iPredictTM will capture the major market share with its best accuracy and be the first prediction tool for AMD. We aim to commercialize iPredictTM for the screening and prevention of AMD, saving millions of citizens from blindness and reduced quality of life. With iPredictTM’s improvements in speed of delivery, cost of care, and ease of access, the product will be a significant addition to the healthcare system. The iPredictTM’s telemedicine platform will allow large-scale screening from remote/rural areas, primary care clinics, optometry offices and ophthalmology clinics. PROJECT NARRATIVE Age-related macular degeneration (AMD) in its late forms, “dry” or “wet”, is the leading cause of blindness in developed countries. Early intervention and therapy can significantly reduce the progression of early to late AMD. Hence, the identification of patients with early AMD and referral to an ophthalmologist is critically needed to help prevent vision loss. To achieve this goal, we propose to develop an automated screening and prediction system that can be widely deployed to identify these individuals at risk of vision loss.",A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration,10320271,R44EY031202,"['Affect', 'Age', 'Age related macular degeneration', 'American', 'Antioxidants', 'Blindness', 'Categories', 'Clinic', 'Clinical', 'Clinics and Hospitals', 'Code', 'Color', 'Computer software', 'Counseling', 'Data', 'Data Set', 'Databases', 'Developed Countries', 'Devices', 'Diagnosis', 'Drusen', 'Ear', 'Early Intervention', 'Evaluation', 'Eye', 'Eye diseases', 'Feasibility Studies', 'Fees', 'Goals', 'Health Insurance Portability and Accountability Act', 'Healthcare Systems', 'Image', 'Image Analysis', 'Incentives', 'Individual', 'Injections', 'Intervention', 'Java', 'Lasers', 'Learning Module', 'Machine Learning', 'Manuals', 'Methods', 'Minerals', 'Modeling', 'New York', 'Nonexudative age-related macular degeneration', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patients', 'Phase', 'Prevention', 'Prevention strategy', 'Primary Health Care', 'Provider', 'Pythons', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Sales', 'Savings', 'Screening procedure', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Smoking', 'Specialist', 'Speed', 'Sun Exposure', 'Supplementation', 'System', 'Telemedicine', 'Testing', 'Therapeutic Intervention', 'Time', 'Trademark', 'Treatment Cost', 'Validation', 'Vision', 'Visit', 'Visual Acuity', 'Vitamins', 'age related', 'base', 'biobank', 'cardiovascular risk factor', 'care costs', 'checkup examination', 'commercial application', 'convolutional neural network', 'cost', 'deep learning', 'follow-up', 'improved', 'photobiomodulation', 'prediction algorithm', 'predictive modeling', 'prevent', 'prognostic', 'programs', 'prospective', 'prototype', 'remote screening', 'research clinical testing', 'retinal imaging', 'rural area', 'screening', 'sociodemographic factors', 'software as a service', 'success', 'tool', 'user-friendly']",NEI,"IHEALTHSCREEN, INC.",R44,2021,45000,585067
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10372655,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'detection platform', 'digital health', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2021,52000,511154
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,10128374,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2021,77243,2966077
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,10158538,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2021,93342,570146095
"Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident Summary Following a large scale radiological or nuclear event, hundreds of thousands of people may be exposed to ionizing radiation/s and require subsequent dose-dependent medical management. It will be crucial to collect and analyze human biofluids (such as blood, urine, saliva) as soon as possible within the first week for accurate dose prediction and early triage decision. There is a need for FDA-approved in vitro diagnostic high-throughput biodosimetry devices with the ability to determine past radiation exposure with precision and accuracy. At the Center for High Throughput Radiation Biodosimetry, the Columbia University Center for Medical Countermeasures against Radiation (CMCR), we have developed FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system, to measure radiation-responsive proteins in human peripheral blood samples for retrospective estimation of radiation dose. The protein panel also includes biomarkers for blood leukocyte subtypes to reflect hematological sensitivity and injury. The FAST- DOSE assay system is intended as an in vitro diagnostic device (IVD) as defined by 21 CFR 809.3. The platform uses a commercial imaging flow cytometry system (ImageStream®X) and associated Image Data Exploration and Analysis Software (IDEAS®) to rapidly quantify changes in biomarker expression levels within specific cellular structures using fluorescent imagery and algorithms for estimation of absorbed dose. The studies planned here are designed to develop and optimize our FAST-DOSE assay system to accurately estimate absorbed dose and assess hematopoietic injury in human lymphocytes after ionizing irradiation. The first objective is to build on our current biomarker validation data for early engagement with the FDA via the pre-submission process. We have used the human ex vivo model and humanized mouse (Hu-NSG) and non- human primate (NHP) models to validate biomarker expression and radiosensitivity in blood leukocytes after acute ionizing radiation exposure. The Specific Aims proposed here are designed to: optimize the assay protocol and identify biomarker dose/time kinetics for accurate dose predictions in vitro and test 1) inter-donor variation, 2) intra-donor variation and 3) inter-laboratory variability (Aim 1); test the effect of specific confounders: age and sex, inheritance with germline BRCA1/2 pathogenic variant, and inflammation and trauma on the biomarker response, before and after irradiation (Aim 2); measure biomarker levels and time kinetics in vivo and correlate with hematopoietic injury, based on peripheral blood leukocyte counts, and stem and progenitor cell levels in the bone marrow of Hu-NSG mice (Aim 3) and, develop mathematical models (using machine learning and regression techniques) to select the best FAST-DOSE biomarkers and their combinations for generating dose predictions based on the ex vivo and in vivo dose response of these biomarkers (Aim 4). Our vision for future development is to develop a more simplified, faster rapid FAST-DOSE assay system whereby the biomarkers could be developed and transitioned for use in a point-of-care (POC) device. NARRATIVE We have developed a high-throughput biodosimetry device, the FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system to measure radiation-responsive proteins in human blood leukocytes for retrospective estimation of radiation dose. Studies are designed to validate and test the performance of the blood protein biomarker panel to accurately predict absorbed dose after ionizing radiation exposure. We will correlate biomarker expression levels and time kinetics with hematopoietic injury, based on peripheral blood leukocyte counts and bone marrow toxicity in humanized mice.","Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident",10336135,U01AI148309,"['Academic Medical Centers', 'Acute', 'Age', 'Algorithms', 'BRCA1 gene', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Proteins', 'Blood specimen', 'Bone Marrow', 'Burn injury', 'Cell Culture Techniques', 'Cellular Structures', 'Computer software', 'Confidence Intervals', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Dose', 'Exposure to', 'FDA approved', 'Flow Cytometry', 'Fluorescence', 'Future', 'Gold', 'Hematology', 'Hematopoietic', 'Human', 'Image', 'Imagery', 'Immune', 'Immunoassay', 'Individual', 'Industrial Accidents', 'Inflammation', 'Inherited', 'Injury', 'Ionizing radiation', 'Ions', 'Kinetics', 'Laboratories', 'Leukocytes', 'Linear Regressions', 'Lymphocyte', 'Machine Learning', 'Mass Screening', 'Measures', 'Medical', 'Medical center', 'Modeling', 'Mus', 'Noise', 'Nuclear Accidents', 'Pathogenicity', 'Patients', 'Performance', 'Physiological', 'Population', 'Process', 'Proteins', 'Protocols documentation', 'Radiation', 'Radiation Accidents', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation exposure', 'Reaction Time', 'Reproducibility', 'Research Design', 'Roentgen Rays', 'Saliva', 'Screening procedure', 'Seeds', 'Surface Antigens', 'System', 'Techniques', 'Testing', 'Time', 'Toxic effect', 'Trauma', 'Triage', 'Uncertainty', 'Urine', 'Variant', 'Vision', 'White Blood Cell Count procedure', 'base', 'biodosimetry', 'biomarker panel', 'biomarker performance', 'biomarker validation', 'blood damage', 'data exploration', 'design', 'dirty bomb', 'dosimetry', 'humanized mouse', 'in vitro testing', 'in vivo', 'in-vitro diagnostics', 'irradiation', 'machine learning algorithm', 'mathematical model', 'medical countermeasure', 'micronucleus', 'nonhuman primate', 'nonlinear regression', 'performance tests', 'peripheral blood', 'point of care', 'predicting response', 'predictive modeling', 'protein biomarkers', 'response', 'response biomarker', 'sex', 'stem', 'stem cells']",NIAID,COLUMBIA UNIVERSITY HEALTH SCIENCES,U01,2021,100000,558628098
"CounterAct Administrative Supplement to NS114020 Automated Phenotyping in Epilepsy Acute intoxication with organophosphorus (OP) pesticides is a significant public health concern and long-term neurological effects are not well understood. A major obstacle to progress towards reproducible, rigorous preclinical research in the long-term effects of OP- induced status epilepticus is that current experimental approaches often require prohibitively time and labor-intensive 24/7 video-EEG monitoring and inherently subjective scoring of seizures by human observers (like the widely used Racine scale). While algorithms for automated seizure detection in EEG are improving, the critically important behavioral manifestations of acquired epilepsy and assessment of its cognitive comorbidities remain poorly quantified. Our parent grant focuses on developing an objective, high-throughput technique to characterize epileptic phenotypes using a new method called motion sequencing (MoSeq) and apply it to automated anti-epileptic drugs (AED) screening. The central idea of MoSeq rests on the discovery that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales that are arranged according to specific rules (“grammar”) that can be detected without observer bias by artificial intelligence (AI)-assisted 3D video analysis. In this administrative supplement project, we propose to employ and refine MoSeq to address key challenges in research into the development of new medical countermeasures (MCM) against nerve agents and OP pesticides. This includes testing if it is possible to objectively study the long-term effects of OP intoxication and evaluate MCMs at scale by determine epilepsy-specific behavioral modules and associated transition probabilities in mice after acute OP exposure. In addition, given that neuroinflammation is likely to play a key role in OP-induced persistent neuronal circuit disturbance, we will test if microglial depletion can rescue the OP-induced chronic changes in behavioral syllables and transition probabilities. Together, the aims in this administrative supplement will both benefit from and contribute to our parent grant’s goal to develop a reliable, sharable tool for the research community to study seizures and cognitive comorbidities of epilepsy. There is an urgent need for medical countermeasures (MCMs) against nerve agents and organophosphorus (OP) pesticides. The project will leverage from our recent technical breakthroughs in artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to test if it is possible to objectively study the long-term effects of OP intoxication and evaluate MCMs at scale. If successful, this innovative approach is expected to have a significant and sustained impact on preclinical research by enabling objective, automated, inexpensive, reproducible assessment of epileptic phenotypes in experimental animals after acute OP intoxication to aid the testing of anti-seizure drugs and other novel therapies.",CounterAct Administrative Supplement to NS114020 Automated Phenotyping in Epilepsy,10227611,R01NS114020,"['3-Dimensional', 'Acute', 'Address', 'Administrative Supplement', 'Animal Behavior', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Cannabidiol', 'Chronic', 'Cognitive', 'Communities', 'Complex', 'Data', 'Detection', 'Development', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Exposure to', 'Goals', 'Human', 'Intoxication', 'Isoflurophate', 'Long-Term Effects', 'Longitudinal Studies', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Neurologic Effect', 'Observer Variation', 'Pesticides', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Probability', 'Public Health', 'Reproducibility', 'Research', 'Rest', 'Seizures', 'Status Epilepticus', 'Stereotyping', 'Structure', 'Techniques', 'Technology', 'Testing', 'Three-dimensional analysis', 'Time', 'acquired epilepsy', 'automated algorithm', 'comorbidity', 'improved', 'innovation', 'medical countermeasure', 'nerve agent', 'neuroinflammation', 'neuronal circuitry', 'novel therapeutics', 'parent grant', 'pre-clinical research', 'screening', 'tool', 'valproate']",NINDS,STANFORD UNIVERSITY,R01,2021,123798,560644462
"Continuing Tool Development for Longitudinal Network Analysis: Enriching the Diagnostic Power of Disease-Specific Connectomic Biomarkers by Deep Graph Learning Project Summary/Abstract A plethora of neuroscience studies shows mounting evidence that neurodegenerative diseases manifest distinct network dysfunction patterns much earlier prior to the onset of clinical symptoms. Since the subject-specific longitudinal network changes are more relevant to the neuropathological process than topological patterns derived from cross-sectional data, recognizing the subtle and dynamic longitudinal network biomarkers from noisy network data is of great demand to enhance the sensitivity and specificity of computer-assisted diagnosis in neurodegenerative diseases. However, current popular statistical inference or machine learning approaches used for neuroimages (in a regular data structure such as grid and lattice) are not fully optimized for the learning task on brain network data which is often encoded in a high dimensional graph (an irregular and non-linear data structure). Such gross adaption is partially responsible for the lack of reliable biomarkers that can be used to predict cognitive decline in routine clinical practice. To address this challenge, we aim to (1) develop a novel GNN (graph neural network) based learning framework to hierarchically discover the multi-scale network biomarkers that can recognize the disease-relevant network alterations over time, and (2) examine the diagnostic power of the new network biomarkers derived from our GNN-based machine learning engine across neurodegenerative diseases such as Alzheimer’s disease, Parkinson’s disease, and frontotemporal dementia. The success of this project will allow us to integrate the novel GNN-based learning component into our current longitudinal network analysis toolbox and release the AI (artificial intelligence) based network analysis software to the neuroscience and neuroimaging community. Project Narrative The goal of this project is to continue the tool development of longitudinal network analysis for neurodegenerative diseases with the focus on the machine learning component. To do so, we will first develop the GNN (graph neural network) based learning framework to discover the multi-scale network biomarkers from the population of brain network data. After examining the diagnostic value of the network biomarkers discovered by our learning- based method across neurodegenerative diseases such as Alzheimer’s disease, Parkinson’s disease, and frontotemporal dementia, we will integrate the machine learning component into our current longitudinal network analysis software and release to the neuroscience and neuroimaging community.",Continuing Tool Development for Longitudinal Network Analysis: Enriching the Diagnostic Power of Disease-Specific Connectomic Biomarkers by Deep Graph Learning,10109509,R03AG070701,"['Address', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease diagnosis', 'Artificial Intelligence', 'Biological Markers', 'Brain', 'Clinical', 'Cognitive', 'Communities', 'Computer software', 'Computer-Assisted Diagnosis', 'Data', 'Databases', 'Diagnostic', 'Dimensions', 'Disease', 'Early Diagnosis', 'Event', 'Evolution', 'Frontotemporal Dementia', 'Goals', 'Graph', 'Image', 'Impaired cognition', 'Individual', 'Industry', 'Investigation', 'Label', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Nerve Degeneration', 'Network-based', 'Neural Network Simulation', 'Neurodegenerative Disorders', 'Neurofibrillary Tangles', 'Neurosciences', 'Outcome', 'Parkinson Disease', 'Pathway Analysis', 'Pattern', 'Population', 'Process', 'Research', 'Resolution', 'Resources', 'Sample Size', 'Senile Plaques', 'Sensitivity and Specificity', 'Source Code', 'Structure', 'Supervision', 'Symptoms', 'Syndrome', 'Techniques', 'Text', 'Time', 'United States National Institutes of Health', 'base', 'clinical practice', 'cohort', 'collaboratory', 'comparison group', 'computerized tools', 'data mining', 'data structure', 'deep learning', 'design', 'high dimensionality', 'machine learning method', 'method development', 'network dysfunction', 'neural network', 'neuroimaging', 'novel', 'outcome forecast', 'software development', 'success', 'tool', 'tool development']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,R03,2021,158733,511185245
"Evaluation of multiple medication exposures concurrently using a novel algorithm PROJECT SUMMARY The development of large observational health databases (OHD) has expanded the data available for analysis by pharmacoepidemiology research. The efficiency of these studies may be improved by simultaneously studying the association of multiple medications with a disease of interest. Unfortunately, prior research has demonstrated that it is difficult to distinguish true-positive from false-positive results when studying multiple exposures simultaneously, thus limiting the conclusions drawn from these types of studies and representing a major gap in the field. The objective of this proposal, which is the first step in achieving the applicant's long- term goal of improving the diagnosis and treatment of gastrointestinal diseases using insights derived from OHD, is to evaluate and validate medication class enrichment analysis (MCEA), a novel set-based signal-to- noise enrichment algorithm developed by the applicant to analyze multiple exposures from OHD with high sensitivity and specificity. The central hypothesis of this proposal is that MCEA has equal sensitivity and greater specificity compared to logistic regression, the most widely used analytic method for OHD, for identifying true associations between medications and clinical outcomes. The applicant will complete the following two interrelated specific aims to test the hypothesis: Aim 1 – to calculate the sensitivity and specificity of medication class enrichment analysis (MCEA) and logistic regression (LR) for identifying medication associations with Clostridium difficile infection (CDI) and Aim 2 – to calculate the sensitivity and specificity of MCEA and LR for identifying medication associations with gastrointestinal hemorrhage (GIH). The rationale for these aims is that by reproducing known medication-disease associations without false positives, MCEA can be used to identify novel pharmacologic associations with gastrointestinal diseases in future studies. The expected outcome for the proposed research is that it will demonstrate MCEA as a valid method for pharmacoepidemiology research, opening new research opportunities for the study of multi-exposure OHD. These new research opportunities may lead to more rapid identification of potential pharmacologic causes of emerging diseases and discovery of unanticipated beneficial medication effects, allowing such medications to be repurposed for new indications. To attain the expected outcome, the applicant will complete additional coursework that builds on his Master of Science in Clinical Epidemiology to learn computational biology, machine learning, and econometrics techniques. With the support of this grant and his institution, he will also directly apply these techniques to pharmacoepidemiology applications under the close mentorship of a carefully selected team of faculty with extensive experience in gastroenterology, pharmacoepidemiology, medical informatics, and mentoring prior K-award grant recipients. Through these activities, the applicant will develop the skills necessary to obtain NIH R01-level funding and become a leader in developing novel techniques for application to the epidemiologic study of gastrointestinal diseases. PROJECT NARRATIVE Traditionally, research studying medications associated with diseases are limited to analyzing one medication at a time. This novel proposal will validate medication class enrichment analysis, a recently developed algorithm to study multiple medications simultaneously for association with a disease of interest. Validation of this method will allow researchers to use existing medical databases to more rapidly identify potential medication causes of emerging diseases and identify medications with unanticipated beneficial effects, allowing such medications to be repurposed for new indications.",Evaluation of multiple medication exposures concurrently using a novel algorithm,10128442,K08DK119475,"['Address', 'Algorithms', 'Aminoglycosides', 'Antibiotics', 'Anticoagulants', 'Antiplatelet Drugs', 'Big Data to Knowledge', 'Biological', 'Carbapenems', 'Case-Control Studies', 'Cephalosporins', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Computational Biology', 'Computer software', 'Data', 'Databases', 'Development', 'Development Plans', 'Diagnosis', 'Digestive System Disorders', 'Disease', 'Electronic Health Record', 'Epidemiologic Methods', 'Evaluation', 'Faculty', 'Fluoroquinolones', 'Funding', 'Future', 'Gastroenterology', 'Gastrointestinal Diseases', 'Gastrointestinal Hemorrhage', 'Generations', 'Genomics', 'Goals', 'Grant', 'Health', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'K-Series Research Career Programs', 'Lead', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Master of Science', 'Medical', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Noise', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Penicillins', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacology', 'Research', 'Research Design', 'Research Personnel', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Techniques', 'Testing', 'Time', 'United Kingdom', 'United States Department of Veterans Affairs', 'United States National Institutes of Health', 'Validation', 'analytical method', 'base', 'beta-Lactams', 'career development', 'clinical epidemiology', 'econometrics', 'epidemiology study', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'interest', 'novel', 'research study', 'simulation', 'skills', 'usability']",NIDDK,UNIVERSITY OF PENNSYLVANIA,K08,2021,167900,593605914
"Development of an artificial intelligence-driven, imaging-based platform for pretreatment identification of extranodal extension in head and neck cancer Project Summary. The goal of this project is to develop, optimize, and evaluate an artificial intelligence (AI)- driven, medical imaging platform that utilizes computed tomography (CT) imaging to identify the presence of extranodal extension (ENE) in head and neck squamous cell carcinoma (HNSCC). HNSCC is a debilitating disease with significant patient-related morbidity related to the disease itself and its management, which is complex and consists of a combination of surgery, radiation, and chemotherapy. A key factor in determining proper HNSCC management is the presence of ENE, which occurs when tumor infiltrates through the capsule of an involved lymph node into the surrounding tissue. ENE is both an important prognostic factor and an indication for adjuvant treatment escalation with the addition of chemotherapy to radiation following surgery. This “trimodality therapy” is problematic, as it is associated with increased treatment-related morbidity and healthcare costs, but no improvement in disease control compared to upfront chemoradiation alone. The challenge is that ENE can only be definitively diagnosed pathologically after surgery, and pretreatment radiographic ENE identification has proven unreliable for even expert diagnosticians, leading to high rates of trimodality therapy and suboptimal treatment outcomes. In HNSCC management there is a critical need for improved pretreatment ENE identification to 1) select appropriate patients for surgery to avoid the excess morbidity and costs of trimodality therapy, 2) risk-stratify patients optimally, and 3) select appropriate patients for treatment de-escalation or intensification clinical trials. In recent years, Deep learning, a subtype of machine learning, under the umbrella of AI, has generated breakthroughs in computerized medical image analysis, at times outperforming human experts and discovering patterns hidden to the naked eye. While AI is poised to transform the fields of cancer imaging and personalized cancer care, there remain significant barriers to clinical implementation. The hypothesis of this project is that AI can be used to successfully identify HNSCC ENE on pretreatment imaging in retrospective and prospective patient cohorts and to develop a platform for lymph node auto-segmentation that will promote clinical utility of the platform. This hypothesis will be tested by rigorous optimization and evaluation of a deep learning ENE identification platform. Specifically, the platform will be validated for accuracy, sensitivity, specificity, and discriminatory performance on two heterogeneous retrospective datasets and two prospective cohorts derived from institutional and national Phase II clinical trials for HNSCC patients. The platform will then be directly compared with head and neck radiologists to determine if radiologist performance can be augmented with AI. In parallel, AI will be utilized to develop an auto-segmentation platform for tumor and lymph nodes, which will 1) improve the platform's clinical impact and 2) provide a valuable tool for treatment planning and future imaging-based research for HNSCC patients. 1 Project Narrative Identification of extranodal extension (ENE) for head and neck cancer in the pretreatment setting would be extremely useful in selecting the optimal treatment strategy for patients. Currently, ENE can only be definitively diagnosed pathologically after surgery, and pretreatment radiographic ENE prediction has proven unreliable for expert diagnosticians. This project uses artificial intelligence to identify ENE pretreatment on Computed Tomography, with the goal of developing a clinically usable tool to help patients with newly diagnosed head and neck cancers and their physicians choose the most effective treatment strategy that minimizes the risk of side effects.","Development of an artificial intelligence-driven, imaging-based platform for pretreatment identification of extranodal extension in head and neck cancer",10105483,K08DE030216,"['Adjuvant', 'Algorithms', 'Artificial Intelligence', 'Biopsy', 'Clinic', 'Clinical', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Enrollment', 'Evaluation', 'Extranodal', 'Eye', 'Foundations', 'Future', 'Geography', 'Goals', 'Head', 'Head and Neck Cancer', 'Head and Neck Squamous Cell Carcinoma', 'Head and neck structure', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Institution', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Medical Imaging', 'Morbidity - disease rate', 'Neck Dissection', 'Newly Diagnosed', 'Operative Surgical Procedures', 'Output', 'Pathologic', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phase II Clinical Trials', 'Physicians', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Prognostic Factor', 'Prospective cohort', 'Radiation', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Scientist', 'Sensitivity and Specificity', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'cancer imaging', 'capsule', 'chemoradiation', 'chemotherapy', 'clinical implementation', 'cohort', 'computerized', 'cost', 'deep learning', 'design', 'disorder control', 'effective therapy', 'heuristics', 'imaging platform', 'improved', 'insight', 'interest', 'lymph nodes', 'neural network', 'neural network architecture', 'novel', 'optimal treatments', 'patient stratification', 'personalized cancer care', 'phase II trial', 'prediction algorithm', 'prospective', 'prospective test', 'radiologist', 'radiomics', 'risk minimization', 'side effect', 'success', 'therapy development', 'tool', 'treatment planning', 'treatment strategy', 'tumor']",NIDCR,BRIGHAM AND WOMEN'S HOSPITAL,K08,2021,168240,327644200
"Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions Project Summary/Abstract DNA sequencing has spawned the “microbiome revolution” -- thousands of microbes and a dizzying number of microbial interactions that are associated with human health and disease. Unfortunately, most species in the microbiome are known only by a (partial) genome. The limited phenotypic data on newly discovered bacteria reveal species that behave unlike any of our model organisms. While genome-scale modeling plays an important role in understanding the microbiome, the paucity of phenotypic data for most species prevents detailed simulation of the microbial communities that affect our health. This project will develop an automated system for profiling, synthesizing, and modeling microbial communities. The center of our approach is Deep Phenotyping, an automated robotic platform that performs complex growth experiments on demand. Data from Deep Phenotyping will be used to train metabolic and statistical models of the oral pathogens Streptococcus mutans and Candida albicans to predict conditions that keep both microbes in a nonpathogenic state. Project Narrative The microbiome revolution has uncovered thousands of species of bacteria with roles in health and disease. This project automates the identification of interactions between environments, genes, and the microbes that live in and around us. Understanding these interactions is a critical step in re-engineering the microbiome to improve human health.","Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions",10063870,R21EB027396,"['Affect', 'Animal Model', 'Antibiotics', 'Area', 'Bacteria', 'Biochemical Pathway', 'Bioinformatics', 'Biological', 'Biological Assay', 'Candida albicans', 'Carbon', 'Coculture Techniques', 'Collaborations', 'Combinatorics', 'Communities', 'Complex', 'Computer software', 'DNA sequencing', 'Data', 'Development', 'Disease', 'Engineering', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Future', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Human Microbiome', 'Hybrids', 'Image', 'Individual', 'Knock-out', 'Knowledge', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Metabolic', 'Methods', 'Microbe', 'Microbiology', 'Modeling', 'Oral', 'Oral candidiasis', 'Pathway interactions', 'Phenotype', 'Play', 'Positioning Attribute', 'Regulator Genes', 'Research Personnel', 'Robotics', 'Role', 'Shapes', 'Source', 'Statistical Models', 'Streptococcus mutans', 'Structure', 'System', 'Technology', 'Time', 'Training', 'Work', 'base', 'combinatorial', 'cost', 'design', 'dysbiosis', 'experience', 'experimental study', 'fitness', 'fungus', 'genome-wide', 'improved', 'instrumentation', 'large datasets', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microorganism interaction', 'network models', 'open source', 'oral pathogen', 'pathogenic fungus', 'phenotypic data', 'preference', 'prevent', 'screening', 'simulation', 'transcription factor', 'transcriptome sequencing', 'transposon sequencing']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2021,178370,76545728
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,10077550,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2021,190362,2135841
"High Throughput Screen and High Information Follow-Up Tests for Genotoxicants Project Summary  Current batteries of genetic toxicology assays exhibit several critical deficiencies. First, the throughput capacity of in vitro genotoxicity tests is low, and does not meet current needs, especially for early, high volume screening environments that need to prioritize chemicals for further testing and/or development. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no information provided about genotoxic mode of action. This is severely limiting, as it does not generate key information necessary for prioritizing chemicals for further testing, guiding subsequent assays’ endpoints/experimental designs, or conducting risk assessments. Finally, most current assays do not place requisite emphasis on dose response relationships, and therefore do not contextualize the results in terms of potency. These deficiencies prevent genotoxicity data from optimally contributing to modern risk assessments, where all of these capabilities and high information content are essential. We will solve these issues by developing, optimizing, and validating a two-tiered testing strategy based on multiplexed DNA damage responsive biomarkers and high-speed flow cytometric analysis. The first-tier focuses on throughput and is used to prioritize likely genotoxicants for more comprehensive analysis in second tier testing. Specifically, it involves a collection of several multiplexed biomarkers that will be used to identify likely genotoxic agents and provide a preliminary assessment of genotoxic mode of action. The gH2AX biomarker detects DNA double strand breaks, phospho-histone H3 identifies mitotic cells, nuclear p53 content reports on p53 activation in response to DNA damage, the frequency of 8n+ cells measure polyploidization, and the ratio of nuclei to microsphere counts provides information about treatment-related cytotoxicity. The second tier focuses on information content and considers many more concentrations as well as additional biomarkers, including micronucleus formation. Collectively, the tier two results provide definitive predictions about test chemicals’ genotoxic potential, mode of action, and potency. Over the course of this project we will study more than 3,000 diverse chemicals in order to understand the performance characteristics and generalizability of the two-tiered testing strategy. An interlaboratory trial will be conducted with prototype assay kits to assess the transferability of the methods, with the ultimate goal of providing the Nation with commercially available kits and testing services. Project Narrative Some chemicals in commercial use and in the environment can cause DNA damage and this damage can contribute to the development of cancer and other severe diseases. We will develop, optimize, and validate an improved testing strategy based on highly automated processes tracking several DNA damage biomarkers that can be analyzed without the need for animal testing. These methods will be configured into commercially available kits and testing services.",High Throughput Screen and High Information Follow-Up Tests for Genotoxicants,10255405,R44ES033138,"['Address', 'Animal Testing', 'Biological Assay', 'Biological Markers', 'Buffers', 'Canada', 'Cell Line', 'Cell Nucleus', 'Cells', 'Characteristics', 'Chemicals', 'Code', 'Collection', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Dose', 'Elements', 'End Point Assay', 'Environment', 'Exhibits', 'Experimental Designs', 'Flow Cytometry', 'Formulation', 'Frequencies', 'Goals', 'Health', 'Histone H3', 'Human', 'In Vitro', 'Industry', 'Logistics', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Metabolic Activation', 'Methods', 'Microspheres', 'Miniaturization', 'Mitotic', 'Modeling', 'Modernization', 'Mutagenicity Tests', 'Mutagens', 'National Toxicology Program', 'Nuclear', 'Performance', 'Phase', 'Process', 'Protease Inhibitor', 'Reagent', 'Recommendation', 'Reporting', 'Risk Assessment', 'Sampling', 'Scheme', 'Sensitivity and Specificity', 'Speed', 'Statistical Data Interpretation', 'System', 'TP53 gene', 'Techniques', 'Temperature', 'Testing', 'Time', 'Toxicogenetics', 'Toxicology', 'Training', 'Validation', 'Work', 'base', 'blind', 'cell type', 'climate change', 'computerized tools', 'cytotoxicity', 'design', 'experimental study', 'follow-up', 'genotoxicity', 'high throughput screening', 'improved', 'innovation', 'instrumentation', 'micronucleus', 'phosphatase inhibitor', 'prevent', 'programs', 'prototype', 'response', 'response biomarker', 'screening', 'testing services']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2021,204743,651293
"Sleep metrics from machine learning for Alzheimer's disease diagnostics PROJECT SUMMARY This proposal is responsive to NIH solicitation PA-17-089 for projects involving secondary analysis of pre-existing geriatric datasets. While presently there is no cure for Alzheimer’s disease, existing literature indicates that early diagnosis in the preclinical stage, i.e., before the onset of clinical symptoms, will be key to treatments. There is a pressing need for noninvasive predictors of cognitive decline that can enable early identification of individuals at Alzheimer’s disease risk. A mounting body of scientific evidence suggests that sleep disturbances (including microarchitectural disruptions to non-rapid-eye-motion sleep and decline in sleep quality) might be the earliest observable symptoms of Alzheimer’s disease. On-the-go sleep and activity monitoring could address the need for noninvasive indicators of cognitive decline in subjects who are in the (asymptomatic or mildly symptomatic) preclinical stage of Alzheimer’s disease. Here, we will build on preliminary results that reveal a set of sleep features derived from polysomnography (PSG) that are predictive of cognitive performance. We are proposing to perform secondary analysis of sleep and cognition data from the Multi-Ethnic Study of Atherosclerosis (MESA) cohort using state-of-the-art deep learning tools to enable sleep-based prediction of cognitive impairment for early detection of Alzheimer’s disease. While PSG is the gold standard for sleep measurement, it is not well- suited for routine, day-to-day use. In comparison, wrist-based measurements (e.g. actigraphy, heart rate, ECG, and pulse oximetry) obtained from wearable devices allow “on-the-go” sleep monitoring. The combination of these on-the-go measures with the latest artificial intelligence tools is a feasible route to early Alzheimer’s diagnostics. We will use attention-guided long short-term memory autoencoders to identify overt and latent characteristics of the raw time-series datasets, which will allow us to more effectively mine the rich MESA data resource. Our deep learning framework will also take into account sociodemographic variables, indicators of health status, and medications. To ensure scientific rigor, secondary validation of the MESA-trained deep learning models will be performed on PSG and actigraphy data from the Harvard Aging Brain Study, which is a longitudinal study designed to further our understanding of what differentiates normal aging from preclinical Alzheimer’s disease. To address any concern about the “black-box” nature of deep learning models, we will compare the learned feature set with sleep microarchitectural features previously computed using classical statistical techniques. Previous data suggests that a subject’s apolipoprotein ε4 (ApoE4) allele carrier status influences the degree to which their sleep patterns impact their cognitive abilities. We will verify this by incorporating ApoE4 status as an additional input to the deep learning model. Literature shows that over 60% of patients with mild cognitive impairment and Alzheimer’s disease have at least one clinical sleep disorder. The on-the-go prediction paradigm using noninvasive sleep measurements to be validated in this project will have a significant impact on early Alzheimer’s diagnostics and facilitate ongoing clinical trials. PROJECT NARRATIVE Sleep disturbances are a common feature of dementia due to Alzheimer’s disease. Early detection of Alzheimer’s disease before the onset of symptoms would be critically important for disease management and therapeutics. In this R21 Exploratory Analyses Grant, we propose to develop and validate state-of-the-art deep learning tools to discover novel sleep-based predictors for Alzheimer’s disease through secondary analysis of sleep, activity, and cognitive data from the Multi-Ethnic Study of Atherosclerosis (MESA) cohort of human subjects.",Sleep metrics from machine learning for Alzheimer's disease diagnostics,10221599,R21AG068890,"['Accelerometer', 'Address', 'Affect', 'Age', 'Alleles', 'Alzheimer disease detection', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Apolipoproteins', 'Artificial Intelligence', 'Attention', 'Biological Markers', 'Characteristics', 'Clinical', 'Clinical Trials', 'Cognition', 'Cognitive', 'Consensus', 'Data', 'Data Set', 'Dementia', 'Devices', 'Diagnostic', 'Disease', 'Disease Management', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Elderly', 'Electrocardiogram', 'Electroencephalography', 'Ensure', 'Eye', 'Funding Opportunities', 'Genetic', 'Goals', 'Gold', 'Grant', 'Health Status Indicators', 'Heart Rate', 'Impaired cognition', 'Individual', 'Learning', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Multi-Ethnic Study of Atherosclerosis', 'National Institute on Aging', 'Nature', 'Neurobehavioral Manifestations', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Polysomnography', 'Pulse Oximetry', 'Research Design', 'Route', 'Series', 'Sleep', 'Sleep Disorders', 'Sleep disturbances', 'Symptoms', 'Techniques', 'Therapeutic', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Wrist', 'actigraphy', 'aging brain', 'autoencoder', 'base', 'carrier status', 'cognitive ability', 'cognitive performance', 'cognitive testing', 'cohort', 'data resource', 'deep learning', 'drug candidate', 'drug development', 'high risk', 'human subject', 'improved', 'long short term memory', 'machine learning algorithm', 'mild cognitive impairment', 'normal aging', 'novel', 'pre-clinical', 'predictive marker', 'predictive modeling', 'response', 'secondary analysis', 'sleep pattern', 'sleep quality', 'sociodemographic variables', 'tool', 'wearable device']",NIA,UNIVERSITY OF MASSACHUSETTS LOWELL,R21,2021,217797,7208224
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10226322,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data repository', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2021,220287,570146095
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,R21EY032567,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2021,242250,685608202
"Using Multi-Spectral Imaging with Microchip Electrophoresis to Accurately Screen Newborns for Sickle Cell Disease PROJECT SUMMARY Hemoglobin (Hb) disorders are among the world's most common monogenic diseases. Nearly 7% of the world’s population carry Hb gene variants. Sickle cell disease (SCD) arises when Hb mutations are inherited homozygously (HbSS) or paired with another β-globin gene mutation. Globally, an estimated 400,000 babies are born annually with SCD, and 70%-75% are in sub-Saharan Africa (SSA). It is estimated that 50-90% in SSA die by their 5th birthday, 70% of these deaths are preventable. Effective management of SCD involves early diagnosis, and genetic counselling, and, importantly, nationwide newborn screening (NBS). NBS programs utilizing centralized laboratories have dramatically reduced SCD mortality in high-resource countries. NBS requires sensitive detection of relatively low levels of Hb variants in the presence of high fetal Hb (HbF). Normal HbA and sickle HbS should be accurately identified in the presence of high levels (up to 90%) of HbF. The current gold standard for Hb variant testing is high-performance liquid chromatography (HPLC), which requires expensive equipment and reagents, highly trained personnel, and modern laboratories. In low- resource regions, very few centralized laboratories can perform costly Hb testing. Testing is not available to the large percentage of infants born outside of a major hospital or city. There is an unmet need for affordable, portable, easy-to-use, accurate, point-of-care (POC) tests to facilitate decentralized Hb testing to enable nationwide NBS programs. In 2019, the World Health Organization (WHO) listed Hb electrophoresis as an essential in vitro diagnostic in low- and middle-income countries. We have developed a POC microchip electrophoresis Hb variant testing system, MicroChip Electrophoresis (MCE), under the product name “Gazelle Hb Variant” by Hemex Health, Inc. MCE reports Hb phenotype, Hb quantification (%Hb), and an interpretive statement showing genotype (such as SCD, Sickle Cell Trait, or Normal). MCE has been extensively validated for hemoglobinopathies, including SCD, hemoglobin E disease, and thalassemia. Newborns and infants below 6 weeks of age have very low concentrations of Hb variants other than Hb F which is high, therefore an improvement to lower the limit of detection (LoD) is needed to support NBS programs worldwide. By decreasing the LoD from the current 10% to 2%, newborns and infants can be screened with this affordable system. The innovation in this SBIR Phase I is the integration of multi-spectral imaging and machine learning based data analysis capability to MCE to develop MCE+ to accurately screen newborns for common Hb variants. We propose the following aims: Aim 1: Integrate multi-spectral imaging and machine learning algorithm into the MCE platform to enable identification and quantification of hemoglobin variants in newborns. Aim 2: Perform clinical testing of the MCE+ multi-spectral newborn screening system. Significance of this project is that MCE+ is the only affordable POC system for quantitative and objective hemoglobin variant testing that allows screening at birth. PROJECT NARRATIVE Up to 50 to 90% of children born with sickle cell disease (SCD) in economically disadvantaged countries (over 400,000 per year) die before the age of five, although the WHO estimates that 70% could be saved through simple, cost-effective treatments. Early diagnosis starting at birth is critical for implementing effective disease management, but newborn screening is a challenge for low resource environments where a decentralized, point-of-care solution is needed. This project enables our affordable, point-of-care platform based on microchip electrophoresis technology to accurately perform newborn screening.",Using Multi-Spectral Imaging with Microchip Electrophoresis to Accurately Screen Newborns for Sickle Cell Disease,10255480,R43HL156685,"['Africa', 'Africa South of the Sahara', 'Age', 'Bedside Testings', 'Birth', 'Blood', 'Care Technology Points', 'Caring', 'Child', 'Cities', 'Clinical', 'Clinical Research', 'Country', 'Data Analyses', 'Decentralization', 'Detection', 'Development', 'Disease', 'Disease Management', 'Drops', 'Early Diagnosis', 'Economically Deprived Population', 'Electrophoresis', 'Ensure', 'Environment', 'Equipment', 'Fetal Hemoglobin', 'Gender', 'Gene Mutation', 'Genetic Counseling', 'Genotype', 'Ghana', 'Gold', 'Health', 'Health Status', 'Hemoglobin', 'Hemoglobin E Disease', 'Hemoglobin concentration result', 'Hemoglobinopathies', 'High Pressure Liquid Chromatography', 'Hospitals', 'Human Resources', 'India', 'Infant', 'Inherited', 'Laboratories', 'Machine Learning', 'Mendelian disorder', 'Microchip Electrophoresis', 'Modernization', 'Mutation', 'Names', 'Neonatal Screening', 'Newborn Infant', 'Phase', 'Phenotype', 'Point-of-Care Systems', 'Population', 'Race', 'Reagent', 'Reference Standards', 'Reporting', 'Resources', 'Sickle Cell Anemia', 'Sickle Cell Trait', 'Small Business Innovation Research Grant', 'Southeastern Asia', 'Specificity', 'System', 'Teaching Hospitals', 'Technology', 'Testing', 'Thalassemia', 'Training', 'Validation', 'Variant', 'Work', 'World Health Organization', 'base', 'beta Globin', 'commercialization', 'cost', 'cost effective', 'detection limit', 'diagnostic accuracy', 'effective therapy', 'genetic variant', 'improved', 'in-vitro diagnostics', 'innovation', 'innovative technologies', 'low and middle-income countries', 'machine learning algorithm', 'miniaturize', 'mortality', 'novel', 'point of care', 'portability', 'preventable death', 'research clinical testing', 'screening', 'screening program', 'sickling', 'spectrograph', 'trait']",NHLBI,"HEMEX HEALTH, INC.",R43,2021,256580,1815440
"Computational Analysis of Enzyme Catalysis and Regulation Project Summary: It is of great fundamental and biomedical importance to understand the physical princi- ples that govern the coupling between the chemical step in a biomolecule and other events, such as penetration of water molecules into the active site, recruitment of transient metal ions, or conformational rearrangements near and afar. This is a challenging task, however, due to the intrinsic multi-scale nature of the problem. As a result, our understanding in factors that dictate the efﬁciency and speciﬁcity of enzyme catalysis remains in- complete, especially regarding contributions beyond the active site; this knowledge gap has greatly limited our ability to design highly efﬁcient enzymes de novo. Motivated by these considerations, the overarching theme of our research is to develop and apply multi-scale computational methods to reveal the underlying mechanism of enzyme catalysis at an atomic level, with a particular emphasis on establishing to what degree the chem- ical step is coupled with other processes proximal or distal to the active site. Speciﬁcally, we aim to develop an efﬁcient QM/MM framework to compute free energy proﬁles of enzyme reactions with a good balance of computational speed and accuracy; further integration with enhanced sampling approaches, machine learning techniques and modern computational hardwares enables us to gain insights into the nature of coupling be- tween the chemical step and other events during the functional cycle. Accordingly, we are in a unique position to pursue several lines of exciting applications, which include the mechanism and impact of transient metal ion recruiting in nucleic acid processing enzymes, the catalytic and regulatory mechanism of peripheral membrane enzymes, and systemic analysis of allosteric coupling in a transcription factor; an emerging research direction is to explore the interplay of stability, catalytic activity, and allostery during continuous directed evolution. Our project integrates computational method developments with applications inspired by recent experimental ad- vances, such as time-resolved crystallography, deep mutational scanning and continuous directed evolution. The research efforts will lead to novel computational tools and mechanistic insights into the regulatory mech- anisms of enzymes by processes either near or remote from the active site. Thus the project will have both fundamental impacts and implications for better design strategies for catalysis and allostery in biomolecules. Narrative: The computational methodologies we develop will be applicable to a broad set of metalloen- zymes and proteins of biomedical relevance. In particular, we target fundamental mechanistic problems in enzymes that catalyze nucleic acids synthesis/modiﬁcation and lipid metabolism, since mutations in these en- zymes are implicated in numerous human diseases such as cancer, insulin resistance and diabetes. Although our project does not focus on design of drugs, the mechanistic insights into enzyme catalysis and allosteric regulation will broaden strategies that can be used to target various enzymes of biomedical signiﬁcance.",Computational Analysis of Enzyme Catalysis and Regulation,10206585,R35GM141930,"['Active Sites', 'Allosteric Regulation', 'Catalysis', 'Chemicals', 'Computer Analysis', 'Computing Methodologies', 'Coupled', 'Coupling', 'Crystallography', 'Diabetes Mellitus', 'Directed Molecular Evolution', 'Distal', 'Drug Design', 'Enzymes', 'Equilibrium', 'Event', 'Free Energy', 'Insulin Resistance', 'Ions', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Membrane', 'Metals', 'Modernization', 'Modification', 'Molecular Conformation', 'Mutation', 'Nature', 'Nucleic Acids', 'Penetration', 'Peripheral', 'Positioning Attribute', 'Process', 'Proteins', 'Reaction', 'Regulation', 'Research', 'Sampling', 'Specificity', 'Speed', 'Techniques', 'Time', 'Tweens', 'Water', 'computerized tools', 'design', 'enzyme mechanism', 'human disease', 'insight', 'lipid metabolism', 'method development', 'mutation screening', 'novel', 'recruit', 'transcription factor']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2021,295591,61050884
"Image-guided Biocuration of Disease Pathways From Scientific Literature Realization of precision medicine ideas requires an unprecedented rapid pace of translation of biomedical discoveries into clinical practice. However, while many non-canonical disease pathways and uncommon drug actions, which are of vital importance for understanding individual patient-specific disease pathways, are accumulated in the literature, most are not organized in databases. Currently, such knowledge is curated manually or semi-automatically in a very limited scope. Meanwhile, the volume of biomedical information in PubMed (currently 28 million publications) keeps growing by more than a million articles per year, which demands more efficient and effective biocuration approaches.  To address this challenge, a novel biocuration method for automatic extraction of disease pathways from figures and text of biomedical articles will be developed.  Specific Aim 1: To develop focused benchmark sets of articles to assess the performance of the biocuration pipeline.  Specific Aim 2: To develop a method for extraction of components of disease pathways from articles’ figures based on deep-learning techniques.  Specific Aim 3: To develop a method for reconstruction of disease-specific pathways through enrichment and through graph neural network (GNN) approaches.  Specific Aim 4: To conduct a comprehensive evaluation of the pipeline.  The overarching goal of this project is to develop a computer-based automatic biocuration ecosystem for rapid transformation of free-text biomedical literature into a machine-processable format for medical applications.  The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. It will especially benefit cancer patients for which up-to-date knowledge of newly discovered molecular mechanisms and drug actions is critical. The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. In this project, a novel biocuration method for an automatic extraction of disease mechanisms from figures and text in scientific literature will be developed. These mechanisms will be stored in a database for further querying to assist in medical diagnosis and treatment.",Image-guided Biocuration of Disease Pathways From Scientific Literature,10149399,R01LM013392,"['Address', 'Architecture', 'Benchmarking', 'Biological', 'Cancer Patient', 'Communities', 'Computers', 'Databases', 'Deposition', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Pathway', 'Ecosystem', 'Elements', 'Evaluation', 'Feedback', 'Genes', 'Goals', 'Graph', 'Health', 'Image', 'Informatics', 'Knowledge', 'Label', 'Language', 'Link', 'Literature', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Medical', 'Methods', 'Molecular', 'Molecular Analysis', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'PubMed', 'Publications', 'Regulation', 'Reporting', 'Research', 'Retrieval', 'Selection Criteria', 'Signal Pathway', 'Source', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'Translations', 'Visual', 'Work', 'base', 'clinical practice', 'deep learning', 'design', 'detector', 'drug action', 'image guided', 'improved', 'individual patient', 'knowledge base', 'knowledge curation', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'precision medicine', 'reconstruction', 'success', 'text searching', 'tool', 'usability']",NLM,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,313018,63611576
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,10109124,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'data analysis pipeline', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'programmed cell death protein 1', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2021,314000,560644462
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876,338121506
"Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics Abstract The primary objective is to develop an artificial intelligence-centric, quantitative and noninvasive software platform that can be integrated into 3D angiographic scanners (DSA, CTA or MRA) to provide guidance regarding the diagnosis and management of intracranial aneurysms (IA). Hemorrhagic stroke secondary to ruptured IAs leads to significant morbidity and mortality and affects over 35,000 patients on a yearly basis in the United States. The diagnosis of asymptomatic IAs is on the rise with the increasing use of cerebral imaging. However, guidance regarding which aneurysms should be treated has not advanced. Leveraging recent advances in computational science and technology, particularly artificial intelligence, the proposed software platform built on two enabling technologies can (1) propel automated “patient-specific” hemodynamic evaluations into the clinical workflow and (2) conduct “data-driven” risk assessments of IA rupture on an individual basis. Specific research aims are to (1) develop a clinically-oriented CFD platform that enables automated “patient-specific” hemodynamic evaluations of IAs, (2) investigate data-driven analytics toward prediction of rupture risk for IAs and (3) evaluate the data-driven analytics in a blind study. Once validated, a follow-up R01 project is planned to examine the clinical utility of the proposed software platform in a prospective clinical study as a single gateway for computer-aided evaluation of cerebral aneurysms. Public Health Relevance/Narrative This R01 proposal is to investigate the feasibility of developing an innovative, non-invasive and artificial intelligence-centric tool that can be used as a software add-on to clinical angiographic (e.g. DSA) scanners. The software can automatically select high-risk aneurysms for immediate treatments from a pool of patients with unruptured intracranial aneurysms, impacting the clinical management of intracranial aneurysms.",Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics,10121043,R01EB029570,"['3-Dimensional', 'Affect', 'Aneurysm', 'Angiography', 'Architecture', 'Artificial Intelligence', 'Benign', 'Biomedical Computing', 'Biomedical Engineering', 'Brain hemorrhage', 'Cerebral Aneurysm', 'Cerebrum', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computational Geometry', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Engineering', 'Ensure', 'Evaluation', 'Genetic', 'Growth', 'Human', 'Image', 'Individual', 'Intracranial Aneurysm', 'Knowledge', 'Liquid substance', 'Machine Learning', 'Medicine', 'Methods', 'Michigan', 'Morbidity - disease rate', 'Morphology', 'Natural History', 'Neural Network Simulation', 'Outcome', 'Patients', 'Physics', 'Play', 'Research', 'Research Proposals', 'Risk', 'Risk Assessment', 'Role', 'Rupture', 'Ruptured Aneurysm', 'Secondary to', 'Smoker', 'Technology', 'TensorFlow', 'Testing', 'Training', 'Translational Research', 'United States', 'Universities', 'Wisconsin', 'Work', 'analytical method', 'base', 'blind', 'computer grid', 'convolutional neural network', 'deep learning', 'flexibility', 'follow-up', 'hemodynamics', 'high risk', 'image guided', 'innovation', 'learning strategy', 'mortality', 'neurosurgery', 'open source', 'personalized management', 'prevent', 'prospective', 'prototype', 'public health relevance', 'shear stress', 'success', 'tool']",NIBIB,MICHIGAN TECHNOLOGICAL UNIVERSITY,R01,2021,346966,4826901
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,10085244,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'machine learning method', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2021,356625,323604360
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,10063532,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,360227,169622494
"Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK) PROJECT SUMMARY  Contemporary ocular surgeries are performed by skilled surgeons through operating microscopes, utilizing freehand techniques and manually operated precision micro-instruments, where the outcomes are often limited by the surgeon's skill levels and experiences. To overcome these human factors, we have assembled an interdisciplinary team including a clinician-scientist and eye surgeon, an optical device scientist and medical robotic engineers to translate existing and developing technologies in our laboratories into precision, “deep- learning” artificial intelligence (AI) guided robotic ocular surgical devices for precise automated Deep Anterior Lamellar Keratoplasty (AUTO-DALK).  DALK is a highly attractive treatment of corneal disease with normally functioning endothelium. However, the procedure is unusually challenging from a technical perspective and time-consuming, limiting its acceptance among corneal surgeons. The most challenging aspect of the procedure is related to the delamination of stroma from Descemet's membrane (DM). A procedure, commonly called “Big Bubble” is used to separate stroma from DM using deep intrastromal pneumatic injection. However, even experienced surgeons have difficulty precisely placing the injection. The most common complication of DALK is the excessive depth of the needle insertion resulting in Descemet's membrane perforation requiring conversion to full-thickness penetrating keratoplasty with its much longer recovery period and a higher risk of graft failure from rejection. The reported rates of Descemet's membrane perforation for beginner and experienced surgeons are 31.8% and 11.7% respectively. In addition, interface haze between the donor and recipient cornea is a common problem caused by the insufficient depth of needle insertion and failure to remove the host stromal tissue, which results in loss of postoperative visual acuity. These problems relate directly to the inability of the current surgical practice to precisely assess the depth of the tooltips inside the cornea layer in real-time.  Here we will build upon our previous and ongoing work in robust fiber optic common-path optical coherence tomography (CP-OCT) and AI-guide system based on convolutional neural network (CNN) robotic microsurgical tools that enable clinicians to precisely guide surgical tools at micron scale. The proposed AUTO- DALK surgical tool system is capable of one-dimensional real-time depth tracking, motion compensation, and detection of early instrument contact with tissue, which enables clinicians to perform DALK precisely and safely. The tool will be built on a handheld platform that will consist of CP-OCT probe, trephine and microinjector that allows precise and safe removal of the anterior section of cornea down to DM  We hypothesize that AI-OCT providing intelligent visualization and depth controlled optimal cornea cutting and tissue tracking will perform the task of DALK with better accuracy and efficiency over the manually performed trephine cutting and “Big Bubble” pneumodissection. Project Narrative  This proposal addresses fundamental limitations in current corneal transplant surgery by developing an artificial intelligence guided compact robotic surgical tool that could empower corneal surgeons to achieve difficult surgical objectives, reduce intraoperative complications, and improve clinical outcomes when performing Deep Anterior Lamellar Keratoplasty (DALK). Further, these capabilities are broadly applicable in other microsurgical problems, and the tools will enable further advances both for ophthalmology and for other microsurgical disciplines.",Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK),10100636,R01EY032127,"['Accounting', 'Address', 'Adrenal Cortex Hormones', 'Animal Model', 'Anterior', 'Artificial Intelligence', 'Blindness', 'Blunt Trauma', 'Burr hole procedure', 'Cadaver', 'Clinical', 'Complication', 'Consumption', 'Cornea', 'Corneal Diseases', 'Corneal Opacity', 'Corneal dystrophy', 'Data', 'Descemet&apos', 's membrane', 'Devices', 'Dimensions', 'Discipline', 'Distal', 'Drops', 'Early Diagnosis', 'Endophthalmitis', 'Endothelial Cells', 'Endothelium', 'Engineering', 'Ensure', 'Epithelial', 'Excision', 'Expert Systems', 'Eye', 'Eye Surgeon', 'Failure', 'Fiber Optics', 'Financial compensation', 'Geometry', 'Glaucoma', 'Goals', 'Graft Survival', 'Hemorrhage', 'Human', 'Image', 'Immune', 'Incidence', 'Infection', 'Injections', 'Intelligence', 'Intraoperative Complications', 'Iris', 'Keratoconus', 'Keratoplasty', 'Laboratories', 'Lamellar Keratoplasty', 'Lead', 'Manuals', 'Mechanics', 'Medical', 'Microscope', 'Modeling', 'Motion', 'Movement', 'Needles', 'Ocular Hypertension', 'Operative Surgical Procedures', 'Ophthalmology', 'Optical Coherence Tomography', 'Optics', 'Oryctolagus cuniculus', 'Outcome', 'Pathological Dilatation', 'Patients', 'Penetrating Keratoplasty', 'Perforation', 'Performance', 'Postoperative Complications', 'Postoperative Period', 'Procedures', 'Ptosis', 'Recovery', 'Repeat Surgery', 'Reporting', 'Research Personnel', 'Risk', 'Robotics', 'Rupture', 'Safety', 'Scientist', 'Secondary to', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Systems Development', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Topical Corticosteroids', 'Translating', 'Transplantation Surgery', 'Trauma', 'Validation', 'Visual', 'Visual Acuity', 'Visualization', 'Work', 'base', 'convolutional neural network', 'corneal scar', 'curative treatments', 'deep learning', 'design', 'experience', 'graft failure', 'high risk', 'iatrogenic injury', 'improved', 'in vivo', 'instrument', 'interest', 'novel', 'phantom model', 'photonics', 'preservation', 'prototype', 'sensor', 'skills', 'surgery outcome', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,409997,807432003
"Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident Summary Following a large scale radiological or nuclear event, hundreds of thousands of people may be exposed to ionizing radiation/s and require subsequent dose-dependent medical management. It will be crucial to collect and analyze human biofluids (such as blood, urine, saliva) as soon as possible within the first week for accurate dose prediction and early triage decision. There is a need for FDA-approved in vitro diagnostic high-throughput biodosimetry devices with the ability to determine past radiation exposure with precision and accuracy. At the Center for High Throughput Radiation Biodosimetry, the Columbia University Center for Medical Countermeasures against Radiation (CMCR), we have developed FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system, to measure radiation-responsive proteins in human peripheral blood samples for retrospective estimation of radiation dose. The protein panel also includes biomarkers for blood leukocyte subtypes to reflect hematological sensitivity and injury. The FAST- DOSE assay system is intended as an in vitro diagnostic device (IVD) as defined by 21 CFR 809.3. The platform uses a commercial imaging flow cytometry system (ImageStream®X) and associated Image Data Exploration and Analysis Software (IDEAS®) to rapidly quantify changes in biomarker expression levels within specific cellular structures using fluorescent imagery and algorithms for estimation of absorbed dose. The studies planned here are designed to develop and optimize our FAST-DOSE assay system to accurately estimate absorbed dose and assess hematopoietic injury in human lymphocytes after ionizing irradiation. The first objective is to build on our current biomarker validation data for early engagement with the FDA via the pre-submission process. We have used the human ex vivo model and humanized mouse (Hu-NSG) and non- human primate (NHP) models to validate biomarker expression and radiosensitivity in blood leukocytes after acute ionizing radiation exposure. The Specific Aims proposed here are designed to: optimize the assay protocol and identify biomarker dose/time kinetics for accurate dose predictions in vitro and test 1) inter-donor variation, 2) intra-donor variation and 3) inter-laboratory variability (Aim 1); test the effect of specific confounders: age and sex, inheritance with germline BRCA1/2 pathogenic variant, and inflammation and trauma on the biomarker response, before and after irradiation (Aim 2); measure biomarker levels and time kinetics in vivo and correlate with hematopoietic injury, based on peripheral blood leukocyte counts, and stem and progenitor cell levels in the bone marrow of Hu-NSG mice (Aim 3) and, develop mathematical models (using machine learning and regression techniques) to select the best FAST-DOSE biomarkers and their combinations for generating dose predictions based on the ex vivo and in vivo dose response of these biomarkers (Aim 4). Our vision for future development is to develop a more simplified, faster rapid FAST-DOSE assay system whereby the biomarkers could be developed and transitioned for use in a point-of-care (POC) device. NARRATIVE We have developed a high-throughput biodosimetry device, the FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system to measure radiation-responsive proteins in human blood leukocytes for retrospective estimation of radiation dose. Studies are designed to validate and test the performance of the blood protein biomarker panel to accurately predict absorbed dose after ionizing radiation exposure. We will correlate biomarker expression levels and time kinetics with hematopoietic injury, based on peripheral blood leukocyte counts and bone marrow toxicity in humanized mice.","Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident",10089406,U01AI148309,"['Academic Medical Centers', 'Acute', 'Age', 'Algorithms', 'BRCA1 gene', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Proteins', 'Blood specimen', 'Bone Marrow', 'Burn injury', 'Cell Culture Techniques', 'Cellular Structures', 'Computer software', 'Confidence Intervals', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Dose', 'Exposure to', 'FDA approved', 'Flow Cytometry', 'Fluorescence', 'Future', 'Gold', 'Hematology', 'Hematopoietic', 'Human', 'Image', 'Imagery', 'Immune', 'Immunoassay', 'Individual', 'Industrial Accidents', 'Inflammation', 'Inherited', 'Injury', 'Ionizing radiation', 'Ions', 'Kinetics', 'Laboratories', 'Leukocytes', 'Linear Regressions', 'Lymphocyte', 'Machine Learning', 'Mass Screening', 'Measures', 'Medical', 'Medical center', 'Modeling', 'Mus', 'Noise', 'Nuclear Accidents', 'Pathogenicity', 'Patients', 'Performance', 'Physiological', 'Population', 'Process', 'Proteins', 'Protocols documentation', 'Radiation', 'Radiation Accidents', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation exposure', 'Reaction Time', 'Reproducibility', 'Research Design', 'Roentgen Rays', 'Saliva', 'Screening procedure', 'Seeds', 'Surface Antigens', 'System', 'Techniques', 'Testing', 'Time', 'Toxic effect', 'Trauma', 'Triage', 'Uncertainty', 'Urine', 'Variant', 'Vision', 'White Blood Cell Count procedure', 'base', 'biodosimetry', 'biomarker panel', 'biomarker performance', 'biomarker validation', 'blood damage', 'data exploration', 'design', 'dirty bomb', 'dosimetry', 'humanized mouse', 'in vitro testing', 'in vivo', 'in-vitro diagnostics', 'irradiation', 'machine learning algorithm', 'mathematical model', 'medical countermeasure', 'micronucleus', 'nonhuman primate', 'nonlinear regression', 'performance tests', 'peripheral blood', 'point of care', 'predicting response', 'predictive modeling', 'protein biomarkers', 'response', 'response biomarker', 'sex', 'stem', 'stem cells']",NIAID,COLUMBIA UNIVERSITY HEALTH SCIENCES,U01,2021,483863,558628098
"Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system Abstract Numerous small vessels making up the central nervous system blood and lymphatic vascular networks are heterogeneous and region-specific dynamic structures, whose segments, position, shape and function can change in response to physiological and pathophysiological conditions. To date it has not been possible to integrate blood and lymphatic vascular elements and their microenvironment to achieve a holistic quantitative characterization of the combined brain and meningeal tissue-scale vascular networks, its structure and function in normal and disease states. This application proposes to develop microscopy- based high-throughput image analysis techniques for automated extraction of blood and lymphatic vascular networks enabling quantitative morphodynamic characterization of cerebrovascular microenvironment changes in two intracranial compartments – the brain and dura mater. The study will focus on new algorithms for precise region-specific microvessel registration, mosaicing, segmentation, fusion and colocalization for constructing large tissue scale spatially aligned dual blood/lymphatic vascular network structural maps in the animals of both sexes, as well as characterization of heterogeneities of microvascular networks, including blood and lymphatic vasculature, under estrogen and sleep deprivation (the conditions relevant to multiple cerebrovascular disorders) compared to physiological settings. In other words, advanced microscopy-based techniques will be used to image blood and lymphatic vessels at sub-micron resolution in dura mater and the brain, and then cutting-edge deep machine learning imaging analysis methods will be employed to segment and quantify these vessels, their geometry, vessel wall structure, functionality, and interrelationship. Detailed structural analysis of microvascular networks is essential for accurate evaluation of the distribution of physical forces, substrate delivery and tissue clearance of waste, as well as sex differences and consequences of intracranial networks remodeling under physiological and pathological conditions. This will create knowledge enabling a better understanding of the pathogenesis of vascular impairments under estrogen and sleep deprivation, identify common molecular mechanisms and the efficacy and effectiveness of different therapeutic treatments. Without the ability to construct total structural and functional blood/lymphatic vascular network maps from studies limited to individual tissue component parts, it is little wonder that translation from the molecular and cellular levels to the whole organ and system levels is deficient and hinders translational progress towards a comprehensive understanding of the pathophysiology associated with a range of neurological disorders. Detailed analysis of structural relationships of both blood and lymphatic circulation in the brain system will have a direct impact on our general understanding of vascular function in brain/meningeal communication, and the cause and resolution of numerous diseases resulting from intracranial vascular disorders including impact of sex hormone (estrogen) deprivation, sleep deprivation, migraines, stroke, multiple sclerosis, dural arterio-venous fistulae, intradural hygroma and hematoma, spontaneous cerebral spinal fluid leaks, and intradural aneurysms that can lead to the development of neurological and cognitive impairment, including Alzheimer's. Quantitative description of blood and lymphatic vessel network structures using image analytics and machine learning algorithms distributed as software tools will have broad applications to quantification of other thin complex curvilinear anatomical structures (i.e. nerves, neuronal circuits, neurons, and neuroglia). The new software for blood and vessel network measurement will enable translation of fundamental pathophysiological knowledge gained from this proposal towards the development and assessment of the effectiveness of treatments and therapeutic interventions to enhance health, lengthen life, and reduce illness and disability associated with a range of neurological disorders.",Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system,10138039,R01NS110915,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Aneurysm', 'Animals', 'Arteriovenous fistula', 'Blood', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Brain', 'Brain Mapping', 'Cardiovascular system', 'Cephalic', 'Cerebrospinal Fluid', 'Cerebrovascular Disorders', 'Chronic', 'Chronic Insomnia', 'Communication', 'Complex', 'Computer software', 'Cystic Lymphangioma', 'Development', 'Disease', 'Dura Mater', 'Dural Arteriovenous Fistulas', 'Effectiveness', 'Elements', 'Estrogens', 'Evaluation', 'Female', 'Functional disorder', 'Geometry', 'Gonadal Steroid Hormones', 'Health', 'Hematoma', 'Heterogeneity', 'Hybrids', 'Image', 'Image Analysis', 'Imaging Techniques', 'Impaired cognition', 'Impairment', 'Individual', 'Knowledge', 'Lead', 'Life', 'Link', 'Lymphatic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Meningeal', 'Metabolism', 'Methods', 'Microscopy', 'Migraine', 'Modeling', 'Molecular', 'Morphology', 'Mosaicism', 'Multiple Sclerosis', 'Mus', 'Nerve', 'Neuraxis', 'Neuroglia', 'Neurologic', 'Neurons', 'Optical Coherence Tomography', 'Parietal', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Physiological', 'Positioning Attribute', 'Resolution', 'Route', 'Sex Differences', 'Shapes', 'Site', 'Sleep', 'Sleep Deprivation', 'Sleep Disorders', 'Sleep disturbances', 'Software Tools', 'Stroke', 'Structure', 'Subdural Hematoma', 'Subdural Hygroma', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Thinness', 'Tissues', 'Translations', 'Treatment Effectiveness', 'Vascular Diseases', 'Vascular remodeling', 'Vascular resistance', 'Venous', 'associated symptom', 'base', 'body system', 'cerebral microvasculature', 'cerebrovascular', 'clinically relevant', 'confocal imaging', 'deep learning', 'deprivation', 'detection limit', 'disability', 'geometric structure', 'in vivo', 'lymphatic circulation', 'lymphatic vasculature', 'lymphatic vessel', 'machine learning algorithm', 'male', 'microleakage', 'nervous system disorder', 'neuronal circuitry', 'noninvasive diagnosis', 'novel', 'response', 'sex', 'sleep pattern', 'solute', 'stem', 'submicron', 'tool', 'wasting']",NINDS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,534438,63611576
"A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration PROJECT SUMMARY Age-related macular degeneration (AMD), in the dry or wet form, is the leading cause of vision loss in the developed countries. The Age-Related Eye Disease Study (AREDS) showed that specific antioxidant vitamin supplementation reduces the risk of progression from intermediate stages to late AMD and maintains visual acuity in approximately 25% of patients. While treatment of wet AMD with Intraocular injections can be effective in maintaining vision, such treatments are costly and may be associated with significant cardiovascular risks, or even progression of dry AMD. Hence, it is critical to identify patients at the earlier stages. Unfortunately, there is no effective, automated screening tool to accomplish this, and the patients themselves may be asymptomatic. The goal of this SBIR Direct-to-Phase II proposal is to provide such tool. We have demonstrated the feasibility of AMD screening software ‘iPredictTM’ by successfully identifying 98.1% of individuals with early or intermediate stage AMD. iPredictTM also successfully predicted which individuals would develop late AMD within one year with 87.8% accuracy and two years with 88.4% accuracy. iPredictTM has prototype components for image analysis and machine learning. We also developed a HIPAA compliant telemedicine platform which will enable iPredictTM to perform large-scale screening from remote and rural areas. In order to bring the product to market, these components need to be integrated and tested which is the aim of our proposed Direct-to-Phase II proposal. We aim to develop the finished product which will be ready for the market. We also aim to evaluate the efficacy of iPredictTM in a clinical setup. The AMD preventative market is estimated around $5.4 billion in the U.S. alone. iPredictTM will capture the major market share with its best accuracy and be the first prediction tool for AMD. We aim to commercialize iPredictTM for the screening and prevention of AMD, saving millions of citizens from blindness and reduced quality of life. With iPredictTM’s improvements in speed of delivery, cost of care, and ease of access, the product will be a significant addition to the healthcare system. The iPredictTM’s telemedicine platform will allow large-scale screening from remote/rural areas, primary care clinics, optometry offices and ophthalmology clinics. PROJECT NARRATIVE Age-related macular degeneration (AMD) in its late forms, “dry” or “wet”, is the leading cause of blindness in developed countries. Early intervention and therapy can significantly reduce the progression of early to late AMD. Hence, the identification of patients with early AMD and referral to an ophthalmologist is critically needed to help prevent vision loss. To achieve this goal, we propose to develop an automated screening and prediction system that can be widely deployed to identify these individuals at risk of vision loss.",A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration,10172914,R44EY031202,"['Affect', 'Age', 'Age related macular degeneration', 'American', 'Antioxidants', 'Blindness', 'Categories', 'Clinic', 'Clinical', 'Clinics and Hospitals', 'Code', 'Color', 'Computer software', 'Counseling', 'Data', 'Data Set', 'Databases', 'Developed Countries', 'Devices', 'Diagnosis', 'Drusen', 'Ear', 'Early Intervention', 'Evaluation', 'Eye', 'Eye diseases', 'Feasibility Studies', 'Fees', 'Goals', 'Health Insurance Portability and Accountability Act', 'Healthcare Systems', 'Image', 'Image Analysis', 'Incentives', 'Individual', 'Injections', 'Intervention', 'Java', 'Lasers', 'Learning Module', 'Machine Learning', 'Manuals', 'Methods', 'Minerals', 'Modeling', 'New York', 'Nonexudative age-related macular degeneration', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patients', 'Phase', 'Prevention', 'Prevention strategy', 'Primary Health Care', 'Provider', 'Pythons', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Sales', 'Savings', 'Screening procedure', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Smoking', 'Specialist', 'Speed', 'Sun Exposure', 'Supplementation', 'System', 'Telemedicine', 'Testing', 'Therapeutic Intervention', 'Time', 'Trademark', 'Treatment Cost', 'Validation', 'Vision', 'Visit', 'Visual Acuity', 'Vitamins', 'age related', 'base', 'biobank', 'cardiovascular risk factor', 'care costs', 'checkup examination', 'commercial application', 'convolutional neural network', 'cost', 'deep learning', 'follow-up', 'improved', 'photobiomodulation', 'prediction algorithm', 'predictive modeling', 'prevent', 'prognostic', 'programs', 'prospective', 'prototype', 'remote screening', 'research clinical testing', 'retinal imaging', 'rural area', 'screening', 'sociodemographic factors', 'software as a service', 'success', 'tool', 'user-friendly']",NEI,"IHEALTHSCREEN, INC.",R44,2021,545819,585067
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,10136061,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2021,579506,560644462
"BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging Project Summary Electrophysiological recordings in humans and animals play an essential role in developing an understanding of the human brain. Signal recording technology spans the entire scale from invasive microelectrode single-unit recordings, through mesoscale macroelectrode measures of local field potentials, to whole-brain monitoring through measurement of scalp potentials (EEG) and extracranial magnetic fields (MEG). Analysis of these data presents a host of challenges, from low level noise removal and artifact rejection to sophisticated spatio-temporal modeling and statistical inference. The multidisciplinary neuroscience research community has an ongoing need for validated and documented open-source software to perform this analysis and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets this need. Brainstorm is a Matlab/Java multi-platform (Linux, MacOS, Windows) software package for analysis and visualization of electrophysiological data. The software is extensively documented through a series of detailed tutorials and actively supported through a user forum and a mailing list. Over the past 8 years we have registered 16,000 distinct users, provided hands on instruction to 1,200 trainees, and the software has been used and cited in ~600 journal papers. Brainstorm includes tools for importing MEG/EEG, intracranial EEG, animal electrophysiology, and near-infrared spectroscopy (NIRS) data from multiple vendors, extensive interactive features for data preprocessing, selection and visualization, coregistration to volume and surface MRIs and atlases, forward and inverse mapping of cortical current density, time-series and connectivity analysis, and a range of statistical tools. Data can be analyzed through a graphical interface or through scripted pipelines. The current proposal represents a plan to extend Brainstorm in a manner that leverages the unique features of our software and addresses important needs for large-scale data analysis. In this project we will continue to extend and support our software through the following three specific aims: (i) we will harness recent developments in distributed and shared data and high performance computing resources, together with standardization of data organization, to facilitate large-scale, reproducible analysis of electrophysiological data. (ii) We will also address the need for improved modeling resulting from the increasing use of both invasive recordings and direct brain stimulation through development of new modeling software for accurate computation of the intracranial electromagnetic fields produced by brain stimulation and neuronal activation. (iii) Finally, we will continue to add new functionality and to support the software through in-person training, online forums, documentation and other resources. Project Narrative Magnetoencephalography (MEG) and Electroencephalography (EEG) are absolutely non-invasive brain imaging tools, which provide information on the spatial distribution and precise temporal orchestration of human brain activity. In addition to basic neuroscience research, MEG and EEG can be also used to understand and diagnose abnormalities underlying a wide range neurological and psychiatric illnesses, including epilepsy, schizophrenia, obsessive-compulsive disorder, autism spectrum disorders, and Alzheimer's disease, as well as cognitive deficits such as delayed acquisition of language. The neuroscience research community has an ongoing need for validated and documented open-source software to perform these analyses and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets these needs with well-documented and tested novel analyses using MEG and EEG in combination with anatomical MRI and intracranial EEG data.",BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging,10113609,R01EB026299,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animals', 'Archives', 'Area', 'Atlases', 'Basic Science', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical Research', 'Cloud Computing', 'Code', 'Cognitive deficits', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Development', 'Diagnosis', 'Documentation', 'Educational workshop', 'Electrodes', 'Electroencephalography', 'Electromagnetic Fields', 'Electromagnetics', 'Electrophysiology (science)', 'Ensure', 'Environment', 'Epilepsy', 'Excision', 'Frequencies', 'Goals', 'Grant', 'High Performance Computing', 'Human', 'Image', 'Imaging Device', 'Institution', 'Java', 'Joints', 'Journals', 'Language Development', 'Lead', 'Linux', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maintenance', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Near-Infrared Spectroscopy', 'Neurologic', 'Neurons', 'Neurosciences Research', 'Noise', 'Obsessive-Compulsive Disorder', 'Online Systems', 'Paper', 'Pathway Analysis', 'Pattern', 'Persons', 'Play', 'Pythons', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scalp structure', 'Schizophrenia', 'Series', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Surface', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Universities', 'Vendor', 'Visualization', 'Work', 'autism spectrum disorder', 'cloud storage', 'cognitive benefits', 'computerized tools', 'computing resources', 'cortex mapping', 'data archive', 'data curation', 'data repository', 'data resource', 'data sharing', 'data standards', 'data structure', 'density', 'design', 'electric field', 'graphical user interface', 'hands on instruction', 'improved', 'interoperability', 'large datasets', 'large scale data', 'magnetic field', 'multidisciplinary', 'neuroimaging', 'novel', 'open source', 'relating to nervous system', 'response', 'spatiotemporal', 'tool']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,616433,324592664
"Quantification of Liver Fibrosis with MRI and Deep Learning Project Summary/Abstract  Chronic liver disease (CLD) is a common cause of morbidity and mortality in the U.S. and throughout the world. In 2017, CLD had an age-adjusted death rate of 10.9/100,000 total population and an estimated lifetime cost of fatty liver disease alone in the U.S. of ~$222 billion. Liver fibrosis (LF) is the most important and only histologic feature known to predict outcomes from CLD. The current standard for assessing LF is biopsy, which is costly, prone to sampling error, and invasive with poor patient acceptance. Thus, there is an urgent unmet need for noninvasive, highly accurate and precise diagnostic technologies for detection and quantification of LF. Our overarching objective is to apply Deep Learning (DL) methods using conventional non-elastographic magnetic resonance (MR) images, MR elastography (MRE), and clinical data to accurately detect and measure LF in children and adults with CLD, using biopsy-derived histologic data as the reference standard. In this project, we will dedicate our efforts to accomplishing the following specific aims. In Aim 1, we will develop and validate a DL framework to accurately segment liver and spleen in order to extract radiomic (gray-scale signal intensity distribution, shape and morphology, volumetry, and inter-voxel signal intensity pattern and texture) and deep features (complex abstractions of patterns non-linearly constructed throughout the transformation estimated by data-driven DL training procedures) from conventional multiparametric MRI. These features allow detection of liver and spleen structural abnormalities/tissue aberrations. In Aim 2, we will develop and validate an “ensemble” DL model (LFNet) to predict biopsy-derived LF stage and LF percentage using the integration of conventional multimodal MRI radiomic and deep features, MRE data, as well as clinical data. In Aim 3, we will develop and validate a DL model (LSNet) to quantify MRE-derived liver stiffness (LS) using conventional multiparametric MRI radiomic and deep features as well as clinical data. The proposed models will help physicians to more accurately detect and follow CLD by 1) quantifying LS from conventional MR imaging without the need for MRE; and, more importantly, 2) predicting histologic LF stage and LF percentage without the need for biopsy, while avoiding inter- radiologist variability, reducing radiologist workload, and ultimately reducing healthcare costs. We will validate the models using both internal and independent external data from various scanners and sites. The techniques we develop are expected to improve medical diagnosis and prognostication in the same way as DL has revolutionized other fields. This study will significantly impact public health because it will allow physicians and researchers to more accurately diagnose and quantify CLD and LF as well as permit more frequent assessments in a noninvasive, patient-centric manner, thus potentially improving patient outcomes while lowering healthcare costs. The techniques we develop also can be readily extended for the prediction of other important liver-related clinical outcomes, including impending complications such as portal hypertension, time to liver transplant/transplant listing, and mortality risk, among others. Project Narrative  Chronic liver disease (CLD) is a common cause of illness and death worldwide, and it is a significant healthcare and financial burden. Liver fibrosis (LF) is a measurable feature of CLD that is important to assess the severity of disease, evaluate for progression and therapy response, and predict outcomes. We propose to apply artificial intelligence methods to noninvasive conventional magnetic resonance images and readily- available clinical data for accurate detection and quantification of LF, thus significantly impacting public health by facilitating personalized therapies without the need for liver biopsy, improved outcomes, and lower healthcare costs.",Quantification of Liver Fibrosis with MRI and Deep Learning,10096229,R01EB030582,"['Address', 'Adult', 'Age', 'American', 'Appearance', 'Artificial Intelligence', 'Bilirubin', 'Biopsy', 'Body mass index', 'Cessation of life', 'Characteristics', 'Child', 'Childhood', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Complex', 'Computer-Assisted Diagnosis', 'Crowding', 'Data', 'Data Set', 'Databases', 'Death Rate', 'Decision Making', 'Descriptor', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Evaluation', 'Eye', 'Fatty Liver', 'Financial Hardship', 'Goals', 'Health Care Costs', 'Health Expenditures', 'Healthcare', 'Histologic', 'Human', 'Image', 'Individual', 'Institution', 'Laboratories', 'Length of Stay', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Magnetic Resonance Elastography', 'Magnetic Resonance Imaging', 'Maps', 'Mathematics', 'Measurable', 'Measures', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Population', 'Portal Hypertension', 'Procedures', 'Property', 'Public Health', 'Reference Standards', 'Research', 'Research Personnel', 'Residual state', 'Risk', 'Risk Factors', 'Running', 'Sampling Errors', 'Series', 'Severity of illness', 'Shapes', 'Signal Transduction', 'Site', 'Spleen', 'Staging', 'Structural defect', 'Techniques', 'Testing', 'Texture', 'Time', 'Tissues', 'Training', 'Transplantation', 'Vendor', 'Viral hepatitis', 'Visual', 'Workload', 'accurate diagnosis', 'accurate diagnostics', 'chronic liver disease', 'classification algorithm', 'clinical risk', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'diagnostic technologies', 'elastography', 'hospital readmission', 'hospitalization rates', 'improved', 'improved outcome', 'learning strategy', 'life time cost', 'liver biopsy', 'liver transplantation', 'mortality', 'mortality risk', 'multimodality', 'multitask', 'non-linear transformation', 'outcome prediction', 'personalized diagnostics', 'personalized medicine', 'predictive modeling', 'prognostic', 'radiologist', 'radiomics', 'response', 'sex']",NIBIB,CINCINNATI CHILDRENS HOSP MED CTR,R01,2021,628266,168440418
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,10143171,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,655746,551214295
"A computer vision toolbox for computational analysis of nonverbal social communication PROJECT SUMMARY We will develop novel computer vision tools to reliably and precisely measure nonverbal social communication through quantifying communicative facial and bodily expressions. Our tools will be designed and developed in order to maximize their usability by non-engineer behavioral scientists, filling the enormous gap between engineering advances and their clinical accessibility. Significance: Social interaction inherently relies on perception and production of coordinated face and body expressions. Indeed, atypical face and body movements are observed in many disorders, impacting social interaction and communication. Traditional systems for quantifying nonverbal communication (e.g., FACS, BAP) require extensive training and coding time. Their tedious coding requirements drastically limits their scalability and reproducibility. While an extensive literature exists on advanced computer vision and machine learning techniques for face and body analysis, there is no well-established method commonly used in mental health community to quantify production of facial and bodily expressions or efficiently capture individual differences in nonverbal communication in general. As a part of this proposal, we will develop a computer vision toolbox including tools that are both highly granular and highly scalable, to allow for measurement of complex social behavior in large and heterogeneous populations. Approach: Our team will develop tools that provide granular metrics of nonverbal social behavior, including localized face and body kinematics, characteristics of elicited expressions, and imitation performance. Our tools will facilitate measurement of social communication both within a person and between people, to allow for assessment of individual social communication cues as well as those that occur within bidirectional social contexts. Preliminary Data: We have developed and applied novel computer vision tools to assess: (1) diversity of mouth motion during conversational speech (effect size d=1.0 in differentiating young adults with and without autism during a brief natural conversation), (2) interpersonal facial coordination (91% accuracy in classifying autism diagnosis in young adults during a brief natural conversation, replicated in an independent child sample), and (3) body action imitation (85% accuracy in classifying autism diagnosis based on body imitation performance). As apart of current proposal, we will develop more generic methods that can be used in normative and clinical samples. Aims. In Aim 1, we will develop tools to automatically quantify fine-grained face movements and their coordination during facial expression production; in Aim 2, we will develop tools to quantify body joint kinematics and their coordination during bodily expression production; in Aim 3, we will demonstrate the tools’ ability to yield dimensional metrics using machine learning. Impact: Our approach is designed for fast and rigorous assessment of nonverbal social communication, providing a scalable solution to measure individual variability, within a dimensional and transdiagnostic framework. PROJECT NARRATIVE This project develops novel tools for measuring nonverbal social communication as manifested through facial and bodily expressions. Using advanced computer vision and machine learning methodologies, we will quantify humans’ communicative social behavior. The results of this project will impact public health by facilitating a rich characterization of normative development of social functioning, providing access to precise phenotypic information for neuroscience and genetics studies, and by measuring subtle individual differences to determine whether some interventions or treatments work better than others.",A computer vision toolbox for computational analysis of nonverbal social communication,10150095,R01MH122599,"['Adolescent', 'Age', 'Area', 'Behavior', 'Behavioral', 'Behavioral Research', 'Behavioral Sciences', 'Characteristics', 'Child', 'Clinical', 'Code', 'Communication', 'Community Health', 'Complex', 'Computational Technique', 'Computer Analysis', 'Computer Vision Systems', 'Cues', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Educational Materials', 'Engineering', 'Face', 'Facial Expression', 'Genetic study', 'Goals', 'Gold', 'Grain', 'Grant', 'Human', 'Individual', 'Individual Differences', 'Intervention', 'Joints', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Motion', 'Movement', 'Nature', 'Neurologic', 'Neurosciences', 'Nonverbal Communication', 'Oral cavity', 'Participant', 'Perception', 'Performance', 'Persons', 'Phenotype', 'Population Heterogeneity', 'Production', 'Public Health', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Sampling', 'Science', 'Scientist', 'Sex Differences', 'Social Behavior', 'Social Development', 'Social Environment', 'Social Functioning', 'Social Interaction', 'Speech', 'System', 'Techniques', 'Teenagers', 'Time', 'Training', 'Translations', 'Validation', 'Work', 'analysis pipeline', 'autism spectrum disorder', 'automated algorithm', 'base', 'behavior measurement', 'behavioral health', 'clinical application', 'computerized tools', 'design', 'individual variation', 'interest', 'kinematics', 'novel', 'open source', 'sex', 'social', 'social communication', 'tool', 'usability', 'young adult']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2021,660945,178185562
"Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors Project Summary Scientific understanding of adaptive immune receptors (i.e. antibodies and T cell receptors) has the potential to revolutionize prophylaxis, diagnosis, and treatment of disease. High‐throughput DNA sequencing and functional experiments have now brought the study of adaptive immune receptors into the big‐data era. To realize this potential of these data they must be matched with appropriately powerful analytical techniques. Existing probabilistic and mechanistic models are insufficient to capture the complexities of these data, while a naïve application of machine learning cannot leverage our profound existing knowledge of the immune system. The goal of this project is to blend deep learning with mechanistic modeling in order to predict and understand the evolution and function of adaptive immune receptors. Aim 1: Develop generative models of immune receptor sequences that capture the complexity of real adaptive immune receptor repertoires. These will combine deep learning along with our knowledge of VDJ recombination, and provide a rigorous platform for detailed repertoire comparison. Aim 2: Develop quantitative mechanistic models of antibody somatic hypermutation that incorporate the underlying biochemical processes. Estimate intractable likelihoods using deep learning to infer important latent variables, and validate models using knock‐out experiments in cell lines. Aim 3: Develop hybrid deep learning models to predict binding properties from sequence data, combining large experimentally‐derived binding data with even larger sets of immune sequences from human immune memory samples. Incorporate structural information via 3D convolution or distance‐based penalties. These tools will reveal the full power of immune repertoire data for medical applications. We will obtain more rigorous comparisons of repertoires via their distribution in a relevant space. These will reveal the effects of immune perturbations such as vaccination and disease, allowing us to pick out sequences that are impacted by these perturbations. We will have a greater quantitative understanding of somatic hypermutation in vivo, and statistical models that appropriately capture long‐range effects of collections of mutations. We will also have algorithms that will be able to combine repertoire data and sparse binding data to predict binding properties. Put together, these advances will enable rational vaccine design, treatment for autoimmune disease, and identification of T cells that are promising candidates for cancer immunotherapy. Project Narrative Adaptive immune receptors (i.e. antibodies and T cell receptors) enable our body to fight off disease, “remember” pathogens, and train the immune system through vaccination. Immunologists have learned via high‐throughput sequencing that adaptive immune receptors have a truly remarkable diversity. In this proposal, we develop machine‐learning methods for these sequence data, which will allow us to predict the maturation, statistical distribution, and binding properties of adaptive immune receptors, and thus to better design vaccinations, autoimmune disease treatment, and immunotherapy treatment for cancer.",Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors,10159730,R01AI146028,"['3-Dimensional', 'Algorithms', 'Animal Model', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Autoimmune Diseases', 'Automobile Driving', 'Big Data', 'Binding', 'Biochemical', 'Biochemical Process', 'Categories', 'Cell Line', 'Characteristics', 'Collection', 'Complement', 'Complex', 'Data', 'Data Set', 'Dependence', 'Diagnosis', 'Disease', 'Entropy', 'Evolution', 'Exposure to', 'Foundations', 'Gene Conversion', 'Generations', 'Goals', 'High-Throughput DNA Sequencing', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Immune', 'Immune response', 'Immune system', 'Immunoglobulin Somatic Hypermutation', 'Immunologic Memory', 'Immunologic Receptors', 'Immunological Models', 'Immunologics', 'Immunologist', 'Immunology', 'Immunotherapy', 'In Vitro', 'Individual', 'Knock-out', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Pathway interactions', 'Population', 'Procedures', 'Process', 'Property', 'Prophylactic treatment', 'Resolution', 'Sampling', 'Science', 'Statistical Distributions', 'Statistical Methods', 'Statistical Models', 'Structure', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'V(D)J Recombination', 'Vaccination', 'Vaccine Design', 'Vaccines', 'Validation', 'Work', 'algorithm training', 'analytical tool', 'base', 'biochemical model', 'cancer immunotherapy', 'cancer therapy', 'complex data', 'deep learning', 'deep neural network', 'deep sequencing', 'design', 'experimental study', 'fighting', 'functional group', 'in vivo', 'insertion/deletion mutation', 'large datasets', 'machine learning method', 'markov model', 'pathogen', 'progenitor', 'receptor', 'repaired', 'response', 'success', 'three dimensional structure', 'tool']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,689648,758431960
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,10112310,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'PhenX Toolkit', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'data quality', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2021,693835,593605914
"A ""Culture"" Shift: Integrated Bacterial Screening and Antibacterial Susceptibility Test on Microfluidic Digital Array for Bloodstream Infections PROJECT SUMMARY The ability for clinicians to effectively treat bacterial infections with targeted antibacterials in the acute-care settings hinges on diagnostics capable of identifying the pathogen broadly and determining its susceptibility to antibacterials in a timely manner. Bloodstream infection (BSI) is a particularly representative disease because it is the leading cause of death due to infections with rapid disease progression. Unfortunately, the inconvenient delay of blood culture for definitive diagnosis contributes to widespread empiric use of broad- spectrum antibacterials and emergence of multi-drug-resistant pathogens. Toward addressing this critical unmet need, we propose to develop a new molecular diagnostic platform that integrates bacterial detection, species identification (ID), and antibacterial susceptibility testing (AST) from blood samples in a streamlined test. The expected sample-to-answer turnaround time is 90 min for ID and as early as 2-3 hr for AST. Such integrated diagnostic solution within the proposed timeframe will transform acute-care clinicians’ ability to establish diagnosis of bacterial infections, need for infection control, and antibacterial treatment based on objective data to improve clinical outcome. Using an innovative microfluidic digital array chip for assaying single cells as a backbone technology, we propose to develop a new molecular diagnostic platform which promises rapid ID and AST and allows customizable workflow and assay tailored to the clinical scenario while adjustable based on real-time results. The array chip seamlessly integrates digitization of cells, brief incubation (under various drug conditions), single-cell PCR (scPCR) or reverse transcriptase PCR (scRT-PCR) and single-cell high-resolution melt (scHRM). Thereby, bacterial pathogen can be detected at the level of single-cells, identified based on species- specific melt curves, and their antibacterial susceptibility profile subsequently assessed by measuring changes in rRNA level as a biosynthetic marker of cell viability. ScPCR/scRT-PCR enables sensitive detection and absolute quantification of rRNA of individual cells critical to rapid and reliable differentiation between viable and no-viable cells; while scHRM overcomes a key limitation of bulk HRM to resolve multiple species for diagnosing polymicrobial infections or discarding contaminations. Since both ID and AST do not rely on culture, they reduce total turnaround time from days to minutes/hours. We have assembled a superb team of multi-disciplinary investigators and industry advisors with complementary expertise and strong track record of team science. We propose the following aims:1) to develop a streamlined BSI diagnostic protocol for integrated ID and AST; 2) to develop a microfluidic array chip that enables ID and AST with single-cell resolution; 3) to develop instrument and analysis programs for single- cell ID and AST; and 4) to demonstrate the single-cell diagnostic platform, we will perform analytical and pilot clinical validation studies. PROJECT NARRATIVE The main goal of this research project is to develop a single-cell pathogen diagnostic platform which integrates broad-range bacterial detection, species identification (ID) and antibacterial susceptibility testing (AST) in a streamlined test.","A ""Culture"" Shift: Integrated Bacterial Screening and Antibacterial Susceptibility Test on Microfluidic Digital Array for Bloodstream Infections",10078849,R01AI137272,"['Acute', 'Address', 'Anti-Bacterial Agents', 'Bacterial Infections', 'Biological Assay', 'Blood', 'Blood Cells', 'Blood Tests', 'Blood specimen', 'Cause of Death', 'Cell Separation', 'Cell Survival', 'Cells', 'Clinical', 'Cytolysis', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Goals', 'Gold', 'Hour', 'Individual', 'Industry', 'Infection', 'Infection Control', 'Libraries', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microfluidics', 'Nutritional', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Predisposition', 'Preparation', 'Protocols documentation', 'RNA-Directed DNA Polymerase', 'Recombinant DNA', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Ribosomal RNA', 'Sampling', 'Science', 'Sepsis', 'Technology', 'Testing', 'Time', 'Transcript', 'Validation', 'Vertebral column', 'Whole Blood', 'acute care', 'automated algorithm', 'base', 'chromatin immunoprecipitation', 'classification algorithm', 'clinical decision-making', 'design', 'diagnostic platform', 'diagnostic technologies', 'digital', 'empowered', 'imager', 'improved', 'innovation', 'instrument', 'melting', 'molecular diagnostics', 'mortality', 'multi-drug resistant pathogen', 'multidisciplinary', 'novel', 'pathogen', 'pathogenic bacteria', 'programs', 'prospective', 'prototype', 'rRNA Precursor', 'screening', 'validation studies']",NIAID,JOHNS HOPKINS UNIVERSITY,R01,2021,720032,807432003
"COVID-19 detection through scent analysis with a compact GC device Recent studies, including ours, have suggested that breath may allow us to diagnose COVID-19 infection and even monitor its progress. As compared to immunological and genetic based methods using sample media like blood, nasopharyngeal swab, and saliva, breath analysis is non-invasive, simple, safe, and inexpensive; it allows a nearly infinite amount of sample volume and can be used at the point-of-care for rapid detection. Fundamentally, breath also provides critical metabolomics information regarding how human body responds to virus infection and medical intervention (such as drug treatment and mechanical ventilation). The objectives of the proposed SCENT project are: (1) to refine automated, portable, high-performance micro-gas chromatography (GC) device and related data analysis / biomarker identification algorithms for rapid (5-6 minutes), in-situ, and sensitive (down to ppt) breath analysis and (2) to conduct breath analysis on up to 760 patients, and identify and validate the COVID-19 biomarkers in breath. Thus, in coordination with the RADx-rad Data Coordination Center (DCC), we will complete the following specific aims. (1) Refine 5 automated micro-GC devices to achieve higher speed and better separation capability. We will construct 5 new automated and portable one-dimensional micro-GC devices that require only ~6 minutes of assay time (improved from current 20 minutes) at the ppt level sensitivity (Sub-Aim 1a). Then the devices will be upgraded to 2-dimensional micro-GC to significantly increase the separation capability (Sub-Aim 1b). In the meantime, we will optimize and automate our existing data processing and biomarker identification algorithms and codes to streamline the workflow so that the GC device can automatically process and analyze the data without human intervention (Sub-Aim 1c). (2) Identify breath biomarkers that distinguish COVID-19 positive (symptomatic and asymptomatic) and negative patients. We will recruit a training cohort of 380 participants, including 190 COVID-19 positive patients (95 symptomatic and 95 asymptomatic) and 190 COVID-19 negative patients from two hospitals (Michigan Medicine – Ann Arbor and the Henry Ford Hospital – Detroit). We will conduct breath analysis using machine learning to identify VOC patterns that match each COVID-19 diagnostic status. (3) Validate the COVID-19 biomarkers using our refined micro-GC devices. Using the refined 2-D micro-GC devices from Sub-Aim 1b, we will recruit a new validation cohort of 380 participants (190 COVID-19 positive patients and 190 COVID-19 negative patients) to validate the biomarkers identified in Aim 2.  We will leverage existing engineering, data science, clinical, regulatory, and commercialization resources throughout the project to hit our milestones, ensuring a high likelihood of rapid patient impact. Upon completion of this work, we will have a portable micro-GC device and accompanying automated algorithms that can detect and monitor COVID-19 status for people in a variety of clinical and community settings. Narrative  Our team of engineers, clinicians, and data scientists has developed a portable, high performance breath analyzer that can be used to detect certain diseases. In this project, we will adapt and refine our existing device and algorithms so they can be used for rapid, safe, and non- invasive COVID-19 detection. People will simply breath into the device and it will quickly provide results, meaning that it can be used in a variety of everyday settings to help fight against the COVID-19 pandemic.",COVID-19 detection through scent analysis with a compact GC device,10266206,U18TR003812,"['Acute', 'Agreement', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Biotechnology', 'Blood', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnosis', 'COVID-19 diagnostic', 'COVID-19 monitoring', 'COVID-19 pandemic', 'COVID-19 patient', 'Cessation of life', 'Clinical', 'Code', 'Critical Care', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Science', 'Data Scientist', 'Devices', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Ensure', 'Gas Chromatography', 'Genetic', 'Health', 'Hospitals', 'Human', 'Human body', 'Immunologics', 'In Situ', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Licensing', 'Machine Learning', 'Mechanical ventilation', 'Medical', 'Medicine', 'Methods', 'Michigan', 'Monitor', 'Participant', 'Patients', 'Pattern', 'Performance', 'Pharmacotherapy', 'Process', 'Production', 'RADx Radical', 'Research', 'Resources', 'Respiratory Failure', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Saliva', 'Sampling', 'Savings', 'Services', 'Severities', 'Speed', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Virus Diseases', 'Work', 'automated algorithm', 'base', 'biomarker identification', 'cohort', 'commercialization', 'community setting', 'computerized data processing', 'cost', 'design', 'fight against', 'fighting', 'global health', 'improved', 'metabolomics', 'multidisciplinary', 'nasopharyngeal swab', 'outcome forecast', 'pandemic disease', 'point of care', 'portability', 'rapid detection', 'recruit', 'respiratory hypoxia', 'screening', 'severe COVID-19', 'two-dimensional']",NCATS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,U18,2021,999775,641965656
"Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array PROJECT SUMMARY COVID-19 presents a public health emergency: There is a critical need for rapid, not reagent intensive, non- invasive testing technologies. This program will lead to the production of a prototype system to diagnose COVID-19 infection using the body odor signature of the disease. Our goal is to maximize societal impact by creating a validated prototype that can be used in a community or workplace setting by minimally trained personnel for low-cost, on-the-spot diagnosis within minutes. The system will be developed in a manner that puts it on a pathway for rapid FDA approval. The Research Aims are: Aim 1. Optimization, assembly, and integration of a prototype system with the ability to odor signature of COVID-19 in samples of body odor. The system will be simple to use, pose essentially zero risk to the operator and the test subject, and report a result within minutes. The production cost at scale will be approximately $9,000 for the complete measurement system, with a per test cost of approximately $0.50. The design and construction of the prototype will be conducted by Novo Engineering, a leading firm with extensive experience in medical device development. Aim 2. Software development. Software for the system from VOC sampling to final diagnostic result will be developed to ensure error-free operation of the device. Our preliminary results suggest that simple linear discriminant analysis (LDA) does an excellent job of classifying VOCs from human body odor as COVID-19 positive or negative (92% sensitivity and 87% specificity). Optimization of the sensor array (Aim 1) and use of richer feature sets in our classifier models will lead to further performance improvements in the prototype system. Aim 3. System Benchmarking and Validation. We will benchmark the full prototype system against a number of VOC mixtures, with and without in vitro skin models. The system will undergo extensive testing against body odor samples from individuals with pathological conditions other than COVID-19 and other sources of potentially confounding VOCs. The prototype will be validated against 1000 samples drawn from the COVID-SAFE program at Penn. The screening will include all members of the Penn community, and represents incredible racial and ethnic diversity as well as a wide variance in age, sex, and gender. Aim 4. Regulatory Approval Plan The plan will be developed under the direction of Sr/Key personnel John Fuson, JD, an attorney at Crowell & Moring LLP and a former Associate Chief Counsel at FDA. Novo Engineering has extensive experience in guiding prototype design in alignment with the requirements for FDA approval. The proposed COVID-19 VOC-based testing device will be regulated by the FDA, likely as a Class I or II medical device. Because there is no clear predicate device to reference in this case, we intend to submit a direct de novo petition to FDA asking the agency to categorize and clear the proposed COVID-19 testing device as Class I or Class II without reference to any predicate. PROJECT NARRATIVE This program addresses the critical unmet need of an effective means to screen for COVID-19 infection, and potentially other novel virus infections, in a community setting based upon the body odor signature of the disease. The program will result in a validated prototype system, with a test time of minutes, a test cost of approximately $0.50, on a path to rapid FDA approval.","Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array",10266403,U18TR003775,"['Address', 'Age', 'Astronomy', 'Benchmarking', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 screening', 'COVID-19 testing', 'Carbon Nanotubes', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Chemicals', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Computers', 'Counseling', 'DNA', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Discriminant Analysis', 'Disease', 'Engineering', 'Ensure', 'Florida', 'Future', 'Gender', 'Goals', 'Gold', 'Hand', 'Health', 'Housekeeping', 'Human', 'Human Resources', 'Human body', 'In Vitro', 'Individual', 'Information Sciences', 'International', 'Intuition', 'Laboratories', 'Lawyers', 'Mass Fragmentography', 'Measurement', 'Mechanics', 'Medical Device', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Nose', 'Occupations', 'Odors', 'Participant', 'Pathologic', 'Pathway interactions', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phase', 'Physics', 'Production', 'RADx', 'Reagent', 'Reporting', 'Research', 'Risk', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Sampling', 'Skin', 'Software Engineering', 'Solid', 'Source', 'Specificity', 'Spottings', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Viral', 'Virus Diseases', 'Visual', 'Workplace', 'animal care', 'artificial neural network', 'base', 'community setting', 'coronavirus disease', 'cost', 'design', 'design and construction', 'ethnic diversity', 'experience', 'high standard', 'machine learning algorithm', 'medical schools', 'member', 'multidisciplinary', 'nano', 'nanosensors', 'next generation', 'novel virus', 'operation', 'prevent', 'programs', 'prototype', 'public health emergency', 'racial diversity', 'sample collection', 'screening', 'screening program', 'sensor', 'sex', 'software development', 'software systems', 'vapor', 'volatile organic compound']",NCATS,UNIVERSITY OF PENNSYLVANIA,U18,2021,999830,593605914
"Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors ABSTRACT Aura is a digital health platform that uses Epilog™, a miniature, wireless, wearable EEG sensor worn on the scalp below hairline that can record clinical and subclinical seizures. After an initial diagnosis of epilepsy, an epileptologist will use known information about patients’ seizures to guide the best scalp location to place the Epilog EEG sensor (A). EEG data is continuously transferred (B) to the Aura app on a person’s smartphone (C) using secure BluetoothTM where it communicates over WiFi (D) to the Aura cloud platform (E). Epilog EEG is analyzed for seizures and a daily digital seizure diary is shared with epileptologists (F) and pushed back to the Aura app (G). Epilog is recharged daily, and reusable for a year. Epilog is designed to be discreet, allowing for continuous use in all facets of daily life. Data are a 10 s snippet of the beginning of a focal seizure with motor impairment and intact awareness (ILAE 1A1) recorded from Epitel’s single-channel Epilog sensor placed on the left forehead. The patient was admitted for video-EEG monitoring as standard-of-care. This seizure was verified independently by three epileptologists. In Phase I, automated, machine learning-based seizure detection algorithms will be designed to first work in the Aura cloud to detect seizures in Epilog EEG, including seizures a person may not consciously know they are having (>50% of all seizures), such as while sleeping. Aura will run these algorithms developed exclusively for Epilog’s single-channel of EEG to provide a daily digital seizure diary. In Phase II, the Aura system will enter clinical validation trials for FDA clearance as an EEG-based automated home seizure detection and alerting system. Early in Phase II Aura will be commercialized as a medical device-enabled-service business model. Out-of-pocket costs for a person living with epilepsy is an average of $380/year. Armed with long-term, reproducible EEG, epileptologists will now have a more precise, quantitative record of seizure counts, enabling them to adapt patient treatment more rapidly and successfully to improve quality of life. Aura will give people living with epilepsy their lives back. Aura provides certainty where you are and when you need it. Throughout Phase II, physiological, psychological, behavioral, and environmental factors will be combined in the Aura app to collect 27,000 days of multi-modal data from 300 patients to create an unprecedented dataset of features known to precipitate seizures. These data will be used in Phase III to create a robust, wearable seizure forecasting system using artificial intelligence that combines multi-modal seizure precipitating factors, creating an hourly seizure probability. Aura will profoundly disrupt how epilepsy is managed and improve the quality of life of people living with epilepsy. This grant proposal aims to create a digital health platform that includes a wearable medical device worn on the scalp below the hairline. The system detects and counts seizures, and alerts to seizures in real time. The goal is to empower people with epilepsy to take control of their seizure monitoring and help improve the treatment of epilepsy.",Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors,10200346,U44NS121562,"['Adoption', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Auras', 'Awareness', 'Back', 'Behavioral', 'Bluetooth', 'Businesses', 'Cellular Phone', 'Clinical', 'Community Hospitals', 'Consumption', 'Cues', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Electroencephalography', 'Emergency Medicine', 'Environment', 'Environmental Risk Factor', 'Epilepsy', 'Event', 'Family', 'Financial Hardship', 'Focal Seizure', 'Forehead', 'Freedom', 'Goals', 'Gold', 'Home environment', 'Hospitals', 'Hour', 'Left', 'Life', 'Location', 'Machine Learning', 'Manuals', 'Medical Device', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Neurologic', 'Paper', 'Patient Self-Report', 'Patients', 'Periodicity', 'Persons', 'Phase', 'Physiological', 'Precipitating Factors', 'Predisposition', 'Probability', 'Process', 'Quality of life', 'Reproducibility', 'Running', 'Scalp structure', 'Screening procedure', 'Secure', 'Seizures', 'Services', 'Sleep', 'Subclinical Seizures', 'System', 'Time', 'Validation', 'Wireless Technology', 'Work', 'base', 'cloud platform', 'cost', 'design', 'diaries', 'digital', 'digital health', 'effective therapy', 'encryption', 'improved', 'machine learning algorithm', 'motor impairment', 'multimodal data', 'multimodality', 'optimal treatments', 'programs', 'psychologic', 'remote monitoring', 'sensor', 'social', 'standard of care']",NINDS,"EPITEL, INC.",U44,2021,999853,0
"A Handheld Microchip for GC analysis of breath to screen for COVID-19 Project Summary  The COVID-19 pandemic has caused unprecedented societal suffering and economic disruption. In the United States, more than six million people have contracted COVID-19 and more than one hundred ninety thousand patients have died of this disease to date. Although current COVID-19 diagnostic testing technologies are critical for slowing the spread of the virus and preventing future outbreaks, they are not practical for field use. Current diagnostic tests are cumbersome to perform because they use aqueous solutions, require multiple steps, and hours-to-days to obtain results. Since the US began to reopen the economy in May, there has been a significant increase in the number of COVID-19 cases. Therefore, there is an urgent need to develop a diagnostic approach that is non-invasive, portable, and can rapidly provide test results.  The overall goal of the project is to develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). The handheld tool will be a closed system for trapping select volatile organic compounds (VOCs) on a microfabricated chip. The captured VOCs will be eluted with ethanol and then analyzed using a commercially available, portable GC-PID instrument. Artificial intelligence (AI) and machine learning algorithms will be applied to recognize the VOC pattern that correlates with COVID-19 infection. The central innovation is the microfabricated chip that captures carbonyl compounds in exhaled breath and thus serves as a preconcentrator, which enables analysis of carbonyl VOCs by the portable GC-PID. The hypothesis is that the carbonyl metabolome in exhaled breath is directly related to the body’s reaction to the novel coronavirus infection, and changes in the carbonyl VOC composition in exhaled breath relative to healthy controls can be used to detect both symptomatic and asymptomatic COVID-19 patients.  Three specific aims are proposed to fulfill the overall goal. Aim 1 is to build a disposable handheld breath analyzer tool for concentrating carbonyl VOCs. Aim 2 is to identify VOC patterns in the breath of COVID-19 patients by machine learning algorithms. Aim 3 is to integrate portable GC technology with the breath sampling tool for COVID-19 screening guided by an AI system. The University of Louisville is uniquely suited to rapidly transition the microchip technology to field use because of the PI and Co-PI’s experience in breath analysis and translational research, and the project team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence as well as the state-of-the-art facilities that include a MicroNano Technology Center, Biosafety Level 3 Regional Biocontainment Lab, and an NIH-funded REACH program. 8. Project Narrative  This project will develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). Artificial intelligence and machine learning algorithms will be used to analyze the detected signals of volatile organic compounds (VOCs) in exhaled breath by the portable GC for detection of COVID-19 patients. UofL is uniquely suited to develop this approach because of the PI’s expertise in breath analysis for detection of Tuberculosis and lung cancer and the team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence.",A Handheld Microchip for GC analysis of breath to screen for COVID-19,10266377,U18TR003787,"['2019-nCoV', 'Acute', 'Address', 'Artificial Intelligence', 'Biochemical Process', 'Biometry', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnostic', 'COVID-19 pandemic', 'COVID-19 patient', 'COVID-19 screening', 'COVID-19 test', 'Cancer Detection', 'Clinic', 'Collaborations', 'Collection', 'Communicable Diseases', 'Contracts', 'Coronavirus Infections', 'Detection', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Economics', 'Epithelial Cells', 'Ethanol', 'Exhalation', 'Expert Systems', 'Foundations', 'Funding', 'Future', 'Goals', 'Hour', 'Human', 'Influenza', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Malignant neoplasm of lung', 'Mass Fragmentography', 'Medical Device', 'Modeling', 'Monitor', 'Nasal Epithelium', 'Oxidative Stress', 'Patients', 'Pattern', 'Process', 'Production', 'Protocols documentation', 'Rapid screening', 'Reaction', 'Reagent', 'Research Project Grants', 'Role', 'SARS-CoV-2 infection', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Silicon', 'Sterilization', 'System', 'Technology', 'Test Result', 'Testing', 'Training', 'Translational Research', 'Tuberculosis', 'United States', 'United States National Institutes of Health', 'Universities', 'Vial device', 'Viral', 'Viral Respiratory Tract Infection', 'Virulent', 'Virus', 'Virus Diseases', 'adduct', 'aqueous', 'asymptomatic COVID-19', 'biosafety level 3 facility', 'bronchial epithelium', 'carbonyl compound', 'detection sensitivity', 'detector', 'experience', 'innovation', 'instrument', 'machine learning algorithm', 'metabolome', 'microchip', 'mobile computing', 'novel coronavirus', 'photoionization', 'point of care', 'portability', 'prevent', 'programs', 'prototype', 'reagent testing', 'tool', 'virology', 'volatile organic compound']",NCATS,UNIVERSITY OF LOUISVILLE,U18,2021,1026672,73765201
"Web-based Automated Imaging Differentiation of Parkinsonism SUMMARY Across the globe, there has been a considerable growth in the number of people diagnosed with Parkinsonism. Estimates indicate that from 1990 to 2015 the number of Parkinsonism diagnoses doubled, with more than 6 million people currently carrying the diagnosis, and by year 2040, 12 and 14.2 million people will be diagnosed with Parkinsonism. Parkinson’s disease (PD), multiple system atrophy Parkinsonian variant (MSAp), and progressive supranuclear palsy (PSP) are neurodegenerative forms of Parkinsonism, which can be difficult to diagnose as they share similar motor and non-motor features, and they each have an increased chance of developing dementia. In the first five years of a PD diagnosis, about 58% of PD are misdiagnosed, and of these misdiagnoses about half have either MSA or PSP. Since PD, MSAp, and PSP require unique treatment plans and different medications, and clinical trials testing new medications require the correct diagnosis, there is an urgent need for both clinic ready and clinical-trial ready markers for differential diagnosis of PD, MSAp, and PSP. Over the past decade, we have developed diffusion imaging as an innovative biomarker for differentiating PD, MSAp, and PSP. In this proposal, we will leverage our extensive experience to create a web-based software tool that can process diffusion imaging data from anywhere in the world. We will disseminate and test the tool in the largest prospective cohort of participants with Parkinsonism (PD, MSAp, PSP), working closely with the Parkinson Study Group. The reason to test this in the Parkinson Study Group network, is because they are the community that evaluates Phase II and Phase III clinical trials in Parkinsonism. This web-based software tool will be capable of reading raw diffusion imaging data, performing quality assurance procedures, analyzing the data using a validated pipeline, and providing imaging metrics and diagnostic probability. We will test the performance of the wAID-P by enrolling 315 total subjects (105 PD, 105 MSAp, 105 PSP) across 21 sites in the Parkinson Study Group. Each site will perform imaging, clinical scales, diagnosis, and will upload the data to the web-based software tool. The clinical diagnosis will be blinded to the diagnostic algorithm and the imaging diagnosis will be compared to the movement disorders trained neurologist diagnosis. We will also enroll a portion of the cohort into a brain bank to ascertain pathological confirmation and to test the algorithm against cases with post-mortem diagnoses. The final outcome will be to disseminate a validated diagnostic algorithm to the Parkinson neurological and radiological community and to make it available to all on a website. NARRATIVE In this proposal, we will be developing, disseminating, and evaluating a web-based software tool that can perform MRI analyses for the diagnostic accuracy of Parkinsonism. Our goal is to leverage our years of experience and algorithm development, to test a prospective cohort of Parkinson’s disease, Multiple System Atrophy, and Progressive Supranuclear Palsy. We expect that at the end of the project, we will have validated a web-based software tool that can use MRIs from different vendors to read, analyze, and predict the diagnosis of different forms of Parkinsonism.",Web-based Automated Imaging Differentiation of Parkinsonism,10106864,U01NS119562,"['Algorithms', 'American', 'Area Under Curve', 'Autopsy', 'Biological Markers', 'Blinded', 'Brain', 'Clinic', 'Clinical', 'Clinical Trials', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Dementia', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Enrollment', 'Goals', 'Growth', 'Health', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Modeling', 'Motor', 'Movement Disorders', 'Multiple System Atrophy', 'Nerve Degeneration', 'Neurologic', 'Neurologist', 'Online Systems', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Participant', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Probability', 'Procedures', 'Process', 'Progressive Supranuclear Palsy', 'Prospective cohort', 'Protocols documentation', 'Radiology Specialty', 'Reading', 'Research Personnel', 'Risk', 'Secure', 'Signal Transduction', 'Site', 'Software Tools', 'System', 'Techniques', 'Testing', 'TimeLine', 'Tissues', 'Training', 'Translating', 'Validation', 'Variant', 'Vendor', 'Water', 'accurate diagnosis', 'algorithm development', 'atypical parkinsonism', 'clinical Diagnosis', 'cohort', 'data exchange', 'diagnostic accuracy', 'diagnostic biomarker', 'disease diagnosis', 'dopamine transporter', 'experience', 'imaging biomarker', 'improved', 'indexing', 'individualized medicine', 'innovation', 'outcome forecast', 'performance tests', 'programs', 'quality assurance', 'support vector machine', 'tool', 'treatment planning', 'web site']",NINDS,UNIVERSITY OF FLORIDA,U01,2021,1553260,188894159
