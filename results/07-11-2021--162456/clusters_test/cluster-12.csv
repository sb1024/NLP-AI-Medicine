text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"HistoTools:  A suite of digital pathology tools for quality control, annotation and dataset identification ABSTRACT: Roughly 40% of the US population will be diagnosed with some form of cancer in their lifetime. In a majority of these cases, a definitive cancer diagnosis is only possible via histopathologic confirmation using a tissue slide. Increasingly, these slides are being digitally scanned as high-resolution images for usage in both clinical and research digital pathology (DP) workflows. Our group has been pioneering the use of deep learning (DL), a form of machine learning, for segmentation, detection, and classification of various cancers using digital pathology images. DL learns features and their associated weighting from large datasets to maximally discriminate between user labeled data (e.g., cancer vs non-cancer, nuclei vs non-nuclei); a paradigm known as “learn from data”. Unfortunately, this paradigm makes DL especially sensitive to low quality slides, noise induced by small errors in the manual user labeling process, and general dataset heterogeneity. As many groups do not intentionally account for these problems, they learn that successful employment of DL technologies relies heavily on explicitly addressing challenges associated with (a) carefully curating high quality slides without preparation or scanning artifacts, (b) obtaining a large precise collection of annotations delineating objects of interest, and (c) selecting diverse datasets to ensure robust classifier performance when clinically deploying the model. To address these challenges we propose HistoTools, a suite of three modules or “Apps”: (1) HistoQC examines slides for artifacts and computes metrics associated with slide presentation characteristics (e.g., stain intensity, compression levels) helping to quantify ranges of acceptable characteristics for downstream algorithmic evaluation. (2) HistoAnno drastically improves the efficiency of annotation efforts using a combined active learning and deep learning approach to ensure experts focus only on regions which are important for classifier improvement. (3) HistoFinder aids in selecting suitable training and test cohorts to guarantee that various tissue level characteristics are well balanced, leading to increased reproducibility. Our team already has working prototypes of HistoQC (100% concordance with a pathologist, evaluated on n>1200 slides) and HistoAnno (30% efficiency improvement during annotation tasks). In this U01, we seek to further develop and evaluate HistoTools in the context of enhancing two companion diagnostic (CDx) assays being developed in our group. First, we will use HistoTools to quality control and annotate nuclei, tubules, and mitosis for improving our CDx classifier for predicting recurrence in breast cancers using a cohort of n>900 patients from completed trial ECOG 2197. Secondly, HistoTools will be employed for quality control and identification of tumor infiltrating lymphocytes and cancer nuclei towards improving our CDx classifier for predicting response to immunotherapy in lung cancer using the n>700 patients from completed clinical trials Checkmate 017 and 057. These tools will build on our existing open source tool repository to aid in real-time feedback and dissemination throughout the ITCR and cancer research community. RELEVANCE: This project will result in development of HistoTools, a new digital pathology toolkit for common pre-experiment machine learning tasks in the oncology domain such as (a) timely identification of poor quality slides and slide regions, (b) quantitative metrics driving optimized cohort selection, and (c) generation of highly precise and relevant annotations. Each component is designed to directly combat an existing bottleneck in the evolving usage of digital pathology. HistoTools will significantly enhance the functionality of existing toolboxes and pipelines, facilitating increasingly sophisticated machine learning applications in oncology.","HistoTools:  A suite of digital pathology tools for quality control, annotation and dataset identification",10116983,U01CA239055,"['Active Learning', 'Address', 'Adoption', 'Algorithms', 'American', 'American Society of Clinical Oncology', 'Automobile Driving', 'Cancer Patient', 'Cell Nucleus', 'Characteristics', 'Classification', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collection', 'Communities', 'Computer Assisted', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Eastern Cooperative Oncology Group', 'Employment', 'Ensure', 'Environment', 'Estrogen receptor positive', 'Evaluation', 'Feedback', 'Generations', 'Histologic', 'Histology', 'Image', 'Immunotherapy', 'International', 'Label', 'Learning', 'Lymphocyte', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Masks', 'Mitosis', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Nature', 'Nivolumab', 'Noise', 'Non-Small-Cell Lung Carcinoma', 'Nuclear', 'Oncology', 'Optics', 'Outcome', 'Paper', 'Pathologist', 'Patients', 'Performance', 'Population', 'Preparation', 'Process', 'Quality Control', 'Recurrence', 'Reproducibility', 'Research', 'Role', 'Scanning', 'Slide', 'Societies', 'Stains', 'Technology', 'Testing', 'The Cancer Imaging Archive', 'Time', 'Tissues', 'Training', 'Tumor-Infiltrating Lymphocytes', 'Validation', 'Visualization', 'Weight', 'Work', 'anticancer research', 'base', 'cancer diagnosis', 'cancer recurrence', 'cohort', 'combat', 'companion diagnostics', 'deep learning', 'design', 'diagnostic assay', 'digital', 'digital pathology', 'experimental study', 'heterogenous data', 'high resolution imaging', 'imaging informatics', 'improved', 'indexing', 'industry partner', 'innovation', 'interactive tool', 'interest', 'large datasets', 'learning network', 'malignant breast neoplasm', 'open source', 'outcome forecast', 'outcome prediction', 'pathology imaging', 'photonics', 'predicting response', 'prognostic', 'prototype', 'quantitative imaging', 'repository', 'response', 'tool', 'tumor heterogeneity']",NCI,CASE WESTERN RESERVE UNIVERSITY,U01,2021,1
"A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration PROJECT SUMMARY Age-related macular degeneration (AMD), in the dry or wet form, is the leading cause of vision loss in the developed countries. The Age-Related Eye Disease Study (AREDS) showed that specific antioxidant vitamin supplementation reduces the risk of progression from intermediate stages to late AMD and maintains visual acuity in approximately 25% of patients. While treatment of wet AMD with Intraocular injections can be effective in maintaining vision, such treatments are costly and may be associated with significant cardiovascular risks, or even progression of dry AMD. Hence, it is critical to identify patients at the earlier stages. Unfortunately, there is no effective, automated screening tool to accomplish this, and the patients themselves may be asymptomatic. The goal of this SBIR Direct-to-Phase II proposal is to provide such tool. We have demonstrated the feasibility of AMD screening software ‘iPredictTM’ by successfully identifying 98.1% of individuals with early or intermediate stage AMD. iPredictTM also successfully predicted which individuals would develop late AMD within one year with 87.8% accuracy and two years with 88.4% accuracy. iPredictTM has prototype components for image analysis and machine learning. We also developed a HIPAA compliant telemedicine platform which will enable iPredictTM to perform large-scale screening from remote and rural areas. In order to bring the product to market, these components need to be integrated and tested which is the aim of our proposed Direct-to-Phase II proposal. We aim to develop the finished product which will be ready for the market. We also aim to evaluate the efficacy of iPredictTM in a clinical setup. The AMD preventative market is estimated around $5.4 billion in the U.S. alone. iPredictTM will capture the major market share with its best accuracy and be the first prediction tool for AMD. We aim to commercialize iPredictTM for the screening and prevention of AMD, saving millions of citizens from blindness and reduced quality of life. With iPredictTM’s improvements in speed of delivery, cost of care, and ease of access, the product will be a significant addition to the healthcare system. The iPredictTM’s telemedicine platform will allow large-scale screening from remote/rural areas, primary care clinics, optometry offices and ophthalmology clinics. PROJECT NARRATIVE Age-related macular degeneration (AMD) in its late forms, “dry” or “wet”, is the leading cause of blindness in developed countries. Early intervention and therapy can significantly reduce the progression of early to late AMD. Hence, the identification of patients with early AMD and referral to an ophthalmologist is critically needed to help prevent vision loss. To achieve this goal, we propose to develop an automated screening and prediction system that can be widely deployed to identify these individuals at risk of vision loss.",A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration,10320271,R44EY031202,"['Affect', 'Age', 'Age related macular degeneration', 'American', 'Antioxidants', 'Blindness', 'Categories', 'Clinic', 'Clinical', 'Clinics and Hospitals', 'Code', 'Color', 'Computer software', 'Counseling', 'Data', 'Data Set', 'Databases', 'Developed Countries', 'Devices', 'Diagnosis', 'Drusen', 'Ear', 'Early Intervention', 'Evaluation', 'Eye', 'Eye diseases', 'Feasibility Studies', 'Fees', 'Goals', 'Health Insurance Portability and Accountability Act', 'Healthcare Systems', 'Image', 'Image Analysis', 'Incentives', 'Individual', 'Injections', 'Intervention', 'Java', 'Lasers', 'Learning Module', 'Machine Learning', 'Manuals', 'Methods', 'Minerals', 'Modeling', 'New York', 'Nonexudative age-related macular degeneration', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patients', 'Phase', 'Prevention', 'Prevention strategy', 'Primary Health Care', 'Provider', 'Pythons', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Sales', 'Savings', 'Screening procedure', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Smoking', 'Specialist', 'Speed', 'Sun Exposure', 'Supplementation', 'System', 'Telemedicine', 'Testing', 'Therapeutic Intervention', 'Time', 'Trademark', 'Treatment Cost', 'Validation', 'Vision', 'Visit', 'Visual Acuity', 'Vitamins', 'age related', 'base', 'biobank', 'cardiovascular risk factor', 'care costs', 'checkup examination', 'commercial application', 'convolutional neural network', 'cost', 'deep learning', 'follow-up', 'improved', 'photobiomodulation', 'prediction algorithm', 'predictive modeling', 'prevent', 'prognostic', 'programs', 'prospective', 'prototype', 'remote screening', 'research clinical testing', 'retinal imaging', 'rural area', 'screening', 'sociodemographic factors', 'software as a service', 'success', 'tool', 'user-friendly']",NEI,"IHEALTHSCREEN, INC.",R44,2021,45000
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10372655,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'detection platform', 'digital health', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2021,52000
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,10128374,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2021,77243
"Deep learning for renal tumor characterization Our long-term objective is to develop deep learning techniques capable of predicting characteristics and treatment response or response to surveillance to assist clinical decision- making in renal tumors that are potential candidates for ablation therapy, biopsy, active surveillance or surgical resection. An increasing number of renal tumors are being diagnosed, due in part to incidental detection from the increased use of cross-sectional imaging. Although partial nephrectomy is still considered the primary treatment for small renal masses, percutaneous ablation is increasingly performed as a therapeutic, nephron-sparing approach. One challenge for interventional radiologists and urologists who manage these patients is selection for therapy, since the average rate of progression is slow for small renal tumors and metastasis rarely occurs. A technique that could distinguish indolent tumors from those will progress based on data from the imaging methods used to detect and delineate renal masses would enable early triage to observation versus invasive treatment. Deep learning, a type of machine learning technique which takes raw images as input, and applies many layers of transformations to calculate an output signal, has already led to breakthroughs in other areas of image recognition, and is increasingly used for medical image analysis. However, its application in the field of interventional radiology is currently limited. Furthermore, no study in the literature has applied deep learning to kidney lesion segmentation and characteristics/outcome prediction. In this project, we propose to develop novel deep learning architectures based on routine MR imaging that allow for accurate renal mass segmentation and prediction of characteristics and outcome in renal tumors. Using data from four independent cohorts, we will use our deep learning architectures to predict (1) benign versus malignant histology (2) growth rate in stage 1a renal cell carcinoma (3) SSIGN score in clear cell renal cell carcinoma and (4) clinical endpoints. We will integrate segmentation and classification into one net that suitable for clinical application. In addition, we will compare results with those of experts and traditional machine learning approaches. The inability to determine aggressiveness of renal tumors based on pretreatment imaging makes it challenging for urologists or interventional radiologists to select appropriate patients for active surveillance versus therapy with nephrectomy or ablation. Our research project uses deep learning to distinguish renal mass from normal tissue and predict characteristics, treatment response or response to surveillance in renal tumors. By using a multi-institutional patient cohort and conventional MR imaging sequences, we will demonstrate the generalizability and broad applicability of our algorithm. Our models have the potential to help guide clinical management of patients with renal tumors.",Deep learning for renal tumor characterization,10116348,R03CA249554,"['3-Dimensional', 'Ablation', 'Algorithms', 'Architecture', 'Area', 'Benign', 'Biopsy', 'Characteristics', 'Classification', 'Clear cell renal cell carcinoma', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Dropout', 'Ensure', 'Excision', 'Future', 'Growth', 'Histology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Intervention', 'Interventional radiology', 'Kidney', 'Kidney Neoplasms', 'Learning', 'Lesion', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Medical Imaging', 'Metastatic Neoplasm to the Kidney', 'Modeling', 'Nephrectomy', 'Nephrons', 'Neural Network Simulation', 'Normal tissue morphology', 'Oncology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient imaging', 'Patients', 'Performance', 'Process', 'Renal Cell Carcinoma', 'Renal Mass', 'Research Project Grants', 'Selection for Treatments', 'Signal Transduction', 'Techniques', 'Therapeutic', 'Training', 'Triage', 'Update', 'Urologist', 'Weight', 'base', 'cancer imaging', 'clinical application', 'clinical decision-making', 'cohort', 'deep learning', 'deep neural network', 'design', 'imaging modality', 'improved', 'interest', 'learning network', 'novel', 'outcome prediction', 'predictive modeling', 'radiologist', 'radiomics', 'random forest', 'treatment response', 'tumor']",NCI,RHODE ISLAND HOSPITAL,R03,2021,80500
"Generation of parametric images for FDG PET using dual-time-point scans Project Summary/Abstract Positron emission tomography combined with computed tomography (PET/CT) using the radiolabeled tracer 2- deoxy-2-(18F)fluoro-D-glucose (FDG) has become a standard imaging tool for cancer patient management. The semi-quantitative parameter standardized uptake value (SUV) is routinely used in clinical for tumor uptake quantification, which is computed on the static PET image acquired at a certain time (typically 60 min) post tracer injection for a short interval (typically 5-15 min). However, the quantification accuracy of SUV from a single PET scan suffers from the variabilities of tracer plasma clearance and acquisition start time. The dual- time-point FDG PET imaging has been intensively investigated and used in both clinical and research studies, typically one scan at 60 min and the other at 120 min, showing the potential to enhance the diagnostic accuracy of FDG PET by differentiating malignancy from inflammation and normal tissue. However, the current clinical dual-time-point FDG PET studies use the relative SUV change between two scans as the quantification index, which cannot eliminate the variations in tracer plasma clearance. Meanwhile, the dual-time-point protocol has not been optimized and standardized currently, leading to conflicting results. The fully-quantitative parameter, tracer net uptake rate constant Ki, is the most accurate parameter to quantify FDG PET, which is calculated using dynamic imaging with compartmental modeling. Ki is independent on the plasma clearance or acquisition start time. However, the long and complex acquisition protocol (typically at least 60 min), which requires dynamic scanning and sequential arterial blood sampling (or image-derived blood activity) used as input function from the time of injection, limits its application in clinical practice. Meanwhile, generation of the parametric Ki image, which can provide additional heterogeneity information for FDG PET, is challenging clinically using voxel-by-voxel compartmental modeling due to the computational cost and being sensitive to noise using non-linear least squares. The graphical Patlak plot, can be used for simplified Ki calculation and Ki image generation by voxel-by-voxel fitting. However, it still needs dynamic scanning starting from 15-30 min after injection and input function from the time of injection. The aims of this proposal are 1) to optimize the dual-time-point protocol for accurate Ki quantification using Patlak plot without the need for individual patient's input function, and 2) to generate high-quality low-noise dual-time-point Ki images using novel techniques based on deep learning. Upon the success of this project, our proposed approach can obtain reliable tumor Ki quantification and parametric Ki image ""for free"" without adding any additional complexity on the existing dual- time-point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology. We expect the translation of this approach to clinical investigation to be fast, as this is a post-processing approach and is based on data already acquired using clinically used protocol without imposing additional burden to technologists. Project Narrative For FDG PET imaging, we propose to develop a novel and simple approach of quantifying tumor Ki and generating parametric Ki image ""for free"" without adding any additional complexity on the existing dual-time- point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology.",Generation of parametric images for FDG PET using dual-time-point scans,10117077,R03EB027864,"['Blood', 'Blood specimen', 'Cancer Patient', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Data', 'Diagnosis', 'Generations', 'Glucose', 'Heterogeneity', 'Image', 'Imaging Device', 'Inflammation', 'Injections', 'Label', 'Least-Squares Analysis', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Noise', 'Normal tissue morphology', 'Oncology', 'Patients', 'Plasma', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation exposure', 'Radiolabeled', 'Scanning', 'Standardization', 'Techniques', 'Time', 'Tracer', 'Training', 'Translations', 'Variant', 'X-Ray Computed Tomography', 'attenuation', 'base', 'clinical investigation', 'clinical practice', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'diagnostic accuracy', 'image reconstruction', 'improved', 'indexing', 'individual patient', 'innovation', 'novel', 'parametric imaging', 'population based', 'research study', 'simulation', 'success', 'tumor', 'uptake']",NIBIB,YALE UNIVERSITY,R03,2021,83750
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,10158538,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2021,93342
"Generalizable Deep Learning Networks for Dual-tracer Amyloid/Tau PET/MRI Imaging of Alzheimer's Disease Project Summary  Alzheimer’s Disease (AD) is a devastating neurodegenerative disorder and a major public health crisis, currently affecting over 5.8 million Americans and expected to rise as the population ages. Positron emission tomography (PET) imaging can identify the hallmark proteinopathies of AD, including amyloid protein plaques and neurofibrillary tangles (composed primarily of tau protein) accumulating in the brain. While there is evident need for more PET neuroimaging, for example, to elucidate the sequence of amyloid and tau deposition in preclinical AD, its increased utility in longitudinal imaging studies with large study populations is limited by recruitment and cost. In particular, making multiple visits to the scanning site will be difficult for participants living far away, and the high cost of injected radiotracers will limit the scalability of PET studies.  In this project we propose using deep learning-based convolutional neural networks (CNNs) to enhance ultra-low-dose amyloid and tau PET for imaging AD. Our specific aims are (1) to validate the diagnostic value of the CNNs in actual ultra-low-dose amyloid and tau imaging sessions, with the injected dose as low as 1% of the original, and with actual ultra-low-dose data, to validate simulations for use in subsequent aims and future studies; (2) to apply the ultra-low-dose CNN to data collected on other PET systems and tracers, in order to demonstrate the CNN’s generalizability; and (3) to evaluate the value of deep learning-aided ultra-low-dose amyloid and tau PET for tracking cognitive decline in a preclinical AD population.  The innovation of this work lies in using multimodal imaging in addition to advanced machine learning techniques to enable acquisition of diagnostic-level PET images at extremely low dose levels. Performing actual ultra-low-dose PET acquisitions is also highly novel in itself. The outcome of this proposal is removing the limiting factors to large-scale clinical longitudinal imaging, shortening acquisitions spanning multiple days and visits to several hours in one visit with a successive ultra-low-dose and full-dose dual-tracer scan protocol. Significant dose reduction can also be achieved, allowing for more frequent amyloid/tau PET scanning. This flexibility will not only increase the utility of PET, aid longitudinal studies in dementia, but enable future comprehensive imaging of multiple PET-based biomarkers as these tracers are being developed. Project Narrative  More frequent PET scans can be used for dementia, a major cause of deaths in the United States, to understand the pathogenesis of the brain proteinopathies involved, to identify at-risk individuals, and to provide outcome markers for clinical trials of anti-amyloid/tau therapies; but recruitment for studies, cost, and radiation dose to the scanned participant are critical factors limiting its use. This work aims to train versatile deep learning-based neural networks which can produce diagnostic-level images from ultra-low-dose (as low as 1%) amyloid and tau PET acquisitions. Our study will provide flexibility in recruitment (running ultra-low-dose and full-dose scans in succession for dual-tracer studies), reduce the cost for radiotracer use, and reduce the dose in scanned participants, a “win-win” for researchers and patients.",Generalizable Deep Learning Networks for Dual-tracer Amyloid/Tau PET/MRI Imaging of Alzheimer's Disease,10214874,K99AG068310,"['Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease pathology', 'American', 'Amyloid', 'Amyloid Proteins', 'Biological Markers', 'Brain', 'Cause of Death', 'Cerebrum', 'Clinical', 'Clinical Markers', 'Clinical Trials', 'Cognitive', 'Data', 'Dementia', 'Deposition', 'Diagnostic', 'Dose', 'Drowning', 'Early Diagnosis', 'Evaluation', 'Follow-Up Studies', 'Future', 'Hour', 'Image', 'Impaired cognition', 'Individual', 'Injections', 'Investigative Techniques', 'Longitudinal Studies', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Modeling', 'Multimodal Imaging', 'Neurodegenerative Disorders', 'Neurofibrillary Tangles', 'Outcome', 'Participant', 'Pathogenesis', 'Patient Recruitments', 'Patients', 'Performance', 'Population', 'Positron-Emission Tomography', 'Proteins', 'Protocols documentation', 'Public Health', 'Radiation Dose Unit', 'Radioactivity', 'Reading', 'Research Design', 'Research Personnel', 'Risk', 'Running', 'Scanning', 'Schedule', 'Signal Transduction', 'Site', 'System', 'Techniques', 'Testing', 'Tracer', 'Training', 'United States', 'Visit', 'Vulnerable Populations', 'Work', 'apolipoprotein E-4', 'base', 'clinical application', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'flexibility', 'imaging agent', 'imaging study', 'innovation', 'learning network', 'longitudinal positron emission tomography', 'machine learning method', 'mild cognitive impairment', 'multimodality', 'neuroimaging', 'novel', 'pre-clinical', 'radiotracer', 'recruit', 'research study', 'serial imaging', 'sex', 'simulation', 'study population', 'tau Proteins', 'theories', 'uptake']",NIA,STANFORD UNIVERSITY,K99,2021,100863
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,10054168,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Height', 'Human', 'Image', 'Image Analysis', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Visualization', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'detection sensitivity', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'screening guidelines', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,120631
"Super-Resolution Tau PET Imaging for Alzheimer's Disease PROJECT SUMMARY Preclinical Alzheimer’s disease (the presymptomatic phase of Alzheimer’s disease) is characterized by pathophysiological changes without measurable cognitive decline and begins decades before the onset of cognitive symptoms. Preclinical Alzheimer’s disease research is in pressing need of new biomarker endpoints to enable disease monitoring before traditional cognitive endpoints are measurable. The overarching research objectives of this R03 Small Project Grant are to develop a super-resolution (SR) positron emission tomography (PET) imaging framework for tau (a pathophysiological hallmark of Alzheimer’s disease) and to assess the clinical utility of localized outcome measures obtained from SR PET images. Studies show that tau pathology in the medial temporal lobe is an important marker of cognitive decline in Alzheimer’s disease. Cohorts focused on preclinical Alzheimer’s now incorporate serialized 18F-flortaucipir PET scans for longitudinal tracking of tau accumulation in key anatomical regions-of-interest (ROIs). The quantitative accuracy of tau PET, however, is degraded by the limited spatial resolution capabilities of PET, which lead to inter-ROI spillover and partial volume effects. The problem is further compounded in studies spanning several decades, many of which were commenced on legacy scanners with even lower resolution capabilities than the current state of the art. Additionally, many longitudinal studies began on older scanners and later transitioned to newer models posing a multi-scanner data harmonization challenge. The proposed SR framework will perform a mapping from a low- resolution scanner’s image domain to a high-resolution scanner’s image domain and enable PET resolution recovery and data harmonization. Underlying the proposed framework is a neural network model that can be adversarially trained in self-supervised mode without requiring paired input/output image samples for training. This critical feature ensures practical clinical utility of the method as the need for paired low-resolution and high- resolution datasets from the same subject with similar tracer dose and scan settings is a major barrier for the clinical translatability of simpler supervised alternatives for SR. The proposed network, although trained using unpaired clinical data, receives guidance from an ancillary neural network separately pretrained using paired simulation datasets. For this purpose, we will synthesize paired low- and high-resolution images from a series of digital tau phantoms that will be created for this project. Training and validation of the self-supervised SR framework will be performed via secondary use of de-identified 18F-flortaucipir PET scans from the Harvard Aging Brain Study, a longitudinal cohort focused on preclinical Alzheimer’s disease. We will evaluate SR performance using a variety of image quality metrics. To assess the clinical utility of localized super-resolution measures, we will perform cross-sectional statistical power analyses that estimate sample sizes per arm needed to power clinical trials. Accurate localized measures of tau generated by this project could enable early diagnosis of Alzheimer’s disease and facilitate ongoing clinical trials by reducing sample sizes required for a given effect size. PROJECT NARRATIVE The objective of this R03 Small Project Grant is to develop methods for generating high-resolution images of abnormal tau protein tangles, which are a hallmark of Alzheimer’s disease. This will be achieved by building a self-supervised super-resolution framework based on a deep neural network for positron emission tomography (PET) imaging of tau. The proposed imaging technique can facilitate early diagnosis and accurate monitoring of Alzheimer’s disease.",Super-Resolution Tau PET Imaging for Alzheimer's Disease,10118776,R03AG070750,"['Address', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease diagnosis', 'Anatomy', 'Artificial Intelligence', 'Binding', 'Biological Markers', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cognitive', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Disease Progression', 'Dose', 'Early Diagnosis', 'Early Intervention', 'Ensure', 'Evaluation', 'Funding Opportunities', 'Future', 'Goals', 'Grant', 'Image', 'Imaging Techniques', 'Impaired cognition', 'Lead', 'Longitudinal Studies', 'Longitudinal cohort', 'Longitudinal cohort study', 'Measurable', 'Measures', 'Medial', 'Memory impairment', 'Methods', 'Modeling', 'Monitor', 'Names', 'Neural Network Simulation', 'Neurobehavioral Manifestations', 'Neurofibrillary Tangles', 'Outcome Measure', 'Output', 'Pathology', 'Performance', 'Phase', 'Positron-Emission Tomography', 'Recovery', 'Research', 'Resolution', 'Sample Size', 'Sampling', 'Scanning', 'Series', 'Statistical Data Interpretation', 'Supervision', 'Surrogate Markers', 'Techniques', 'Technology', 'Temporal Lobe', 'Tracer', 'Training', 'Treatment Efficacy', 'Validation', 'aging brain', 'arm', 'base', 'clinically translatable', 'cohort', 'data harmonization', 'deep learning', 'deep neural network', 'digital', 'drug development', 'high resolution imaging', 'high risk', 'human subject', 'improved', 'in vivo', 'innovation', 'interest', 'neural network', 'neural network architecture', 'neuroimaging', 'neuroimaging marker', 'novel', 'power analysis', 'pre-clinical', 'radioligand', 'radiotracer', 'rate of change', 'response', 'simulation', 'tau Proteins', 'tau aggregation', 'tau mutation']",NIA,UNIVERSITY OF MASSACHUSETTS LOWELL,R03,2021,151980
"Development of an artificial intelligence-driven, imaging-based platform for pretreatment identification of extranodal extension in head and neck cancer Project Summary. The goal of this project is to develop, optimize, and evaluate an artificial intelligence (AI)- driven, medical imaging platform that utilizes computed tomography (CT) imaging to identify the presence of extranodal extension (ENE) in head and neck squamous cell carcinoma (HNSCC). HNSCC is a debilitating disease with significant patient-related morbidity related to the disease itself and its management, which is complex and consists of a combination of surgery, radiation, and chemotherapy. A key factor in determining proper HNSCC management is the presence of ENE, which occurs when tumor infiltrates through the capsule of an involved lymph node into the surrounding tissue. ENE is both an important prognostic factor and an indication for adjuvant treatment escalation with the addition of chemotherapy to radiation following surgery. This “trimodality therapy” is problematic, as it is associated with increased treatment-related morbidity and healthcare costs, but no improvement in disease control compared to upfront chemoradiation alone. The challenge is that ENE can only be definitively diagnosed pathologically after surgery, and pretreatment radiographic ENE identification has proven unreliable for even expert diagnosticians, leading to high rates of trimodality therapy and suboptimal treatment outcomes. In HNSCC management there is a critical need for improved pretreatment ENE identification to 1) select appropriate patients for surgery to avoid the excess morbidity and costs of trimodality therapy, 2) risk-stratify patients optimally, and 3) select appropriate patients for treatment de-escalation or intensification clinical trials. In recent years, Deep learning, a subtype of machine learning, under the umbrella of AI, has generated breakthroughs in computerized medical image analysis, at times outperforming human experts and discovering patterns hidden to the naked eye. While AI is poised to transform the fields of cancer imaging and personalized cancer care, there remain significant barriers to clinical implementation. The hypothesis of this project is that AI can be used to successfully identify HNSCC ENE on pretreatment imaging in retrospective and prospective patient cohorts and to develop a platform for lymph node auto-segmentation that will promote clinical utility of the platform. This hypothesis will be tested by rigorous optimization and evaluation of a deep learning ENE identification platform. Specifically, the platform will be validated for accuracy, sensitivity, specificity, and discriminatory performance on two heterogeneous retrospective datasets and two prospective cohorts derived from institutional and national Phase II clinical trials for HNSCC patients. The platform will then be directly compared with head and neck radiologists to determine if radiologist performance can be augmented with AI. In parallel, AI will be utilized to develop an auto-segmentation platform for tumor and lymph nodes, which will 1) improve the platform's clinical impact and 2) provide a valuable tool for treatment planning and future imaging-based research for HNSCC patients. 1 Project Narrative Identification of extranodal extension (ENE) for head and neck cancer in the pretreatment setting would be extremely useful in selecting the optimal treatment strategy for patients. Currently, ENE can only be definitively diagnosed pathologically after surgery, and pretreatment radiographic ENE prediction has proven unreliable for expert diagnosticians. This project uses artificial intelligence to identify ENE pretreatment on Computed Tomography, with the goal of developing a clinically usable tool to help patients with newly diagnosed head and neck cancers and their physicians choose the most effective treatment strategy that minimizes the risk of side effects.","Development of an artificial intelligence-driven, imaging-based platform for pretreatment identification of extranodal extension in head and neck cancer",10105483,K08DE030216,"['Adjuvant', 'Algorithms', 'Artificial Intelligence', 'Biopsy', 'Clinic', 'Clinical', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Enrollment', 'Evaluation', 'Extranodal', 'Eye', 'Foundations', 'Future', 'Geography', 'Goals', 'Head', 'Head and Neck Cancer', 'Head and Neck Squamous Cell Carcinoma', 'Head and neck structure', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Institution', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Medical Imaging', 'Morbidity - disease rate', 'Neck Dissection', 'Newly Diagnosed', 'Operative Surgical Procedures', 'Output', 'Pathologic', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phase II Clinical Trials', 'Physicians', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Prognostic Factor', 'Prospective cohort', 'Radiation', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Scientist', 'Sensitivity and Specificity', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'cancer imaging', 'capsule', 'chemoradiation', 'chemotherapy', 'clinical implementation', 'cohort', 'computerized', 'cost', 'deep learning', 'design', 'disorder control', 'effective therapy', 'heuristics', 'imaging platform', 'improved', 'insight', 'interest', 'lymph nodes', 'neural network', 'neural network architecture', 'novel', 'optimal treatments', 'patient stratification', 'personalized cancer care', 'phase II trial', 'prediction algorithm', 'prospective', 'prospective test', 'radiologist', 'radiomics', 'risk minimization', 'side effect', 'success', 'therapy development', 'tool', 'treatment planning', 'treatment strategy', 'tumor']",NIDCR,BRIGHAM AND WOMEN'S HOSPITAL,K08,2021,168240
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,10077550,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2021,190362
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for training—a typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training data—a typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,10116379,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2021,195000
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10226322,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data repository', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2021,220287
"Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging PROJECT SUMMARY/ABSTRACT There has been significant work in creating tools that leverage computer vision algorithms to automate medical image analysis. Most of these algorithms have been developed for natural images, which are usually single static images that can be treated individually. However, medical images are usually part of a study that may include various views and orientations that are considered together with other clinical data when making a diagnosis. Three dimensional convolution neural networks (CNN) can address this issue in part when images are evenly spaced, but many medical imaging modalities such as ultrasound (US), fluoroscopy, and biopsy imaging have variable orientations and irregular spacing. Graph convolutional networks (GCN) have the potential to address this issue as they generalize the assumptions of CNNs to work on arbitrarily structured graphs. Automatic thyroid nodule detection in ultrasound (US) is one application that such a graph-based approach could have a large impact. The thyroid cancer incidence rate has tripled in the past thirty years, with an estimated cost of $18-21 billon in 2019. US is the imaging modality of choice, which consists of multiple 2D images of different locations and orientations. US readings are often vague and subjective in nature, which has resulted in a steady increase in the number of biopsies performed over the past 20 years. It is estimated that about one-third of all thyroid biopsy procedures performed in the United States are medically unnecessary, leading to the unmet need for noninvasive diagnostic tests that can reliably identify which nodules require a biopsy. The research objective of this R21 is to develop a new graph-based approach to leverage spatial information contained within imaging studies that will be combined with biomarkers and other known risk factors. Our graph model will enable more complete detection of thyroid cancer, as well as the prediction of future cancer aggression, both with spatially localized explanations. GCN features will be used to predict voxel-level cancer suspicion, thereby enabling a novel method for performing “imaging biopsy.” Finally, voxel-level suspicion maps will be aggregated into patient-level quantitative imaging biomarkers and combined with clinical data to create a multimodal nomogram for performing risk stratification. PROJECT NARRATIVE Medical image analysis plays an important role in computer aided detection and diagnosis, but usually focuses on individual images in isolation. Graph convolutional networks have the ability to utilize the relationships be- tween images in a study to aggregate information and make a more accurate evaluation. The focus of this project is to implement a graph-based approach for distinguishing indolent from aggressive thyroid cancer, thus pre- venting patients from receiving unnecessary treatment and incurring associated negative functional outcomes.",Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging,10110934,R21EB030691,"['3-Dimensional', 'Address', 'Age', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Attention', 'Biological Markers', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Diagnostic tests', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fluoroscopy', 'Functional disorder', 'Future', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'Indolent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Manuals', 'Maps', 'Medical', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Nodule', 'Nomograms', 'Pathology', 'Patient risk', 'Patients', 'Pattern', 'Physiological', 'Play', 'Probability', 'Procedures', 'Protocols documentation', 'Reading', 'Research', 'Risk', 'Risk Factors', 'Risk stratification', 'Role', 'Savings', 'Series', 'Signal Transduction', 'Structure', 'Techniques', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Tweens', 'Ultrasonography', 'United States', 'Work', 'base', 'body system', 'cancer imaging', 'cancer risk', 'clinical imaging', 'clinically significant', 'computer aided detection', 'convolutional neural network', 'cost estimate', 'deep learning', 'detection platform', 'functional outcomes', 'image registration', 'imaging biomarker', 'imaging modality', 'imaging study', 'innovation', 'mortality', 'multimodality', 'network models', 'noninvasive diagnosis', 'novel', 'patient stratification', 'predictive modeling', 'prevent', 'quantitative imaging', 'radiologist', 'tool', 'treatment planning', 'unnecessary treatment', 'ward']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,224566
"FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring Project Abstract/Summary Ultra-low dose CT, defined as sub-millisievert (sub-mSv) imaging of the entire chest, abdomen or pelvis, is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, photon starvation and electronic noise make imaging at such dose levels challenging. Photon starvation refers to the number of transmitted photons. When no photons are transmitted, the measurement is essentially useless. If few photons are transmitted, the measurement carries information, but its interpretation and value are confounded by electronic noise. Solutions with encouraging results have been offered for sub-mSv chest imaging, but these are not widely available and not easily generalizable across anatomical sites, vendors and scanner models. We propose a novel, robust solution for ultra-low dose CT that will overcome these issues. We refer to our solution as FAIR-CT, which stands for Finite-Angle Integrated-Ray CT. FAIR-CT operates under the principle that photon starvation and the confounding effect of electronic noise are best handled by avoiding them, which is made possible by increasing the data integration time during the source-detector rotation. FAIR-CT data strongly deviate from the classical CT data model and share the streak artifact problem of sparse view sampling. FAIR-CT data acquisition also affects azimuthal resolution. We anticipate that these issues can be suitably handled using advanced image reconstruction techniques. Once available, FAIR-CT will allow improvements in longitudinal monitoring of patients with chronic diseases such as COPD, urolithiasis and diabetes, thereby reducing mortality and co-morbidities. FAIR-CT will also allow advancing cancer therapy treatments by enabling adjustments in radiation therapy plans between dose fractions without increasing CT radiation exposure, and by facilitating early detection of inflammations in drug-based therapies. To bring FAIR-CT towards fruition, we will work on two specific aims: (1) Creation of a comprehensive collection of FAIR-CT data sets enabling rigorous development, validation and evaluation of image reconstruction algorithms; (2) Development, validation and evaluation of advanced image reconstruction algorithms. The FAIR-CT data sets will involve the utilization of state-of-the-art scanners and include real patient data synthesized from high dose scans acquired for standard of care. Two complementary image reconstruction approaches will be investigated. Namely, model-based iterative reconstruction with non-linear forward model and dedicated compressed sensing regularization; and deep learning-based refinement of FBP reconstructions using target images with task-adapted image quality. Image quality evaluation will account for critical biological variables and involve objective metrics such as structure similarity and contrast-to-noise ratio for clinically-proven lesions, as well as task-based performance metrics involving human readers. Ultra-low dose X-ray computed tomography is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, physics-related challenges and impractical solutions make this concept unavailable for everyday clinical use. We will develop a novel solution that is practical and can quickly be brought to clinical practice.",FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring,10158473,R21EB029179,"['Abdomen', 'Academia', 'Advanced Malignant Neoplasm', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Body mass index', 'Chest', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Clinical', 'Collection', 'Computers', 'Cystic Fibrosis', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Dose', 'Early Diagnosis', 'Epidemic', 'Evaluation', 'Fruit', 'Goals', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Industry', 'Inflammation', 'Inflammatory Bowel Diseases', 'Lesion', 'Malignant Neoplasms', 'Measurement', 'Metabolic Diseases', 'Modeling', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Noise', 'Obesity', 'Patient Monitoring', 'Patients', 'Pelvis', 'Performance', 'Pharmaceutical Preparations', 'Photons', 'Physics', 'Polycystic Kidney Diseases', 'Process', 'Pulmonary Inflammation', 'Radiation exposure', 'Radiation therapy', 'Radiology Specialty', 'Reader', 'Research', 'Resolution', 'Rotation', 'Sampling', 'Scanning', 'Source', 'Starvation', 'Structure', 'Techniques', 'Technology', 'Time', 'Validation', 'Vendor', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer risk', 'cancer therapy', 'clinical practice', 'clinical translation', 'clinically translatable', 'comorbidity', 'data acquisition', 'data integration', 'data modeling', 'data sharing', 'deep learning', 'detector', 'expectation', 'image reconstruction', 'improved', 'low dose computed tomography', 'mortality', 'novel', 'reconstruction', 'sex', 'side effect', 'standard of care', 'targeted imaging', 'urolithiasis']",NIBIB,UNIVERSITY OF UTAH,R21,2021,227282
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,10170765,R21EB025621,"['Abdomen', 'Acoustics', 'Adult', 'Age', 'Anatomy', 'Area', 'Award', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Evaluation', 'Excision', 'Family suidae', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Measurement', 'Metals', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translations', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization', 'Work', 'algorithm training', 'base', 'convolutional neural network', 'cost', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'metallicity', 'obese patients', 'obese person', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2021,235027
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,R21EY032567,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2021,242250
"Reading workstation for clinical contrast echocardiography Proposal Summary There is increasing appreciation of a syndrome in which patients female patients, present with chest pain due to myocardial ischemia and have a normal or near normal coronary angiogram. Termed coronary microvascular dysfunction (MVD) this disorder is not benign with cardiovascular event rates similar to those with established coronary artery disease. Clinical tools are therefore needed to both identify MVD patients and better understand the mechanisms causing myocardial ischemia. There is evidence that myocardial contrast echocardiography (MCE) provides incremental information in the evaluation of patients with coronary artery disease, myocardial viability, or diseases of the microvasculature. Despite data demonstrating the diagnostic and prognostic benefit of MCE in evaluating patients with MVD, its clinical use has been limited to only a handful of experts in the field, because there are currently no widely available clinical tools to support MCE quantitative analysis and interpretation. The overall aim of this Phase I proposal is to provide clinicians with a new tool to evaluate the myocardial flow-function relationship that is critical to identifying patients with MVD by using echocardiography. We will develop clinical software that can rapidly process MCE data into a standardized, quantitative and easy- to- interpret format. In Aim 1, the power of image averaging and computer aided assessment of radial wall thickening will be used to enhance the current standard of care which relies solely on readers' visual estimation of segmental function. An algorithm will be developed to rearrange the order of images so that images representing the same phase of the cardiac cycle are grouped together. Functional analysis will then be developed using computer-aided tracings of epicardial and endocardial borders. In Aim 2, a software module for quantitative analysis of real-time MCE perfusion will be developed that will incorporate statistical confidence, derived from the performance of image processing algorithms to inform the interpreter about the data strength. Machine learning will be utilized to train and deploy a neural network for the pixel-by-pixel assessment of myocardial perfusion. In Aim 3, we will combine myocardial perfusion and function modules into a novel, perfusion-function mode of imaging (PF-mode). This new mode will be applied to an archival sample of clinically diagnosed MVD cases to demonstrate the feasibility to detect abnormalities in the myocardial flow-function relationship. The composite PF-mode will include a cine-loop rendered for one cardiac cycle where parametric images (perfusion) are superimposed over averaged ultrasound images with an overlay of graphic representation of wall thickness (function). This novel mode of imaging provides the means to diagnose MVD in a single clinical study. Project Narrative Project Title: Reading workstation for clinical contrast echocardiography Despite a wealth of evidence that myocardial contrast echocardiography imaging of myocardial perfusion provides incremental information in the evaluation of patients with diseases of the myocardial microvasculature (MVD), its clinical use has been limited to only a handful of experts in the field. In this proposal, we have created a multidisciplinary partnership between physicians-scientists and engineers with the overall aim to address this clinical gap that exists between a proven echocardiographic technique and the technology necessary to enable widespread adoption of MCE clinically. We will develop a software program enabling a new method for evaluating the myocardial flow-function relationship using echocardiography that will enable the identification of MVD using MCE studies at the level of expert readers.",Reading workstation for clinical contrast echocardiography,10155647,R43HL152939,"['Address', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Apical', 'Benign', 'Blood', 'Blood Flow Velocity', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular system', 'Chest Pain', 'Classification', 'Clinical', 'Clinical Research', 'Clip', 'Code', 'Color', 'Computer Assisted', 'Computer software', 'Computers', 'Contrast Echocardiography', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Echocardiography', 'Engineering', 'Evaluation', 'Event', 'Eye', 'Female', 'Guidelines', 'Image', 'Imaging Techniques', 'Machine Learning', 'Mechanics', 'Medical', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Myocardial', 'Myocardial Ischemia', 'Myocardial perfusion', 'Names', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Physicians', 'Process', 'Radial', 'Reader', 'Reading', 'Recommendation', 'Rest', 'Scientist', 'Side', 'Societies', 'Software Engineering', 'Standardization', 'Stress', 'Syndrome', 'Techniques', 'Technology', 'Thick', 'Time', 'Training', 'Ultrasonography', 'Vendor', 'Visual', 'arteriole', 'base', 'clinical Diagnosis', 'endothelial dysfunction', 'image processing', 'imaging software', 'indexing', 'multidisciplinary', 'neural network', 'novel', 'parametric imaging', 'perfusion imaging', 'prognostic', 'programs', 'sample archive', 'single photon emission computed tomography', 'standard of care', 'tool', 'user-friendly']",NHLBI,"NARNAR, LLC",R43,2021,252399
"Using Multi-Spectral Imaging with Microchip Electrophoresis to Accurately Screen Newborns for Sickle Cell Disease PROJECT SUMMARY Hemoglobin (Hb) disorders are among the world's most common monogenic diseases. Nearly 7% of the world’s population carry Hb gene variants. Sickle cell disease (SCD) arises when Hb mutations are inherited homozygously (HbSS) or paired with another β-globin gene mutation. Globally, an estimated 400,000 babies are born annually with SCD, and 70%-75% are in sub-Saharan Africa (SSA). It is estimated that 50-90% in SSA die by their 5th birthday, 70% of these deaths are preventable. Effective management of SCD involves early diagnosis, and genetic counselling, and, importantly, nationwide newborn screening (NBS). NBS programs utilizing centralized laboratories have dramatically reduced SCD mortality in high-resource countries. NBS requires sensitive detection of relatively low levels of Hb variants in the presence of high fetal Hb (HbF). Normal HbA and sickle HbS should be accurately identified in the presence of high levels (up to 90%) of HbF. The current gold standard for Hb variant testing is high-performance liquid chromatography (HPLC), which requires expensive equipment and reagents, highly trained personnel, and modern laboratories. In low- resource regions, very few centralized laboratories can perform costly Hb testing. Testing is not available to the large percentage of infants born outside of a major hospital or city. There is an unmet need for affordable, portable, easy-to-use, accurate, point-of-care (POC) tests to facilitate decentralized Hb testing to enable nationwide NBS programs. In 2019, the World Health Organization (WHO) listed Hb electrophoresis as an essential in vitro diagnostic in low- and middle-income countries. We have developed a POC microchip electrophoresis Hb variant testing system, MicroChip Electrophoresis (MCE), under the product name “Gazelle Hb Variant” by Hemex Health, Inc. MCE reports Hb phenotype, Hb quantification (%Hb), and an interpretive statement showing genotype (such as SCD, Sickle Cell Trait, or Normal). MCE has been extensively validated for hemoglobinopathies, including SCD, hemoglobin E disease, and thalassemia. Newborns and infants below 6 weeks of age have very low concentrations of Hb variants other than Hb F which is high, therefore an improvement to lower the limit of detection (LoD) is needed to support NBS programs worldwide. By decreasing the LoD from the current 10% to 2%, newborns and infants can be screened with this affordable system. The innovation in this SBIR Phase I is the integration of multi-spectral imaging and machine learning based data analysis capability to MCE to develop MCE+ to accurately screen newborns for common Hb variants. We propose the following aims: Aim 1: Integrate multi-spectral imaging and machine learning algorithm into the MCE platform to enable identification and quantification of hemoglobin variants in newborns. Aim 2: Perform clinical testing of the MCE+ multi-spectral newborn screening system. Significance of this project is that MCE+ is the only affordable POC system for quantitative and objective hemoglobin variant testing that allows screening at birth. PROJECT NARRATIVE Up to 50 to 90% of children born with sickle cell disease (SCD) in economically disadvantaged countries (over 400,000 per year) die before the age of five, although the WHO estimates that 70% could be saved through simple, cost-effective treatments. Early diagnosis starting at birth is critical for implementing effective disease management, but newborn screening is a challenge for low resource environments where a decentralized, point-of-care solution is needed. This project enables our affordable, point-of-care platform based on microchip electrophoresis technology to accurately perform newborn screening.",Using Multi-Spectral Imaging with Microchip Electrophoresis to Accurately Screen Newborns for Sickle Cell Disease,10255480,R43HL156685,"['Africa', 'Africa South of the Sahara', 'Age', 'Bedside Testings', 'Birth', 'Blood', 'Care Technology Points', 'Caring', 'Child', 'Cities', 'Clinical', 'Clinical Research', 'Country', 'Data Analyses', 'Decentralization', 'Detection', 'Development', 'Disease', 'Disease Management', 'Drops', 'Early Diagnosis', 'Economically Deprived Population', 'Electrophoresis', 'Ensure', 'Environment', 'Equipment', 'Fetal Hemoglobin', 'Gender', 'Gene Mutation', 'Genetic Counseling', 'Genotype', 'Ghana', 'Gold', 'Health', 'Health Status', 'Hemoglobin', 'Hemoglobin E Disease', 'Hemoglobin concentration result', 'Hemoglobinopathies', 'High Pressure Liquid Chromatography', 'Hospitals', 'Human Resources', 'India', 'Infant', 'Inherited', 'Laboratories', 'Machine Learning', 'Mendelian disorder', 'Microchip Electrophoresis', 'Modernization', 'Mutation', 'Names', 'Neonatal Screening', 'Newborn Infant', 'Phase', 'Phenotype', 'Point-of-Care Systems', 'Population', 'Race', 'Reagent', 'Reference Standards', 'Reporting', 'Resources', 'Sickle Cell Anemia', 'Sickle Cell Trait', 'Small Business Innovation Research Grant', 'Southeastern Asia', 'Specificity', 'System', 'Teaching Hospitals', 'Technology', 'Testing', 'Thalassemia', 'Training', 'Validation', 'Variant', 'Work', 'World Health Organization', 'base', 'beta Globin', 'commercialization', 'cost', 'cost effective', 'detection limit', 'diagnostic accuracy', 'effective therapy', 'genetic variant', 'improved', 'in-vitro diagnostics', 'innovation', 'innovative technologies', 'low and middle-income countries', 'machine learning algorithm', 'miniaturize', 'mortality', 'novel', 'point of care', 'portability', 'preventable death', 'research clinical testing', 'screening', 'screening program', 'sickling', 'spectrograph', 'trait']",NHLBI,"HEMEX HEALTH, INC.",R43,2021,256580
"Tracking the microbiome: purpose-built machine learning tools for tracking microbial strains over time Summary/Abstract Approximately 150 million people annually experience urinary tract infections (UTI), the most common cause of which is uropathogenic Escherichia coli (UPEC). The gut is a known reservoir of UPEC, which typically reside at low abundance, but can transcend the periurethral area to invade the bladder. While the E. coli population within the gut can be diverse, it has been suggested that certain strains have a greater propensity to migrate and cause infection. This may be one driving factor to explain why half of those with an acute infection have a recurrence even after taking antibiotics that clear the first infection from the urinary tract. Being able to detect and track E. coli strains over time would have direct clinical applications for those patients who have frequent recurrences due to gut UPEC carriage. One such clinical application would be early detection and intervention before the onset of infection. Unfortunately, current metagenomic algorithms are not capable of performing strain tracking accurately enough for clinical relevance, especially for low abundance species such as E. coli. A major factor for this lack of accuracy is that all current state-of-the-art metagenomic tools completely ignore temporal dependence between samples. Even if it is known that multiple samples are from the same patient, current tools analyze those samples as if they were independent. Furthermore, many metagenomic tools ignore the sequence quality information that is provided for every nucleobase in every read. We propose to develop a more precise strain tracking algorithm that does take this additional information into account, making the tool host-time-quality aware. Finally, we will pilot and validate our algorithm on a clinically relevant gnotobiotic colonization model. Specifically, humanized germ-free mice will be undergoing two rounds of E. coli challenges with therapeutic perturbations from antibiotics or mannosides, a small molecule precision antibiotic-sparing therapeutic. We propose the following specific aims: (1) Develop the first purpose-built computational method for tracking bacterial strains in the microbiome over time, (2) Gnotobiotic mouse model undergoing UPEC challenges and a therapeutic perturbation. These aims would advance the microbiome field forward allowing for the future development of therapeutics and clinical diagnostics. Narrative Pathogens often reside in the gut at low abundance, hindering our ability to detect them and obfuscating their pathogenesis. To overcome this challenge, we propose to develop high-quality and high-resolution tools for tracking bacterial strains over time. These tools will further our scientific understanding surrounding bacterial infections and ultimately aid in the development of new therapeutics.",Tracking the microbiome: purpose-built machine learning tools for tracking microbial strains over time,10218776,R21AI154075,"['Address', 'Algorithms', 'Antibiotics', 'Area', 'Automobile Driving', 'Awareness', 'Bacterial Infections', 'Bayesian Modeling', 'Bayesian learning', 'Bladder', 'Communicable Diseases', 'Complex', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Consensus', 'Custom', 'Data', 'Dependence', 'Development', 'Dropout', 'Early Diagnosis', 'Early Intervention', 'Enterobacteriaceae', 'Escherichia coli', 'Future', 'Germ-Free', 'Gnotobiotic', 'Goals', 'Infection', 'Invaded', 'Lead', 'Machine Learning', 'Mannosides', 'Metagenomics', 'Methods', 'Modeling', 'Mus', 'Pathogenesis', 'Patients', 'Population', 'Process', 'Publishing', 'Recurrence', 'Research', 'Resolution', 'Sampling', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Source', 'Statistical Models', 'Techniques', 'Therapeutic', 'Time', 'Transcend', 'Urinary tract infection', 'Uropathogenic E. coli', 'Validation', 'Variant', 'acute infection', 'base', 'clinical application', 'clinical diagnostics', 'clinically relevant', 'de novo mutation', 'experience', 'experimental study', 'flexibility', 'human microbiota', 'improved', 'in vivo', 'machine learning method', 'microbial', 'microbiome', 'microbiome therapeutics', 'microbiota', 'mouse model', 'novel therapeutics', 'nucleobase', 'pathogen', 'recurrent infection', 'small molecule', 'stem', 'targeted treatment', 'therapeutic development', 'time use', 'tool']",NIAID,BRIGHAM AND WOMEN'S HOSPITAL,R21,2021,268500
"Multi-atlas and whole body radiomics approaches for image-guided treatment of gynecologic cancers ABSTRACT  Gynecologic cancers are among the leading causes of cancer death in women worldwide. These patients typically are socioeconomically disadvantaged, with poor access to screening and vaccination. Consequently, they often present with locoregionally advanced disease, for which pelvic radiotherapy (RT) with concurrent cisplatin (i.e., chemoradiotherapy) is the standard of care. This treatment is limited, however, by high rates of treatment failure. Intensifying treatment through the delivery of chemotherapy doublets, either concurrently or as adjuvant therapy following chemoradiotherapy, is a promising strategy to improve outcomes. However, the delivery of intensive chemotherapy is complicated by high rates of gastrointestinal and hematologic toxicity. Strategies to reduce toxicity while increasing efficacy of chemoradiotherapy are needed.  Standard pelvic RT techniques encompass large volumes of normal tissue including bowel, bone marrow, bone, bladder, and rectum, leading to preventable radiation-induced toxicity. Image-guided radiation therapy (IGRT) can improve target localization and dosimetry, optimizing target dose while minimizing dose to surrounding normal tissues. However, IGRT can be highly resource intensive, and comparative effectiveness trials have been lacking. For this reason, there is considerable controversy as to the utility of IG-IMRT in this disease. Our research group has been at the forefront of developing novel, cost-effective IGRT approaches with wide potential to facilitate better delivery of concurrent and/or adjuvant chemotherapy.  Previously we have found that radiation-induced injury to hematopoietically active bone marrow is a critical determinant of tolerance to intensive chemotherapy. Using machine learning methods, we recently developed a multi-atlas-based IGRT method that can predict canonical distributions of active bone marrow, which can obviate the need for positron emission tomography (PET) in settings where this technology is unavailable or unaffordable. The proposed new research will study the ability of multi-atlas-based IGRT to reduce hematologic toxicity and improve chemotherapy delivery compared to standard treatment, using data from 450 patients enrolled to a randomized phase III trial (NRG-GY006). Furthermore, we will use serial whole body PET/CT to study the impact of radiation dose and chemotherapy intensity on the compensatory hematopoietic response, and have developed novel whole body radiomics biomarkers to quantify the inflammatory state, which we hypothesize can influence patients' outcomes and tolerance to chemotherapy.  The new research extends our work associated with a current R01 grant (1R01CA197059-01) to conduct correlative science associated with the GY006 trial. The overarching goal of this research line is to augment the therapeutic ratio of chemoradiotherapy for pelvic cancers using advanced image-guided radiation techniques. If successful, this research would significantly alter the approach to the treatment of many pelvic malignancies for which chemoradiotherapy is standard. PROJECT NARRATIVE In this study, we will test the ability of a novel method called multi-atlas-based image guided radiation therapy (IGRT) to reduce acute hematologic toxicity and improve chemotherapy delivery compared to conventional RT, which could obviate the need for expensive functional imaging in socioeconomically disadvantaged and resource constrained populations, such as patients with gynecologic cancers. In addition, we will use serial positron emission tomography to study effects of chemotherapy and radiation on the subacute compensatory hematopoietic response, and will seek to develop and validate novel whole body radiomics models of the inflammatory state as predictive biomarkers for gynecologic cancers. We are in an optimal situation to conduct impactful and innovative research in the context of an ongoing phase III cooperative group randomized registration trial (NRG GY006), affording us the opportunity to conduct rigorous correlative science on a large sample with high data quality, quality assurance, and carefully controlled treatment effects.",Multi-atlas and whole body radiomics approaches for image-guided treatment of gynecologic cancers,10108128,R01CA255780,"['Acute', 'Adjuvant Chemotherapy', 'Adjuvant Therapy', 'Aftercare', 'Aging', 'Atlases', 'Biological Markers', 'Bladder', 'Bone Marrow', 'Cancer Etiology', 'Cancer Patient', 'Cessation of life', 'Chemotherapy and/or radiation', 'Cisplatin', 'Consumption', 'Data', 'Dependence', 'Disease', 'Distant', 'Dose', 'Effectiveness', 'Enrollment', 'Functional Imaging', 'Goals', 'Grant', 'Hematology', 'Hematopoiesis', 'Hematopoietic', 'Inflammatory', 'Injury', 'Intensity-Modulated Radiotherapy', 'Intestines', 'Malignant Female Reproductive System Neoplasm', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Neck', 'Normal tissue morphology', 'Organ', 'Outcome', 'Patient Selection', 'Patient-Focused Outcomes', 'Patients', 'Pelvic Cancer', 'Pelvis', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Positron-Emission Tomography', 'Predictive Factor', 'Process', 'Radiation', 'Radiation Dose Unit', 'Radiation therapy', 'Randomized', 'Rectum', 'Recurrence', 'Research', 'Resources', 'Sampling', 'Science', 'Site', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Toxic effect', 'Treatment Failure', 'Treatment outcome', 'Triapine', 'Vaccination', 'Woman', 'Work', 'advanced disease', 'base', 'bone', 'chemoradiation', 'chemotherapy', 'comparative effectiveness trial', 'cost', 'cost effective', 'data quality', 'dosimetry', 'fluorodeoxyglucose positron emission tomography', 'gastrointestinal', 'image guided', 'image guided radiation therapy', 'image-guided radiation', 'imaging approach', 'imaging biomarker', 'improved', 'improved outcome', 'innovation', 'machine learning method', 'mortality', 'novel', 'personalized medicine', 'phase III trial', 'predictive marker', 'quality assurance', 'radiation-induced injury', 'radiomics', 'recruit', 'response', 'screening', 'socioeconomic disadvantage', 'standard care', 'standard of care', 'tool', 'treatment effect', 'trial design', 'whole body imaging']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,276286
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10162472,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2021,283097
"SCH: Active Learning for Medical Applications Cancer is considered one of the most dilapidating health problems that the world is facing due to its physical, emotional, financial, and spiritual toll. Automating cancer diagnosis can ultimately impact its treatment and recovery. Computational algorithmic methods can greatly improve the efficiency of pathologists through partial or complete automation of the diagnostic process. Computer-aided diagnosis has augmented preventive check-ups for many medical conditions like breast cancer, colonic polyps, and lung cancer. Digitization of tissue slides has thus opened up the process of diagnosis through analysis of digital images. The dearth of highly trained pathologists who can address the growing diagnostic needs heightens the importance of such automation. Recent advances in big data analytics and in particular machine learning can possibly impact greatly the domain of computer-aided cancer diagnosis. Convolutional Neural Networks (CNNs) in particular have already revolutionized the domain of computer vision with performances in various cases compared to that exhibited by humans. One of the main factors that fueled the recent resurgence of CNNs is the availability of large datasets. CNNs adjust, via training, millions of parameters allowing them to learn complex and highly nonlinear dependencies among data (i.e., images). However, collecting such large amounts of annotated data (assigning them to one of many possible categories, e.g., benign vs. cancerous vs. other stages) is either challenging or very expensive or in many cases unavailable. This is definitely the case of the medical domain. Tissue slides from suspected cancerous regions are examined under a microscope and are classified as benign or malignant. CNNs offer a promising pathway to achieve some degree of automation in identifying cancerous cases in image data. This research work will explore the challenges· of discovering the underlying discriminative features, hidden in the image and possibly different than those used by human experts, in order to improve the accuracy of diagnosis. We will also focus on algorithms to minimize the amount of data required to train the neural network without sacrificing performance and generalization. Cancer has been a major health concern and one of the leading causes of death in the US and around the world. Automating cancer diagnosis can impact cancer staging and ultimately its treatment, effectively leading to higher survival rates. This proposal' promises the creation of computational algorithmic methods that can lead to partial or complete automation of the cancer diagnostic process.",SCH: Active Learning for Medical Applications,10086856,R01CA225435,"['Active Learning', 'Address', 'Algorithms', 'Attention', 'Automation', 'Benchmarking', 'Benign', 'Big Data Methods', 'Breast', 'Cancer Diagnostics', 'Cancerous', 'Categories', 'Cause of Death', 'Clinics and Hospitals', 'Collaborations', 'Colonic Polyps', 'Communities', 'Complex', 'Computational algorithm', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Data', 'Data Discovery', 'Data Set', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'Early Diagnosis', 'Educational Curriculum', 'Educational workshop', 'Emotional', 'Engineering', 'Exhibits', 'Health', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Information Retrieval', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical', 'Medical Imaging', 'Medical center', 'Methodology', 'Methods', 'Microscope', 'Middle School Student', 'Modality', 'Pathologist', 'Pathway interactions', 'Pattern', 'Performance', 'Preventive', 'Process', 'Prostate', 'Recovery', 'Research', 'Research Personnel', 'Scheme', 'Science', 'Security', 'Slide', 'Survival Rate', 'System', 'Testing', 'Tissues', 'Training', 'Transportation', 'Underrepresented Populations', 'Variant', 'Visual Manifestations', 'Work', 'X-Ray Computed Tomography', 'algorithmic methodologies', 'cancer diagnosis', 'cancer type', 'cohesion', 'convolutional neural network', 'data exploration', 'diagnostic accuracy', 'digital imaging', 'hands-on learning', 'histological slides', 'image processing', 'improved', 'interest', 'kidney imaging', 'large datasets', 'learning community', 'learning strategy', 'machine learning method', 'malignant breast neoplasm', 'neural network', 'object recognition', 'online repository', 'outreach', 'outreach program', 'phenomenological models', 'programs', 'repository', 'self-directed learning', 'stem', 'tool', 'user-friendly', 'web page', 'wiki']",NCI,UNIVERSITY OF MINNESOTA,R01,2021,309176
"A magnetic capsule endoscope for colonoscopy in patients with inflammatory bowel disease We propose to develop, optimize, and conduct first in-human measurements of our Magnetic Flexible Endoscope (MFE) robotic platform that may provide a safer and more intelligent alternative to standard colonoscopy (CLS) for patients with Inflammatory Bowel Disease (IBD). Patients with IBD are at increased risk for colorectal cancer and therefore surveillance has been recommended to occur at intervals less than that recommended for the general population. Thus, over the course of their lifetime, they are subjected to more frequent CLS than their non-lBD counterparts, resulting in a more than 6-fold increase in adverse events. The main risks of CLS are related to procedural sedation, patient discomfort, or perforation of the colon from looping. Looping and mesenteric stretching occur due to the design of the colonoscope. Special maneuvers can be performed to minimize looping, making CLS a procedure that requires a great degree of technical skill and experience to perform safely. By using the proposed robotic platform, the endoscopist will be able to control the motion of the MFE to perform navigation, diagnosis, and therapy (i.e. biopsy, polyp removal/retrieval, injection) inside the human colon. MFE motion is achieved by magnetic coupling between an external permanent magnet (attached to a robotic arm outside the patient's body) and an internal permanent magnet (located inside the proximal head of the MFE). A small-diameter flexible tether between the head of the endoscope and the distal control module (outside the patient's body) allows for passage of commercially available therapeutic tools, insufflation, irrigation, suction/aspiration, and electrical wiring. Employing magnetic attraction at the head of the endoscope, for advancement and manipulation, permits the tether to follow passively-reducing the risk of mesenteric stretching or looping when compared to the traditional colonoscope. We will leverage our experience and extensive preliminary results to test the hypotheses that (1) intelligent robotic control and assistive autonomy in endoscopic tasks improves endoscopic performance, (2) quantifying the portion of colon lumen visualized provides valuable feedback to improve MFE operation and diagnostic yield, and (3) that the MFE is safe and successfully functions in the human colon in a manner similar to conventional CLS. The investigative team, combining engineering and clinical faculty, is uniquely positioned to achieve success of this study-collectively possessing expertise in endoscopic device design, clinical CLS, assessment and validation of innovative gastrointestinal technologies, robotics, magnetism, image processing, artificial intelligence, and translation of research-engineering developments into clinical applications. Additionally, the investigators have a long-standing history of close and fruitful collaboration including R01 EB018992. If successful, this approach will demonstrate first in-human use of the MFE that reduces potential adverse events in an at-risk population (IBD patients), is intuitive to control, and integrates intelligent guidance into colon exploration and inspection. The robotic platform we propose has the potential to provide a safer, more accessible, and potentially painless alternative to standard colonoscopy for patients with Inflammatory Bowel Disease (Ulcerative Colitis or Crohn's disease)-a disease that impacts the lives of over three million Americans, who are at a 6-fold increased risk for post-colonoscopy adverse events when compared to their non-lBD counterparts. The platform uses magnetic actuation, intelligent closed-loop control, and integrated assistive autonomy of our diagnostic and therapeutic magnetic flexible endoscope (MFE) to facilitate intuitive endoscopist-directed motion under precise control with a novel colon-visualization-index (CVI) that provides feedback to the endoscopist with estimates of the portion of colon lumen successfully imaged to maximize the yield of exam. We propose the first in-human study of a magnetically actuated robotic platform for colonoscopy and the first in-human demonstration of intelligent control with assistive autonomy using magnetic fields.",A magnetic capsule endoscope for colonoscopy in patients with inflammatory bowel disease,10121126,R01EB018992,"['3-Dimensional', 'Address', 'Adverse event', 'Algorithms', 'American', 'Anatomy', 'Animal Model', 'Articulation', 'Artificial Intelligence', 'Automation', 'Benchmarking', 'Benign', 'Biopsy', 'Cadaver', 'Caliber', 'Cecum', 'Clinical', 'Collaborations', 'Collection', 'Colon', 'Colonoscopes', 'Colonoscopy', 'Complication', 'Coupling', 'Crohn&apos', 's disease', 'Detection', 'Development', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Distal', 'Dysplasia', 'Electric Wiring', 'Endoscopes', 'Endoscopy', 'Engineering', 'Excision', 'Failure', 'Family suidae', 'Feedback', 'Frequencies', 'Funding', 'Future', 'General Population', 'Goals', 'Gold', 'Guidelines', 'Head', 'Human', 'Image', 'Inflammatory Bowel Diseases', 'Injections', 'Insufflation', 'Intelligence', 'Intervention', 'Intubation', 'Intuition', 'Irrigation', 'Learning', 'Lesion', 'Magnetism', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Medical Device', 'Mesentery', 'Methods', 'Modeling', 'Motion', 'Mucositis', 'Mucous Membrane', 'Nature', 'Nursing Faculty', 'Painless', 'Pathology', 'Patients', 'Perforation', 'Performance', 'Polyps', 'Populations at Risk', 'Positioning Attribute', 'Procedures', 'Provider', 'Recording of previous events', 'Research Personnel', 'Retrieval', 'Risk', 'Robotics', 'Safety', 'Sedation procedure', 'Software Validation', 'Stream', 'Stretching', 'Suction', 'Surface', 'Technical Degree', 'Technical Expertise', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Translational Research', 'Ulcerative Colitis', 'Validation', 'Vision', 'Visualization', 'Work', 'arm', 'base', 'biomaterial compatibility', 'capsule', 'clinical application', 'colorectal cancer risk', 'comorbidity', 'design', 'detection method', 'experience', 'first-in-human', 'flexibility', 'gastrointestinal', 'human study', 'image processing', 'improved', 'in vivo', 'indexing', 'innovation', 'instrument', 'lifetime risk', 'magnetic field', 'novel', 'operation', 'outcome forecast', 'pain patient', 'phantom model', 'prevent', 'procedure safety', 'reconstruction', 'response', 'robot assistance', 'robot control', 'skills', 'success', 'tool', 'trial comparing']",NIBIB,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,316138
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876
"Assessment of ultrasound features of knee osteoarthritis in a population-based community cohort Project summary Our long-term goal is to demonstrate the utility of ultrasound for OA assessment, standardize its acquisition and scoring, and promote increased uptake of US for use in clinical, research, and trial settings. Knee osteoarthritis (KOA) is highly prevalent and frequently debilitating. Development of potential treatments has been hampered by the heterogenous nature of this common chronic condition, which is characterized by a number of subgroups, or phenotypes, with different underlying pathophysiological mechanisms. Imaging, genetics, biochemical biomarkers, and other features can be used to characterize phenotypes, but variations in data types can make it difficult to harmonize definitions. While radiography is widely used in KOA imaging, it is limited in its ability to assess early disease (when interventions are most likely to succeed) and is insensitive to change. Ultrasound (US) is a widely accessible, time-efficient and cost-effective imaging modality that can provide detailed and reliable information about all joint tissues (e.g., cartilage, meniscus, synovium, bone), and could therefore inform phenotypes in KOA (e.g., by presence of synovitis, effusion, cartilage damage, calcium crystal deposition, and popliteal cysts). Use of US is currently limited by the lack of systematically performed studies in well-characterized non-clinical populations. To address this gap and further the use of this advantageous imaging modality for KOA, we will obtain standardized US and radiography in the population- based Johnston County Health Study (JoCoHS), the new enrollment phase of the 25+ year Johnston County OA Project which includes white, African American, and Hispanic men and women aged 35-70, to achieve three aims. In Aim 1, we will determine the population prevalence (n~3000) of knee US features including cartilage and meniscal damage, synovitis/effusion, calcium crystal deposition, popliteal cysts and osteophytes overall and in key subgroups by age, sex, race/ethnicity, and symptom status. Aim 2 will allow quantification of the associations between these US features and radiographic findings and symptom scores overall and in key subgroups (e.g., those with and without radiographic KOA, by sex, by race/ethnicity). For Aim 3, we will apply novel machine learning methodologies (e.g., Direction-projection-permutation [DiProPerm] hypothesis testing, Joint and Individual Variation [JIVE], and Distance-Weighted Discrimination [DWD]) to a) develop an overall US score for symptomatic KOA and b) identify the contribution of US variables to phenotypes relevant to KOA based on general health, physical activity, and functional assessments. This study is a crucial step to establish the foundation for US as an assessment tool for clinical use, research, and clinical trials in KOA, providing unique population-based cross-sectional data regarding the utility of US and forming the basis for future longitudinal work evaluating its value and performance characteristics related to incident and progressive KOA. Project narrative Osteoarthritis is an enormous and increasing public health problem that, like many other chronic conditions, is not a single disease but a heterogeneous condition consisting of multiple subgroups, or phenotypes, with differing underlying mechanisms. Ultrasound is an accessible, time-efficient, and cost-effective imaging modality that provides invaluable data about all joint tissues involved in osteoarthritis and has the potential to identify important phenotypes. The proposed work is relevant to the NIAMS mission and represents a crucial step to establish the foundation for ultrasound as an assessment tool for use in clinics, research, and clinical trials in osteoarthritis.",Assessment of ultrasound features of knee osteoarthritis in a population-based community cohort,10158441,R01AR077060,"['Address', 'African American', 'Age', 'Area', 'Assessment tool', 'Bilateral', 'Biochemical', 'Biological Markers', 'Bone Spur', 'Calcium', 'Cartilage', 'Categories', 'Characteristics', 'Chronic', 'Claustrophobias', 'Clinic', 'Clinical', 'Clinical Assessment Tool', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Communities', 'County', 'Crystal Formation', 'Crystallization', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Discrimination', 'Disease', 'Enrollment', 'Ethnic Origin', 'Etiology', 'Foundations', 'Future', 'General Population', 'Goals', 'Health', 'Hispanics', 'Image', 'Implant', 'Individual', 'Infrastructure', 'Intervention', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Meniscus structure of joint', 'Methodology', 'Mission', 'Modality', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Nature', 'Outcome', 'Pain', 'Participant', 'Pathology', 'Performance', 'Phase', 'Phenotype', 'Physical activity', 'Popliteal Cyst', 'Population', 'Population Study', 'Prevalence', 'Public Health', 'Race', 'Receiver Operating Characteristics', 'Research', 'Risk Factors', 'Sex Differences', 'Specialist', 'Standardization', 'Subgroup', 'Symptoms', 'Syndrome', 'Synovial Membrane', 'Synovitis', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Variant', 'Woman', 'Work', 'aged', 'base', 'bone', 'cohort', 'cost', 'cost effective', 'effusion', 'follow-up', 'imaging genetics', 'imaging modality', 'individual variation', 'interest', 'men', 'novel', 'point of care', 'population based', 'recruit', 'rheumatologist', 'sex', 'uptake']",NIAMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,331837
"Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics Abstract The primary objective is to develop an artificial intelligence-centric, quantitative and noninvasive software platform that can be integrated into 3D angiographic scanners (DSA, CTA or MRA) to provide guidance regarding the diagnosis and management of intracranial aneurysms (IA). Hemorrhagic stroke secondary to ruptured IAs leads to significant morbidity and mortality and affects over 35,000 patients on a yearly basis in the United States. The diagnosis of asymptomatic IAs is on the rise with the increasing use of cerebral imaging. However, guidance regarding which aneurysms should be treated has not advanced. Leveraging recent advances in computational science and technology, particularly artificial intelligence, the proposed software platform built on two enabling technologies can (1) propel automated “patient-specific” hemodynamic evaluations into the clinical workflow and (2) conduct “data-driven” risk assessments of IA rupture on an individual basis. Specific research aims are to (1) develop a clinically-oriented CFD platform that enables automated “patient-specific” hemodynamic evaluations of IAs, (2) investigate data-driven analytics toward prediction of rupture risk for IAs and (3) evaluate the data-driven analytics in a blind study. Once validated, a follow-up R01 project is planned to examine the clinical utility of the proposed software platform in a prospective clinical study as a single gateway for computer-aided evaluation of cerebral aneurysms. Public Health Relevance/Narrative This R01 proposal is to investigate the feasibility of developing an innovative, non-invasive and artificial intelligence-centric tool that can be used as a software add-on to clinical angiographic (e.g. DSA) scanners. The software can automatically select high-risk aneurysms for immediate treatments from a pool of patients with unruptured intracranial aneurysms, impacting the clinical management of intracranial aneurysms.",Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics,10121043,R01EB029570,"['3-Dimensional', 'Affect', 'Aneurysm', 'Angiography', 'Architecture', 'Artificial Intelligence', 'Benign', 'Biomedical Computing', 'Biomedical Engineering', 'Brain hemorrhage', 'Cerebral Aneurysm', 'Cerebrum', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computational Geometry', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Engineering', 'Ensure', 'Evaluation', 'Genetic', 'Growth', 'Human', 'Image', 'Individual', 'Intracranial Aneurysm', 'Knowledge', 'Liquid substance', 'Machine Learning', 'Medicine', 'Methods', 'Michigan', 'Morbidity - disease rate', 'Morphology', 'Natural History', 'Neural Network Simulation', 'Outcome', 'Patients', 'Physics', 'Play', 'Research', 'Research Proposals', 'Risk', 'Risk Assessment', 'Role', 'Rupture', 'Ruptured Aneurysm', 'Secondary to', 'Smoker', 'Technology', 'TensorFlow', 'Testing', 'Training', 'Translational Research', 'United States', 'Universities', 'Wisconsin', 'Work', 'analytical method', 'base', 'blind', 'computer grid', 'convolutional neural network', 'deep learning', 'flexibility', 'follow-up', 'hemodynamics', 'high risk', 'image guided', 'innovation', 'learning strategy', 'mortality', 'neurosurgery', 'open source', 'personalized management', 'prevent', 'prospective', 'prototype', 'public health relevance', 'shear stress', 'success', 'tool']",NIBIB,MICHIGAN TECHNOLOGICAL UNIVERSITY,R01,2021,346966
"Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity PROJECT SUMMARY The long-term goal of this project is to determine whether optical coherence tomography (OCT) and OCT angiography (OCTA) might lead more accurate and objective diagnosis, earlier intervention, and improved outcomes in retinopathy of prematurity (ROP). International consensus and National Institute of Health (NIH) funded clinical trials over the last 30 years have defined the phenotypic classifications, natural history, prognosis, and management of ROP. However, it is well established that due to the subjectivity of the ophthalmoscopic examination, and systematic bias between examiners, there is significant variation in treatment of the most severe forms of ROP in the real world. This leads to both under-treatment (and poor outcomes due to retinal detachment) and over-treatment (exposing neonates to the ocular and systemic risks of treatment). Roughly 20,000 babies per year develop retinal detachments (RD) due to ROP and there is strong evidence that most of these are preventable. In adult retinal vascular diseases, most notably diabetic retinopathy (DR), OCT and OCTA can detect and quantify disease features such as diabetic macular edema (DME) and retinal neovascularization (NV) before they are noted clinically, enabling earlier treatment and reducing the risk of blindness from RD. However, evaluating the use of this technology in neonates requires high speed and portable technology, and the commercially available handheld OCTs are too slow for ultra-widefield (UWF) OCT and OCTA imaging. Several groups (including our own) have published preliminary results using prototype 100 to 200 kHz swept- source (SS) OCT systems, however consistent data acquisition remains challenging due to the lack of fixation and subsequent motion in an awake neonate, which has limited the evaluation of the potential benefits of the technology in this population. Recently, there has been much interest in using artificial intelligence (AI) (specifically deep learning), which relies on high speed graphics processing units (GPUs) to provide real time OCT image processing, segmentation, and tracking. This application addresses 2 fundamental gaps in knowledge: (1) Can we overcome the technical challenges through the development of a faster ultrawide-field view SS-OCT system coupled with a GPU-enabled DL software system to enable consistent data acquisition in neonates? (2) Would quantitative objective metrics of ROP improve objectivity of ROP diagnosis and detect subclinical signs of disease progression which may enable earlier intervention and improved outcomes in the future. By leveraging our institution’s OCT, AI, and ROP expertise, we will address these questions in three specific aims: (1) Develop an ultra-high speed, handheld, panoramic ultra-widefield OCT/OCTA system. (2) Develop real time GPU accelerated intelligent image acquisition software. (3) Evaluate the clinical significance OCT derived biomarkers. Successful translation of this technology to the ROP population could improve the accuracy and objectivity of ROP diagnosis, and lead to earlier intervention and improved outcomes in patients with severe ROP. PROJECT NARRATIVE Optical Coherence Tomography (OCT) and OCT angiography (OCTA) have proven the ability to detect subclinical disease, provide quantitative evaluation of disease progression, and improve outcomes in the leading causes of blindness in adults, age-related macular degeneration and diabetic retinopathy. Technological and practical limitations have limited the application of this technology in routine use for non-sedated children undergoing routine screening for retinopathy of prematurity (ROP), the leading cause of blindness in children. The proposed project will develop an ultra-high speed, handheld OCT system with graphics processing unit (GPU) enabled real-time processing to improve the feasibility of panoramic ultra-widefield OCT/OCTA imaging in non-sedated neonates and evaluate the clinical utility of OCT-derived biomarkers in ROP.",Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity,10198930,R01HD107494,"['Address', 'Adult', 'Aftercare', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Artificial Intelligence', 'Biological Markers', 'Blindness', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Trials', 'Computer software', 'Consensus', 'Coupled', 'Cross-Sectional Studies', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Disease Progression', 'Dyes', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Evaluation', 'Eye', 'Fluorescein Angiography', 'Funding', 'Fundus', 'Future', 'Goals', 'Image', 'Image Analysis', 'Injections', 'Institution', 'Intelligence', 'International', 'Knowledge', 'Lasers', 'Lead', 'Length', 'Longitudinal Studies', 'Measurement', 'Medical Imaging', 'Methods', 'Monitor', 'Morphologic artifacts', 'Motion', 'Natural History', 'Neonatal', 'Ophthalmic examination and evaluation', 'Ophthalmoscopes', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Peripheral', 'Phenotype', 'Pilot Projects', 'Population', 'Primary Health Care', 'Publishing', 'Quantitative Evaluations', 'Retina', 'Retinal Detachment', 'Retinal Neovascularization', 'Retinopathy of Prematurity', 'Risk', 'Scanning', 'Severities', 'Severity of illness', 'Source', 'Speed', 'Structure', 'System', 'Systematic Bias', 'Technology', 'Testing', 'Time', 'Translations', 'United States National Institutes of Health', 'Variant', 'Vascular Diseases', 'Visualization', 'accurate diagnosis', 'arm', 'awake', 'base', 'blind', 'clinical Diagnosis', 'clinically significant', 'data acquisition', 'deep learning', 'design', 'diabetic', 'disease classification', 'disorder of macula of retina', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'instrument', 'interest', 'lens', 'macular edema', 'neonate', 'neovascularization', 'novel', 'outcome forecast', 'overtreatment', 'parallel computer', 'portability', 'prototype', 'real-time images', 'research clinical testing', 'routine screening', 'sample fixation', 'software systems', 'standard of care', 'treatment response', 'treatment risk']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,377300
"A Quantitative Risk Model for Predicting Outcome and Identifying Structural Biomarkers of Treatment Targets in Oral Cancer on a Large Multi-Center Patient Cohort Post-resection prognostication for oral cavity cancers (OCC) is qualitative and potentially ambiguous. A significant subset (25-37%) of Stage I/II patients still develop local recurrence after treatment with surgery alone. The long-term goal of this proposal will be to create a Quantitative Risk Model (QRM) using machine learning and artificial intelligence to predict recurrence risk for Stage I/II patients using image-based biomarkers of aggression. The objective is to develop and validate state-of-the-art systems for biomarker imaging, quantification, and modeling to accurately predict risk of recurrence in cancer patients based on image analytics. The central hypothesis is that a quantitative, artificial intelligence approach to pathology will result in significantly greater prognostic value compared with manual microscope-based analysis. The rationale for this work is that tumor aggression can be predicted from patterns present in pathology images, given the existence of histological risk models that have been clinically validated in the past; however, these risk models are not in widespread use because they are less accurate, robust, and transportable to the larger community of pathologists. This proposal will test the central hypothesis through three specific aims: (1) Develop an analysis pipeline that can accurately predict recurrence risk for Stage I/II OCC patients and identify treatment targets (e.g. adaptive local immune response and angiogenesis); (2) Demonstrate robust performance across a multi-site data cohort collected from seven national and international centers; and (3) Distil the results of QRM analysis to synoptic pathology reporting, demonstrating the ability of QRM to interface with standard clinical reporting tools. The innovation for addressing these aims comes from a unique application of active learning for training artificial intelligence to recognize tissue structures, new features for quantifying tissue architecture based on the interface between tumor and host, and a novel approach for large cross-site validation. Moreover, this proposal develops a unique mapping between computational pathology and commonly-used synoptic reporting variables, enabling rapid uptake of this work into existing clinical workflows. This research is significant because it provides personalized outcome predictions for a niche group of undertreated patients with limited options and can serve as the foundation for designing future clinical trials through identification of treatment targets. Multi-site training and evaluation, combined with AI-to-report mapping, will be broadly applicable to a large group of computational approaches, bridging the gap between engineering research labs and clinical application. The expected outcome of this work is a trained model for predicting Stage I/II OCC recurrence, identification of treatment targets, and mapping to synoptic reports, as well as a broadly-applicable workflow for the broader computational pathology community. This project will have a large positive impact on patients and surgical pathologists by enabling rapid, accurate prognosis and directed treatment plans in an easy-to-use pipeline that integrates seamlessly into existing clinical workflows. We aim to develop a quantitative risk model for oral cavity cancer patients, 25-37% of whom will experience debilitating post-treatment recurrence. Using state-of-the-art machine learning and artificial intelligence methods, we will develop and validate our risk model on a large multi-site cohort of patients, and develop an AI-assisted synoptic report-filling tool for integrating into clinical practice. A computational pathology approach to characterizing disease will help identify patients for whom aggressive multimodality therapy will improve outcomes and post-treatment quality of life.",A Quantitative Risk Model for Predicting Outcome and Identifying Structural Biomarkers of Treatment Targets in Oral Cancer on a Large Multi-Center Patient Cohort,10149283,R01DE028741,"['Active Learning', 'Address', 'Aftercare', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'Biological Markers', 'Blinded', 'Cancer Patient', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Collection', 'Combined Modality Therapy', 'Communities', 'Companions', 'Consensus', 'Country', 'Data', 'Databases', 'Disease', 'Elements', 'Engineering', 'Evaluation', 'Excision', 'Foundations', 'Future', 'Goals', 'Head and Neck Surgery', 'Head and neck structure', 'Histologic', 'Image', 'Immune response', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical Economics', 'Methods', 'Microscope', 'Modeling', 'Operative Surgical Procedures', 'Oral Stage', 'Outcome', 'Pathologist', 'Pathology', 'Pathology Report', 'Patients', 'Pattern', 'Performance', 'Play', 'Postoperative Period', 'Productivity', 'Quality of life', 'Radiation therapy', 'Randomized', 'Recurrence', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Risk', 'Salvage Therapy', 'Screening procedure', 'Semantics', 'Site', 'Slide', 'Specimen', 'Standardization', 'Structure', 'Surgical Pathology', 'System', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Work', 'Workload', 'analysis pipeline', 'angiogenesis', 'base', 'cancer recurrence', 'cancer type', 'clinical application', 'clinical practice', 'cohort', 'computational pipelines', 'deep learning', 'design', 'digital', 'digital pathology', 'expectation', 'experience', 'experimental study', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'improved outcome', 'innovation', 'international center', 'malignant mouth neoplasm', 'novel strategies', 'outcome forecast', 'outcome prediction', 'pathology imaging', 'patient oriented', 'predictive modeling', 'pressure', 'prognostic', 'prognostic value', 'quality assurance', 'quantitative imaging', 'screening', 'segmentation algorithm', 'tool', 'treatment planning', 'tumor', 'uptake']",NIDCR,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2021,380042
"Developing computational algorithms for histopathological image analysis Project Summary  Histopathology is the cornerstone of disease diagnosis and prognosis. With the advance of imaging technology, whole-slide image (WSI) scanning of tissue slides is becoming a routine clinical procedure and producing a massive amount of data that captures histopathological details in high resolution. Most current pathological image analysis methods, similar to general image analysis approaches, mainly focus on morphology features, such as tissue texture and granularity, but ignore the complex hierarchical structures of tissues. Cells are the fundamental building blocks to tissues. Different types of cells are first organized into cellular components, which together with the extracellular matrix, form different types of tissue architectures. Understanding the interactions among these different types of cells can provide critical insights into biology and disease status. However, there are some major computational challenges: (1) How to identify and classify different types of cells in tissue, (2) how to characterize the highly complex and heterogeneous spatial organization of tissue, and (3) how to integrate histopathology data with other types of data to study disease status and progression. The goal of this proposal is to develop novel computational methods to analyze histopathology image data to study disease status and progression. In order to achieve this goal, we have built a strong research team with complementary expertise in image analysis, machine learning, statistical modeling, and clinical pathology. Specifically, we will develop novel algorithms to: (1) classify different types of cells from histopathology tissue WSI scans, (2) characterize and quantify cell spatial distribution and cell-cell interactions, and (3) integrate histopathology data with other types data to study disease progression. All proposed methods were motivated by real-world biological and clinical applications across different types of diseases, such as liver diseases, infectious diseases, and cancer. If implemented successfully, the proposed study will facilitate the analysis and modeling of data generated from histopathology tissue slides to improve disease risk assessment, diagnosis, and outcome prediction. Narrative Technological advances in histopathology imaging and computing have enabled the in-depth characterization of pathology tissues. The overarching goal of this proposal is to develop computational algorithms to analyze histopathology image data to study disease status and progression.",Developing computational algorithms for histopathological image analysis,10097119,R01GM140012,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Bayesian Method', 'Biological', 'Biology', 'Biomedical Research', 'Cell Communication', 'Cells', 'Classification', 'Clinical', 'Clinical Pathology', 'Communicable Diseases', 'Communities', 'Complex', 'Computational algorithm', 'Computer Models', 'Computing Methodologies', 'Data', 'Diagnosis', 'Disease', 'Disease Progression', 'Evaluation', 'Extracellular Matrix', 'Genomics', 'Goals', 'Graph', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histologic', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Intuition', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Network-based', 'Pathologic', 'Pathologist', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Physics', 'Procedures', 'Research', 'Resolution', 'Risk Assessment', 'Scanning', 'Slide', 'Spatial Distribution', 'Stains', 'Statistical Models', 'Structure', 'Texture', 'Tissue imaging', 'Tissues', 'base', 'cancer type', 'cell type', 'clinical application', 'clinical care', 'convolutional neural network', 'data integration', 'data modeling', 'deep learning algorithm', 'digital', 'digital pathology', 'disease diagnosis', 'disorder risk', 'drug discovery', 'experience', 'improved', 'insight', 'machine learning method', 'molecular pathology', 'multiple datasets', 'novel', 'outcome forecast', 'outcome prediction', 'particle', 'pathology imaging', 'predictive modeling', 'software development', 'user friendly software', 'whole slide imaging']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,409167
"Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK) PROJECT SUMMARY  Contemporary ocular surgeries are performed by skilled surgeons through operating microscopes, utilizing freehand techniques and manually operated precision micro-instruments, where the outcomes are often limited by the surgeon's skill levels and experiences. To overcome these human factors, we have assembled an interdisciplinary team including a clinician-scientist and eye surgeon, an optical device scientist and medical robotic engineers to translate existing and developing technologies in our laboratories into precision, “deep- learning” artificial intelligence (AI) guided robotic ocular surgical devices for precise automated Deep Anterior Lamellar Keratoplasty (AUTO-DALK).  DALK is a highly attractive treatment of corneal disease with normally functioning endothelium. However, the procedure is unusually challenging from a technical perspective and time-consuming, limiting its acceptance among corneal surgeons. The most challenging aspect of the procedure is related to the delamination of stroma from Descemet's membrane (DM). A procedure, commonly called “Big Bubble” is used to separate stroma from DM using deep intrastromal pneumatic injection. However, even experienced surgeons have difficulty precisely placing the injection. The most common complication of DALK is the excessive depth of the needle insertion resulting in Descemet's membrane perforation requiring conversion to full-thickness penetrating keratoplasty with its much longer recovery period and a higher risk of graft failure from rejection. The reported rates of Descemet's membrane perforation for beginner and experienced surgeons are 31.8% and 11.7% respectively. In addition, interface haze between the donor and recipient cornea is a common problem caused by the insufficient depth of needle insertion and failure to remove the host stromal tissue, which results in loss of postoperative visual acuity. These problems relate directly to the inability of the current surgical practice to precisely assess the depth of the tooltips inside the cornea layer in real-time.  Here we will build upon our previous and ongoing work in robust fiber optic common-path optical coherence tomography (CP-OCT) and AI-guide system based on convolutional neural network (CNN) robotic microsurgical tools that enable clinicians to precisely guide surgical tools at micron scale. The proposed AUTO- DALK surgical tool system is capable of one-dimensional real-time depth tracking, motion compensation, and detection of early instrument contact with tissue, which enables clinicians to perform DALK precisely and safely. The tool will be built on a handheld platform that will consist of CP-OCT probe, trephine and microinjector that allows precise and safe removal of the anterior section of cornea down to DM  We hypothesize that AI-OCT providing intelligent visualization and depth controlled optimal cornea cutting and tissue tracking will perform the task of DALK with better accuracy and efficiency over the manually performed trephine cutting and “Big Bubble” pneumodissection. Project Narrative  This proposal addresses fundamental limitations in current corneal transplant surgery by developing an artificial intelligence guided compact robotic surgical tool that could empower corneal surgeons to achieve difficult surgical objectives, reduce intraoperative complications, and improve clinical outcomes when performing Deep Anterior Lamellar Keratoplasty (DALK). Further, these capabilities are broadly applicable in other microsurgical problems, and the tools will enable further advances both for ophthalmology and for other microsurgical disciplines.",Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK),10100636,R01EY032127,"['Accounting', 'Address', 'Adrenal Cortex Hormones', 'Animal Model', 'Anterior', 'Artificial Intelligence', 'Blindness', 'Blunt Trauma', 'Burr hole procedure', 'Cadaver', 'Clinical', 'Complication', 'Consumption', 'Cornea', 'Corneal Diseases', 'Corneal Opacity', 'Corneal dystrophy', 'Data', 'Descemet&apos', 's membrane', 'Devices', 'Dimensions', 'Discipline', 'Distal', 'Drops', 'Early Diagnosis', 'Endophthalmitis', 'Endothelial Cells', 'Endothelium', 'Engineering', 'Ensure', 'Epithelial', 'Excision', 'Expert Systems', 'Eye', 'Eye Surgeon', 'Failure', 'Fiber Optics', 'Financial compensation', 'Geometry', 'Glaucoma', 'Goals', 'Graft Survival', 'Hemorrhage', 'Human', 'Image', 'Immune', 'Incidence', 'Infection', 'Injections', 'Intelligence', 'Intraoperative Complications', 'Iris', 'Keratoconus', 'Keratoplasty', 'Laboratories', 'Lamellar Keratoplasty', 'Lead', 'Manuals', 'Mechanics', 'Medical', 'Microscope', 'Modeling', 'Motion', 'Movement', 'Needles', 'Ocular Hypertension', 'Operative Surgical Procedures', 'Ophthalmology', 'Optical Coherence Tomography', 'Optics', 'Oryctolagus cuniculus', 'Outcome', 'Pathological Dilatation', 'Patients', 'Penetrating Keratoplasty', 'Perforation', 'Performance', 'Postoperative Complications', 'Postoperative Period', 'Procedures', 'Ptosis', 'Recovery', 'Repeat Surgery', 'Reporting', 'Research Personnel', 'Risk', 'Robotics', 'Rupture', 'Safety', 'Scientist', 'Secondary to', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Systems Development', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Topical Corticosteroids', 'Translating', 'Transplantation Surgery', 'Trauma', 'Validation', 'Visual', 'Visual Acuity', 'Visualization', 'Work', 'base', 'convolutional neural network', 'corneal scar', 'curative treatments', 'deep learning', 'design', 'experience', 'graft failure', 'high risk', 'iatrogenic injury', 'improved', 'in vivo', 'instrument', 'interest', 'novel', 'phantom model', 'photonics', 'preservation', 'prototype', 'sensor', 'skills', 'surgery outcome', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,409997
"Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization Project Summary Prostate cancer (PCa) is the most diagnosed form of non-cutaneous cancer in US men. The selection of patients who require immediate treatment from those suitable for active surveillance currently relies on non- specific and inaccurate measurements. A method that allows clinicians to more confidently discriminate clinically relevant from non-life-threatening tumors is needed to improve patient management. Multiparametric magnetic resonance imaging (mpMRI) is the preferred non-invasive imaging modality for characterizing primary PCa. However, its accuracy for detecting clinically significant PCa is variable. We propose to address this limitation by combining mpMRI with positron emission tomography (PET) with a PCa-specific radiotracer and using advanced multimodal machine learning models (i.e. radiomics and deep learning) to characterize tumor aggressiveness based on the imaging data. Recently, scanners capable of simultaneous PET and MR data acquisition in human subjects have become commercially available. An integrated MR-PET scanner is the ideal tool for comparing MR and PET derived image features to identify those that provide complementary information and build a hybrid PET-mpMRI model that most accurately identifies clinically significant tumors. While this novel technology allows the acquisition of perfectly coregistered complementary anatomical, functional and metabolic data in a single imaging session, a new challenge needs to first be addressed to obtain quantitatively accurate PET data. In an integrated MR-PET scanner, the information needed for PET attenuation correction (AC) has to be derived from the MR data and the methods currently available for this task are inadequate for advanced quantitative studies. We have formed an academic-industrial partnership to accelerate the translation of multimodal MR-PET machine learning approaches into PCa research and clinical applications by addressing the AC challenge and validating machine learning models for detecting clinically significant disease against gold standard histopathology in patients undergoing radical prostatectomy. Specifically, we will: (1) Develop and validate an MR-based approach for obtaining quantitatively accurate PET data. We hypothesize that attenuation maps as accurate as those obtained using a 511 keV transmission source – the true gold standard for PET AC – will be obtained; (2) Identify the multimodal radiomics model that most accurately predicts PCa aggressiveness. We hypothesize that the diagnostic accuracy of this approach will be superior to that offered by the stand-alone modalities; (3) Evaluate radiomics and deep learning approaches for predicting pPCa aggressiveness. We hypothesize that machine learning approaches will achieve a higher predictive accuracy when applied to data acquired simultaneously than sequentially. Project narrative A better method to non-invasively characterize primary prostate cancer is needed to improve patient management. Extracting additional information from multimodality quantitative MR-PET data using machine learning approaches is expected to result in better diagnostic performance. In this work, we propose to accelerate the translation of quantitative MR-PET to prostate cancer research and clinical applications. In particular, we will develop and validate an MR-based attenuation correction approach to guarantee that quantitatively accurate PET data are obtained in an integrated MR-PET scanner and then use machine learning approaches to characterize the aggressiveness of the tumors in patients undergoing radical prostatectomy.",Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization,10114224,R01CA218187,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Biopsy', 'Cancer Death Rates', 'Cancer Patient', 'Classification', 'Computer software', 'Data', 'Data Set', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Early treatment', 'FOLH1 gene', 'Gold', 'Guidelines', 'Hand', 'Histopathology', 'Hybrids', 'Image', 'Individual', 'Interobserver Variability', 'Kinetics', 'Lesion', 'Life Expectancy', 'Ligands', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Maps', 'Measurement', 'Meta-Analysis', 'Metabolic', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Morphology', 'PSA level', 'Patient Selection', 'Patients', 'Pelvis', 'Performance', 'Phenotype', 'Physiological', 'Positron-Emission Tomography', 'Prostate', 'Quality of life', 'Radical Prostatectomy', 'Reproducibility', 'Risk', 'Scanning', 'Source', 'Testing', 'Time', 'Translations', 'Work', 'anticancer research', 'attenuation', 'base', 'bone imaging', 'cancer classification', 'cancer imaging', 'clinical application', 'clinically relevant', 'clinically significant', 'data acquisition', 'deep learning', 'diagnostic accuracy', 'human subject', 'imaging modality', 'improved', 'industry partner', 'men', 'multimodal data', 'multimodality', 'new technology', 'non-invasive imaging', 'radiologist', 'radiomics', 'radiotracer', 'tool', 'transmission process', 'tumor']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,414490
"Prevalence effects in visual research: Theoretical and practical implications Low prevalence searches form an important and problematic class of visual search tasks. These are tasks where the search target is rare. Many socially important tasks like airport security or cancer screening are low prevalence tasks. Previous work, much of it from our lab, has shown that low prevalence can have undesirable effects. Most notably, miss (false negative) errors are markedly elevated at low prevalence. This is a clear problem if the purpose of the search is to detect something rare but important like cancer or a terrorist threat. Our previous work has documented this pattern of increased miss errors in a number of expert domains including cytology (cervical cancer screening), airport baggage screening, and breast cancer screening. False alarm (false positive) error rates typically decline at low prevalence, moving in the opposite direction from miss errors. This indicates a shift in the observer’s decision criterion. At low prevalence, observers become more reluctant to call something a target. Several studies – ours and others - have shown that this “conservative” criterion shift is not adequate to explain the entire prevalence effect. Wolfe and VanWert (2010) developed a “Dual- Threshold” model that better captures the important aspects of the prevalence effect data by proposing two effects of low prevalence: (1) the conservative shift in the criterion for deciding if an attended item is a target, and (2) a lowering of the “quitting threshold.” The quitting threshold determines when observers end a search. Quitting too soon also increases the chance that the observer will miss a target. Prevalence effects have been studied in experimental isolation from other aspects of search. However, in tasks like breast cancer screening, other factors interact with prevalence. The four projects in the present proposal each investigate one of these interactions. Project 1 examines the relationship of prevalence to the “vigilance decrements” that are seen as time elapses in a task. In search, observers must maintain an internal, mental representation of the search target (or targets). Project 2 is concerned with the impact of prevalence on these “target templates”. Advances in artificial intelligence (notably deep learning) are producing tools to assist expert searchers. However, once deployed, these AI tools have been less effective than theory predicts. Project 3 tests the hypothesis that part of the problem is another side-effect of low prevalence and the project tests a potential intervention. Finally, clinicians, searching for one type of target (e.g. pneumonia) are supposed to report signs of other possible problems (e.g. lung cancer). Project 4 probes the role of prevalence in the failure to report such “incidental findings”. Again, we test several interventions. This is “use-inspired, basic research” whose results will provide guidance for experts performing socially important low prevalence tasks. Important tasks like breast cancer screening involve visual search for rare (“low prevalence”)  targets but, unfortunately, low prevalence is known to increase the percentage of targets that are  missed even by well-trained experts. In a task like breast cancer screening, prevalence interacts  with other factors like observer vigilance or the effectiveness of an artificial intelligence tool.  This proposal studies four of these interactions with the goal of counteracting the malign effects  of prevalence; thus making it possible for experts to perform their critical search tasks more  effectively.",Prevalence effects in visual research: Theoretical and practical implications,10111519,R01EY017001,"['Artificial Intelligence', 'Basic Science', 'Breast Cancer Detection', 'Cervical Cancer Screening', 'Collaborations', 'Cytology', 'Data', 'Detection', 'Effectiveness', 'Failure', 'Flecks', 'Goals', 'Human', 'Hybrids', 'Incidental Findings', 'Intervention', 'Joints', 'Low Prevalence', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methods', 'Modeling', 'Paper', 'Pattern', 'Performance', 'Pneumonia', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Screening for cancer', 'Security', 'Talents', 'Testing', 'Time', 'Training', 'Trust', 'Visual', 'Work', 'analog', 'base', 'clinically significant', 'deep learning', 'design', 'improved', 'mental representation', 'programs', 'side effect', 'social', 'theories', 'tool', 'vigilance', 'visual search']",NEI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,441020
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",10075930,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Reference Standards', 'Research', 'Risk', 'Risk stratification', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'diagnostic technologies', 'disorder subtype', 'elastography', 'hepatocellular injury', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,448421
"Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis Project Summary Blood culture sensitivity in neonates is poor but is the “Gold Standard” for the diagnosis of sepsis. Universal genotyping of pathogen genomic sequences using High Resolution Melt (U-HRM) provides a simple, low cost, rapid, and modern alternative to blood culture testing. By measuring the fluorescence of an intercalating dye as PCR-amplified pathogen DNA fragments are heated and disassociate, sequence defined melt curves are generated with single-nucleotide resolution in a closed-tube reaction. We have advanced U- HRM into a digital PCR format (U-dHRM), where DNA sequences that are present in mixtures are individually amplified and identified as is needed for polymicrobial infections. We have also established unique signature melt curves for 37 bacterial species that commonly infect older children and adults and automatically identify them using machine learning technology. With the goal of creating an accurate and valid test for the timely diagnosis of neonatal sepsis, we will advance this technology to identify unique fungal, viral, and bacterial HRM signatures along with antibiotic resistance genes with an accuracy of 99-100% on minimal blood volume (1mL). Our aims are: Aim 1. Optimize and assess the U-dHRM platform for neonatal bacteremia diagnosis by expand our bacterial database (13 additional bacteria) to detect causes of >99% of neonatal bacterial infections, expand our antibiotic resistance gene database to include five clinically actionable genes, and assessing the performance of the system for bacteremia diagnosis in mock and clinical whole blood samples; Aim 2. Advance the U-dHRM platform for simultaneous detection of fungal and viral pathogens by upgrading our optical system to enable expansion to fungal and viral detection in a high-throughput format, multiplexing the assay to expand to viral and fungal pathogens causing >99% non-bacterial infections, and conducting analytical validation of the multiplexed platform using mock whole blood samples; and Aim 3. Advance the machine learning algorithm for detection of emerging pathogens by developing and integrating an anomaly detection algorithm for reporting emerging pathogens that are not included in our database and validating the algorithm using data generated in Aims 1 and 2. Thus, this proposal directly addresses the funding call by applying a multidisciplinary approach to overcome the biomedical challenge of rapidly diagnosis sepsis, a hidden public health disaster. Project Narrative Digital High Resolution Melting (dHRM) of DNA combined with machine learning creates unique “fingerprints"" for microbes and antibiotic resistance, allowing for faster and more precise detection and treatment of pathogen(s) causing sepsis. This project will advance and test the clinical performance of dHRM technology in the diagnosis of neonatal sepsis. Our goal is to rapidly and accurately identify pathogens and their resistance markers to facilitate accurate antimicrobial therapy, reducing antibiotic overuse in non-infected infants.",Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis,10151581,R01AI134982,"['Address', 'Adult', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Biological Assay', 'Birth Weight', 'Blood', 'Blood Volume', 'Blood specimen', 'Child', 'Clinical', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disasters', 'Dyes', 'Emerging Technologies', 'Exposure to', 'Fingerprint', 'Fluorescence', 'Funding', 'Genes', 'Genome', 'Genotype', 'Goals', 'Gold', 'Hour', 'Immune response', 'Individual', 'Infection', 'Machine Learning', 'Measures', 'Microbe', 'Modernization', 'Neonatal', 'Nucleotides', 'Optics', 'Organism', 'Patients', 'Performance', 'Predisposition', 'Public Health', 'RNA', 'Reaction', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Sampling', 'Sepsis', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tube', 'United States', 'Validation', 'Variant', 'Very Low Birth Weight Infant', 'Viral', 'Whole Blood', 'Woman', 'antimicrobial', 'base', 'circulating DNA', 'clinically actionable', 'clinically relevant', 'cost', 'detection limit', 'diagnosis standard', 'digital', 'early onset', 'interdisciplinary approach', 'intrapartum', 'machine learning algorithm', 'melting', 'microbial', 'neonatal sepsis', 'neonate', 'overtreatment', 'pathogen', 'pathogen genome', 'pathogen genomics', 'pathogenic fungus', 'pathogenic virus', 'point of care', 'premature', 'rapid diagnosis', 'resistance gene', 'sample collection', 'septic', 'therapy resistant', 'viral detection']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,469594
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"Multi-Task MR Simulation for Abdominal Radiation Treatment Planning The accuracy of radiation treatment planning (RTP) heavily influences the effectiveness of external beam radiotherapy (EBRT). Individualized RTP begins with a “simulation”, in which the patient in a treatment position is commonly scanned using computed tomography (CT) to define the treatment target and organs at risk (OARs). When soft-tissue contrast is inadequate to support accurate target and OAR delineation in CT based RTP, conservatively large treatment margins are used to avoid a geometric miss. The crude treatment prevents delivering sufficient radiation dose to the tumor without exceeding the tolerance of surrounding normal tissues. Magnetic resonance (MR) can be used as a simulation platform complementary to CT for improved soft-tissue conspicuity. Yet, such a complicated, costly and tedious multi-modal RTP workflow along with unavoidable systematic MR-CT co-registration errors has limited its applications in EBRT, especially at the abdominal site whereby anatomies are highly mobile. Over the past few years, there is a keen interest in the integration of MR alone into RTP and even the therapy workflow (i.e. MR-guided radiotherapy, MRgRT). The abdomen poses critical challenges to MR simulation. Current MR imaging sequences are suboptimal to produce motion-free images and resolve respiratory motion. MR data processing for abdominal RTP is underdeveloped. Contouring of target and OARs typically relies on manual, tedious procedures that are time-consuming and variation-prone. In this proposal, we will substantially improve the MR acquisition and automated multi-organ segmentation, so the potential of MR as a simulation modality can be fully unleashed for abdominal EBRT. Three specific aims will be completed. In Aim 1, we will develop and validate a standalone multi-task MR (MT-MR) sequence dedicated to abdominal MR simulation. In Aim 2, we will develop an MT-MR simulation based multi-organ auto- segmentation tool. In Aim 3, we will optimize a deep learning-based dose prediction model and assess the effectiveness of the MT-MR based RTP workflow in adaptive stereotactic body radiotherapy planning of pancreatic cancer patients. Successful completion of the project will significantly promote the clinical adoption of MR simulation for abdominal RTP, which will improve treatment precision and outcomes. Moreover, the developed techniques will open the door to future studies aiming at optimizations in both cancer diagnosis and radiotherapy. Imaging is essential for precise radiation treatment planning. MR based planning is challenging in the abdomen whereby anatomies are highly mobile. We will substantially improve the MR acquisition and automated multi- organ segmentation, so the potential of MR as an imaging-based planning modality can be fully unleashed for abdominal radiation treatment.",Multi-Task MR Simulation for Abdominal Radiation Treatment Planning,10331615,R01EB029088,"['3-Dimensional', 'Abdomen', 'Address', 'Adoption', 'Anatomy', 'Breathing', 'Clinical', 'Consumption', 'Data', 'Data Collection', 'Detection', 'Development', 'Dose', 'Effectiveness', 'Fatty acid glycerol esters', 'Future', 'Geometry', 'Goals', 'Image', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Modality', 'Motion', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pancreas', 'Patients', 'Phase', 'Positioning Attribute', 'Precision therapeutics', 'Procedures', 'Protocols documentation', 'Protons', 'Radiation Dose Unit', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Site', 'Solid', 'Spatial Distribution', 'Study Subject', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Tissues', 'Variant', 'Water', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'cancer diagnosis', 'cancer radiation therapy', 'computerized data processing', 'contrast imaging', 'cost', 'deep learning', 'density', 'experience', 'image processing', 'image reconstruction', 'improved', 'interest', 'learning strategy', 'multimodality', 'multitask', 'novel', 'pancreatic cancer patients', 'predictive modeling', 'prevent', 'respiratory', 'simulation', 'soft tissue', 'standard of care', 'success', 'tool', 'treatment planning', 'tumor']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,507076
"Nonlinear performance analysis and prediction for robust low dose lung CT 1 PROJECT SUMMARY / ABSTRACT  2 Nonlinear algorithms such as model-based reconstruction (MBR) and deep learning (DL) reconstruction have  3 sparked tremendous research interest in recent years. Compared to traditional linear approaches, the nonline-  4 arity of these algorithm transcends traditional signal-to-noise requirement and offer flexibility to draw information  5 from a variety of sources (e.g., statistical model, prior image, dictionary, training data). MBR has enabled numer-  6 ous advancements including low-dose CT and advanced scanning protocols. Deep learning algorithms are rap-  7 idly emerging and have demonstrated superior dose vs. image quality tradeoffs in research settings. However,  8 widespread clinical adoption of nonlinear algorithms has been impeded by the lack of a lack of systematic, quan-  9 titative methods for performance analysis. Nonlinear methods come with numerous dependencies on the imag- 10 ing techniques, the imaging target, and the prior information, and the data itself. The relationship between these 11 dependencies and image quality is often opaque. Furthermore, improper selection of algorithmic parameters can 12 lead to erroneous features (e.g., smaller lesions, texture) in the reconstruction. Therefore, methods to quantify 13 and predict performance permit efficient and quantifiable performance evaluation to provide the robust control 14 and understanding of imaging output necessary for reliable clinical application and regulatory oversight. 15 We propose to establish a robust, predictive framework for performance assessment and optimization that can 16 be generalized to any reconstruction method. We quantify performance in turns of the perturbation response and 17 covariance as a function of imaging techniques, system configurations, patient anatomy, and, importantly, the 18 perturbation itself. The perturbation response quantifies the appearance (e.g., biases, blurs, distortions), and, 19 together with the covariance, allows the computation of more complex metrics such as task-based performance 20 and radiomic measures including size, shape, and texture information. We illustrate utility of the approach in lung 21 imaging with the following specific aims: Aim 1: Develop a lesion library and generate perturbations encom- 22 passing clinically relevant features. We will extract lesions from public databases and develop methods lesion 23 emulation in for realistic CT simulation and physical data via 3D printing technology. Aim 2: Develop a gener- 24 alized prediction framework for perturbation response and covariance. Using analytical and neural network 25 modeling, we will establish a framework that predicts perturbation response and covariance across imaging 26 scenarios for classes of algorithms with increasing data-dependence including MBR with a Huber penalty, MBR 27 with dictionary regularization, and a deep learning reconstructor. Aim 3: Develop assessment and optimiza- 28 tion strategies to drive robust, low dose lung screening CT methods. We will optimize and adapt nonlinear 29 algorithms and protocols for lung cancer screening to achieve faithful representations of clinical features. This 30 work has the potential to drive much-needed quantitative assessment standards that directly relate image quality 31 to diagnostic performance and optimal strategies for robust, reliable clinical deployment of nonlinear algorithms. 32 PROJECT NARRATIVE Major research efforts have been devoted to the development of nonlinear reconstruction algorithms – from model-based reconstruction to deep learning, these algorithms have demonstrated many advantages such as improved image quality, reduced radiation dose, and additional diagnostic information that are not achievable with traditional linear reconstructions. However, only a disproportionately small number has reach the clinic due to the lack of a predictive image quality analysis framework to quantify diagnostic performance, control algorithm behavior, and ensure consistent performance for robust clinical deployment. The propose effort use a combination of analytic and machine learning approaches to drive much-needed quantitative assessment standards that directly relate image quality to diagnostic performance and establish optimal strategies for robust, reliable clinical deployment of nonlinear algorithms.",Nonlinear performance analysis and prediction for robust low dose lung CT,10121056,R01CA249538,"['3D Print', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Appearance', 'Beauty', 'Behavior', 'Biological Models', 'Clinic', 'Clinical', 'Complex', 'Data', 'Databases', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Dictionary', 'Digital Libraries', 'Dimensions', 'Dose', 'Ensure', 'Evaluation', 'Genes', 'Image', 'Image Analysis', 'Imaging Techniques', 'Lead', 'Lesion', 'Libraries', 'Lung', 'Lung CAT Scan', 'Lung nodule', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Nodule', 'Noise', 'Non-linear Models', 'Outcome', 'Output', 'Patients', 'Performance', 'Play', 'Predictive Analytics', 'Property', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Role', 'Sampling', 'Scanning', 'Scheme', 'Shapes', 'Signal Transduction', 'Source', 'Statistical Models', 'System', 'Techniques', 'Technology', 'Texture', 'Training', 'Transcend', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinical translation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'exhaustion', 'flexibility', 'imaging system', 'improved', 'insight', 'interest', 'low dose computed tomography', 'lung cancer screening', 'machine learning method', 'neural network', 'novel', 'predicting response', 'quantitative imaging', 'radiomics', 'reconstruction', 'response', 'screening', 'shape analysis', 'simulation', 'success', 'targeted imaging']",NCI,JOHNS HOPKINS UNIVERSITY,R01,2021,512567
"Integrate Dynamic System Model and Machine Learning for Calibration-Free Noninvasive ICP Project Summary  No clinical device exists for noninvasive intracranial pressure (nICP) assessment. Past attempts have focused on identifying ICP-related signals that are noninvasively measureable, but have done little to address the calibration problem. Without calibration, only ICP trending can be inferred at the best. However, noninvasive calibration is not trivial. A universal calibration will fail because individual patients require different calibration to obtain accurate results. On the other hand, the use of plain regression for individualized calibration is infeasible because ICP cannot be obtained noninvasively for a de novo patient to begin with.  Invasive ICP monitoring remains a standard of care and this can be leveraged to continuously grow a database of ICP, noninvasive signals, and different calibration equations, e.g., each built from a pair of invasive ICP and noninvasive signal in the database. Then nICP becomes feasible by selecting from a rich set of calibration equations the optimal choice for a de novo patient. In this project, we will pursue three aims that will lead to the development of an accurate noninvasive ICP system based on Transcranial Doppler. These aims are: 1) To implement and validate core algorithms needed for achieving accurate nICP; 2) To test if estimated nICP is sensitive to variations in ultrasound probe placement; 3) To test the generalizability of the proposed nICP approach.  Large epidemiologic surveys reveal that ICP is monitored in only about 58% of US patients when ICP monitoring is indicated. It is a smaller percentage (37%) in European patients and even fewer in developing countries. The proposed nICP approach does not have the high risks associated with invasive ICP, requires no onsite neurosurgical expertise, and can be economically deployed and readily practiced. Therefore, its potential impact is enormous. Project Narrative  No clinically accepted device exists for noninvasive intracranial pressure (ICP) assessment. This proposed project aims to complete the development and validation of a novel noninvasive ICP assessment approach. Large epidemiologic surveys reveal that ICP is monitored in only about 58% of US patients when ICP monitoring is indicated. It is a smaller percentage (37%) in European patients and even fewer in developing countries. The proposed nICP approach does not have the high risks associated with invasive ICP, requires no onsite neurosurgical expertise, and can be economically deployed and readily practiced. Therefore, its potential impact is enormous.",Integrate Dynamic System Model and Machine Learning for Calibration-Free Noninvasive ICP,10228768,R01NS106905,"['Address', 'Adherence', 'Adoption', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Biological Models', 'Blood Flow Velocity', 'Blood Pressure', 'Body mass index', 'Calibration', 'Cerebrovascular Circulation', 'Clinical', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Developing Countries', 'Development', 'Devices', 'Electrocardiogram', 'Ensure', 'Epidemiology', 'Equation', 'Europe', 'European', 'Fibrinogen', 'Gender', 'Intracranial Hypertension', 'Intracranial Pressure', 'Lead', 'Learning', 'Libraries', 'Machine Learning', 'Measurement', 'Measures', 'Modeling', 'Monitor', 'Morphology', 'Movement', 'Nature', 'Patients', 'Physiologic pulse', 'Research', 'Residual state', 'Secure', 'Signal Transduction', 'Stress Tests', 'Surveys', 'System', 'Temporal bone structure', 'Testing', 'Training', 'Transcranial Doppler Ultrasonography', 'Ultrasonography', 'Validation', 'Variant', 'base', 'dynamic system', 'high risk', 'indexing', 'individual patient', 'kernel methods', 'learning algorithm', 'middle cerebral artery', 'novel', 'standard of care', 'trend']",NINDS,DUKE UNIVERSITY,R01,2021,544156
"A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration PROJECT SUMMARY Age-related macular degeneration (AMD), in the dry or wet form, is the leading cause of vision loss in the developed countries. The Age-Related Eye Disease Study (AREDS) showed that specific antioxidant vitamin supplementation reduces the risk of progression from intermediate stages to late AMD and maintains visual acuity in approximately 25% of patients. While treatment of wet AMD with Intraocular injections can be effective in maintaining vision, such treatments are costly and may be associated with significant cardiovascular risks, or even progression of dry AMD. Hence, it is critical to identify patients at the earlier stages. Unfortunately, there is no effective, automated screening tool to accomplish this, and the patients themselves may be asymptomatic. The goal of this SBIR Direct-to-Phase II proposal is to provide such tool. We have demonstrated the feasibility of AMD screening software ‘iPredictTM’ by successfully identifying 98.1% of individuals with early or intermediate stage AMD. iPredictTM also successfully predicted which individuals would develop late AMD within one year with 87.8% accuracy and two years with 88.4% accuracy. iPredictTM has prototype components for image analysis and machine learning. We also developed a HIPAA compliant telemedicine platform which will enable iPredictTM to perform large-scale screening from remote and rural areas. In order to bring the product to market, these components need to be integrated and tested which is the aim of our proposed Direct-to-Phase II proposal. We aim to develop the finished product which will be ready for the market. We also aim to evaluate the efficacy of iPredictTM in a clinical setup. The AMD preventative market is estimated around $5.4 billion in the U.S. alone. iPredictTM will capture the major market share with its best accuracy and be the first prediction tool for AMD. We aim to commercialize iPredictTM for the screening and prevention of AMD, saving millions of citizens from blindness and reduced quality of life. With iPredictTM’s improvements in speed of delivery, cost of care, and ease of access, the product will be a significant addition to the healthcare system. The iPredictTM’s telemedicine platform will allow large-scale screening from remote/rural areas, primary care clinics, optometry offices and ophthalmology clinics. PROJECT NARRATIVE Age-related macular degeneration (AMD) in its late forms, “dry” or “wet”, is the leading cause of blindness in developed countries. Early intervention and therapy can significantly reduce the progression of early to late AMD. Hence, the identification of patients with early AMD and referral to an ophthalmologist is critically needed to help prevent vision loss. To achieve this goal, we propose to develop an automated screening and prediction system that can be widely deployed to identify these individuals at risk of vision loss.",A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration,10172914,R44EY031202,"['Affect', 'Age', 'Age related macular degeneration', 'American', 'Antioxidants', 'Blindness', 'Categories', 'Clinic', 'Clinical', 'Clinics and Hospitals', 'Code', 'Color', 'Computer software', 'Counseling', 'Data', 'Data Set', 'Databases', 'Developed Countries', 'Devices', 'Diagnosis', 'Drusen', 'Ear', 'Early Intervention', 'Evaluation', 'Eye', 'Eye diseases', 'Feasibility Studies', 'Fees', 'Goals', 'Health Insurance Portability and Accountability Act', 'Healthcare Systems', 'Image', 'Image Analysis', 'Incentives', 'Individual', 'Injections', 'Intervention', 'Java', 'Lasers', 'Learning Module', 'Machine Learning', 'Manuals', 'Methods', 'Minerals', 'Modeling', 'New York', 'Nonexudative age-related macular degeneration', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patients', 'Phase', 'Prevention', 'Prevention strategy', 'Primary Health Care', 'Provider', 'Pythons', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Sales', 'Savings', 'Screening procedure', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Smoking', 'Specialist', 'Speed', 'Sun Exposure', 'Supplementation', 'System', 'Telemedicine', 'Testing', 'Therapeutic Intervention', 'Time', 'Trademark', 'Treatment Cost', 'Validation', 'Vision', 'Visit', 'Visual Acuity', 'Vitamins', 'age related', 'base', 'biobank', 'cardiovascular risk factor', 'care costs', 'checkup examination', 'commercial application', 'convolutional neural network', 'cost', 'deep learning', 'follow-up', 'improved', 'photobiomodulation', 'prediction algorithm', 'predictive modeling', 'prevent', 'prognostic', 'programs', 'prospective', 'prototype', 'remote screening', 'research clinical testing', 'retinal imaging', 'rural area', 'screening', 'sociodemographic factors', 'software as a service', 'success', 'tool', 'user-friendly']",NEI,"IHEALTHSCREEN, INC.",R44,2021,545819
"Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues Summary Fast, accurate, and scalable testing has been recognized unanimously as crucial for mitigating the impact of COVID-19 and future pandemics. We propose a technology that allows rapid (~2 minutes) testing for SARS CoV-2. Our technology combines novel label-free imaging and dedicated deep-learning algorithms to detect and classify viral populations in exhaled air. If successful, this project will result in a device based on quantitative phase imaging and integrated AI tools, which will detect the unlabeled virus acquired by the patient’s breath condensed on a microscope slide. Toward this goal, we will advance Spatial Light Interference Microscopy (SLIM), an ultrasensitive label-free imaging technique, proven to measure structures down to the sub-nanometer scale. SLIM was developed in the PI’s Lab at UIUC, its original publication received 490 citations to date, and has been commercialized by Phi Optics (Research Park, UIUC), with sales across the world in both academia and industry. Applying the computed fluorescence maps back to the QPI data, we propose to measure nanoscale features of viral particles, with high specificity, minimal preparation time, and independent of clinical infrastructure. As a result, the new technology will eventually be ideal for point-of-care settings, surveillance screening and as a home monitoring device. We anticipate that our approach will be scalable to other viruses, with new imaging and training data. Narrative We propose a breath test using label-free imaging and AI: an individual exhales on a microscope slide, which is fed into a SLIM microscope equipped with a computer that runs deep-learning pre-trained algorithms for SARS CoV-2 identification. The result is displayed in real time, with the entire procedure requiring < 2min.",Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues,10249738,R01CA238191,"['2019-nCoV', 'Academia', 'Air', 'Artificial Intelligence', 'Back', 'Bedside Testings', 'Biology', 'Breath Tests', 'COVID-19', 'COVID-19 testing', 'Cancer Prognosis', 'Chemicals', 'Classification', 'Clinical', 'Clinical Microbiology', 'Computer software', 'Computers', 'Data', 'Devices', 'Exhalation', 'Fluorescence', 'Fluorescence Microscopy', 'Future', 'Glass', 'Goals', 'Histopathology', 'Home environment', 'Image', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Industry', 'Influenza', 'Infrastructure', 'Interference Microscopy', 'Label', 'Light', 'Maps', 'Measures', 'Microscope', 'Modification', 'Morphologic artifacts', 'Nature', 'Optics', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Phototoxicity', 'Population', 'Preparation', 'Procedures', 'Publications', 'Research', 'Running', 'Sales', 'Slide', 'Specificity', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Tissue Stains', 'Training', 'Viral', 'Virus', 'Virus Diseases', 'algorithm training', 'base', 'clinical infrastructure', 'coronavirus disease', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'imaging system', 'instrument', 'monitoring device', 'nanoscale', 'new technology', 'novel', 'operation', 'pandemic disease', 'particle', 'point of care', 'prototype', 'screening', 'tool']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2021,576268
"Learning to Predict Delayed Cerebral Ischemia with Novel Continuous Cerebral Arterial State Index Project Summary  Delayed cerebral ischemia (DCI) is the most devastating complication after aneurysmal subarachnoid hemorrhage (aSAH) and has an incidence rate of 30%. Current practice relies on intermittent assessment of neurological status and daily cerebral blood flow velocity (CBFV) by Transcranial Doppler ultrasound (TCD) to guide medical management to prevent DCI. Only after medical management fails, is endovascular treatment (EVT) including intraarterial vasodilator infusion and/or intracranial angioplasty initiated. This reactive practice does not account for early predictors of DCI and may miss the optimal EVT window at an early stage of DCI development before symptoms or severe deviations from normal hemodynamics. The goal of this project is to develop algorithms to predict DCI and related targets at an early stage in their development. An accurate prediction of DCI will enable a more proactive strategy to prevent and treat the underlying cause of DCI.  The following three aims will be pursued towards the goal of the project: 1) Develop aSAH-specific intracranial pressure (ICP) pulse-based cerebral arterial state index; 2) Develop and validate predictive models of targets related to delayed cerebral ischemia after aSAH; 3) Conduct a prospective institution- specific adaption and validation of the developed models.  Our DCI predictive algorithms only need data available in current clinical practice hence they can be readily adopted. If validated, these algorithms will enable clinicians to monitor risk of DCI continuously and to proactively deliver appropriate treatment. The proposed prospective study of algorithm implementation and adaptation will well prepare future clinical trials to test the efficacy of algorithm-informed interventions. Project Narrative  Delayed cerebral ischemia (DCI) is a devastating complication after aneurysmal subarachnoid hemorrhage (aSAH) and has an incidence rate of 30%. Current practice relies on intermittent assessment of neurological status and daily cerebral blood flow velocity (CBFV) by Transcranial Doppler ultrasound (TCD) to guide medical management to prevent DCI. The goal of this project is to develop algorithms to predict DCI and other related targets at an early stage in their development to enable a more proactive strategy to prevent and treat the underlying cause of DCI.",Learning to Predict Delayed Cerebral Ischemia with Novel Continuous Cerebral Arterial State Index,10251348,R01NS113541,"['Acute', 'Adopted', 'Algorithms', 'Aneurysmal Subarachnoid Hemorrhages', 'Angioplasty', 'Appearance', 'Area', 'Blood Flow Velocity', 'Cerebral Ischemia', 'Cerebral perfusion pressure', 'Cerebrovascular Circulation', 'Cerebrum', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Complication', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Diagnosis', 'Dilatation - action', 'Distal', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Event', 'Future', 'Goals', 'Hydrocephalus', 'Incidence', 'Individual', 'Infusion procedures', 'Injury', 'Institution', 'Intervention', 'Intracranial Pressure', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Modeling', 'Monitor', 'Morphology', 'Nature', 'Neurologic', 'Neurological status', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Procedures', 'Process', 'Prospective Studies', 'Pulse Pressure', 'Recurrence', 'Reproducibility', 'Research', 'Risk', 'Shapes', 'Signal Transduction', 'Source', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Training', 'Transcranial Doppler Ultrasonography', 'Validation', 'Vasodilator Agents', 'base', 'clinical practice', 'constriction', 'data streams', 'diagnostic accuracy', 'efficacy testing', 'electronic data', 'hemodynamics', 'improved', 'indexing', 'machine learning algorithm', 'novel', 'prediction algorithm', 'predictive modeling', 'prevent', 'prospective', 'recurrent neural network', 'relating to nervous system', 'temporal measurement', 'vector']",NINDS,DUKE UNIVERSITY,R01,2021,582524
"Shape up! Kids Project Summary/Abstract Of all markers of pediatric health, the most intuitive is body shape. Human and animal studies indicate that weight loss/gain correlates closely with increasing/decreasing insulin sensitivity, respectively. Anthropometry and regional composition measures such as waist circumference, waist to hip ratio (WHR), and visceral adipose tissue area are better predictors of obesity-related diseases and mortality risk than pediatric body mass index Z-score. Dual-energy X-ray absorptiometry can quantify regional adiposity in more detail than these measures but is underutilized for many reasons including the sensitivity to children to ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments in optical technology to better describe phenotypes of pediatric body shape and its relation to metabolic risks (obesity, “failure to thrive”) and bone density and size. If successful, sophisticated obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment technology. The long term goal of the Shape Up! Kids Study is 1) to provide pediatric phenotype descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, muscle mass, lean mass, and percent fat) and bone mineral density (BMD) over a wide range of ages (5 to 18 years), weights and heights, stratified by sex, and ethnicity. Our central hypothesis is that optical estimates with shape classification of soft tissue composition and bone density better predict fracture and metabolic risk factors than anthropometry (WC, WHR, and BM) alone. The Investigators will highly leverage existing data from the National Health and Nutrition Examination Survey and Bone Mineral Density in Children Study. Our specific aims are: 1) Identify the unique associations of body shape to body composition and bone density indices in a pediatric population that represents the variance found in the US population, 2) Describe the precision and accuracy of optical scans to monitor change in body composition, bone density, 3) Estimate the level of association of optical scans to common health indicators including metabolic risk factors. Our exploratory aim is to investigate holistic, high-resolution descriptors of 3D body shape as direct predictors of body composition and metabolic risk using statistical shape models and Latent Class Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self-assessment technologies that are capable of representing over 95% of the shape variance in the US pediatric population, and to define how these models relate to important metabolic status indicators. The positive impact of these outcomes will be the immediate applicability to other researcher studies and clinicians using the automated tools and models developed here for 3D optical images. PROJECT NARRATIVE  The proposed research is relevant to public health because they have the potential to provide a better understanding of what children are at high risk of metabolic consequences of obesity. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults, and are becoming epidemic in children as well. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Shape up! Kids,10109111,R01DK111698,"['3-Dimensional', 'Adipose tissue', 'Adult', 'Age', 'Algorithms', 'Animals', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Surface', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Bone Density', 'Child', 'Childhood', 'Classification', 'Clinical', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Epidemiology', 'Ethnic Origin', 'Failure to Thrive', 'Fatty acid glycerol esters', 'Fracture', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Liver', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'Muscle', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Pediatric Radiology', 'Personal Satisfaction', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Factors', 'Safety', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Visceral', 'Visceral fat', 'Waist-Hip Ratio', 'Weight', 'bone', 'clinical practice', 'cost', 'disorder prevention', 'disorder risk', 'handheld mobile device', 'health assessment', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolomics', 'mortality', 'mortality risk', 'muscle form', 'optical imaging', 'predictive modeling', 'sensor', 'sex', 'soft tissue', 'subcutaneous', 'tool', 'waist circumference']",NIDDK,UNIVERSITY OF HAWAII AT MANOA,R01,2021,582917
"Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients ABSTRACT The prevalence of obesity in the United States has risen to record levels over the past 40 years, putting strain on the healthcare system and creating difficult challenges for medical imaging. We propose to overcome the challenges that obesity poses to ultrasound imaging by (1) developing novel image-quality improvement techniques, and (2) implementing them on pulse-echo ultrasound imaging systems to yield high-quality images of the liver. Ultrasound imaging is uniquely affected by the presence of additional connective tissue and thick subcutaneous fat layers in overweight and obese patients; these additional subcutaneous layers greatly exacerbate reverberation and phase-aberration of the acoustic wave, leading to high levels of clutter, degraded resolution, and overall poor-quality ultrasound images. Our proposed methods will determine the local speed-of-sound in abdominal tissue layers and use this information to accomplish distributed phase-aberration correction. We also apply machine learning techniques to model and suppress the effects of reverberation clutter and speckle noise. The combination of these techniques is expected to achieve significant improvements in liver image quality. These image-quality improvement methods will be implemented on a real-time ultrasound scanner and will be evaluated in clinical imaging tasks of overweight and obese patients undergoing ultrasound surveillance of hepatocellular carcinoma. Successful development of the proposed technology will not only enable high-quality ultrasound imaging of the liver in otherwise difficult-to-image overweight and obese patients, but also facilitate improved image quality across nearly all ultrasound imaging applications, for all populations. NARRATIVE This proposal aims to develop and test several new techniques to overcome the current limitations of ultrasound to make high-quality images in overweight and obese individuals. These novel ultrasound techniques will be initially applied to improve liver imaging in overweight and obese patients in a pilot study, though the benefits of this new high-quality imaging technology will extend to all other areas of clinical ultrasound imaging.",Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients,10236260,R01EB027100,"['Abdomen', 'Acoustics', 'Affect', 'American', 'Architecture', 'Area', 'Attenuated', 'Cardiac', 'Cirrhosis', 'Clinical', 'Computer software', 'Connective Tissue', 'Data', 'Development', 'Diffuse', 'Disease', 'Fatty acid glycerol esters', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Image', 'Imaging technology', 'Lesion', 'Liver', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Noise', 'Obesity', 'Output', 'Overweight', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Resolution', 'Risk Factors', 'Signal Transduction', 'Source', 'Speed', 'Subcutaneous Tissue', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thyroid Gland', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Weight', 'clinical imaging', 'elastography', 'epidemiology study', 'fetal', 'high body mass index', 'imaging system', 'improved', 'in vivo', 'liver imaging', 'neural network', 'novel', 'obese patients', 'obese person', 'patient population', 'prototype', 'radio frequency', 'simulation', 'sound', 'subcutaneous']",NIBIB,STANFORD UNIVERSITY,R01,2021,585234
"Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo 1 Dermatologists rely on visual (clinical widefield) and dermoscopic examination of skin lesions to guide the need  2 for biopsy. With this approach, sensitivity is high, but specificity tends to be quite variable and lower, resulting  3 in millions of biopsies of benign lesions every year. To improve specificity, several optical technologies are  4 being developed to noninvasively detect skin cancer. Of these, reflectance confocal microscopy (RCM) is the  5 furthest advanced in clinical utility, proven for diagnosing skin cancers with high sensitivity and specificity.  6 RCM imaging, guided by dermoscopy, detects skin cancers with 2 times superior specificity, and reduces the  7 benign-to-malignant biopsy rate by 2 times, compared to that with dermoscopy alone. In 2016, the Centers for  8 Medicare and Medicaid Services granted current procedural terminology (CPT) reimbursement codes for RCM  9 imaging of skin. RCM imaging combined with dermoscopy is now advancing into clinical practice, sparing pa- 10 tients from unnecessary biopsies of benign lesions. However, toward widespread acceptance and adoption, a 11 key challenge is that clinical widefield examination, dermoscopy and RCM imaging are currently performed as 12 three separate procedures with separate devices. Clinicians do not precisely know the location of RCM imag- 13 es relative to the surrounding contextual lesion morphology that is seen with clinical widefield examination and 14 dermoscopy, resulting in lower and more variable diagnostic accuracy (particularly, sensitivity, positive and 15 negative predictive values). We propose a novel solution: (i) a new objective lens with an integrated micro- 16 camera, to deliver a concurrent widefield image of the skin surface surrounding the location of RCM imaging; 17 (ii) a new software algorithm for widefield image-based tracking of the location of RCM images within a dermoscopic 18 field of view; (iii) a new diagnostic approach that will proactively use widefield imaging to locate RCM images in 19 dermoscopic images. We intend to deliver this integrated widefield clinical, dermoscopic and RCM imaging ap- 20 proach into the clinic, toward a new standard for more accurate, consistent and faster RCM imaging to guide 21 patient care. Preliminary studies with a “mock” objective lens and micro-camera on a bench-top set-up 22 demonstrated excellent optical sectioning (~2 µm) and resolution (~1 µm) for RCM imaging, and accurate and 23 repeatable location of RCM fields-of-view within the widefield image. RCM images showed excellent cellular 24 and morphologic detail in vivo. Our specific aims are (1) to develop a handheld reflectance confocal micro- 25 scope with integrated widefield camera; (2) to develop image processing algorithms for real-time widefield im- 26 aging-guided tracking of RCM image locations within dermoscopic fields; (3) to test and validate performance 27 on 100 patients. Although our proposition is for skin lesions, the research will surely have wider impact for 28 imaging in other settings, particularly, with miniaturized confocal microscopes and endoscopes, which have 29 very small fields-of-view. We are a highly synergistic team from Montana State University, Memorial Sloan 30 Kettering Cancer Center, Northeastern University and Caliber Imaging and Diagnostics (formerly, Lucid Inc.). RELEVANCE TO PUBLIC HEALTH Clinical examination and dermoscopy combined with reflectance confocal microscopy (RCM) imaging is a newly emerging optical imaging procedure that can noninvasively guide diagnosis of skin cancers, and reduce the need for biopsy. However, clinical examination, dermoscopy and RCM imaging are currently performed as three separate procedures with separate devices, limiting effectiveness and impact. We propose a device to combine the three into a single procedure, which will help dermatologists and patients by making the skin examinations quicker, more accurate and more consistent, expanding the impact of this proven approach.",Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo,10127641,R01EB028752,"['Address', 'Adoption', 'Affordable Care Act', 'Aging', 'Algorithmic Software', 'Algorithms', 'Benign', 'Biopsy', 'Caliber', 'Cancer Center', 'Categories', 'Cellular Morphology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Current Procedural Terminology', 'Dermatologist', 'Dermatology', 'Dermis', 'Dermoscopy', 'Devices', 'Diagnosis', 'Diagnostic', 'Drops', 'Effectiveness', 'Endoscopes', 'Engineering', 'Epidermis', 'Grant', 'Head and neck structure', 'Image', 'Imaging Techniques', 'Lesion', 'Lesion by Morphology', 'Letters', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medicaid services', 'Medicare/Medicaid', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopic', 'Montana', 'Morphology', 'Optics', 'Oral', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sensitivity and Specificity', 'Site', 'Skin', 'Skin Cancer', 'Specificity', 'Surface', 'Technology', 'Testing', 'Time', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Visual', 'base', 'blind', 'cancer diagnosis', 'clinical examination', 'clinical practice', 'cost', 'design', 'design and construction', 'diagnostic accuracy', 'gastrointestinal', 'image guided', 'image processing', 'image registration', 'improved', 'in vivo', 'innovation', 'instrument', 'instrumentation', 'interest', 'lens', 'medical specialties', 'microscopic imaging', 'miniaturize', 'novel', 'novel diagnostics', 'optical imaging', 'prospective test', 'reflectance confocal microscopy', 'response', 'routine practice', 'skin lesion', 'volunteer']",NIBIB,MONTANA STATE UNIVERSITY - BOZEMAN,R01,2021,589357
"Wearable Multi-modality Cuffless Blood Pressure Monitoring Abstract Continuous blood pressure (BP) is one of the most critical monitoring parameters during anesthesia, surgery and in intensive care units (ICU). Both hypotension and hypertension can impair the function of vital organs (e.g. brain, heart and kidneys), and intraoperative hypotension is associated with postoperative mortality, which makes it important to detect BP changes as quickly as possible to prompt timely intervention or therapy. However, the current gold standard technology for BP monitoring, an invasive arterial line (a-line), causes patient suffering (physical pain) and increases the risk of infection. In the United States, about 80,000 blood stream infections caused by an arterial catheter are reported annually. Due to the inherent risks associated with a-line, it is used only for clinically indicated high risk surgeries or ICU patients. As a result of the a-line risks and discomforts, even though more than 300 million surgeries are performed worldwide each year, only a small portion receive continuous BP monitoring. In addition, although vital sign (ECG, pulse oximetry, BP etc) monitoring is routine in surgical rooms and ICUs, currently most monitoring devices are fixed in individual rooms, which result in gaps in patient monitoring, accidents during patient transport process, and extra work to disconnect and reconnect sensors when leaving and entering a new facility. Seamless “continuum of care” monitoring—for instance from surgical room to ICUs, including transport in between and without reconnecting sensors—is on top of the wish list by clinician. In recent years, efforts have been made to develop portable ECG monitors and “mobile ICUs”; however so far, no continuous and seamless BP monitoring has been achieved. This proposal fully leverages the outcomes from the related R21 (EB022271) project. We will develop novel machine learning and deep learning based data fusion algorithms to use existing vital signs for continuous BP monitoring, then integrate them with our unique wearable patient monitoring system to form a novel perioperative patient monitoring system. We will test the system’s performance against gold standard a- line and Finapres BP technologies. to develop a fully functional technology for noninvasive, continuous, and seamless BP monitoring. We will also develop a public database for future BP technology development. The proposed multimodality algorithms, seamless BP monitoring system and PhysioNet database will provide major steps forward to meet the clinical need for noninvasive continuous BP monitoring. Project Narrative Continuous blood pressure (BP) is one of the most critical monitoring parameters during anesthesia, surgery and in intensive care units (ICU). However, the current gold standard technology for BP monitoring, the invasive arterial line (a-line), causes patient suffering (physical pain) and increases the risk of infection, and current noninvasive BP technologies have poor stability. In this project we will develop novel algorithms and hardware with improved stability to meet the clinical need for noninvasive continuous BP monitoring,",Wearable Multi-modality Cuffless Blood Pressure Monitoring,10121622,R01EB027122,"['Academia', 'Accidents', 'Algorithms', 'Anesthesia procedures', 'Annual Reports', 'Arterial Lines', 'Benchmarking', 'Blood', 'Blood Pressure', 'Blood Pressure Monitors', 'Brain', 'Cardiac Surgery procedures', 'Catheters', 'Clinical', 'Continuity of Patient Care', 'Data', 'Databases', 'Development', 'Electrocardiogram', 'Ensure', 'Evaluation', 'Finite Element Analysis', 'Future', 'Goals', 'Gold', 'Heart', 'Hypertension', 'Hypotension', 'Impairment', 'Individual', 'Industry', 'Infection', 'Intensive Care Units', 'Intervention', 'Investigation', 'Kidney', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Operative Surgical Procedures', 'Organ', 'Outcome', 'Pain', 'Patient Monitoring', 'Patient Monitoring System', 'Patients', 'Performance', 'Perioperative', 'Physiologic pulse', 'Postoperative Period', 'Process', 'Pulse Oximetry', 'Risk', 'Signal Transduction', 'Site', 'Stream', 'System', 'Technology', 'Temporal Arteries', 'Testing', 'Time', 'Transport Process', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Work', 'base', 'data format', 'data fusion', 'data privacy', 'data sharing', 'deep learning', 'experience', 'feature extraction', 'high risk', 'improved', 'indexing', 'infection risk', 'light weight', 'monitoring device', 'mortality', 'multimodality', 'novel', 'patient privacy', 'portability', 'privacy protection', 'recurrent neural network', 'sensor', 'surgical risk', 'technology development', 'tonometry']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,595683
"Quantification of Liver Fibrosis with MRI and Deep Learning Project Summary/Abstract  Chronic liver disease (CLD) is a common cause of morbidity and mortality in the U.S. and throughout the world. In 2017, CLD had an age-adjusted death rate of 10.9/100,000 total population and an estimated lifetime cost of fatty liver disease alone in the U.S. of ~$222 billion. Liver fibrosis (LF) is the most important and only histologic feature known to predict outcomes from CLD. The current standard for assessing LF is biopsy, which is costly, prone to sampling error, and invasive with poor patient acceptance. Thus, there is an urgent unmet need for noninvasive, highly accurate and precise diagnostic technologies for detection and quantification of LF. Our overarching objective is to apply Deep Learning (DL) methods using conventional non-elastographic magnetic resonance (MR) images, MR elastography (MRE), and clinical data to accurately detect and measure LF in children and adults with CLD, using biopsy-derived histologic data as the reference standard. In this project, we will dedicate our efforts to accomplishing the following specific aims. In Aim 1, we will develop and validate a DL framework to accurately segment liver and spleen in order to extract radiomic (gray-scale signal intensity distribution, shape and morphology, volumetry, and inter-voxel signal intensity pattern and texture) and deep features (complex abstractions of patterns non-linearly constructed throughout the transformation estimated by data-driven DL training procedures) from conventional multiparametric MRI. These features allow detection of liver and spleen structural abnormalities/tissue aberrations. In Aim 2, we will develop and validate an “ensemble” DL model (LFNet) to predict biopsy-derived LF stage and LF percentage using the integration of conventional multimodal MRI radiomic and deep features, MRE data, as well as clinical data. In Aim 3, we will develop and validate a DL model (LSNet) to quantify MRE-derived liver stiffness (LS) using conventional multiparametric MRI radiomic and deep features as well as clinical data. The proposed models will help physicians to more accurately detect and follow CLD by 1) quantifying LS from conventional MR imaging without the need for MRE; and, more importantly, 2) predicting histologic LF stage and LF percentage without the need for biopsy, while avoiding inter- radiologist variability, reducing radiologist workload, and ultimately reducing healthcare costs. We will validate the models using both internal and independent external data from various scanners and sites. The techniques we develop are expected to improve medical diagnosis and prognostication in the same way as DL has revolutionized other fields. This study will significantly impact public health because it will allow physicians and researchers to more accurately diagnose and quantify CLD and LF as well as permit more frequent assessments in a noninvasive, patient-centric manner, thus potentially improving patient outcomes while lowering healthcare costs. The techniques we develop also can be readily extended for the prediction of other important liver-related clinical outcomes, including impending complications such as portal hypertension, time to liver transplant/transplant listing, and mortality risk, among others. Project Narrative  Chronic liver disease (CLD) is a common cause of illness and death worldwide, and it is a significant healthcare and financial burden. Liver fibrosis (LF) is a measurable feature of CLD that is important to assess the severity of disease, evaluate for progression and therapy response, and predict outcomes. We propose to apply artificial intelligence methods to noninvasive conventional magnetic resonance images and readily- available clinical data for accurate detection and quantification of LF, thus significantly impacting public health by facilitating personalized therapies without the need for liver biopsy, improved outcomes, and lower healthcare costs.",Quantification of Liver Fibrosis with MRI and Deep Learning,10096229,R01EB030582,"['Address', 'Adult', 'Age', 'American', 'Appearance', 'Artificial Intelligence', 'Bilirubin', 'Biopsy', 'Body mass index', 'Cessation of life', 'Characteristics', 'Child', 'Childhood', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Complex', 'Computer-Assisted Diagnosis', 'Crowding', 'Data', 'Data Set', 'Databases', 'Death Rate', 'Decision Making', 'Descriptor', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Evaluation', 'Eye', 'Fatty Liver', 'Financial Hardship', 'Goals', 'Health Care Costs', 'Health Expenditures', 'Healthcare', 'Histologic', 'Human', 'Image', 'Individual', 'Institution', 'Laboratories', 'Length of Stay', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Magnetic Resonance Elastography', 'Magnetic Resonance Imaging', 'Maps', 'Mathematics', 'Measurable', 'Measures', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Population', 'Portal Hypertension', 'Procedures', 'Property', 'Public Health', 'Reference Standards', 'Research', 'Research Personnel', 'Residual state', 'Risk', 'Risk Factors', 'Running', 'Sampling Errors', 'Series', 'Severity of illness', 'Shapes', 'Signal Transduction', 'Site', 'Spleen', 'Staging', 'Structural defect', 'Techniques', 'Testing', 'Texture', 'Time', 'Tissues', 'Training', 'Transplantation', 'Vendor', 'Viral hepatitis', 'Visual', 'Workload', 'accurate diagnosis', 'accurate diagnostics', 'chronic liver disease', 'classification algorithm', 'clinical risk', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'diagnostic technologies', 'elastography', 'hospital readmission', 'hospitalization rates', 'improved', 'improved outcome', 'learning strategy', 'life time cost', 'liver biopsy', 'liver transplantation', 'mortality', 'mortality risk', 'multimodality', 'multitask', 'non-linear transformation', 'outcome prediction', 'personalized diagnostics', 'personalized medicine', 'predictive modeling', 'prognostic', 'radiologist', 'radiomics', 'response', 'sex']",NIBIB,CINCINNATI CHILDRENS HOSP MED CTR,R01,2021,628266
"Application of Advanced Quantitative Methods to Schizophrenia Research PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found a decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Prefrontal white matter is among the areas usually involved. Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities, suggesting that abnormalities causing diminished FA are subtle, and that postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a FIC/NIMH collaboration with the Macedonian Academy of Sciences and Arts, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the spatial orientation of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high- resolution images of Bielschowsky stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This technique yields clear images of individual axons that can be traced and measured in 3 dimensions. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin- related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models in three multi-omics data fusion approaches to combine different types of high-dimensional data, including those produced by Aims 1 and 2, with known structural properties of axons and myelin in white matter, in order to build a model or detect novel dependencies of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. NARRATIVE Our ongoing research in North Macedonia and at Columbia University / New York State Psychiatric Institute has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale to study schizophrenia.",Application of Advanced Quantitative Methods to Schizophrenia Research,10099068,R01MH125030,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Antibodies', 'Architecture', 'Area', 'Arts', 'Autopsy', 'Axon', 'Biochemical', 'Biochemistry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Clinical', 'Collaborations', 'Collection', 'Confocal Microscopy', 'Consensus', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Electron Microscope', 'Electron Microscopy', 'Electrons', 'Evaluation', 'Face', 'Fiber', 'Forensic Medicine', 'Genetic Transcription', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Individual', 'Institutes', 'Interviewer', 'Knowledge', 'Label', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofibrillary Tangles', 'Neurofilament Proteins', 'New York', 'Oligodendroglia', 'Online Systems', 'Optic Nerve', 'Paraffin', 'Pathologist', 'Pharmaceutical Preparations', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Psychiatrist', 'Psychologist', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Schizophrenia', 'Science', 'Shotguns', 'Silver Staining', 'Space Perception', 'Stains', 'Structure', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Toxicology', 'Training', 'Transcript', 'Triad Acrylic Resin', 'Universities', 'Variant', 'Visualization', 'base', 'cognitive function', 'cohort', 'data archive', 'data fusion', 'deep neural network', 'density', 'design', 'diffusion anisotropy', 'high resolution imaging', 'histological studies', 'imaging study', 'innovation', 'instrument', 'interest', 'microscopic imaging', 'multidimensional data', 'multiple omics', 'network models', 'novel', 'precursor cell', 'psychologic', 'reconstruction', 'sex', 'symposium', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2021,641403
"Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance PROGRAM SUMMARY Radiological imaging is often the first step of the diagnostic pathway for many devastating diseases; thus, an erroneous assessment of “normal” can lead to death. Whereas a grayscale object in an image can be described by its first-order image statistics—such as contrast, spatial frequency, position, entropy, and orientation—none of these dimensions, by itself, indicates abnormal vs normal radiological findings. We are a highly diverse team proposing an empirical approach to determine the mixtures of the first-order statistics—the “visual textures”— that radiology experts explicitly and implicitly use to identify the locations of potential abnormalities in medical images. Our innovative approach does not rely on assumptions about which textures may or may not be im- portant to abnormality detection. Instead, we will track the oculomotor behavior of expert radiologists to deter- mine their conscious and unconscious targeting choices, and thus ascertain which textures are empirically in- formative. The ability of expert radiologists to rapidly find abnormalities suggests that they may be able to first identify them in their retinal periphery. Peripheral visual analysis skills are therefore potentially critical to radio- logic performance, despite being understudied. We will measure these skills and leverage the results to develop perceptual learning heuristics to improve peripheral abnormality texture detection. By comparing novices to ex- perts we will determine whether the first are inexpert due to a lack of sensitivity to diagnostically relevant textures (texture informativeness), or to a lack of knowledge about which textures are abnormal, or to a combined lack of both sensitivity and knowledge. Radiology also requires the acquisition of oculomotor skills through practice and optimization. Radiologic expertise thus changes the oculomotor system in predictable and detectable ways, in much the same way that an athlete’s body and brain change as a function of expertise acquisition in their sport. We will therefore analyze both the consistency between experts’ fixation choices in medical images, and the eye movement performance characteristics of experts vs novice radiologists, to create an objective oculomotor bi- omarker of radiological expertise. The differences between novices and experts will train a deep learning (DL) system, which will have human visual and oculomotor performance characteristics. Training the DL with the abnormalities identified by a panel of expert radiologists will allow it to pinpoint the possible solutions in the manner of a simulated human radiologist performing at peak accuracy, precision, and speed. The resulting rank- ordered list of possible optimal and suboptimal image-reading strategies will serve as a benchmarking tool to quantify the performance of actual clinicians and residents who read the same images, rested vs fatigued. Meas- uring the effects of both training and fatigue on radiology expertise will be a major interdisciplinary cross-cutting advance in performance assessment. Our proposal to quantify fatigue in terms of erosion of expertise represents a transformational advance towards objective fitness-for-duty and expertise measures in medicine and beyond. PROJECT NARRATIVE There are 25-32 million perceptual errors in radiological case studies worldwide each year, contributing to med- ical error, the third most common cause of death in the US. We seek to reduce detection errors in radiology with four innovations: (1) we will empirically and objectively determine the visual textures used by expert radiologists to identify abnormalities within medical images; (2) we will determine the ways in which expert radiologists use their eyes, and especially their peripheral vision, to scan images and target informative regions; (3) we will de- velop a perceptual learning paradigm to optimally train residents in both texture perception and oculomotor per- formance domains; and (4) we will construct a deep learning model bestowed with simulated human visual and oculomotor capabilities, to create a normative model of human radiological expertise. The combined results from these studies will quantify peak expert performance and be employed to track and enhance individual expertise acquisition during radiology training; thus, the proposed research will help reduce medical error and moreover provide objective fitness-for-duty measurement tools—based on quantified biomarkers—to evaluate and ame- liorate the effects of fatigue on radiologic performance.",Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance,10220201,R01CA258021,"['Assessment tool', 'Benchmarking', 'Biological Markers', 'Brain', 'COVID-19', 'Cancer Detection', 'Case Study', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical/Radiologic', 'Collection', 'Conscious', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Diagnostic', 'Dimensions', 'Disease', 'Elements', 'Ensure', 'Entropy', 'Exposure to', 'Eye', 'Eye Movements', 'Fatigue', 'Film', 'Foundations', 'Frequencies', 'Human', 'Image', 'Incentives', 'Individual', 'Instruction', 'Knowledge', 'Lead', 'Learning', 'Location', 'Measurement', 'Measures', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Modeling', 'Nature', 'North America', 'Outcome', 'Participant', 'Pathway interactions', 'Perception', 'Perceptual learning', 'Performance', 'Peripheral', 'Positioning Attribute', 'Radiologic Finding', 'Radiology Specialty', 'Reading', 'Research', 'Residencies', 'Resolution', 'Rest', 'Retina', 'Scanning', 'Societies', 'Speed', 'Sports', 'Stress', 'System', 'Testing', 'Texture', 'Thoracic Radiography', 'Time', 'Training', 'Unconscious State', 'Vision', 'Visual', 'Workload', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cancer imaging', 'cohort', 'deep learning', 'design', 'experience', 'fitness', 'heuristics', 'human error', 'human model', 'improved', 'innovation', 'learning network', 'lung imaging', 'meetings', 'novel', 'oculomotor', 'oculomotor behavior', 'pandemic disease', 'patient safety', 'programs', 'radiological imaging', 'radiologist', 'sample fixation', 'shift work', 'skills', 'statistics', 'tool', 'tool development']",NCI,SUNY DOWNSTATE MEDICAL CENTER,R01,2021,646124
"Radiomics and Pathomics to predict upstaging of DCIS Abstract  Ductal carcinomas in situ (DCIS) of the breast are a heterogeneous group of neoplastic lesions that are usually detected by screening mammography. Workup generally includes a percutaneous (core) Biopsy (Bx) for histologic confirmation, followed by multiparametric MRI (mpMRI), followed by breast-conserving excision, and adjuvant radiation. Approximately 20-25% of patients with core Bx-confirmed DCIS are upstaged to invasive carcinoma upon pathology of resected tissue. Foreknowledge of this would dictate a more aggressive surgical intervention, including sentinel node biopsy for axillary staging. Further, another 20-25% of patients are judged to have low-risk disease and current thought is that such women may have better outcomes in an active surveillance setting, and this is being tested in clinical trials. The ultimate goal and the overall impact of this project is to use machine learning to identify biochemical (SA1) or imaging (SA2) biomarkers, as well as their combination (SA3) to discriminate indolent from aggressive DCIS, as determined by upstaging upon excisional biopsy.  The major hypothesis to be tested in this work is that hypoxia and expression of hypoxia-related proteins (HRPs) can discriminate aggressive from more indolent DCIS, and that this can be used for decision support. Expression of HRPs is optimally characterized by immunohistochemistry (IHC), and we have deployed methods for multiplexed IHC, as well as methods for advanced analytics using machine learning (pathomics). We have also shown that hypoxic habitats within breast cancers can be identified from mpMRI using machine learning (radiomics). We thus propose to use pathomics of core biopsies and radiomics of mpMRI to determine the presence and extent of hypoxic habitats in DCIS prior to surgery to predict subsequent upstaging after surgical resection. This work will be performed in Aim 1 for pathomics and Aim 2 for radiomics, and Aim 3 will develop combined radio-pathomics predictors. Each aim will contain: (a) retrospective arms for training, tuning, and testing; and (b) prospective internal and external cohorts for rigorous validation. For the retrospective studies, we have identified 604 cases wherein women with DCIS obtained core Bx, mpMRI, and surgery with pathology at Moffitt in the last 10 years. Internal prospective studies will accrue ~6 women/month who have consented to the total Cancer Care® protocol and who have their complete workup at Moffitt. External validation cohorts will be accrued at UCSF and at Advent Health.  At the end of this work we will have developed a risk model for DCIS that can be deployed prior to surgery to guide decisions along the spectrum from active surveillance at one end to more extensive surgical intervention at the other. This is expected to lay a foundation for subsequent interventional trials. Additionally, the inclusion of hypoxia as a central hypothesis has high potential to illuminate components of the natural history of this disease. Narrative  Ductal carcinoma in situ (DCIS) is one of the most commonly diagnosed malignancies of the breast and data are lacking with regard to optimal treatment. Consequently, the majority of DCIS are treated in the same manner: i.e. surgery +/- radiation +/- hormonal therapy that results in either over- or under-treatment of many patients. In the current work we will test the hypothesis that histologic or radiologic markers prior to surgery can guide decision support by identifying predicting up-staging and pathological risk scoring following surgical excision.",Radiomics and Pathomics to predict upstaging of DCIS,10120171,R01CA249016,"['Acidosis', 'Adjuvant', 'Adjuvant Therapy', 'Antibodies', 'Area', 'Attention', 'Axilla', 'Basic Science', 'Biochemical', 'Biological Markers', 'Biopsy', 'Breast', 'Breast Carcinogenesis', 'Carcinoma', 'Cells', 'Clinical', 'Clinical Paths', 'Clinical Trials', 'Consent', 'Core Biopsy', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Duct (organ) structure', 'Epigenetic Process', 'Evolution', 'Excision', 'Excision biopsy', 'Formalin', 'Foundations', 'Functional disorder', 'Genotype', 'Goals', 'Habitats', 'Health', 'Heritability', 'Histologic', 'Hyperplasia', 'Hypoxia', 'Image', 'Immunohistochemistry', 'Indolent', 'Intervention Trial', 'Knowledge', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mammographic screening', 'Mammography', 'Metastatic breast cancer', 'Methods', 'Milk', 'Modeling', 'Multiparametric Analysis', 'Mutation', 'Noninfiltrating Intraductal Carcinoma', 'Operative Surgical Procedures', 'Outcome', 'Paraffin Embedding', 'Pathologic', 'Pathology', 'Patients', 'Periodicity', 'Phenotype', 'Physiological', 'Population', 'Prevalence', 'Process', 'Prospective Studies', 'Prospective cohort', 'Proteins', 'Protocols documentation', 'Radiation', 'Radio', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Resected', 'Retrospective Studies', 'Retrospective cohort', 'Risk', 'SLC2A1 gene', 'Sentinel Lymph Node Biopsy', 'Staging', 'Stains', 'Surgical Pathology', 'Testing', 'Time', 'Tissue Embedding', 'Tissues', 'Training', 'Validation', 'Variant', 'Woman', 'Work', 'advanced analytics', 'arm', 'base', 'breast malignancies', 'cancer care', 'cohort', 'contrast enhanced', 'deep learning', 'disease natural history', 'disorder risk', 'hormone therapy', 'malignant breast neoplasm', 'neoplastic', 'optimal treatments', 'practical application', 'preclinical study', 'premalignant', 'prospective', 'radiomics', 'standard of care', 'statistics', 'tumor', 'validation studies']",NCI,H. LEE MOFFITT CANCER CTR & RES INST,R01,2021,699147
"Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction Nuclear medicine imaging in children has been shown to have significant clinical value across all organ systems. In providing this significant benefit it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that of adults, owing to their higher tissue sensitivity and longer potential lifespan. The governing principle of this project will be to minimize radiation dose while methodically ensuring that lesion detection performance is fully preserved. This will be accomplished by using validations based on both numerical and physician observers measuring performance in tasks that emulate those performed clinically. We will employ two approaches in tandem to enable lowering dose while maintaining performance. First, we will use advanced image reconstruction and processing techniques. Corrections for various forms of image quality degradation will be incorporated in the reconstruction, and deep learning (DL) will be used for post-reconstruction denoising. Second, we will develop methods to correct for both body and respiratory motion, which degrade diagnostic accuracy. Correcting for body and respiratory motion will allow dose to be reduced without loss of image quality and will also offer a technological alternative to using sedation or even general anesthesia to minimize motion when imaging children. For this investigation we have selected 99mTc-labeled dimercaptosuccinic acid (DMSA) renal imaging as a testbed to demonstrate our approaches. Damage to the renal cortex resulting from infection of the kidneys is a critical issue in children, including newborns and toddlers. DMSA SPECT is the “gold-standard” in the evaluation of pyelonephritis and renal scarring post- infection. The concepts we will demonstrate for reduction of radiation dose and correction of motion with DMSA will be translatable to other SPECT (and PET) studies in pediatric imaging and beyond.  Our Specific Aims are: 1. Establish infrastructure for investigating and evaluating advanced reconstruction and motion correction; 2. Determine the extent of radiation dose reduction to pediatric patients through improved reconstruction and DL denoising while maintaining optimal full-dose lesion detection accuracy; 3. Develop data-driven and depth-sensing camera methods for body and respiratory motion estimation and correction; and 4. Conduct numerical and physician observer studies to validate the level of dose reduction enabled by DL denoising and motion correction. Narrative  In nuclear medicine imaging, it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that in adults, owing to their higher tissue sensitivity and longer potential lifespan. Correcting for body and respiratory motion occurring during imaging will improve the quality of the formed three-dimensional images of the patient by reducing blurring and image artifacts and offer a technological alternative to using sedation or even general anesthesia to reduce motion when imaging children, which can bear health risks of its own. We propose an advanced reconstruction methodology which would enable reduction in the amount of activity administered and compensate for patient motion during imaging.",Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction,10168531,R01EB029315,"['3-Dimensional', 'Adult', 'Algorithms', 'American', 'Area', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'DMSA', 'Data', 'Databases', 'Detection', 'Development', 'Discipline of Nuclear Medicine', 'Dose', 'Enhancing Lesion', 'Ensure', 'European', 'Evaluation', 'Freedom', 'Gaussian model', 'General Anesthesia', 'Gold', 'Guidelines', 'Health', 'Hybrids', 'Image', 'Imaging problem', 'Infection', 'Infrastructure', 'Investigation', 'Kidney', 'Label', 'Lesion', 'Longevity', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Morphologic artifacts', 'Motion', 'Newborn Infant', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Population', 'Positron-Emission Tomography', 'Procedures', 'Pyelonephritis', 'ROC Curve', 'Radiation Dose Unit', 'Respiration', 'Risk', 'Scheme', 'Sedation procedure', 'Societies', 'Statistical Study', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Tissues', 'Toddler', 'Ursidae Family', 'Validation', 'base', 'body system', 'cardiac single photon emission computed tomography', 'clinically significant', 'deep learning', 'denoising', 'denoising deep learning', 'diagnostic accuracy', 'image processing', 'image reconstruction', 'improved', 'innovation', 'kidney cortex', 'kidney infection', 'molecular imaging', 'pediatric patients', 'preservation', 'reconstruction', 'renal scarring', 'respiratory', 'response', 'single photon emission computed tomography']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2021,724046
"High-definition, wide field of view corneal imaging The cornea is the primary focusing structure of our visual system. Infections and diseases in the tissue can impair vision and lead to blindness, even in eyes with intact neurosensory function. Corneal disease is one of the leading causes of visual deficiency and blindness in the world. Tissue evaluation is an important step for assessing the health of the donor cornea and its appropriateness for different types of placement, yet this process suffers from high subjectivity. High-definition corneal imaging is needed to assist in selection of the most appropriate tissue for transplant. Progress on this front would greatly serve public need, as the cornea is the most commonly transplanted tissue worldwide, with nearly 185,000 transplants annually. Thus, a more sensitive and quantitative method for objective evaluation of tissue at eye banks is needed. We have developed a 3D high-definition imaging instrument based on Gabor-Domain Optical Coherence Microscopy (GDOCM). Our SBIR Phase I research successfully accomplished all Aims and demonstrated the feasibility of quantitative assessment of corneal tissue over a large field of view with GDOCM. Our Phase I results demonstrated that GDOCM has the following key advantages over existing corneal imaging techniques, which include specular and confocal microscopy: 1) improved accuracy of tissue qualification with 4-10x increase in field of view that reduces sampling error – this will provides a truer assessment of the overall tissue characteristics; 2) ability to simultaneously measure corneal thickness, quantify endothelial cell density, and identify morphological variations due to corneal disease – this will lead to complete corneal evaluation in a single instrument; 3) leveraging machine learning innovations to minimize variability induced by users – this will result in a more objective evaluation; 4) enhanced 3D cellular-level imaging of thin translucent endothelial cells – this will enable a detailed understanding of cell viability. The results of the proposed Phase studies II will demonstrate that GDOCM can provide high-definition, 3D visualization of corneal structures with immediate commercial application for qualification of donor tissue in eye banks, and with a path to in vivo clinical imaging of patients with corneal disease. Current corneal evaluation methods employed at eye banks have limited field of view and/or insufficient resolution, and their results suffer from high subjectivity. We propose to commercialize a Gabor-domain optical coherence microscope to enable non-invasive, high-definition, wide field of view imaging in 3D for eye banks.","High-definition, wide field of view corneal imaging",10172909,R44EY028827,"['3-Dimensional', 'Address', 'Area', 'Assessment tool', 'Blindness', 'Cell Count', 'Cell Density', 'Cell Survival', 'Cell Viability Process', 'Cellular Morphology', 'Characteristics', 'Clinic', 'Confocal Microscopy', 'Cornea', 'Corneal Diseases', 'Disease', 'Endothelial Cells', 'Evaluation', 'Eye', 'Eye Banks', 'Goals', 'Gold', 'Grant', 'Health', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Industry', 'Infection', 'Innovation Corps', 'International', 'Lead', 'Legal patent', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Ophthalmology', 'Optics', 'Organ Transplantation', 'Patient imaging', 'Phase', 'Positioning Attribute', 'Process', 'Research', 'Resolution', 'Rights', 'Sampling', 'Sampling Errors', 'Small Business Innovation Research Grant', 'Standardization', 'Structure', 'Technology', 'Thick', 'Thinness', 'Time', 'Tissue Donors', 'Tissue Transplantation', 'Tissues', 'Training', 'Transplantation', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visual', 'Visual impairment', 'Visual system structure', 'Visualization software', 'base', 'clinical development', 'clinical imaging', 'commercial application', 'density', 'image processing', 'improved', 'in vivo', 'in vivo regeneration', 'innovation', 'instrument', 'instrumentation', 'microscopic imaging', 'multidisciplinary', 'neurosensory', 'novel', 'phase 2 study', 'programs', 'prototype', 'screening', 'three-dimensional visualization', 'tool', 'trend']",NEI,LIGHTOPTECH CORPORATION,R44,2021,741958
"An interactive, digital platform to transform biological learning Abstract: The next generation of health care professionals will need to understand the foundational principles of biology. Science textbooks play a critical role in supporting biological understanding in school, yet these books are not designed to meet the diverse learning needs of students in today’s classrooms. By their nature, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current Life Science textbooks and to revolutionize reading with adaptable texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned inheritance (NGSS LS3A) content into Spanish (Aim 1); designing, developing, and testing the application to function through a web browser (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content to address 12 additional NGSS standards in English and Spanish (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive reading technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning needs. This Fast-Track project will produce an interactive, digital textbook to support students’ understanding of Life Science by giving them the ability to seamlessly move between different reading levels and languages and to play games that enhance their understanding of scientific language and concepts. This project will also solicit feedback from teachers and students to develop teacher support materials and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform biological learning",10083748,R44GM133245,"['Address', 'Adoption', 'Biological', 'Biological Sciences', 'Biology', 'Books', 'Brain', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Gametogenesis', 'Health Professional', 'Healthcare', 'Home environment', 'Individual', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Nature', 'Phase', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Spinal Cord', 'Students', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'Vocabulary', 'base', 'concept mapping', 'design', 'digital', 'education resources', 'egg', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'reading ability', 'resource guides', 'response', 'science teacher', 'scientific literacy', 'skills', 'sperm cell', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2021,750000
"An interactive, digital platform to transform physical science learning Abstract: The next generation of science and health care professionals will need to understand the foundational concepts of physics. While textbooks play a critical role in science learning, these books are not designed to meet the diverse learning needs of students in today’s classrooms. Unfortunately, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current physical science textbooks and to revolutionize reading with interactive texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned force and motion (NGSS PS2A) content into Spanish (Aim 1); designing and developing science learning games (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content in both English and Spanish to address 9 additional NGSS standards (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive learning technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning disabilities. This Fast-Track project will produce a bilingual, digital platform to support students’ understanding of Physical Science, which will allow students to seamlessly move between different reading levels and languages, play science learning games, and receive personalized content. This project will also solicit feedback from teachers and students, develop teacher support materials, and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform physical science learning",10303076,R44GM137622,"['Address', 'Adoption', 'Books', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Drops', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Health Professional', 'Healthcare', 'Home environment', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Motion', 'Phase', 'Physics', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Rewards', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Students', 'Techniques', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'adaptive learning', 'base', 'bilingualism', 'design', 'digital', 'education resources', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'physical science', 'reading ability', 'response', 'science teacher', 'scientific literacy', 'skills', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2021,774997
"Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT PROJECT SUMMARY Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before heart attacks occur and is currently used to predict risk in millions of patients annually. Under the current grant, we have established a unique collaborative multicenter registry including over 23,000 imaging datasets (REFINE SPECT) with both prognostic (major adverse cardiovascular events) and diagnostic (invasive catheterization) outcomes. Using this registry, we have demonstrated that a combination of MPS image analysis and artificial intelligence (AI) tools achieved superior predictive performance compared to visual assessment by experienced readers or current state-of-the-art quantitative techniques. In the renewal, we plan to expand REFINE SPECT with now-available enhanced datasets (adding CT and myocardial blood flow information) and leverage latest AI advances to provide a personalized decision support tool for patient-specific cardiovascular risk assessment and estimation of benefit from revascularization following MPS. The overall aim is to optimize the clinical capabilities of MPS in risk prediction and treatment guidance by integrating all available imaging and clinical data with state-of-the-art AI methods. For this work, we propose the following 3 specific aims: (1) To expand and enhance our REFINE SPECT registry including CT and MPS flow data, (2) To develop fully automated techniques for all MPS and CT image analysis, (3) To apply explainable deep learning time-to-event AI models for optimal prediction of MACE and benefit from revascularization from all image and clinical data. This work will result in an immediately deployable clinical tool, which will optimally predict risk of adverse events and establish the relative benefits from specific therapies, beyond what is possible by subjective visual analysis and mental integration of all imaging (MPS, CT, flow), and clinical data by physicians. Such quantitative integrative methods are not yet available, leaving the current practice for assessing risk and recommending therapy highly subjective. The precise quantitative results will be presented to clinicians in easy to understand terms (e.g., % risk per year, or relative risk of one therapy vs. the alternative) for a specific patient. Additionally, our methods to make AI conclusions more tangible will improve adoption of this technology. All results will be derived fully automatically thus eliminating any variability. Our approach will fit into current MPS practice and will be immediately translatable to clinics worldwide. Most importantly, this research will allow patients to benefit from increased precision and accuracy in risk assessment, thereby optimizing the use of imaging in guiding patient management decisions and ultimately improving outcomes. PROJECT NARRATIVE Myocardial perfusion imaging with SPECT is often used to predict who is at risk of heart attack and should undergo treatment such as coronary bypass or stenting; however, physicians read images visually and report results with wide variability. With the latest artificial intelligence tools and new types of imaging (including CT and fast SPECT scans), the investigators propose to develop and validate an automated clinical tool to optimize risk prediction and objectively establish the relative benefit of a specific therapy. This new tool will consider all available patient images and other relevant information to provide a personalized explanation and precise calculation of risk and potential benefits from therapy for each patient.",Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT,10110023,R01HL089765,"['Adoption', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blood', 'Blood flow', 'Calcium', 'Cardiovascular system', 'Catheterization', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Data', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'Country', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Deposition', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Event', 'Grant', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Injections', 'International', 'Joints', 'Maps', 'Measures', 'Methods', 'Modeling', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Outcome', 'Patient imaging', 'Patients', 'Perception', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Positron-Emission Tomography', 'Psyche structure', 'Public Health', 'Reader', 'Recommendation', 'Registries', 'Relative Risks', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Scanning', 'Site', 'Statistical Models', 'Stents', 'Stress', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Visual', 'Work', 'X-Ray Computed Tomography', 'adverse event risk', 'attenuation', 'cardiovascular risk factor', 'clinically relevant', 'deep learning', 'experience', 'improved', 'improved outcome', 'multidisciplinary', 'next generation', 'non-invasive imaging', 'novel', 'perfusion imaging', 'personalized decision', 'prognostic', 'radiotracer', 'relating to nervous system', 'single photon emission computed tomography', 'support tools', 'time use', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2021,777637
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",10139080,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'innovation', 'machine learning method', 'myocardial injury', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2021,790095
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,10136081,R01HL150394,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'detection test', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,821265
"Clinical performance of hemodynamics-based non-invasive device for skin cancer testing Skin cancer is the most common form of cancer in the US, accounting for just under half of all diagnosed cancers (5+ million diagnoses), 27,000+ deaths each year and the annual treatment costs of over $8.1 billion. The early diagnosis of skin cancer has significant impact on patient outcomes and health care costs but remains highly subjective and requires highly specialized training while existing diagnostic devices offer low positive predictive value which results in both, missed skin cancers as well as a large number of unnecessary biopsies. When a patient presents with a suspicious skin lesion, uncertainty in the initial assessment by a dermatologist may lead to biopsies that suggest that no subsequent treatment is necessary (false positive - FP) while at the same time lesions that are not biopsied may warrant treatment (false negative - FN) potentially giving rise to claims of malpractice. FPs subject patients to unnecessary procedures and the health care system to unnecessary costs. FNs result in delayed treatment, compromising patient outcomes and increasing health care costs. This diagnostic problem is exacerbated when a patient first presents to a primary care practice due to lesser diagnostic performance. Here, some patients may be referred unnecessarily to dermatologists while other cases go undetected. The Veriskin’s TruScore device is a proprietary, non-invasive, low-cost, easy-to-use, hand-held unit that supports the diagnosis of skin cancer. It rapidly and objectively determines whether a suspicious skin lesion is cancerous, reducing the number of FNs and also reducing the need for unnecessary biopsies. The device provides a score of 0% to 100% indicating the probability of malignancy. The TruScore works by detecting and analyzing force-induced hemodynamic abnormalities due to pathological angiogenesis which is a well established early hallmark of cancer. Pilot clinical studies indicate >99% sensitivity and >94% specificity in differentiating of skin cancer from a variety of benign conditions. The device is useful at all levels of care, but the greatest benefits to patients may result when the device is used in primary care practice. The specific goal of this project is to test the device in a larger scale clinical study. The long-term goal of the project is to achieve widespread clinical adoption of this simple-to-use and low-cost non- invasive skin cancer diagnostic method and device that will (1) facilitate sensitive, specific and non-subjective assessment of suspect skin regions by general practice clinicians and nurse practitioners, (2) enable precise targeting of patients for biopsies and/or escalation of care and (3) provide overall reduction in skin cancer treatment costs. Project Narrative The lack of accurate, objective skin cancer assessment tool for frontline caregivers leads to preventable loss of lives and costs the US healthcare system over $8B each year.  VeriSkin device enables a low cost, non-invasive, easy-to-use skin cancer diagnostic method that will (1) facilitate accurate and non-subjective assessment of suspect skin lesions by general practice clinicians, nurse practitioners and physician assistants, (2) enable precise targeting of patients for biopsies and/or escalation of care resulting in reduction in both the number of missed skin cancers and the number of unneeded referrals to dermatologists and unnecessary biopsies, and (3) provide overall reduction in skin cancer treatment costs.  The requested funds will be used to demonstrate the safety and the effectiveness of the device in a larger clinical study needed to enable regulatory approval of the device.",Clinical performance of hemodynamics-based non-invasive device for skin cancer testing,10127607,R44CA250768,"['Accounting', 'Adoption', 'Affect', 'Algorithmic Analysis', 'Assessment tool', 'Basal Cell', 'Behavior', 'Benign', 'Biopsy', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Cancer Detection', 'Cancer Diagnostics', 'Cancerous', 'Caregivers', 'Caring', 'Certification', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Coupled', 'Cutaneous', 'Data Analyses', 'Decision Making', 'Dermatologist', 'Detection', 'Device Approval', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Early Diagnosis', 'Effectiveness', 'Family Practice', 'Frequencies', 'Funding', 'General Practices', 'General Practitioners', 'Goals', 'Hand functions', 'Health Care Costs', 'Health Personnel', 'Healthcare Systems', 'Image', 'Institutional Review Boards', 'Intercellular Fluid', 'Internal Medicine', 'Investments', 'Lead', 'Lesion', 'Light', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malpractice', 'Measurement', 'Measures', 'Methods', 'Mind', 'Morphology', 'Neoplasms', 'Nevus', 'Non-Invasive Cancer Detection', 'Nurse Practitioners', 'Optics', 'Painless', 'Pathologic', 'Pathologic Neovascularization', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physician Assistants', 'Physicians', 'Pigments', 'Predictive Value', 'Primary Health Care', 'Privatization', 'Probability', 'Procedures', 'Process', 'Provider', 'Research', 'Risk', 'Safety', 'Savings', 'Screening for Skin Cancer', 'Sensitivity and Specificity', 'Skin', 'Skin Cancer', 'Specialist', 'Specificity', 'Squamous cell carcinoma', 'Structure', 'Technology', 'Testing', 'Time', 'Training', 'Treatment Cost', 'Tumor Tissue', 'Uncertainty', 'Unnecessary Procedures', 'Vascular resistance', 'Work', 'absorption', 'accurate diagnosis', 'base', 'cancer diagnosis', 'clinical practice', 'commercialization', 'cost', 'design', 'hemodynamics', 'improved', 'machine learning algorithm', 'mechanical pressure', 'melanoma', 'novel', 'peace', 'pressure', 'response', 'safety testing', 'screening', 'skills', 'skin lesion', 'tumor', 'vascular abnormality']",NCI,"VERISKIN, INC.",R44,2021,833460
"Portable GC detector for breath-based COVID diagnostics Project Summary/Abstract: This proposal has two major goals: 1) Define signature exhaled breath volatile organic compounds (VOCs) to diagnose SARS-CoV-2 infections, and 2) Develop a portable chemical sensing device that can capture and detect exhaled VOCs and includes machine learning algorithms for automated data processing and results interpretation. This project will bring a portable sensor forward into clinical use with the aim of supplementing COVID-19 diagnostics with a reagentless alternative. Breath testing of exhaled VOC biomarkers is a relatively new concept that has the potential to transform healthcare in the US and globally. Our overarching hypothesis is that a miniature breath analysis device can measure signatures of exhaled breath VOCs in real-time and correlate their profile to viral upper respiratory infections such as SARS-CoV-2, even asymptomatically. In Aim #1, we propose a prospective, observational study to analyze breath samples from COVID-19 positive and negative subjects, solely for the purpose of analysis through gold standard GC- MS to define breath VOC biomarkers of infection. We will recruit subjects at two local sites, the UC Davis Medical Center (Sacramento, CA) and VA Northern California Health Care System (Mather, CA), where MPI Dr. Kenyon and Co-Is Drs. Harper and Schivo have joint clinical appointments. Our group has a proven track record to conduct these types of clinical breath studies. In Aim #2, we will develop a portable breath analysis device using our novel miniature differential mobility spectrometry (DMS) detector, coupled with chip-based gas chromatography. DMS is a subset of ion mobility spectrometry and detects VOCs at ambient temperatures and pressures, making it highly appropriate for portable devices. This device would include our custom chip- based preconcentrator, which is packed with a chemical sorbent for extraction of VOCs from breath, and will compare functionality of a compact commercially available GC column to a micro-GC column chip from Deviant, a subcontractor in this work. Individual components of this device have already been developed, and under direction of MPI Prof. Davis, Chair of Mechanical and Aerospace Engineering, a team of research engineers would integrate these pieces together into a single unit. Collaborator Prof. Chuah would guide development of a custom software package for the device with machine learning and artificial intelligence capabilities for automated data processing and interpretation. The device would be placed in the hands of clinicians, who would provide feedback that engineers would immediately incorporate into the device and return to the clinicians for more testing. Under Aim #3, our team would process the GC-MS and GC-DMS data generated in this work, identifying a novel VOC profile for COVID-19 diagnostics. Aim #4 would initiate towards the end of this study to develop both a regulatory pathway & contract manufacturing plan for large scale production and deployment of the device for clinical approval. These efforts are supported by collaborator Dr. Nam Tran, Director of Clinical Pathology & Clinical Chemistry at the UC Davis Medical Center. Project Narrative: In the United States and worldwide, public health experts agree that nations must increase their capacity to test for COVID-19, yet global supplies for testing materials remain scarce. This project would lead to the development of an entirely new type of COVID-19 test, one that could diagnose infections with only a breath sample. Through this proposal, our team would develop a portable device that could identify people with COVID-19 infections by analyzing volatile organic compounds (VOCs) found in exhaled breath.",Portable GC detector for breath-based COVID diagnostics,10266337,U18TR003795,"['2019-nCoV', 'Aerospace Engineering', 'Appointment', 'Artificial Intelligence', 'Automatic Data Processing', 'Benchmarking', 'Biological Markers', 'Breath Tests', 'COVID diagnostic', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 diagnostic', 'COVID-19 test', 'California', 'Catalogs', 'Chemicals', 'Clinical', 'Clinical Chemistry', 'Clinical Pathology', 'Clinical Trials', 'Communities', 'Computer software', 'Consultations', 'Contact Tracing', 'Contracts', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Engineering', 'Environment', 'Exhalation', 'Feedback', 'Fingerprint', 'Flushing', 'Funding', 'Gas Chromatography', 'Gases', 'Goals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Heating', 'Human Resources', 'Individual', 'Industry', 'Infection', 'Intuition', 'Joints', 'Lead', 'Liquid substance', 'Machine Learning', 'Manufacturer Name', 'Maps', 'Mass Spectrum Analysis', 'Materials Testing', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical center', 'National Institute of Biomedical Imaging and Bioengineering', 'Observational Study', 'Output', 'Pattern', 'Polymerase Chain Reaction', 'Process', 'Production', 'Public Health', 'Publishing', 'Rapid diagnostics', 'Reagent', 'Regulatory Pathway', 'Research', 'SARS-CoV-2 infection', 'SARS-CoV-2 positive', 'Sampling', 'Sensitivity and Specificity', 'Site', 'Skin', 'Spectrometry', 'Standardization', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Translational Research', 'United States', 'United States National Institutes of Health', 'Upper Respiratory Infections', 'Viral', 'Work', 'base', 'clinical care', 'detector', 'deviant', 'differential expression', 'disease transmission', 'graphical user interface', 'instrument', 'intelligent algorithm', 'ion mobility', 'large scale production', 'machine learning algorithm', 'metabolomics', 'novel', 'novel diagnostics', 'pandemic disease', 'portability', 'pressure', 'programs', 'prospective', 'prototype', 'recruit', 'risk mitigation', 'scale up', 'sensor', 'standard of care', 'volatile organic compound']",NCATS,UNIVERSITY OF CALIFORNIA AT DAVIS,U18,2021,975463
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,10150910,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2021,984177
"Malarial retinopathy screening system for improved diagnosis of cerebral malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. In 2018, malaria affected more than 213 million people in Africa alone and claimed 381,000 lives, more than 65% of whom were African children less than 5 years old. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM, incorrect treatment, and resulting mortality or neurological disability. The specificity of the current standard of care for clinical diagnosis of CM (physical symptoms, coma, and malaria parasite test such as rapid diagnostic testing) is reported around 61%. Therefore, there is a significant market need for a highly specific, low-cost, and easy-to-use test to improve CM diagnosis and save lives. Since Malarial retinopathy (MR) is greater than 95% specific to the presence of CM, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. Screening for MR in addition to the current standard of care improves the specificity of CM diagnosis from 61% to 100%. VisionQuest Biomedical has developed ASPIRE, the first fully automated MR detection software integrated with a low-cost and portable retinal camera, a system that can be operated by minimally trained personnel such as medical technician or nurse without the need of an ophthalmic specialist. We have assembled a multidisciplinary team of regulatory consultants, commercialization experts, business development specialists, and clinicians; to clinically deploy and launch ASPIRE in our target market in Africa. This team will validate and prepare ASPIRE for regulatory clearance as well as finalize the marketing and commercial rollout strategy. In Phase II-B, the research team at VisionQuest Biomedical deployed a fully-functional clinical version of ASPIRE and tested it in nine malaria clinics in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In CRP, ASPIRE will be validated for technical and clinical performance and will be brought to commercial readiness with regulatory clearance. We will accomplish this through four specific aims. In the first aim, the software system for MR detection will be validated to bring it under design controls. In the second aim, we will deploy ASPIRE at 25 clinics in Africa to demonstrate safety and efficacy as well as to promote market traction. The third aim will focus on preparing ASPIRE for regulatory submission. In the fourth aim, we will complete African healthcare market research for a startup market of 5 countries (Malawi, Zambia, Kenya, Uganda, Rwanda) and finalize marketing and rollout strategy. Within one year after CRP, our goal will be to deploy ASPIRE in more than 200 malaria clinics across 5 countries in Africa. Narrative Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection, which claims hundreds of thousands of lives of African children every year. The detection of retinal biomarkers of CM, called malarial retinopathy, can improve the diagnostic accuracy of CM. This project proposes the development, clinical deployment, and commercialization of a fully automated malarial retinopathy detection system consisting of a low-cost retinal camera and automatic malarial retinopathy detection software.",Malarial retinopathy screening system for improved diagnosis of cerebral malaria,10253474,SB1AI162452,"['5 year old', 'Affect', 'Africa', 'African', 'Artificial Intelligence', 'Biological Markers', 'Businesses', 'Cerebral Malaria', 'Cessation of life', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Coma', 'Computer software', 'Consult', 'Country', 'Detection', 'Development', 'Diagnosis', 'Diagnostic tests', 'Disease', 'Expert Systems', 'Feedback', 'Goals', 'Government', 'Grant', 'Health', 'Healthcare Market', 'Human Resources', 'Incidence', 'Institution', 'Institutional Review Boards', 'Internet', 'Kenya', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Market Research', 'Marketing', 'Medical', 'Medical Device', 'Medicine', 'Neurologic', 'Nurses', 'Parasites', 'Pathology', 'Performance', 'Pharmacy facility', 'Phase', 'Policies', 'Rapid diagnostics', 'Readiness', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Rwanda', 'Safety', 'Series', 'Software Validation', 'Specialist', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Traction', 'Training', 'Uganda', 'Validation', 'Work', 'Zambia', 'clinical Diagnosis', 'clinical research site', 'commercialization', 'cost', 'design', 'detection platform', 'diagnostic accuracy', 'disability', 'improved', 'malaria infection', 'mortality', 'multidisciplinary', 'physical symptom', 'portability', 'programs', 'research clinical testing', 'research study', 'screening', 'smartphone Application', 'software systems', 'standard of care', 'success', 'usability', 'verification and validation', 'web site']",NIAID,VISIONQUEST BIOMEDICAL INC,SB1,2021,999158
"COVID-19 detection through scent analysis with a compact GC device Recent studies, including ours, have suggested that breath may allow us to diagnose COVID-19 infection and even monitor its progress. As compared to immunological and genetic based methods using sample media like blood, nasopharyngeal swab, and saliva, breath analysis is non-invasive, simple, safe, and inexpensive; it allows a nearly infinite amount of sample volume and can be used at the point-of-care for rapid detection. Fundamentally, breath also provides critical metabolomics information regarding how human body responds to virus infection and medical intervention (such as drug treatment and mechanical ventilation). The objectives of the proposed SCENT project are: (1) to refine automated, portable, high-performance micro-gas chromatography (GC) device and related data analysis / biomarker identification algorithms for rapid (5-6 minutes), in-situ, and sensitive (down to ppt) breath analysis and (2) to conduct breath analysis on up to 760 patients, and identify and validate the COVID-19 biomarkers in breath. Thus, in coordination with the RADx-rad Data Coordination Center (DCC), we will complete the following specific aims. (1) Refine 5 automated micro-GC devices to achieve higher speed and better separation capability. We will construct 5 new automated and portable one-dimensional micro-GC devices that require only ~6 minutes of assay time (improved from current 20 minutes) at the ppt level sensitivity (Sub-Aim 1a). Then the devices will be upgraded to 2-dimensional micro-GC to significantly increase the separation capability (Sub-Aim 1b). In the meantime, we will optimize and automate our existing data processing and biomarker identification algorithms and codes to streamline the workflow so that the GC device can automatically process and analyze the data without human intervention (Sub-Aim 1c). (2) Identify breath biomarkers that distinguish COVID-19 positive (symptomatic and asymptomatic) and negative patients. We will recruit a training cohort of 380 participants, including 190 COVID-19 positive patients (95 symptomatic and 95 asymptomatic) and 190 COVID-19 negative patients from two hospitals (Michigan Medicine – Ann Arbor and the Henry Ford Hospital – Detroit). We will conduct breath analysis using machine learning to identify VOC patterns that match each COVID-19 diagnostic status. (3) Validate the COVID-19 biomarkers using our refined micro-GC devices. Using the refined 2-D micro-GC devices from Sub-Aim 1b, we will recruit a new validation cohort of 380 participants (190 COVID-19 positive patients and 190 COVID-19 negative patients) to validate the biomarkers identified in Aim 2.  We will leverage existing engineering, data science, clinical, regulatory, and commercialization resources throughout the project to hit our milestones, ensuring a high likelihood of rapid patient impact. Upon completion of this work, we will have a portable micro-GC device and accompanying automated algorithms that can detect and monitor COVID-19 status for people in a variety of clinical and community settings. Narrative  Our team of engineers, clinicians, and data scientists has developed a portable, high performance breath analyzer that can be used to detect certain diseases. In this project, we will adapt and refine our existing device and algorithms so they can be used for rapid, safe, and non- invasive COVID-19 detection. People will simply breath into the device and it will quickly provide results, meaning that it can be used in a variety of everyday settings to help fight against the COVID-19 pandemic.",COVID-19 detection through scent analysis with a compact GC device,10266206,U18TR003812,"['Acute', 'Agreement', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Biotechnology', 'Blood', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnosis', 'COVID-19 diagnostic', 'COVID-19 monitoring', 'COVID-19 pandemic', 'COVID-19 patient', 'Cessation of life', 'Clinical', 'Code', 'Critical Care', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Science', 'Data Scientist', 'Devices', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Ensure', 'Gas Chromatography', 'Genetic', 'Health', 'Hospitals', 'Human', 'Human body', 'Immunologics', 'In Situ', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Licensing', 'Machine Learning', 'Mechanical ventilation', 'Medical', 'Medicine', 'Methods', 'Michigan', 'Monitor', 'Participant', 'Patients', 'Pattern', 'Performance', 'Pharmacotherapy', 'Process', 'Production', 'RADx Radical', 'Research', 'Resources', 'Respiratory Failure', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Saliva', 'Sampling', 'Savings', 'Services', 'Severities', 'Speed', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Virus Diseases', 'Work', 'automated algorithm', 'base', 'biomarker identification', 'cohort', 'commercialization', 'community setting', 'computerized data processing', 'cost', 'design', 'fight against', 'fighting', 'global health', 'improved', 'metabolomics', 'multidisciplinary', 'nasopharyngeal swab', 'outcome forecast', 'pandemic disease', 'point of care', 'portability', 'rapid detection', 'recruit', 'respiratory hypoxia', 'screening', 'severe COVID-19', 'two-dimensional']",NCATS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,U18,2021,999775
"Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array PROJECT SUMMARY COVID-19 presents a public health emergency: There is a critical need for rapid, not reagent intensive, non- invasive testing technologies. This program will lead to the production of a prototype system to diagnose COVID-19 infection using the body odor signature of the disease. Our goal is to maximize societal impact by creating a validated prototype that can be used in a community or workplace setting by minimally trained personnel for low-cost, on-the-spot diagnosis within minutes. The system will be developed in a manner that puts it on a pathway for rapid FDA approval. The Research Aims are: Aim 1. Optimization, assembly, and integration of a prototype system with the ability to odor signature of COVID-19 in samples of body odor. The system will be simple to use, pose essentially zero risk to the operator and the test subject, and report a result within minutes. The production cost at scale will be approximately $9,000 for the complete measurement system, with a per test cost of approximately $0.50. The design and construction of the prototype will be conducted by Novo Engineering, a leading firm with extensive experience in medical device development. Aim 2. Software development. Software for the system from VOC sampling to final diagnostic result will be developed to ensure error-free operation of the device. Our preliminary results suggest that simple linear discriminant analysis (LDA) does an excellent job of classifying VOCs from human body odor as COVID-19 positive or negative (92% sensitivity and 87% specificity). Optimization of the sensor array (Aim 1) and use of richer feature sets in our classifier models will lead to further performance improvements in the prototype system. Aim 3. System Benchmarking and Validation. We will benchmark the full prototype system against a number of VOC mixtures, with and without in vitro skin models. The system will undergo extensive testing against body odor samples from individuals with pathological conditions other than COVID-19 and other sources of potentially confounding VOCs. The prototype will be validated against 1000 samples drawn from the COVID-SAFE program at Penn. The screening will include all members of the Penn community, and represents incredible racial and ethnic diversity as well as a wide variance in age, sex, and gender. Aim 4. Regulatory Approval Plan The plan will be developed under the direction of Sr/Key personnel John Fuson, JD, an attorney at Crowell & Moring LLP and a former Associate Chief Counsel at FDA. Novo Engineering has extensive experience in guiding prototype design in alignment with the requirements for FDA approval. The proposed COVID-19 VOC-based testing device will be regulated by the FDA, likely as a Class I or II medical device. Because there is no clear predicate device to reference in this case, we intend to submit a direct de novo petition to FDA asking the agency to categorize and clear the proposed COVID-19 testing device as Class I or Class II without reference to any predicate. PROJECT NARRATIVE This program addresses the critical unmet need of an effective means to screen for COVID-19 infection, and potentially other novel virus infections, in a community setting based upon the body odor signature of the disease. The program will result in a validated prototype system, with a test time of minutes, a test cost of approximately $0.50, on a path to rapid FDA approval.","Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array",10266403,U18TR003775,"['Address', 'Age', 'Astronomy', 'Benchmarking', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 screening', 'COVID-19 testing', 'Carbon Nanotubes', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Chemicals', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Computers', 'Counseling', 'DNA', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Discriminant Analysis', 'Disease', 'Engineering', 'Ensure', 'Florida', 'Future', 'Gender', 'Goals', 'Gold', 'Hand', 'Health', 'Housekeeping', 'Human', 'Human Resources', 'Human body', 'In Vitro', 'Individual', 'Information Sciences', 'International', 'Intuition', 'Laboratories', 'Lawyers', 'Mass Fragmentography', 'Measurement', 'Mechanics', 'Medical Device', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Nose', 'Occupations', 'Odors', 'Participant', 'Pathologic', 'Pathway interactions', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phase', 'Physics', 'Production', 'RADx', 'Reagent', 'Reporting', 'Research', 'Risk', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Sampling', 'Skin', 'Software Engineering', 'Solid', 'Source', 'Specificity', 'Spottings', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Viral', 'Virus Diseases', 'Visual', 'Workplace', 'animal care', 'artificial neural network', 'base', 'community setting', 'coronavirus disease', 'cost', 'design', 'design and construction', 'ethnic diversity', 'experience', 'high standard', 'machine learning algorithm', 'medical schools', 'member', 'multidisciplinary', 'nano', 'nanosensors', 'next generation', 'novel virus', 'operation', 'prevent', 'programs', 'prototype', 'public health emergency', 'racial diversity', 'sample collection', 'screening', 'screening program', 'sensor', 'sex', 'software development', 'software systems', 'vapor', 'volatile organic compound']",NCATS,UNIVERSITY OF PENNSYLVANIA,U18,2021,999830
"Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors ABSTRACT Aura is a digital health platform that uses Epilog™, a miniature, wireless, wearable EEG sensor worn on the scalp below hairline that can record clinical and subclinical seizures. After an initial diagnosis of epilepsy, an epileptologist will use known information about patients’ seizures to guide the best scalp location to place the Epilog EEG sensor (A). EEG data is continuously transferred (B) to the Aura app on a person’s smartphone (C) using secure BluetoothTM where it communicates over WiFi (D) to the Aura cloud platform (E). Epilog EEG is analyzed for seizures and a daily digital seizure diary is shared with epileptologists (F) and pushed back to the Aura app (G). Epilog is recharged daily, and reusable for a year. Epilog is designed to be discreet, allowing for continuous use in all facets of daily life. Data are a 10 s snippet of the beginning of a focal seizure with motor impairment and intact awareness (ILAE 1A1) recorded from Epitel’s single-channel Epilog sensor placed on the left forehead. The patient was admitted for video-EEG monitoring as standard-of-care. This seizure was verified independently by three epileptologists. In Phase I, automated, machine learning-based seizure detection algorithms will be designed to first work in the Aura cloud to detect seizures in Epilog EEG, including seizures a person may not consciously know they are having (>50% of all seizures), such as while sleeping. Aura will run these algorithms developed exclusively for Epilog’s single-channel of EEG to provide a daily digital seizure diary. In Phase II, the Aura system will enter clinical validation trials for FDA clearance as an EEG-based automated home seizure detection and alerting system. Early in Phase II Aura will be commercialized as a medical device-enabled-service business model. Out-of-pocket costs for a person living with epilepsy is an average of $380/year. Armed with long-term, reproducible EEG, epileptologists will now have a more precise, quantitative record of seizure counts, enabling them to adapt patient treatment more rapidly and successfully to improve quality of life. Aura will give people living with epilepsy their lives back. Aura provides certainty where you are and when you need it. Throughout Phase II, physiological, psychological, behavioral, and environmental factors will be combined in the Aura app to collect 27,000 days of multi-modal data from 300 patients to create an unprecedented dataset of features known to precipitate seizures. These data will be used in Phase III to create a robust, wearable seizure forecasting system using artificial intelligence that combines multi-modal seizure precipitating factors, creating an hourly seizure probability. Aura will profoundly disrupt how epilepsy is managed and improve the quality of life of people living with epilepsy. This grant proposal aims to create a digital health platform that includes a wearable medical device worn on the scalp below the hairline. The system detects and counts seizures, and alerts to seizures in real time. The goal is to empower people with epilepsy to take control of their seizure monitoring and help improve the treatment of epilepsy.",Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors,10200346,U44NS121562,"['Adoption', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Auras', 'Awareness', 'Back', 'Behavioral', 'Bluetooth', 'Businesses', 'Cellular Phone', 'Clinical', 'Community Hospitals', 'Consumption', 'Cues', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Electroencephalography', 'Emergency Medicine', 'Environment', 'Environmental Risk Factor', 'Epilepsy', 'Event', 'Family', 'Financial Hardship', 'Focal Seizure', 'Forehead', 'Freedom', 'Goals', 'Gold', 'Home environment', 'Hospitals', 'Hour', 'Left', 'Life', 'Location', 'Machine Learning', 'Manuals', 'Medical Device', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Neurologic', 'Paper', 'Patient Self-Report', 'Patients', 'Periodicity', 'Persons', 'Phase', 'Physiological', 'Precipitating Factors', 'Predisposition', 'Probability', 'Process', 'Quality of life', 'Reproducibility', 'Running', 'Scalp structure', 'Screening procedure', 'Secure', 'Seizures', 'Services', 'Sleep', 'Subclinical Seizures', 'System', 'Time', 'Validation', 'Wireless Technology', 'Work', 'base', 'cloud platform', 'cost', 'design', 'diaries', 'digital', 'digital health', 'effective therapy', 'encryption', 'improved', 'machine learning algorithm', 'motor impairment', 'multimodal data', 'multimodality', 'optimal treatments', 'programs', 'psychologic', 'remote monitoring', 'sensor', 'social', 'standard of care']",NINDS,"EPITEL, INC.",U44,2021,999853
"Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. Annually, malaria affects more than 200 million people and claims the lives of over 440,000 people worldwide, mostly African children. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM and incorrect treatment. An accurate means to confirm the presence of CM or to investigate for a non-malarial illness is critically needed to improve outcomes. Since Malarial retinopathy (MR) is greater than 90% specific and sensitive to the presence of CM once clinically diagnosed, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. VisionQuest Biomedical and its collaborators have assembled a team of inter-disciplinary scientists with considerable experience in automated retinal image analysis, clinical ophthalmology with specialized research in malarial retinopathy (MR), and cerebral malaria diagnosis (CM). This team will develop and test ASPIRE, a system for detection of MR consisting of automated MR detection software integrated with a low-cost and portable retinal camera. Our proposed ASPIRE system will augment, not replace, the current CM diagnostic standard; increasing the accuracy of CM diagnoses, leading to a smaller number of false positive outcomes. In Phases I and II, the research team at VisionQuest Biomedical developed the automated MR detection software and interfaced it with a handheld retinal camera. The resulting clinical prototype of ASPIRE was tested onsite in a health-clinic in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In Phase II-B, the MR detection system will be refined, productized, and the resulting commercial prototype will be validated on prospective datasets. We will accomplish this through three specific aims. In the first aim, the software system for MR detection will be adapted and improved to work with low-cost and portable iNview camera. In the second aim, we will refine iNview’s driver-software and integrate the camera with MR detection software to produce the first commercial prototype. The third aim will focus on collecting the retinal image data for algorithm testing as well as for validating the commercial prototype in an observational clinical study to be conducted at nine clinical sites in Malawi, Uganda, and Zambia in Africa. Narrative Cerebral malaria is a life-threatening clinical syndrome associated with malarial infection, which affects about 200 million people annually and claims the lives of over 440,000 people worldwide, mostly African children. The presence of malarial retinopathy can provide additional insight and improve the diagnostic accuracy of CM. This project proposes the development of a fully-automated malaria retinopathy detection system consisting of a low-cost retinal camera and automatic malaria retinopathy detection software.",Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria,10074515,R44AI112164,"['5 year old', 'Address', 'Affect', 'Africa', 'African', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'Caring', 'Cellular Phone', 'Cerebral Malaria', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Country', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Enrollment', 'Expert Systems', 'Foundations', 'Goals', 'Grant', 'Health', 'Health Personnel', 'Healthcare', 'Image Analysis', 'Incidence', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Medicine', 'Ophthalmologist', 'Ophthalmology', 'Ophthalmoscopy', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Poison', 'Predictive Value', 'Price', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Safety', 'Scientist', 'Seasons', 'Series', 'Site', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Test Result', 'Testing', 'Uganda', 'Validation', 'Work', 'Zambia', 'base', 'clinical Diagnosis', 'clinical research site', 'cost', 'cost effectiveness', 'design', 'detection platform', 'diagnostic accuracy', 'experience', 'imaging capabilities', 'improved', 'improved outcome', 'innovation', 'insight', 'malaria infection', 'mortality', 'performance site', 'portability', 'programs', 'prospective', 'prototype', 'research study', 'response', 'retinal imaging', 'screening', 'smartphone Application', 'software development', 'software systems', 'success', 'usability']",NIAID,VISIONQUEST BIOMEDICAL INC,R44,2021,1000000
"A Handheld Microchip for GC analysis of breath to screen for COVID-19 Project Summary  The COVID-19 pandemic has caused unprecedented societal suffering and economic disruption. In the United States, more than six million people have contracted COVID-19 and more than one hundred ninety thousand patients have died of this disease to date. Although current COVID-19 diagnostic testing technologies are critical for slowing the spread of the virus and preventing future outbreaks, they are not practical for field use. Current diagnostic tests are cumbersome to perform because they use aqueous solutions, require multiple steps, and hours-to-days to obtain results. Since the US began to reopen the economy in May, there has been a significant increase in the number of COVID-19 cases. Therefore, there is an urgent need to develop a diagnostic approach that is non-invasive, portable, and can rapidly provide test results.  The overall goal of the project is to develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). The handheld tool will be a closed system for trapping select volatile organic compounds (VOCs) on a microfabricated chip. The captured VOCs will be eluted with ethanol and then analyzed using a commercially available, portable GC-PID instrument. Artificial intelligence (AI) and machine learning algorithms will be applied to recognize the VOC pattern that correlates with COVID-19 infection. The central innovation is the microfabricated chip that captures carbonyl compounds in exhaled breath and thus serves as a preconcentrator, which enables analysis of carbonyl VOCs by the portable GC-PID. The hypothesis is that the carbonyl metabolome in exhaled breath is directly related to the body’s reaction to the novel coronavirus infection, and changes in the carbonyl VOC composition in exhaled breath relative to healthy controls can be used to detect both symptomatic and asymptomatic COVID-19 patients.  Three specific aims are proposed to fulfill the overall goal. Aim 1 is to build a disposable handheld breath analyzer tool for concentrating carbonyl VOCs. Aim 2 is to identify VOC patterns in the breath of COVID-19 patients by machine learning algorithms. Aim 3 is to integrate portable GC technology with the breath sampling tool for COVID-19 screening guided by an AI system. The University of Louisville is uniquely suited to rapidly transition the microchip technology to field use because of the PI and Co-PI’s experience in breath analysis and translational research, and the project team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence as well as the state-of-the-art facilities that include a MicroNano Technology Center, Biosafety Level 3 Regional Biocontainment Lab, and an NIH-funded REACH program. 8. Project Narrative  This project will develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). Artificial intelligence and machine learning algorithms will be used to analyze the detected signals of volatile organic compounds (VOCs) in exhaled breath by the portable GC for detection of COVID-19 patients. UofL is uniquely suited to develop this approach because of the PI’s expertise in breath analysis for detection of Tuberculosis and lung cancer and the team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence.",A Handheld Microchip for GC analysis of breath to screen for COVID-19,10266377,U18TR003787,"['2019-nCoV', 'Acute', 'Address', 'Artificial Intelligence', 'Biochemical Process', 'Biometry', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnostic', 'COVID-19 pandemic', 'COVID-19 patient', 'COVID-19 screening', 'COVID-19 test', 'Cancer Detection', 'Clinic', 'Collaborations', 'Collection', 'Communicable Diseases', 'Contracts', 'Coronavirus Infections', 'Detection', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Economics', 'Epithelial Cells', 'Ethanol', 'Exhalation', 'Expert Systems', 'Foundations', 'Funding', 'Future', 'Goals', 'Hour', 'Human', 'Influenza', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Malignant neoplasm of lung', 'Mass Fragmentography', 'Medical Device', 'Modeling', 'Monitor', 'Nasal Epithelium', 'Oxidative Stress', 'Patients', 'Pattern', 'Process', 'Production', 'Protocols documentation', 'Rapid screening', 'Reaction', 'Reagent', 'Research Project Grants', 'Role', 'SARS-CoV-2 infection', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Silicon', 'Sterilization', 'System', 'Technology', 'Test Result', 'Testing', 'Training', 'Translational Research', 'Tuberculosis', 'United States', 'United States National Institutes of Health', 'Universities', 'Vial device', 'Viral', 'Viral Respiratory Tract Infection', 'Virulent', 'Virus', 'Virus Diseases', 'adduct', 'aqueous', 'asymptomatic COVID-19', 'biosafety level 3 facility', 'bronchial epithelium', 'carbonyl compound', 'detection sensitivity', 'detector', 'experience', 'innovation', 'instrument', 'machine learning algorithm', 'metabolome', 'microchip', 'mobile computing', 'novel coronavirus', 'photoionization', 'point of care', 'portability', 'prevent', 'programs', 'prototype', 'reagent testing', 'tool', 'virology', 'volatile organic compound']",NCATS,UNIVERSITY OF LOUISVILLE,U18,2021,1026672
"Improved AD/ADRD Assessment Sensitivities Using a Novel In-Situ Sensor System Project Summary/Abstract  Accurate assessment of daily functions for individuals at risk for and with AD/ADRD, is fundamental to detection, diagnosis, and characterization of its progression and prescribed treatments. Current assessment techniques typically rely on non- continuous, discreet observations provided from a third party and covering single or limited performance domains. With significantly larger portions of American’s choosing to age in place, any assessment technology must be able to be in-situ (low-cost, ubiquitous) and operate without user interface (autonomous) to provide objective, cross-domain, and continuous daily function measurements and reporting.  The primary objective of this fast track SBIR project is to demonstrate the feasibility and effectiveness of using the Birkeland Current Sovrin IoT system to continuously and accurately assess daily functions, ADLs, and IADLs, for persons experiencing cognitive decline in a home or assisted care settings. This includes direct comparison with an accepted assessment technique, ADCS-ADL/23. Machine learning and artificial intelligent techniques will be employed to identify novel subfactors for improved sensitivities from available sensor data combinations. Secondary objectives include establishing a significant data set of detailed daily actions (<10 sec resolution) for 100+ individuals with AD/ADRD. Long-term goals support future intervention studies through improved assessment tools with enhanced sensitivity to early and mid-stage decline.  The Birkeland Current Sovrin IoT system makes use of patented proximity-based energy monitoring and control sensors, data analytics and change detection algorithms to continuously monitor activities of individuals in a home or assisted care environment. Intelligent power-strips and battery-based sensors located throughout the home or facility, monitor real time absolute location of individuals, caregivers, and devices they interact with. Correlation of high-fidelity data allows accurate determination of activities, attribution to a specific individual, mobility measurement, and behavior assessment across traditional and novel ADL/IADL categories. Birkeland Current is teamed with Texas A&M Center for Population Health and Aging, Georgia, Tech Institute for People and Technology, Baylor Scott and White Division of Gerontology, and multiple home-care and assisted-care facilities, in the development of the study approach, implementation plan, analytics tools, and applications to aging populations and future intervention studies. Project Narrative  The proposed research would utilize novel, ubiquitous Internet-of-Things sensors and automated analytics to demonstrate enhanced sensitivity and future utility of continuous in-situ IADL/ADL data for dementia research and its effectiveness in characterizing interventions for Alzheimer’s and related dementias of aging populations in support of NIA stated priorities.",Improved AD/ADRD Assessment Sensitivities Using a Novel In-Situ Sensor System,10144919,R44AG065118,"['Address', 'Adoption', 'Aging', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'American', 'Artificial Intelligence', 'Assessment tool', 'Behavior assessment', 'Behavioral Symptoms', 'Caregivers', 'Caring', 'Categories', 'Centers for Population Health', 'Classification', 'Communities', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Dementia', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Early Diagnosis', 'Early identification', 'Effectiveness', 'Environment', 'Future', 'Gerontology', 'Goals', 'Grouping', 'Health care facility', 'Home environment', 'Impaired cognition', 'In Situ', 'Individual', 'Industry', 'Institutes', 'Intelligence', 'Internet of Things', 'Intervention', 'Intervention Studies', 'Legal patent', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metadata', 'Methods', 'Monitor', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Problem Solving', 'Protocols documentation', 'Publishing', 'Recommendation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Risk', 'Series', 'Small Business Innovation Research Grant', 'System', 'Techniques', 'Technology', 'Technology Assessment', 'Texas', 'Time', 'Training', 'United States National Institutes of Health', 'Use Effectiveness', 'aging in place', 'aging population', 'analytical tool', 'base', 'cost', 'daily functioning', 'data acquisition', 'data integration', 'database structure', 'design', 'detection platform', 'experience', 'home test', 'improved', 'insight', 'instrumental activity of daily living', 'learning algorithm', 'novel', 'patient home care', 'personalized care', 'real time monitoring', 'sensor', 'symposium', 'tool']",NIA,BIRKELAND CURRENT LLC,R44,2021,1807912
