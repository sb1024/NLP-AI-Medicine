text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Innovative Vaccine Approaches ABSTRACT Support is requested for a Keystone Symposia conference entitled Innovative Vaccine Approaches, organized by Drs. Mariagrazia Pizza, Galit Alter and Gordon Dougan. The conference will be held in Vancouver, Canada from June 27- July 1, 2021. Vaccines have the power to prevent and potentially eradicate a wide range of infectious diseases, representing one of the most effective life-saving measures at our disposal against global health threats. The recent coronavirus pandemic has brought the importance and urgency of vaccine development efforts into sharp focus. Moreover, the vaccinology field is evolving very rapidly, thanks to advances in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis of antigens and antigen- antibody complexes and impacts of variation. Over the years, this field has also experienced an elucidation of mechanisms of immunity and protection, and identification of correlates. However, many questions are still unsolved and innovative approaches are needed to address new vaccine challenges like antimicrobial resistance, emerging infectious diseases, cancer and diseases associated with our aging population. This conference will cover the latest advances and novel approaches towards vaccine development, including: (1) novel antigen delivery systems; (2) in vitro and in vivo model systems for vaccine appraisal (3) the use of human challenge models; (4) the role of ‘systems biology’ in the comprehensive analysis of immune correlates, biomarker identification and safety; (5) machine-learning approaches to define correlations between antibody repertoires and protection; and (6) strategies for developing low cost vaccines for economically challenged populations. Together these topics will provide attendees with the new ideas and tools to continue to forge new frontiers in vaccine capabilities. PROJECT NARRATIVE Vaccines have the power to prevent and potentially eradicate a wide range of both infectious and non- infectious diseases. The field is evolving very rapidly due to improvements in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis techniques. This conference will accelerate advances the field, bringing together public and private communities to ensure the end of the COVID-19 pandemic and other epidemics that afflict the population. This event provides a unique opportunity for discussion of the key challenges in making low cost vaccines for economically challenged populations and how to address burning topics such as pandemics, antimicrobial resistance, emerging infectious diseases, cancer and an aging population.",Innovative Vaccine Approaches,10237543,R13AI161938,"['Address', 'Antibody Repertoire', 'Antigen-Antibody Complex', 'Antigens', 'Antimicrobial Resistance', 'Biological Models', 'COVID-19 pandemic', 'Canada', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Coronavirus', 'Disease', 'Educational workshop', 'Emerging Communicable Diseases', 'Ensure', 'Epidemic', 'Event', 'Future', 'Genomics', 'Human', 'Immersion', 'Immune', 'Immunity', 'Immunology', 'In Vitro', 'Knowledge', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Microbiology', 'Modeling', 'Outcome', 'Population', 'Privatization', 'Research', 'Research Personnel', 'Role', 'Safety', 'Savings', 'Scientist', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Vaccines', 'Variant', 'aging population', 'biomarker identification', 'clinical practice', 'cost', 'experience', 'frontier', 'global health', 'in vivo Model', 'innovation', 'manufacturability', 'next generation', 'novel', 'novel strategies', 'novel vaccines', 'pandemic disease', 'posters', 'prevent', 'symposium', 'tool', 'vaccine development', 'vaccine discovery', 'vaccinology']",NIAID,KEYSTONE SYMPOSIA,R13,2021,8000
"Computational Analysis of Enzyme Catalysis and Regulation Project Summary: It is of great fundamental and biomedical importance to understand the physical princi- ples that govern the coupling between the chemical step in a biomolecule and other events, such as penetration of water molecules into the active site, recruitment of transient metal ions, or conformational rearrangements near and afar. This is a challenging task, however, due to the intrinsic multi-scale nature of the problem. As a result, our understanding in factors that dictate the efﬁciency and speciﬁcity of enzyme catalysis remains in- complete, especially regarding contributions beyond the active site; this knowledge gap has greatly limited our ability to design highly efﬁcient enzymes de novo. Motivated by these considerations, the overarching theme of our research is to develop and apply multi-scale computational methods to reveal the underlying mechanism of enzyme catalysis at an atomic level, with a particular emphasis on establishing to what degree the chem- ical step is coupled with other processes proximal or distal to the active site. Speciﬁcally, we aim to develop an efﬁcient QM/MM framework to compute free energy proﬁles of enzyme reactions with a good balance of computational speed and accuracy; further integration with enhanced sampling approaches, machine learning techniques and modern computational hardwares enables us to gain insights into the nature of coupling be- tween the chemical step and other events during the functional cycle. Accordingly, we are in a unique position to pursue several lines of exciting applications, which include the mechanism and impact of transient metal ion recruiting in nucleic acid processing enzymes, the catalytic and regulatory mechanism of peripheral membrane enzymes, and systemic analysis of allosteric coupling in a transcription factor; an emerging research direction is to explore the interplay of stability, catalytic activity, and allostery during continuous directed evolution. Our project integrates computational method developments with applications inspired by recent experimental ad- vances, such as time-resolved crystallography, deep mutational scanning and continuous directed evolution. The research efforts will lead to novel computational tools and mechanistic insights into the regulatory mech- anisms of enzymes by processes either near or remote from the active site. Thus the project will have both fundamental impacts and implications for better design strategies for catalysis and allostery in biomolecules. Narrative: The computational methodologies we develop will be applicable to a broad set of metalloen- zymes and proteins of biomedical relevance. In particular, we target fundamental mechanistic problems in enzymes that catalyze nucleic acids synthesis/modiﬁcation and lipid metabolism, since mutations in these en- zymes are implicated in numerous human diseases such as cancer, insulin resistance and diabetes. Although our project does not focus on design of drugs, the mechanistic insights into enzyme catalysis and allosteric regulation will broaden strategies that can be used to target various enzymes of biomedical signiﬁcance.",Computational Analysis of Enzyme Catalysis and Regulation,10206585,R35GM141930,"['Active Sites', 'Allosteric Regulation', 'Catalysis', 'Chemicals', 'Computer Analysis', 'Computing Methodologies', 'Coupled', 'Coupling', 'Crystallography', 'Diabetes Mellitus', 'Directed Molecular Evolution', 'Distal', 'Drug Design', 'Enzymes', 'Equilibrium', 'Event', 'Free Energy', 'Insulin Resistance', 'Ions', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Membrane', 'Metals', 'Modernization', 'Modification', 'Molecular Conformation', 'Mutation', 'Nature', 'Nucleic Acids', 'Penetration', 'Peripheral', 'Positioning Attribute', 'Process', 'Proteins', 'Reaction', 'Regulation', 'Research', 'Sampling', 'Specificity', 'Speed', 'Techniques', 'Time', 'Tweens', 'Water', 'computerized tools', 'design', 'enzyme mechanism', 'human disease', 'insight', 'lipid metabolism', 'method development', 'mutation screening', 'novel', 'recruit', 'transcription factor']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2021,295591
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,10111538,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2021,1354555
"Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space Project Summary  The natural environment is intrinsically spatiotemporally heterogenous at both macroscopic and microscopic levels. What shapes such a heterogeneity includes the concentration gradients of biologically relevant chemical species in the extracellular medium including dioxygen (O2), reactive oxygen species (ROS), as well as essential redox-active transition metals. While a significant amount of effort has been devoted to spectroscopically image these chemical moieties, our capability to spatiotemporally control their concentration distributions in the extracellular medium remains limited. This is especially the case for biofilms and microbiota, in which the microorganisms’ small length scales pose significant challenges for concentration modulation. The inadequate control of concentration heterogeneity limits our capability of mimicking the natural environments in vitro and investigating how local concentration gradients affect microbial functionality. Therefore, there is a need for an advanced method of controlling chemical concentrations at microscopic level.  Our proposed research aims to use electrochemical nano-/micro-electrodes to spatiotemporally control the concentration gradients in the extracellular medium. When an electrochemical reaction occurs on an electrode’s surface, a concentration gradient is established near the electrode. Taking advantages of this phenomena with the assistance of numerical simulation, we will employ an array of nano-/micro-electrodes with individually addressable electrochemical potentials to program any arbitrary spatiotemporal concentration profiles. We will fine-tune the surface chemistry and the electrochemical properties of these electrodes to ensure biocompatibility and reaction specificity. The developed system will be applied to biofilms and we aim to investigate how the microbial social behavior will be affected by a perturbation of local O2 concentration. Moreover, we will use this device to mimic the heterogenous environment in the gut and culture gut microbiota in vitro. An algorithm based on machine learning will be employed to actively adjust electrode potentials, maintaining a stable concentration profile despite the accumulation of gut microorganisms.  Ultimately, our work will expand our capability of controlling the concentration heterogeneity in nature. The developed electrochemical system will serve an in vitro platform to culture microorganisms in their native environment, or as a tool to perturb the concentration profiles. Combining electrochemistry, inorganic chemistry, and nanomaterials the research will enable a deeper understanding of the spatial distribution and temporal response of microbial systems. Project Narrative The natural environment is intrinsically heterogenous yet our control of concentrations for chemical species is limited at microscopic level. The proposed research is relevant to the mission of the NIH because it describes the development of technology that will expand our capability of controlling chemical concentration profiles in a variety of microbial systems relevant to the public health. The research described here will enable a deeper understanding of disease-related microbial systems and help to formulate strategies to combat diseases.",Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space,10256801,R35GM138241,"['Affect', 'Algorithms', 'Biological', 'Chemicals', 'Chemistry', 'Devices', 'Dioxygen', 'Disease', 'Electrochemistry', 'Electrodes', 'Ensure', 'Environment', 'Heterogeneity', 'In Vitro', 'Individual', 'Inorganic Chemistry', 'Length', 'Machine Learning', 'Methods', 'Microbial Biofilms', 'Microscopic', 'Mission', 'Nanoarray Analytical Device', 'Nature', 'Oxidation-Reduction', 'Property', 'Public Health', 'Reaction', 'Reactive Oxygen Species', 'Research', 'Shapes', 'Social Behavior', 'Spatial Distribution', 'Specificity', 'Surface', 'System', 'Transition Elements', 'United States National Institutes of Health', 'Work', 'base', 'biomaterial compatibility', 'combat', 'extracellular', 'gut microbiota', 'microbial', 'microbiota', 'microorganism', 'microorganism culture', 'nano', 'nanomaterials', 'programs', 'response', 'simulation', 'spatiotemporal', 'spectroscopic imaging', 'technology development', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2021,371084
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,10113656,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Structure', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics tool', 'cancer therapy', 'computerized data processing', 'contig', 'convolutional neural network', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'preservation', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,DANA-FARBER CANCER INST,R01,2021,397125
"Maximizing Investigators' Research Award (R35) PROJECT SUMMARY The “Tools for Transmission of Agents and Conditions (TRAC)” program will synergize statistical and mathematical modeling work in three areas of application: 1) Tuberculosis (TB) incidence and transmission; 2) monitoring substance use disorder (SUD) patterns; and 3) SARS CoV-2 transmission modeling. These three conditions are major public health problems, with TB being the leading cause of infectious disease death globally, SUD causing more deaths in the United States than HIV/AIDS in its peak, and SARS CoV-2 causing a pandemic with societal disruption and mortality exceeding anything we have experienced in the last century. We need improved analytical tools that leverage existing data to monitor these diseases, infer transmission hot spots, determine the efficacy of interventions, and understand the burden of these conditions. This program will bring together an expert group of quantitative researchers with skills that are readily applied to these problems. We also leverage our strong collaborations with clinician researchers and public health officials to ensure that the methods we develop are addressing important questions and consistent with our current understanding of these diseases. By creating a program to facilitate communication between these experts, we will enable greater innovation in modeling key aspects of these diseases and create exciting methodological synergies across diseases. Our team is well positioned to incorporate data from emerging technologies, including high throughput sequencing data to determine TB risk signatures and inform transmission links for TB and SARS CoV-2. Our expertise in machine learning, a broad range of statistical methodologies, and mathematical modeling will enable us to leverage the rich information in large databases that are emerging to better understand SUD patterns and identify risk signatures. We will also build infrastructure with our partners to make the analytical tools that we develop more accessible to public health practitioners and other researchers. The impact of this work is to develop a suite of analytical tools that leverage rapidly emerging rich data sets to improve our understanding of disease transmission patterns, monitor changing dynamics of these conditions, and understand intervention strategies that are most effective. This work will inform public health practice for these diseases and create reproducible tools that can be used in an ongoing way. PROJECT NARRATIVE This project will generate analytical tools to address three major public health challenges: 1) Tuberculosis, 2) Substance use disorders, and 3) SARS CoV-2. These tools will improve our understanding of the transmission patterns of these diseases, advance our ability to monitor them, and inform intervention strategies. We will build infrastructure to make these methods available to public health practitioners and other researchers.",Maximizing Investigators' Research Award (R35),10205596,R35GM141821,"['2019-nCoV', 'AIDS/HIV problem', 'Address', 'Area', 'Award', 'Cessation of life', 'Collaborations', 'Communicable Diseases', 'Communication', 'Data', 'Data Set', 'Databases', 'Disease', 'Emerging Technologies', 'Ensure', 'High-Throughput Nucleotide Sequencing', 'Hot Spot', 'Incidence', 'Infrastructure', 'Intervention', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Pattern', 'Positioning Attribute', 'Public Health', 'Public Health Practice', 'Reproducibility', 'Research', 'Research Personnel', 'Risk', 'SARS-CoV-2 transmission', 'Statistical Models', 'Substance Use Disorder', 'Treatment Efficacy', 'Tuberculosis', 'United States', 'Work', 'analytical tool', 'disease transmission', 'experience', 'improved', 'innovation', 'mathematical model', 'mortality', 'pandemic disease', 'programs', 'skills', 'synergism', 'tool', 'transmission process']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R35,2021,171876
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,10213202,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computational pipelines', 'computerized tools', 'dark matter', 'dietary', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'in silico', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2021,981634
"A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth This project provides a data science framework and a toolbox of best practices for systematic and reproducible data-driven methods for validating and deriving RDoC constructs with relevance to psychopathology. Despite recent advances in methods for data-driven constructs, results are often hard to reproduce using samples from other studies. There is a lack of systematic statistical methods and analytical design for enhancing reproducibility. To fill this gap, we will develop a data science framework, including novel scalable algorithms and software, to derive and validate RDoC constructs. Although the proposed methods will generally apply to all RDoC domains and constructs, we focus specifically on furthering understanding of the RDoC domains of cognitive control (CC) and attention (ATT) constructs implicated in attention deficit disorder (ADHD) and obsessive-compulsive disorder (OCD). Our application will use multi-modal neuroimaging, behavioral, and clinical/self-report data from large, nationally representative samples from the on Adolescent Brain Cognitive Development (ABCD) study and multiple local clinical samples with ADHD and OCD. Specifically, using the baseline ABCD samples, in aim 1, we will apply and develop methods to assess and validate the current configuration of RDoC for CC and ATT using confirmatory latent variable modeling. We will implement and develop new unsupervised learning methods to construct new computational-driven, brain-based domains from multi-modal image data. In Aim 2, We will introduce network analysis (via Gaussian graphical models) to characterize heterogeneity in the interrelationship of RDoC measurements due to observed characteristics (i.e., age and sex). We will further model the heterogeneity of the population due to unobserved characteristics by introducing the data-driven precision phenotypes, which are the subgroup of participants with similar RDoC dimensions. We propose a Hierarchical Bayesian Generative Model and scalable algorithm for simultaneous dimension reduction and identify precision phenotypes. The model also serves as a tool to transfer information from the community sample ABCD to local clinical enriched studies. In aim 3, we will utilize the follow-up samples from ABCD and local clinical enriched data sets to validate the results from Aims 1 and 2 and assess the clinical utility of the precision phenotypes in predicting psychological development in follow-up time. Our project will provide a suite of analytical tools to validate existing RDoC constructs and derive new, reproducible constructs by accounting for various sources of heterogeneity. To advance the understanding of psychopathology using dimensional constructs of measurements from multiple units of analysis, we propose reproducible statistical framework for validating and deriving RDoC constructs with relevance to psychopathology. We will use multi-modal neuroimaging, behavioral and clinical/self-report data from multiple samples to develop this framework. The design of our study consists of analyzing large, nationally representative samples, validating the results in local clinically enriched samples, and transfer information from the large community samples to local clinical samples.",A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth,10250553,R01MH124106,"['11 year old', 'Accounting', 'Adolescent', 'Age', 'Algorithmic Software', 'Algorithms', 'Attention', 'Attention Deficit Disorder', 'Base of the Brain', 'Behavioral', 'Brain', 'Characteristics', 'Child', 'Chronology', 'Clinical', 'Clinical Data', 'Communities', 'Data', 'Data Reporting', 'Data Science', 'Data Set', 'Development', 'Dimensions', 'Ensure', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Goals', 'Heterogeneity', 'Image', 'Knowledge', 'Learning', 'Link', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Obsessive-Compulsive Disorder', 'Participant', 'Pathway Analysis', 'Patient Self-Report', 'Phenotype', 'Population Heterogeneity', 'Prediction of Response to Therapy', 'Psychological Transfer', 'Psychopathology', 'Reproducibility', 'Reproducibility of Results', 'Research Domain Criteria', 'Sampling', 'Source', 'Statistical Methods', 'Structure', 'Subgroup', 'Symptoms', 'Time', 'Variant', 'Youth', 'age effect', 'analytical tool', 'autoencoder', 'base', 'biological sex', 'cognitive control', 'cognitive development', 'deep learning', 'design', 'follow up assessment', 'follow-up', 'high dimensionality', 'independent component analysis', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'multimodality', 'network models', 'neuroimaging', 'novel', 'psychologic', 'response', 'sex', 'tool', 'unsupervised learning']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2021,660324
"Non-target analysis of maternal and cord blood samples: Advancing computational tools and discovering novel chemicals PROJECT SUMMARY/ABSTRACT  Non-targeted analysis (NTA) provides a comprehensive approach to analyze environmental and biological samples for nearly all chemicals present. Despite the recent advancements in NTA, the number of confirmed chemicals with analytical standards remains fairly small compared to the number of detected features. There is, thus, a need to further develop computational tools to derive more chemical structures and leverage the full potential of HRMS. Enhancing our ability to derive more chemical structures will enable the discovery of new industrial chemicals that humans are exposed to, especially in critical windows of development, such as pregnancy. It will also enable the discovery of endogenously produced metabolites that may be related to biological outcomes of importance, such as preterm birth. The objective of my proposal is to develop novel computational methods to significantly advance our ability to analyze and interpret non-targeted analysis data from high-resolution mass spectrometry (HRMS) and apply them to study prenatal exposures to industrial chemicals and endogenous metabolites in a large cohort of pregnant women from Northern California. My proposal builds on my expertise in analytical and environmental chemistry and my current postdoctoral experience in computational chemistry and applications in human exposure. I seek additional training to develop and apply innovative computational methods to better characterize the human exposome and in particular the exposome of preterm birth. The contribution of my proposal will be two-fold: (1) developing novel computational structure-prediction algorithms for HRMS datasets based on MS data and physicochemical properties (equilibrium partition ratios between organic solvents and water, e.g., octanol/water, chlorobenzene/water, diethyl ether/water etc.) (Aim 1) and apply them to derive potential structures for chemical features detected in a HRMS dataset from 340 maternal and 340 matched cord blood samples to complement the limited number of chemicals identified through MS/MS and analytical standards (Aim 2); and (2) study the interplay between the exposome and the metabolome in preterm birth using molecular interaction networks to visualize and compare how molecular interactions between industrial chemicals and endogenous metabolites differ between preterm and full-term birth (Aim 3). The K99 training will expand my prior research experience through coursework, research apprenticeship, and mentored reading, with specific training in: (1) advanced analytical skills including -omics data analysis, machine learning, and biostatistics; (2) epidemiology, risk assessment, human exposure to chemical stressors; and (3) human pregnancy and development. The skills acquired during this award are critical to my long-term goal to advance computational methods to better analyze and interpret non-targeted analysis data to support efforts to better characterize the human exposome. This work will produce new scientific knowledge to greatly advance the understanding of the influence of environmental exposures in the development of adverse health outcomes and in particular, preterm birth. PROJECT NARRATIVE  Advances in high-resolution mass spectrometry (HRMS) offer unique opportunities to study the human exposome and the development of adverse health outcomes. Despite advances in non-targeted analysis, the number of confirmed chemicals remains fairly limited compared to the number of detected chemical features. The goal of this proposal is to develop novel computational methods to derive chemical structures and apply them to a large dataset of HRMS data from blood samples of pregnant women to study the influence of the exposome on pregnancy outcomes with a focus on preterm birth.",Non-target analysis of maternal and cord blood samples: Advancing computational tools and discovering novel chemicals,10191991,K99ES032892,"['Algorithms', 'Analytical Chemistry', 'Area', 'Award', 'Bile fluid', 'Binding', 'Bioinformatics', 'Biological', 'Biological Monitoring', 'Biometry', 'Birth', 'Blood specimen', 'California', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Chlorobenzene', 'Clinical Data', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Endocrine Disruptors', 'Ensure', 'Environmental Exposure', 'Epidemiology', 'Equilibrium', 'Ethyl Ether', 'Exposure to', 'Flame Retardants', 'Goals', 'Health', 'Human', 'Human Development', 'Industrialization', 'Knowledge', 'Liquid Chromatography', 'Low Birth Weight Infant', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mentors', 'Metabolic Diseases', 'Methods', 'Neurodevelopmental Disorder', 'Octanols', 'Organic solvent product', 'Outcome', 'Pathway interactions', 'Pesticides', 'Plasticizers', 'Poly-fluoroalkyl substances', 'Pregnancy', 'Pregnancy Outcome', 'Pregnant Women', 'Premature Birth', 'Property', 'Reading', 'Research', 'Resolution', 'Risk Assessment', 'Sampling', 'Science', 'Stimulus', 'Structure', 'Sum', 'Term Birth', 'Time', 'Toxicity Tests', 'Training', 'Umbilical Cord Blood', 'Water', 'Work', 'advanced analytics', 'apprenticeship', 'base', 'case control', 'cohort', 'computational chemistry', 'computer framework', 'computerized tools', 'data integration', 'developmental toxicity', 'environmental chemistry', 'experience', 'exposed human population', 'human disease', 'in silico', 'innovation', 'insight', 'large datasets', 'machine learning algorithm', 'metabolome', 'metabolomics', 'molecular mass', 'novel', 'prediction algorithm', 'prenatal', 'prenatal exposure', 'psychologic', 'reproductive toxicity', 'response', 'skills', 'small molecule libraries', 'stressor', 'success', 'time of flight mass spectrometry', 'tool']",NIEHS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K99,2021,99848
"ARAGORN: Autonomous Relay Agent for Generation Of Ranked Networks We propose an Autonomous Relay Agent for Generation of Ranked Networks (ARAGORN), which will query Knowledge Providers (KPs) and synthesize answers relevant to user-specified questions, building upon algorithms and components developed as part of the ROBOKOP [1,2] application during the feasibility phase of Translator. The ARAGORN services represent the next generation of ROBOKOP component services, iterating and innovating in response to challenges exposed in the Translator feasibility phase. Based on that work, we have identified overarching issues that must be addressed to truly unleash the power of Translator. 1. ARAs must be able to operate in a federated knowledge environment effectively and efficiently. First-generation Translator tools assembled full data sets from which to extract answers, which were subsequently ranked. Second-generation tools must be able to efficiently operate on massive, distributed data, demanding a new approach. ARAGORN will act asynchronously, interleaving KP queries with partial scoring of answers, prioritizing search directions on-the-fly, and delivering early results that are updated over time in response to newly explored paths 2. ARAs must bridge the precision mismatch between data representations and algorithms that require specificity, and users who pose questions and prefer answers at a more abstract level. Biomedical scientists do not pose questions as database queries. Furthermore, even expert users of current biomedical databases such as ROBOKOP KG or RTX require exploration and experimentation to craft queries to express their intent. ARAGORN will employ multiple strategies to remove this barrier to asking questions effectively, from basic maintenance of a question library, to node generalization, query rewriting, and machine learning techniques such as capsule graph networks. ARAGORN will further use elements of specific answers to create gestalt explanations, clustering, and combining answers with similar content, revealing the commonalities and contradictions in answers. 3. ARAs must be able to generalize answer ranking to address a broader range of question formulations and data types, and to account for counterevidence. In the Translator implementation phase, we anticipate having access to many varied KPs and ARAs that provide diverse quantitative metadata regarding the confidence in assertions or strength of associations. There will be a pressing need to synthesize such data into scores for arbitrarily-shaped answer graphs, in order to filter and prioritize answers for further analysis or user digestion. ARAGORN will address this need by providing a novel scoring algorithm capable of (a) scoring arbitrary directed multi-hypergraphs, (b) accounting for heterogeneous quantitative metadata; and (c) leveraging relationship polarity to incorporate counterevidence. ARAGORN will provide access to this functionality, and connect to KPs using community-defined APIs and data models. The ARAGORN team has contributed to these community efforts during the Translator feasibility phase, and if funded will continue to work with the Standards and Reference Implementations (SRI) group, NCATS staff, and other awardees to continue to define and refine methods and models for data sharing and collaboration. The ARAGORN services will be created with collaboration in mind, such that they can be plugged into larger pipelining and architectural efforts. Most of the risks to the ARAGORN strategy are shared by the entire program; as standardization evolves, the ARAGORN team and other members of the Translator consortium will be required to spend effort updating components. ARAGORN will require access to ontology and similarity tools that we anticipate will be provided by KPs or shared infrastructure; if these do not materialize, the ARAGORN team will create the tools that it needs to accomplish its goals. Additionally, we are assuming the existence of fully translator-compliant KPs from which to draw data; if the program collectively decides that compliance is enforced in ARAs instead, we will draw on our work in ROBOKOP to implement the necessary normalization components in ARAGORN. n/a",ARAGORN: Autonomous Relay Agent for Generation Of Ranked Networks,10332268,OT2TR003441,"['Accounting', 'Address', 'Algorithms', 'Architecture', 'Collaborations', 'Communities', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Digestion', 'Elements', 'Environment', 'Formulation', 'Funding', 'Generations', 'Goals', 'Graph', 'Infrastructure', 'Knowledge', 'Libraries', 'Machine Learning', 'Maintenance', 'Metadata', 'Methods', 'Mind', 'Modeling', 'Ontology', 'Phase', 'Provider', 'Risk', 'Services', 'Specific qualifier value', 'Specificity', 'Standardization', 'Techniques', 'Time', 'Update', 'Work', 'arbitrary spin', 'base', 'biomedical scientist', 'capsule', 'data modeling', 'data sharing', 'database query', 'distributed data', 'innovation', 'member', 'next generation', 'novel', 'novel strategies', 'programs', 'response', 'tool']",NCATS,UNIV OF NORTH CAROLINA CHAPEL HILL,OT2,2021,1052712
"Muscle Control Mechanism of Voice Production in Vocal Fold Paralysis Project Summary After nearly five decades of human voice research, much remains unknown regarding muscle control mechanism of voice production. Studies confirmed that vocal fold pre-phonatory posture (geometry, position, tension and stiffness) is among the primary factors controlling vocal fold vibratory dynamics and voice type. However, very limited data is available on muscle control of these properties, primarily due to experimental difficulties. Muscle control of glottic geometry and dynamics has been studied in in vivo human and animal models, but these studies were limited to an endoscopic superior view, thus cannot to provide 3D deformation/movement of the vocal folds. Moreover, tension and stiffness of the vocal fold tissues are very difficult to obtain in vivo due to a lack of reliable techniques. A significant knowledge gap remains regarding how intrinsic laryngeal muscles (ILMs) control voice production through vocal fold posturing as well as how ILM dysfunctions, such as vocal fold paralysis/paresis (VFP), affect voice production by altering vocal fold posturing. In this project, we propose to use an innovative approach that integrates experimental data and state-of-the-art computer modeling techniques to produce a complete dataset of 3D vocal fold postures (geometry, position, tension, stiffness), 3D vocal fold vibratory dynamics, and voice outcomes in the full muscle control space including symmetric, asymmetric and compensative muscle activations. The PI’s group recently developed a state-of-the-art, physics based, 3D computer model that integrates realistic laryngeal anatomy, physiologically quantifiable inputs, inverse material parameterization and machine learning for simulating vocal fold posturing and flow-structure-acoustics interaction (FSAI) during voice production. For this project, we propose to combine this embodied model with experimental data to generate a holistic view of vocal fold posturing and FSAI with great temporal and spatial details in the full muscle control space. In particular, the model will reveal the 3D complexity of vocal fold postures and vibrations and provide measures of tension and stiffness with muscle activations, which have not been available. We propose to use the dataset to elucidate causal links among muscle activity, vocal fold posturing, vocal fold vibration and voice outcome. Muscle combinations with distinct posturing, vibration and acoustic patterns will be identified. The new knowledge is expected to elucidate the muscle control mechanism of voice production through vocal fold posturing. The proposed work has the potential to improve insight into the function and dysfunction of the ILMs and to serve as a foundation for novel, targeted therapeutic approaches. We hope to develop possible biomechanical metrics for the diagnosis and optimal methodology for treatment of VFP. Project Narrative Vocal fold paralysis/paresis (VFP) is the most common etiology of voice disorders which affects 9% of the U.S. population. Diagnosis and optimal treatment of VFP remain challenging because of incomplete understanding of muscle control mechanism of vocal fold posturing and vibration. This project will build causal links among muscle activation, vocal fold posturing, vocal fold vibration and voice acoustics, allowing for the development of possible biomechanical metrics for diagnosis and optimal treatment of VFP.",Muscle Control Mechanism of Voice Production in Vocal Fold Paralysis,10299679,R15DC019229,"['3-Dimensional', 'Acoustics', 'Affect', 'Anatomy', 'Animal Model', 'Biomechanics', 'Canis familiaris', 'Computer Models', 'Consultations', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dimensions', 'Doctor of Medicine', 'Etiology', 'Financial compensation', 'Foundations', 'Functional disorder', 'Geometry', 'Human', 'Knowledge', 'Laryngeal muscle structure', 'Larynx', 'Link', 'MRI Scans', 'Machine Learning', 'Measures', 'Methodology', 'Modeling', 'Movement', 'Muscle', 'Otolaryngology', 'Outcome', 'Paralysed', 'Paresis', 'Pattern', 'Physics', 'Physiological', 'Population', 'Positioning Attribute', 'Posture', 'Production', 'Property', 'Research', 'Structure', 'Students', 'Techniques', 'Testing', 'Tissues', 'Universities', 'Voice', 'Voice Disorders', 'Work', 'base', 'clinically relevant', 'experimental study', 'human model', 'improved', 'in vivo', 'innovation', 'insight', 'novel', 'optimal treatments', 'professor', 'simulation', 'targeted treatment', 'vibration', 'vocal cord']",NIDCD,UNIVERSITY OF MAINE ORONO,R15,2021,431951
"Investigating the impact and patterns of homologous recombination and adaptive evolution on bacterial genomes Project summary In contract to sexual organisms, the mechanisms of population genetics in bacteria are far less understood. Two fundamental aspects of bacterial population genetics remain sorely understudied: i) the impact of DNA exchange on the evolution of bacterial genomes and populations is largely unknown. ii) the prominence of adaptive evolution has not been comprehensively assessed in bacteria. Determining how recombination and adaptive evolution impact bacteria is key to understand the biology of these organisms and to develop relevant models of their evolution. Although bacteria reproduce clonally, there is increasing evidence that the vast majority of these organisms are capable of homologous recombination by exchanging pieces of DNA in a process similar to gene conversion in animals and plants. This process enhances microbial capacity to adapt to stresses or changing environments and the exchange of DNA between bacterial strains is a major concern for human health as exemplified by the transfer of virulence and antibiotic resistance genes. Despite the central role of this process, the rates and patterns of recombination remain unresolved in bacteria. The extent of recombination often varies greatly from one study to another and, as a result, the same bacterial species can be perceived as clonal in one study and highly recombining in another. In this project, we propose to re-evaluate the landscape of recombination rates and patterns along the genomes of hundreds of bacterial species. Using new methodological frameworks based on Approximate Bayesian Computation and Deep Learning, we will identify the factors shaping the variation in recombination rate across bacteria. We will also uncover recombination rate variation across bacterial chromosomes (i.e. hot spots and cold spots). Our rate estimates will also allow us to study how recombination drives the evolution of genomic architecture of bacteria, including turnover in gene content. Finally, we will quantify the impact of adaptive evolution in bacteria, which may be substantially larger than in other organisms due to large bacterial effective population sizes. We will also investigate the relationship between adaptation and recombination, and identify the genes/pathways responsible for adaptation. In summary, this study will evaluate the rates and patterns of recombination across hundreds of species, determine the factors driving the evolution of the recombination process, reveal the role of adaptive evolution in bacteria, and the interplay between recombination and adaptation. Project narrative Homologous recombination and adaptive evolution are key mechanisms driving bacterial adaptation to new environments and new treatments. The proposed study aims to apply new approaches to determine the rates and patterns of recombination across genomic data in order to identify the factors shaping the rates and landscapes of recombination as well as the impact of adaptive evolution on bacteria. Upon completion, this project will provide a global view of the interplay between recombination and adaptative evolution across hundreds of bacterial species.",Investigating the impact and patterns of homologous recombination and adaptive evolution on bacterial genomes,10135120,R01GM132137,"['Address', 'Affect', 'Animals', 'Antibiotic Resistance', 'Architecture', 'Automobile Driving', 'Bacteria', 'Bacterial Chromosomes', 'Bacterial Genome', 'Bacterial Infections', 'Bayesian Analysis', 'Biology', 'Chromosomes', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Contracts', 'DNA', 'Data Set', 'Ecology', 'Elements', 'Environment', 'Epidemic', 'Evolution', 'Fibrinogen', 'Frequencies', 'Gene Conversion', 'Genes', 'Genetic Models', 'Genetic Recombination', 'Genome', 'Genomics', 'Health', 'Hot Spot', 'Human', 'Individual', 'Knowledge', 'Laboratories', 'Maps', 'Mediating', 'Methodology', 'Methods', 'Modeling', 'Organism', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Prokaryotic Cells', 'Recombinants', 'Role', 'Sampling', 'Shapes', 'Spottings', 'Stress', 'Structure', 'Testing', 'Time', 'Variant', 'Virulence', 'Virulent', 'Work', 'base', 'deep learning', 'gene function', 'genome analysis', 'genomic data', 'high throughput screening', 'homologous recombination', 'innovation', 'large datasets', 'microbial', 'novel strategies', 'resistance gene', 'tool', 'trait']",NIGMS,UNIVERSITY OF NORTH CAROLINA GREENSBORO,R01,2021,289206
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,10240955,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Hi-C', 'Human', 'Human Biology', 'Human Genome', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data infrastructure', 'data integration', 'data standards', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'large scale data', 'member', 'mouse genome', 'multiple data types', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2021,1975273
"Modeling Homeostasis of Human Blood Metabolites PROJECT SUMMARY  Metabolite levels in human blood are regulated by a relatively strict system of homeostatic control. Previous investigations of homeostasis have taken a number of approaches, and models of glucose and a few other metabolites have been developed, typically focused on a single organ. However, while potentially extremely useful, an accurate and quantitative model of blood metabolite levels under homeostasis does not currently exist.  It is well known that numerous demographic and clinical factors such as gender, age, BMI, smoking, etc., as well as pre-analytical factors and many diseases, significantly affect the levels of blood metabolites. Numerous studies in the field of metabolomics have attempted to account for the effects of many such factors. However, efforts to quantify these effects and validate them across different studies have so far been challenging, and resulted in consistent failures to validate discovered putative biomarkers. The challenges to integrate metabolite profiles with clinical and demographic factors are complicated by the high dimensionality of the data and the numerous correlations among the metabolites. Traditional statistical methods are incapable of accounting for these factors, and hence, investigations suffer from a high false discovery rate (FDR).  To overcome these challenges, we propose to develop quantitative statistical models of blood metabolite levels in healthy adults, and thereby produce a predictive model of homeostasis. Our preliminary work indicates that we can predict metabolite levels with much reduced variance using the reproducibly measured levels of a large pool of blood metabolites and clinical and demographic variables. We propose to develop sophisticated models of homeostasis based on advanced statistical methods and evaluate their predictive performance across different sample sets and metabolite classes.  The proposed project has four main Aims: (1) Obtain broad-based metabolomics data on blood samples collected from geographically distinct sites to explore the effects of a range of confounding effects on metabolite levels. (2) Model individual or biologically related groups of metabolite levels using multivariate statistical approaches to determine the contribution of clinical/demographic and pre-analytical variables and their predictability across collection site. (3) Investigate the interactions between metabolites and clinical/demographic variables using machine learning approaches to identify stable metabolites and key interactions. (4) Provide the community with user-friendly software packages for the prediction of blood metabolite levels under homeostasis.  An overall model of the metabolite concentrations in blood will be highly useful for a number of applications that include a better understanding of systems biology at the whole organism level, and ultimately improved risk prediction, disease diagnosis, treatment monitoring and outcomes analysis. PROJECT NARRATIVE A quantitative model of blood homeostasis based on predicting the normal levels of small molecules in the blood can help identify diseases or other stresses that cause changes to those levels. The proposed statistical methods that will be used to develop this homeostasis model have the potential to efficiently identify more reliable disease markers and to more accurately predict disease risk.",Modeling Homeostasis of Human Blood Metabolites,10159296,R01GM131491,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biometry', 'Blood', 'Blood specimen', 'Body mass index', 'Clinical', 'Collection', 'Communities', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Demographic Factors', 'Development', 'Dimensions', 'Disease', 'Disease Marker', 'Evaluation', 'Failure', 'Gases', 'Gender', 'Geographic Locations', 'Geography', 'Glucose', 'Homeostasis', 'Human', 'Individual', 'Investigation', 'Ions', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolite Interaction', 'Modeling', 'Monitor', 'NMR Spectroscopy', 'Organ', 'Outcome', 'Performance', 'Sampling', 'Site', 'Smoking', 'Source', 'Statistical Methods', 'Statistical Models', 'Stress', 'Supervision', 'System', 'Systems Biology', 'Technology', 'Temperature', 'Time', 'Training', 'Validation', 'Whole Organism', 'Work', 'base', 'clinical effect', 'cohort', 'computerized tools', 'data quality', 'disease diagnosis', 'disorder risk', 'improved', 'interoperability', 'lipidomics', 'metabolome', 'metabolomics', 'multidimensional data', 'predictive modeling', 'risk prediction', 'sample collection', 'small molecule', 'software development', 'user friendly software', 'user-friendly', 'validation studies']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2021,376064
"Modeling Homeostasis of Human Blood Metabolites PROJECT SUMMARY  Metabolite levels in human blood are regulated by a relatively strict system of homeostatic control. Previous investigations of homeostasis have taken a number of approaches, and models of glucose and a few other metabolites have been developed, typically focused on a single organ. However, while potentially extremely useful, an accurate and quantitative model of blood metabolite levels under homeostasis does not currently exist.  It is well known that numerous demographic and clinical factors such as gender, age, BMI, smoking, etc., as well as pre-analytical factors and many diseases, significantly affect the levels of blood metabolites. Numerous studies in the field of metabolomics have attempted to account for the effects of many such factors. However, efforts to quantify these effects and validate them across different studies have so far been challenging, and resulted in consistent failures to validate discovered putative biomarkers. The challenges to integrate metabolite profiles with clinical and demographic factors are complicated by the high dimensionality of the data and the numerous correlations among the metabolites. Traditional statistical methods are incapable of accounting for these factors, and hence, investigations suffer from a high false discovery rate (FDR).  To overcome these challenges, we propose to develop quantitative statistical models of blood metabolite levels in healthy adults, and thereby produce a predictive model of homeostasis. Our preliminary work indicates that we can predict metabolite levels with much reduced variance using the reproducibly measured levels of a large pool of blood metabolites and clinical and demographic variables. We propose to develop sophisticated models of homeostasis based on advanced statistical methods and evaluate their predictive performance across different sample sets and metabolite classes.  The proposed project has four main Aims: (1) Obtain broad-based metabolomics data on blood samples collected from geographically distinct sites to explore the effects of a range of confounding effects on metabolite levels. (2) Model individual or biologically related groups of metabolite levels using multivariate statistical approaches to determine the contribution of clinical/demographic and pre-analytical variables and their predictability across collection site. (3) Investigate the interactions between metabolites and clinical/demographic variables using machine learning approaches to identify stable metabolites and key interactions. (4) Provide the community with user-friendly software packages for the prediction of blood metabolite levels under homeostasis.  An overall model of the metabolite concentrations in blood will be highly useful for a number of applications that include a better understanding of systems biology at the whole organism level, and ultimately improved risk prediction, disease diagnosis, treatment monitoring and outcomes analysis. PROJECT NARRATIVE A quantitative model of blood homeostasis based on predicting the normal levels of small molecules in the blood can help identify diseases or other stresses that cause changes to those levels. The proposed statistical methods that will be used to develop this homeostasis model have the potential to efficiently identify more reliable disease markers and to more accurately predict disease risk.",Modeling Homeostasis of Human Blood Metabolites,10372262,R01GM131491,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biometry', 'Blood', 'Blood specimen', 'Body mass index', 'Clinical', 'Collection', 'Communities', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Demographic Factors', 'Development', 'Dimensions', 'Disease', 'Disease Marker', 'Evaluation', 'Failure', 'Gases', 'Gender', 'Geographic Locations', 'Geography', 'Glucose', 'Homeostasis', 'Human', 'Individual', 'Investigation', 'Ions', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolite Interaction', 'Modeling', 'Monitor', 'NMR Spectroscopy', 'Organ', 'Outcome', 'Performance', 'Sampling', 'Site', 'Smoking', 'Source', 'Statistical Methods', 'Statistical Models', 'Stress', 'Supervision', 'System', 'Systems Biology', 'Technology', 'Temperature', 'Time', 'Training', 'Validation', 'Whole Organism', 'Work', 'base', 'clinical effect', 'cohort', 'computerized tools', 'data quality', 'disease diagnosis', 'disorder risk', 'improved', 'interoperability', 'lipidomics', 'metabolome', 'metabolomics', 'multidimensional data', 'predictive modeling', 'risk prediction', 'sample collection', 'small molecule', 'software development', 'user friendly software', 'user-friendly', 'validation studies']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2021,431464
"Tracking the dynamics of how schemas scaffold recall Project Summary Every new experience in our life takes place within the context of familiar environments and situations. However, most research on memory has focused on the artificial memorization of word lists, symbols or pictures; these studies do not meaningfully address how structured prior knowledge about the world (e.g., in the form of a familiar spatial map, or knowledge of how restaurant meals unfold over time) can scaffold new learning. In the proposed studies, I aim to precisely characterize how and where prior knowledge and new information are represented, how they get linked at encoding, and how they interact at recall to allow memories to be retrieved. In the first proposed study of my F99 phase, I test the hypothesis that hippocampal engagement at event boundaries during learning binds new information (i.e. objects) to the scaffold of existing knowledge (i.e. knowledge of a familiar location), and that hippocampal activation during recall mediates the successful retrieval of the bound object from the location in which it was stored. I also test the hypothesis that distinctive representations of spatial locations in the brain will reduce interference between objects stored in those locations. There is a potential downside to using prior knowledge as a scaffold: When there is too much information attached to one part of the scaffold, old and new memories will interfere with each other. How, then, could someone prioritize the retrieval of new memories over older (now-irrelevant) memories that were linked to the scaffold? Recent research on intentional forgetting suggests a solution to this limitation. Specifically, in my second proposed study, I test the hypothesis (supported by neurophysiological evidence, prior neuroimaging results, and computational models) that previously encoded memories can be weakened by moderately activating their neural representation, thereby “cleaning” the scaffold and reducing interference. In the K00 phase, I will extend my research to identify pathologies in how clinical populations use prior knowledge to interpret and remember their experiences, using tools from computational psychiatry; I also plan to design new technological tools to address these issues. Overall, the proposed project makes use of naturalistic and ecologically valid stimuli (in the form of continuous stimuli and immersive virtual reality) paired with advanced machine learning tools applied to brain imaging data, to study the fundamental nature of how new and old information are linked to allow learning. In the long-term, the findings from this project regarding how prior knowledge can be optimally leveraged to support new learning will lead to the development of tools to help memory-impaired individuals make better use of prior knowledge to support new learning, as well as remedies for groups where deficiencies in prior knowledge prevent them from learning properly. Project Narrative In my dissertation, I will use newly-developed machine learning techniques to study how the brain uses prior knowledge (about the spatial structure of an environment, or how certain types of events unfold in time) to scaffold new learning. By precisely characterizing how this scaffolding process works, my research will help to identify ways in which prior knowledge can be more optimally leveraged to support learning. This will lead to the development of tools to help memory-impaired individuals make better use of intact prior knowledge to support new learning, as well as remedies for groups where deficiencies in prior knowledge prevent them from learning properly.",Tracking the dynamics of how schemas scaffold recall,10156352,F99NS120644,"['Address', 'Behavioral', 'Binding', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognitive', 'Computer Models', 'Cues', 'Data', 'Doctor of Philosophy', 'Environment', 'Event', 'Face', 'Functional Magnetic Resonance Imaging', 'General Population', 'Goals', 'Hippocampus (Brain)', 'Human', 'Image', 'Individual', 'Institution', 'Knowledge', 'Lead', 'Learning', 'Life', 'Link', 'Literature', 'Location', 'Machine Learning', 'Maps', 'Mediating', 'Memory', 'Memory impairment', 'Mentors', 'Methods', 'Nature', 'Neurosciences', 'Participant', 'Pathology', 'Perception', 'Performance', 'Phase', 'Play', 'Population', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Psyche structure', 'Psychiatry', 'Research', 'Research Project Grants', 'Restaurants', 'Retrieval', 'Scanning', 'Scientist', 'Self-Help Devices', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Thinking', 'Time', 'Work', 'computerized tools', 'design', 'experience', 'field study', 'forgetting', 'memory encoding', 'memory retrieval', 'neuroimaging', 'neurophysiology', 'phase 1 testing', 'prevent', 'relating to nervous system', 'scaffold', 'skills', 'statistics', 'tool', 'tool development', 'virtual', 'virtual reality', 'virtual reality environment', 'virtual world']",NINDS,PRINCETON UNIVERSITY,F99,2021,47036
"Arizona Technology Development and Clinical Education Program for Students in Kidney Health (ADVANCE Kidney Health) PROJECT SUMMARY  To expand the kidney-related biomedical workforce and counter the increasing disparity between the growing prevalence of renal disease and the disproportionate level of trainees, researchers and practitioners in nephrology and kidney health, we developed the Arizona Technology Development and Clinical Education Program for Students in Kidney Health (ADVANCE Kidney Health). ADVANCE Kidney Health is an education- based, hands-on research, education and clinical experience that applies pillars of 1) science, medical and engineering education; 2) training in innovation, entrepreneurialism and scientific translation; 3) experiential learning, mentorship and clinical immersion; and 4) needs-based application and practical translation – all aimed at producing motivated, trained and committed biomedical trainees interested in renal health and science to advance the workforce and develop the new health-related therapies of the future. The program recruits undergraduate students from across 15 departments within the College of Engineering at the University of Arizona (UArizona) that include: Biomedical Engineering, Electrical and Computer Engineering, Mechanical Engineering and Chemical Engineering. ADVANCE Kidney Health is structured to provide trainees a medical school experience for early-stage undergraduate learners geared to instill an understanding of renal anatomy and kidney function. The core structure accesses a clinical experience to instill a motivation to pursue kidney- related patient care and/or translational research and progresses to an already established innovation bootcamp that culminates in an interdisciplinary capstone that has doubled in size over 10 years and accesses by more than 450 captive engineering students. The program leverages new infrastructure in medical and engineering education along with transdisciplinary programs aimed at innovation, technology development and entrepreneurialism with 15 physician navigators in kidney health and 23 engineering and scientific mentors spanning renal physiology, biomedical engineering, optical sciences and machine learning. The result is an interrelated program that bridges renal medicine, engineering and product development to develop new pipelines and on-ramps to impact career decisions and grow the future kidney-related workforce. PROJECT NARRATIVE  The prevalence of end-stage renal failure (ESRD) has increased ~40% over 20 years, but the kidney-related biomedical workforce has been unable to keep pace. New pathways to a career in nephrology and kidney-related medicine and research are vitally needed that combine early and frequent experiential opportunities to engage in patient-oriented kidney care and contribute to innovative technologies that will one-day change how renal dysfunction is diagnosed and treated. ADVANCE Kidney Health responds to this need by assembling diverse mentors, interdisciplinary infrastructure and novel engineering technologies to impact career trajectories and develop the new technological cures of tomorrow.",Arizona Technology Development and Clinical Education Program for Students in Kidney Health (ADVANCE Kidney Health),10230895,R25DK128859,"['Active Learning', 'Acute Renal Failure with Renal Papillary Necrosis', 'Address', 'Anatomy', 'Arizona', 'Biomedical Engineering', 'Businesses', 'COVID-19', 'Career Mobility', 'Caring', 'Chemical Engineering', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Computers', 'Coupled', 'Critical Thinking', 'Diabetes Mellitus', 'Diagnosis', 'Dialysis procedure', 'Disease', 'Education', 'Elderly', 'Elements', 'End stage renal failure', 'Engineering', 'Faculty', 'Future', 'Generations', 'Growth', 'Health', 'Health Sciences', 'Health Technology', 'Hypertension', 'Immersion', 'Infrastructure', 'Internal Medicine', 'Internships', 'Kidney', 'Kidney Diseases', 'Laws', 'Legal patent', 'Machine Learning', 'Mechanics', 'Medical', 'Medicine', 'Mentors', 'Mentorship', 'Motivation', 'Nephrology', 'Optics', 'Pathway interactions', 'Patient Care', 'Patients', 'Physicians', 'Physiology', 'Population', 'Prevalence', 'Problem Solving', 'Ramp', 'Renal function', 'Research', 'Research Personnel', 'Running', 'Schools', 'Science', 'Scientist', 'Seeds', 'Solid', 'Stimulus', 'Structure', 'Students', 'Technology', 'Technology Transfer', 'Thinking', 'Time', 'Touch sensation', 'Training', 'Translational Research', 'Translations', 'United States', 'Universities', 'base', 'bridge program', 'cancer therapy', 'career', 'career development', 'career preparation', 'cohort', 'college', 'design', 'early experience', 'education research', 'experience', 'fascinate', 'graduate student', 'hands on research', 'innovation', 'innovative technologies', 'interest', 'kidney dysfunction', 'medical schools', 'new technology', 'novel', 'patient oriented', 'product development', 'programs', 'recruit', 'response', 'skills', 'summer research', 'technology development', 'undergraduate education', 'undergraduate student']",NIDDK,UNIVERSITY OF ARIZONA,R25,2021,140400
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10228757,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2021,349146
"Detection and characterization of critical under-immunized hotspots Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots,10197938,R01GM109718,"['Affect', 'Bayesian Method', 'Behavioral Model', 'California', 'Characteristics', 'Communicable Diseases', 'Communities', 'Computer Models', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Disease model', 'Economic Burden', 'Economics', 'Epidemic', 'Epidemiology', 'Exhibits', 'Funding', 'Geography', 'Growth', 'Health', 'Health Personnel', 'Herd Immunity', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Individual', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Measles-Mumps-Rubella Vaccine', 'Medical', 'Methodology', 'Methods', 'Minnesota', 'Modeling', 'New Jersey', 'New York', 'Oregon', 'Outcome', 'Pathway interactions', 'Policies', 'Policy Maker', 'Population', 'Population Analysis', 'Privatization', 'Public Health', 'Records', 'Registries', 'Resolution', 'Resource Allocation', 'Resources', 'Risk', 'Scanning', 'Schools', 'Science', 'Source', 'System', 'Systems Analysis', 'Techniques', 'Time', 'Uncertainty', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Washington', 'Work', 'base', 'data mining', 'demographics', 'diverse data', 'economic cost', 'economic outcome', 'health care delivery', 'health disparity', 'health organization', 'improved', 'interest', 'novel', 'novel strategies', 'population based', 'provider networks', 'public health intervention', 'social', 'social media', 'spatiotemporal', 'statistics', 'tool', 'transmission process', 'vaccine hesitancy']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,321062
"SMART NANPs: new molecular platform for communication with human immune system and modulation of therapeutic responses Principal Investigator/Program Director (Last, First, Middle): Afonin, Kirill, A  PROJECT SUMMARY  What if healthcare providers were equipped with biocompatible, biodegradable, robust, and affordable treatment options that combine therapeutic modalities with controlled mechanisms of action? What if this versatile technology had learning capacity and could be educated to recognize patient-specific diseases and interfere with their progression by redirecting fundamental cellular processes? What if the very same formulation could offer an additional means of control over patients’ immune responses and further advance favorable therapeutic outcomes with minimal toxicities? These next generation therapies would then become a game changer in helping to prevent, detect, diagnose, and treat diseases and disabilities at their source. With the support from MIRA (R35) funding, we envision a data-driven platform, SMART NANPs (specific, modular, adjustable, reproducible, and targeted nucleic acid nanoparticles), encoded by self-assembling nucleic acids. By controlling the flow of genetic information across all forms of life, nucleic acids have become instrumental in acquiring new knowledge about major cellular processes and origins of diseases. Besides their diverse biological roles, these biopolymers can be programmed into NANPs with specified physicochemical properties and functionalities that dictate NANPs’ biological actions with endless possibilities for reprogramming cellular behavior through molecular signaling. We recently discovered that different architectural parameters and compositions of NANPs, delivered to primary human immune cells, can activate monocytes and dendritic cells to produce type I and type III interferons. This pioneering work on NANPs’ immunorecognition highlighted an unforeseen clinical application for this technology in the field of vaccines and immunotherapy. A defined structure-function relationship for any given NANP would then allow conditional actuation of its immunorecognition or any other therapeutic activity through a set of embedded architectural codes. With this notion, we introduced two orthogonal concepts of therapeutic NANPs which can be conditionally activated in human cancer cells to release pre-programmed therapeutics. By uniting these breakthroughs and other preliminary findings from my lab, as highlighted in the current application, and integrating them into a unified network of SMART NANPs with programmable control of biodistribution, immunological activity, and therapeutic modules, we will advance the current repertoire of therapies against infectious diseases and cancers (through NANP-based vaccines and immunotherapies), cardiovascular diseases (through regulated coagulation by thrombin-targeting NANPs), and address drug overdose and safety issues (through the biodegradable nature of NANPs and their controlled deactivation). To maximize the successful translation of this technology, the proposed program will employ a multidisciplinary approach that spans the fields of nucleic acid nanotechnology, immunology, drug delivery, translational oncology, and machine learning. The long-term goal of this program is to elevate SMART NANPs to the level of clinical use. Principal Investigator/Program Director (Last, First, Middle): Afonin, Kirill, A PROJECT NARRATIVE  Beyond their traditionally known roles as carriers and regulators of genetic information, nucleic acids have auspiciously emerged as versatile therapies for taking advantage of cellular pathways to drive the sensing, targeting, and silencing of a variety of diseases. With MIRA support, we will explore additional nanotechnology- based therapeutic options that enlist a biocompatible nucleic acid-encoded platform (SMART NANPs) for the controlled immunostimulation and modulation of therapeutic responses. This research program aims to advance the envisioned technology towards personalized medicine and aid in addressing top public health challenges in the U.S. as they relate to cancer (through vaccines and immunotherapies), cardiovascular diseases (through regulated coagulation), and drug overdose and safety (through the biodegradable nature of the platform and its functional regulation).",SMART NANPs: new molecular platform for communication with human immune system and modulation of therapeutic responses,10086567,R35GM139587,"['Address', 'Architecture', 'Biodistribution', 'Biological', 'Biopolymers', 'Cardiovascular Diseases', 'Cell physiology', 'Cells', 'Clinical', 'Coagulation Process', 'Code', 'Communicable Diseases', 'Communication', 'Data', 'Dendritic Cells', 'Diagnosis', 'Disease', 'Drug Delivery Systems', 'Formulation', 'Funding', 'Goals', 'Health Personnel', 'Human', 'Immune', 'Immune response', 'Immune system', 'Immunization', 'Immunologics', 'Immunology', 'Immunotherapy', 'Interferons', 'Knowledge', 'Learning', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Modality', 'Molecular', 'Nanotechnology', 'Nature', 'Nucleic Acids', 'Oncology', 'Overdose', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Principal Investigator', 'Property', 'Public Health', 'Regulation', 'Reproducibility', 'Research', 'Role', 'Safety', 'Signal Transduction', 'Source', 'Specific qualifier value', 'Structure-Activity Relationship', 'Technology', 'Therapeutic', 'Thrombin', 'Toxic effect', 'Translations', 'Vaccines', 'Work', 'base', 'biomaterial compatibility', 'cancer cell', 'cell behavior', 'clinical application', 'disability', 'genetic information', 'immunoregulation', 'interdisciplinary approach', 'monocyte', 'nanoparticle', 'next generation', 'personalized medicine', 'prevent', 'programs', 'therapy outcome', 'treatment response']",NIGMS,UNIVERSITY OF NORTH CAROLINA CHARLOTTE,R35,2021,141556
"Nathan Shock Center for Excellence in Basic Biology of Aging OVERALL—PROJECT SUMMARY Healthspan is a complex trait, influenced by many interacting polymorphic alleles and environmental factors that may accelerate or delay aging, reduce or increase disease risk, and/or promote extended lifespan. Thus, assessing the role of genetic variation in aging requires an experimental strategy capable of modeling the genetic and biological complexity of human populations while allowing for efficient identification and validation of candidate genes. With this proposal, the JAX NSC seeks support to further develop and disseminate the next generation of genetic, phenotyping, and information resources necessary to enable a systems-wide approach to understanding healthy aging. Over the past 15 years, The JAX NSC has transformed aging research both at JAX and across the geroscience community, providing central resources to support investigators that have resulted in 26 peer-reviewed publications in the last funding period. The Center has developed nascent regional and national resources for aging research, including aging mouse resources and tissues that support our numerous collaborations and external researchers. All JAX NSC data and tools are publicly disseminated on the Mouse Phenome Database and the JAX NSC website, thus ensuring that the resources generated and expertise acquired through the Center is readily available to the aging research community. In this renewal, we will advance towards our goal by providing unique resources, tools, and support to geroscience investigators while leveraging JAX's unparalleled expertise in the large-scale identification and functional validation of complex polygenic traits in mice. We will do this by providing effective Center administration and enhancing the utility of JAX NSC resources throughout the aging community (Aim 1); expanding the research focus on aging, healthspan and age-related diseases through a robust Research Development Core (Aim 2); increasing the diversity of mouse resources available for aging research, including a new study to, for the first time, investigate the effect of genetic variation on cellular senescence and treatment with senolytic drugs (Aim 3); strengthening the data and computational and support available to the aging community (Aim 4); expanding the use of machine learning technologies in interpretation of aging pathologies (Aim 5). The Center will be led by a highly experienced team of Principal Investigators and Core Leaders who, with oversight from an External Advisory Board, will provide effective management to facilitate the goals and objectives of the Center. The Center will leverage unparalleled institutional resources, facilities and expertise of The Jackson Laboratory, a globally renowned institution for mouse genetics research, to enhance its goals and the utility of the resources it generates for the aging research community. OVERALL—PUBLIC HEALTH RELEVANCE Human aging is influenced by genetic factors, whereby differences in longevity as well as changes in health and disease risk with time are linked to variation in individuals' genetic codes. The Jackson Laboratory Nathan Shock Center will develop resources to encourage the use of a wider range of mouse models in aging research. Resources—including aged mouse models that mirror human genetic variation, metabolic and microbiome data, and methods to reveal genetic factors tied to human aging—will be available to the scientific community, accelerating research to understand and ultimately prolong healthy human aging.",Nathan Shock Center for Excellence in Basic Biology of Aging,10261436,P30AG038070,"['Advisory Committees', 'Aging', 'Alleles', 'Animals', 'Biological', 'Biology of Aging', 'Candidate Disease Gene', 'Cell Aging', 'Collaborations', 'Communities', 'Complex', 'Computer Assisted', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Educational workshop', 'Ensure', 'Environmental Risk Factor', 'Funding', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Models', 'Genetic Research', 'Genetic Variation', 'Geroscience', 'Goals', 'Health', 'Heart', 'Histologic', 'Human', 'Human Genetics', 'Image Analysis', 'Inbred Strain', 'Individual', 'Information Resources', 'Institution', 'Joints', 'Laboratories', 'Leadership', 'Link', 'Liver', 'Longevity', 'Lung', 'Machine Learning', 'Maps', 'Mentorship', 'Metabolic', 'Methods', 'Mus', 'Pathology', 'Peer Review', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Pilot Projects', 'Polygenic Traits', 'Population', 'Principal Investigator', 'Process', 'Protocols documentation', 'Publications', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Shock', 'Statistical Methods', 'Structure', 'System', 'Technology', 'The Jackson Laboratory', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Validation', 'Variant', 'Visit', 'age related', 'aged', 'animal tissue', 'behavioral phenotyping', 'candidate validation', 'career development', 'data dissemination', 'data management', 'data tools', 'disorder risk', 'experience', 'healthspan', 'healthy aging', 'insight', 'microbiome', 'mouse genetics', 'mouse model', 'next generation', 'novel', 'open source', 'phenome', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'senescence', 'symposium', 'tool', 'trait', 'user-friendly', 'web site']",NIA,JACKSON LABORATORY,P30,2021,1069526
"Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design PROJECT SUMMARY/ABSTRACT The study of biomolecular interactions and design of new therapeutics requires accurate physical models of the atomistic interactions between small molecules and biological macromolecules. Over the least few decades, molecular mechanics force ﬁelds have demonstrated the potential that physical models hold for quantitative biophysical modeling and predictive molecular design. However, a signiﬁcant technology gap exists in our ability to build force ﬁelds that achieve high accuracy, can be systematically improved in a statistically robust manner, be extended to new areas of chemistry, can model post-translational and covalent modiﬁcations, are able to quantify systematic errors in predictions, and can be broadly applied across a high-performance software packages. In this project, we aim to bridge this technology gap to enable new generations of accurate quantitative biomolec- ular modeling and (bio)molecular design for chemical biology and drug discovery. In Aim 1, we will produce a modern, open infrastructure to enable practitioners to rapidly and conveniently construct and employ accurate and statistically robust physical force ﬁelds via automated machine learning methods. In Aim 2, we will construct open, machine-readable experimental and quantum chemical datasets that will accelerate next-generation force ﬁeld development. In Aim 3, we will develop statistically robust Bayesian inference techniques to enable the auto- mated construction of type assignment schemes that avoid overﬁtting and selection of physical functional forms statistically justﬁed by the data. This approach will also provide an estimate of the systematic error in predicted properties arising from uncertainty in parameters or functional form choices—generally the dominant source of error—to be quantiﬁed with little added expense. In Aim 4, we will integrate and apply this infrastructure to produce open, transferable, self-consistent force ﬁelds that achieve high accuracy and broad coverage for modeling small molecule interactions with biomolecules (including unnatural amino or nucleic acids and covalent modiﬁcations by organic molecules), with the ultimate goal of covering all major biomolecules. This research is signiﬁcant in that the technology developed in this project has the potential to radically transform the study of biomolecular phenomena by providing highly accurate force ﬁelds with exceptionally broad chemical coverage via fully consistent parameterization of organic (bio)molecules. In addition, we will produce new tools to automate force ﬁeld creation and tailoring to speciﬁc problem domains, quantify the systematic error in predictions, and identify new data for improving force ﬁeld accuracy. This will greatly improve our ability to study diverse biophysical processes at the molecular level, and to rationally design new small-molecule, protein, and nucleic acid therapeutics. This approach will bring statistical rigor to the ﬁeld of force ﬁeld construction and application by providing a means to make data-driven decisions, while enhancing reproducibility by enabling it to become a rigorous and reproducible science using a fully open infrastructure and datasets. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life do their jobs. They also use simulations to help design new medications – compounds that can bind and inﬂuence the behavior of these molecules of life, and thereby block diseases at the molecular level. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms.",Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design,10105344,R01GM132386,"['Address', 'Area', 'Automobile Driving', 'Bayesian Analysis', 'Binding', 'Biological', 'Biology', 'Biophysical Process', 'Biophysics', 'Charge', 'Chemicals', 'Chemistry', 'Complex', 'Computer Simulation', 'Computer software', 'DNA', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Design', 'Electrostatics', 'Ensure', 'Error Sources', 'Generations', 'Goals', 'Heart', 'Individual', 'Infrastructure', 'Investigation', 'Learning', 'Life', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Molecular', 'Nucleic Acids', 'Occupations', 'Perception', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Property', 'Proteins', 'RNA', 'Readability', 'Reproducibility', 'Research', 'Roentgen Rays', 'Scheme', 'Science', 'Scientist', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Technology', 'Temperature', 'Therapeutic', 'Thermodynamics', 'Training', 'Uncertainty', 'Validation', 'Work', 'base', 'behavior influence', 'biophysical model', 'chemical synthesis', 'cheminformatics', 'data infrastructure', 'design', 'drug discovery', 'experience', 'experimental study', 'improved', 'interest', 'machine learning method', 'macromolecule', 'models and simulation', 'molecular mechanics', 'multidisciplinary', 'new technology', 'next generation', 'novel therapeutics', 'nucleic acid-based therapeutics', 'open data', 'open source', 'physical model', 'physical property', 'quantum', 'simulation', 'simulation software', 'small molecule', 'software infrastructure', 'sound', 'tool', 'unnatural amino acids']",NIGMS,UNIVERSITY OF COLORADO,R01,2021,608856
"Pan-vaccine Analysis to Test the Impact of Cytomegalovirus on Vaccine Efficacy PROJECT SUMMARY/ABSTRACT Cytomegalovirus (CMV) infects around 50% of the US population. Even though the CMV exists in a latent state in healthy individuals, it profoundly shapes the immune system. Recent studies suggest that the CMV infection alters the immune response to influenza vaccine. However, the exact effect of CMV on the efficacy of the influenza vaccine remains controversial. In addition, how CMV shapes the immune responses toward other vaccines are unknown. We hypothesize that latent CMV infection induces critical changes in the immune system, which alters the efficacy of multiple types of vaccines. The ImmPort database currently hosts 133 vaccine studies, covering 21 types of vaccines, creating an unprecedented opportunity for us to test our hypothesis. We will perform a comprehensive meta-analysis to test the relationship between CMV and vaccine efficacies, and will use state-of-art statistical models (e.g., Dynamic Bayesian Network) to identify the mechanism by which CMV alters the vaccine response. Leveraging the group's expertise in computational immunology and rich datasets on ImmPort, we will address the following aims. Aim1: Test the effect of CMV on influenza vaccine outcome. We will perform a meta-analysis of 60 influenza studies available on ImmPort to test the impact of CMV. We will quantify and standardize the efficacy of influenza vaccine across studies, which are measured by hemagglutinin inhibition (HAI) assays before and after the vaccination. We will also determine the CMV infection status in subjects, either directly from serological tests or indirectly from immune- phenotyping data using cutting-edge machine learning tools. We will then test if CMV increases the response to influenza vaccine by analyzing data from all studies in a unified statistical framework while taking the heterogeneity between studies into account. Aim2: Bayesian network analysis of influenza vaccine response. We will harmonize multimodal immune-phenotyping data from the influenza vaccine studies, including transcriptomics data, cytometry data, and cytokine measurements. We will use state-of-art network analysis methods (e.g., Dynamic Bayesian network) to model the interplay between the immune components over time. Using the Bayesian network, we will investigate the mechanism by which CMV shapes the outcome of influenza vaccination. Aim3: Explore the effect of CMV infection on other vaccines. We will extend our analysis to vaccines other than influenza vaccine, (e.g., West Nile, Hepatitis B, yellow fever, malaria, and Tuberculosis). We will quantify the vaccine efficacy using assays specific to the vaccine type, such as Controlled Human Malaria Infection (CHMI) for the malaria vaccine and Plaque Reduction Neutralization Test for the yellow fever vaccine. We will perform separate network analyses to characterize the relationship between CMV and the immune response of individual vaccines. We will then perform joint analysis across vaccine types to identify the common impact of CMV across vaccine types. PROJECT NARRATIVE Infectious diseases remain an urgent problem, resulting in an estimated 3 million deaths worldwide and more than 110,000 deaths in the United States annually, but the efficacy of vaccines against many infectious diseases remains suboptimal, including malaria, influenza, and dengue. To improve the vaccines, it is crucial to understand the factors that affect the immune response toward vaccines. In this study, we investigate how cytomegalovirus affects the efficacy of multiple vaccines, providing valuable information for improving the design of vaccines.",Pan-vaccine Analysis to Test the Impact of Cytomegalovirus on Vaccine Efficacy,10171553,UH2AI153016,"['Address', 'Affect', 'Bayesian Analysis', 'Bayesian Modeling', 'Bayesian Network', 'Biological Assay', 'Cells', 'Cessation of life', 'Communicable Diseases', 'Communities', 'Computer Models', 'Cytomegalovirus', 'Cytomegalovirus Infections', 'Cytomegalovirus Vaccines', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dengue', 'Diagnosis', 'Disease', 'Goals', 'Hemagglutinin', 'Hepatitis', 'Hepatitis B', 'Herpesviridae', 'Heterogeneity', 'Human', 'Immune', 'Immune response', 'Immune system', 'Immunology', 'Individual', 'Influenza', 'Influenza vaccination', 'Joints', 'Knowledge', 'Machine Learning', 'Malaria', 'Malaria Vaccines', 'Measurement', 'Measures', 'Meta-Analysis', 'Methods', 'Modeling', 'Neutralization Tests', 'Outcome', 'Outcome Measure', 'Pathway Analysis', 'Population', 'Research', 'Research Personnel', 'Resources', 'Serology test', 'Shapes', 'Standardization', 'Statistical Models', 'Testing', 'Time', 'Tuberculosis', 'United States', 'Vaccination', 'Vaccine Design', 'Vaccines', 'Validation', 'Virus', 'Virus Latency', 'West Nile virus', 'Yellow Fever', 'Yellow Fever Vaccine', 'cytokine', 'design', 'improved', 'individual response', 'influenza virus vaccine', 'malaria infection', 'multimodality', 'network models', 'pathogen', 'phenotypic data', 'response', 'tool', 'transcriptomics', 'vaccine efficacy', 'vaccine response', 'vaccine trial']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",UH2,2021,201875
"Monitoring mosquito eco-systems and vector-control strategies using a stand-off optical sensor. Monitoring mosquito ecosystems and vector-control strategies using a stand-off optical sensor.  PI: B. Thomas – NIH R21 Project Summary:  Vector control strategies remain one of the most effective ways to protect human populations from the large number of mosquito borne diseases such as malaria, dengue fever, zika virus, or West Nile virus. Mosquito populations are generally monitored using physical traps, however this method suffers from many disadvantages. It requires long and expensive laboratory analysis by qualified personnel which drastically reduces the number of observed insects as well as time of trap deployment. Traps also provide a poor estimate of the actual population size or population density because the attractive range of traps is generally unknown and may change with weather conditions. These limitations are strong drawbacks in our ability to evaluate the effectiveness of various types of vector-control strategies (chemicals, biological, environmental modifications etc.). Inferior methods are not necessarily identified which ultimately contributes to the spread of infectious diseases. In this context, we argue that new methodologies to monitor insect population dynamics is key in the necessary effort to improve control program performance.  A team from the New Jersey Institute of Technology in collaboration with the Hudson Mosquito Program seeks support to carry out a series of field experiments using a new optical sensor capable of identifying in real-time the family, species, and gender of mosquitoes in its field of view. The laser-based instrument is a dual-wavelength polarization-sensitive stand-off sensor. For each flying insect transiting through the infrared laser beams, the sensor can retrieve the optical properties of the wings and body of the insect as well as its wing beat frequency. Preliminary data from a laboratory prototype and numerical simulations indicate that the instrument, using a supervised machine learning classifier, can identify the species, gender, and gravidity of mosquitoes up to 300 m away. The instrument will be deployed in a high mosquito density area in New Jersey to continuously monitor the mosquito population over the whole season from April to October 2021. Continuous measurements will allow to identify a number of insects that is orders a magnitude higher than physical traps. As the probed volume of air is known, data analysis will provide the population density for each class of insects from which the population dynamics will be derived. In addition, the time and date of each insect transit allow to study the circadian rhythm, peak activities, and behavior as a function of atmospheric conditions measured by a weather station. In 2022, a similar experiment will be conducted at the same location while the Hudson Mosquito Program will conduct a vector control campaign targeting Culex and Aedes mosquitoes, both responsible for the spread of various infectious diseases. The impact of multiple applications of airborne pyrethroid insecticide on targeted and non-targeted insects will be evaluated by studying the mortality rates and population dynamics for each species. Both years, the data will be compared to physical traps on site, the current gold standard method, for further analysis and validation. Project Narrative  Mosquito-borne diseases are a major challenge for Human health as they affect nearly 700 million people every year and result in close to one million deaths; however, lack of reliable data on mosquito populations has become a serious obstacle to evaluate the effectiveness of vector control programs. The proposed study will make use of a new methodology based on applied optics to remotely count and identify in real-time the species and sex group of flying mosquitoes in their natural habitat. This novel methodology will be used to evaluate the impact of insecticide applications on the population dynamics of key vector of infectious diseases.",Monitoring mosquito eco-systems and vector-control strategies using a stand-off optical sensor.,10215105,R21AI153732,"['Aedes', 'Affect', 'Air', 'Area', 'Behavior', 'Biological', 'Cessation of life', 'Chemicals', 'Circadian Rhythms', 'Collaborations', 'Communicable Diseases', 'Controlled Environment', 'Culex (Genus)', 'Culicidae', 'Data', 'Data Analyses', 'Dengue Fever', 'Development', 'Disadvantaged', 'Ecosystem', 'Effectiveness', 'Event', 'Evolution', 'Family', 'Female', 'Flying body movement', 'Frequencies', 'Gender', 'General Population', 'Gold', 'Gravidity', 'Habitats', 'Health', 'Human', 'Human Resources', 'Inferior', 'Insecta', 'Insecticides', 'Institutes', 'Knowledge', 'Laboratories', 'Lasers', 'Location', 'Malaria', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modification', 'Monitor', 'Mosquito-borne infectious disease', 'New Jersey', 'Noise', 'Optics', 'Outcome', 'Output', 'Performance', 'Periodicity', 'Population', 'Population Density', 'Population Dynamics', 'Population Sizes', 'Price', 'Property', 'Research', 'Residual state', 'Resolution', 'Seasons', 'Series', 'Signal Transduction', 'Site', 'System', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Validation', 'Weather', 'West Nile virus', 'Wing', 'Zika Virus', 'atmospheric conditions', 'base', 'density', 'effectiveness evaluation', 'efficacy evaluation', 'egg', 'experimental study', 'improved', 'instrument', 'learning classifier', 'mortality', 'novel', 'optical sensor', 'programs', 'prototype', 'pyrethroid', 'rate of change', 'sensor', 'sex', 'simulation', 'supervised learning', 'vector', 'vector control']",NIAID,NEW JERSEY INSTITUTE OF TECHNOLOGY,R21,2021,187106
"The Network for Investigation of Delirium: Unifying Scientists (NIDUS)'s 9th-13th Annual Delirium Boot Camps: A Foundation for Future Exploration Delirium is a serious cognitive disorder associated with Alzheimer’s disease and related dementias (ADRD) that affects ~2.6 million older adults yearly. It is a frequent complication of acute illness, surgery and, now, of COVID-19 infection in older adults. Recognizing the relative dearth of delirium research, the National Institute for Aging (NIA) supported the establishment of the Network for Investigation of Delirium: Unifying Scientists (NIDUS), a collaborative interdisciplinary group of 28 investigators, from 27 institutions, to advance delirium research and develop network infrastructure. This included the creation of an annual “NIDUS bootcamp” conference, to bring together the growing national- and international delirium research community for networking and education. The bootcamp aims are to advance the science of the field and to provide junior investigators with intensive mentorship, through mock NIH application reviews, clinical and research lectures, breakout sessions, and post-bootcamp networking. Bootcamp alumni are provided guidance on: 1) using the NIDUS Delirium Research Hub, Measurement resources and Bibliography, 2) submitting proposals to the NIDUS Pilot Program (13 one-year $50,000 grants awarded), NIA GEMSSTAR/CLINSTAR, the Alzheimer’s Association, and other foundations, 3) attending Mentoring webinars, 4) participating in Junior Faculty Working Groups, and 5) submitting research abstracts to the American Delirium Society (ADS) Annual Meeting. As PIs, 94 alumni have received 46 grants, of which 18 (40%) were NIH-funded, and published 265 original peer- reviewed articles. NIDUS has jumpstarted the careers of many young investigators, particularly bootcamp alumni, enabling them to launch independent programs in delirium research. The goal of this application is to support continuation of a yearly, themed Delirium Bootcamp Conference (DBC), to ensure that the progress of this active research community is sustained. The first-year theme will be the inter-relationship between delirium and ADRD. The Specific Aims are to: (1) Engage and support junior investigators in delirium research through mentorship and access to the NIDUS resources/network (2) Boost the researchers’ funding success (3) Facilitate publication of delirium research and provide ongoing mentorship, and (4) Facilitate networking among junior, mid-career, and senior researchers during and after DBC. As the pool of delirium investigators expands, there is a critical need for a conference focused on addressing cutting-edge research methods in all areas of delirium research, including the relationship with ADRD, “-Omics” research, machine learning and big data, innovations in randomized trials, animal models and mechanistic research, and clinical practice improvement. The DBC will provide an unparalleled opportunity to advance cutting-edge delirium research through interactive didactic sessions and in-depth guidance on complex and nuanced research methods essential for the highest caliber and most impactful delirium research. Delirium is a serious, yet understudied, cognitive disorder that affects millions of elder Americans, and is closely related to Alzheimer’s disease and related dementias (ADRD). The NIA-supported (2015-2020) Network for Investigation of Delirium Unifying Scientists (NIDUS), a collaborative international network of delirium investigators, developed a successful, annual “NIDUS Bootcamp” conference, laying the foundation for this proposal. The new Delirium Bootcamp (DBC) will convene junior investigators and senior faculty in an annual conference with innovations including: 1) a new thematic focus each year, with the 2021 theme highlighting ADRD; 2) focus on high-impact, state-of-the-art methodologies to advance the field in new directions; 3) finding optimal methods to address the unique challenges of delirium research, and 4) developing collaborative interdisciplinary papers to be initiated at the DBC and completed in ongoing groups; thus, fostering the training, career development and success of the next generation of delirium investigators.",The Network for Investigation of Delirium: Unifying Scientists (NIDUS)'s 9th-13th Annual Delirium Boot Camps: A Foundation for Future Exploration,10237513,R13AG072860,"['Acute', 'Acute Disease', 'Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'American', 'Animal Model', 'Area', 'Attention', 'Award', 'Bibliography', 'Big Data', 'COVID-19', 'Caliber', 'Clinical', 'Clinical Research', 'Cognition', 'Cognition Disorders', 'Collaborations', 'Communities', 'Community Networks', 'Complex', 'Complication', 'Delirium', 'Discipline', 'Education', 'Elderly', 'Ensure', 'Epidemiology', 'Faculty', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Grant', 'Health Expenditures', 'Infrastructure', 'Institution', 'International', 'Investigation', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurement', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Monoclonal Antibody R24', 'National Institute on Aging', 'Network Infrastructure', 'Operative Surgical Procedures', 'Paper', 'Participant', 'Peer Review', 'Pilot Projects', 'Public Health', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'SARS-CoV-2 infection', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Societies', 'Study Section', 'Training', 'United States National Institutes of Health', 'Writing', 'career', 'career development', 'clinical practice', 'cost', 'innovation', 'interdisciplinary collaboration', 'lectures', 'meetings', 'multidisciplinary', 'neglect', 'next generation', 'patient population', 'peer', 'programs', 'randomized trial', 'response', 'secondary analysis', 'senior faculty', 'skill acquisition', 'success', 'support network', 'symposium', 'systematic review', 'webinar', 'working group']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,R13,2021,50000
"Evaluation of multiple medication exposures concurrently using a novel algorithm PROJECT SUMMARY The development of large observational health databases (OHD) has expanded the data available for analysis by pharmacoepidemiology research. The efficiency of these studies may be improved by simultaneously studying the association of multiple medications with a disease of interest. Unfortunately, prior research has demonstrated that it is difficult to distinguish true-positive from false-positive results when studying multiple exposures simultaneously, thus limiting the conclusions drawn from these types of studies and representing a major gap in the field. The objective of this proposal, which is the first step in achieving the applicant's long- term goal of improving the diagnosis and treatment of gastrointestinal diseases using insights derived from OHD, is to evaluate and validate medication class enrichment analysis (MCEA), a novel set-based signal-to- noise enrichment algorithm developed by the applicant to analyze multiple exposures from OHD with high sensitivity and specificity. The central hypothesis of this proposal is that MCEA has equal sensitivity and greater specificity compared to logistic regression, the most widely used analytic method for OHD, for identifying true associations between medications and clinical outcomes. The applicant will complete the following two interrelated specific aims to test the hypothesis: Aim 1 – to calculate the sensitivity and specificity of medication class enrichment analysis (MCEA) and logistic regression (LR) for identifying medication associations with Clostridium difficile infection (CDI) and Aim 2 – to calculate the sensitivity and specificity of MCEA and LR for identifying medication associations with gastrointestinal hemorrhage (GIH). The rationale for these aims is that by reproducing known medication-disease associations without false positives, MCEA can be used to identify novel pharmacologic associations with gastrointestinal diseases in future studies. The expected outcome for the proposed research is that it will demonstrate MCEA as a valid method for pharmacoepidemiology research, opening new research opportunities for the study of multi-exposure OHD. These new research opportunities may lead to more rapid identification of potential pharmacologic causes of emerging diseases and discovery of unanticipated beneficial medication effects, allowing such medications to be repurposed for new indications. To attain the expected outcome, the applicant will complete additional coursework that builds on his Master of Science in Clinical Epidemiology to learn computational biology, machine learning, and econometrics techniques. With the support of this grant and his institution, he will also directly apply these techniques to pharmacoepidemiology applications under the close mentorship of a carefully selected team of faculty with extensive experience in gastroenterology, pharmacoepidemiology, medical informatics, and mentoring prior K-award grant recipients. Through these activities, the applicant will develop the skills necessary to obtain NIH R01-level funding and become a leader in developing novel techniques for application to the epidemiologic study of gastrointestinal diseases. PROJECT NARRATIVE Traditionally, research studying medications associated with diseases are limited to analyzing one medication at a time. This novel proposal will validate medication class enrichment analysis, a recently developed algorithm to study multiple medications simultaneously for association with a disease of interest. Validation of this method will allow researchers to use existing medical databases to more rapidly identify potential medication causes of emerging diseases and identify medications with unanticipated beneficial effects, allowing such medications to be repurposed for new indications.",Evaluation of multiple medication exposures concurrently using a novel algorithm,10128442,K08DK119475,"['Address', 'Algorithms', 'Aminoglycosides', 'Antibiotics', 'Anticoagulants', 'Antiplatelet Drugs', 'Big Data to Knowledge', 'Biological', 'Carbapenems', 'Case-Control Studies', 'Cephalosporins', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Computational Biology', 'Computer software', 'Data', 'Databases', 'Development', 'Development Plans', 'Diagnosis', 'Digestive System Disorders', 'Disease', 'Electronic Health Record', 'Epidemiologic Methods', 'Evaluation', 'Faculty', 'Fluoroquinolones', 'Funding', 'Future', 'Gastroenterology', 'Gastrointestinal Diseases', 'Gastrointestinal Hemorrhage', 'Generations', 'Genomics', 'Goals', 'Grant', 'Health', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'K-Series Research Career Programs', 'Lead', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Master of Science', 'Medical', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Noise', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Penicillins', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacology', 'Research', 'Research Design', 'Research Personnel', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Techniques', 'Testing', 'Time', 'United Kingdom', 'United States Department of Veterans Affairs', 'United States National Institutes of Health', 'Validation', 'analytical method', 'base', 'beta-Lactams', 'career development', 'clinical epidemiology', 'econometrics', 'epidemiology study', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'interest', 'novel', 'research study', 'simulation', 'skills', 'usability']",NIDDK,UNIVERSITY OF PENNSYLVANIA,K08,2021,167900
"Systems biology frameworks to unravel mechanisms driving complex disorders Project Summary/Abstract This application proposes a training program to integrate the PI, Dr. Varadan's previous research efforts in informatics and machine learning into investigations pertaining to the etiology and progression of Barrett's Esophagus, a gastrointestinal disorder of significant public health interest. Much of Dr. Varadan's previous research has involved developing intelligent algorithms and informatics approaches to decode the interconnections within complex biological systems, with only a basic understanding of the clinical needs and complexities involved in translational research. The proposed project would provide a broad and in-depth mentored experience focused on clinical and biological aspects of Barrett's Esophagus, as well as added knowledge in the use of preclinical model systems to investigate biological mechanisms. The overall goal is to expand the PI's experience and training in the design and conduct of translational studies focused on gastrointestinal (GI) diseases. This objective will be achieved through a combination of didactic and research activities conducted under an exceptional mentoring team of translational researchers at Case Western Reserve University, spanning achievements across clinical management of GI disorders, molecular genetics and inflammatory processes associated with diseases of the gut. Accordingly, this proposal leverages Dr. Varadan's computational background to address an urgent and unmet need within the biomedical research community to develop reliable analytic approaches that can quantify signaling network activities in individual biological samples by integrating multi-omics measurements. We recently conceived a systems biology computational framework, InFlo, which integrates molecular profiling data to decode the functional states of cellular/molecular processes underpinning complex human diseases. Barrett's esophagus is one such complex disease gaining increasing importance to public health, as it is the known precursor to the deadly cancer, esophageal adenocarcinoma. Given that the mechanisms underlying the etiology and pathogenesis of Barrett's Esophagus remain elusive, a major objective of this proposal is to employ the InFlo framework combined molecular profiles derived from primary tissue cohorts, in vitro and in vivo model systems to establish the molecular roadmap of BE pathogenesis and disease recurrence, thus elucidating unifying mechanisms underlying this disease. This systems biology approach would enable the development of evidence-based, diagnostic/prognostic biomarkers for Barrett's esophagus and inform preventive strategies within at-risk populations. Project Narrative This proposal details a novel systems biology approach to enable seamless integration of patient molecular data to decipher the mechanisms underlying complex human diseases. Using this novel integrative analytics approach, we propose to resolve the molecular basis for the development and recurrence of Barrett's Esophagus, a disease with significant public health importance, since it is a known precursor to a lethal esophageal cancer and the mechanisms underpinning this disease remain largely unknown. The findings from our proposed research will enable the development of new diagnostic and prognostic biomarkers and will also inform preventive strategies in high-risk patient populations.",Systems biology frameworks to unravel mechanisms driving complex disorders,10086862,K25DK115904,"['3-Dimensional', 'Ablation', 'Achievement', 'Address', 'Automobile Driving', 'Award', 'Barrett Esophagus', 'Biological', 'Biological Models', 'Biomedical Research', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Clinical', 'Clinical Management', 'Columnar Epithelium', 'Communities', 'Competence', 'Complex', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Electrical Engineering', 'Ephrins', 'Epithelial', 'Esophageal Adenocarcinoma', 'Esophageal Tissue', 'Esophagitis', 'Esophagus', 'Etiology', 'Event', 'Exhibits', 'Follow-Up Studies', 'Gastrointestinal Diseases', 'Gene Expression', 'Gland', 'Goals', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Informatics', 'Injury', 'Interleukin-1 beta', 'Investigation', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Maps', 'Measurement', 'Mentors', 'Modeling', 'Molecular', 'Molecular Abnormality', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mucous Membrane', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Populations at Risk', 'Pre-Clinical Model', 'Prevention strategy', 'Process', 'Prognostic Marker', 'Proliferating', 'Proteins', 'Public Health', 'Recurrence', 'Research', 'Research Activity', 'Risk', 'Risk Factors', 'Sampling', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Squamous Epithelium', 'Stomach', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Training Programs', 'Transgenic Mice', 'Translational Research', 'Universities', 'Validation', 'base', 'candidate identification', 'candidate marker', 'career', 'cohort', 'complex biological systems', 'computer framework', 'design', 'diagnostic biomarker', 'evidence base', 'experience', 'genetic manipulation', 'genome-wide', 'high risk', 'human disease', 'in vivo Model', 'injury and repair', 'intelligent algorithm', 'interest', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel diagnostics', 'patient population', 'prevent', 'resistance mechanism', 'standard of care', 'stem cells', 'success', 'therapeutic target', 'transcriptome', 'transcriptomics', 'translational scientist', 'translational study']",NIDDK,CASE WESTERN RESERVE UNIVERSITY,K25,2021,171720
"Carolina Population Center PROJECT SUMMARY/ABSTRACT The Carolina Population Center requests infrastructure support that will advance population dynamics research at CPC by increasing research impact, innovation, and productivity, supporting the development of junior scientists, and reducing the administrative burden on scientists. Infrastructure support will advance science in three primary research areas: Sexuality, Reproduction, Fertility, and Families; Population, Health, and the Environment; and Inequality, Mobility, Disparities, and Well-Being. Much of the research at CPC draws on large publicly available longitudinal data sets that our faculty have designed and collected, including the National Longitudinal Study of Adolescent to Adult Health, the China Health and Nutrition Survey, newer surveys associated with the Transfer Project, and the Study of the Tsunami Aftermath and Recovery, all of which will continue to be important in work related to our primary research areas over the next five years. These projects embody several themes that have guided research at CPC since the Center's inception. These themes, which will continue to shape our work, are the importance of life course processes and longitudinal data, multi-level processes and measurement of context, interventions and natural experiments as means of learning about causal processes, and the relevance of sociodemographic variables such as age, gender, race- ethnicity, and socioeconomic status for disparities in health and well-being. By embedding these themes, our projects provide data that enable us to address barriers that otherwise impede progress in the population sciences generally, and in our primary research areas in particular. We request support for three cores which in combination will provide an institutional infrastructure that will push populations dynamics research forward by empowering CPC faculty to tackle challenging questions using state of the art measurement techniques and methods. The Administrative Core plans activities that maintain a stimulating intellectual community, streamlines administrative processes so that scientists can focus on research, coordinates activities of the Cores so that services are offered efficiently, and communicates information about research and data more broadly. The Development Core supports early stage investigators and other faculty with exciting new ideas through multiple mechanisms: workshops, access to technical expertise in measurement, and seed grants. The Research Services Core enables scientists to address complex and important population research issues by providing access to state-of-the-art research tools and professional support for programming, survey development, and analysis. NARRATIVE This project will provide infrastructure support for a cutting edge program of research on population dynamics at the Carolina Population Center. Research at the Center will analyze state-of-the art data to address fundamental questions regarding fertility, adolescent health, and links between the environment and health. Special attention will be paid to factors creating health disparities.",Carolina Population Center,10136647,P2CHD050924,"['Address', 'Adolescent', 'Adopted', 'Adult', 'Age', 'Applications Grants', 'Area', 'Attention', 'Biological Markers', 'China', 'Cognitive', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer Vision Systems', 'Creativeness', 'Data', 'Data Collection', 'Development', 'Diffuse', 'Educational workshop', 'Environment', 'Ethnic Origin', 'Extramural Activities', 'Faculty', 'Family', 'Fertility', 'Fostering', 'Funding', 'Gender', 'Genetic', 'Grant', 'Hand', 'Health', 'Health Surveys', 'Home environment', 'Inequality', 'Infrastructure', 'Intervention', 'Journals', 'Learning', 'Life Cycle Stages', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mainstreaming', 'Measurement', 'Mentors', 'Methods', 'Natural experiment', 'Nutrition Surveys', 'Personal Satisfaction', 'Phase', 'Policy Making', 'Population', 'Population Dynamics', 'Population Research', 'Population Sciences', 'Postdoctoral Fellow', 'Process', 'Production', 'Productivity', 'Publishing', 'Race', 'Recovery', 'Reproduction', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resources', 'Schools', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Seeds', 'Services', 'Sexuality', 'Shapes', 'Socioeconomic Status', 'Structure', 'Students', 'Surveys', 'Talents', 'Teacher Professional Development', 'Technical Expertise', 'Techniques', 'Training Programs', 'Tsunami', 'Universities', 'Work', 'adolescent health', 'career', 'collaborative environment', 'cost', 'data access', 'design', 'empowered', 'experience', 'faculty support', 'health disparity', 'innovation', 'interdisciplinary collaboration', 'longitudinal dataset', 'novel strategies', 'population health', 'privacy protection', 'programs', 'research and development', 'response', 'sociodemographic variables', 'success', 'tool']",NICHD,UNIV OF NORTH CAROLINA CHAPEL HILL,P2C,2021,766127
"A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers PROJECT SUMMARY/ABSTRACT  This application, “A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,” is in response to PAR-16-238, Dissemination and Implementation Research in Health (R01). Acute respiratory distress syndrome (ARDS) has high prevalence (10% of intensive care unit admissions) and mortality up to 46%. Low tidal volume ventilation (LTVV) is the most effective therapy for ARDS, lowering mortality by 20-25%, and is part of standard practice. However, use of LTVV is as low as 19% of ARDS patients. There is a poor understanding of the barriers to LTVV adoption: current approaches are deficient because they incorporate biases, lack consistency and comprehensiveness, ignore the influence of interpersonal network- or team- based factors, and do not address setting-specific variation. Our research team has previously identified some patient- and clinician-specific facilitators of and barriers to LTVV adoption. We have used two state-of-the-art data driven methods—data science and network analysis—to preliminarily quantify the impact of a diverse array of potential factors affecting LTVV adoption, including network- and team-based factors. The proposed research is guided by the Consolidated Framework for Implementation Research (CFIR) and Rogers' Diffusion of Innovations theory. The overall goals of the proposed research are to understand the differences in facilitators and barriers to LTVV adoption between academic and community settings through a definitive, systematic study in a large, diverse consortium of medical centers, and to advance implementation science by providing a model for how data science and network analysis can be applied to understand the adoption of a complex intervention. The overarching hypothesis is that there are different patient-, clinician-, network-, and team-based facilitators and barriers to LTVV adoption in academic and community settings. We will determine whether different patient- and clinician- (Aim 1 cohort study, clinician survey, and data science analysis), clinician interpersonal network- (Aim 2 network analysis), and team structure and dynamics-based (Aim 3 team construction and modeling) facilitators of and barriers to LTVV adoption exist between academic and community hospital settings. Successful completion of the proposed research will provide a comprehensive understanding of the differences in the facilitators of and barriers to LTVV adoption between academic and community settings, and will advance implementation science by serving as a model of how data science and network analysis can be applied to complex implementation problems. Implementation strategies that account for all these factors may be more likely to lead to significant practice change. PROJECT NARRATIVE  Acute respiratory distress syndrome (ARDS) has high prevalence and mortality among critically ill patients; low tidal volume ventilation is the most effective therapy for ARDS but is used infrequently. Successful completion of the proposed research will identify differences in the facilitators of and barriers to adoption of low tidal volume ventilation between academic and community hospital settings in a large and diverse consortium of medical centers. The proposed research will generate a model of how data science and network analysis can be used to understand the implementation of a complex evidence-based practice.",A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,10178076,R01HL140362,"['Acute', 'Admission activity', 'Adoption', 'Adult Respiratory Distress Syndrome', 'Affect', 'Attitude', 'Caring', 'Characteristics', 'Cohort Studies', 'Community Hospitals', 'Complex', 'Consolidated Framework for Implementation Research', 'Critical Illness', 'Data', 'Data Science', 'Diffusion of Innovation', 'Environment', 'Evidence based practice', 'Goals', 'Health', 'Healthcare Systems', 'Height', 'High Prevalence', 'Hypoxemia', 'Individual', 'Inflammatory', 'Intensive Care Units', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Medical center', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Nurses', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Professional Organizations', 'Pulmonary Edema', 'Research', 'Severities', 'Speed', 'Structure', 'Surveys', 'Syndrome', 'System', 'Testing', 'Tidal Volume', 'Variant', 'base', 'community setting', 'complex data', 'computer science', 'dissemination research', 'effective therapy', 'experimental study', 'health care settings', 'implementation research', 'implementation science', 'implementation strategy', 'lung injury', 'machine learning method', 'mortality', 'multidisciplinary', 'novel', 'respiratory', 'response', 'theories', 'ventilation']",NHLBI,NORTHSHORE UNIVERSITY HEALTHSYSTEM,R01,2021,680901
"Enabling the Accelerated Discovery of Novel Chemical Probes by Integration of Crystallographic, Computational, and Synthetic Chemistry Approaches ABSTRACT Identification of high-quality chemical probes, molecules with high specificity and selectivity against macromolecules, is of critical interest to drug discovery. Although millions of compounds have been screened against thousands of protein targets, small-molecule probes are currently available for only 4% of the human proteome. Thus, more efficient approaches are required to accelerate the development of novel, target-specific probes. In 2019, a new bold initiative called “Target 2035” was launched with the goal of “creating […] chemical probes, and/or functional antibodies for the entire proteome” by 2035. In support of this ambitious initiative, we propose to develop and test a novel integrative AI-driven methodology for rapid chemical probe discovery against any target protein. Here, we will build an integrative workflow where the unique XChem database of experimental crystallographic information describing the pose and nature of chemical fragments binding to the target protein will be used in several innovative computational approaches to predict the structure of organic molecules with high affinity towards specific targets. The candidate molecules will be experimentally validated and then optimized, using computational algorithms, into lead molecules to seed chemical probe development. The proposed project is structured around three following interrelated keystones: (i) Develop a novel method for ligand-binding hot-spot identification and discovery of novel chemical probe candidates; (ii) Develop novel fragment-based integrative computational approach for accelerated de novo design of chemical probes; (iii) Consensus prediction of target-specific ligands, synthesis, and experimental validation of computational hits.  More specifically, we will develop a hybrid method to predict structures of high-affinity ligands for proteins for which XChem fragment screens have been completed. These approaches will be used for screening of ultra- large (>10 billion) chemical libraries to identify putative high affinity ligands within crystallographically determined pockets. Then, we will develop and employ an approach using graph convolutional neural networks for de novo design of a library of strong binders that will be evaluated to select the best candidates for chemical optimization. Finally, we will combine traditional structure-based and novel approaches, developed in this project to select consensus hit compounds against three target proteins: transcription factor brachyury, hydrolase NUDT5, and bromodomain BAZ2B. Iterative design guided by the computational algorithms, synthesis, and testing will progressively optimize molecules to micromolar leads to chemical probes for the target proteins.  Completion of the proposed aims will deliver a robust integrative workflow to identify leads for chemical probes against diverse target proteins. We expect that our AI-based computational approach to convert crystallographically-determined chemical fragments into lead compounds coupled with the experimental validation of computational algorithms will accelerate the discovery of new chemical probes, expand the druggable proteome, and support future drug discovery studies PROJECT NARRATIVE This project is devoted to the development of a novel integrative, structure-based, artificial intelligence driven methodology for rapid chemical probe discovery against any target protein. The candidate molecules will be experimentally validated for three selected targets, transcription factor brachyury, hydrolase NUDT5, and bromodomain BAZ2B, and then optimized, using computational algorithms, into lead molecules to seed chemical probe development. We expect that our AI-based computational approach to convert crystallographically- determined chemical fragments into lead compounds coupled with the experimental validation of computational algorithms will accelerate the discovery of new chemical probes, expand the coverage of druggable proteome, and support future drug discovery studies.","Enabling the Accelerated Discovery of Novel Chemical Probes by Integration of Crystallographic, Computational, and Synthetic Chemistry Approaches",10100996,R01GM140154,"['Affinity', 'Algorithms', 'Antibodies', 'Artificial Intelligence', 'Binding', 'Binding Sites', 'Biological Assay', 'Biophysics', 'Brachyury protein', 'Bromodomain', 'Chemicals', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'Coupled', 'Databases', 'Development', 'Docking', 'Future', 'Goals', 'Graph', 'Hot Spot', 'Human', 'Hybrids', 'Hydrolase', 'Laboratories', 'Lead', 'Learning', 'Libraries', 'Ligand Binding', 'Ligands', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Modernization', 'Nature', 'Phosphotransferases', 'Procedures', 'Proteins', 'Proteome', 'Psychological reinforcement', 'Resources', 'Roentgen Rays', 'Screening procedure', 'Seeds', 'Specificity', 'Structure', 'Synthesis Chemistry', 'Testing', 'Validation', 'X-Ray Crystallography', 'base', 'chemical synthesis', 'computational chemistry', 'convolutional neural network', 'cost', 'design', 'drug candidate', 'drug discovery', 'innovation', 'interest', 'iterative design', 'macromolecule', 'novel', 'novel strategies', 'protein structure prediction', 'scaffold', 'screening', 'small molecule', 'small molecule libraries', 'structural genomics', 'success', 'transcription factor']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,563072
"University of Buffalo Clinical and Translational Science Institute Contact PD/PI: Murphy, Timothy F The Buffalo Translational Consortium (BTC), which includes the University at Buffalo (UB) health sciences schools, the major healthcare institutions in our region, four key research institutes and five influential community partners, have embarked on a comprehensive strategic plan to build a strong foundation for clinical and translational research in response to our community needs. Buffalo is the second most populous city in New York State and has a rich cultural history. The proportion of underrepresented minorities in Buffalo in 2018 (50%) parallels that projected for the US in 2050, making Buffalo a microcosm of what the US will look like in 30 years. A similar proportion of our population experiences health disparities. The vision for our CTSA hub is to perform innovative research across the translational spectrum to improve the health of our community and the nation. We will develop, test and share novel approaches to engage difficult-to-engage populations and reduce health disparities in our community, which represents a “population of the future”. Guided by our vision, the CTSA has catalyzed a transformation of our environment since our CTSA was first funded in August 2015 with remarkable growth in clinical and translational research. Further, in just the past year, the UB medical school has moved into a spectacular new building and our clinical partner, Kaleida Health, the largest healthcare system in the region, opened the new Oishei Children’s Hospital, both on the Buffalo Niagara Medical Campus and connected to the Clinical and Translational Research Center devoted entirely to clinical and translational research that opened in 2012. This rapid and continuing trajectory of growth in healthcare and research in the region has resulted in a new 21st century Academic Health Center with healthcare, medical education and clinical and translational research on one campus in the heart of Buffalo, creating a foundation to enhance the impact of our CTSA even further. While launching our CTSA, we have prioritized participation in the national consortium through hosting and testing Innovation Labs as a team science tool, working with multiple hubs on initiatives to solve translational research barriers and sharing tools that we have developed with the CTSA consortium, including novel health informatics tools. Our CTSA has five ambitious but achievable aims, including: 1) Accelerate innovative translational research with teams that engage communities, regional stakeholders and the national consortium; 2) Train an excellent, diverse workforce to advance translation of discoveries; 3) Enhance inclusion of special populations across the lifespan and difficult-to-engage populations; 4) Streamline clinical research processes focusing on quality and efficiency with emphasis on multisite studies; 5) Develop, test and share biomedical informatics tools to integrate data from multiple sources to speed translation. Guided by our vision to perform research to improve the health of our community and the nation, we will continue our momentum to expand translational research, train our diverse workforce, streamline processes, engage our community, and actively contribute to the national consortium. Page 243 Project Summary/Abstract Contact PD/PI: Murphy, Timothy F The University at Buffalo Clinical and Translational Science Institute (CTSI) is the coordinating center of the Buffalo Translational Consortium, which includes the region's premier research, educational and clinical institutions with influential community partners. The vision of the CTSI is to perform innovative clinical and translational research to reduce health disparities and improve the health of our community and the nation. We engage our community as research partners to create a shared environment to bring discoveries in the laboratory, clinic and community to benefit individual and public health. Page 244 The University at Buffalo Clinical and Translational Science Institute (CTSI) is the coordinating center of the Buffalo Translational Consortium, which includes the region's premier research, educational and clinical institutions with influential community partners. The vision of the CTSI is to perform innovative clinical and translational research to reduce health disparities and improve the health of our community and the nation. We engage our community as research partners to create a shared environment to bring discoveries in the laboratory, clinic and community to benefit individual and public health.",University of Buffalo Clinical and Translational Science Institute,10103865,UL1TR001412,"['Achievement', 'Address', 'Adopted', 'African American', 'Buffaloes', 'Center for Translational Science Activities', 'Cities', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Communities', 'Community Health', 'County', 'Coupled', 'Cultural Backgrounds', 'Data', 'Diverse Workforce', 'Ensure', 'Environment', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Growth', 'Health', 'Health Care Research', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Healthcare', 'Healthcare Systems', 'Heart', 'Image', 'Imaging technology', 'Individual', 'Influentials', 'Informatics', 'Institutes', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Life Expectancy', 'Longevity', 'Medical', 'Medical Education', 'Medical center', 'Methods', 'Natural Language Processing', 'New York', 'Outcomes Research', 'Participant', 'Pediatric Hospitals', 'Phenotype', 'Population', 'Poverty', 'Process', 'Program Development', 'Prospective Studies', 'Public Health', 'Public Health Informatics', 'Recording of previous events', 'Recruitment Activity', 'Refugees', 'Research', 'Research Institute', 'Research Personnel', 'Research Training', 'Resources', 'Schools', 'Science', 'Sensitivity and Specificity', 'Site', 'Special Population', 'Speed', 'Strategic Planning', 'System', 'Testing', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'Universities', 'Vision', 'Work', 'Workforce Development', 'base', 'biomedical informatics', 'clinical center', 'clinical data repository', 'community partnership', 'data sharing', 'education research', 'experience', 'health care disparity', 'health disparity', 'imaging genetics', 'improved', 'informatics tool', 'innovation', 'interoperability', 'medical schools', 'multidisciplinary', 'multiple data sources', 'novel', 'novel strategies', 'recruit', 'response', 'sharing platform', 'skills', 'social health determinants', 'structured data', 'tool', 'translational impact', 'translational pipeline', 'translational scientist', 'unstructured data']",NCATS,STATE UNIVERSITY OF NEW YORK AT BUFFALO,UL1,2021,3826724
"Meta-analysis in human brain mapping This is the competing renewal of the R01 (MH074457-14) which sustains the BrainMap Project (www.brainmap.org). BrainMap is a neuroimaging research resource facilitating cognitive neuroscience and disease-biomarker discovery via coordinate-based meta-analysis (CBMA). BrainMap provides its end-user community with: curated 3-D coordinate data and experimental metadata from peer-reviewed publications; extensively validated computational tools for CBMA; CBMA-derived tools for data interpretation (e.g., functional property and disease loadings by location) and data analysis (e.g., via CBMA-derived disease models); instructional materials and on-site and on-line venues for learning CBMA methods; and, on-going end-user support. At present, BrainMap.org hosts two coordinate-based databases: task-activation (TA DB) and voxel- based morphometry (VBM DB). A voxel-based physiology database (VBP DB) is in the planning and piloting phase. BrainMap maintains an integrated pipeline of cross-platform (Java) tools for data coding (Scribe), filtered retrieval (Sleuth), activation-likelihood estimation (ALE) CBMA (GingerALE), data visualization (Mango), and data interpretation (CBMA-derived Mango plugins). Multiple network-modeling approaches have been successfully applied to BrainMap data – independent components analysis (ICA), author-topic modeling (ATM), graph-theory modeling (GTM), structural equation modeling (SEM), connectivity-based parcellation (CBP), and meta-analytic connectivity modeling (MACM) – but none are yet optimized and “pipelined” for general use. Utilization of BrainMap resources is substantial: our software, data and meta-data have been used in >1,000 peer-reviewed articles. Of these, > 500 were published in the current funding cycle (2015- 2020). Four aims are proposed, to maintain and extend this high-impact research resource.  Aim 1. Voxel-based Physiology DataBase (VBP DB) with Analysis Exemplars. Aim 2. BrainMap Community Portal for Multivariate Modeling with Applications & Exemplars. Aim 3. Large-scale Parameter Estimations. Aim 4. BrainMap Pipeline Enhancements and Community Support. The overall goal of the BrainMap Project is to provide the human neuroimaging community with curated data sets, metadata, computational tools, and related resources that enable coordinate-based meta-analyses (CBMA), meta-analytic connectivity modeling (MACM), meta-data informed interpretation (“decoding”) of imaging results, and meta-analytic priors for mining (including machine learning) primary (per-subject) neuroimaging data.",Meta-analysis in human brain mapping,10157292,R01MH074457,"['3-Dimensional', 'Address', 'Brain Mapping', 'Categories', 'Code', 'Cognition Disorders', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Disease model', 'Educational workshop', 'Equation', 'Funding', 'Goals', 'Guidelines', 'Human', 'Image', 'Java', 'Learning', 'Location', 'Machine Learning', 'Mango - dietary', 'Manuals', 'Mental disorders', 'Meta-Analysis', 'Metabolic', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Multivariate Analysis', 'Output', 'Peer Review', 'Phase', 'Physiology', 'Property', 'Publications', 'Publishing', 'Research Domain Criteria', 'Resources', 'Retrieval', 'Site', 'Software Framework', 'Structure', 'Surface', 'Symptoms', 'Taxonomy', 'Texas', 'Training', 'Uncertainty', 'Validation', 'base', 'biomarker discovery', 'case control', 'cognitive neuroscience', 'cohort', 'computerized tools', 'connectome', 'data submission', 'data tools', 'data visualization', 'design', 'experimental study', 'graph theory', 'hemodynamics', 'independent component analysis', 'learning materials', 'lectures', 'morphometry', 'network models', 'neuroimaging', 'simulation', 'webinar']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R01,2021,637306
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,10160982,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2021,575125
"Automated Molecular Identity Disambiguator (AutoMID) PROJECT SUMMARY Small molecules are one of the most important classes of therapeutics alleviating suffering and in many cases death for hundreds of millions of people worldwide. Small molecules also serve as invaluable tools to study biology, often with the goal to validate novel targets for the development of future therapeutic drugs. Reproducibility of experimental results and the interoperability and reusability of resulting datasets depend on accurate descriptions of associated research objects, and most critically on correct representations of small molecules that are tested in biological assays. For example, it is not possible to develop predictive models of protein target - small molecule interactions if their chemical structure representations are not correct. Many factors contribute to errors in reported chemical structures in small molecule screening and omics reference databases, scientific publications, and many other web-based resources and documents. Because of the complexity of representing small molecules chemical structure graphs and the lack of thorough curation, errors are frequently introduced by non-experts and error propagation across different digital research assets is a pervasive problem. To address this challenging problem via a scalable approach, we propose the Automated Molecular Identity Disambiguator (AutoMID). AutoMID will be usable in batch mode at scale via an API, for example to assist chemical structure standardization and registration by maintainers of digital research assets, and also via interactive (UI) mode for everyday researchers to quickly and easily validate or correct their small molecule representations. AutoMID will leverage extensive highly standardized linked databases of chemical structures and associated information including names, synonyms, biological activity and physical properties and their sources / provenance and leverage expert rules and AI to enable reliable disambiguation of chemical structure identities at scale. PROJECT NARRATIVE Small molecules are one of the most important types of drugs. They also serve as invaluable tools to study biology. The complexity of representing chemical graphs and the lack of thorough curation leads to frequent small molecule structure errors, which propagate across digital research assets, impeding their interoperability and reusability. To address this challenging problem, we propose the Automated Molecular Identity Disambiguator (AutoMID). Built on expert knowledge and AI, AutoMID will enable researchers and maintainers of data repositories to reliably identify and resolve ambiguities in chemical structures at scale.",Automated Molecular Identity Disambiguator (AutoMID),10150086,R01LM013391,"['Address', 'Adoption', 'Biological', 'Biological Assay', 'Biology', 'Categories', 'Cessation of life', 'Chemical Structure', 'Chemicals', 'Classification', 'Complex', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Data Store', 'Databases', 'Deposition', 'Detection', 'Development', 'FAIR principles', 'Future', 'Goals', 'Graph', 'Hand', 'Hybrids', 'In Vitro', 'Individual', 'Knowledge', 'Legal patent', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Metadata', 'Modeling', 'Molecular', 'Molecular Structure', 'Names', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Privatization', 'Property', 'Proteins', 'Publications', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Semantics', 'Source', 'Standardization', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Training', 'base', 'cheminformatics', 'data harmonization', 'data modeling', 'data repository', 'design', 'digital', 'high throughput screening', 'improved', 'in silico', 'in vivo', 'interoperability', 'knowledge curation', 'novel', 'online resource', 'physical property', 'predictive modeling', 'relational database', 'screening', 'small molecule', 'software systems', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2021,279970
"PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally. However, a vital step for EHR-based research is valid, accurate, and reliable phenotyping (i.e., correctly identifying individuals with a particular trait of interest). Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. However, each requires an extensive investment of time and resources to develop due to the heterogeneity, complexity, inaccuracy, and frequent fragmentation of EHRs. The lack of general, automatic, and portable approaches to enable accurate high- throughput phenotyping is a critical barrier that hampers our ability to leverage valuable clinical data in EHRs for better healthcare. We propose a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that we have developed from public resources and will further refine and implement across various EHRs. We recognize that mass information about phenotypes is often described in significant detail and continuedly accumulated within publicly available resources (e.g., MedlinePlus and Wikipedia). We hypothesize this information can be retrieved, filtered, organized, measured, and formalized into standard EHR phenotype profiles. Indeed, we have used such an ensemble approach to integrate four generalizable online medication resources (e.g., SIDER and RxNorm) to create MEDI--a resource linking 2,136 medications and 13,304 indications. In preliminary studies, we extended this strategy to phenotyping and created a prototype PheMAP. For each phenotype, we identified relevant clinical concepts and weighted each based on its importance to the phenotype. We then mapped all associated concepts to commonly-used clinical terminologies. Our preliminary studies showed an average consistency of 98.6%±0.8% between our early-stage PheMAP and three validated eMERGE algorithms (Type 2 Diabetes, dementia, and hypothyroidism). We seek support to refine and optimize PheMAP and develop tools to allow researchers to implement PheMAP efficiently in different EHRs. This will allow researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention. Since PheMAP is created using independent resources that are more generalizable than a local clinical dataset, the implementation will generate more consistent outcomes in different EHRs for large-scale analyses.The work we propose is a necessary step toward being able to conduct high-throughput genome-wide and phenome-wide association analyses (GWASs and PheWASs). We will use data from multiple biobanks to accomplish these tasks. Specifically, we will achieve the following goals in this grant: 1.refine PheMAP and conduct large-scale validation, 2. implement PheMAP and perform representative GWASs and PheWASs, 3. Use PheMAP to conduct GWASs for unstudied or understudied diseases and phenotypes, and 4. Share PheMAP to facilitate research using EHRs. Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally while a vital step for EHR-based research is valid, accurate, and reliable phenotyping. Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. We propose to refine, validate, and share a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that allows researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention.","PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping",10095131,R01GM139891,"['Algorithms', 'Benchmarking', 'Biological', 'Catalogs', 'Clinical', 'Clinical Data', 'Data', 'Data Set', 'Dementia', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Environment', 'Evaluation', 'Genes', 'Genotype', 'Goals', 'Grant', 'Healthcare', 'Heritability', 'Heterogeneity', 'Human', 'Hypothyroidism', 'Individual', 'Institution', 'Intervention', 'Investments', 'Knowledge', 'Left', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Medical center', 'MedlinePlus', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Sensorineural Hearing Loss', 'Signal Transduction', 'Site', 'Statistical Models', 'Terminology', 'Time', 'Validation', 'Work', 'base', 'biobank', 'biomedical ontology', 'clinically relevant', 'cost', 'data modeling', 'disease phenotype', 'experience', 'genome wide association study', 'genome-wide', 'implementation tool', 'interest', 'novel', 'off-label drug', 'off-label use', 'phenome', 'phenotyping algorithm', 'portability', 'prototype', 'tool', 'trait']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,432500
"Integrating genomic and clinical data to predict disease phenotypes using heterogeneous ensembles PROJECT SUMMARY Genomic and other “omic” profiles hold immense potential for advancing personalize/precision medicine by enabling the accurate prediction of disease phenotypes or outcomes for individual patients, which can be used by a clinician to design an appropriate plan of care. However, despite this potential, the actual impact of these omic profiles on disease phenotype prediction may be limited by the fact that even large cohorts collecting these data do not cover large enough numbers of individuals. In contrast, a variety of clinical data types, such as laboratory tests and physician notes, are routinely collected and studied for a much larger number of patients undergoing treatment for such diseases at medical centers. The abundance of these clinical data, and their complementarity with multi-omic data, offer an opportunity to advance personalized medicine by integrating these disparate types of data. However, this disparity in data formats, namely several omic profiles being structured, and several clinical data types, such as physician notes, being unstructured, poses challenges for this integration. An associated challenge due to this disparity is that different classes of computational methods are likely to be the most effective for predicting disease phenotypes from these clinical and omics datasets. These challenges pose barriers for current data integration methods to address this problem. Here, we propose an innovative approach to this integration by assimilating diverse base phenotype predictors inferred from individual clinical and omics datasets into heterogeneous ensembles. These ensembles, which have shown promise for several other computational genomics problems, can aggregate an unrestricted number and variety of base predictors, which is ideal for this integration problem. Specifically, we describe how existing heterogeneous ensemble methods for single datasets can be transformed and advanced to address the multiple clinical and omic dataset integration problem. In particular, we detail novel algorithms for improving these integrative ensembles by modeling and incorporating the inherent patient and dataset heterogeneity in these datasets. We also propose novel algorithms for leveraging the inherent complementarity among clinical and omic datasets, as well as an innovative approach for handling expected missing data, both with the goal of making ensemble phenotype predictors more accurate and applicable to patient cohorts. To assess the performance of this novel suite of data integration-oriented heterogeneous ensembles, we will validate their effectiveness for predicting asthma and Inflammatory Bowel Disease phenotypes in substantial patient cohorts with diverse omics and clinical datasets. We will publicly release efficient software implementations of the methods developed in this project to enable others to carry out similar analyses with other diverse data collections. Successful accomplishment of the proposed work will contribute to the advancement of personalized medicine through accurate individualized prediction of disease phenotypes. Predictive modeling is expected to become a cornerstone on the path to achieving precision/personalized medicine, as one of the key tasks here will be making individualized predictions of disease characteristics/phenotypes like subtype and risk of progression and/or recurrence. We propose several innovative computational algorithms for developing accurate predictive models that integrate diverse clinical and omic data, as well as several rigorous validation exercises that will demonstrate the capabilities of these models. Successful accomplishment of the proposed work will contribute to the advancement of personalized/precision medicine through more accurate individualized prediction of disease characteristics.",Integrating genomic and clinical data to predict disease phenotypes using heterogeneous ensembles,10218766,R01HG011407,"['Address', 'Algorithms', 'Asthma', 'Automobile Driving', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Disease', 'Disease Outcome', 'Docking', 'Effectiveness', 'Electronic Health Record', 'Encapsulated', 'Exercise', 'Genomics', 'Goals', 'Health', 'Individual', 'Inflammatory Bowel Diseases', 'Institution', 'Laboratories', 'Learning', 'Malignant Neoplasms', 'Medical', 'Medical Imaging', 'Medical center', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Profiling', 'Multiomic Data', 'Patients', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Recurrence', 'Research Personnel', 'Risk', 'Sampling', 'Structure', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Validation', 'Variant', 'Work', 'advanced disease', 'base', 'clinical phenotype', 'cohort', 'data format', 'data integration', 'deep learning', 'design', 'disease phenotype', 'diverse data', 'feature selection', 'flexibility', 'genomic data', 'heterogenous data', 'improved', 'individual patient', 'innovation', 'insight', 'member', 'multiple datasets', 'multiple omics', 'multitask', 'novel', 'novel strategies', 'outreach', 'patient population', 'personalized medicine', 'personalized predictions', 'precision medicine', 'predictive modeling', 'programs', 'rapid growth', 'repository', 'scale up', 'transcriptomics', 'vector']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,539951
"Mechanoregulation of Ciliary Motility Project Summary Mechanoregulation is a fundamental mechanism for the control of dynamic and multiscale biological systems. A mechanoregulatory network is responsible for the motility of cilia by converting the action of thousands of individual dynein motors bound to doublet microtubules in the cilium into a single waveform. This waveform has evolved to efficiently displace fluid, allowing either cell self-propulsion or the transport of extracellular liquid over epithelial surfaces. Ciliary motility in humans is therefore essential for the movement of sperm cells, the removal of bacteria and viruses from the respiratory tract, and the circulation of cerebrospinal fluid in the brain. Cilia are also used by protozoan pathogens for movement, contributing to their pathogenicity. The biflagellate alga, Chlamydomonas reinhardtii, has become the model system for studying the relationship between cilia ultrastructure and ciliary motilty. Using this organism, we have determined single-particle electron cryomicroscopy (cryo-EM) structures of the bases of dyneins and mechanoregulatory complexes natively bound to doublet microtubules. These structures map the interconnected network of microtubules, mechanoregulators, and dynein motors in unparalleled atomic detail. The structures reveal the mechanisms that dock mechanoregulators to doublet microtubules and generate new hypotheses for how they control dynein behavior. These preliminary structural studies provide a unique opportunity to better understand the structure, function and assembly pathway of the largest mechanoregulator, the radial spoke. In aim 1, I propose to elucidate the complete structure of a native radial spoke using cryo-EM and cross-linking mass spectrometry. Structural information will resolve how its 20+ unique subunits interact and function together to respond to both mechanical and chemical signals. Due to the high conservation of radial-spoke subunits among organisms, our structure will provide insights into the etiology of ciliopathy-causing mutations in humans. In aim 2, I propose to test hypotheses that have arisen from our “on-doublet” structures using an interdisciplinary combination of structure-guided mutagenesis, waveform analysis by high-speed microcinematography, and structural characterization using electron cryotomography. This work will provide experimental evidence for the fundamental molecular mechanisms that control ciliary motility. In aim 3, I propose to use a proteomic and structural approach to determine the mechanisms of radial-spoke assembly. This work will test our current structure-based model of assembly and has the potential to identify the first radial-spoke biogenesis factors. Collectively, these studies will provide unprecedented mechanistic insight into the mechanoregulatory pathways that control ciliary motility and promises to open new avenues for the treatment of ciliopathies. Project Narrative Motile cilia are microtubule-based organelles that produce a driving force for cellular locomotion or fluid flow. In humans, defects in motile cilia can lead to infertility, chronic respiratory disease, and even reversal of the orientation of the bodily organs. This project aims to reveal the detailed workings of the mechanoregulatory network that controls ciliary motility, which will help us to better understand the molecular basis of cilia-related diseases.",Mechanoregulation of Ciliary Motility,10180150,R01GM141109,"['Algae', 'Animal Model', 'Bacteria', 'Behavior', 'Biogenesis', 'Biological Models', 'Blood Circulation', 'Brain', 'Cells', 'Cerebrospinal Fluid', 'Chemicals', 'Chlamydomonas reinhardtii', 'Chronic', 'Cilia', 'Cilium Microtubule', 'Communication', 'Complement', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Defect', 'Disease', 'Docking', 'Dynein ATPase', 'Electrons', 'Epithelial', 'Etiology', 'Excision', 'Genes', 'Human', 'Immunoprecipitation', 'Individual', 'Infertility', 'Lead', 'Link', 'Liquid substance', 'Literature', 'Locomotion', 'Lung diseases', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Mechanics', 'Mediating', 'Microtubules', 'Modeling', 'Molecular', 'Molecular Machines', 'Motor', 'Movement', 'Mucous body substance', 'Mutagenesis', 'Mutation', 'Nature', 'Oocytes', 'Organ', 'Organelles', 'Organism', 'Paralysed', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Proteomics', 'Publishing', 'Radial', 'Regulation', 'Resolution', 'Respiratory System', 'Sampling', 'Side', 'Signal Transduction', 'Speed', 'Structure', 'Surface', 'Testing', 'Work', 'base', 'biological systems', 'cell motility', 'ciliopathy', 'cilium motility', 'crosslink', 'driving force', 'extracellular', 'fluid flow', 'insight', 'nexin', 'novel', 'particle', 'pathogen', 'reconstruction', 'respiratory virus', 'sperm cell']",NIGMS,HARVARD MEDICAL SCHOOL,R01,2021,414050
"Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences Abstract A major approach in causal inference literature aimed at mitigating bias due to unmeasured confounding is the so- called instrumental variable (IV) design which relies on identifying a variable which (i) influences the treatment process, (ii) has no direct effect on the outcome other than through the treatment, and (iii) is independent of any unmeasured confounder. IV methods are very well developed and widely used in social and health science, although validity of IV inferences may not be reliable if any of required assumptions (i)-(iii) is violated. This proposal aims to develop (a) new IV methods robust to violation of any of (i)-(iii); (b) New negative control methods that can be used to detect and sometimes to nonparametrically account for unmeasured confounding bias; (c) New bracketing methods for partial inference about causal effects in comparative interrupted time series studies. The proposed methods will be used to address current scientific queries in three major substantive public health areas:(1) to understand the health effects of air pollution; (2) to quantify the causal effects of modifiable risk factors for Alzheimer's disease and related disorders; (3) To uncover the mechanism by which a randomized package of interventions produced a substantial reduction of HIV incidence in a recent major cluster randomized trial of treatment as prevention in Botswana, Africa. Our proposal will provide the best available analytical methods to date to resolve confounding concerns in these high impact public health applications and more broadly in observational studies in the health sciences. Summary This proposal aims to develop new causal inference methods to tame bias due to hidden confounding factors in obser- vational studies as well as in randomized experiments subject to non-adherence. The proposed methods are firmly grounded in modern semiparametric theory which will be used to obtain more robust and efficient inferences about causal effects in a broad range of public health applications including in Epidemiology of Aging, Environmental Health Epidemiology and HIV/AIDS Prevention.",Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences,10159821,R01AG065276,"['AIDS prevention', 'Address', 'Adherence', 'Africa', 'Aging', 'Air Pollution', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Area', 'Blood Pressure', 'Body mass index', 'Botswana', 'Cluster randomized trial', 'Data', 'Diabetes Mellitus', 'Disease', 'Environmental Health', 'Epidemiology', 'Genetic', 'HIV', 'Health', 'Health Sciences', 'Incidence', 'Interruption', 'Intervention', 'Learning', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Masks', 'Mendelian randomization', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Observational Study', 'Outcome', 'Participant', 'Process', 'Public Health', 'Public Health Applications Research', 'Randomized', 'Research Design', 'Research Personnel', 'Risk Factors', 'Series', 'Social Sciences', 'Testing', 'Thromboplastin', 'Time', 'ambient air pollution', 'analytical method', 'c new', 'comparative', 'design', 'experimental study', 'genetic variant', 'high dimensionality', 'intervention effect', 'modifiable risk', 'mortality', 'novel', 'pleiotropism', 'semiparametric', 'simulation', 'theories', 'treatment as prevention', 'treatment effect', 'uptake', 'user friendly software']",NIA,UNIVERSITY OF PENNSYLVANIA,R01,2021,468961
"Consortium for Immunotherapeutics against Emerging Viral Threats SUMMARY: OVERALL  This proposal, Consortium for Immunotherapeutics Against Emerging Viral Diseases, addresses a critical gap in the biodefense portfolio by building an academic-industry partnership to advance effective, fully human, antibody-based immunotherapeutics against three major families of emerging/re-emerging viruses: Lassa virus, Ebola and other Filoviruses, and mosquito-transmitted Alphaviruses that threaten millions worldwide. This program follows directly from our significant body of preliminary data (the largest available for these families of viruses), therapeutics in hand, multidisciplinary expertise, and demonstrated collaborative success. Included in the proposed CETR portfolio are: (1) the only available immunotherapeutics against endemic Lassa virus, with reversal of late-stage disease and complete survival in infected non-human primates, (2) novel Ebola and pan- ebolavirus therapeutics that also completely protect non-human primates from disease, and that were built by the paradigm-shifting and comprehensive analysis of a global consortium, and (3) much needed, first-in-class therapeutics against the re-emerging alphaviruses that have tremendous epidemic potential in the United States and around the globe. These multidisciplinary studies, founded upon pioneering structural biology of the antigen targets, include innovations such as agnostic, high-throughput Fc profiling and optimization, coupled with Fv evolution to enhance potency and developability, as well as a sophisticated statistical and computational analysis core to evaluate thresholds and correlates of protection across the major families of pathogens. Together, we aim to understand what findings represent general rules and what data are specific to each virus family. We also aim to provide streamlined systems for antibody choice and optimization that do not yet exist, and to build a broadly applicable platform for mAb discovery and delivery against any novel pathogen as they emerge. The recent resurgence of Lassa, the epidemic nature of Ebola virus and other re-emerging filoviruses, as well as the major population at risk by global movement of mosquito-borne alphaviruses together demonstrate the tremendous global need for immunotherapeutics developed and advanced by this program. NARRATIVE Three major families of emerging viruses (Lassa and other arenaviruses, Ebola and other filoviruses, and mosquito-borne alphaviruses) threaten human health worldwide, but lack approved therapeutics or vaccines. The proposed multidisciplinary consortium, an academic-industry partnership, will advance safe and effective, fully human, monoclonal antibody therapies against these viruses, using candidate therapies that confer complete protection in non-human primates as our starting point. Our collaborative databases, multivariate analyses and innovative antibody optimization strategies will establish platforms for discovery and delivery of much-needed treatments against these and other infectious diseases.",Consortium for Immunotherapeutics against Emerging Viral Threats,10158446,U19AI142790,"['Address', 'Alphavirus', 'Antibodies', 'Antigen Targeting', 'Arenavirus', 'Arthritogenic', 'Biological Assay', 'Communicable Diseases', 'Computer Analysis', 'Computer Models', 'Computing Methodologies', 'Coupled', 'Culicidae', 'Data', 'Databases', 'Developed Countries', 'Developing Countries', 'Disease', 'Ebola', 'Ebola virus', 'Epidemic', 'Evolution', 'Family', 'Filovirus', 'Fostering', 'Goals', 'Hand', 'Health', 'Human', 'Immune', 'Immunotherapeutic agent', 'Lassa virus', 'Machine Learning', 'Mathematics', 'Mediating', 'Monoclonal Antibodies', 'Monoclonal Antibody Therapy', 'Movement', 'Multivariate Analysis', 'Nature', 'Populations at Risk', 'Primate Diseases', 'Reagent', 'Research Project Grants', 'Resources', 'Statistical Data Interpretation', 'System', 'Talents', 'Testing', 'Therapeutic', 'Therapeutic Monoclonal Antibodies', 'Translating', 'Translations', 'United States', 'Vaccines', 'Viral', 'Virus', 'Virus Diseases', 'base', 'biodefense', 'chikungunya', 'clinical development', 'design', 'experience', 'human monoclonal antibodies', 'improved', 'industry partner', 'innovation', 'insight', 'mosquito-borne', 'multidisciplinary', 'nonhuman primate', 'novel', 'pandemic disease', 'pathogen', 'programs', 'research study', 'structural biology', 'success', 'synergism', 'tool']",NIAID,LA JOLLA INSTITUTE FOR IMMUNOLOGY,U19,2021,7065330
"The plasticity of well-being:  A research network to define, measure and promote human flourishing PROJECT SUMMARY/ABSTRACT This U24 application is written in response to RFA-AT-20-003 to establish a high-priority research network on emotional well-being (EWB). While psychological research on well-being has dramatically increased over the past 15 years, virtually all of this work has been descriptive and has not emphasized the “how” of well-being: How might well-being be cultivated? In addition, virtually all of the extant work on the correlates of individual differences in well-being has used responses on retrospective questionnaires as the primary tool to assess well-being. While there have been exciting findings, particularly relating individual differences in well-being to various indices of physical health, many questions remain and methodological limitations plague the validity of this work. This U24 network will assemble a highly multi-disciplinary group of 10 investigators across 3 (or more in the future) institutions to significantly advance our understanding of the “how” of EWB, identify the core plastic constituents of EWB, specify and/or develop robust measures of these constituents at biological, behavioral and experiential levels of analysis and characterize the plasticity of these constituents. The measurement strategy will ultimately focus on the development of technology-based passive measures of EWB that require no explicit user input and are highly scalable. The network will also focus its efforts on the development and evaluation of programs to train EWB and will assess whether such programs might serve as prevention strategies. The network will consist of scientists and scholars from a broad range of fields including psychology, neuroscience, electrical and computer engineering, population health and biology, computer science and the humanities. These scientists and scholars will focus on the following major aims: Aim 1: To arrive at a core consensus of the minimal set of constituents that can be described and measured at biological, behavioral and experiential levels that constitute the plastic elements of EWB and to specify already existing measures and /or develop novel measures of each of these constructs at each level of analysis. Aim 2: Using the active measures described in Aim 1, to develop passive measures using digital technologies of at least two of the core constituents of well-being. Aim 3: To develop pilot projects specifically focusing on prevention strategies for learning well-being in various samples. The network will train new investigators and bring established investigators into this new field, disseminate a framework for understanding the plasticity of well- being, a toolbox of measures for assessing the plasticity of components of well-being, and several pilot datasets that showcase the novel passive and field-friendly biological measures. In these ways, the network will dramatically accelerate progress in the nascent field of EWB. PROJECT NARRATIVE This U24 network on emotional well-being (EWB) will catalyze the emerging field of the plasticity of well-being and will showcase how well-being can be learned and the consequences of such skill development on physical and emotional health and on prevention of disease. A framework for understanding how well-being can be learned along with measures of the core components of well-being that can be learned will be developed and disseminated. The network will also train new investigators in this area and will engage established investigators to contribute to this field.","The plasticity of well-being:  A research network to define, measure and promote human flourishing",10151850,U24AT011289,"['Area', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Biological', 'Cellular Phone', 'Communities', 'Computers', 'Consensus', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Distal', 'Drug abuse', 'Elements', 'Emotional', 'Engineering', 'Face', 'Future', 'Gold', 'Grant', 'Health', 'Human', 'Humanities', 'Individual Differences', 'Institution', 'Interruption', 'Literature', 'Measurement', 'Measures', 'Mental Depression', 'Methodology', 'Mind', 'Modernization', 'Neurosciences', 'Outcome', 'Patient Self-Report', 'Personal Satisfaction', 'Pilot Projects', 'Plague', 'Population Biology', 'Prevention strategy', 'Program Evaluation', 'Psychology', 'Publications', 'Questionnaires', 'Randomized Controlled Trials', 'Regulation', 'Research', 'Research Personnel', 'Research Priority', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specific qualifier value', 'Subgroup', 'Techniques', 'Technology', 'To specify', 'Training', 'Well in self', 'Work', 'base', 'computer science', 'cost', 'digital', 'disorder prevention', 'indexing', 'learning strategy', 'mHealth', 'machine learning algorithm', 'meetings', 'member', 'mindfulness meditation', 'multidisciplinary', 'novel', 'physical conditioning', 'population health', 'prevent', 'programs', 'psychologic', 'response', 'skill acquisition', 'social', 'standard measure', 'technology development', 'tool', 'virtual', 'web site']",NCCIH,UNIVERSITY OF WISCONSIN-MADISON,U24,2021,30000
"AUGS/DUKE UrogynCREST program PROJECT SUMMARY Health Services Research (HSR) and predictive analytics are rapidly growing fields and will have enormous implications for women’s health research in pelvic floor disorders (PFDs). The AUGS/DUKE Urogynecology Clinical Research Educational Scientist Training (UrogynCREST) program will prepare participants to recognize the critical role that data play in delivering high quality health care. It brings together expertise in health service and women’s health research, medical informatics and prediction modeling. This program will target Urogynecology Faculty at the Assistant Professor level who seek successful careers in health services research (HSR) and analytics. Participants will obtain skills through a combination of didactic and interactive coursework; hands-on manipulation of data through extraction, cleaning, and analysis; and project-based one on one mentoring. The UrogynCREST program will be an interactive, hands-on educational program with centralized activities organized and delivered by distance through a popular on-line learning platform called Sakai, with educational software designed to support teaching, research and collaboration. A diverse faculty with expertise in data sciences teaches courses and the advanced methodology required to perform HSR. Yearly in-person meetings at the annual American Urogynecologic Society meeting enhance networking and the development of partnerships between participants from various institutions, as well as, interactions with the mentors and other HSR in the field. The program’s strategy allows national leaders with particular skills in the field to provide their knowledge to the participants and help mentor them through development of a relevant research question and identification of an appropriate and existing database(s) to address the question. With the guidance of a dedicated statistician and analyst programmer, participants will learn and perform the necessary computer programming needed to extract, clean and analyze these data. Participants whose projects involve the development of prediction models in the form of scores, nomograms or other tools will learn how to build and validate such tools in the existing project. Each participant’s project will culminate in the completion of a submitted manuscript to a peer- reviewed journal or study proposal and publicly available tools when relevant. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and resources for invigorating data discovery and tools for investigations in HSR specifically addressing (PFDs). PROJECT NARRATIVE: The AUGS/DUKE UrogynCREST program will prepare participants to recognize the critical role that data play in delivering high quality health care for pelvic floor disorders. It will add structure to the health data science education for Assistant Professor Level Faculty in Urogynecology by bringing together expertise in health service and women’s health research, medical informatics, and prediction modeling. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and mentorship for invigorating data discovery and tools for investigations in health service research specifically addressing pelvic floor disorders.",AUGS/DUKE UrogynCREST program,10126885,R25HD094667,"['Address', 'Age', 'American', 'Area', 'Caring', 'Clinical Research', 'Collaborations', 'Communities', 'Connective Tissue', 'Data', 'Data Discovery', 'Data Science', 'Databases', 'Development', 'E-learning', 'Educational process of instructing', 'Faculty', 'Fecal Incontinence', 'Fostering', 'Future', 'Goals', 'Health Services', 'Health Services Research', 'Healthcare', 'Infrastructure', 'Institution', 'Instruction', 'Investigation', 'Journals', 'Knowledge', 'Lead', 'Learning', 'Manuscripts', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modernization', 'Muscle', 'Nomograms', 'Participant', 'Peer Review', 'Pelvic Floor Disorders', 'Pelvis', 'Persons', 'Play', 'Predictive Analytics', 'Process', 'Public Health', 'Research', 'Resources', 'Role', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Shapes', 'Societies', 'Software Design', 'Structure', 'Techniques', 'Testing', 'Training Programs', 'Urinary Incontinence', 'Woman', 'Women&apos', 's Health', 'base', 'career', 'clinical decision-making', 'clinical development', 'computer program', 'computer science', 'data tools', 'design', 'health care quality', 'health data', 'improved', 'injured', 'innovation', 'meetings', 'pelvic organ prolapse', 'predictive modeling', 'professor', 'programs', 'recruit', 'science education', 'skills', 'social', 'statistical and machine learning', 'tool']",NICHD,DUKE UNIVERSITY,R25,2021,151418
"Modeling the Incompleteness and Biases of Health Data Modeling the Incompleteness and Biases of Health Data Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. Existing efforts for missing health data imputation often focus on only cross-sectional correlation (e.g., correlation across subjects or across variables) but neglect autocorrelation (e.g., correlation across time points). Moreover, they often focus on modeling incompleteness but neglect the biases in health data. Modeling both the incompleteness and bias may contribute to better understanding of health data and better support clinical decision making. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets. Aim 1 introduces the MICA framework to jointly consider cross-sectional correlation and auto-correlation. In Aim 2, we will augment MICA to be bias-aware (hence BAMICA) to account for biases stemmed from multiple roots such as healthcare process and use them as features in imputing missing health data. This augmentation is achieved by a novel recurrent neural network architecture that keeps track of both evolution of health data variables and bias factors. In Aim 3, we will supplement unstructured clinical notes to structured health data for modeling incompleteness and biases using a novel architecture of graph neural network on top of memory network. We will apply graph neural networks to process clinical notes in order to learn proper representations as input to the memory networks for imputation and downstream predictive modeling tasks. Depending on the clinical problem and data availability, not all modules may be needed. Thus our proposed BAMICA framework is designed to be flexible and consists of selectable modules to meet some or all of the above needs. In summary, our proposal bridges a key knowledge gap in jointly modeling incompleteness and biases in health data and utilizes unstructured clinical notes to supplement and augment such modeling in order to better support predictive modeling and clinical decision making. We will demonstrate generalizability by experimenting on four large clinical and cohort study datasets, and by scaling up to the eMERGE network spanning 11 institutions nationwide. We will disseminate the open-source framework. The principled and flexible framework generated by this project will bring significant methodological advancement and have a direct impact on enhancing discovery from health data. Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets.",Modeling the Incompleteness and Biases of Health Data,10168611,R01LM013337,"['Adoption', 'Algorithms', 'Architecture', 'Awareness', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Collection', 'Communities', 'Computer software', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Diagnostic tests', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Evolution', 'Functional disorder', 'General Hospitals', 'Goals', 'Graph', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Hour', 'Individual', 'Inpatients', 'Institution', 'Intuition', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Learning', 'Measurement', 'Medical', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Regimen', 'Research', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Structure', 'Symptoms', 'System', 'Test Result', 'Testing', 'Time', 'Training', 'Validation', 'clinical decision support', 'clinical decision-making', 'data mining', 'data quality', 'design', 'experimental study', 'flexibility', 'health care service utilization', 'health data', 'improved', 'lifetime risk', 'machine learning algorithm', 'neglect', 'neural network', 'neural network architecture', 'novel', 'open source', 'patient population', 'personalized diagnostics', 'personalized therapeutic', 'predictive modeling', 'recurrent neural network', 'scale up', 'social health determinants', 'stem', 'structured data', 'text searching', 'tool', 'trait']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,315727
"Estimating Mediation Effects in Prevention Studies The purpose of this competing continuation grant proposal is to develop, evaluate and apply  methodological and statistical procedures to investigate how prevention programs change outcome  variables. These mediation analyses assess the link between program effects on the constructs targeted  by a prevention program and effects on the outcome. As noted by many researchers and federal  agencies, mediation analyses identify the most effective program components and increase  understanding of the underlying mechanisms leading to changing outcome variables. Information from  mediation analysis can make interventions more powerful, more efficient, and shorter. The P. I. of this grant received a one-year NIDA small grant and four multi-year grants to develop and evaluate mediation  analysis in prevention research. This work led to many publications and innovations. The proposed  five-year continuation focuses on the further development and refinement of exciting new mediation  analysis statistical developments. Four statistical topics represent next steps in this research and include  analytical and simulation research as well as applications to etiological and prevention data. The work expands on our development of causal mediation and Bayesian mediation methods that hold great promise for mediation analysis. In Study 1, practical causal mediation and Bayesian mediation analyses  for research designs are developed and evaluated. This approach will clarify methods and develop  approaches for dealing with violation of testable and untestable assumptions. Study 2 investigates  important measurement issues for the investigation of mediation. This work will focus on methods to identify critical facets of mediating variables, approaches to understanding whether mediators and  outcomes are redundant, and develop methods for studies with big data. Study 3 continues the development and evaluation of new longitudinal mediation methods for ecological momentary assessment data and other studies with massive data collection. These new methods promise to more accurately model change over time for both individuals and groups of individuals. Study 4 develops methods to  uncover subgroups in mediation analysis including causal mediation methods, multilevel models, and new  approaches based on residuals for identifying individuals for whom mediating processes differ in  effectiveness from other individuals. For each study, we will investigate unique issues with mediation analysis of prevention data including methods for small N and also massive data collection (big data), the RcErLitEicVaANl rCoEle(Soeef imnsetruacstiounrse):ment for mediating mechanisms, and the application of the growing literature on  causal methods and Bayesian methods. Study 5 applies new statistical methods to data from several NIH  The project further develops a method, statistical mediation analysis, that extracts more information from  funded prevention studies providing important feedback about the usefulness of the methods. Study 6  research. Mediation analysis explains how and why prevention and treatments are successful. Mediation  disseminates new information about mediation analysis through our website and other media, by  analysis improves prevention and treatment so that their effects are greater and even cost less. communication with researchers, and publications from the project. n/a",Estimating Mediation Effects in Prevention Studies,10168488,R37DA009757,"['Address', 'Applications Grants', 'Bayesian Method', 'Behavioral Mechanisms', 'Big Data', 'Biological Models', 'Communication', 'Complex', 'Consultations', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Ecological momentary assessment', 'Educational workshop', 'Effectiveness', 'Etiology', 'Evaluation', 'Feedback', 'Funding', 'Grant', 'Individual', 'Individual Differences', 'Intervention', 'Investigation', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Outcome', 'Persons', 'Prevention', 'Prevention Research', 'Prevention program', 'Principal Investigator', 'Procedures', 'Process', 'Psychometrics', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Residual state', 'Statistical Data Interpretation', 'Statistical Methods', 'Subgroup', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Work', 'base', 'computer program', 'cost', 'data space', 'design', 'dynamic system', 'improved', 'innovation', 'interest', 'longitudinal design', 'model design', 'multilevel analysis', 'novel strategies', 'programs', 'simulation', 'substance use treatment', 'successful intervention', 'theories', 'therapy design', 'tool', 'treatment research', 'web site']",NIDA,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R37,2021,360584
"Developing Computational Methods for Surveillance of Antimicrobial Resistant Agents PROJECT ABSTRACT  Antimicrobial resistance is a critical public health issue. Infections with drug resistant pathogens are estimated to cause an additional eight million hospitalization days annually over the hospitalizations that would be seen for infections with susceptible agents. The use of antibiotics (in both clinical and agricultural settings) is being viewed as precursor for these infections and thus, is a major public health concern—particularly as outbreaks become more frequent and severe. However, scientiﬁc evidence describing the hazards associated with antibiotic use is lacking due to inability to quantify the risk of these practices. One promising avenue to elucidate this risk is to use shotgun metagenomics to identify the AMR genes in samples taken through systematic spatiotemporal surveillance. The goal of this proposed work is to develop algorithms that will provide such a means for analysis. The algorithms need to be scalable to very large datasets and thus, will require the development and use succinct data structures.  In order to achieve this goal, the investigative team will develop the theoretical foundations and applied meth- ods needed to study AMR through the use of shotgun metagenomics. A major focus of the proposed work is developing algorithms that can handle very large datasets. To achieve this scalability, we will create novel means to create, compress, reconstruct and update very large de Bruijn graphs that metagenomics data in a manner needed to study AMR. In addition, we will pioneer the study of AMR through long read data by proposing new algorithmic problems and solutions that use data. For example, identifying the location of speciﬁc genes in a metagenomics sample using long read data has not been proposed or studied. Thus, the algorithmic ideas and techniques developed in this project will not only advance the study of AMR, but contribute to the growing domain of big data analysis and pan-genomics.  Lastly, we plan to apply our methods to samples collected from both agricultural and clinical settings in Florida. Analysis of preliminary and new data will allow us to conclude about (1) the public risk associated with antimicro- bial use in agriculture; (2) the effectiveness of interventions used to reduce resistant bacteria, and lastly, (3) the factors that allow resistant bacteria to grow, thrive and evolve. A–1 PROJECT NARRATIVE  Antibiotic use in agriculture is a major public health concern that is receiving a lot of media attention, par- ticularly as antibiotic-resistant infections in become more frequent and severe. This research will build a novel bioinformatics framework for determining how antimicrobial resistant genes evolve, grow, and persist in a system that has been affected by antibiotic use. This will, in turn, facilitate the development of effective intervention methods that reduce resistant pathogens in clinical and agricultural settings. N–1",Developing Computational Methods for Surveillance of Antimicrobial Resistant Agents,10053321,R01AI141810,"['Affect', 'Agriculture', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Attention', 'Bacteria', 'Base Pairing', 'Big Data', 'Bioinformatics', 'Clinical', 'Collaborations', 'Combating Antibiotic Resistant Bacteria', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Compression', 'Data Set', 'Development', 'Disease Outbreaks', 'Effectiveness of Interventions', 'Florida', 'Food production', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Graph', 'Hospitalization', 'Infection', 'International', 'Investigation', 'Length', 'Location', 'Measures', 'Memory', 'Metagenomics', 'Methods', 'Monitor', 'Noise', 'Organism', 'Pathogenicity', 'Plasmids', 'Prevention', 'Public Health', 'Research', 'Resistance', 'Risk', 'Sampling', 'Shotguns', 'Structure', 'Surveillance Methods', 'System', 'Techniques', 'Time', 'Translating', 'Update', 'Work', 'antibiotic resistant infections', 'bacterial resistance', 'base', 'combinatorial', 'drug resistant pathogen', 'effective intervention', 'foodborne outbreak', 'genetic variant', 'hazard', 'improved', 'large datasets', 'machine learning algorithm', 'method development', 'microbial', 'microbiome analysis', 'microbiome research', 'multiple datasets', 'novel', 'pathogen', 'petabyte', 'reconstruction', 'research and development', 'resistance gene', 'spatiotemporal', 'standard care']",NIAID,UNIVERSITY OF FLORIDA,R01,2021,422334
"Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation Project Summary/Abstract: With the surge of large genomics data, there is an immense increase in the breadth and depth of different omics datasets and an increasing importance in the topic of privacy of individuals in genomic data science. Detailed genetic and environmental characterization of diseases and conditions relies on the large-scale mining of functional genomics data; hence, there is great desire to share data as broadly as possible. However, there is a scarcity of privacy studies focused on such data. A key first step in reducing private information leakage is to measure the amount of information leakage in functional genomics data, particularly in different data file types. To this end, we propose to to derive information-theoretic measures for private information leakage in different data types from functional genomics data. We will also develop various file formats to reduce this leakage during sharing. We will approach the privacy analysis under three aims. First, we will develop statistical metrics that can be used to quantify the sensitive information leakage from raw reads. We will systematically analyze how linking attacks can be instantiated using various genotyping methods such as single nucleotide variant and structural variant calling from raw reads, signal profiles, Hi-C interaction matrices, and gene expression matrices. Second, we will study different algorithms to implement privacy-preserving transformations to the functional genomics data in various forms. Particularly, we will create privacy-preserving file formats for raw sequence alignment maps, signal track files, three-dimensional interaction matrices, and gene expression quantification matrices that contain information from multiple individuals. This will allow us to study the sources of sensitive information leakages other than raw reads, for example signal profiles, splicing and isoform transcription, and abnormal three-dimensional genomic interactions. Third, we will investigate the reads that can be mapped to the microbiome in the raw human functional genomics datasets. We will use inferred microbial information to characterize private information about individuals, and then combine the microbial information with the information from human mapped reads to increase the re-identification accuracy in the linking attacks described in the second aim. We will use the tools to quantify the sensitive information and privacy-preserving file formats in the available datasets from large sequencing projects, such as the ENCODE, The Cancer Genome Atlas, 1,000 Genomes, gEUVADIS, and Genotype-Tissue Expression projects. Project Narrative: Sharing large-scale functional genomics data is critical for scientific discovery, but comes with important privacy concerns related to the possible misuse of such data. This proposal will quantify and manage the rieslkasted to releasing functional genomics datasets, based on integrating inferred genotypes from the raw sequence files, signal tracks, and microbiome mapped sequences. Finally, we will develop file formats, statistical methodologies, and related software for anonymization of functional genomics data that enable open sharing.",Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation,10251876,R01HG010749,"['3-Dimensional', 'Address', 'Algorithms', 'Assessment tool', 'Biology', 'ChIP-seq', 'Code', 'Computer software', 'Consent', 'DNA sequencing', 'Data', 'Data Files', 'Data Science', 'Data Set', 'Databases', 'Diet', 'Disease', 'Environment', 'Equilibrium', 'Extravasation', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Glean', 'Hi-C', 'Human', 'Individual', 'Institutes', 'Laws', 'Learning', 'Letters', 'Life Style', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Mining', 'Motivation', 'Participant', 'Patients', 'Phenotype', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Protein Isoforms', 'Protocols documentation', 'Provider', 'Pythons', 'Quantitative Trait Loci', 'RNA Splicing', 'Research Personnel', 'Risk', 'Risk Assessment', 'Sampling', 'Sequence Alignment', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Smoker', 'Source', 'Structure', 'Techniques', 'The Cancer Genome Atlas', 'Tissues', 'Variant', 'base', 'clinically relevant', 'computerized data processing', 'data mining', 'data sharing', 'experimental study', 'file format', 'functional genomics', 'genome sequencing', 'genomic data', 'human tissue', 'interest', 'large datasets', 'microbial', 'microbiome', 'open data', 'privacy preservation', 'social', 'tool', 'transcriptome sequencing']",NHGRI,YALE UNIVERSITY,R01,2021,526482
"MUFA-SIRT1 signaling as a central node regulating healthspan PROJECT SUMMARY Macronutrients serve a multitude of roles beyond provision of energy, with numerous nutrients and/or their downstream metabolites acting as signaling molecules to coordinate cellular metabolism and function. Indeed, numerous nutrient sensing pathways (e.g. mTOR, AMPK and sirtuins) have evolved allowing us to respond to specific nutrients/metabolites, which in turn impacts healthspan. Sirtuins are largely thought to be driven by redox, whereby high levels of NAD, a cofactor in the sirtuin reaction and indicator of low energy charge, drives sirtuin-catalyzed deacylation of target proteins. SIRT1, the most-studied sirtuin, is a key nutrient sensing node that regulates a plethora of cellular functions to promote lifespan extension and healthy aging. As a result, there is immense interest in the use of SIRT1 activating compounds (STACs) to prevent or treat a wide range of aging-related disease. The links between dietary macronutrients, nutrient sensing and healthspan have historically focused upon caloric or protein restriction with limited attention given to dietary lipids. However, a small and growing body of literature has linked monounsaturated fatty acids (MUFAs) to improved healthspan. In addition to positive effects on lifespan and healthy aging in model organisms, dietary MUFAs have been linked to wide-ranging health benefits in epidemiological studies and, since they are a primary constituent of olive oil, thought to contribute to the benefits of the Mediterranean Diet. Despite these studies, little is known about the biological underpinnings through which MUFAs elicit their beneficial health effects. We have previously shown that lipid droplet catabolism (i.e. lipolysis) increases SIRT1 and downstream PGC-1a/PPAR- a signaling as a means to increase mitochondrial biogenesis and function during times of nutrient deprivation. Our preliminary data show for the first time that MUFAs released specifically from lipolysis are trafficked to the nucleus where they allosterically activate SIRT1 towards select acetylated peptide substrates. This discovery makes MUFAs the first-known endogenous allosteric activators of SIRT1. Moreover, we show that MUFAs activate SIRT1 through a similar mechanism to resveratrol suggesting that MUFA signaling may modulate the response to exogenous SIRT1 activators. Based on these preliminary data, the objective of this application is to further characterize the role of MUFAs as endogenous SIRT1 activators. We hypothesize that MUFAs selectively activate SIRT1 to modulate the response to numerous dietary interventions known to impact healthspan. To test our objective, we propose the following aims: Aim 1: To define how MUFAs modulate SIRT1 substrate selectivity. Aim 2: To characterize the SIRT1-dependent effects of MUFAs/olive oil on healthspan. Aim 3: To determine the contribution of MUFAs in mediating the response to STACs or caloric restriction. Upon completion of the proposes studies, we will have further expanded our understanding of SIRT1 biology allowing for refined approaches to activate SIRT1 to promote healthy aging. NARRATIVE The proposed studies will advance our understanding into the underlying biology linking dietary factors to healthspan. The data gleaned from these studies will help refine therapeutic or nutritional avenues to modulate lifespan and aging-related diseases resulting in a direct, positive impact on human health.",MUFA-SIRT1 signaling as a central node regulating healthspan,10263268,R01AG069768,"['Aging', 'Animal Model', 'Animals', 'Attention', 'Biogenesis', 'Biological', 'Biology', 'Caloric Restriction', 'Catabolism', 'Cell Nucleus', 'Cell physiology', 'Charge', 'Clinical Trials', 'Data', 'Deacetylation', 'Development', 'Diet', 'Dietary Factors', 'Dietary Fats', 'Dietary Intervention', 'Disease', 'Dose', 'FRAP1 gene', 'Fasting', 'Glean', 'Gold', 'Health', 'Health Benefit', 'Human', 'Link', 'Lipids', 'Lipolysis', 'Literature', 'Longevity', 'Machine Learning', 'Macronutrients Nutrition', 'Maps', 'Mediating', 'Mediterranean Diet', 'Metabolism', 'Mitochondria', 'Modeling', 'Monounsaturated Fatty Acids', 'Mus', 'Nutrient', 'Nutritional', 'Oils', 'Olive oil preparation', 'Olives - dietary', 'Outcome', 'Oxidation-Reduction', 'PPAR alpha', 'Pathway interactions', 'Peptides', 'Pharmacologic Substance', 'Proteins', 'Proteomics', 'Reaction', 'Research', 'Resveratrol', 'Role', 'SIRT1 gene', 'Signal Transduction', 'Signaling Molecule', 'Sirtuins', 'Source', 'Testing', 'Therapeutic', 'Time', 'Work', 'analog', 'base', 'cofactor', 'deacylation', 'detection of nutrient', 'dietary', 'epidemiology study', 'healthspan', 'healthy aging', 'improved', 'innovation', 'interest', 'middle age', 'mutant mouse model', 'novel', 'nutrient deprivation', 'polyphenol', 'prevent', 'red wine', 'response']",NIA,UNIVERSITY OF MINNESOTA,R01,2021,317579
"National Alzheimer's Coordinating Center Project summary/abstract NACC (as U01 AG016976, at University of Washington) has been active since 1999. The existing NACC infrastructure is described in the Facilities and Resources Section of this application. The broad goals of the past funding cycles are consistent with those of the current U24 RFA — that is, to serve as: a.) the central hub for organizing and enabling communication within and outside of the ADRC program, including annual meetings and steering committees; b.) a national data resource, collecting data from the Alzheimer's Disease Research Centers (ADRCs) as well as affiliated data and sample repositories; and c.) a facilitator of current and future AD/ADRD research. NACC has considerable experience and success in reaching these goals, and is positioned for continued success in a rapidly advancing field. New data and methods are appearing in areas such as biomarkers, neuropathology, and tests for early detection. Through the strategic adoption of technological advances, we will build on these accomplishments at an accelerated pace. Building on our already significant capabilities, we will: promote and broaden communication within and outside of the ADRC program; expand informatics capabilities of NACC consistent with FAIR principles; conduct and support methodologic and applied research, leveraging deep expertise in biostatistics and data science; and support early-career research scientists by providing peer-reviewed competitive funding for several “junior investigators” each year. We aim to continue to improve our approach in each arena by combining time-tested approaches with the new tools and innovations we are developing to meet the changing scientific, technological, and communication needs of the NIA ADRC program and the field. Narrative NACC (as U01 AG016976, at University of Washington — now seeking renewal as a U24) has been active since 1999, and has established a standardized, longitudinal clinical database of over 42,000 individuals (with neuropathology data on over 6,100), as well as cross-sectional, retrospective data on roughly 66,000 individuals seen at ADRCs between 1984 and 2005. NACC has made these data freely available to researchers worldwide, resulting in hundreds of publications. We will modernize and intensify our informatics approach, making data access and use more efficient; will grow communication and coordination capabilities with the ADRCs and collaborating NIA projects; will develop and apply big-data research tools for the field; and will provide competitive, peer-reviewed research support for several new investigators each year. Together with the field’s leaders, NACC will innovate, develop, and drive solutions to meet the changing needs of the field as well as the NIA ADRC program.",National Alzheimer's Coordinating Center,10204491,U24AG072122,"['Achievement', 'Adoption', 'Age', 'Alzheimer disease prevention', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Applied Research', 'Area', 'Award', 'Big Data', 'Biological Markers', 'Biometry', 'Collaborations', 'Communication', 'Complex', 'Consultations', 'Contracts', 'Data', 'Data Collection', 'Data Coordinating Center', 'Data Science', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Dementia', 'Early Diagnosis', 'Enrollment', 'Environment', 'Faculty', 'Funding', 'Future', 'Genetic', 'Genetic Diseases', 'Genomics', 'Goals', 'Heterogeneity', 'Individual', 'Informatics', 'Infrastructure', 'Institutes', 'Lead', 'Leadership', 'Link', 'Medicine', 'Methodology', 'Methods', 'Mission', 'Modernization', 'Peer Review', 'Positioning Attribute', 'Publications', 'Recording of previous events', 'Research', 'Research Peer Review', 'Research Personnel', 'Research Support', 'Resources', 'Risk Factors', 'Sampling', 'Scientist', 'Secure', 'Services', 'Site', 'Source', 'Specimen', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Washington', 'base', 'career', 'clinical database', 'clinical examination', 'cohort', 'community center', 'data access', 'data resource', 'data sharing', 'data visualization', 'deep learning', 'digital', 'disease heterogeneity', 'e-science', 'experience', 'high standard', 'imaging biomarker', 'improved', 'innovation', 'instrument', 'interest', 'interoperability', 'meetings', 'neuroimaging', 'neuropathology', 'novel', 'programs', 'repository', 'social media', 'success', 'tool', 'translational health science', 'trend', 'web site']",NIA,UNIVERSITY OF WASHINGTON,U24,2021,6979612
"Reconstruction of heterogeneous and small macromolecules by cyro-EM PROJECT SUMMARY Single-particle electron cryomicroscopy (cryo-EM) has recently joined X-ray crystallography and NMR spectroscopy as a high-resolution structural method for biological macromolecules. In addition, cryo-EM produces images of individual molecules, and therefore has the potential to resolve conformational changes. The proposal aims to develop new algorithms and software for extending the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing computational tools for cryo-EM. This extension requires solving two of the most challenging computational problems posed by cryo-EM. First, mapping the structural variability of macromolecules is widely recognized as the main computational challenge in cryo-EM. Structural variations are of great significance to biologists, as they provide insight into the functioning of molecular machines. Existing computational tools are limited to a small number of distinct conformations, and therefore are incapable of tackling highly mobile biomolecules with multiple, continuous spectra of conformational changes. The first area of investigation in this project is the development of a computational framework to analyze continuous variability. The proposed approach is based on a new mathematical representation of continuously changing structures and its efficient estimation using Markov chain Monte Carlo (MCMC) algorithms. MCMC algorithms have found great success in many other scientific disciplines, yet they have been mostly overlooked for cryo-EM single particle analysis. Second, a major limiting factor for present cryo-EM studies is the molecule size. Images of small molecules (below ~50kDa) have too little signal to allow existing methods to provide valid 3-D reconstructions. It is commonly believed that cryo-EM cannot be used for molecules that are too small to be reliably detected and picked from micrographs. Challenging that widespread belief, the second area of investigation focuses on developing a groundbreaking approach for reconstructing small molecules directly from micrographs without particle picking. The new approach is based on autocorrelation analysis and completely bypasses particle picking and orientation assignment and requires just one pass over the data. The single-pass approach opens new possibilities for real-time processing during data acquisition. PROJECT NARRATIVE Determining structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, and a first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to significantly increase the power of structure-determination using electron cryomicroscopy (cryo-EM). Importantly, our methods will broaden the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing techniques.",Reconstruction of heterogeneous and small macromolecules by cyro-EM,10163220,R01GM136780,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Area', 'Belief', 'Biological', 'Biological Process', 'Bypass', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Cryoelectron Microscopy', 'Crystallization', 'Data', 'Data Set', 'Detection', 'Development', 'Diffusion', 'Dimensions', 'Discipline', 'Drug Design', 'Fostering', 'G-Protein-Coupled Receptors', 'Heterogeneity', 'Human Genome', 'Image', 'Individual', 'Institution', 'Investigation', 'Ion Channel', 'Ion Pumps', 'Machine Learning', 'Maps', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mathematics', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Molecular Motors', 'Molecular Weight', 'Motion', 'NMR Spectroscopy', 'Names', 'Noise', 'Particle Size', 'Phase', 'Polymerase', 'Preparation', 'Proteins', 'Pythons', 'Research', 'Resolution', 'Ribosomes', 'Roentgen Rays', 'Sampling', 'Signal Transduction', 'Spliceosomes', 'Structural Protein', 'Structure', 'Techniques', 'Time', 'Uncertainty', 'Update', 'Variant', 'Work', 'X-Ray Crystallography', 'base', 'computer framework', 'computerized data processing', 'computerized tools', 'data acquisition', 'expectation', 'flexibility', 'high dimensionality', 'improved', 'insight', 'interest', 'macromolecule', 'molecular mass', 'novel strategies', 'open source', 'particle', 'programs', 'protein complex', 'protein structure', 'receptor', 'reconstruction', 'small molecule', 'statistics', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2021,312940
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,10085664,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'detection limit', 'disease phenotype', 'driver mutation', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'machine learning method', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistical learning', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,305167
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,10183147,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Streptococcus pyogenes', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2021,729285
"Pro-inflammatory activation of human macrophages regulated by lncRNAs Project Summary Macrophage activation promotes major inflammatory disorders, including arterial diseases. Its underlying mechanisms, however, remain obscure. The present study will establish a systems approach, involving computational prediction analyses, multi-omics, network science, and in vitro and in vivo validation, to discover long noncoding RNA (lncRNA)-mediated mechanisms for pro-inflammatory activation of macrophages and arterial disease. In Specific Aim 1, we will involve omics studies of human macrophages to identify lncRNAs and their interacting proteins and develop computational analyses to predict human lncRNAs that regulate macrophage activation. Specific Aim 2 will examine the functionality of candidate lncRNAs in macrophage activation in vitro and in vivo. The findings from the study will help to identify new mechanisms for macrophage activation and may provide molecular bases for new therapies. Project Narrative Inflammation plays a key role in coronary artery disease and other major vascular diseases, global health threats. Even with potent risk modifiers, e.g., statins, many patients still suffer vascular events. Long noncoding RNAs (lncRNAs) regulate various biological processes. We aim to discover lncRNAs that promotes vascular inflammation. The potential outcomes will offer new targets for much needed therapies for vascular diseases.",Pro-inflammatory activation of human macrophages regulated by lncRNAs,10199025,R01HL149302,"['Address', 'Biological', 'Biological Process', 'Biology', 'Blood', 'Blood Vessels', 'Cells', 'Communities', 'Complex', 'Computational Biology', 'Computer Analysis', 'Coronary Arteriosclerosis', 'Data', 'Development', 'Discipline', 'Disease', 'Drug usage', 'Endotoxemia', 'Event', 'Gene Expression Profiling', 'Goals', 'Hematopoietic Stem Cell Transplantation', 'Heterogeneity', 'Human', 'In Vitro', 'Inflammation', 'Inflammatory', 'Laboratories', 'Lesion', 'Leukocytes', 'Life', 'Link', 'Machine Learning', 'Macrophage Activation', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Myocardial', 'NF-kappa B', 'Network-based', 'Outcome', 'Pathway Analysis', 'Patients', 'Plasma', 'Play', 'Protein Analysis', 'Proteins', 'Proteomics', 'RNA', 'Reporting', 'Residual state', 'Risk', 'Risk Factors', 'Role', 'Science', 'Signal Transduction', 'Small Interfering RNA', 'Splenocyte', 'System', 'Systems Biology', 'Tissues', 'Untranslated RNA', 'Validation', 'Vascular Diseases', 'arterial lesion', 'base', 'cytokine', 'experimental study', 'femoral artery', 'gain of function', 'global health', 'human disease', 'humanized mouse', 'in vivo', 'injured', 'loss of function', 'macrophage', 'modifiable risk', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel therapeutics', 'overexpression', 'protein protein interaction', 'single cell analysis', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'vascular inflammation']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,724962
"Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0) OVERALL: ABSTRACT  The scope of regenerative medicine encompasses the repair, regeneration, and replacement of defective, injured, and diseased tissues and organs. The success of regenerative therapies is dependent, at least in part, on a favorable microenvironment in which the regenerative processes occur. Technological innovations and a deepened mechanistic understanding of how these microenvironmental signals influence tissue regeneration has drawn attention to the critical importance of the clinical field with foundations in the application of physical, thermal, and electrical stimuli to promote functional restoration—rehabilitation. We propose that the fields of regenerative medicine and rehabilitative science are inextricably intertwined, an intersection of disciplines that we and others have termed Regenerative Rehabilitation. To realize the full potential of Regenerative Rehabilitation, there is a need for formalized mechanisms that promote the interaction of basic scientists with rehabilitation specialists. During the initial funding cycle, the Alliance for Regenerative Rehabilitation Research & Training (AR3T) built a national network of investigators and programs that has helped to expand scientific knowledge, expertise and methodologies across the domains of regenerative medicine and rehabilitation. This proposal seeks funding for AR3T 2.0, in which we will build on successes achieved and lessons learned over the initial period of support with the goal of being even more responsive to the needs of the greater community. Six specific aims define a framework upon which we will achieve our goals. AR3T will provide education and drive the science underlying Regenerative Rehabilitation by: 1) Providing didactic programs that expose rehabilitation researchers to cutting-edge investigations and state-of-the-art technologies in the field of regenerative medicine (Didactic Aim); 2) Cultivating collaborative opportunities between renowned investigators in the fields of regenerative medicine and rehabilitation (Collaborations Aim); 3) Coordinating a pilot funding program to support novel lines of Regenerative Rehabilitation research (Pilot Funding Aim); 4) Developing and validating technologies to advance the measurement and use of the regenerative rehabilitation programs (Technology Aim); 5) Promoting our center’s expertise to a broad community of trainees, investigators, and clinicians (Promotion Aim); 6) Carefully monitoring and evaluating the effectiveness of our program will ensure that we are successful in achieving our goals (Quality Control Aim). Administrative note: In the preparation of this proposal, we made every effort to present a comprehensive and detailed plan for achieving our goals while minimizing redundancy. Therefore, in multiple places, we refer the reader to specific components of the application, rather than repeating text. We appreciate the time and effort the reviewers devote to the evaluation of the proposals.  Sincerely, Fabrisia, Tom and Mike PROJECT NARRATIVE  Regenerative Rehabilitation is the integration of principles and approaches across the fields of rehabilitation science and regenerative medicine. The integration of these two fields will increase the efficiency of interventions designed to optimize physical functioning to the benefit of a wide range of individuals with disabilities. The Alliance for Regenerative Rehabilitation Research & Training (AR3T) 2.0 will build on the momentum gained over the first cycle of funding with the goal of continuing to illuminate and seize opportunities to expand scientific knowledge, expertise and methodologies in the domain of Regenerative Rehabilitation.",Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0),10210417,P2CHD086843,"['Accountability', 'Activities of Daily Living', 'Age', 'Attention', 'Awareness', 'Basic Science', 'Biocompatible Materials', 'Clinical', 'Collaborations', 'Communities', 'Congenital Abnormality', 'Country', 'Data Analyses', 'Development', 'Disabled Persons', 'Discipline', 'Disease', 'Documentation', 'Education', 'Effectiveness', 'Ensure', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'In Vitro', 'Incubators', 'Individual', 'Injury', 'Intervention', 'Investigation', 'Journals', 'Knowledge', 'Laboratories', 'Machine Learning', 'Marketing', 'Measurement', 'Mechanics', 'Mentors', 'Methodology', 'Methods', 'Mission', 'Monitor', 'Natural regeneration', 'Organ', 'Performance', 'Physical Function', 'Pre-Clinical Model', 'Preparation', 'Process', 'Quality Control', 'Reader', 'Regenerative Medicine', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Science', 'Scientist', 'Series', 'Signal Transduction', 'Specialist', 'Stimulus', 'Structure', 'Systems Analysis', 'Technology', 'Text', 'Time', 'Tissues', 'Training', 'Trauma', 'Treatment Efficacy', 'Update', 'career', 'effectiveness evaluation', 'falls', 'functional restoration', 'gait examination', 'healing', 'injured', 'innovation', 'interest', 'investigator training', 'multidisciplinary', 'new technology', 'novel', 'novel strategies', 'pre-clinical', 'programs', 'regenerative', 'regenerative rehabilitation', 'regenerative therapy', 'rehabilitation research', 'rehabilitation science', 'repaired', 'response', 'sabbatical', 'social media', 'success', 'symposium', 'technological innovation', 'therapy design', 'tissue regeneration', 'webinar']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P2C,2021,983634
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. Its software collection supports exploration and quantitative analyses of its own and other databases by providing a wide range of well-documented, rigorously tested open-source programs that can be run on any platform. PhysioNet's team of researchers drive the creation and enrichment of: i) Data collections that provide comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC (Medical Information Mart for Intensive Care) Databases of critical care patients; ii) Analytic methods for quantification of information encoded in physiologic signals relevant to risk stratification and health status assessment; iii) User interfaces, reference materials and services that add value and improve access to the resource’s data and software; and iv) unique annual Challenges focusing on high priority clinical problems, such as early prediction of sepsis, detection and quantification of sleep apnea syndromes from a single lead electrocardiogram (ECG), false alarm detection in the intensive care unit (ICU), continuous fetal ECG monitoring, and paroxysmal atrial fibrillation detection and prediction. PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are otherwise inaccessible. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world-wide, growing community of researchers, clinicians, educators, trainees, and medical instrument and software developers retrieve about 380 GB of data per day and publish a yearly average of nearly 300 new scholarly articles. Over the next five years we aim to: 1) Enhance PhysioNet’s impact with new data and technology; 2) Develop new methods to quantify dynamical information in physiologic signals relevant for health status assessment, and for acute and chronic risk stratification, and 3) Harness the research community through our international Challenges that address key clinical problems and a new data annotation initiative. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,10225620,R01EB030362,"['Acute', 'Address', 'Adult', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological Markers', 'Biomedical Research', 'Cardiovascular system', 'Chronic', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupling', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Doctor of Philosophy', 'Documentation', 'Educational Background', 'Electrocardiogram', 'Entropy', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Growth', 'Health Status', 'Heart failure', 'Image', 'Improve Access', 'Intensive Care', 'Intensive Care Units', 'International', 'Label', 'Lead', 'Legal patent', 'Life', 'Link', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Monitor', 'Neonatal', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patient Care', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Stroke', 'Students', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Work', 'analytical method', 'base', 'clinical care', 'cloud based', 'data archive', 'data exploration', 'data resource', 'fetal', 'graphical user interface', 'high school', 'innovation', 'instrument', 'instrumentation', 'interest', 'open source', 'opioid use', 'programs', 'repository', 'response', 'risk stratification', 'time interval', 'tool']",NIBIB,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2021,707970
"Structure based design of trimer interface epitope focused universal influenza vaccines The “Computational Models of Immunity” projects in this application focus on development and implementation of new structure-based design tools for influenza hemagglutinin (HA) protein trimer interface specific antibodies or vaccine antigens. These projects will use knowledge about the structure and function of human neutralizing antibodies to the trimer interface of the HA head that we have in hand or will discover, in order to design new antibodies or vaccines in silico. We have access to peripheral blood cells from a diverse panels of subjects with prior natural infection, or exposure to experimental inoculation with vaccines encoding HA molecules with both seasonal vaccines and unusual experimental influenza subtypes, including H3variant, H5, H6, H7, H9, and H10 viruses. The immune B memory cell populations from these individuals are the ideal starting materials to isolate unusual heterosubtypic antibodies. Recently, we identified the HA head trimer interface as a major new site of vulnerability for universal influenza antibodies and candidate vaccines. Here, we will study existing and isolate additional broadly heterosubtypic human antibodies to the trimer interface of the HA head. We will determine the immunome of the responding heterosubtypic clones using high-throughput next generation sequencing of antibody gene repertoires that comprise the clonal lineages of the most heterosubtypic antibodies isolated. Once antibodies with unusual breadth or activity are isolated, the structure of these antibodies will be determined in complex with purified HA molecules in the Structural Core using crystallography and single particle electron microscopy (EM) studies. Such structures will provide the coordinates for the modeling experiments using Rosetta. We will in silico mature human antibodies to increase affinity for the HA antigen of specific virus types and use multi-state design to maximize breadth, i.e., create antibodies that recognize HAs of all clades, subtypes, groups, or even types. We then will synthesize and express these novel antibodies and determine neutralization activity, binding affinity, and competition binding groups of designed antibodies, using a diverse HA panel and pseudotyped viruses with all type A HAs in nature. The co-crystal structure of these human antibodies with HA will be the template for in silico design of structurally stable epitope-focused immunogens. We will first validate these designed immunogens by testing the interaction with the target human antibodies. Further, these immunogens will be experimentally tested by evaluating immune responses. Then, we will use the novel immunogens to isolate new antibodies from subjects naturally exposed to influenza, to show that the immunogens present antigens recognized by natural immune responses. The next generation of viral vaccines and biologics alike will be designed rationally, based on a structural understanding of how protective antibodies engage the epitope of the target. The multidisciplinary group in this application will develop and implement new structure based computational models, and then validate the power of the computational design approach with laboratory experiments focused on the structural basis of broad neutralization of influenza through recognition of the a novel site of vulnerability in the interface of the hemagglutinin head domain.",Structure based design of trimer interface epitope focused universal influenza vaccines,10126805,U01AI150739,"['Affinity', 'Antibodies', 'Antibody Repertoire', 'Antigens', 'B-Lymphocytes', 'Binding', 'Binding Sites', 'Biological', 'Blood Cells', 'Cells', 'Complex', 'Computer Models', 'Crystallization', 'Crystallography', 'Development', 'Electron Microscopy', 'Engineering', 'Epitopes', 'Exposure to', 'Generations', 'Genes', 'Glycoproteins', 'Goals', 'Hand', 'Head', 'Hemagglutinin', 'Human', 'Immune', 'Immune response', 'Immunity', 'In Vitro', 'Individual', 'Infection', 'Influenza', 'Influenza Hemagglutinin', 'Influenza vaccination', 'Knowledge', 'Laboratories', 'Linear Programming', 'Machine Learning', 'Maps', 'Masks', 'Mass Spectrum Analysis', 'Memory B-Lymphocyte', 'Methods', 'Modeling', 'Nature', 'Polysaccharides', 'Population', 'Proteins', 'Research', 'Research Project Grants', 'Roentgen Rays', 'Sequence Analysis', 'Site', 'Standardization', 'Structure', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'Validation', 'Viral', 'Viral Vaccines', 'Virus', 'Virus Diseases', 'X-Ray Crystallography', 'antibody engineering', 'base', 'combat', 'cross reactivity', 'design', 'experimental study', 'immunogenicity', 'in silico', 'in vivo', 'influenza virus strain', 'influenza virus vaccine', 'influenzavirus', 'innovation', 'laboratory experiment', 'molecular recognition', 'mouse model', 'multidisciplinary', 'nanoparticle', 'neutralizing antibody', 'next generation', 'next generation sequencing', 'novel', 'pandemic disease', 'particle', 'programs', 'protective efficacy', 'receptor binding', 'response', 'scaffold', 'screening', 'structural biology', 'therapeutic vaccine', 'tool', 'universal influenza vaccine', 'vaccine candidate']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,U01,2021,1224163
"Mechanisms of mechano-chemical rupture of blood clots and thrombi Mechanisms of mechano-chemical rupture of blood clots and thrombi Prashant K. Purohit, John L. Bassani, Valeri Barsegov and John W. Weisel The goal of this proposal is to explore and understand the fracture toughness of blood clots and thrombi, thus providing a mechanistic basis for life-threatening thrombotic embolization. A combination of experiments, theoretical modeling and computer simulations will reveal how mechanical stresses (due to blood flow) in synergy with enzymatic lysis induce structural damage from the molecular to continuum scales and affect the propensity of a clot to embolize. The specific aims of this proposal are: (1) Measure and model fracture toughness of fibrin gels in quasi-static conditions, (2) Investigate rate dependent dissipative effects on toughness of fibrin gels, and (3) Study the effects of blood cells, prothrombotic blood composition, and fibrinolysis on rupture of blood clots. In Specific Aim (SA) 1, we will measure toughness of fibrin clots and provide a structural basis for rupture at the micron and nanometer scales. In SA2, we will delve into the thermodynamics and rate-dependence of the fracture of fibrin gels, including fluid flow through pores and fluid drag on fibrin fibers to capture how energy dissipation increases toughness. In the translational SA3, we will investigate toughness of physiologically relevant clots with effects of platelets, red blood cells, and neutrophils in the absence and presence of the physiological fibrinolytic activator (tPA). We will also study the rupture of clots made from the blood of venous thromboembolism patients to explore the effects of (pro)thrombotic alterations of blood composition on clot mechanical stability. Our preliminary studies show that i) the toughness of cross-linked fibrin gels is in the range of those for synthetic hydrogels, ii) the addition of tPA to a crack tip reduces the loads for crack growth, iii) fibers are aligned and broken along the tensile direction at the crack tip, and iv) crack propagation results from the rupture of covalent and non-covalent bonds. We also developed v) dynamic force spectroscopy in silico to mechanically test fibrin fibers and fibrin networks using pulling simulations and vi) atomic stress approach to map the stress-strain fields using the output from simulations. We will use continuum and finite element models of swellable biopolymer hydrogels, and statistical mechanical models for the forced unfolding of fibrin molecules. We will employ multiscale computational modeling based on Molecular Dynamics simulations of atomic structures of fibrin fibers, and Langevin simulations of fibrin networks accelerated on Graphics Processing Units. The proposed experiments cover the whole gamut of macroscopic tensile tests, shear rheometry, electron microscopy and confocal microscopy to visualize and quantitate the structural alterations of ruptured blood clots. Our experiments and modeling will help us to understand the mechanisms of thrombotic embolization and will address the clinically important question: why is there a strong association between clot structure/mechanical properties and cardiovascular diseases? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering. Project Narrative The research objective of this proposal is to measure, model and predict the mechanisms of mechano-chemical rupture of blood clots and thrombi at the molecular and continuum length scales. Our experiments and modeling will help to understand the mechanisms of embolization and will address the clinically important question: why is there a strong correlation between clot structure/mechanical properties and cardiovascular disease? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering.",Mechanisms of mechano-chemical rupture of blood clots and thrombi,10165811,R01HL148227,"['Address', 'Affect', 'Biocompatible Materials', 'Biological', 'Biomedical Engineering', 'Biopolymers', 'Blood', 'Blood Cells', 'Blood Platelets', 'Blood coagulation', 'Blood flow', 'Cardiovascular Diseases', 'Cause of Death', 'Chemicals', 'Clinical', 'Clinical Medicine', 'Coagulation Process', 'Complex', 'Computer Models', 'Computer Simulation', 'Confocal Microscopy', 'Cytolysis', 'Dependence', 'Diagnosis', 'Disease', 'Electron Microscopy', 'Elements', 'Enzymes', 'Erythrocytes', 'Evolution', 'Fiber', 'Fibrin', 'Fibrinogen', 'Fibrinolysis', 'Fracture', 'Frustration', 'Gel', 'Glean', 'Goals', 'Growth', 'Hydrogels', 'Knowledge', 'Laws', 'Length', 'Life', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Mechanical Stress', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Molecular Structure', 'Output', 'Patients', 'Physicians', 'Physiological', 'Plasma', 'Predisposition', 'Prevention', 'Process', 'Property', 'Prophylactic treatment', 'Proteins', 'Research', 'Research Proposals', 'Resistance', 'Resources', 'Rupture', 'Specimen', 'Spectrum Analysis', 'Stress', 'Structural Models', 'Structural defect', 'Structure', 'Testing', 'Theoretical Studies', 'Theoretical model', 'Therapeutic Embolization', 'Thermodynamics', 'Thick', 'Thrombin', 'Thromboembolism', 'Thrombosis', 'Thrombus', 'Traction', 'Work', 'base', 'crosslink', 'density', 'design', 'disability', 'experimental study', 'fiber cell', 'fluid flow', 'in silico', 'in vivo', 'insight', 'instrumentation', 'interdisciplinary approach', 'materials science', 'mechanical properties', 'models and simulation', 'molecular dynamics', 'molecular scale', 'multi-scale modeling', 'nanoscale', 'neutrophil', 'novel strategies', 'predictive modeling', 'prevent', 'response', 'simulation', 'synergism', 'theories', 'thrombotic', 'tool', 'venous thromboembolism', 'viscoelasticity']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R01,2021,639595
"Multi-omic networks associated with COPD progression in TOPMed Cohorts PROJECT SUMMARY Chronic obstructive pulmonary disease (COPD) is the fourth leading cause of death in the US. Although COPD occurs predominantly in smokers, it is unknown why only a minority of smokers (~20-40%) develop chronic airflow limitation or destruction of distal airspaces (emphysema). The difference susceptibility to tobacco smoke could be explained by differences in genetics or environment, which lead to activation or repression of pathways that are important in the pathogenesis and progression of COPD. Recent advances in high throughput omics (whole genome sequencing, DNA methylation, RNA-Seq, proteomics and metabolomics) applied to NHLBI cohorts now permits a comprehensive assessment of the molecular profiles of susceptible patients. This proposal will use sparse multiple canonical correlation network analysis (SmCCNet) to integrate these existing -omics data from three NHLBI cohorts: COPDGene, Jackson Heart Study, and SPIROMICS. The three independent cohorts will allow replication of specific molecular networks which can be used to target new therapies or more precise prognostic information to individuals (i.e., precision medicine). The first two of these cohorts have large numbers of African American subjects, who are underrepresented in omics studies. We will perform population specific analyses, which will allow us to determine which molecular signatures and pathways might be specific to African Americans. PROJECT NARRATIVE Chronic obstructive pulmonary disease (COPD) is the fourth leading cause of death in the US. To help identify why only some smokers develop COPD, this proposal will integrate recently collected extensive molecular profiles from three NHLBI cohorts (COPDGene, Jackson Heart Study, and SPIROMICS) to discover molecular networks that are important in both diagnosis and progression. In addition to non- Hispanic Whites, by focusing on African Americans, which are highly underrepresented in these types of studies, we expect that there are specific molecular network differences that may lead to specific therapies (i.e., precision medicine) based on race/ethnicity.",Multi-omic networks associated with COPD progression in TOPMed Cohorts,10138019,R01HL152735,"['African American', 'Biology', 'Cause of Death', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Complex', 'Computers', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease Progression', 'Distal', 'Environment', 'Epidemiologist', 'Epigenetic Process', 'Ethnic Origin', 'Genetic', 'Genetic Markers', 'Individual', 'Investigation', 'Jackson Heart Study', 'Knowledge', 'Lead', 'Lung', 'Methods', 'Minority', 'Molecular', 'Molecular Disease', 'Molecular Profiling', 'National Heart, Lung, and Blood Institute', 'Not Hispanic or Latino', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Phenotype', 'Population', 'Predisposition', 'Proteomics', 'Publications', 'Pulmonary Emphysema', 'Quantitative Trait Loci', 'Race', 'Repression', 'Research', 'Research Design', 'Research Personnel', 'Sample Size', 'Scanning', 'Scientist', 'Smoker', 'Spirometry', 'System', 'Technology', 'Tobacco smoke', 'Trans-Omics for Precision Medicine', 'Transcript', 'Underrepresented Minority', 'Work', 'X-Ray Computed Tomography', 'airway obstruction', 'alpha 1-Antitrypsin', 'base', 'chronic airflow obstruction', 'clinical phenotype', 'cohort', 'disease phenotype', 'genetic variant', 'genome sequencing', 'improved', 'metabolomics', 'multidisciplinary', 'multiple omics', 'new therapeutic target', 'novel', 'novel diagnostics', 'precision medicine', 'prognostic', 'protein metabolite', 'single molecule', 'soluble RAGE', 'transcriptome sequencing', 'transcriptomics', 'unsupervised learning', 'whole genome']",NHLBI,UNIVERSITY OF COLORADO DENVER,R01,2021,759026
"Modeling to Design Treatments for Idiopathic Lung Fibrosis PROJECT SUMMARY Every year in this country 40,000 patients are diagnosed with idiopathic pulmonary fibrosis (IPF), a progressive and terminal disease caused by excessive extracellular matrix production by myofibroblasts in distributed lesions, or “fibrotic foci”, throughout the lung. Despite the availability of two FDA-approved drugs that are considered standard of care, the mortality rate for IPF patients exceeds 30% at four years, and there are no drugs that halt disease progression, making diagnosis with IPF a death sentence for over 500,000 Americans living with this disease. Identifying the cells of origin that give rise to myofibroblasts is necessary for finding treatments that can halt or cure IPF. Based on experimental data and computational simulations from our research team, we hypothesize that myofibroblasts arise from microvascular pericytes (cells that normally enwrap capillaries) when heterotypic pericyte-endothelial interactions become disrupted. We further posit that strategic modulation of kinase-mediated signaling in pericytes can prevent pericyte-to-myofibroblast transitions and halt the progression of IPF. We propose to combine computational modeling with experiments to study pericyte-to-myofibroblast differentiation and to investigate how microvessel adaptations in the lung contribute to IPF. Specifically, we will develop a new agent-based model (ABM) that incorporates logic-based intracellular signaling networks to simulate cell behaviors and leverages Bayesian inference for rule refinement (Aim 1), validate the ABM's ability to predict pericyte phenotype transitions and the emergence of fibrotic foci in response to drugs using the murine bleomycin model of IPF (Aim 2), and bridge murine experiments with clinical data in order to predict how druggable kinase-driven signaling pathways affect IPF progression via modulation of pericytes and microvessels (Aim 3). To our knowledge, our proposed studies will be the first to combine computational modeling with experiments to study microvascular contributors to IPF progression. In addition to producing a new computational model that is validated for bridging pre-clinical study results to clinical outcomes, we expect to identify new therapeutic approaches for IPF that target microvascular cells, previously underexplored but potentially critical contributors to this deadly disease. PROJECT NARRATIVE Idiopathic pulmonary fibrosis (IPF) is a deadly disease caused by uncontrolled tissue fibrosis in the lungs. There are no FDA-approved drugs that cure or prevent disease progression. We propose to combine computational modeling with experiments study how fibroblasts and microvessel remodeling in the lung contribute to disease and to identify novel drugs and drug combinations that target these processes in order to effectively treat IPF.",Modeling to Design Treatments for Idiopathic Lung Fibrosis,10305193,R01HL155143,"['Affect', 'Alveolar', 'American', 'Bayesian Analysis', 'Biological', 'Bleomycin', 'Blood capillaries', 'Cardiac', 'Cell Communication', 'Cells', 'Cessation of life', 'Cicatrix', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Computer Models', 'Computer Simulation', 'Country', 'Data', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Drug Combinations', 'Drug Targeting', 'Drug usage', 'Endothelial Cells', 'Endothelium', 'Environment', 'Extracellular Matrix', 'FDA approved', 'Fibroblasts', 'Fibrosis', 'Harvest', 'Heterogeneity', 'Histology', 'Human', 'Impairment', 'Lesion', 'Logic', 'Lung', 'Machine Learning', 'Mediating', 'Modeling', 'Molecular', 'Mus', 'Myofibroblast', 'Nature', 'New Agents', 'Outcome', 'Output', 'Patients', 'Pericytes', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Pirfenidone', 'Platelet-Derived Growth Factor', 'Platelet-Derived Growth Factor Receptor', 'Process', 'Production', 'Progressive Disease', 'Publishing', 'Pulmonary Fibrosis', 'Research', 'Retina', 'Signal Pathway', 'Signal Transduction', 'Tamoxifen', 'Terminal Disease', 'Time', 'Tissues', 'To specify', 'Transforming Growth Factors', 'Translating', 'Validation', 'Vascular Endothelial Growth Factor Receptor-1', 'Vascular Endothelial Growth Factors', 'base', 'cell behavior', 'experimental study', 'human data', 'idiopathic pulmonary fibrosis', 'kinase inhibitor', 'models and simulation', 'mortality', 'mouse model', 'new therapeutic target', 'novel', 'novel drug combination', 'novel therapeutic intervention', 'novel therapeutics', 'pre-clinical', 'preclinical study', 'predicting response', 'predictive modeling', 'prevent', 'pulmonary agents', 'pulmonary function', 'response', 'skeletal', 'standard of care', 'therapy design', 'transcriptome sequencing', 'transcriptomics']",NHLBI,UNIVERSITY OF VIRGINIA,R01,2021,548214
"Metabolic Basis of Bacterial Community Function in the Cystic Fibrosis Airway Abstract. Cystic fibrosis (CF) is a fatal genetic disease characterized by overproduction of mucus in the lungs followed by chronic lung infections. Conventional wisdom has been that most CF lung infections involve a single dominant organism, most commonly the pathogenic bacterium Pseudomonas aeruginosa. Advances in culture-independent techniques have revealed that CF lung infections are rarely mono-microbial and instead usually involve complex microbial communities, yet the interspecies interactions that drive these communities are poorly understood. Furthermore, numerous studies have demonstrated that polymicrobial infections are more difficult than mono-microbial infections to eradicate with antibiotics, leading to the concept of recalcitrant communities. The mechanisms underlying recalcitrance are thought to involve synergistic interactions between community members, but very little data are available to understand this phenomenon. Combined with the realization that many CF patients respond poorly to available antibiotic regimens compels a more detailed understanding of interspecies interactions and their impacts on antibiotic recalcitrance to improve the treatment of CF infections, as well as other polymicrobial diseases. Here, we combine big-data bioinformatics, in silico computational modeling and in vitro culture experiments to gain insights into the metabolic interactions that drive CF disease outcomes and antibiotic recalcitrance. The research will leverage an available data set of hundreds of CF patient samples that provide both bacterial composition data and clinical metadata, including measures of lung function. These samples will be clustered according to their measured compositions and metabolic capabilities predicted through computational metabolic modeling to test the hypothesis that the vast complexity of these many bacterial communities can be collapsed into a small number of model communities that capture most of the observed metabolic variability. These computational predictions will be tested by developing in vitro cell culture models that recapitulate the most important metabolic features of the in vivo polymicrobial communities (Aim 1). By applying bioinformatics and modeling to the same clinical data, we will test the hypothesis that community metabolic features drive disease outcomes and the virulence potential of these communities (Aim 2). Finally, we will interrogate the clinical data and in vitro communities to test the hypothesis that community metabolic features drive antibiotic recalcitrance and differentiate community responsiveness to antibiotics according to these metabolic features (Aim 3). Our research will yield novel insights into how complex polymicrobial communities are compositionally structured, interact metabolically, contribute to disease and respond to antibiotics. Moreover, the research will validate in vitro models that offer the potential for development of novel antimicrobial strategies to better treat chronic, polymicrobial infections in CF and other diseases. Our transdisciplinary team offers the necessary expertise in bioinformatics, computational modeling, microbial physiology and CF polymicrobial infections to tackle this complex problem. Project Narrative: Infections associated with cystic fibrosis, and other polymicrobial infections, are still a significant cause of morbidity and mortality. Here we propose to apply bioinformatics, modeling and experimental tools to a large clinical data set to gain new insight into how to treat complex, chronic polymicrobial infections.",Metabolic Basis of Bacterial Community Function in the Cystic Fibrosis Airway,10293007,R01AI155424,"['Acute', 'Acute Disease', 'Antibiotics', 'Antimicrobial Resistance', 'Bacteria', 'Big Data', 'Bioinformatics', 'Cell Culture Techniques', 'Chronic', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Communities', 'Complex', 'Computer Models', 'Consumption', 'Culture-independent methods', 'Cystic Fibrosis', 'Data', 'Data Set', 'Development', 'Disease', 'Disease Outcome', 'Dose', 'Energy-Generating Resources', 'Event', 'Exhibits', 'Experimental Models', 'Exposure to', 'Feeding Patterns', 'Genetic Diseases', 'Genetic study', 'In Vitro', 'Individual', 'Infection', 'Lung', 'Lung infections', 'Machine Learning', 'Measures', 'Metabolic', 'Metadata', 'Microbe', 'Microbial Physiology', 'Minimum Inhibitory Concentration measurement', 'Modeling', 'Morbidity - disease rate', 'Mucous body substance', 'Mutation', 'Nature', 'Organism', 'Outcome', 'Outcome Measure', 'Output', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Pseudomonas aeruginosa', 'Pseudomonas aeruginosa infection', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Regimen', 'Research', 'Resistance', 'Role', 'Sampling', 'Sputum', 'Staphylococcus aureus', 'Streptococcus', 'Structure', 'Testing', 'Virulence', 'Work', 'antibiotic tolerance', 'antimicrobial', 'antimicrobial drug', 'bacterial community', 'base', 'bioinformatics tool', 'cystic fibrosis airway', 'cystic fibrosis infection', 'cystic fibrosis patients', 'experimental study', 'feeding', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'insight', 'member', 'metabolomics', 'microbial', 'microbial community', 'mortality', 'novel', 'novel therapeutics', 'pathogenic bacteria', 'polymicrobial biofilm', 'polymicrobial disease', 'pulmonary function', 'pulmonary function decline', 'success', 'tool', 'translational impact']",NIAID,DARTMOUTH COLLEGE,R01,2021,466513
"Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics Project Summary/Abstract Viral genome sequencing is growing exponentially and cutting-edge molecular technologies, guided by genomic data, show great promise in detecting and responding to viruses. Yet we lack a computational framework that efficiently leverages viral data to design the nucleic or amino acid sequences applied by these technologies. The proposal provides a career development plan to (i) build computational techniques — algorithms, models, and software — that yield highly accurate diagnostic assays, with potential to outperform existing ones, and (ii) use the techniques to proactively design assays for detecting 1,000s of viruses. The project will first develop methods for designing optimal viral genome-informed diagnostics. The study will formulate objective functions that evaluate an assay’s performance across a distribution of anticipated viral targets. Combinatorial optimization algorithms and generative models, constructed in the study, will optimize the functions. The project will also develop datasets for training predictive models of assay performance, which are used in the objective functions, focusing on CRISPR-, amplification-, and antigen-based diagnostics. Preliminary experimental results suggest such models can render assays with exquisite sensitivity and specificity. The study will compare the algorithmically-designed assays to state-of-the-art tests for four viruses. With these methods, the project will design diagnostic assays that are species-specific and broadly effective across genomic diversity for all viruses known to infect vertebrates. The study will build a system to monitor the assays’ effectiveness against emerging viral genomic diversity and to continually update them as needed. To enable the broad adoption of these methods, the project will implement them efficiently in accessible software. The proposal aligns with a NIAID goal of improving diagnostics via data science. The methods developed here may also aid therapy and vaccine design, and will leave the world better prepared to combat viral outbreaks. The career development award will provide training for the candidate in applied areas of long-term interest to his career. The candidate has previous experience in developing computational methods and analyzing viral genomes. Through the award, he will gain new knowledge and skills in diagnostic applications, alongside formal and informal training in immunology, bioengineering, and related laboratory techniques. This training will help the candidate progress toward therapy and vaccine applications that could benefit from advanced computational methods. The Broad Institute provides a supportive environment for the candidate’s development, including career development workshops, research seminars aligned with the proposed plan, and opportunities to initiate collaborations with scientists having expertise complementary to the candidate’s. The research and training will help him form an independent research group focused on developing and applying computational methods to enable more effective microbial surveillance and response. Project Narrative Viral genomic data is reshaping how we prepare for and respond to viral threats, but there is a scarcity of computational techniques that harness this vast, ever-growing data for designing diagnostic assays. The project will develop and test algorithms, machine learning models, and software systems to efficiently design highly accurate diagnostic assays by optimizing well-defined objective functions, applied to multiple diagnostic technologies, and will build a resource of broadly effective diagnostic assays for 1,000s of viral species. The resource and software developed in the project will advance capabilities for detecting viruses, and the new methods may accommodate challenges in designing more effective viral therapies and vaccines.",Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics,10284445,K01AI163498,"['2019-nCoV', 'Adoption', 'Algorithm Design', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Award', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Biomedical Engineering', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Combinatorial Optimization', 'Computational Technique', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Dengue', 'Detection', 'Development', 'Development Plans', 'Diagnostic', 'Disease Outbreaks', 'Educational workshop', 'Effectiveness', 'Ensure', 'Failure', 'Focus Groups', 'Genome', 'Genomics', 'Goals', 'Growth', 'Immunology', 'Influenza', 'Institutes', 'K-Series Research Career Programs', 'Knowledge', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Nucleic Acids', 'Performance', 'Research', 'Research Training', 'Resolution', 'Resources', 'Scientist', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Validation', 'Variant', 'Vertebrates', 'Viral', 'Viral Genome', 'Virus', 'ZIKA', 'accurate diagnostics', 'advanced analytics', 'antigen diagnostic', 'base', 'career', 'career development', 'combat', 'computer framework', 'design', 'detection assay', 'diagnostic assay', 'diagnostic technologies', 'enzyme activity', 'experience', 'genome sequencing', 'genomic data', 'improved', 'insight', 'interest', 'microbial', 'model design', 'pathogen', 'predictive modeling', 'predictive test', 'prevent', 'response', 'skills', 'software development', 'software systems', 'spatiotemporal', 'success', 'supportive environment', 'therapy design', 'viral genomics']",NIAID,"BROAD INSTITUTE, INC.",K01,2021,129165
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,10147906,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2021,417279
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"OpenMM: Scalable biomolecular modeling, simulation, and machine learning PROJECT SUMMARY / ABSTRACT OpenMM [http://openmm.org] is the most widely-used open source GPU-accelerated framework for biomolecular modeling and simulation (>1300 citations, >270,000 downloads, >1M deployed instances). Its Python API makes it widely popular as both an application (for modelers) and a library (for developers), while its C/C++/Fortran bindings enable major legacy simulation packages to use OpenMM to provide high performance on modern hardware. OpenMM has been used for probing biological questions that leverage the $14B global investment in structural data from the PDB at multiple scales, from detailed studies of single disease proteins to superfamily-wide modeling studies and large-scale drug development efforts in industry and academia. Originally developed with NIH funding by the Pande lab at Stanford, we aim to fully transition toward a community governance and sustainable development model and extend its capabilities to ensure OpenMM can power the next decade of biomolecular research. To fully exploit the revolution in QM-level accuracy with machine-learning (ML) potentials, we will add plug-in support for ML models augmented by GPU-accelerated kernels, enabling transformative science with QM-level accuracy. To enable high-productivity development of new ML models with training dataset sizes approaching 100 million molecules, we will develop a Python framework to enable OpenMM to be easily used within modern ML frameworks such as TensorFlow and PyTorch. Together with continued optimizations to exploit inexpensive GPUs, these advances will power a transformation within biomolecular modeling and simulation, much as deep learning has transformed computer vision. PROJECT NARRATIVE Biomolecular modeling and simulation is a key technology for leveraging the $14B global investment in biomolec- ular structure data in the protein databank to understand the basic molecular mechanisms underlying biology and disease and the development of new therapies. In this proposal, we aim to expand the development of OpenMM, a free and open source biomolecular modeling and simulation package that can exploit a wide range of consumer-grade and high-end graphics processing units (GPUs) to enable researchers and applications built on OpenMM to achieve high performance with extreme ﬂexibility. A key aspect of this proposal is to accelerate research in the emerging ﬁeld of biomolecular machine learning by tightly integrating OpenMM with modern ma- chine learning frameworks, enabling researchers to build, use, and deploy machine learning potentials, collective variables, and integrators to advance the state of biomolecular modeling.","OpenMM: Scalable biomolecular modeling, simulation, and machine learning",10100573,R01GM140090,"['Academia', 'Architecture', 'Automobile Driving', 'Binding', 'Biological', 'Biological Process', 'Biological Response Modifier Therapy', 'Biology', 'Chemical Models', 'Chemicals', 'Chemistry', 'Code', 'Communities', 'Computer Vision Systems', 'Custom', 'Data', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Ensure', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Home environment', 'Hybrids', 'Industry', 'Investigation', 'Investments', 'Laboratories', 'Learning', 'Libraries', 'Ligands', 'Machine Learning', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Conformation', 'Performance', 'Plug-in', 'Productivity', 'Proteins', 'Pythons', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Speed', 'Standardization', 'Structure', 'Study models', 'Sustainable Development', 'System', 'Technology', 'TensorFlow', 'Training', 'United States National Institutes of Health', 'Update', 'Work', 'cluster computing', 'deep learning', 'deep neural network', 'drug development', 'enzyme mechanism', 'flexibility', 'insight', 'interoperability', 'model development', 'models and simulation', 'molecular mechanics', 'next generation', 'novel therapeutics', 'open source', 'operation', 'physical model', 'predictive modeling', 'protein data bank', 'quantum', 'repository', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2021,426294
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,10136061,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2021,579506
"Center for Machine Learning in Urology PROJECT SUMMARY We propose to establish an Exploratory Center for Interdisciplinary Research in Benign Urology at the Children’s Hospital of Philadelphia (CHOP) and the University of Pennsylvania (Penn), the central mission of which is to apply machine learning to improve the understanding of the pathophysiology, diagnosis, risk stratification, and prediction of treatment responses of benign urological disease among children and adults. The proposed CHOP/Penn Center for Machine Learning in Urology (CMLU) addresses critical structural and scientific barriers that impede the development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. Structurally, urologic research occurs in silos, with little interaction among investigators that study different diseases or different populations (e.g. pediatric and adult). Scientifically, analysis of imaging and other types complex data is limited by inter-observer variability, and incomplete utilization of available information. This proposal overcomes these barriers by applying cutting-edge approaches in machine learning to analyze CT images that are routinely obtained for evaluation of individuals with kidney stone disease. Central to the CHOP/Penn CMLU is the partnership of urologists and experts in machine learning, which will bring a new approach to generating knowledge that advances research and clinical care. In addition, the CMLU will expand the urologic research community by providing a research platform and standalone machine learning executables that could be applied to other datasets. The Center’s mission will be achieved through the following Aims, with progress assessed through systematic evaluation: Aim 1. To expand the research base investigating benign urological disease. We will establish a community with the research base, particularly with the KURe, UroEpi programs, other P20 Centers, and O’Brien Centers. We will build this community by providing mini-coaching clinics to facilitate application of machine learning to individual projects, developing an educational hub for synchronous and asynchronous engagement with the research base, and making freely available all source codes and standalone executables for all machine learning tools. Aim 2. To improve prediction of ureteral stone passage using machine learning of CT images. The CMLU has developed deep learning methods that segment and automate measurement of urinary stones and adjacent renal anatomy. In the Research Project, we will compare these methods to existing segmentation methods and the current gold standard of manual measurement. We will then extract informative features from thousands of CT scans to predict the probability of spontaneous passage of ureteral stones for children and adults evaluated in the CHOP and Penn healthcare systems. Aim 3. To foster collaboration in benign urological disease research across levels of training and centers through an Educational Enrichment Program. We will amplify interactions across institutions and engage investigators locally and nationally by providing summer research internships, and interinstitutional exchange program, and an annual research symposium. PROJECT NARRATIVE The proposed CHOP/Penn O’Brien Center for Machine Learning in Urology addresses critical structural and scientific barriers that impede development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. This application overcomes these barriers by applying cutting- edge approaches in machine learning to analyze complex imaging data for individuals with kidney stone disease.The Center’s strategic vision of using machine learning to generate knowledge that improves diagnosis, risk stratification strategies, and prediction of outcomes among children and adults will be achieved through the implementation of a Educational Enrichment Program and a Research Project.",Center for Machine Learning in Urology,10260577,P20DK127488,"['Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Benign', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Investigator', 'Code', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Educational Status', 'Evaluation', 'Fostering', 'Functional disorder', 'Funding', 'Future', 'Gold', 'Healthcare Systems', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internships', 'Interobserver Variability', 'Investigation', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Lead', 'Longevity', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Mission', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pediatric Hospitals', 'Pennsylvania', 'Philadelphia', 'Population', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Probability', 'Publishing', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Site', 'Source Code', 'Structure', 'Students', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Urinary Calculi', 'Urologic Diseases', 'Urologist', 'Urology', 'Vision', 'Visit', 'X-Ray Computed Tomography', 'base', 'clinical care', 'complex data', 'deep learning', 'deep neural network', 'design', 'experience', 'feature selection', 'human error', 'improved', 'interdisciplinary collaboration', 'interest', 'learning strategy', 'novel strategies', 'outcome prediction', 'peer', 'programs', 'risk stratification', 'routine imaging', 'senior faculty', 'skills', 'summer research', 'symposium', 'tool', 'urologic', 'web page']",NIDDK,CHILDREN'S HOSP OF PHILADELPHIA,P20,2021,332101
"Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors Project Summary Scientific understanding of adaptive immune receptors (i.e. antibodies and T cell receptors) has the potential to revolutionize prophylaxis, diagnosis, and treatment of disease. High‐throughput DNA sequencing and functional experiments have now brought the study of adaptive immune receptors into the big‐data era. To realize this potential of these data they must be matched with appropriately powerful analytical techniques. Existing probabilistic and mechanistic models are insufficient to capture the complexities of these data, while a naïve application of machine learning cannot leverage our profound existing knowledge of the immune system. The goal of this project is to blend deep learning with mechanistic modeling in order to predict and understand the evolution and function of adaptive immune receptors. Aim 1: Develop generative models of immune receptor sequences that capture the complexity of real adaptive immune receptor repertoires. These will combine deep learning along with our knowledge of VDJ recombination, and provide a rigorous platform for detailed repertoire comparison. Aim 2: Develop quantitative mechanistic models of antibody somatic hypermutation that incorporate the underlying biochemical processes. Estimate intractable likelihoods using deep learning to infer important latent variables, and validate models using knock‐out experiments in cell lines. Aim 3: Develop hybrid deep learning models to predict binding properties from sequence data, combining large experimentally‐derived binding data with even larger sets of immune sequences from human immune memory samples. Incorporate structural information via 3D convolution or distance‐based penalties. These tools will reveal the full power of immune repertoire data for medical applications. We will obtain more rigorous comparisons of repertoires via their distribution in a relevant space. These will reveal the effects of immune perturbations such as vaccination and disease, allowing us to pick out sequences that are impacted by these perturbations. We will have a greater quantitative understanding of somatic hypermutation in vivo, and statistical models that appropriately capture long‐range effects of collections of mutations. We will also have algorithms that will be able to combine repertoire data and sparse binding data to predict binding properties. Put together, these advances will enable rational vaccine design, treatment for autoimmune disease, and identification of T cells that are promising candidates for cancer immunotherapy. Project Narrative Adaptive immune receptors (i.e. antibodies and T cell receptors) enable our body to fight off disease, “remember” pathogens, and train the immune system through vaccination. Immunologists have learned via high‐throughput sequencing that adaptive immune receptors have a truly remarkable diversity. In this proposal, we develop machine‐learning methods for these sequence data, which will allow us to predict the maturation, statistical distribution, and binding properties of adaptive immune receptors, and thus to better design vaccinations, autoimmune disease treatment, and immunotherapy treatment for cancer.",Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors,10159730,R01AI146028,"['3-Dimensional', 'Algorithms', 'Animal Model', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Autoimmune Diseases', 'Automobile Driving', 'Big Data', 'Binding', 'Biochemical', 'Biochemical Process', 'Categories', 'Cell Line', 'Characteristics', 'Collection', 'Complement', 'Complex', 'Data', 'Data Set', 'Dependence', 'Diagnosis', 'Disease', 'Entropy', 'Evolution', 'Exposure to', 'Foundations', 'Gene Conversion', 'Generations', 'Goals', 'High-Throughput DNA Sequencing', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Immune', 'Immune response', 'Immune system', 'Immunoglobulin Somatic Hypermutation', 'Immunologic Memory', 'Immunologic Receptors', 'Immunological Models', 'Immunologics', 'Immunologist', 'Immunology', 'Immunotherapy', 'In Vitro', 'Individual', 'Knock-out', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Pathway interactions', 'Population', 'Procedures', 'Process', 'Property', 'Prophylactic treatment', 'Resolution', 'Sampling', 'Science', 'Statistical Distributions', 'Statistical Methods', 'Statistical Models', 'Structure', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'V(D)J Recombination', 'Vaccination', 'Vaccine Design', 'Vaccines', 'Validation', 'Work', 'algorithm training', 'analytical tool', 'base', 'biochemical model', 'cancer immunotherapy', 'cancer therapy', 'complex data', 'deep learning', 'deep neural network', 'deep sequencing', 'design', 'experimental study', 'fighting', 'functional group', 'in vivo', 'insertion/deletion mutation', 'large datasets', 'machine learning method', 'markov model', 'pathogen', 'progenitor', 'receptor', 'repaired', 'response', 'success', 'three dimensional structure', 'tool']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,689648
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,10224845,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Methodology', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'feature selection', 'high dimensionality', 'innovation', 'inquiry-based learning', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2021,388750
"Swift.ai: research and development of an integrated platform for machine-assisted research synthesis Project Abstract (30 lines of text)  1 Systematic review and evidence mapping, both forms of research synthesis, are formal, sequential processes  2 for identifying, assessing, and integrating the primary scientific literature. These approaches, already  3 cornerstones of evidence-based medicine, have recently gained significant popularity in several other  4 disciplines including environmental, agricultural, and public health research and are increasingly utilized for  5 informed decision making by governmental organizations. It has been estimated that more than 25,000  6 systematic reviews are conducted and published annually and selecting studies for inclusion is one of the most  7 resource intensive steps for any systematic review or evidence map. In Phase I of our research plan, we have  8 developed a web-based, collaborative systematic review web application called SWIFT-Active Screener, an  9 innovative document screening tool that allows users to identify the majority of relevant articles after screening 10 only a fraction of the total number of abstracts. Our goal for the current proposal is to conduct additional 11 research and development required to make SWIFT-Active Screener a commercial success, while also 12 building on and leveraging methods and software we have previously built to address other stages in the 13 systematic review pipeline. Therefore, one of the primary aims of our ongoing research and development is to 14 address this need by expanding the Active Screener application into an integrated platform for research 15 synthesis by uniting it with several of our other related software products. The resulting platform, which we call 16 “swift.ai,” is described in detail in “Aim 1 – Software engineering to create a unified platform for research 17 synthesis.” In “Aim 2 – Improved statistical methods for Active Screener 2.0”, we expand on the methodological 18 research completed during Phase I of this SBIR, to further develop and refine our methods. Specifically, we 19 investigate new ways to integrate state-of-the art methods in deep learning and new ways to better utilize the 20 large amounts of screening data collected from our users in order to improve our models. Finally, in “Aim 3 – 21 Living evidence maps powered by Active Screener 2.0,” we explore new approaches for using machine 22 learning to facilitate evidence mapping. Project narrative Systematic review is a formal process used widely in evidence-based medicine and environmental health research to identify, assess, and integrate the primary scientific literature with the goal of answering a specific, targeted question in pursuit of the current scientific consensus. By conducting research and development to build a unified, web-based, collaborative, systematic review software application that integrates the latest developments in deep-learning, machine learning, natural language processing and artificial intelligence, we will make an important contribution toward ongoing efforts to automate systematic review. These efforts will serve to make systematic reviews both more efficient to produce and less expensive to maintain, a result which will greatly accelerate the process by which scientific consensus is obtained in a variety of medical and health-related disciplines having great public significance.",Swift.ai: research and development of an integrated platform for machine-assisted research synthesis,10259172,R44ES029001,"['Active Learning', 'Address', 'Adoption', 'Agriculture', 'Artificial Intelligence', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Set', 'Decision Making', 'Development', 'Discipline', 'Elements', 'Endocrine disruption', 'Environmental Health', 'Evidence Based Medicine', 'Feedback', 'Focus Groups', 'Goals', 'Government', 'Health', 'Influentials', 'Internet', 'Learning', 'Letters', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methodology', 'Methods', 'Mission', 'Modeling', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Online Systems', 'Phase', 'Policies', 'Positioning Attribute', 'Problem Formulations', 'Procedures', 'Process', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Review Literature', 'Sampling', 'Scientist', 'Screening procedure', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Statistical Methods', 'System', 'Testing', 'Text', 'Toxicology', 'Uncertainty', 'Update', 'active method', 'cost', 'data modeling', 'data sharing', 'deep learning', 'evidence base', 'improved', 'innovation', 'novel strategies', 'public health research', 'research and development', 'response', 'screening', 'simulation', 'success', 'systematic review', 'user-friendly', 'web app']",NIEHS,"SCIOME, LLC",R44,2021,820314
"Deep learning based antibody design using high-throughput affinity testing of synthetic sequences Project Summary We will develop and apply a new high-throughput methodology for rapidly designing and testing antibodies for a myriad of purposes, including cancer and infectious disease immunotherapeutics. We will improve upon current approaches for antibody design by providing time, cost, and humane benefits over immunized animal methods and greatly improving the power of present synthetic methods that use randomized designs. To accomplish this, we will display millions of computationally designed antibody sequences using recently available technology, test the displayed antibodies in a high-throughput format at low cost, and use the resulting test data to train molecular dynamics and machine learning methods to generate new sequences for testing. Based on our test data our computational method will identify sequences that have ideal properties for target binding and therapeutic efficacy. We will accomplish these goals with three specific aims. We will develop a new approach to integrated molecular dynamics and machine learning using control targets and known receptor sequences to refine our methods for receptor generalization and model updating from observed data (Aim 1). We will design an iterative framework intended to enable identification of highly effective antibodies within a minimal number of experiments, in which our methods automatically propose promising antibody sequences to profile in subsequent assays (Aim 2). We will employ rounds of automated synthetic design, affinity test, and model improvement to produce highly target-specific antibodies. (Aim 3). ! Project Narrative We will develop new computational methods that learn from millions of examples to design antibodies that can be used to help cure a wide variety of human diseases such as cancer and viral infection. Previous antibody design approaches used a trial and error approach to find antibodies that worked well. In contrast our mathematical methods will directly produce new antibody designs by learning from large-scale experiments that test antibodies for function against disease targets. !",Deep learning based antibody design using high-throughput affinity testing of synthetic sequences,10116306,R01CA218094,"['Affinity', 'Animals', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Binding', 'Biological Assay', 'Budgets', 'Classification', 'Cloud Computing', 'Communicable Diseases', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Fc Receptor', 'Goals', 'Human', 'Immunize', 'Immunotherapeutic agent', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Modeling', 'Molecular Machines', 'Oligonucleotides', 'Output', 'Performance', 'Phage Display', 'Property', 'Randomized', 'Research', 'Services', 'Specific qualifier value', 'Specificity', 'Statistical Models', 'Technology', 'Test Result', 'Testing', 'Therapeutic', 'Thinness', 'Time', 'Training', 'Treatment Efficacy', 'Update', 'Virus Diseases', 'Work', 'antibody test', 'base', 'cloud based', 'commercialization', 'computing resources', 'cost', 'deep learning', 'design', 'experimental study', 'human disease', 'improved', 'iterative design', 'learning strategy', 'machine learning method', 'mathematical methods', 'molecular dynamics', 'novel', 'novel strategies', 'outcome prediction', 'predictive test', 'receptor']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2021,591130
"Machine-learning based control of functional electrical stimulation ABSTRACT We request a supplement to enable successful continuation and completion of the project Aims as originally outlined in our funded grant proposal (1 R01 NS102259-01A1). This project involves restoration of upper limb movements in temporarily paralyzed non-human primates using machine-learning control of electrical stimulation of 30 muscles. Unanticipated circumstances led to financial challenges that limit our ability to complete the project. If a supplement is provided, we believe that we can successfully complete the Aims of the project. The supplement would provide funds to cover the costs associated with purchasing, training, implanting, and recording from two additional monkeys PROJECT NARRATIVE This application is for a supplement to enable successful continuation and completion of the project Aims as originally outlined in a funded grant proposal. This project involves restoration of upper limb movements in temporarily paralyzed non-human primates using machine- learning control of electrical stimulation of muscles.",Machine-learning based control of functional electrical stimulation,10319903,R01NS102259,"['Applications Grants', 'Electric Stimulation', 'Funding', 'Implant', 'Machine Learning', 'Monkeys', 'Muscle', 'Paralysed', 'Training', 'Upper limb movement', 'base', 'cost', 'functional electrical stimulation', 'nonhuman primate', 'restoration']",NINDS,UNIVERSITY OF ARIZONA,R01,2021,75200
"COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is still a major gap in that much data is still not openly shareable, which we propose to address. In addition, current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions) as well as for the individual requesting the data (e.g. substantial computational re- sources and time is needed to pool data from large studies with local study data). This needs to change, so that the scientific community can create a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see overview on this from our group7). The large amount of existing data requires an approach that can analyze data in a distributed way while (if required) leaving control of the source data with the individual investigator or the data host; this motivates a dynamic, decentralized way of approaching large scale analyses. During the previous funding period, we developed a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). Our system provides an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data is avoided, while the strength of large-scale analyses can be retained. During this new phase we respond to the need for advanced algorithms such as linear mixed effects models and deep learning, by proposing to develop decentralized models for these approaches and also implement a fully scalable cloud-based framework with enhanced security features. To achieve this, in Aim 1, we will incorporate the necessary functionality to scale up analyses via the ability to work with either local or commercial private cloud environments, together with advanced visualization, quality control, and privacy and security features. This suite of new functions will open the floodgates for the use of COINSTAC by the larger neuroscience community to enable new discovery and analysis of unprecedented amounts of brain imaging data located throughout the world. We will also improve usability, training materials, engage the community in contributing to the open source code base, and ultimately facilitate the use of COINSTAC's tools for additional science and discovery in a broad range of applications. In Aim 2 we will extend the framework to handle powerful algorithms such as linear mixed effects models and deep learning, and to perform meta-learning for leveraging and updating fit models. And finally, in Aim 3, we will test this new functionality through a partnership with the worldwide ENIGMA addiction group, which is currently not able to perform advanced machine learning analyses on data that cannot be centrally located. We will evaluate the impact of 6 main classes of substances of abuse (e.g. methamphetamines, cocaine, cannabis, nicotine, opiates, alcohol and their combinations) using the new developed functionality. 3 Project Narrative  Hundreds of millions of dollars have been spent on collecting human neuroimaging data for clinical and re- search studies, many of which do not come with subject consent for sharing or contain sensitive data which are not easily shared, such as genetics. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a viable solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we propose enables us to capture this `missing data' and achieve the same performance as pooling of both open and `closed' repositories by developing privacy preserving versions of advanced and cutting edge algorithms (including linear mixed effects models and deep learning) and incorpo- rating within an easy-to-use and scalable platform which enables distributed computation. 2","COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data",10269008,R01DA040487,"['Address', 'Adoption', 'Agreement', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Atlases', 'Awareness', 'Brain', 'Brain imaging', 'Cannabis', 'Clinical Data', 'Cocaine', 'Communities', 'Consent', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Set', 'Decentralization', 'Development', 'Environment', 'Family', 'Funding', 'Genetic', 'Genomics', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Learning', 'Legal', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measures', 'Methamphetamine', 'Modeling', 'Movement', 'Neurosciences', 'Nicotine', 'Opioid', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Privacy', 'Privatization', 'Process', 'Public Health', 'Quality Control', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Security', 'Series', 'Site', 'Source', 'Source Code', 'Statistical Bias', 'Structure', 'Substance of Abuse', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Visualization', 'Work', 'addiction', 'base', 'cloud based', 'computational platform', 'computerized data processing', 'computerized tools', 'data harmonization', 'data repository', 'data reuse', 'data sharing', 'data visualization', 'deep learning', 'distributed data', 'improved', 'large datasets', 'learning algorithm', 'life-long learning', 'negative affect', 'neuroimaging', 'novel', 'novel strategies', 'open data', 'open source', 'peer', 'privacy preservation', 'repository', 'scale up', 'structural genomics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'usability', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2021,617911
"Adaptive evolutionary inference frameworks for understudied populations using generative neural networks PROJECT SUMMARY In the field of population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, these algorithms rely heavily on simulated datasets, which currently fail to recapitulate the features of diverse natural genomes. Deep neural networks in particular are disconnected from evolutionary modeling, and their results are difficult to interpret in a biological context. In this project, we propose to develop simulation frameworks that automatically adapt to any population or species. The resulting customized synthetic datasets will be used to train neural networks that quantify the unique evolutionary histories of understudied human groups. By including genealogical and epigenetic information as auxiliary input, we will be able to link predictions back to genomic features. Our results will enable us to estimate the interactions between local phenomena such as natural selection, mutation patterns, and recombination hotspots. Taken together, outcomes from our work will allow us to create a detailed model evolutionary of processes, both along the genome and across human populations. PROJECT NARRATIVE In population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, it is difficult to apply these algorithms to understudied populations, as they are reliant on custom simulations, difficult to interpret, and disconnected from evolutionary modeling. The goals of this project are to develop simulation frameworks that automatically adapt to diverse datasets, allowing us to study evolutionary forces along the genome and across human populations.",Adaptive evolutionary inference frameworks for understudied populations using generative neural networks,10114449,R15HG011528,"['Admixture', 'African', 'Algorithms', 'Area', 'Back', 'Biological', 'Biological Process', 'Chromatin', 'Classification', 'Custom', 'Data', 'Data Set', 'Decision Trees', 'Epigenetic Process', 'European', 'Event', 'Evolution', 'Exposure to', 'Genealogy', 'Genes', 'Genetic Recombination', 'Genome', 'Genomic Segment', 'Genomics', 'Geography', 'Goals', 'Graph', 'Human', 'Human Genetics', 'Image', 'Individual', 'Industry', 'Internships', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Outcome', 'Pattern', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Recording of previous events', 'Research', 'Signal Transduction', 'Students', 'Training', 'Trees', 'Validation', 'Visualization', 'Work', 'automated algorithm', 'base', 'biobank', 'computer science', 'convolutional neural network', 'deep neural network', 'epigenetic marker', 'flexibility', 'health care settings', 'machine learning algorithm', 'machine learning method', 'methylation pattern', 'migration', 'neural network', 'simulation', 'single cell sequencing', 'statistics', 'theories', 'undergraduate student']",NHGRI,HAVERFORD COLLEGE,R15,2021,432494
"In-silico prediction of protein-peptide interactions. IN-SILICO PREDICTION OF PROTEIN-PEPTIDE INTERACTIONS Automated docking methods are used extensively for gaining a mechanistic understanding of the molecular interactions underpinning cellular processes. While these tools work well for small molecules they perform poorly for peptides and cannot handle Intrinsically Disordered Proteins (IDPs) which play very important roles in these processes. The goal of this project is the development of an efficient and practical peptide docking software, useful for designing therapeutic peptides and gaining insight into IDPs binding ordered proteins. The proposed software supports biomedical applications ranging from investigating chemical pathways to designing and optimizing therapeutic molecules for diseases such as cancer and metabolic disorders. Under the previous award we developed and released a new method for docking fully-flexible peptides with up to 20 standard amino acids: AutoDock CrankPep (ADCP). We showed that it outperforms current state-of-the-art docking methods. For the next award, we propose to: 1) further develop ADCP to support docking IPDs with up to 70 amino acids and improve support for therapeutic peptides containing modified amino acids and complex macrocycles; 2) develop peptide-specific scoring functions to increase docking success rates and methods for predicting the free energy of binding of peptides. This will be done by exploiting the latest advances in statistical potentials for docking, as well as applying machine-learning techniques; 3) test and validate the software on our datasets, community benchmarks, and through our collaborations with outstanding biologists working on biomedical applications spanning from designing drugs for thrombosis and influenza, to modeling IDPs interacting with globular proteins; and 4) document the software and release it under an open source license on a regular basis along with datasets we compile and update on regularly. The proposed research will occur in the context of collaborations with experimental biologists working on highly relevant biomedical projects and providing experimental feedback and validation. In addition, this project will benefit from various collaborations with experts in the fields of computational biology, applied mathematics and artificial intelligence. This docking software tool will be developed by applying best practices in software engineering and be implemented as a modular, extensible, component-based software framework for peptide docking. This docking engine will be part of the widely used AutoDock software suite. The ability to model complexes formed by proteins and fully-flexible peptides or IDPs is in high demand and will greatly extend the range of peptide-based therapeutic approaches for which automated docking can be successfully applied. It will also support gaining insights into interactions of IDPs with proteins. As such, it will impact the research of many medicinal chemists and biologist and extend the use of computational tools to a wider community of scientists, thereby supporting the advancement of biomedical research. Automated docking is a workhorse for rational drug design, however, applying these methods to peptides has remained challenging, thus impeding the designing of therapeutic peptides and the study of Intrinsically Disordered Proteins (IDP) binding to their ordered partners. During the prior funding period, we made substantial progress toward peptide docking, resulting in a new docking engine: AutoDock CrankPep, which outperforms state-of-the-art docking methods for linear and cyclic peptides with up to 20 standard amino acids. We propose to further develop AutoDock CrankPep to support docking of therapeutic peptides with modified amino acids as well as IDPs with up to 70 amino acids, creating a practical docking tool for peptides that will impact the research of many computational and medicinal chemists and biologist, contribute to our understanding of biological processes, and significantly advance biomedical research.",In-silico prediction of protein-peptide interactions.,10259801,R01GM096888,"['Amino Acids', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Award', 'Benchmarking', 'Binding', 'Binding Proteins', 'Biological', 'Biological Availability', 'Biological Process', 'Biomedical Research', 'Cell physiology', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Cyclic Peptides', 'Data Set', 'Development', 'Disease', 'Docking', 'Documentation', 'Drug Design', 'Educational workshop', 'Feedback', 'Free Energy', 'Funding', 'Goals', 'Half-Life', 'Influenza', 'Insulin', 'Libraries', 'Licensing', 'Ligands', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Mediating', 'Metabolic Diseases', 'Methods', 'Modeling', 'Modernization', 'Mutate', 'Pathway interactions', 'Peptides', 'Performance', 'Peripheral', 'Permeability', 'Pharmaceutical Preparations', 'Play', 'Process', 'Production', 'Property', 'Proteins', 'Renaissance', 'Research', 'Role', 'Scientist', 'Signal Pathway', 'Software Engineering', 'Software Framework', 'Software Tools', 'Specificity', 'Structure', 'Study models', 'Techniques', 'Testing', 'Therapeutic', 'Thrombosis', 'Toxic effect', 'Training', 'Update', 'Validation', 'Work', 'base', 'combinatorial', 'computerized tools', 'computing resources', 'design', 'flexibility', 'globular protein', 'graphical user interface', 'improved', 'improved functioning', 'in silico', 'insight', 'interest', 'interoperability', 'novel', 'open source', 'peptide drug', 'predictive tools', 'programs', 'protein protein interaction', 'receptor', 'screening', 'small molecule', 'success', 'symposium', 'therapeutic target', 'tool', 'translational study', 'virtual screening']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2021,399375
"SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community Physics-based simulations provide a powerful framework for understanding biological form and function. They harmonize heterogeneous experimental data with real-world physical constraints, helping researchers understand biological systems as they engineer novel drugs, new diagnostics, medical devices, and surgical interventions. The rise in new sensors and simulation tools is generating an increasing amount of data, but this data is often inaccessible, preventing reuse and limiting scientific progress. In 2005, we launched SimTK, a website to develop and share biosimulation tools, models, and data, to address these issues. SimTK now supports 62,000+ researchers globally and 950+ projects. Members use it to meet their grants’ data sharing responsibilities; experiment with new ways of collaborating; and build communities around their datasets and tools. However, challenges remain: many researchers still do not share their digital assets due to the time needed to prepare, document, and maintain those assets, and since SimTK hosts a growing number of diverse digital assets, the site now also faces the challenge of making these assets discoverable and reusable. Thus, we propose a plan to extend SimTK and implement new solutions to promote scientific data sharing and reuse. First, we will maintain the reliable, user-friendly foundation upon which SimTK is built, continuing to provide the excellent support our members expect and supporting the site’s existing features for sharing and building communities. Second, we will implement methods to establish a culture of model and data sharing in the biomechanics community. We will encourage researchers to adopt new habits, making sharing part of their workflow, by enabling the software and systems they use to automatically upload models and data to SimTK via an application programming interface (API) and by recruiting leading researchers in the community to serve as beta testers and role models. Third, we will create tools to easily replicate and extend biomechanics simulations. Containers and cloud computing services allow researchers to capture and share a snapshot of their computing environment, enabling unprecedented fidelity in sharing. We will integrate these technologies into SimTK and provide custom, easy-to-use interfaces to replicate and extend simulation studies. Lastly, we will develop a metadata standard for models and data for the biomechanics community, increasing reusability and discoverability of the rich set of resources shared on SimTK. We will use the new standard on SimTK and fill in the metadata fields automatically using natural language processing and machine learning, minimizing the burden and inaccuracies of manual metadata entry. We will evaluate our success in achieving these aims by tracking the number of assets shared and the frequency they are used as a springboard to new research. These changes will accelerate biomechanics research and provide new tools to increase the reusability and impact of shared resources. By lowering barriers to data sharing in the biosimulation community, SimTK will continue to serve as a model for how to create national infrastructure for scientific subdisciplines. SimTK is a vibrant hub for the development and sharing of simulation software, data, and models of biological structures and processes. SimTK-based resources are being used to design medical devices and drugs, to generate new diagnostics, to create surgical interventions, and to provide insights into biology. The proposed enhancements to SimTK will accelerate progress in the field by lowering barriers to and standardizing data and model sharing, thus 1) increasing the quantity and also, importantly, the quality of resources that researchers share and 2) enabling others to reproduce and build on the wealth of past biomechanics research studies.",SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community,10085652,R01GM124443,"['Achievement', 'Address', 'Adopted', 'Biological', 'Biological Models', 'Biology', 'Biomechanics', 'Biophysics', 'Cloud Computing', 'Code', 'Communities', 'Computer software', 'Consumption', 'Custom', 'Data', 'Data Files', 'Data Set', 'Development', 'Documentation', 'Engineering', 'Ensure', 'Environment', 'Explosion', 'Face', 'Foundations', 'Frequencies', 'Goals', 'Grant', 'Habits', 'Infrastructure', 'Letters', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Device', 'Medical Device Designs', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Operative Surgical Procedures', 'Pharmaceutical Preparations', 'Physics', 'Process', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Security', 'Services', 'Site', 'Structure', 'System', 'Technology', 'Time', 'Update', 'Work', 'application programming interface', 'base', 'biological systems', 'biomechanical model', 'community building', 'complex biological systems', 'data access', 'data cleaning', 'data ecosystem', 'data reuse', 'data sharing', 'data standards', 'digital', 'experience', 'experimental study', 'insight', 'member', 'metadata standards', 'new technology', 'novel diagnostics', 'novel therapeutics', 'prevent', 'recruit', 'research study', 'response', 'role model', 'sensor', 'simulation', 'simulation software', 'software systems', 'success', 'tool', 'user-friendly', 'web site']",NIGMS,STANFORD UNIVERSITY,R01,2021,489919
"Administrative Supplement: Using machine learning to predict odor characteristics from molecular structure PROJECT SUMMARY/ABSTRACT We cannot yet look at a chemical structure and predict if the molecule will have an odor, much less what character it will have. The goal of the proposed research is to apply machine learning to predict perceptual characteristics from chemical features of molecules. The specific aims of the proposal will determine (1) which molecules are odorous , and (2) what data are needed to model odor character. Building a highly predictive model requires two key ingredients: high-quality data and a sound modeling approach. High-quality data must be accurate (ratings are consistent and describe true odor properties) and detailed (ratings describe even small differences in odor properties). We have collected human psychophysical data on a diverse set of molecules and have trained a model to predict if a molecule has an odor, but pilot data identified odorous contaminants that limit model training and measurement of model accuracy. In Aim 1, I will apply my background in analytical chemistry to evaluate the accuracy of the data, using gas chromatography to identify and correct errors caused by chemical contaminants. In Aim 2, I will apply my experience in human sensory evaluation to measure and compare the consistency and the degree of detail in ratings that can be achieved with different sensory methods and subject training procedures. By executing my training plan, I will develop the skills in statistical programming and machine learning needed to employ a sound modeling approach to these problems. The model constructed in Aim 1 will enable prediction of odor classification (odor/odorless) for any molecule and thus define which molecules are perceptually relevant. Predicting odor character is a far more complex challenge – while a molecule can have only one of two odor classifications (odor or odorless) it may elicit any number of diverse odor character attributes (fruity, floral, musky, sweet, etc.). Descriptive Analysis (DA) is the gold standard method for generating accurate and detailed sensory profiles, but this method is time-consuming. We estimate that an odor character dataset will be large enough (“model-ready”) to predict odor character with approximately 10,000 molecules and that it would require more than 30,000 hours of human subject evaluation, or approximately 6 years for the typical trained panel, to produce this dataset using DA. Before we invest the time and resources, it is responsible to evaluate the relative data quality of more rapid sensory methods. The results of Aim 2 are expected to determine the best approach for generating a model-ready dataset by quantifying trade-offs in degree of detail (data resolution), rating consistency, and method speed of five candidate sensory methods. Together, these aims represent a significant step forward in linking chemical recipe to human odor perception, an advancement that supports the NIDCD goal of understanding normal olfactory function (how stimulus relates to percept) and has many potential applications in foods (what composition of molecules should be present to produce a target aroma percept). PROJECT NARRATIVE Currently, scientists cannot predict whether a molecule will have an odor and, if so, what odor characteristics it will have based on its chemical structure. The goal of this project is to develop predictive models linking chemical composition to odor characteristics. These models will advance our understanding of the human olfactory system and help design strategies for improving the aroma and palatability of healthy foods.",Administrative Supplement: Using machine learning to predict odor characteristics from molecular structure,10405294,F32DC019030,"['Address', 'Administrative Supplement', 'Analytical Chemistry', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Classification', 'Collection', 'Complex', 'Consumption', 'Data', 'Data Set', 'Descriptor', 'Development', 'Evaluation', 'Food', 'Fruit', 'Gas Chromatography', 'Goals', 'Gold', 'Health Food', 'Hour', 'Human', 'Human Resources', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Structure', 'National Institute on Deafness and Other Communication Disorders', 'Odors', 'Olfactory Pathways', 'Palate', 'Perception', 'Positioning Attribute', 'Procedures', 'Programmed Learning', 'Property', 'Protocols documentation', 'Psychophysics', 'Quality Control', 'Recipe', 'Research', 'Research Technics', 'Resolution', 'Resources', 'Sampling', 'Science', 'Scientist', 'Sensory', 'Smell Perception', 'Speed', 'Stimulus', 'Structure', 'Testing', 'Time', 'Training', 'Work', 'base', 'data quality', 'design', 'experience', 'food science', 'human subject', 'improved', 'machine learning algorithm', 'model building', 'predictive modeling', 'prevent', 'rapid technique', 'skills', 'sound']",NIDCD,MONELL CHEMICAL SENSES CENTER,F32,2021,2500
"National Resource for Network Biology (NRNB) OVERALL - PROJECT SUMMARY The mission of the National Resource for Network Biology (NRNB) is to advance the science of biological networks by creating leading-edge bioinformatic methods, software tools and infrastructure, and by engaging the scientific community in a portfolio of collaboration and training opportunities. Much of biomedical research is dependent on knowledge of biological networks of multiple types and scales, including molecular interactions among genes, proteins, metabolites and drugs; cell communication systems; relationships among genotypes and biological and clinical phenotypes; and patient and social networks. NRNB-supported platforms like Cytoscape are among the most widely used software tools in biology, with tens of thousands of active users, enabling researchers to apply network concepts and data to understand biological systems and how they are reprogrammed in disease.  NRNB’s three Technology Research and Development projects introduce innovative concepts with the potential to transform network biology, transitioning it from a static to a dynamic science (TR&D 1); from flat network diagrams to multi-scale hierarchies of biological structure and function (TR&D 2); and from descriptive interaction maps to predictive and interpretable machine learning models (TR&D 3). In previous funding periods our technology projects have produced novel and highly cited approaches, including network-based biomarkers for stratification of disease, data-driven gene ontologies assembled completely from network data, and deep learning models of cell structure and function built using biological networks as a scaffold.  During the next period of support, we introduce dynamic regulatory networks formulated from single-cell transcriptomics and advanced proteomics data (TR&D 1); substantially improved methodology for the study of hierarchical structure and pleiotropy in biological networks (TR&D 2); and procedures for using networks to seed machine learning models of drug response that are both mechanistically interpretable and transferable across biomedical contexts (TR&D 3). These efforts are developed and applied in close collaboration with outside investigators from 19 Driving Biomedical Projects who specialize in experimental generation of network data, disease biology (cancer, neuropsychiatric disorders, diabetes), single-cell developmental biology, and clinical trials. TR&Ds are also bolstered by 7 Technology Partnerships in which NRNB scientists coordinate technology development with leading resource-development groups in gene function prediction, mathematics and algorithm development, and biomedical databases. Beyond these driving collaborations, we continually support a broader portfolio of transient (non-driving) research collaborations; organize and lead international meetings including the popular Network Biology track of the Intelligent Systems for Molecular Biology conference; and deliver a rich set of training opportunities and network analysis protocols. OVERALL - PROJECT NARRATIVE We are all familiar with some of the components of biological systems – DNA, proteins, cells, organs, individuals – but understanding biological systems involves more than just cataloging its component parts. It is critical to understand the many interactions of these parts within systems, and how these systems give rise to biological functions and responses and determine states of health and disease. The National Resource for Network Biology provides the scientific community with a broad platform of computational tools for the study of biological networks and for incorporating network knowledge in biomedical research.",National Resource for Network Biology (NRNB),10145009,P41GM103504,"['Area', 'Automobile Driving', 'Beds', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Biomedical Technology', 'Cataloging', 'Cell Communication', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Conceptions', 'DNA', 'Data', 'Data Set', 'Databases', 'Developmental Cell Biology', 'Diabetes Mellitus', 'Disease', 'Disease stratification', 'Drug Modelings', 'Ecosystem', 'Educational workshop', 'Event', 'Expert Systems', 'Feedback', 'Funding', 'Gene Proteins', 'Generations', 'Genes', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Health', 'Individual', 'Infrastructure', 'International', 'Knowledge', 'Lead', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mentors', 'Methodological Studies', 'Methods', 'Mission', 'Modeling', 'Molecular Biology', 'National Institute of General Medical Sciences', 'Network-based', 'Ontology', 'Organ', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Phase Transition', 'Phenotype', 'Positioning Attribute', 'Procedures', 'Proteins', 'Proteomics', 'Protocols documentation', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Running', 'Science', 'Scientist', 'Seeds', 'Services', 'Social Network', 'Software Tools', 'Structure', 'Students', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Visual', 'Visualization', 'Work', 'algorithm development', 'biological systems', 'clinical phenotype', 'cloud storage', 'computational platform', 'computerized tools', 'deep learning', 'gene function', 'genomics cloud', 'improved', 'innovation', 'interoperability', 'lens', 'mathematical algorithm', 'meetings', 'method development', 'multi-scale modeling', 'neuropsychiatric disorder', 'next generation', 'novel', 'pleiotropism', 'prediction algorithm', 'programs', 'protein metabolite', 'response', 'scaffold', 'single cell analysis', 'software infrastructure', 'symposium', 'technology development', 'technology research and development', 'tool', 'training opportunity', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P41,2021,1210147
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10256071,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2021,339505
"A deep learning platform to evaluate the reliability of scientific claims by citation analysis. The opioid epidemic in the United States has been traced to a 1980 letter reporting in the prestigious New England Journal of Medicine that synthetic opioids are not addictive. A belated citation analysis led the journal to append this letter with a warning this letter has been “heavily and uncritically cited” as evidence that addiction is rare with opioid therapy.” This epidemic is but one example of how unreliable and uncritically cited scientific claims can affect public health, as studies from industry report that a substantial part of biomedical reports cannot be independently verified. Yet, there is no publicly available resource or indicator to determine how reliable a scientific claim is without becoming an expert on the subject or retaining one. The total citation count, the commonly used measure, is inherently a poor proxy for research quality because confirming and refuting citations are counted as equal, while the prestige of the journal is not a guarantee that a claim published there is true. The lack of indicators for the veracity of reported claims costs the public, businesses, and governments, billions of dollars per year. We have developed a prototype that automatically classifies statements citing a scientific claim into three classes: those that provide supporting or contradicting evidence, or merely mention the claim. This unique capability enables scite users to analyze the reliability of scientific claims at an unprecedented scale and speed, helping them to make better-informed decisions. The prototype has attracted potential customers among top biotechnology and pharmaceutical companies, research institutions, academia, and academic publishers. We propose to conduct research that will refine scite into an MVP by optimizing prototype efficiency and accuracy until they reach feasible milestones, and will refine the product-market fit in our beachhead market, academic publishing, whose influence on the integrity and reliability of research is difficult to overestimate. We propose to develop a platform that can be used to evaluate the reliability of scientific claims. Our deep learning model, combined with a network of experts, automatically classifies citations as supporting, contradicting, or mentioning, allowing users to easily assess the veracity of scientific articles and consequently researchers. By introducing a system that can identify how a research article has been cited, not just how many times, we can assess research better than traditional analytical approaches, thus helping to improve public health by identifying and promoting reliable research and by increasing the return on public and private investment in research.",A deep learning platform to evaluate the reliability of scientific claims by citation analysis.,10162578,R44DA050155,"['Academia', 'Address', 'Affect', 'Architecture', 'Biotechnology', 'Businesses', 'Classification', 'Data', 'Data Set', 'Epidemic', 'Government', 'Human', 'Industry', 'Institution', 'Investments', 'Journals', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Marketing', 'Measures', 'Medicine', 'Modeling', 'National Institute of Drug Abuse', 'New England', 'Performance', 'Pharmacologic Substance', 'Phase', 'Privatization', 'Program Description', 'Proxy', 'Public Health', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sales', 'Small Business Innovation Research Grant', 'Speed', 'System', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Vision', 'Visual system structure', 'addiction', 'commercialization', 'cost', 'dashboard', 'deep learning', 'design', 'improved', 'insight', 'interest', 'learning classifier', 'literature citation', 'opioid epidemic', 'opioid therapy', 'product development', 'programs', 'prototype', 'synthetic opioid', 'tool', 'user-friendly']",NIDA,"SCITE, INC.",R44,2021,753275
"A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning SUMMARY Adaptive evolution (AE) is both a “force of good” as it can help to optimize biological processes in industry, but it is also a “force of frustration” when infectious diseases exploit AE to escape the host immune system or become resistant to drugs. It has long been assumed close to impossible to make predictions on AE due to the presumed predominating influences of random forces and events. However, the observation that evolutionary repeatability across traits and species is far more common than previously thought, suggests that AE, with the right data and approach, may become (partially) predictable. Indeed, we found through experiments with the bacterial pathogen Streptococcus pneumoniae on its response to antibiotics and the emergence of antimicrobial resistance, that in order to make AE predictable a detailed understanding of at least two aspects of the bacterial system are required: 1.) the genetic constraints of the system (i.e. the architecture of the organismal network); and 2.) where and how in the system stress is experienced and processed. We showed that by mapping out ~25% of the bacterium's network, determining phenotypic and transcriptional antibiotic responses, applying network analyses to capture and quantify the responses in a network context, and exploiting experimental evolution to pin-point adaptive mutations in the genome it becomes possible, by means of machine learning, to uncover hidden patterns in the data that make AE predictions feasible. This means that the network in interaction with the environment shapes the adaptive landscape, it limits available solutions and makes some solutions more likely than others, thereby driving repeatability and enabling predictability. In this proposal we build on these exciting developments with the goal to map out the constraints of S. pneumoniae's entire network and develop a machine learning model that can forecast adaptive evolution a priori, and on a genome-wide scale. To accomplish this, we combine in aim 1 parts of Tn-Seq, dTn-Seq and Drop-Seq to finalize a new tool Tn-Seq^2 (Tn-Seq squared) that is able to map genetic-interactions in high-throughput and genome-wide. We use Tn-Seq^2 to reconstruct the first genome-wide genetic interaction network for S. pneumoniae in the presence of 20 antibiotics. In aim 2 we create 85 HA-tagged Transcription factor induction (TFI) strains and: a) Determine with ChIP-Seq the DNA-binding sites for all 85 TFs in S. pneumoniae; b) By overexpressing each TFI strain followed by RNA- Seq we determine each TFs regulatory signature; c) Use a Transcriptional Regulator Induced Phenotype screen in the presence of 20 antibiotics to untangle environment specific links between genetic and transcriptional perturbations and their phenotypic outcomes. Lastly, in aim 3, we train and test a variety of machine learning approaches to design an optimal model that predicts which genes in the genome are most likely to adapt in the presence of a specific antibiotic. The development of this predictive AE model, will not only be useful in predicting the emergence of antibiotic resistance, but the strategy should be valuable for most any biological field for which adaptive changes are important, ranging from biological engineering to cancer. NARRATIVE Adaptive evolution (AE) is the driving force behind the emergence of antibiotic resistance and if it were possible to predict AE before it happens, it could help in preventing resistance. Here we use cutting-edge existing and newly designed genomics tools and analytical approaches to develop a machine learning model that can predict AE a priori, and on a genome-wide scale.",A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning,10155396,R01AI148470,"['Achievement', 'Affect', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Automobile Driving', 'Bacteria', 'Binding Sites', 'Biological', 'Biological Process', 'Biomass', 'ChIP-seq', 'Communicable Diseases', 'Complex', 'DNA Binding', 'Data', 'Development', 'Drug resistance', 'Engineering', 'Ensure', 'Environment', 'Escherichia coli', 'Event', 'Evolution', 'Exposure to', 'Fermentation', 'Frustration', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Immune system', 'Immunotherapeutic agent', 'Industry', 'Life', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Microfluidics', 'Modeling', 'Mutation', 'Organism', 'Outcome', 'Pathway Analysis', 'Pattern', 'Phenotype', 'Photosynthesis', 'Planet Earth', 'Process', 'Resistance', 'Shapes', 'Streptococcus pneumoniae', 'Stress', 'System', 'Testing', 'Time', 'Training', 'Yeasts', 'design', 'driving force', 'droplet sequencing', 'emerging antibiotic resistance', 'emerging antimicrobial resistance', 'experience', 'experimental study', 'genetic architecture', 'genome-wide', 'genomic tools', 'network architecture', 'novel', 'overexpression', 'pathogenic bacteria', 'predictive modeling', 'prevent', 'process optimization', 'programs', 'response', 'tool', 'trait', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transposon sequencing']",NIAID,BOSTON COLLEGE,R01,2021,391250
"Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data Project Abstract/Summary Our interdisciplinary research team will develop algorithms to accelerate the detection of respiratory virus outbreaks at an unprecedented local scale in US cities. We propose to advance outbreak detection by combining machine learning data integration methods and spatial models of disease transmission. The dynamic models that will be developed will provide mechanistic engines for distinguishing typical from atypical disease trends and the optimization methods evaluate the informativeness of data sources to achieve specified public health goals through the rapid evaluation of diverse input data sources. Working with local healthcare and public health leaders, we will translate the algorithms into user-friendly online tools to support preparedness plans and decision-making. Our proposed research is organized around three major aims. In Aim 1, we will apply machine learning and signal processing methods to build systems that track the earliest indicators of emerging outbreaks within seven US cities. We will evaluate non-clinical data reflecting early and mild symptoms as well as clinical data covering underserved communities and geographic and demographic hotspots for viral emergence. In Aim 2, we will develop sub-city scale models reflecting the syndemics of co-circulating respiratory viruses and chronic respiratory diseases (CRD) that can exacerbate viral infections. We will infer viral transmission rates and socio-environmental risk cofactors by fitting the model to respiratory disease data extracted from millions of electronic health records (EHRs) for the last nine years. We will then partner with clinical and EHR experts to translate our models into the first outbreak detection system for severe respiratory viruses that incorporates EHR data on CRDs. Using machine learning techniques, we will further integrate other surveillance, environmental, behavioral and internet predictor data sources to maximize the accuracy, sensitivity, speed and population coverage of our algorithms. In Aim 3, we will develop an open-access Python toolkit to facilitate the integration of next generation data into outbreak surveillance models. This project will produce practical early warning algorithms for detecting emerging viral threats at high spatiotemporal resolution in several US cities, elucidate socio-geographic gaps in current surveillance systems and hotspots for viral emergence, and provide a robust design framework for extrapolating these algorithms to other US cities. Project Narrative We will develop innovative algorithms for detecting emerging respiratory viruses within US cities. To do so, we will model the syndemic dynamics of respiratory viruses and chronic respiratory diseases and apply machine learning to combine geospatial data that track early indicators of emerging threats. Working with local public health and healthcare collaborators, we will translate this research into practical tools for addressing socio- geographic gaps in surveillance and accelerating the detection, prevention and mitigation of severe outbreaks.","Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data",10265769,R01AI151176,"['Absenteeism', 'Address', 'African', 'Age', 'Algorithm Design', 'Algorithms', 'Area', 'Articulation', 'Bayesian Method', 'Behavioral', 'Caring', 'Chronic', 'Chronic Disease', 'Cities', 'Climate', 'Clinical', 'Clinical Data', 'Collaborations', 'Communicable Diseases', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Disease', 'Disease Outbreaks', 'Disease Surveillance', 'Disease model', 'Ebola', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Evaluation', 'Geography', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Human', 'Individual', 'Infection', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Interdisciplinary Study', 'International', 'Internet', 'Intervention', 'Location', 'Lung diseases', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mexico', 'Modeling', 'Neighborhoods', 'Pollution', 'Population', 'Prevention', 'Public Health', 'Pythons', 'Readiness', 'Reporting', 'Research', 'Resolution', 'Risk', 'Rural', 'Schools', 'Sentinel', 'Series', 'Signal Transduction', 'Social Environment', 'Specific qualifier value', 'Speed', 'Subgroup', 'Surveillance Modeling', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'Translating', 'Uncertainty', 'Validation', 'Viral', 'Virus', 'Virus Diseases', 'Visualization', 'Work', 'World Health Organization', 'austin', 'base', 'cofactor', 'comorbidity', 'dashboard', 'data acquisition', 'data integration', 'design', 'detection method', 'detection platform', 'digital', 'disease transmission', 'diverse data', 'epidemiologic data', 'epidemiological model', 'experimental study', 'flexibility', 'global health', 'health care availability', 'health goals', 'high risk', 'high risk population', 'influenza outbreak', 'influenzavirus', 'innovation', 'insight', 'metropolitan', 'next generation', 'novel', 'outcome prediction', 'pandemic disease', 'public health intervention', 'respiratory virus', 'school district', 'signal processing', 'simulation', 'social media', 'sociodemographic group', 'socioeconomics', 'sound', 'spatiotemporal', 'stem', 'tool', 'transmission process', 'trend', 'underserved community', 'user-friendly', 'viral transmission']",NIAID,YALE UNIVERSITY,R01,2021,482268
"Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data Project Abstract/Summary Our interdisciplinary research team will develop algorithms to accelerate the detection of respiratory virus outbreaks at an unprecedented local scale in US cities. We propose to advance outbreak detection by combining machine learning data integration methods and spatial models of disease transmission. The dynamic models that will be developed will provide mechanistic engines for distinguishing typical from atypical disease trends and the optimization methods evaluate the informativeness of data sources to achieve specified public health goals through the rapid evaluation of diverse input data sources. Working with local healthcare and public health leaders, we will translate the algorithms into user-friendly online tools to support preparedness plans and decision-making. Our proposed research is organized around three major aims. In Aim 1, we will apply machine learning and signal processing methods to build systems that track the earliest indicators of emerging outbreaks within seven US cities. We will evaluate non-clinical data reflecting early and mild symptoms as well as clinical data covering underserved communities and geographic and demographic hotspots for viral emergence. In Aim 2, we will develop sub-city scale models reflecting the syndemics of co-circulating respiratory viruses and chronic respiratory diseases (CRD) that can exacerbate viral infections. We will infer viral transmission rates and socio-environmental risk cofactors by fitting the model to respiratory disease data extracted from millions of electronic health records (EHRs) for the last nine years. We will then partner with clinical and EHR experts to translate our models into the first outbreak detection system for severe respiratory viruses that incorporates EHR data on CRDs. Using machine learning techniques, we will further integrate other surveillance, environmental, behavioral and internet predictor data sources to maximize the accuracy, sensitivity, speed and population coverage of our algorithms. In Aim 3, we will develop an open-access Python toolkit to facilitate the integration of next generation data into outbreak surveillance models. This project will produce practical early warning algorithms for detecting emerging viral threats at high spatiotemporal resolution in several US cities, elucidate socio-geographic gaps in current surveillance systems and hotspots for viral emergence, and provide a robust design framework for extrapolating these algorithms to other US cities. Project Narrative We will develop innovative algorithms for detecting emerging respiratory viruses within US cities. To do so, we will model the syndemic dynamics of respiratory viruses and chronic respiratory diseases and apply machine learning to combine geospatial data that track early indicators of emerging threats. Working with local public health and healthcare collaborators, we will translate this research into practical tools for addressing socio- geographic gaps in surveillance and accelerating the detection, prevention and mitigation of severe outbreaks.","Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data",10113533,R01AI151176,"['Absenteeism', 'Address', 'African', 'Age', 'Algorithm Design', 'Algorithms', 'Area', 'Articulation', 'Bayesian Method', 'Behavioral', 'Caring', 'Chronic', 'Chronic Disease', 'Cities', 'Climate', 'Clinical', 'Clinical Data', 'Collaborations', 'Communicable Diseases', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Disease', 'Disease Outbreaks', 'Disease Surveillance', 'Disease model', 'Ebola', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Evaluation', 'Geography', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Human', 'Individual', 'Infection', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Interdisciplinary Study', 'International', 'Internet', 'Intervention', 'Location', 'Lung diseases', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mexico', 'Modeling', 'Neighborhoods', 'Pollution', 'Population', 'Prevention', 'Public Health', 'Pythons', 'Readiness', 'Reporting', 'Research', 'Resolution', 'Risk', 'Rural', 'Schools', 'Sentinel', 'Series', 'Signal Transduction', 'Social Environment', 'Specific qualifier value', 'Speed', 'Subgroup', 'Surveillance Modeling', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'Translating', 'Uncertainty', 'Validation', 'Viral', 'Virus', 'Virus Diseases', 'Visualization', 'Work', 'World Health Organization', 'austin', 'base', 'cofactor', 'comorbidity', 'dashboard', 'data acquisition', 'data integration', 'design', 'detection method', 'detection platform', 'digital', 'disease transmission', 'diverse data', 'epidemiologic data', 'epidemiological model', 'experimental study', 'flexibility', 'global health', 'health care availability', 'health goals', 'high risk', 'high risk population', 'influenza outbreak', 'influenzavirus', 'innovation', 'insight', 'metropolitan', 'next generation', 'novel', 'outcome prediction', 'pandemic disease', 'public health intervention', 'respiratory virus', 'school district', 'signal processing', 'simulation', 'social media', 'sociodemographic group', 'socioeconomics', 'sound', 'spatiotemporal', 'stem', 'tool', 'transmission process', 'trend', 'underserved community', 'user-friendly', 'viral transmission']",NIAID,YALE UNIVERSITY,R01,2021,596017
"Unified Computation Tools for Natural Products Research Summary The overarching goal for this proposed renewal application will be to further advance tools that are in development and to effectively integrate several types of analytical data with biological assay data and genomic information. This will create a powerful set of tools for faster and even more accurate identification of new molecules, dereplication of known ones, and to directly infer biological activities from spectroscopic information. In the current period of support, we have made substantial progress in developing highly useful tools for automatic annotations and identifications of organic molecules, specifically focused on natural products. The Global Natural Products Social (GNPS) Molecular Networking analysis and knowledge dissemination ecosystem has processed almost 160,000 jobs in nearly 160 countries worldwide, has 4-6,000 new job submissions per month and is accessed over 200,000 times a month (majority accessions are for reference library access, inspection of public data and previous jobs that the community shares as hyperlinks in papers), and has become a mainstream tool for the annotation of organic molecules deriving from diverse sources, especially in metabolomics workflows. The public website for Small Molecule Accurate Recognition Technology (SMART), a deep learning model for providing candidate structures based on 1H-13C HSQC NMR data, went live in December 2019 and already has over 3000 jobs in 50 countries. All tools developed in this proposal will become part of this analysis ecosystem. The four laboratories contributing to this proposed research activity have created an open and integrated team that is continuing to creatively innovate new informatic tools to enhance small molecule structure annotations and inference of their chemical and biological properties. We have four specific aims: 1) To complete the development and evaluation of a set of new and innovative tools for natural products analysis, and deploy these as freely available resources for the worldwide community. 2) To refine the structural characterization of molecules through leveraging repository scale mass spectral information along with NMR data and genomic inputs. 3) To create a new SMART-based tool that integrates mass spectrometry and HSQC NMR data as the input for a new deep learning system with the goal of achieving more accurate predictions of structure. 4) To use deep learning to enhance SMART with bioactivity data so as to enable SMART to predict activities of molecules based on spectroscopic features. The data will also augment the GNPS database with biological assay binding data. An additional consequence of these goals will be the further digitization of natural products analytical data so that they can be used in the computational tools planned herein, as well as other tools in the future. Completion of these four specific aims will create new integrated tools for the precise identification of new natural product structures, and enable inference of their structural relatedness to other classes of organic molecules and their biological properties. Thus, these new informatic tools will have the potential to greatly enhance the small molecule drug discovery process.         Unified Computational Tools for Natural Products Research Approximately 50% of all FDA approved drugs trace their origins to natural products, either directly or through indirect routes of development. To accelerate and make more efficient the study of natural products, we are developing innovative computational tools for the rapid annotation of natural product structures and their associated chemical and biological properties.",Unified Computation Tools for Natural Products Research,10211176,R01GM107550,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Chemicals', 'Classification', 'Communities', 'Country', 'Cyanobacterium', 'Data', 'Data Analytics', 'Databases', 'Development', 'Ecosystem', 'Evaluation', 'FDA approved', 'Future', 'Genomics', 'Goals', 'Grant', 'Knowledge', 'Laboratories', 'Legal patent', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Natural Products', 'Noise', 'Nuclear Magnetic Resonance', 'Occupations', 'Organism', 'Paper', 'Pathway Analysis', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Property', 'Publications', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Route', 'Source', 'Spectrometry', 'Structure', 'Students', 'System', 'Technology', 'Time', 'annotation  system', 'base', 'computerized tools', 'deep learning', 'drug discovery', 'genome sequencing', 'genomic data', 'informatics tool', 'innovation', 'marine natural product', 'metabolomics', 'quantum', 'repository', 'small molecule', 'social', 'tool', 'web site']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,547104
"Arkansas Bioinformatics Consortium Project Summary/Abstract The Arkansas Research Alliance proposes to hold five annual workshops on the subject of bioinformatics. The purpose is to bring six major Arkansas institutions into closer collaboration. Those institutions are: University of Arkansas-Fayetteville; Arkansas State University; University of Arkansas for Medical Sciences; University of Arkansas at Little Rock; University of Arkansas at Pine Bluff; and the National Center for Toxicological Research. The workshops will focus on capabilities at each of the six in sciences related to bioinformatics including artificial intelligence, big data, machine learning, food and agriculture, high speed computing, and visualization capabilities. As this work progresses, educational coordination and student encouragement will be important components. Principals from all six institutions are collaborating to accomplish the workshop goals. Project Narrative The FDA ability to protect the public health is directly related to its ability to access and utilize the latest scientific data. Increased proficiency in collecting, presenting, validating, understanding, and drawing quantitative inference from the massive volume of new scientific results is necessary for success in that effort. The complexity involved requires continued development of new tools available and being developed within the realm of information technology, and the workshops proposed here will address this need. Specific Aims  • Thoroughly understand the resources in Arkansas available for furthering the capabilities in  bioinformatics and its associated needs, e.g., access to high speed computing capability and use  of computational tools. • Develop a set of plans to harness and grow those capabilities, especially those that are relevant  to the needs of NCTR and FDA. • Stimulate interest and capability across Arkansas in bioinformatics to produce a larger cadre of  expertise as these plans are implemented. • Enlist NCTR’s help in directing the effort toward seeking local, national and international data  that can be more effectively analyzed to produce results needed by FDA and others, e.g.,  reviewing decades of genomic/treatment data on myeloma patients at the University of  Arkansas for Medical Sciences. • Develop ways in which the Arkansas capabilities can be combined into a coordinated, synergistic  force larger than the sum of its parts. • Encourage students and faculty in the development of new models and techniques to be used in  bioinformatics and related fields. • Improve inter-institutional communication, including developing standardized bioinformatics  curricula and more universal course acceptance.",Arkansas Bioinformatics Consortium,10214625,R13FD006690,[' '],FDA,ARKANSAS RESEARCH ALLIANCE,R13,2021,3125
"Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1 PROJECT SUMMARY Previous studies showed discrepancies of health and behavior prevalence between American Indians (AI) population and other racial or ethnic groups. Most health surveys have certain limitations when studying AI population due to the small sample sizes for AI population. Data collected by AI Tribal Epidemiology Centers (TECs) provides an excellent opportunity to conduct research for AI population due to sufficient sample size and extensive information. However, most surveys conducted by TECs used non-probability sampling design (e.g. convenient sample) due to its lower cost and increased time efficiency. Non-probability sample may suffer from sampling, coverage and nonresponse errors without further proper adjustments. Such difficulties greatly hampers the analysis of AI population in health and behavior research. Our general hypothesis is that data integration by combining information from non-probability and probability samples can reduce sampling, coverage and nonresponse errors in original non-probability sample. The Goal of this project is to develop an accurate and robust data integration methodology for AI population analysis specifically tailored to health and behavior research. During the past years, we have 1) studied data integration using calibration and parametric modeling approaches; 2) investigated machine learning and propensity score modeling methods in survey sampling and other fields; and 3) assembled an experienced team of multi-disciplinary team of experts. In this project, we propose to capitalize on our expertise and fulfill the following Specific Aims: Aim 1. Develop a data integration approach using machine learning and propensity score modeling We will develop machine learning and propensity score based data integration approaches to combine information from non-probability and probability samples. Compared to existing methods (i.e., Calibration, Parametric approach), our proposed approaches are more robust against the failure of underlying model assumptions. The inference is more general and multi-purpose (e.g. one can estimate most parameters such as means, totals and percentiles). Simulation studies will be performed to compare our proposed methods with other existing methods. A computing package will be built to implement the method in other settings. Aim 2. Evaluate the accuracy and robustness of the proposed method in AI health and behavior research We will use real data to validate the proposed methods in terms of accuracy and robustness to the various data types. The performance will also be assessed by comparing with results from existing data integration methods such as calibration and parametric modeling approaches. The planned study takes advantage of a unique data source and expands the impact of the Indian Health Service (IHS)-funded research. We expect this novel integration method will vertically advance the field by facilitating the analysis based on non-probability sample, which can provide in-depth understanding regarding the AI population health and behavior studies. Project Narrative The overall goal of this R21 project is to develop an accurate, robust and multi-purpose data integration methodology for AI population (non-probability sample) analysis specifically tailored to health and behavior research such as diabetes and smoking. The code implementing the proposed method will be released and is general enough to be applied to AI population studies of other fileds. The success of this study will vertically advance the field by facilitating the AI population analysis, which can provide a better guidance and new insights on the future precision personalized prevention and treatment of certain diseases.",Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1,10271402,R21MD014658,"['Adult', 'Age', 'American', 'American Indians', 'Behavioral', 'Behavioral Risk Factor Surveillance System', 'Calibration', 'Censuses', 'Code', 'Communities', 'Community Surveys', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Sources', 'Diabetes Mellitus', 'Disease', 'Epidemiology', 'Ethnic group', 'Event', 'Failure', 'Funding', 'Future', 'General Population', 'Geographic state', 'Goals', 'Health', 'Health Fairs', 'Health Surveys', 'Health behavior', 'High Prevalence', 'Kansas', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Not Hispanic or Latino', 'Oklahoma', 'Performance', 'Population', 'Population Analysis', 'Population Study', 'Prevalence', 'Probability', 'Probability Samples', 'Publishing', 'Race', 'Research', 'Research Personnel', 'Respondent', 'Risk Factors', 'Sample Size', 'Sampling', 'Smoking', 'Surveys', 'Target Populations', 'Testing', 'Texas', 'Time', 'Tobacco', 'Training', 'United States Indian Health Service', 'Weight', 'Work', 'Youth', 'base', 'behavioral study', 'cigarette smoking', 'cluster computing', 'cost', 'data integration', 'data quality', 'design', 'experience', 'improved', 'individualized prevention', 'innovation', 'insight', 'multidisciplinary', 'novel', 'personalized medicine', 'population health', 'simulation', 'smoking prevalence', 'success', 'therapy development', 'tribal health']",NIMHD,UNIVERSITY OF OKLAHOMA HLTH SCIENCES CTR,R21,2021,109613
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,10063532,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,360227
"Climate Penalty: Climate-driven Increases in Ozone and PM2.5 Levels and Mortality Project Summary Climate change is the greatest public health challenge of the 21st century. While numerous pathways of the health impact of climate change have been proposed, the “climate penalty” effect, i.e., a warming temperature worsens ambient air quality and consequently influences human health, remains poorly understood, resulting in an underestimated public health burden associated with global warming. Our previous epidemiological studies have reported that higher summer mean temperatures and higher PM2.5 concentrations are each associated with increased all-cause mortality in the Medicare population (aged ≥65) in the Southeastern US (SEUS)1, 2. Satellite and ground-based observations suggest a strong dependence of air pollution on interannual variabilities of summer mean temperature in SEUS3. These findings suggest that the indirect health effect of temperature via the climate penalty on air quality can be potentially important in the SEUS region, in addition to the direct adverse effects that we observed. However, clear epidemiological evidence of the air pollution serving as a mediator for the health effects of temperature, and accurate estimate of this effect is still missing in current literature. Herein, drawing on our preliminary results, we hypothesize that rising temperature can indirectly affect all-cause mortality via worsening both PM2.5 and ozone levels in the SEUS. We propose a study that will leverage the Medicare cohort from 2000-2016 (124 million person-years), the largest longitudinal cohort available for the SEUS and the high-resolution temperature, PM2.5, and O3 data, to investigate all-cause mortality in response to the “climate penalty” effect using a mediation statistical analysis. Specifically, in this project we will (1) update the present- day temperature and ozone predictions at 1-km2 grids across the SEUS through 2016 by incorporating ensemble averaging of machine learning models; (2) quantify the health effect of “climate penalty” on all-cause mortality using a mediation analysis, and explore whether mitigating anthropogenic air pollution emissions might serve as a pathway of climate change adaptation; (3) perform a risk assessment on the excess deaths related to the climate penalty on air pollution for the mid- (2050) and late-21st century (2100), using climate model output, chemical transport modeling, along with the top-down estimate of “climate penalty” from Aim 2. The proposed research will improve understanding of the interplays between climate, air pollution, and human health based on real-world big data, and provide epidemiological evidence of an important pathway that climate change adversely affects human health, with immediate relevance to climate and environmental policymaking. Project Narrative This project aims to estimate the health effect of “climate penalty”, i.e., the rising temperature indirectly affects human health via worsening ambient air quality (primarily PM2.5 and ozone levels) using a mediation analysis based on satellite-retrieved exposures and Medicare all-cause mortality. We will test the hypotheses that 1) the indirect health effect of a warming climate by worsening air quality can be a major public health burden of future climate change, and 2) improving air quality by reducing anthropogenic emission can mitigate the health effect of climate penalty. We will also forecast the excess deaths in 2050 and 2100 related to the climate penalty on air pollution using climate model ensembles simulated for different emission scenarios.",Climate Penalty: Climate-driven Increases in Ozone and PM2.5 Levels and Mortality,10218738,R21ES032606,"['Address', 'Adverse effects', 'Affect', 'Air', 'Air Pollution', 'American', 'Big Data', 'Cessation of life', 'Chemicals', 'Chronic', 'Climate', 'Coupled', 'Data', 'Data Set', 'Databases', 'Dependence', 'Environmental Policy', 'Epidemiology', 'Frequencies', 'Future', 'Global Warming', 'Goals', 'Health', 'Health Insurance', 'Hospitalization', 'Human', 'Individual', 'Knowledge', 'Lead', 'Link', 'Literature', 'Longitudinal cohort', 'Machine Learning', 'Measures', 'Mediation', 'Mediator of activation protein', 'Medicare', 'Modeling', 'Outcome', 'Output', 'Ozone', 'Pathway interactions', 'Personal Satisfaction', 'Persons', 'Planet Earth', 'Policies', 'Policy Making', 'Pollution', 'Population', 'Population Study', 'Positioning Attribute', 'Public Health', 'Quality Control', 'Reaction', 'Reporting', 'Research', 'Resolution', 'Risk Assessment', 'Statistical Data Interpretation', 'Statistical Methods', 'Suggestion', 'Surface', 'Temperature', 'Testing', 'Update', 'Weather', 'air pollution control', 'anthropogenesis', 'atmospheric chemistry', 'base', 'climate change', 'climate impact', 'cohort', 'epidemiology study', 'experience', 'fine particles', 'human old age (65+)', 'improved', 'mortality', 'neural network', 'oxidation', 'pollutant', 'prevent', 'prospective', 'random forest', 'resilience', 'response', 'tropospheric ozone', 'ventilation', 'volatile organic compound', 'warm temperature']",NIEHS,EMORY UNIVERSITY,R21,2021,260895
"A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals PROJECT SUMMARY The aim of this proposal is to deliver an innovative and easy-to-use experimental platform for measuring and quantifying naturalistic behaviors of mammalian animal models used for biomedical research, including rodents and monkeys, across a range of spatial and temporal scales. This will require developing a method for tracking movements freely behaving animals with far higher spatiotemporal resolution and more kinematic detail than currently possible. To overcome the limitations of current technologies, a new solution is proposed that synergistically combines two methods - marker based motion capture and a video- based machine learning approach. First, using marker-based motion capture, the gold standard for 3D tracking in humans, the position of experimental subjects' head, trunk, and limbs will be tracked in 3D with submillimeter precision. An innovative marker design, placement strategy, and post-processing pipeline will ensure an unprecedentedly detailed description of rodent behavior over a large range of timescales. To make the system more efficient, robust, affordable and better suited for high-throughput longitudinal studies, the unprecedentedly rich and large 3D datasets generated by the motion capture experiments will be leveraged to train a deep neural network to predict pose and appendage positions from a set of 1-6 normal video cameras. To best capitalize on the large training datasets, the latest advances in convolutional neural networks for image analysis will be incorporated. Together, these advances will promote generalization of the high-resolution 3D tracking system to a variety of animals and environments, thus establishing a cheap, flexible, and easy-to use kinematic tracking method that can easily be scaled up and adopted by other labs. The large ground-truth datasets will allow the system to be benchmarked and compared against state-of-the art technologies in quantitative and rigorous ways. Preliminary studies have been very positive and suggest large improvements over current methods both when it comes to the range of behaviors that can be tracked and the precision with which they can be measured. Importantly, all new technology will be readily shared with the scientific community, thereby leveraging from this single grant the potential for numerous investigators to dramatically improve the efficiency of their research programs requiring rigorous quantitative descriptions of animal behavior. Narrative We will develop and disseminate innovative new technology for measuring precise 3D kinematics in freely moving animals over long time-periods. Our proposed experimental platform will illuminate how natural behaviors are organized and help us understand how they are controlled by the nervous system, and how this control goes awry in disease. The technological leap made possible by this grant will catalyze a host of studies on the neural mechanisms underlying motor control, learning, and mental disorders, and thus help in the discovery of new diagnostic and therapeutic approaches for afflicted patients.",A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals,10120068,R01GM136972,"['3-Dimensional', 'Address', 'Adopted', 'Anatomy', 'Animal Behavior', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Benchmarking', 'Biological Models', 'Biomedical Research', 'Brain', 'Callithrix', 'Cephalometry', 'Communities', 'Complex', 'Data', 'Data Set', 'Deer Mouse', 'Disease', 'Ensure', 'Environment', 'Gold', 'Grant', 'Hand', 'Head', 'Human', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Learning Disorders', 'Lighting', 'Limb structure', 'Logic', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Monkeys', 'Motion', 'Movement', 'Mus', 'Nervous System Physiology', 'Nervous System control', 'Neurologic Deficit', 'Output', 'Patients', 'Performance', 'Positioning Attribute', 'Posture', 'Process', 'Rattus', 'Research', 'Research Personnel', 'Resolution', 'Rodent', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'appendage', 'base', 'computer science', 'convolutional neural network', 'cost', 'deep neural network', 'design', 'expectation', 'experimental study', 'flexibility', 'improved', 'innovation', 'kinematics', 'motor control', 'neural network', 'neuromechanism', 'new technology', 'novel diagnostics', 'novel therapeutic intervention', 'programs', 'relating to nervous system', 'scale up', 'skeletal', 'spatiotemporal']",NIGMS,HARVARD UNIVERSITY,R01,2021,411071
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10175029,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data repository', 'data resource', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'trustworthiness', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2021,330299
"Modeling the influence of translation-elongation kinetics on protein structure and function Project Summary mRNA degradation is an essential process in post-translational gene regulation, and influences protein expression levels in cells. In S. cerevisea the lifetime of mRNA ranges from 43 sec to 39 min, with a median half-life of 3.6 min. The molecular factors governing these differential degradation rates has long been an area of active research. Recently though, clear evidence has emerged that the codon optimality correlates with half- lives. At a mechanistic level, the emerging perspective is that some transcripts are translated quickly, and some slowly, and that transcripts in which ribosomes end up forming queues, much like a traffic jam of cars on a highway, are recognized by ubiquitin ligases such as Hel2 that trigger the RQC pathway to promote mRNA degradation. There are two major gaps in this field. The first is the capability to predict mRNA half-lives accurately from mRNA sequence features. The second is understanding at the molecular level how the distribution of codon translation speeds along a transcript’s coding sequence promote ribosome queues and hence degradation. In this proposal, a graduate student will combine the PI’s labs expertise in modeling the kinetics of translation and ribosome traffic with interpretable machine learning techniques to address these two gaps. In achieving this, the field will be advanced by having both predictive and explanatory models for how translation speed and codon usage differentially impacts the degradation rates of different mRNAs. Specifically, our first aim is to build an interpretable machine learning model to identify robust and predictive features governing mRNA degradation. Our second aim is to explain at the molecular level why these features influence degradation rates. We will do this in two ways. First, we will use the essential and predictive features resulting from the interpretable machine learning model to identify potential underlying mechanisms contributing to degradation. Second, we will simulate the movement of ribosomes on each transcript based on reported initiation and elongation rates to detect ribosome queues and provide an explanation for differential degradation rates. Finally, our third aim is to test the predictions coming from the models. For example, do the models from Aim 1 accurately predict mRNA half-lives when synonymous mutations are introduced? There is sufficient published data on transcriptome-wide mRNA half-lives on S. cerevisiae to train and test the machine learning models in Aim 1. Further, we have arranged for a machine learning expert to co-advise the graduate student on the second aim. This co-advisor is already a collaborator of the PI on other machine learning projects. Finally, a collaborator who has measured mRNA half-lives will further advise the student on the third aim. In summary, this training supplement will address cutting edge questions in the molecular biology and biophysics of mRNA lifetimes and provide the student the opportunity to get advanced training and expertise in machine learning, molecular modeling, and experimental techniques. Project Narrative Messenger RNA (mRNA) half-lives are influenced by the rate of protein synthesis and the ribosome traffic jams that can form on transcripts when slow-translating codons are encountered by ribosomes. The complex distribution of codon usage across transcripts, and the interplay of initiation and elongation rates that can create ribosome queues make it difficult to predict an mRNA's half-life based on its sequence. Here, we will apply machine learning to accurately predict mRNA half-lives from sequence, and combine it with biophysical modeling to understand the molecular events regulating mRNA degradation.",Modeling the influence of translation-elongation kinetics on protein structure and function,10307359,R35GM124818,"['Address', 'Area', 'Biophysics', 'Cells', 'Code', 'Codon Nucleotides', 'Complex', 'Coupling', 'Data', 'Event', 'Gene Expression Regulation', 'Half-Life', 'Kinetics', 'Lead', 'Machine Learning', 'Measures', 'Messenger RNA', 'Modeling', 'Molecular', 'Molecular Biology', 'Movement', 'Mutation', 'Pathway interactions', 'Process', 'Property', 'Protein Biosynthesis', 'Proteins', 'Publishing', 'Reporter', 'Reporting', 'Research', 'Ribosomes', 'Saccharomyces cerevisiae', 'Speed', 'Students', 'Techniques', 'Testing', 'Training', 'Transcript', 'Translating', 'Translations', 'base', 'biophysical model', 'graduate student', 'insight', 'kinetic model', 'mRNA Transcript Degradation', 'models and simulation', 'molecular modeling', 'protein expression', 'protein structure function', 'ribosome profiling', 'simulation', 'transcriptome', 'ubiquitin ligase']",NIGMS,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R35,2021,31246
"Extraction of molecular signature of HFpEF via a machine learning-empowered proteomic characterization: A study of the BCAA pathway PROJECT SUMMARY Heart failure with preserved ejection fraction (HFpEF), characterized by heart failure symptoms with normal ejection fraction, is highly prevalent. However, most HFpEF patients do not respond to standard therapy for heart failure with reduced ejection fraction (HFrEF), and there are no clear and uniform diagnostic criteria to stratify and differentiate HFpEF from HFrEF. Therefore, there is a pressing unmet need for us to better understand HFpEF at the molecular and system levels. Unbiased approaches such as machine learning (ML) offer a powerful means to tease out the molecular signatures of HFpEF in relevant disease models. The emerging evidence implicates that metabolism and redox homeostasis are two significant disruptions in cellular processes evidenced by clinical symptoms of HFpEF. Previous studies have identified branched-chain amino acid (BCAA) catabolic defect as another major metabolic hallmark in heart failure as well as in metabolic disorders. Moreover, BCAA catabolic defects have been demonstrated to directly impact mitochondrial function and elevate reactive oxygen species (ROS) production, resulting in oxidative stress-sensitive post-translational modifications (O-PTMs) that govern protein function and pathways. These exciting discoveries lead to our new hypothesis that O-PTM-mediated proteome remodeling is a dynamic and pervasive molecular change in diseased hearts, affecting proteins with central function in cardiac homeostasis and pathophysiology. To investigate the unique molecular features and pathogenic mechanisms of HFpEF, we highlight a novel HFpEF mouse model that incorporates both genetic predisposition for obesity/diabetes and pressure-overload, the two major risk factors for HFpEF, by performing trans-aortic constriction (TAC) in the ob/ob mice. We have also perfected the experimental tools and data analysis platform to provide O-PTM profiling at the whole-proteome level in hearts. Accordingly, we have strategically formulated the following aims according to three phenotypic levels: At the systemic level, Aim 1 will establish and characterize in vivo mouse models of HFpEF vs. HFrEF by cardiac and mitochondrial function as well as redox status. At the organellar level, Aim 2 will conduct targeted proteomics profiling of the cardiac mitochondria and extract O-PTM signatures using ML-based methods to achieve deep phenotyping of HFpEF and HFrEF. This information will then be integrated and enriched in an O- PTM molecular atlas and knowledge graph. At the molecular level, Aim 3 will target the BCAA catabolic pathway to exhaustively scrutinize its role in HFpEF and HFrEF. A multilevel understanding of the HFpEF phenotype, from its global profiling to molecular targets, will provide valuable new insights into the disease process that can lead to potential novel diagnostic and therapeutic targets. PROJECT NARRATIVE HFpEF is highly prevalent, yet there are few effective treatments or clear criteria to differentiate it from HFrEF. We propose to extract molecular signatures unique to HFpEF and HFrEF using a novel HFpEF mouse model and machine learning-based approaches. We anticipate that a multilevel understanding of the HFpEF phenotype, from its global profiling to molecular targets, will provide valuable new insights into the disease process that can lead to potential novel diagnostic and therapeutic targets.",Extraction of molecular signature of HFpEF via a machine learning-empowered proteomic characterization: A study of the BCAA pathway,10183311,R01HL146739,"['Address', 'Affect', 'Age', 'Aging', 'Atlases', 'Biology', 'Branched-Chain Amino Acids', 'Cardiac', 'Catabolism', 'Cell physiology', 'Cells', 'Clinical', 'Complex', 'Data Analyses', 'Data Science', 'Defect', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Disease Progression', 'Disease model', 'EFRAC', 'Enzymes', 'Exposure to', 'Failure', 'Functional disorder', 'Genetic Predisposition to Disease', 'Glucose', 'Heart', 'Heart Atrium', 'Heart Diseases', 'Heart failure', 'Homeostasis', 'Hypertension', 'Knowledge', 'Lead', 'Link', 'Machine Learning', 'Mechanical Stress', 'Mediating', 'Metabolic', 'Metabolic Diseases', 'Metabolic Pathway', 'Metabolic stress', 'Metabolism', 'Methodology', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Molecular Genetics', 'Molecular Profiling', 'Molecular Target', 'Mus', 'Myocardium', 'Nature', 'Obese Mice', 'Obesity', 'Organ', 'Oxidation-Reduction', 'Oxidative Stress', 'Pathogenesis', 'Pathogenicity', 'Pathologic', 'Pathway interactions', 'Patients', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Production', 'Proteins', 'Proteome', 'Proteomics', 'Reactive Oxygen Species', 'Regulation', 'Research', 'Research Personnel', 'Risk Factors', 'Role', 'Stress', 'Symptoms', 'System', 'Technology', 'Thinness', 'Treatment Failure', 'Uncertainty', 'Woman', 'antioxidant enzyme', 'base', 'computational platform', 'constriction', 'effective therapy', 'empowered', 'exhaustion', 'fatty acid metabolism', 'heart function', 'in vivo', 'insight', 'knowledge graph', 'men', 'molecular phenotype', 'mouse model', 'new therapeutic target', 'novel', 'novel diagnostics', 'preservation', 'pressure', 'protein function', 'therapeutic target', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,649707
"Multi-omic Subtyping of Chronic Obstructive Pulmonary Disease PROJECT SUMMARY/ABSTRACT Chronic obstructive pulmonary disease (COPD) is the leading cause of respiratory mortality in the United States. COPD is a highly heterogeneous disease and some COPD therapies are only applied to specific clinically defined subtypes. With the advent of multiple high-throughput biological assays and machine learning approaches, data-driven subtypes are increasingly being recognized. We hypothesize that such subtypes exist in COPD and that they can be identified using an integrative, multi-'omic approach. To accomplish this goal, we first propose to complement existing RNA and whole genome sequencing data in the well-phenotyped COPDGene study with peripheral blood microRNA sequencing. We will study the relationship of microRNA to genetic variation and gene expression in COPD. Next, we will apply a patient-based network similarity method to these three data types to identify COPD molecular subtypes. Finally, we will associate these subtypes with important clinical phenotypes and outcomes, and validate these subtypes in an independent subset of subjects. Our analysis targets a key clinical problem in COPD management, and will allow the mentee to become an independent investigator, applying bioinformatic and machine learning methods to genomic data in respiratory diseases. PROJECT NARRATIVE Chronic obstructive pulmonary disease (COPD) is a leading cause of death in the United States. Patients with COPD may have very similar lung function but differ in many other characteristics. We propose to use multiple types of biologic data to identify different COPD subtypes, which may be important for disease prognosis and treatment.",Multi-omic Subtyping of Chronic Obstructive Pulmonary Disease,10205150,K08HL136928,"['Affect', 'Bioinformatics', 'Biological', 'Biological Assay', 'Blood', 'Cause of Death', 'Characteristics', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complement', 'Complex', 'Data', 'Diagnostic radiologic examination', 'Disease', 'Disease Management', 'Expert Opinion', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Diseases', 'Genetic Risk', 'Genetic Variation', 'Genomics', 'Goals', 'Impairment', 'Individual', 'Lung', 'Lung diseases', 'Lung volume reduction surgery', 'Machine Learning', 'Measures', 'Methods', 'MicroRNAs', 'Molecular', 'Molecular Profiling', 'Multiomic Data', 'Muscular Atrophy', 'Network-based', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Phenotype', 'Principal Investigator', 'Pulmonary Emphysema', 'RNA', 'Research Personnel', 'SNP array', 'Severities', 'Spirometry', 'Testing', 'Training', 'Trans-Omics for Precision Medicine', 'United States', 'base', 'clinical phenotype', 'clinically relevant', 'cohort', 'disorder subtype', 'exome', 'genome sequencing', 'genome wide association study', 'genomic data', 'machine learning method', 'miRNA expression profiling', 'molecular subtypes', 'mortality', 'multiple omics', 'next generation sequencing', 'novel', 'outcome forecast', 'patient subsets', 'peripheral blood', 'personalized approach', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'risk variant', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,K08,2021,172800
"Pathogenesis of Primary Biliary Cholangitis PROJECT SUMMARY/ABSTRACT  The major goal of this proposal is to conduct the first multi-omics translational study of Primary Biliary Cholangitis (PBC), thereby identifying the systems-level networks driving pathological processes in this rare, autoimmune liver disease. Improved understanding of PBC pathogenesis is urgently needed to inform tailored care and the development of new effective therapies. Comprehensive assessments of immunity and the role of environmental influence in PBC are currently lacking. Such evaluations would provide critical knowledge to leverage recent advances in the field’s ability to pharmacologically alter the immune system, thereby providing new hope to PBC patients. Having made significant contributions to the understanding of the genomic architecture underlying development of autoimmunity in PBC, we propose a novel, patient-oriented, multi- omics approach. In this new application, we will decipher how peripheral cellular immunity and non-cellular circulating factors contribute to PBC pathogenesis. We hypothesize that multi-omic analyses integrating cellular and non-cellular factors will identify systems-level pathways driving PBC pathogenesis. To test this hypothesis, we develop an innovative platform that combines aspects of machine learning and quantum statistical mechanics to identify omics-based signatures of PBC that when integrated with clinical features will unveil biological pathways driving disease pathogenesis.  To perform this multi-omic study of PBC, we have assembled a world-class, multi-disciplinary team synergizing expertise in PBC biology and omics-scale analytics as well as resources across Mayo Clinic and Columbia University. With a new, in-hand collection of diverse biological specimens from 300 deeply- phenotyped PBC patients and 300 well-matched controls, our studies are already underway with preliminary data demonstrating measureable immunome, methylome, inflammatory protein, exposome, and metabolome differences between PBC patients and controls. In Aim 1, we thoroughly evaluate peripheral immune composition (the immunome) and activation state (methylome, transcriptome, inflammatory proteins) using mass-cytometry (CyTOF), sequencing- and proximity extension-based methods. In Aim 2, we perform a cutting-edge study of exogenous chemicals “the exposome” and endogenous metabolites “the metabolome” using ultrahigh resolution mass spectroscopy to discover pathogenic alterations in metabolism in PBC. We also develop an assay to quantify liver-specific cell-free DNA in blood as a measure of disease severity. In Aim 3, we integrate omic-specific signatures (Aims 1 and 2) using a novel approach to identify and prioritize PBC- associated features for further biological investigation. We then infer clinically-relevant subgroups of PBC patients by performing similarity network fusion analysis. In summary, using state-of-the-art, multi-omic analyses, we will discover systems-level networks driving PBC pathogenesis, spurring development of new hypotheses and studies designed to elucidate PBC pathobiology and identify novel therapies. PROJECT NARRATIVE We will conduct the first multi-omics translational study of primary biliary cholangitis (PBC), to improve understanding of the culprits driving this rare, autoimmune liver disease. By integrating multiple layers of omics data, we will better define the architecture of cellular networks driving PBC. In so doing, we will identify molecular signatures including immune alterations, environmental toxins, and metabolism-related chemicals unique to PBC patients, thereby spurring improved understanding of PBC pathobiology and identification of novel druggable targets.",Pathogenesis of Primary Biliary Cholangitis,10095117,R01DK126691,"['Architecture', 'Artificial Intelligence', 'Autoimmune Process', 'Autoimmunity', 'Automobile Driving', 'Biological', 'Biological Assay', 'Biology', 'Blood', 'Caring', 'Cellular Immunity', 'Chemicals', 'Clinic', 'Clinical', 'Collection', 'Cytometry', 'Data', 'Development', 'Dimensions', 'Disease', 'Disease Progression', 'Environment', 'Evaluation', 'Funding', 'Genomics', 'Goals', 'Hand', 'Heel', 'Immune', 'Immune system', 'Immunity', 'Individual', 'Inflammatory', 'Investigation', 'Knowledge', 'Light', 'Liver', 'Liver diseases', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Mediating', 'Metabolic', 'Metabolism', 'Methods', 'Molecular Profiling', 'Onset of illness', 'Pathogenesis', 'Pathogenicity', 'Pathologic Processes', 'Pathway interactions', 'Patients', 'Peripheral', 'Pharmacology', 'Phenotype', 'Pilot Projects', 'Positioning Attribute', 'Primary biliary cirrhosis', 'Process', 'Proteins', 'Publications', 'Questionnaires', 'Research Design', 'Resolution', 'Resources', 'Risk', 'Role', 'Sampling', 'Severity of illness', 'Specimen', 'Statistical Mechanics', 'Subgroup', 'System', 'Testing', 'Therapeutic', 'Toxic Environmental Substances', 'Universities', 'Work', 'advanced disease', 'base', 'biobank', 'cell free DNA', 'clinically relevant', 'combinatorial', 'effective therapy', 'genomic locus', 'improved', 'innovation', 'insight', 'metabolome', 'methylome', 'multidisciplinary', 'multiple omics', 'new therapeutic target', 'novel', 'novel strategies', 'novel therapeutics', 'patient oriented', 'quantum', 'response', 'toxin metabolism', 'transcriptome', 'translational study']",NIDDK,MAYO CLINIC ROCHESTER,R01,2021,628683
"Bioinformatics Strategies for Genome-Wide Association Studies One promise of precision medicine for Alzheimer’s disease is to edit a patient’s DNA and/or administer therapeutics targeting etiologic molecules that prevent or reverse the disease process using a tailored design. All of this happens at the level of the individual and requires precision knowledge of that patient’s biology. In stark contrast, much of the knowledge we possess about genomic risk factors comes from statistical measures of association in subjects ascertained with and without Alzheimer’s. The conceptual and practical disconnect between the populations we study and the individuals we want to treat is a major source of confusion about how to move forward in an era driven by genome technology. The primary goal of this proposal is to develop novel informatics methodology and software to facilitate precision medicine for Alzheimer’s by connecting population and individual genomic phenomena. We propose here a Virtual Genomic Medicine (VGMed) workbench where clinicians can carry out thought experiments about the treatment of individual Alzheimer’s patients using models of disease risk derived from population-level studies. This will be accomplished by first developing a novel Genomics-guided Automated Machine Learning (GAML) algorithm for deriving risk models from real data that is accessible to Alzheimer’s clinicians (AIM 1). We will then develop a novel simulation approach that is able to generate artificial Alzheimer’s data that preserves the distribution of genetic effects observed in the real data while maintaining other characteristics such as genotype frequencies (AIM 2). This will generate open data allowing anyone to perform virtual interventions on Alzheimer’s patients derived from a population-level risk distribution. The workbench will allow editing of individual genotypes and simulate the administration of drugs by editing machine learning parameters in the simulation model (AIM 3). The change in risk and Alzheimer’s disease status for the specific patient will be tracked in real time. Finally, we provide a feature in the workbench that will allow the Alzheimer’s clinician to generate specific hypotheses about individual genetic variants that can then be validated using integrated Alzheimer’s knowledge sources that include databases such as PubMed and ClinVar thus giving the user immediate feedback (AIM 4). All methods and software will be provided as open-source to the Alzheimer’s disease research community (AIM 5). Most genetic studies of Alzheimer’s disease result in statistical summaries of risk derived from human populations. These statistical summaries are not that helpful for determining the health of an individual. This proposal will create new computer algorithms and software help Alzheimer’s clinicians and researchers connect population-level statistics with individual level genetic effects to advance our understanding of how to treat Alzheimer’s patients based on their own unique genetic makeup.",Bioinformatics Strategies for Genome-Wide Association Studies,10284977,R01LM010098,"['Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Bioinformatics', 'Biology', 'Characteristics', 'ClinVar', 'Communities', 'Computational algorithm', 'Computer software', 'Confusion', 'DNA', 'Data', 'Databases', 'Disease', 'Disease model', 'Etiology', 'Feedback', 'Frequencies', 'Genetic', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Study', 'Process', 'PubMed', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Source', 'Technology', 'Time', 'base', 'data preservation', 'design', 'disorder risk', 'experimental study', 'genetic makeup', 'genetic variant', 'genome wide association study', 'machine learning algorithm', 'models and simulation', 'novel', 'open data', 'open source', 'precision medicine', 'prevent', 'simulation', 'statistics', 'therapeutic target', 'virtual', 'virtual intervention']",NLM,UNIVERSITY OF PENNSYLVANIA,R01,2021,391879
"Mechanism-Driven Virtual Adverse Outcome Pathway Modeling for Hepatotoxicity PROJECT SUMMARY/ABSTRACT  Experimental animal and clinical testing to evaluate hepatotoxicity demands extensive resources and long turnaround times. Utilization of computational models to directly predict the toxicity of new compounds is a promising strategy to reduce the cost of drug development and to screen the multitude of industrial chemicals and environmental contaminants currently lacking safety assessments. However, the current computational models for complex toxicity endpoints, such as hepatotoxicity, are not reliable for screening new compounds and face numerous challenges. Our recent studies have shown that traditional Quantitative Structure-Activity Relationship modeling is applicable for relatively simple properties or toxicity endpoints with a clear mechanism, but fails to address complex bioactivities such as hepatotoxicity. The primary objective of this proposal is to develop novel mechanism-driven Virtual Adverse Outcome Pathway (vAOP) models for the fast and accurate assessment of hepatotoxicity in a high-throughput manner The resulting vAOP models will be experimentally validated using a complement of in vitro and ex vivo testing. We have generated a preliminary vAOP model based on the antioxidant response element (ARE) pathway that has undergone initial validation and refinement using in vitro testing. To this end, our project will generate novel predictive models for hepatotoxicity by applying 1) a virtual cellular stress pathway model to mechanism profiling and assessment of new compounds; 2) computational predictions to fill in the missing data for specific targets within the pathway; 3) in vitro experimental validation with three complementary bioassays; and 4) ex vivo experimental validation with pooled primary human hepatocytes capable of biochemical transformation. The scientific approach of this study is to develop a universal modeling workflow that can take advantage of all available short-term testing information, obtained from both computational predictions using novel machine learning approaches and in vitro experiments, for target compounds of interest. We will validate and use our modeling workflow to directly evaluate the hepatotoxicity of new compounds and prioritize candidates for validation in pooled primary human hepatocytes. The resulting workflow will be disseminated via a web portal for public users around the world with internet access. Importantly, this study will pave the way for the next generation of chemical toxicity assessment by reconstructing the modeling process through a combination of big data, computational modeling, and low cost in vitro experiments. To the best of our knowledge, the implementation of this project will lead to the first publicly available mechanisms-driven modeling and web- based prediction framework for complex chemical toxicity based on publicly-accessible big data. These deliverables will have a significant public health impact by not only prioritizing compounds for safety testing or new chemical development, but also revealing toxicity mechanisms. PROJECT NARRATIVE Hepatotoxicity is a leading safety concern in the development of new chemicals. We will create virtual “Adverse Outcome Pathway” models that will directly evaluate the hepatotoxicity potentials of chemicals using massive public toxicity data. The primary deliverable of this project will be a publically-accessible, web-based search engine to evaluate new chemicals for risk of hepatotoxicity.",Mechanism-Driven Virtual Adverse Outcome Pathway Modeling for Hepatotoxicity,10166848,R01ES031080,"['Address', 'Animal Model', 'Animal Testing', 'Antioxidants', 'Big Data', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Markers', 'Cellular Stress', 'Chemical Injury', 'Chemical Structure', 'Chemicals', 'Clinical', 'Complement', 'Complex', 'Computer Models', 'Computer software', 'Computers', 'Cryopreservation', 'Custom', 'Data', 'Data Pooling', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Drug Costs', 'Ensure', 'Environment', 'Environmental Pollution', 'Evaluation', 'Face', 'Generations', 'Hepatocyte', 'Hepatotoxicity', 'Human', 'In Vitro', 'Industrialization', 'Injury', 'Internet', 'Libraries', 'Liver', 'Luciferases', 'Machine Learning', 'Marketing', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nutraceutical', 'Online Systems', 'Pathway interactions', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Population', 'Process', 'Property', 'Proteomics', 'PubChem', 'Public Health', 'Quantitative Structure-Activity Relationship', 'Research', 'Research Personnel', 'Resources', 'Response Elements', 'Risk', 'Safety', 'Signal Transduction', 'Source', 'Statutes and Laws', 'System', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Toxicology', 'Translating', 'Validation', 'Vertebrates', 'adverse outcome', 'base', 'candidate validation', 'cell injury', 'combat', 'computational toxicology', 'computer framework', 'computerized tools', 'cost', 'data mining', 'deep neural network', 'design', 'developmental toxicity', 'drug development', 'endoplasmic reticulum stress', 'experimental study', 'hepatocellular injury', 'improved', 'in vitro Assay', 'in vitro testing', 'in vivo', 'interest', 'knowledge base', 'large datasets', 'liver injury', 'next generation', 'novel', 'pre-clinical', 'predictive modeling', 'reproductive toxicity', 'research clinical testing', 'safety assessment', 'safety testing', 'screening', 'search engine', 'tool', 'toxicant', 'transcriptomics', 'virtual', 'web portal']",NIEHS,RUTGERS THE STATE UNIV OF NJ CAMDEN,R01,2021,457521
"An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics Immune-repertoire sequence, which consists of an individual's millions of unique antibody and T-cell receptor (TCR) genes, encodes a dynamic and highly personalized record of an individual's state of health. Our long- term goal is to develop the computational models and tools necessary to read this record, to one day be able diagnose diverse infections, autoimmune diseases, cancers, and other conditions directly from repertoire se- quence. The key problem is how to find patterns of specific diseases in repertoire sequence, when repertoires are so complex. Our hypothesis is that a combination of bottom-up (sequence-level) and top-down (systems- level) modeling can reveal these patterns, by encoding repertoires as simple but highly informative models that can be used to build highly sensitive and specific disease classifiers. In preliminary studies, we introduced two new modeling approaches for this purpose: (i) statistical biophysics (bottom-up) and (ii) functional diversity (top-down), and showed their ability to elucidate patterns related to vaccination status (97% accuracy), viral infection, and aging. Building on these studies, we will test our hypothesis through two specific aims: (1) We will develop models and classifiers based on the bottom-up approach, statistical biophysics; and (2) we will de- velop the top-down approach, functional diversity, to improve these classifiers. To achieve these aims, we will use our extensive collection of public immune-repertoire datasets, beginning with 391 antibody and TCR da- tasets we have characterized previously. Our team has deep and complementary expertise in developing computational tools for finding patterns in immune repertoires (Dr. Arnaout) and in the mathematics that under- lie these tools (Dr. Altschul), with additional advice available as needed regarding machine learning (Dr. AlQuraishi). This proposal is highly innovative for how our two new approaches address previous issues in the field. (i) Statistical biophysics uses a powerful machine-learning method called maximum-entropy modeling (MaxEnt), improving on past work by tailoring MaxEnt to learn patterns encoded in the biophysical properties (e.g. size and charge) of the amino acids that make up antibodies/TCRs; these properties ultimately determine what targets antibodies/TCRs can bind, and therefore which sequences are present in different diseases. (ii) Functional diversity fills a key gap in how immunological diversity has been measured thus far, by factoring in whether different antibodies/TCRs are likely to bind the same target. This proposal is highly significant for (i) developing an efficient, accurate, generative, and interpretable machine-learning method for finding diagnostic patterns in repertoire sequence; (ii) applying a robust mathematical framework to the measurement of immuno- logical diversity; (iii) impacting clinical diagnostics; and (iv) adding a valuable new tool for integrative/big-data medicine. The expected outcome of this proposal is an integrated pair of robust and well validated new tools/models for classifying specific disease exposures directly from repertoire sequence. This proposal in- cludes plans to make these tools widely available, to maximize their positive impact across medicine. The proposed research is relevant to public health because B cells/antibodies and T cells play vital roles across such a vast range of health conditions, from infection, to autoimmunity, to cancer, that the ability to de- code what they are doing would be an important step forward for diagnosing these conditions. The proposed research is relevant to the NIH's mission of fostering fundamental creative discoveries, innovative research strategies, and their applications as a basis for ultimately protecting and improving health, specifically relating to the diagnosis of human diseases.",An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics,10165490,R01AI148747,"['Address', 'Affect', 'Aging', 'Amino Acid Motifs', 'Amino Acids', 'Antibodies', 'Autoimmune Diseases', 'Autoimmunity', 'B-Lymphocytes', 'Base Sequence', 'Big Data', 'Binding', 'Biophysics', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Code', 'Collection', 'Complex', 'Computer Models', 'Data Set', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Entropy', 'Fostering', 'Gene Frequency', 'Genes', 'Goals', 'Health', 'Human', 'Immune', 'Immunology', 'Individual', 'Infection', 'Influenza vaccination', 'Intuition', 'Learning', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mission', 'Modeling', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Physics', 'Play', 'Population Heterogeneity', 'Privatization', 'Property', 'Public Health', 'Reading', 'Reporting', 'Research', 'Role', 'Sample Size', 'Sampling', 'Sampling Errors', 'Signs and Symptoms', 'Speed', 'Statistical Study', 'System', 'T-Cell Receptor', 'T-Cell Receptor Genes', 'T-Lymphocyte', 'Testing', 'United States National Institutes of Health', 'Vaccination', 'Virus Diseases', 'Work', 'base', 'biophysical properties', 'clinical diagnostics', 'computerized tools', 'diagnostic accuracy', 'human disease', 'immunological diversity', 'improved', 'information model', 'innovation', 'machine learning method', 'multidisciplinary', 'multilevel analysis', 'novel', 'novel strategies', 'tool']",NIAID,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2021,528873
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,10085244,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'machine learning method', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2021,356625
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,10372268,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'machine learning method', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2021,267499
"Advancing evolutionary genetic inference in humans and other taxa Project Summary/Abstract Background: A major challenge in evolutionary genomics is to characterize the forces shaping present-day patterns of genetic variation. For instance, the extent and manner in which natural selection affects genetic diversity remains highly controversial. Researchers have largely addressed this problem by developing statistical tests or summaries of genome sequence variation that provide insights into the evolutionary forces at play. However, because such approaches typically rely on a single univariate summary of the data, valuable discriminatory information present in the original dataset is lost. A more fruitful strategy would thus be to use multidimensional summaries of genomic data (e.g. a large vector of summary statistics) or even the totality of the input data (e.g. a matrix-representation of a sequence alignment) to make more accurate inferences. An even more powerful approach is to utilize data sets in which the same population is sampled at multiple time points, allowing one to observe evolutionary dynamics in action. Although such genomic time-series data are becoming more prevalent, the development of appropriate computational methodologies has lagged behind the proliferation of such data. Proposal: The Schrider Lab seeks to develop and apply powerful machine learning methods for evolutionary inference. Our work over the next five years will yield powerful software tools leveraging novel representations of genomic datasets, including time-series data. These efforts will dramatically improve researchers' ability to make accurate evolutionary inferences from both population genomic and phylogenetic data. Indeed, preliminary results demonstrate that our methods vastly outperform current approaches in evolutionary genetics. More importantly, we will use these tools to answer pressing evolutionary questions. In particular, our use of time-series data will reveal loci responsible for recent adaptation with much greater confidence than currently possible. Our efforts will help to resolve the controversy over the role of adaptation in shaping patterns of diversity across the human genome. This research has important implications for public health as well, as genes underlying recent adaptations are enriched for disease-associations. Moreover, we are constructing a time-series dataset in the mosquito vector species Aedes aegypti and Aedes albopictus. We will interrogate these data for evidence of recent and ongoing adaptation—this work will reveal loci responsible for the evolution of resistance to insecticides and other control efforts. Encouraging preliminary data also suggest that our work in phylogenetics will substantially improve inferential power in this important research area. More broadly, the success of the novel approaches described in this proposal has the potential to transform the methodological landscape of evolutionary genomic data analysis. Project Narrative The work proposed here seeks to develop and apply powerful machine-learning based software tools for evolutionary genetic inference in humans, mosquito vectors, and other species. Such efforts have important health implications, as they can identify genes involved in adaptation, which in humans are often associated with disease and in mosquitos are often associated with resistance to insecticides and other control efforts.",Advancing evolutionary genetic inference in humans and other taxa,10207692,R35GM138286,"['Address', 'Aedes', 'Affect', 'Area', 'Computing Methodologies', 'Culicidae', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Health', 'Human', 'Human Genome', 'Insecticides', 'Machine Learning', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phylogenetic Analysis', 'Play', 'Population', 'Public Health', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Sampling', 'Sequence Alignment', 'Series', 'Shapes', 'Software Tools', 'Testing', 'Time', 'Variant', 'Work', 'base', 'genomic data', 'improved', 'insight', 'machine learning method', 'novel', 'novel strategies', 'statistics', 'success', 'time use', 'tool', 'vector', 'vector mosquito']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2021,382894
"CSHL Network Biology Conference PROJECT SUMMARY This proposal seeks support for the conference on Network Biology, to take place March/April 2021 to 2025, at the Cold Spring Harbor Laboratory (CSHL). This meeting, held in biannual rotation on the CSHL campus in New York, brings together senior and junior scientists from both experimental and computational laboratories with common interests in network biology. The meeting will emphasize new discoveries and provide an open forum for the presentation of the latest research and results on molecular networks and their relevance to normal and abnormal cellular physiology. It will be essential for advancing knowledge in all aspects of the network modeling process, from data generation in experimental cell biology to data analysis and computer simulation and from the development and validation of network models describing these data to biological inferences made from the models. The conference will include platform sessions on interaction networks, signaling and network dynamics, regulatory networks, computational tools, artificial intelligence and big data, multi-scale networks, networks and disease, networks in differentiation, microbiome networks, network evolution, synthetic networks, network engineering and networks beyond biology though the exact program for the meeting will be assembled after the abstract submission deadline in February 2021 and adapted to ongoing developments in the field in subsequent years. This conference will include significant components designed to facilitate the active participation of younger scientists such as selection of platform speakers on the basis of the scientific merit of their submitted abstracts as well as poster presentations, round tables, lightning talks and poster prizes. Distinguished speakers will also be invited to give platform talks and interact with more junior scientists. The intimate environment at CSHL fosters social interactions and active participation by all. The majority of participants to the previous CSHL Network Biology meeting expressed that they were “very satisfied”. Speakers' panels have consisted of at least 50% women; the gender balance will be maintained in future meetings. In the 2019 iteration of the meeting, a panel discussion was established to address the challenges of Women in Network Science. We will continue to address big community challenges though panel discussions in this meeting. In 2021, we will discuss Applicability and Translatability of Network Biology with panelists including network biologists whose work is deeply influential throughout the ongoing covid-19 pandemic. PROJECT NARRATIVE Biological systems are functionally and structurally formed by complex networks of interacting molecular components, many of which are encoded in the genome. Elucidating the structure and function of these networks and understanding how their dysregulation causes disease are critical steps toward improving human health. This application seeks support for the conference on Network Biology to be held every two years in March/April 2021-25 at the Cold Spring Harbor Laboratory, to bring together experimental and computational biologists and discuss emerging trends and latest results in the field.",CSHL Network Biology Conference,10137390,R13HG011550,"['Address', 'Animals', 'Artificial Intelligence', 'Attention', 'Awareness', 'Big Data', 'Biochemistry', 'Biological', 'Biological Process', 'Biology', 'COVID-19 pandemic', 'Cell physiology', 'Cellular biology', 'Chalk', 'Collaborations', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Discipline', 'Disease', 'Engineering', 'Ensure', 'Environment', 'Equilibrium', 'Event', 'Evolution', 'Faculty', 'Fostering', 'Future', 'Gender', 'Gene Proteins', 'Generations', 'Genetic', 'Genome', 'Geography', 'Health', 'Human', 'Industrialization', 'Influentials', 'International', 'Intervention', 'Knowledge', 'Laboratories', 'Length of Stay', 'Lightning', 'Methodology', 'Microbe', 'Modeling', 'Molecular', 'Nationalities', 'New York', 'Normal Cell', 'Organism', 'Participant', 'Plants', 'Postdoctoral Fellow', 'Prize', 'Process', 'Property', 'Published Comment', 'RNA', 'Reagent', 'Reproducibility', 'Research', 'Research Institute', 'Research Personnel', 'Rotation', 'Schedule', 'Science', 'Scientist', 'Signal Transduction', 'Social Interaction', 'Structure', 'Technology', 'Validation', 'Woman', 'Work', 'base', 'biological systems', 'career', 'computer science', 'computerized tools', 'data exchange', 'data reuse', 'design', 'graduate student', 'host-microbe interactions', 'improved', 'innovation', 'interdisciplinary collaboration', 'interest', 'meetings', 'microbiome', 'multidisciplinary', 'network models', 'posters', 'precision medicine', 'programs', 'senior faculty', 'social', 'symposium', 'trend', 'unpublished works']",NHGRI,COLD SPRING HARBOR LABORATORY,R13,2021,3000
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,10109124,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'data analysis pipeline', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'programmed cell death protein 1', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2021,314000
"Fast and flexible Bayesian phylogenetics via modern machine learning Project Abstract/Summary The SARS-CoV-2 pandemic underlines both our susceptibility to and the toll of a global pathogen outbreak. Phylogenetic analysis of viral genomes provides key insight into disease pathophysiology, spread and po- tential control. However, if these methods are to be used in a viral control strategy they must reliably account for uncertainty and be able to perform inference on 1,000s of genomes in actionable time. Scaling Bayesian phylogenet- ics to meet this need is a grand challenge that is unlikely to be met by optimizing existing algorithms.  We will meet this challenge with a radically new approach: Bayesian variational inference for phylogenet- ics (VIP) using ﬂexible distributions on phylogenetic trees that are ﬁt using gradient-based methods analogous to how one efﬁciently trains massive neural networks. By taking a variational approach we will also be able to integrate phylogenetic analysis into very powerful open-source modeling frameworks such as TensorFlow and PyTorch. This will open up new classes of models, such as neural network models, to integrate data such as sampling location and migration patterns with phylogenetic inference. These ﬂexible models will inform strategies for viral control.  In Aim 1 we will develop the theory necessary for scalable and reliable VIP, including subtree marginal- ization, local gradient updates needed for online algorithms, convergence diagnostics, and parameter support estimates. We will implement these algorithms in our C++ foundation library for VIP. In Aim 2 we will develop a ﬂexible TensorFlow-based modeling platform for phylogenetics, enabling a whole new realm of phylogenetic models based on neural networks to learn phylodynamic heterogeneity with minimal program- ming effort. We will provide efﬁcient gradients to this implementation via our C++ library. In Aim 3 we will use the fact that VIP posteriors are durable and extensible descriptions of the full data posterior to enable dynamic online computation of variational posteriors, including divide-and-conquer Bayesian phylogenetics. This work will enable a cloud-based viral phylogenetics solution to rapidly update our current estimate of the posterior distribution when new data arrive or the model is modiﬁed. 1 Project Narrative We have seen in the current SARS-CoV-2 pandemic, as for all major pathogen outbreaks in the last decade, how phylogenetic (i.e. evolutionary tree) methods are required to use viral genomic information to under- stand large-scale transmission patterns. However, current phylogenetic methods have two major limitations as a tool for viral control: ﬁrst, rigorous Bayesian probabilistic methods cannot scale to 1,000s of genomes, and second, models incorporating phylogenetic trees must be expressed in specialized phylogenetics pack- ages, making modern machine-learning approaches impossible. In this proposal, we develop variational ap- proaches to phylogenetics, which will allow fast inference and procedures to rapidly update inferences when new data arrives, as well as making phylogenetic trees a ﬁrst-class inferential object in major machine-learning packages. 1",Fast and flexible Bayesian phylogenetics via modern machine learning,10266670,R01AI162611,"['Age', 'Algorithms', 'Back', 'Bayesian Method', 'COVID-19 pandemic', 'Code', 'Collection', 'Complex', 'Computational Biology', 'Custom', 'Data', 'Data Set', 'Diagnostic', 'Discipline', 'Disease', 'Disease Outbreaks', 'Epidemic', 'Foundations', 'Functional disorder', 'Genome', 'Graph', 'Heterogeneity', 'Learning', 'Libraries', 'Location', 'Machine Learning', 'Markov chain Monte Carlo methodology', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Nature', 'Neural Network Simulation', 'Pattern', 'Phylogenetic Analysis', 'Predisposition', 'Procedures', 'Public Health', 'Research Personnel', 'Sampling', 'Statistical Models', 'Structural Models', 'Structure', 'Technology', 'TensorFlow', 'Time', 'Training', 'Trees', 'Uncertainty', 'Update', 'Variant', 'Viral', 'Viral Genome', 'Work', 'base', 'cloud based', 'data modeling', 'epidemiologic data', 'flexibility', 'genomic data', 'high dimensionality', 'insight', 'knowledge base', 'mathematical algorithm', 'mathematical methods', 'migration', 'neural network', 'novel strategies', 'open source', 'pathogen', 'prevent', 'scale up', 'social exclusion', 'theories', 'tool', 'transmission process', 'user-friendly', 'viral genomics', 'viral transmission']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,797370
"Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods. 1 This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings –  2 funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating  3 Biology into In Silico Methodologies: Modern Approaches for incorporating biological  4 reasoning and understanding into computational methods. As a “Contemporary Concepts  5 in Toxicology” meeting, this workshop has the full backing, including being financially  6 underwritten, by the Society of Toxicology.  7 Computational modeling is an important tool for assessing the safety and use of  8 chemicals across many industries, including chemical, pharmaceutical, and consumer products.  9 Moreover, in silico methodologies offer academia and regulatory a fast and cheap method of 10 prioritizing its efforts to maintain compliance and safety in the market and environment. 11 This conference is designed to promote the development of actionable insights and 12 methodologies for increasing the biological relevance of in silico solutions. Specifically, this 13 conference will focus on solving the “black box effect”. There are many ways to validate a 14 model’s accuracy and domain – however if the model cannot explain what is happening 15 biologically, its use is severely diminished. This workshop will bring together regulatory, 16 academia, industry, and service providers to discuss current solutions and efforts, as well as 17 ongoing and future research. One goal of this conference will be to develop a roadmap for the 18 incorporation of AOPs (and similar biological reasonings) for computational tools. 19 This workshop has great appeal for multiple stakeholders within toxicology, namely 20 industry, academia, regulators, as well as service providers. The use of machine-learning to 21 replace laboratory toxicological tests is paramount to the future of the industry (3Rs). The use 22 of in silico models are explicitly referenced by NICEATM’s U.S. Strategic Roadmap, as well as 23 TSCA. Moreover, many industries and regulatory entities are taking significant steps away from 24 animal testing. Most recently, the US EPA stated that it will eliminate animal testing by 2035. 25 This workshop will bring together different stakeholders to discuss the current state of 26 AOPs and in silico methodologies, and to work towards a unified approach for their 27 incorporation. The final outcome of the workshop will be a white-paper that not only reviews the 28 current landscape but discusses concretes steps, as outlined in the breakout session, needed 29 for the regulatory acceptance of machine learning technologies – specifically a roadmap for the 30 inclusion of AOPs into computational tools and explanations. This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings – funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating Biology into In Silico Methodologies: Modern Approaches for incorporating biological reasoning and understanding into computational methods. This workshop will bring together different stakeholders to discuss the current state of AOPs and in silico methodologies, and to work towards a unified approach for their incorporation. The final outcome of the workshop will be a white- paper that not only reviews the current landscape but discusses concretes steps, as outlined in the breakout session, needed for the regulatory acceptance of machine learning technologies – specifically a roadmap for the inclusion of AOPs into computational tools and explanations.",Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods.,10144727,R13ES032662,"['Academia', 'Address', 'Adoption', 'Animal Testing', 'Animals', 'Back', 'Biological', 'Biology', 'Budgets', 'Chemicals', 'Chemistry', 'Communities', 'Computer Models', 'Computing Methodologies', 'Decision Making', 'Development', 'Educational workshop', 'Environment', 'Event', 'Funding', 'Future', 'Goals', 'In Vitro', 'Individual', 'Industry', 'Laboratories', 'Laws', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'National Institute of Environmental Health Sciences', 'Nonprofit Organizations', 'Outcome', 'Paper', 'Pathway interactions', 'Pharmacologic Substance', 'Policies', 'Process', 'Publishing', 'Safety', 'Societies', 'System', 'Technology', 'Testing', 'Toxicology', 'United States National Institutes of Health', 'Work', 'adverse outcome', 'cheminformatics', 'computer framework', 'computerized tools', 'consumer product', 'cost', 'design', 'improved', 'in silico', 'in vivo', 'insight', 'meetings', 'predictive modeling', 'research and development', 'service providers', 'symposium', 'tool', 'web site']",NIEHS,"TOXTRACK, LLC",R13,2021,4000
"Clinical Research Education in Genome Science (CREiGS) Project Summary/Abstract  The sensitivity and availability of omic technologies have enabled the genomic, transcriptomic and proteomic characterization of disease phenotypes, at the tissue and even the single cell level. This has allowed development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. Patients of providers who have participated in these educational initiatives also benefit as it allows for more rapid integration of genomic study findings into the clinical care setting. Thus, in response to PAR-19-185, we propose to develop and implement the Clinical Research Education in Genome Science (CREiGS) program that will not only focus on the analysis of genomic data, but also on gene-expression data, the integration of these two data types, as well as introductory theory and application of statistical and machine learning methods. Specifically we propose to accomplish the following specific aims: 1. Develop and successfully implement the online and in-person phases of CREiGS to increase the methodologic ingenuity by which researchers tackle important genomics-related clinical problems. 2. Establish a Diversity Recruitment External Advisory Board to ensure that the most effective strategies are employed to recruit URM doctoral students, postdoctoral fellows, and faculty from academic institutions nationwide into CREiGS. 3. Enhance the dissemination phase of CREiGS by packaging and uploading the asynchronous lectures and the online critical thinking/problem solving assessments with solutions for publicly available, online teaching resources. 4. Implement effective methods to evaluate the efficacy of CREiGS by examining:1) the participants' grasp of the CREiGS core competencies, 2) the clarity and quality of the curriculum, 3) program logistics and operation, and 4) the participants' short-term and long-term success attributed to participation in CREiGS. In summary, we posit that CREiGS will provide participants with a solid foundation in genomics science to answer complex, clinical questions. We believe that CREiGS supports the mission of the NHGRI by providing researchers with rigorous training to “accelerate medical breakthroughs that improve human health.” Project Narrative The sensitivity and availability of omic technologies have allowed for the development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. The overall goal of the Clinical Research Education in Genome Science program is to increase the methodologic ingenuity of students, postdoctoral fellows, and faculty from academic institutions nationwide through a solid foundation in genomics science to answer complex, clinical research questions and improve patient care.",Clinical Research Education in Genome Science (CREiGS),10147746,R25HG011021,"['Area', 'Biomedical Research', 'Cells', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Critical Thinking', 'Data', 'Data Analyses', 'Development', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Gene Expression', 'Genetic', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Hour', 'Human', 'Hybrids', 'Institution', 'Knowledge', 'Logistics', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mission', 'National Human Genome Research Institute', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Play', 'Postdoctoral Fellow', 'Problem Solving', 'Proteomics', 'Provider', 'Recruitment Activity', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Role', 'Single Nucleotide Polymorphism', 'Solid', 'Statistical Methods', 'Students', 'Technology', 'Tissues', 'Training', 'Translational Research', 'Treatment outcome', 'Underrepresented Minority', 'Underserved Population', 'Update', 'cancer therapy', 'clinical care', 'computerized tools', 'data integration', 'data management', 'disease phenotype', 'disorder subtype', 'doctoral student', 'education research', 'efficacy evaluation', 'genetic analysis', 'genome sciences', 'genomic data', 'grasp', 'health disparity', 'improved', 'individual patient', 'innovation', 'lectures', 'machine learning method', 'operation', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'response', 'statistical and machine learning', 'success', 'theories', 'therapy development', 'tool', 'transcriptomics', 'treatment optimization', 'virtual']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R25,2021,162000
"UT Southwestern Center for Translational Medicine Contact PD/PI: Toto, Robert D OVERALL: PROJECT SUMMARY/ABSTRACT The Center for Translational Medicine (CTM) at UT Southwestern is a collaboration among 7 academic institutions, 5 health care systems, 6 teaching hospitals and the North Texas community. Our mission is to improve health in local and global communities through innovation and education. Over the past two funding cycles, our CTSA catalyzed innovation and transformed the culture and landscape of our program Hub. We have trained >1,000 members of the translational workforce, co-led the formation of the Accrual to Clinical Trials CTSA network and established new translational technologies, methods, and processes critical to the translational process at every level. We engaged our local communities early on in the design and conduct of clinical research. We also formed new collaborative research services and education and training programs designed to address the top health challenges of our community and the nation. Through these efforts, the CTM has generated considerable momentum toward advancing translational science propelled by a highly collaborative environment that is hard-wired for Team Science and Community Engagement.  Over the next 5 years, we will optimize the organization of our CTSA Hub for more efficient translation of biomedical discoveries into interventions that will ultimately result in the improved health of both our local populations and, in collaboration with the CTSA Network, the broader U.S. population. We will discover, develop, demonstrate, and disseminate new informatics and artificial intelligence solutions to challenging problems in translation at all levels. In collaboration with Hub partners and relevant national CTSA networks, we propose to develop new methods and processes to further the integration of research into practice at the point of care. Building on our success, we are now poised to achieve the five key objectives of the CTSA Program and the Center for Translational Medicine with the following Specific Aims: Aim 1. Produce a well-trained, highly skilled, diverse Translational Workforce. Aim 2. Inculcate Community Engagement and Team Science. Aim 3. Integrate diverse populations across the lifespan into clinical and translational research. Aim 4. Promote innovation and new scientific Methods and Processes. Aim 5. Develop innovative Informatics solutions to overcome translational roadblocks. Aim 6. Increase Workforce Heterogeneity. Impact: With our highly-integrated dynamic research and training environment in place, our Hub will have a powerful and sustained impact on the field of translational science. We will make a major leap forward in the scope, efficiency, and quality of clinical and translational research for the benefit of our Hub and the national consortium. We will collaborate with the Center for Leading Innovation and Collaboration, the Trial Innovation Network, and the Center for Data to Health to bridge the gap between scientific discovery and improved health. Project Summary/Abstract Page 164 Contact PD/PI: Toto, Robert D O. OVERALL:  PROJECT NARRATIVE Improving the health of our nation requires collaboration among teams of biomedical scientists, health care providers, community members, patients, and policymakers. The goal of this proposal is to engage such teams in a national effort to translate new scientific discoveries into clinical practice to improve health. Project Narrative Page 165",UT Southwestern Center for Translational Medicine,10349035,UL1TR003163,"['Address', 'Adoption', 'Artificial Intelligence', 'Basic Science', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communication', 'Communities', 'Data', 'Data Collection', 'Education', 'Ensure', 'Entrepreneurship', 'Environment', 'Faculty', 'Family', 'Fostering', 'Foundations', 'Funding', 'Gap Junctions', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Incentives', 'Individual', 'Industry', 'Informatics', 'Institution', 'Intervention', 'Leadership', 'Longevity', 'Mentors', 'Methods', 'Mission', 'Outcome', 'Patients', 'Phase', 'Population', 'Population Heterogeneity', 'Process', 'Published Comment', 'Qualitative Methods', 'Reproducibility', 'Research', 'Research Training', 'Resources', 'Rural Community', 'Rural Population', 'Science', 'Scientist', 'Services', 'Special Population', 'Teaching Hospitals', 'Technology', 'Testing', 'Texas', 'Training', 'Training Programs', 'Training Support', 'Training and Education', 'Translating', 'Translational Research', 'Translations', 'Underserved Population', 'Urban Community', 'Urban Population', 'academic program', 'biomedical scientist', 'catalyst', 'clinical practice', 'collaborative environment', 'design', 'ethnic diversity', 'improved', 'informatics training', 'innovation', 'member', 'multimodality', 'novel', 'novel strategies', 'personalized medicine', 'point of care', 'population health', 'pre-clinical', 'programs', 'racial diversity', 'recruit', 'research to practice', 'skills', 'success', 'tool', 'translational medicine', 'user-friendly']",NCATS,UT SOUTHWESTERN MEDICAL CENTER,UL1,2021,8029629
"COPD SUBTYPES AND EARLY PREDICTION USING INTEGRATIVE PROBABILISTIC GRAPHICAL MODELS COPD SUBTYPING AND EARLY PREDICTION USING INTEGRATIVE PROBABILISTIC GRAPHICAL MODELS ABSTRACT One of the main obstacles in developing efficient personalized therapeutic and disease management strategies is that most common diseases are typically defined based on symptoms and clinical measurements, although they are believed to be syndromes, consisting of multiple subtypes with variable etiology. Identifying disease subtypes has thus become very important, but so far it has been met with limited success for most diseases. In asthma, a notable exception, it was the clinical characterization that led to successful subtyping; and this is now incorporated in treatment guidelines. Unsupervised machine learning approaches of single data modalities (e.g., omics, radiographic images) have not produced actionable subtypes due to instability across cohorts. Developing data integrative approaches for multi-scale data, which are becoming available for a number of diseases, is expected to lead to robust subtyping and provide mechanistic insights of disease onset and progression. This proposal focuses on developing new computational methods, based on probabilistic graphical models (PGMs), to address this unmet need; and apply them to investigate three problems of clinical importance in chronic obstructive pulmonary disease (COPD), which is the fourth leading cause of mortality in USA. Our underlying hypothesis is that PGMs can integrate and analyze under the same probabilistic framework heterogeneous biomedical data (omics, chest CT scan, clinical) and identify disease subtypes and their main determinants. The objectives of our proposal is to build a comprehensive computational framework for disease subclassification, identify stable COPD subtypes at the baseline and longitudinally, and build interpretable models of the disease The deliverables of this project are: (1) new integrative computational approaches for clinical subtyping from multi-scale data; (2) new predictors of COPD progression and severity; (3) new discoveries of longitudinally stable COPD subtypes; (4) new predictors of future development of COPD; (5) new omics datasets that will be invaluable to future research in the area (baseline and longitudinal). To ensure the success of the project we follow a team science approach. This multi-PI proposal builds on the ongoing efforts of our group in the area of graphical models and their applications in biomedicine; and the ongoing collaboration of the three PIs that have complementary strengths: Prof. Benos (systems medicine and machine learning), Dr. Hersh (COPD genetics and genomics) and Dr. Sciurba (clinical aspects of COPD). It is powered by the access of the investigators to three major COPD cohorts (COPDGene®, SCCOR, ECLIPSE) that contain multiple parallel deep phenotyping and omics data from thousands of patients and controls. Although in this project we focus on COPD, our methods are generally applicable to any disease, therefore our project will have a positive impact beyond the above deliverables. We believe that due to their robust nature and interpretability, PGMs will soon become the norm for multi-scale biomedical data integration and modeling, when genetic and genomic data collection will become routine prognostic and diagnostic tools in clinical practice. PROJECT NARRATIVE Understanding the etiology of complex diseases and categorizing patients from samples taken from easily accessible tissues (like blood) are two very important aspects that will lead to development of new precision medicine strategies. In this proposal, we plan to develop new computational methods and tools that will allow researchers to identify subphenotypes in any disease. We will apply these methods on three cohorts with thousands of patients with chronic obstructive pulmonary disease (COPD) and our results are expected to help us understand the complexities of this disease and build predictors of future development.",COPD SUBTYPES AND EARLY PREDICTION USING INTEGRATIVE PROBABILISTIC GRAPHICAL MODELS,10206417,R01HL157879,"['Address', 'Algorithms', 'Area', 'Asthma', 'Biology', 'Blood', 'Cause of Death', 'Characteristics', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Disease Management', 'Disease Progression', 'Disease model', 'Enrollment', 'Ensure', 'Etiology', 'Functional Imaging', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Profiling', 'Genes', 'Genetic', 'Genetic Diseases', 'Genomics', 'Graph', 'Health Care Costs', 'Image', 'Incidence', 'Individual', 'Lead', 'Link', 'Machine Learning', 'Measurement', 'Medicine', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Target', 'Multiomic Data', 'Nature', 'Onset of illness', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Pulmonary function tests', 'Pulmonology', 'Research', 'Research Personnel', 'Sampling', 'Science', 'Severities', 'Severity of illness', 'Stable Disease', 'Symptoms', 'Syndrome', 'System', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Visit', 'X-Ray Computed Tomography', 'airway obstruction', 'analytical method', 'base', 'cellular targeting', 'chest computed tomography', 'clinical practice', 'clinical subtypes', 'clinically relevant', 'cohort', 'computer framework', 'computerized tools', 'data integration', 'data modeling', 'disability', 'disease phenotype', 'disorder subtype', 'follow-up', 'genetic variant', 'genomic data', 'imaging genetics', 'improved', 'innovation', 'insight', 'learning algorithm', 'mortality', 'mortality risk', 'multimodal data', 'multimodality', 'multiscale data', 'peripheral blood', 'personalized predictions', 'personalized therapeutic', 'precision medicine', 'predictive modeling', 'prognostic', 'prognostic value', 'pulmonary function', 'success', 'tool', 'treatment guidelines', 'unsupervised learning', 'vector']",NHLBI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,739755
"Developing novel technologies that ensure privacy and security in biomedical data science research Data science holds the promise of enabling new pathways to discovery and can improve the understanding, prevention and treatment of complex disorders such as cancer, diabetes, substance abuse, etc., which are significantly on the rise. The promise of data science can be fully realized only when collected data can be collaboratively shared and analyzed. However, the widespread increases in healthcare data breaches due to inappropriate access as well as the increasing number of novel privacy attacks restrict institutions from sharing data. Indeed, in some cases, the results of the analysis can themselves lead to significant privacy harm. The success of the data commons depends on ensuring the maximal access to data, subject to all of the patient privacy requirements including those mandated by legislation, and all of the constraints of the organization collecting the data itself. While there are existing solutions that can solve parts of the problem, there are significant challenges in truly incorporating these into comprehensive working solutions that are usable by the biomedical research community, and new challenges brought on by modern techniques such as deep learning. The long-term goal of this research is to develop technologies that can holistically enable data sharing while respecting privacy and security considerations and to ensure that they are implemented in existing platforms that have widespread acceptance in the research community. Towards this, the objective of this project is to develop complementary solutions for risk inference, distributed learning, and access control that can enable different modalities of data sharing. The problems studied are general in nature and will evolve depending on research successes and new impediments that arise. The proposed program of research is significant since lack of access to biomedical data can lead to fragmentation of care, resulting in higher economic and social costs, and is a significant impediment to biomedical research. The project will result in open-source, freely available software tools that will be integrated into widely used data collection, cohort identification, and distributed analytics platforms. There are several ongoing collaborations that will serve as initial pilot customers to provide use cases, identify the requirements, evaluate results, and in general validate the developed solutions. Project Narrative Statement of Relevance to Public Health Being able to ensure privacy and security while enabling data sharing and analysis is critical to pave the way forward for public health research and improve our understanding of diseases. The proposed work will address the challenges that impede the use of data across all of the different modalities of data sharing. The integration into existing platforms will ensure that the developed models, tools, and solutions directly impact the research community and improve public health interventions.",Developing novel technologies that ensure privacy and security in biomedical data science research,10077318,R35GM134927,"['Address', 'Biomedical Research', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Commons', 'Data Science', 'Diabetes Mellitus', 'Disease', 'Economics', 'Ensure', 'Goals', 'Healthcare', 'Institution', 'Lead', 'Learning', 'Malignant Neoplasms', 'Modality', 'Modeling', 'Modernization', 'Nature', 'Pathway interactions', 'Prevention', 'Privacy', 'Public Health', 'Research', 'Risk', 'Security', 'Software Tools', 'Statutes and Laws', 'Substance abuse problem', 'Techniques', 'Technology', 'Work', 'biomedical data science', 'care fragmentation', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'new technology', 'novel', 'open source', 'patient privacy', 'programs', 'public health intervention', 'public health research', 'social', 'success', 'tool']",NIGMS,RUTGERS THE STATE UNIV OF NJ NEWARK,R35,2021,383279
"Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises Project summary: Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems. This leads to at least 16 million cases of acute gastroenteritis directly linked to pollution at community water systems, with tens of millions more directly impacted by chemical and organic pollutants. Impacts are further exacerbated in locations dealing with water scarcity, in under-served populations, and within other vulnerable populations already suffering from health disparities. Many of these water problems are the direct result of managerial negligence, inconsistent monitoring, and a lack of the ability to anticipate where problems may arise next. While the reasons for drinking water problems are complex, if we could anticipate where health-based drinking water problems were to occur in the future, it could have an immediate and positive impact on tens of millions of Americans annually. Interestingly, extensive data about water quality and the performance of municipal water systems already exists in large, disparate databases. These databases are largely ignored and, when used, are typically used only anecdotally and retroactively. Preliminary evidence suggests that these existing databases, which contain histories of administrative violations and sub-threshold water-quality results, can be mined to accurately predict future drinking water crises. The Superior Statistical Research R&D team is an internationally recognized group of water experts with cross-cutting expertise in statistics/data analysis/modelling/computing, water-quality monitoring of biological and chemical contaminants, and the ability to clearly and compellingly translate water-quality and health information to actionable steps for individuals, organizations and communities. In this Phase I project, we will show that it is possible to predict water-related, health-based problem areas utilizing already collected, historical data on water quality and municipal water system performance. We will begin by harmonizing the disparate water quality and municipal water system performance in two different states (Michigan and Iowa). We will then utilize machine-learning techniques to predict health-based violation histories and will evaluate our methods by comparing predicted violations to actual health-based violations in the previous 5 years. Finally, we will identify at least 10 municipalities determined by our algorithm to be at the highest risk for future health- based water problems and will do systematic sampling to confirm our model-based predictions. We will then demonstrate how making these predictions can be leveraged to profitability by exploring how our model-based predictions can be presented to customers in an economical, usable form. Proof of our concept and profitability models in two states (Phase I) will set us up for widespread (multi-state) database harmonization and improvement of the proposed machine-learning/modelling effort in Phase II. With multi-state harmonized datasets, identification of key data gaps in particular states/areas, and proven financial models, our technology will ultimately lead to dramatic reductions in the number of health-based drinking water problems annually. Project Narrative Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems, but predicting where and when these health-based drinking water problems will occur remains a large and complex obstacle. Current approaches focus on a reactive approach to health-based water-quality violations in community water systems, rather than a proactive one that seeks to anticipate where problems will occur in the future. The overall goal of this project is to leverage large and disparate historical datasets of water quality to accurately predict locations of future health-based water-quality violations, validate the predictions, and commercialize our proprietary predictions as a practical and cost-saving approach to anticipating and heading off future health-based water problems.",Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises,10253600,R43ES033134,"['Acute', 'Address', 'Algorithms', 'American', 'Area', 'Biological Monitoring', 'Chemicals', 'Cities', 'Coal', 'Communities', 'Community Surveys', 'Complex', 'Cost Savings', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ensure', 'Exposure to', 'Filtration', 'Focus Groups', 'Future', 'Gastroenteritis', 'Goals', 'Government', 'Health', 'Human', 'Individual', 'International', 'Iowa', 'Lead', 'Lead levels', 'Link', 'Location', 'Machine Learning', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'Municipalities', 'Negligence', 'Pathway interactions', 'Performance', 'Persons', 'Phase', 'Pollution', 'Price', 'Provider', 'Public Health', 'ROC Curve', 'Recording of previous events', 'Records', 'Research', 'Safety', 'Sampling', 'Serinus', 'Site', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Trust', 'Underserved Population', 'Vulnerable Populations', 'Water', 'advocacy organizations', 'base', 'commercialization', 'data harmonization', 'data integration', 'drinking water', 'economic impact', 'health disparity', 'high risk', 'improved', 'inner city', 'innovation', 'large scale data', 'member', 'pollutant', 'predictive modeling', 'research and development', 'rural area', 'statistics', 'water quality', 'water sampling', 'water testing', 'willingness to pay']",NIEHS,"SUPERIOR STATISTICAL RESEARCH, LLC",R43,2021,256579
"Methods for Evolutionary Genomics Analysis Summary/Abstract Continuing advances in nucleotide sequencing have resulted in the assembly of datasets containing large numbers of species, genes, and genomic segments. Phylogenomic analyses of these data are essential to progress in understanding evolutionary patterns across the tree of life, and are finding increasing numbers of applications in practical analyses that require understanding of how patterns change over time. The sheer size of phylogenomic datasets limits the practical utility of available methods due to excessive time and memory requirements. We have developed many high impact methods and tools for comparative analysis of molecular sequences, a tradition we propose to continue through this MIRA project by developing innovative methods that address new challenges in phylogenomics. We will focus on pattern-based approaches of machine learning with sparsity constraint (SL) applied to phylogenomics, as a complement to traditional model-based methods in molecular evolution and phylogenetics. In the proposed SL in Phylogenomics (SLiP) framework, we will build models that best explain the biological trait or evolutionary hypothesis of interest, with genomic loci, such as genes, proteins, and genomic segments, serving as model parameters. Preliminary results from two example applications establish the premise and promise of a general SLiP framework. In one, SLiP successfully detected loci whose inclusion in a phylogenomic dataset overtakes a consistent and contrasting signal from hundreds of other loci when inferring phylogenetic relationships. In the other example, SLiP revealed loci and biological functional categories that harbor convergent sequence evolutionary patterns associated with the emergence of the same trait in distinct evolutionary lineages. In all of these analyses, SLiP required only a small fraction of the computational time and memory demanded by traditional methods, and it enabled better evolutionary contrasts with fewer assumptions. Consequently, the successful development of SLiP will improve the feasibility, rigor, and reproducibility of large-scale data analysis. It will also democratize big data analytics via shortened analysis time and a relatively small memory footprint, and encourage the development of a new class of methods for phylogenomic analysis. This framework will be accessed from a free library of SLiP functions, which will be directly useable via command line and available in a graphical interface through integration with the MEGA software. Narrative The long-term goal of my research program is to develop methods and tools for comparative analysis of molecular sequences. In this project, we will develop a new class of phylogenomic methods based on sparse machine learning and benchmark their absolute and relative performance. New techniques and their software implementation will greatly facilitate data analyses that are vital for evolutionary and functional genomics.",Methods for Evolutionary Genomics Analysis,10086181,R35GM139540,"['Address', 'Benchmarking', 'Big Data Methods', 'Biological', 'Categories', 'Complement', 'Computer software', 'Data Analyses', 'Data Set', 'Development', 'Gene Proteins', 'Genes', 'Genomic Segment', 'Genomics', 'Goals', 'Libraries', 'Life', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular Analysis', 'Molecular Evolution', 'Nucleotides', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Reproducibility', 'Research', 'Signal Transduction', 'Techniques', 'Time', 'Trees', 'base', 'comparative', 'functional genomics', 'genomic locus', 'graphical user interface', 'improved', 'innovation', 'interest', 'large scale data', 'programs', 'tool', 'trait']",NIGMS,TEMPLE UNIV OF THE COMMONWEALTH,R35,2021,396250
"Development of a Universal Influenza Vaccine ABSTRACT Influenza virus (flu) ranks highest in disease burden of all infectious diseases as measured in disability-adjusted life years. Seasonal epidemics cause 200,000-500,000 worldwide deaths annually. The total economic burden of seasonal flu is estimated to range from approximately $26B to $87B each year in the US in terms of direct medical expenses and lost work and productivity. Additionally, at least six known flu pandemics have become global human catastrophes, most notably the Spanish Flu pandemic of 1918, which killed 3-5% of the world’s population. Any reduction in the infection rate, transmission, and severity of flu infection would greatly reduce our healthcare expenditures and improve the quality of life for millions of people every year. The current vaccines are formulated annually based on predictions of which circulating flu strains may be prevalent in a given season. The effectiveness of these vaccines varies from year to year based on the circulation of unexpected antigenic variants and other factors. Vaccine design is complicated the by the multiplicity of flu strains, each with rapidly-evolving dominant antigen epitopes (“decoy” epitopes) that largely stimulate strain- restricted immunity. One strategy for rational antigen design, termed Immune Refocusing Technology (IRT), involves introducing mutations that reduce the immunogenicity of these decoy epitopes thus shifting the immune response to target more widely-conserved subdominant epitopes. BMI has previously applied this IRT approach with some notable successes to other viral antigens (e.g. HRV and the RSV F protein), and we now focus on the major flu surface antigen glycoprotein HA using H1, H3, and B vaccine strains as parental antigens. The anticipated effort to design a suitably modified antigen would ordinarily involve a protracted process of trial-and-error testing of many potential candidates. However, we have recently developed the ANATOPE automated B cell epitope prediction software package with algorithm parameters tuned using methods in artificial intelligence. Our algorithm identifies epitopes with a significantly higher success rate than previously available prediction programs. This breakthrough allows us to assign immunogenicity “strength” scores to particular antigen surface patches and will further guide and accelerate the design of mutant antigens that refocus the immune response to cross-strain conserved epitopes. In this application, we propose to engineer and test the immunogenicity of rationally-designed HA antigens containing mutations that both 1) dampen the immunogenicity of dominant strain-restricted decoy epitopes and 2) enhance the immunogenicity of conserved subdominant epitopes associated with broadly neutralizing antibodies. Follow- up studies will assess the rationally-designed antigens in a ferret challenge study and prepare the approach for translation into humans as a universal vaccine that does not require annual reformulation. NARRATIVE Influenza is among the most important pathogens in terms of negative impact upon human health and healthcare expense. The current seasonal vaccines have a mixed record in terms of preventing illness and death. Development of improved vaccines is complicated by the rapid antigenic evolution of circulating viruses and the strain-restricted protections developed by our immune systems. In this proposal, we combine two novel technologies to develop universal influenza vaccines. The first, the Immune Refocusing Technology, is used to alter antibody binding sites, epitopes, such that the immune system can produce a broadened, cross-strain protective response. The second, a computational B cell epitope analysis program called ANATOPE, is used to guide the rational design of antigenic mutants bearing amino acid substitutions that stimulate improved immune responses. This project will focus on improving the breadth of protection stimulated by the three major components of the seasonal vaccine to reduce the need for annual reformulations. If successful, follow-up studies will include additional analysis in alternative animal models, a more comprehensive analysis of T cell immune responses, and preparation for advancement into IND-enabling studies.",Development of a Universal Influenza Vaccine,10211103,R43AI152652,"['Algorithms', 'Amino Acid Substitution', 'Animal Model', 'Animal Testing Alternatives', 'Antibodies', 'Antibody Binding Sites', 'Antibody Formation', 'Antibody Response', 'Antigens', 'Antiviral Agents', 'Artificial Intelligence', 'B-Lymphocyte Epitopes', 'Baculoviruses', 'Binding Sites', 'Biological Assay', 'Blood Circulation', 'Body mass index', 'California', 'Cells', 'Cellular Immunity', 'Cessation of life', 'Communicable Diseases', 'Computational algorithm', 'Computer Analysis', 'Computer software', 'Cryoelectron Microscopy', 'Development', 'Distant', 'Economic Burden', 'Engineering', 'Epidemic', 'Epitopes', 'Evolution', 'Ferrets', 'Follow-Up Studies', 'Future', 'Glycoproteins', 'Goals', 'Ha antigen', 'Health', 'Health Expenditures', 'Healthcare', 'Hemagglutination', 'Hemagglutinin', 'Hong Kong', 'Human', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Immunization', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Influenza A Virus, H3N2 Subtype', 'Insecta', 'Manuals', 'Measures', 'Medical', 'Methods', 'Modeling', 'Modification', 'Mus', 'Mutation', 'Pattern Recognition', 'Population', 'Preparation', 'Process', 'Productivity', 'Proteins', 'Quality of life', 'Recombinants', 'Seasons', 'Sequence Analysis', 'Series', 'Serology test', 'Severities', 'Singapore', 'Site', 'Spanish flu', 'Statistical Data Interpretation', 'Structure', 'Surface', 'Surface Antigens', 'Switzerland', 'T-Lymphocyte', 'Technology', 'Testing', 'Texas', 'Translations', 'Vaccine Design', 'Vaccines', 'Validation', 'Variant', 'Viral Antibodies', 'Viral Antigens', 'Viral Physiology', 'Virus', 'Work', 'antiviral immunity', 'base', 'burden of illness', 'cross reactivity', 'design', 'disability-adjusted life years', 'flu', 'immunogenicity', 'improved', 'in silico', 'indexing', 'infection rate', 'influenza infection', 'influenza virus strain', 'influenza virus vaccine', 'influenzavirus', 'mutant', 'neutralizing antibody', 'new technology', 'novel', 'pandemic influenza', 'pathogen', 'prevent', 'programs', 'response', 'seasonal influenza', 'success', 'transmission process', 'universal influenza vaccine', 'universal vaccine', 'vaccine effectiveness']",NIAID,"BIOLOGICAL MIMETICS, INC.",R43,2021,299218
"Experimentally guided modeling and simulation for cholera dynamics Project Summary/Abstract Coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), remains a global pandemic at present. Quantitative research is urgently needed to clarify the impacts of the current vaccination campaign on the pandemic evolution and economic growth, and to guide future policy development. The overall objective of this proposal is to establish a new computational modeling framework for an investigation of the COVID-19 vaccination campaign in the US, and to incorporate real data to assess the impacts of COVID-19 vaccination on public health and the economy. To achieve this objective, the team will pursue three specific aims: (1) Modeling the transmission and spread of COVID-19 under the impact of vaccination; (2) Modeling the economic impact of COVID-19 vaccination; (3) Conducting a case study for the Chattanooga region in the state of Tennessee. The proposed research is significant because it will incorporate detailed characteristics and potential limitations of the current vaccination campaign (such as the vaccine efficacy, phased allocation schemes, public resistance to vaccination, and vaccine breakthrough due to new variants of SARS- CoV-2) into a sophisticated modeling framework, which will enable us to make more accurate forecasts on the progression and long-term evolution of the pandemic. As such, the project is expected to advance the current understanding of COVID-19 transmission and to quantify the interaction between epidemic spreading, economic growth, and disease prevention and intervention under the impact of COVID-19 vaccination, all of which are important for the control and management of the pandemic. The approach is innovative in the development of a computational framework that integrates novel mechanistic and machine learning models and that connects the epidemic and economic aspects of COVID-19. The innovation of this project is also reflected by the integration of sophisticated computational modeling, rigorous mathematical analysis, intensive numerical simulation, and detailed data validation. The project represents an interdisciplinary collaboration among an applied and computational mathematician with long-term interest in infectious disease modeling (Wang), an epidemiologist with extensive working experiences at CDC and a current member of the regional COVID-19 task force (Heath), a business and management professor with a background in public heath (Mullen), and a statistician with expertise in machine learning and biomedical data analytics (Ma). The success of this project will not only build a solid knowledge base for the complex transmission dynamics of SARS-CoV-2 and the health and economic impacts of COVID-19 vaccination, but also provide important guidelines for the government agencies and public health administrations in pandemic management and policy development. Project Narrative The proposed project is relevant to public health because a deep understanding of the COVID-19 vaccination campaign and its health and economic impacts will help to inform the pandemic management and improve the current practice in disease prevention and intervention. The mathematical and machine learning models developed in this project will improve such understanding and make new knowledge discovery. This research effort aligns with part of NIH's mission to reduce public health burdens of infectious diseases.",Experimentally guided modeling and simulation for cholera dynamics,10376956,R15GM131315,"['2019-nCoV', 'Address', 'Advisory Committees', 'Attention', 'Businesses', 'COVID-19', 'COVID-19 vaccination', 'Case Study', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Cholera', 'Clinical Research', 'Collaborations', 'Communicable Diseases', 'Complement', 'Complex', 'Computer Models', 'Computer Simulation', 'Country', 'County', 'Coupled', 'Data', 'Data Analytics', 'Data Set', 'Development', 'Differential Equation', 'Economic Factors', 'Economic Models', 'Economics', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evolution', 'Foundations', 'Future', 'Goals', 'Government Agencies', 'Growth', 'Guidelines', 'Health', 'Investigation', 'Joints', 'Knowledge Discovery', 'Machine Learning', 'Mathematics', 'Mission', 'Modeling', 'Persons', 'Phase', 'Policy Developments', 'Preventive Intervention', 'Public Health', 'Public Health Administration', 'Research', 'Resistance', 'Route', 'SARS-CoV-2 transmission', 'SARS-CoV-2 variant', 'Scheme', 'Schools', 'Science', 'Solid', 'Techniques', 'Tennessee', 'Theoretical Studies', 'Unemployment', 'United States National Institutes of Health', 'Vaccination', 'Vaccines', 'Validation', 'computer framework', 'disorder prevention', 'dynamic system', 'economic impact', 'economic indicator', 'experience', 'experimental study', 'health economics', 'improved', 'infectious disease model', 'innovation', 'interdisciplinary collaboration', 'interest', 'knowledge base', 'mathematical analysis', 'mathematical learning', 'mathematical model', 'member', 'models and simulation', 'novel', 'pandemic disease', 'professor', 'programs', 'simulation', 'success', 'transmission process', 'vaccine efficacy']",NIGMS,UNIVERSITY OF TENNESSEE CHATTANOOGA,R15,2021,122580
"Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support,10393815,R01GM109718,"['Communicable Diseases', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Economic Burden', 'Economics', 'Epidemic', 'Geography', 'Growth', 'Health', 'Health Personnel', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Methodology', 'Methods', 'Modeling', 'Policy Maker', 'Population', 'Privatization', 'Public Health', 'Resource Allocation', 'Resources', 'Risk', 'Science', 'Source', 'System', 'Techniques', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Work', 'base', 'data mining', 'health care delivery', 'improved', 'novel', 'provider networks', 'statistics', 'undergraduate student']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,11253
"Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease ABSTRACT Rapid progress in biomedical informatics has generated massive high-dimensional data sets (“big data”), ranging from clinical information and medical imaging to genomic sequence data. The scale and complexity of these data sets hold great promise, yet present substantial challenges. To fully exploit the potential informativeness of big data, there is an urgent need to find effective ways to integrate diverse data from different levels of informatics technologies. Existing approaches and methods for data integration to date have several important limitations. In this project, we propose novel statistical methods and strategies to integrate neuroimaging, multi-omics, and clinical/behavioral data sets. To increase power for association analysis compared to existing methods, we propose a novel multi-phenotype multi-variant association method that can evaluate the cumulative effect of common and rare variants in genes or regions of interest, incorporate prior biological knowledge on the multiple phenotype structure, identify associated phenotypes among multiple phenotypes, and be computationally efficient for high-dimensional phenotypes. To improve the prediction of clinical outcomes, we propose a novel machine learning strategy that can integrate multimodal neuroimaging and multi-omics data into a mathematical model and can incorporate prior biological knowledge to identify genomic interactions associated with clinical outcomes. The ongoing Alzheimer's Disease Neuroimaging Initiative (ADNI) and Indiana Memory and Aging Study (IMAS) projects as a test bed provide a unique opportunity to evaluate/validate the proposed methods. Specific Aims: Aim 1: to develop powerful statistical methods for multivariate tests of associations between multiple phenotypes and a single genetic variant or set of variants (common and rare) in regions of interest, and to develop methods for mediation analysis to integrate neuroimaging, genetic, and clinical data to test for direct and indirect genetic effects mediated through neuroimaging phenotypes on clinical outcomes; Aim 2: to develop a novel multivariate model that combines multi-omics and neuroimaging data using a machine learning strategy to predict individuals with disease or those at high-risk for developing disease, and to develop a novel multivariate model incorporating prior biological knowledge to identify genomic interactions associated with clinical outcomes; Aim 3: to evaluate and validate the proposed methods using real data from the ADNI and IMAS cohorts; and Aim 4: to disseminate and support publicly available user-friendly software that efficiently implements the proposed methods. RELEVANCE TO PUBLIC HEALTH: Alzheimer's disease (AD) as an exemplar is an increasingly common progressive neurodegenerative condition with no validated disease modifying treatment. The proposed multivariate methods are likely to help identify novel diagnostic biomarkers and therapeutic targets for AD. Identifying new susceptibility loci/biomarkers for AD has important implications for gaining greater insight into the molecular mechanisms underlying AD. NARRATIVE In this project, we propose novel statistical methods and strategies to integrate high-dimensional neuroimaging, multi-omics, and clinical/behavioral data sets, which aim to increase detection power for association analysis and improve the prediction of clinical outcomes. The development of an advanced integrative analysis platform will provide more comprehensive and integrated approaches to answering complex biological questions. The proposed multivariate analysis methods have a high potential impact on and important implications for gaining greater insight into the molecular mechanisms underlying complex diseases, as well as helping the development of earlier diagnostic tests and novel therapeutic targets.","Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease",10139101,R01LM012535,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer’s disease biomarker', 'Beds', 'Behavioral', 'Big Data', 'Biological', 'Brain', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Complex', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Discipline', 'Disease', 'Disease Progression', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Genomics', 'Genotype', 'Health', 'Heterogeneity', 'Indiana', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mediating', 'Mediation', 'Medical Imaging', 'Memory', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Multiomic Data', 'Multivariate Analysis', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Phenotype', 'Positron-Emission Tomography', 'Proteomics', 'Public Health', 'Science', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Technology', 'Testing', 'Time', 'Validation', 'Variant', 'base', 'biomedical informatics', 'cohort', 'data integration', 'diagnostic biomarker', 'disease classification', 'diverse data', 'endophenotype', 'epigenomics', 'genetic association', 'genetic variant', 'high dimensionality', 'high risk', 'improved', 'insight', 'interest', 'learning strategy', 'mathematical model', 'metabolomics', 'multidimensional data', 'multimodality', 'multiple omics', 'neuroimaging', 'new therapeutic target', 'novel', 'novel diagnostics', 'predict clinical outcome', 'rare variant', 'risk variant', 'therapeutic target', 'transcriptomics', 'user friendly software']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2021,341300
