text,title,id,terms,administration,organization,year,cost,funding
"Development of an artificial intelligence-driven, imaging-based platform for pretreatment identification of extranodal extension in head and neck cancer Project Summary. The goal of this project is to develop, optimize, and evaluate an artificial intelligence (AI)- driven, medical imaging platform that utilizes computed tomography (CT) imaging to identify the presence of extranodal extension (ENE) in head and neck squamous cell carcinoma (HNSCC). HNSCC is a debilitating disease with significant patient-related morbidity related to the disease itself and its management, which is complex and consists of a combination of surgery, radiation, and chemotherapy. A key factor in determining proper HNSCC management is the presence of ENE, which occurs when tumor infiltrates through the capsule of an involved lymph node into the surrounding tissue. ENE is both an important prognostic factor and an indication for adjuvant treatment escalation with the addition of chemotherapy to radiation following surgery. This “trimodality therapy” is problematic, as it is associated with increased treatment-related morbidity and healthcare costs, but no improvement in disease control compared to upfront chemoradiation alone. The challenge is that ENE can only be definitively diagnosed pathologically after surgery, and pretreatment radiographic ENE identification has proven unreliable for even expert diagnosticians, leading to high rates of trimodality therapy and suboptimal treatment outcomes. In HNSCC management there is a critical need for improved pretreatment ENE identification to 1) select appropriate patients for surgery to avoid the excess morbidity and costs of trimodality therapy, 2) risk-stratify patients optimally, and 3) select appropriate patients for treatment de-escalation or intensification clinical trials. In recent years, Deep learning, a subtype of machine learning, under the umbrella of AI, has generated breakthroughs in computerized medical image analysis, at times outperforming human experts and discovering patterns hidden to the naked eye. While AI is poised to transform the fields of cancer imaging and personalized cancer care, there remain significant barriers to clinical implementation. The hypothesis of this project is that AI can be used to successfully identify HNSCC ENE on pretreatment imaging in retrospective and prospective patient cohorts and to develop a platform for lymph node auto-segmentation that will promote clinical utility of the platform. This hypothesis will be tested by rigorous optimization and evaluation of a deep learning ENE identification platform. Specifically, the platform will be validated for accuracy, sensitivity, specificity, and discriminatory performance on two heterogeneous retrospective datasets and two prospective cohorts derived from institutional and national Phase II clinical trials for HNSCC patients. The platform will then be directly compared with head and neck radiologists to determine if radiologist performance can be augmented with AI. In parallel, AI will be utilized to develop an auto-segmentation platform for tumor and lymph nodes, which will 1) improve the platform's clinical impact and 2) provide a valuable tool for treatment planning and future imaging-based research for HNSCC patients. 1 Project Narrative Identification of extranodal extension (ENE) for head and neck cancer in the pretreatment setting would be extremely useful in selecting the optimal treatment strategy for patients. Currently, ENE can only be definitively diagnosed pathologically after surgery, and pretreatment radiographic ENE prediction has proven unreliable for expert diagnosticians. This project uses artificial intelligence to identify ENE pretreatment on Computed Tomography, with the goal of developing a clinically usable tool to help patients with newly diagnosed head and neck cancers and their physicians choose the most effective treatment strategy that minimizes the risk of side effects.","Development of an artificial intelligence-driven, imaging-based platform for pretreatment identification of extranodal extension in head and neck cancer",10105483,"['Adjuvant', 'Algorithms', 'Artificial Intelligence', 'Biopsy', 'Clinic', 'Clinical', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Enrollment', 'Evaluation', 'Extranodal', 'Eye', 'Foundations', 'Future', 'Geography', 'Goals', 'Head', 'Head and Neck Cancer', 'Head and Neck Squamous Cell Carcinoma', 'Head and neck structure', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Institution', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Medical Imaging', 'Morbidity - disease rate', 'Neck Dissection', 'Newly Diagnosed', 'Operative Surgical Procedures', 'Output', 'Pathologic', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phase II Clinical Trials', 'Physicians', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Prognostic Factor', 'Prospective cohort', 'Radiation', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Scientist', 'Sensitivity and Specificity', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'cancer imaging', 'capsule', 'chemoradiation', 'chemotherapy', 'clinical implementation', 'cohort', 'computerized', 'cost', 'deep learning', 'design', 'disorder control', 'effective therapy', 'heuristics', 'imaging platform', 'improved', 'insight', 'interest', 'lymph nodes', 'neural network', 'neural network architecture', 'novel', 'optimal treatments', 'patient stratification', 'personalized cancer care', 'phase II trial', 'prediction algorithm', 'prospective', 'prospective test', 'radiologist', 'radiomics', 'risk minimization', 'side effect', 'success', 'therapy development', 'tool', 'treatment planning', 'treatment strategy', 'tumor']",NIDCR,BRIGHAM AND WOMEN'S HOSPITAL,2021,168240,327644200
"Deep learning of drug sensitivity and genetic dependency of pediatric cancer cells Summary/Abstract The development of novel therapies for pediatric cancers, the second leading cause of death in children, is challenging due to the lack of comprehensive pharmacogenomics resources, unlike the well-established ones in adult cancers. However, breakthroughs in deep learning methods allow learning of intricate pharmacogenomics patterns with unprecedented performance. With a uniquely cross-disciplinary background, the candidate for this proposed K99/R00 has already, as a postdoctoral fellow, (i) developed and published several deep learning models that accurately predicted adult cancer cells’ drug sensitivity and genetic dependency using high- throughput genomics profiles, and (ii) demonstrated the feasibility of transferring the model to predict tumors by a ‘transfer learning’ design. The candidate will extend this research to study pediatric cancers and test the central hypothesis that deep learning extracts genomics signatures to predict the responses of pediatric cancer cells to chemical and genetic perturbations. The proposed study will develop novel deep learning models for predicting drug sensitivity and/or genetic dependency for (Aim 1) currently un-screened pediatric cancer cell lines by learning from screens of adult cells, and (Aim 2) pediatric tumors by learning from adult and/or pediatric cells. Prediction results will be validated by in vitro experiments and data collected from patient-derived xenografts. The proposed study is the first attempt to employ modern computational methods to advance pharmacogenomics studies of pediatric cancer, which would be difficult and costly to pursue via biological assays. Findings will shed light on the optimal drugs and novel therapeutic targets for pediatric malignancies, leading to an optimal and efficient design of preclinical tests. The candidate has a remarkable track record of bioinformatics studies of adult cancer genomics. The focus of this K99 training plan is to develop in-depth understanding of pediatric cancer and preclinical treatment models, and strengthen multifaceted components needed for a successful research career in cancer bioinformatics. The primary mentor, Dr. Peter Houghton, is a renowned leader in pediatric cancer research and preclinical drug testing programs. The candidate also has assembled an outstanding mentor team: Dr. Yidong Chen (co-mentor), a cancer genomics expert and pioneer in bioinformatics analysis of high-throughput technologies; Dr. Jinghui Zhang (collaborator), a computational biologist and leader in integrative genomics studies of major pediatric cancer genome consortiums; Dr. Yufei Huang (collaborator), an expert in state-of-the-art deep learning methods; and two highly knowledgeable consultants with relevant expertise. With this team’s guidance and structured training activities in an ideal training environment, the candidate will strengthen his skills in grant writing and lab management, teaching and mentoring, and broad connections. Overall, the K99/R00 award will be an indispensable support for a timely transition of the candidate to a successful career as a multifaceted, cross-disciplinary investigator in cancer bioinformatics. Narrative Pediatric cancer is the second leading cause of death in children, and genetic studies to inform new drug therapies have been challenging. The proposal will utilize deep learning bioinformatics methods to transfer well-established pharmacogenomics knowledge for adult cancers to the study of pediatric cancers. The findings will facilitate the optimal usage of existing drugs and the development of novel therapies for pediatric cancer, and will facilitate the candidate’s transition to an independent research career as an expert in this area.",Deep learning of drug sensitivity and genetic dependency of pediatric cancer cells,10112859,"['Address', 'Adult', 'Antineoplastic Agents', 'Architecture', 'Area', 'Award', 'Bioinformatics', 'Biological Assay', 'Cancer cell line', 'Cause of Death', 'Cells', 'Characteristics', 'Child', 'Childhood', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Computer Models', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Educational process of instructing', 'Environment', 'Future', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic study', 'Genomics', 'Grant', 'Heterogeneity', 'In Vitro', 'Intelligence', 'Investigation', 'Knowledge', 'Learning', 'Light', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Molecular Profiling', 'Mutation', 'Patients', 'Pattern', 'Pediatric Neoplasm', 'Performance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacotherapy', 'Phase', 'Postdoctoral Fellow', 'Preclinical Testing', 'Psychological Transfer', 'Publishing', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Sampling', 'Scheme', 'Screening for cancer', 'Seasons', 'Structure', 'Testing', 'Time', 'Training', 'Training Activity', 'Translations', 'Writing', 'Xenograft procedure', 'anticancer research', 'base', 'cancer cell', 'cancer genome', 'cancer genomics', 'career', 'chemical genetics', 'clinically relevant', 'cost', 'data resource', 'deep learning', 'design', 'drug development', 'drug discovery', 'drug sensitivity', 'drug testing', 'experimental study', 'genetic signature', 'genome-wide', 'genomic profiles', 'genomic signature', 'high dimensionality', 'high throughput analysis', 'high throughput technology', 'in vivo', 'innovation', 'insight', 'knockout gene', 'learning strategy', 'new therapeutic target', 'novel', 'novel therapeutics', 'pre-clinical', 'predicting response', 'predictive modeling', 'programs', 'resistance mechanism', 'response', 'skills', 'small molecule', 'tumor', 'tumor heterogeneity']",NCI,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,2021,105802,82645678
"Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT) ABSTRACT: The intersection of healthcare and biomedical research is at an inflection point with the convergence of the digital revolution, advances in imaging, nanotechnology, big data science, and precision or personalized medicine. There is a wealth of meaningful, but complex information that could be extracted from imaging data but is not optimally utilized for patient care. Cancer care exemplifies the current challenges which include early detection, accurate distinction of pre- neoplastic and neoplastic lesions, prediction of tumor aggressiveness, determining infiltrative tumor margins during surgical treatment, tracking tumor evolution/ metastasis pattern, recurrence, and potential acquired resistance to treatments over time. Major strides have been made in the personalization of cancer therapies such as immunotherapy, but the availability of specific, relevant, and timely medical data and information is of critical importance to realizing the full potential of precision medicine. Nowhere is this more acutely evident than during interventions in the operating and procedure rooms. Novel methods of image guidance, data integration, information extraction, and knowledge transfer are needed to enable clinicians to fully leverage the information available, especially before, during and after invasive procedures. We are excited to re-submit a proposal for a new P41 biomedical resource center (BTRC) called Advanced Technologies for NCIGT(AT-NCIGT) with 3 TRDs, 10 new collaborative and 10 new service projects, all of which aim to investigate develop and disseminate new technologies for image guided therapy (IGT). The 3 components are Imaging Cancer Heterogeneity for IGT, Deep Learning for IGT and Intraoperative devices for IGT. These new technologies alone and in combinations will allow for greater understanding of disease state, treatment guidance, integration/navigation and in-vivo monitoring of tissue responses and improve the precision of invasive procedures. Thus the overall goal of this proposal is to investigate, develop and disseminate novel technologies for extracting new tissue characteristics (technology research and development core TRD 1: Imaging cancer heterogeneity; analyze them and make them available through state-of-the-art algorithmic and data curation approaches (Deep Learning TRD 2); and enable precise tissue sampling surgical navigation and in-vivo tissue response through the results of novel Intraoperative devices (Intraoperative devices for IGT: TRD 3). In order to effectively disseminate all this new knowledge we have 10 new collaborative and 10 new service projects and will share these novel tools through our established mechanisms, from current BTRC- National Center for Image Guided Therapy (NCIGT), which continues to be dedicated to the innovating for IGT into interventional radiology, surgery, radiation oncology, and procedure-based medicine. Project Narrative The Advanced Technologies-National Center for Image guided Therapy (AT-NCIGT) is a research and technology center with the mission of advancing patient care, by developing novel innovative tools for image guided Therapy (IGT). The three technologies encompass Imaging Cancer Heterogeneity, Deep learning and Intraoperative devices for image guided therapy which will be investigated both individually and in cross TR &D combinations. We will disseminate all technologies through a national network of collaborators, making these discoveries available to the larger medical community.",Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT),10090279,"['3-Dimensional', 'Acute', 'Algorithms', 'Architecture', 'Atlas of Cancer Mortality in the United States', 'Augmented Reality', 'Biomedical Research', 'Biopsy Specimen', 'Blood', 'Brain', 'Brain Neoplasms', 'Cells', 'Characteristics', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Conventional Surgery', 'Data', 'Development', 'Devices', 'Diffusion', 'Discipline', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Evolution', 'Foundations', 'Goals', 'Health Care Research', 'Heterogeneity', 'Histopathology', 'Image', 'Imaging Device', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Information Retrieval', 'Infrastructure', 'Intervention', 'Interventional radiology', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Lung', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant neoplasm of prostate', 'Mass Spectrum Analysis', 'Medical', 'Medicine', 'Metabolic Marker', 'Metabolism', 'Metadata', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphology', 'Nanotechnology', 'Navigation System', 'Needles', 'Neoplasm Metastasis', 'Operating Rooms', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Pattern', 'Physiologic pulse', 'Procedures', 'Prostate', 'Radiation Oncology', 'Recurrence', 'Research', 'Resistance', 'Resolution', 'Retrieval', 'Risk Assessment', 'Sampling', 'Services', 'Signal Transduction', 'Source', 'Specimen', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Supervision', 'T2 weighted imaging', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Visualization', 'base', 'big-data science', 'biomedical resource', 'brain surgery', 'cancer care', 'cancer heterogeneity', 'cancer imaging', 'cancer therapy', 'data curation', 'data integration', 'deep learning', 'design', 'digital', 'image guided', 'image guided therapy', 'image registration', 'imaging modality', 'improved', 'in vivo', 'in vivo monitoring', 'innovation', 'ion mobility', 'learning strategy', 'machine learning algorithm', 'mass spectrometer', 'metabolic imaging', 'microdevice', 'neoplastic', 'new technology', 'novel', 'novel strategies', 'overtreatment', 'personalized cancer therapy', 'personalized medicine', 'precision medicine', 'prostate biopsy', 'protocol development', 'response', 'surgery outcome', 'technology research and development', 'tissue oxygenation', 'tool', 'trait', 'tumor', 'tumor heterogeneity', 'tumor hypoxia']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,2021,1527478,327644200
"SCH: Active Learning for Medical Applications Cancer is considered one of the most dilapidating health problems that the world is facing due to its physical, emotional, financial, and spiritual toll. Automating cancer diagnosis can ultimately impact its treatment and recovery. Computational algorithmic methods can greatly improve the efficiency of pathologists through partial or complete automation of the diagnostic process. Computer-aided diagnosis has augmented preventive check-ups for many medical conditions like breast cancer, colonic polyps, and lung cancer. Digitization of tissue slides has thus opened up the process of diagnosis through analysis of digital images. The dearth of highly trained pathologists who can address the growing diagnostic needs heightens the importance of such automation. Recent advances in big data analytics and in particular machine learning can possibly impact greatly the domain of computer-aided cancer diagnosis. Convolutional Neural Networks (CNNs) in particular have already revolutionized the domain of computer vision with performances in various cases compared to that exhibited by humans. One of the main factors that fueled the recent resurgence of CNNs is the availability of large datasets. CNNs adjust, via training, millions of parameters allowing them to learn complex and highly nonlinear dependencies among data (i.e., images). However, collecting such large amounts of annotated data (assigning them to one of many possible categories, e.g., benign vs. cancerous vs. other stages) is either challenging or very expensive or in many cases unavailable. This is definitely the case of the medical domain. Tissue slides from suspected cancerous regions are examined under a microscope and are classified as benign or malignant. CNNs offer a promising pathway to achieve some degree of automation in identifying cancerous cases in image data. This research work will explore the challenges· of discovering the underlying discriminative features, hidden in the image and possibly different than those used by human experts, in order to improve the accuracy of diagnosis. We will also focus on algorithms to minimize the amount of data required to train the neural network without sacrificing performance and generalization. Cancer has been a major health concern and one of the leading causes of death in the US and around the world. Automating cancer diagnosis can impact cancer staging and ultimately its treatment, effectively leading to higher survival rates. This proposal' promises the creation of computational algorithmic methods that can lead to partial or complete automation of the cancer diagnostic process.",SCH: Active Learning for Medical Applications,10086856,"['Active Learning', 'Address', 'Algorithms', 'Attention', 'Automation', 'Benchmarking', 'Benign', 'Big Data Methods', 'Breast', 'Cancer Diagnostics', 'Cancerous', 'Categories', 'Cause of Death', 'Clinics and Hospitals', 'Collaborations', 'Colonic Polyps', 'Communities', 'Complex', 'Computational algorithm', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Data', 'Data Discovery', 'Data Set', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'Early Diagnosis', 'Educational Curriculum', 'Educational workshop', 'Emotional', 'Engineering', 'Exhibits', 'Health', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Information Retrieval', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical', 'Medical Imaging', 'Medical center', 'Methodology', 'Methods', 'Microscope', 'Middle School Student', 'Modality', 'Pathologist', 'Pathway interactions', 'Pattern', 'Performance', 'Preventive', 'Process', 'Prostate', 'Recovery', 'Research', 'Research Personnel', 'Scheme', 'Science', 'Security', 'Slide', 'Survival Rate', 'System', 'Testing', 'Tissues', 'Training', 'Transportation', 'Underrepresented Populations', 'Variant', 'Visual Manifestations', 'Work', 'X-Ray Computed Tomography', 'algorithmic methodologies', 'cancer diagnosis', 'cancer type', 'cohesion', 'convolutional neural network', 'data exploration', 'diagnostic accuracy', 'digital imaging', 'hands-on learning', 'histological slides', 'image processing', 'improved', 'interest', 'kidney imaging', 'large datasets', 'learning community', 'learning strategy', 'machine learning method', 'malignant breast neoplasm', 'neural network', 'object recognition', 'online repository', 'outreach', 'outreach program', 'phenomenological models', 'programs', 'repository', 'self-directed learning', 'stem', 'tool', 'user-friendly', 'web page', 'wiki']",NCI,UNIVERSITY OF MINNESOTA,2021,309176,340417756
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,2021,318876,338121506
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,10063532,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,2021,360227,169622494
"A Quantitative Risk Model for Predicting Outcome and Identifying Structural Biomarkers of Treatment Targets in Oral Cancer on a Large Multi-Center Patient Cohort Post-resection prognostication for oral cavity cancers (OCC) is qualitative and potentially ambiguous. A significant subset (25-37%) of Stage I/II patients still develop local recurrence after treatment with surgery alone. The long-term goal of this proposal will be to create a Quantitative Risk Model (QRM) using machine learning and artificial intelligence to predict recurrence risk for Stage I/II patients using image-based biomarkers of aggression. The objective is to develop and validate state-of-the-art systems for biomarker imaging, quantification, and modeling to accurately predict risk of recurrence in cancer patients based on image analytics. The central hypothesis is that a quantitative, artificial intelligence approach to pathology will result in significantly greater prognostic value compared with manual microscope-based analysis. The rationale for this work is that tumor aggression can be predicted from patterns present in pathology images, given the existence of histological risk models that have been clinically validated in the past; however, these risk models are not in widespread use because they are less accurate, robust, and transportable to the larger community of pathologists. This proposal will test the central hypothesis through three specific aims: (1) Develop an analysis pipeline that can accurately predict recurrence risk for Stage I/II OCC patients and identify treatment targets (e.g. adaptive local immune response and angiogenesis); (2) Demonstrate robust performance across a multi-site data cohort collected from seven national and international centers; and (3) Distil the results of QRM analysis to synoptic pathology reporting, demonstrating the ability of QRM to interface with standard clinical reporting tools. The innovation for addressing these aims comes from a unique application of active learning for training artificial intelligence to recognize tissue structures, new features for quantifying tissue architecture based on the interface between tumor and host, and a novel approach for large cross-site validation. Moreover, this proposal develops a unique mapping between computational pathology and commonly-used synoptic reporting variables, enabling rapid uptake of this work into existing clinical workflows. This research is significant because it provides personalized outcome predictions for a niche group of undertreated patients with limited options and can serve as the foundation for designing future clinical trials through identification of treatment targets. Multi-site training and evaluation, combined with AI-to-report mapping, will be broadly applicable to a large group of computational approaches, bridging the gap between engineering research labs and clinical application. The expected outcome of this work is a trained model for predicting Stage I/II OCC recurrence, identification of treatment targets, and mapping to synoptic reports, as well as a broadly-applicable workflow for the broader computational pathology community. This project will have a large positive impact on patients and surgical pathologists by enabling rapid, accurate prognosis and directed treatment plans in an easy-to-use pipeline that integrates seamlessly into existing clinical workflows. We aim to develop a quantitative risk model for oral cavity cancer patients, 25-37% of whom will experience debilitating post-treatment recurrence. Using state-of-the-art machine learning and artificial intelligence methods, we will develop and validate our risk model on a large multi-site cohort of patients, and develop an AI-assisted synoptic report-filling tool for integrating into clinical practice. A computational pathology approach to characterizing disease will help identify patients for whom aggressive multimodality therapy will improve outcomes and post-treatment quality of life.",A Quantitative Risk Model for Predicting Outcome and Identifying Structural Biomarkers of Treatment Targets in Oral Cancer on a Large Multi-Center Patient Cohort,10149283,"['Active Learning', 'Address', 'Aftercare', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'Biological Markers', 'Blinded', 'Cancer Patient', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Collection', 'Combined Modality Therapy', 'Communities', 'Companions', 'Consensus', 'Country', 'Data', 'Databases', 'Disease', 'Elements', 'Engineering', 'Evaluation', 'Excision', 'Foundations', 'Future', 'Goals', 'Head and Neck Surgery', 'Head and neck structure', 'Histologic', 'Image', 'Immune response', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical Economics', 'Methods', 'Microscope', 'Modeling', 'Operative Surgical Procedures', 'Oral Stage', 'Outcome', 'Pathologist', 'Pathology', 'Pathology Report', 'Patients', 'Pattern', 'Performance', 'Play', 'Postoperative Period', 'Productivity', 'Quality of life', 'Radiation therapy', 'Randomized', 'Recurrence', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Risk', 'Salvage Therapy', 'Screening procedure', 'Semantics', 'Site', 'Slide', 'Specimen', 'Standardization', 'Structure', 'Surgical Pathology', 'System', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Work', 'Workload', 'analysis pipeline', 'angiogenesis', 'base', 'cancer recurrence', 'cancer type', 'clinical application', 'clinical practice', 'cohort', 'computational pipelines', 'deep learning', 'design', 'digital', 'digital pathology', 'expectation', 'experience', 'experimental study', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'improved outcome', 'innovation', 'international center', 'malignant mouth neoplasm', 'novel strategies', 'outcome forecast', 'outcome prediction', 'pathology imaging', 'patient oriented', 'predictive modeling', 'pressure', 'prognostic', 'prognostic value', 'quality assurance', 'quantitative imaging', 'screening', 'segmentation algorithm', 'tool', 'treatment planning', 'tumor', 'uptake']",NIDCR,STATE UNIVERSITY OF NEW YORK AT BUFFALO,2021,380042,73424103
"Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK) PROJECT SUMMARY  Contemporary ocular surgeries are performed by skilled surgeons through operating microscopes, utilizing freehand techniques and manually operated precision micro-instruments, where the outcomes are often limited by the surgeon's skill levels and experiences. To overcome these human factors, we have assembled an interdisciplinary team including a clinician-scientist and eye surgeon, an optical device scientist and medical robotic engineers to translate existing and developing technologies in our laboratories into precision, “deep- learning” artificial intelligence (AI) guided robotic ocular surgical devices for precise automated Deep Anterior Lamellar Keratoplasty (AUTO-DALK).  DALK is a highly attractive treatment of corneal disease with normally functioning endothelium. However, the procedure is unusually challenging from a technical perspective and time-consuming, limiting its acceptance among corneal surgeons. The most challenging aspect of the procedure is related to the delamination of stroma from Descemet's membrane (DM). A procedure, commonly called “Big Bubble” is used to separate stroma from DM using deep intrastromal pneumatic injection. However, even experienced surgeons have difficulty precisely placing the injection. The most common complication of DALK is the excessive depth of the needle insertion resulting in Descemet's membrane perforation requiring conversion to full-thickness penetrating keratoplasty with its much longer recovery period and a higher risk of graft failure from rejection. The reported rates of Descemet's membrane perforation for beginner and experienced surgeons are 31.8% and 11.7% respectively. In addition, interface haze between the donor and recipient cornea is a common problem caused by the insufficient depth of needle insertion and failure to remove the host stromal tissue, which results in loss of postoperative visual acuity. These problems relate directly to the inability of the current surgical practice to precisely assess the depth of the tooltips inside the cornea layer in real-time.  Here we will build upon our previous and ongoing work in robust fiber optic common-path optical coherence tomography (CP-OCT) and AI-guide system based on convolutional neural network (CNN) robotic microsurgical tools that enable clinicians to precisely guide surgical tools at micron scale. The proposed AUTO- DALK surgical tool system is capable of one-dimensional real-time depth tracking, motion compensation, and detection of early instrument contact with tissue, which enables clinicians to perform DALK precisely and safely. The tool will be built on a handheld platform that will consist of CP-OCT probe, trephine and microinjector that allows precise and safe removal of the anterior section of cornea down to DM  We hypothesize that AI-OCT providing intelligent visualization and depth controlled optimal cornea cutting and tissue tracking will perform the task of DALK with better accuracy and efficiency over the manually performed trephine cutting and “Big Bubble” pneumodissection. Project Narrative  This proposal addresses fundamental limitations in current corneal transplant surgery by developing an artificial intelligence guided compact robotic surgical tool that could empower corneal surgeons to achieve difficult surgical objectives, reduce intraoperative complications, and improve clinical outcomes when performing Deep Anterior Lamellar Keratoplasty (DALK). Further, these capabilities are broadly applicable in other microsurgical problems, and the tools will enable further advances both for ophthalmology and for other microsurgical disciplines.",Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK),10100636,"['Accounting', 'Address', 'Adrenal Cortex Hormones', 'Animal Model', 'Anterior', 'Artificial Intelligence', 'Blindness', 'Blunt Trauma', 'Burr hole procedure', 'Cadaver', 'Clinical', 'Complication', 'Consumption', 'Cornea', 'Corneal Diseases', 'Corneal Opacity', 'Corneal dystrophy', 'Data', 'Descemet&apos', 's membrane', 'Devices', 'Dimensions', 'Discipline', 'Distal', 'Drops', 'Early Diagnosis', 'Endophthalmitis', 'Endothelial Cells', 'Endothelium', 'Engineering', 'Ensure', 'Epithelial', 'Excision', 'Expert Systems', 'Eye', 'Eye Surgeon', 'Failure', 'Fiber Optics', 'Financial compensation', 'Geometry', 'Glaucoma', 'Goals', 'Graft Survival', 'Hemorrhage', 'Human', 'Image', 'Immune', 'Incidence', 'Infection', 'Injections', 'Intelligence', 'Intraoperative Complications', 'Iris', 'Keratoconus', 'Keratoplasty', 'Laboratories', 'Lamellar Keratoplasty', 'Lead', 'Manuals', 'Mechanics', 'Medical', 'Microscope', 'Modeling', 'Motion', 'Movement', 'Needles', 'Ocular Hypertension', 'Operative Surgical Procedures', 'Ophthalmology', 'Optical Coherence Tomography', 'Optics', 'Oryctolagus cuniculus', 'Outcome', 'Pathological Dilatation', 'Patients', 'Penetrating Keratoplasty', 'Perforation', 'Performance', 'Postoperative Complications', 'Postoperative Period', 'Procedures', 'Ptosis', 'Recovery', 'Repeat Surgery', 'Reporting', 'Research Personnel', 'Risk', 'Robotics', 'Rupture', 'Safety', 'Scientist', 'Secondary to', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Systems Development', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Topical Corticosteroids', 'Translating', 'Transplantation Surgery', 'Trauma', 'Validation', 'Visual', 'Visual Acuity', 'Visualization', 'Work', 'base', 'convolutional neural network', 'corneal scar', 'curative treatments', 'deep learning', 'design', 'experience', 'graft failure', 'high risk', 'iatrogenic injury', 'improved', 'in vivo', 'instrument', 'interest', 'novel', 'phantom model', 'photonics', 'preservation', 'prototype', 'sensor', 'skills', 'surgery outcome', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,2021,409997,807432003
"A Machine Learning Approach to Classifying Time Since Stroke using Medical Imaging PROJECT SUMMARY/ABSTRACT Stroke is a leading cause of mortality and morbidity in the United States, with approximately 795,000 Americans experiencing a new or recurrent stroke each year. Intravenous tissue plasminogen activator (IV tPA) is the dominant and most proven treatment option, but its use is only indicated within 4.5 hours following a stroke. Unfortunately, up to 30% of stroke patients present with an unknown time since stroke (TSS) symptom onset, which makes them ineligible to receive IV tPA. Many of these individuals could be spared severe morbidity or mortality if there existed an alternative method for establishing TSS, allowing them to be identified and treated. This proposal will develop machine learning methods to create a physiologically grounded method for predicting TSS based on multiparametric magnetic resonance (MR) and computed tomography (CT) imaging data. We believe our proposed techniques will outperform state-of-the-art methods that are based on subjective image interpretation, and have the potential to provide an objective data point that may be used in conjunction with the subjective assessments of experts, or in clinical environments that lack expertise in stroke imaging Research has established that MR and CT imaging captures information that correlates with TSS. However, existing methods for extracting this information are based on a physician subjectively interpreting the images and delineating regions of interest, processes that have been documented to have only weak to moderate agreement across trained expert reviewers. An automated approach that comprehensively analyzes the spectrum of imaging data could identify complex relationships across channels that more accurately classify TSS. For example, in MR, diffusion-weighted, perfusion-weighted, and fluid attenuated inversion recovery imaging all play important roles in characterizing a stroke, but a deep understanding of how each channel may be combined to describe TSS is unknown. We propose to establish new deep learning methods for fusing this information. Specifically, we will: 1) develop a machine learning framework for classifying TSS; 2) develop a deep convolutional autoencoder to generate novel multimodal image representations from MR and CT to improve classification; and 3) implement visualization techniques that elucidate the relationship between deep features and pathophysiological stroke processes. Under this project, we will use data from the UCLA and UCI Stroke Centers, allowing us to study different patient populations and imaging techniques. The successful completion of this research will provide a new method for estimating TSS from imaging, leading to new prospective trials for providing therapy to patients with unknown TSS. PROJECT NARRATIVE Stroke is a leading cause of death in the United States, with approximately 795,000 Americans experiencing a new or recurrent stroke each year; however patients who present with an unknown stroke onset time are ineli- gible for receiving the leading therapy. The focus of this research is to develop a novel method for classifying stroke onset time from imaging, enabling treatment for a new cohort of patients and potentially saving them from severe morbidity or mortality.",A Machine Learning Approach to Classifying Time Since Stroke using Medical Imaging,10109154,"['Adverse event', 'Affect', 'Agreement', 'Algorithms', 'Alteplase', 'American', 'Area', 'Attenuated', 'Blood flow', 'Brain', 'California', 'Cause of Death', 'Characteristics', 'Classification', 'Clinical', 'Collaborations', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Decision Making', 'Diffusion Magnetic Resonance Imaging', 'Eligibility Determination', 'Engineering', 'Environment', 'Foundations', 'Functional disorder', 'Goals', 'Guidelines', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Infarction', 'Intravenous', 'Learning', 'Liquid substance', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Maps', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Multimodal Imaging', 'Neurologist', 'Patient imaging', 'Patients', 'Perfusion', 'Phenotype', 'Physicians', 'Physiological', 'Play', 'Process', 'Publishing', 'Recovery', 'Recurrence', 'Reperfusion Therapy', 'Research', 'Risk', 'Role', 'Savings', 'Secondary to', 'Shapes', 'Signal Transduction', 'Spectrum Analysis', 'Stroke', 'Techniques', 'Thrombolytic Therapy', 'Time', 'Tissues', 'Training', 'United States', 'Universities', 'Visualization', 'Visualization software', 'Work', 'X-Ray Computed Tomography', 'acute stroke', 'artery occlusion', 'autoencoder', 'base', 'clinical imaging', 'cohort', 'deep learning', 'diffusion weighted', 'experience', 'improved', 'interest', 'learning strategy', 'machine learning method', 'mortality', 'multimodality', 'novel', 'outcome prediction', 'patient population', 'perfusion imaging', 'prevent', 'prospective', 'radiologist', 'spatiotemporal', 'spectrograph', 'stroke patient', 'stroke symptom', 'tool']",NINDS,UNIVERSITY OF CALIFORNIA LOS ANGELES,2021,429902,673201228
"Nonlinear performance analysis and prediction for robust low dose lung CT 1 PROJECT SUMMARY / ABSTRACT  2 Nonlinear algorithms such as model-based reconstruction (MBR) and deep learning (DL) reconstruction have  3 sparked tremendous research interest in recent years. Compared to traditional linear approaches, the nonline-  4 arity of these algorithm transcends traditional signal-to-noise requirement and offer flexibility to draw information  5 from a variety of sources (e.g., statistical model, prior image, dictionary, training data). MBR has enabled numer-  6 ous advancements including low-dose CT and advanced scanning protocols. Deep learning algorithms are rap-  7 idly emerging and have demonstrated superior dose vs. image quality tradeoffs in research settings. However,  8 widespread clinical adoption of nonlinear algorithms has been impeded by the lack of a lack of systematic, quan-  9 titative methods for performance analysis. Nonlinear methods come with numerous dependencies on the imag- 10 ing techniques, the imaging target, and the prior information, and the data itself. The relationship between these 11 dependencies and image quality is often opaque. Furthermore, improper selection of algorithmic parameters can 12 lead to erroneous features (e.g., smaller lesions, texture) in the reconstruction. Therefore, methods to quantify 13 and predict performance permit efficient and quantifiable performance evaluation to provide the robust control 14 and understanding of imaging output necessary for reliable clinical application and regulatory oversight. 15 We propose to establish a robust, predictive framework for performance assessment and optimization that can 16 be generalized to any reconstruction method. We quantify performance in turns of the perturbation response and 17 covariance as a function of imaging techniques, system configurations, patient anatomy, and, importantly, the 18 perturbation itself. The perturbation response quantifies the appearance (e.g., biases, blurs, distortions), and, 19 together with the covariance, allows the computation of more complex metrics such as task-based performance 20 and radiomic measures including size, shape, and texture information. We illustrate utility of the approach in lung 21 imaging with the following specific aims: Aim 1: Develop a lesion library and generate perturbations encom- 22 passing clinically relevant features. We will extract lesions from public databases and develop methods lesion 23 emulation in for realistic CT simulation and physical data via 3D printing technology. Aim 2: Develop a gener- 24 alized prediction framework for perturbation response and covariance. Using analytical and neural network 25 modeling, we will establish a framework that predicts perturbation response and covariance across imaging 26 scenarios for classes of algorithms with increasing data-dependence including MBR with a Huber penalty, MBR 27 with dictionary regularization, and a deep learning reconstructor. Aim 3: Develop assessment and optimiza- 28 tion strategies to drive robust, low dose lung screening CT methods. We will optimize and adapt nonlinear 29 algorithms and protocols for lung cancer screening to achieve faithful representations of clinical features. This 30 work has the potential to drive much-needed quantitative assessment standards that directly relate image quality 31 to diagnostic performance and optimal strategies for robust, reliable clinical deployment of nonlinear algorithms. 32 PROJECT NARRATIVE Major research efforts have been devoted to the development of nonlinear reconstruction algorithms – from model-based reconstruction to deep learning, these algorithms have demonstrated many advantages such as improved image quality, reduced radiation dose, and additional diagnostic information that are not achievable with traditional linear reconstructions. However, only a disproportionately small number has reach the clinic due to the lack of a predictive image quality analysis framework to quantify diagnostic performance, control algorithm behavior, and ensure consistent performance for robust clinical deployment. The propose effort use a combination of analytic and machine learning approaches to drive much-needed quantitative assessment standards that directly relate image quality to diagnostic performance and establish optimal strategies for robust, reliable clinical deployment of nonlinear algorithms.",Nonlinear performance analysis and prediction for robust low dose lung CT,10121056,"['3D Print', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Appearance', 'Beauty', 'Behavior', 'Biological Models', 'Clinic', 'Clinical', 'Complex', 'Data', 'Databases', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Dictionary', 'Digital Libraries', 'Dimensions', 'Dose', 'Ensure', 'Evaluation', 'Genes', 'Image', 'Image Analysis', 'Imaging Techniques', 'Lead', 'Lesion', 'Libraries', 'Lung', 'Lung CAT Scan', 'Lung nodule', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Nodule', 'Noise', 'Non-linear Models', 'Outcome', 'Output', 'Patients', 'Performance', 'Play', 'Predictive Analytics', 'Property', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Role', 'Sampling', 'Scanning', 'Scheme', 'Shapes', 'Signal Transduction', 'Source', 'Statistical Models', 'System', 'Techniques', 'Technology', 'Texture', 'Training', 'Transcend', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinical translation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'exhaustion', 'flexibility', 'imaging system', 'improved', 'insight', 'interest', 'low dose computed tomography', 'lung cancer screening', 'machine learning method', 'neural network', 'novel', 'predicting response', 'quantitative imaging', 'radiomics', 'reconstruction', 'response', 'screening', 'shape analysis', 'simulation', 'success', 'targeted imaging']",NCI,JOHNS HOPKINS UNIVERSITY,2021,512567,807432003
"Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues Summary Fast, accurate, and scalable testing has been recognized unanimously as crucial for mitigating the impact of COVID-19 and future pandemics. We propose a technology that allows rapid (~2 minutes) testing for SARS CoV-2. Our technology combines novel label-free imaging and dedicated deep-learning algorithms to detect and classify viral populations in exhaled air. If successful, this project will result in a device based on quantitative phase imaging and integrated AI tools, which will detect the unlabeled virus acquired by the patient’s breath condensed on a microscope slide. Toward this goal, we will advance Spatial Light Interference Microscopy (SLIM), an ultrasensitive label-free imaging technique, proven to measure structures down to the sub-nanometer scale. SLIM was developed in the PI’s Lab at UIUC, its original publication received 490 citations to date, and has been commercialized by Phi Optics (Research Park, UIUC), with sales across the world in both academia and industry. Applying the computed fluorescence maps back to the QPI data, we propose to measure nanoscale features of viral particles, with high specificity, minimal preparation time, and independent of clinical infrastructure. As a result, the new technology will eventually be ideal for point-of-care settings, surveillance screening and as a home monitoring device. We anticipate that our approach will be scalable to other viruses, with new imaging and training data. Narrative We propose a breath test using label-free imaging and AI: an individual exhales on a microscope slide, which is fed into a SLIM microscope equipped with a computer that runs deep-learning pre-trained algorithms for SARS CoV-2 identification. The result is displayed in real time, with the entire procedure requiring < 2min.",Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues,10249738,"['2019-nCoV', 'Academia', 'Air', 'Artificial Intelligence', 'Back', 'Bedside Testings', 'Biology', 'Breath Tests', 'COVID-19', 'COVID-19 testing', 'Cancer Prognosis', 'Chemicals', 'Classification', 'Clinical', 'Clinical Microbiology', 'Computer software', 'Computers', 'Data', 'Devices', 'Exhalation', 'Fluorescence', 'Fluorescence Microscopy', 'Future', 'Glass', 'Goals', 'Histopathology', 'Home environment', 'Image', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Industry', 'Influenza', 'Infrastructure', 'Interference Microscopy', 'Label', 'Light', 'Maps', 'Measures', 'Microscope', 'Modification', 'Morphologic artifacts', 'Nature', 'Optics', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Phototoxicity', 'Population', 'Preparation', 'Procedures', 'Publications', 'Research', 'Running', 'Sales', 'Slide', 'Specificity', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Tissue Stains', 'Training', 'Viral', 'Virus', 'Virus Diseases', 'algorithm training', 'base', 'clinical infrastructure', 'coronavirus disease', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'imaging system', 'instrument', 'monitoring device', 'nanoscale', 'new technology', 'novel', 'operation', 'pandemic disease', 'particle', 'point of care', 'prototype', 'screening', 'tool']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,2021,576268,76545728
"Application of Advanced Quantitative Methods to Schizophrenia Research PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found a decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Prefrontal white matter is among the areas usually involved. Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities, suggesting that abnormalities causing diminished FA are subtle, and that postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a FIC/NIMH collaboration with the Macedonian Academy of Sciences and Arts, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the spatial orientation of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high- resolution images of Bielschowsky stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This technique yields clear images of individual axons that can be traced and measured in 3 dimensions. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin- related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models in three multi-omics data fusion approaches to combine different types of high-dimensional data, including those produced by Aims 1 and 2, with known structural properties of axons and myelin in white matter, in order to build a model or detect novel dependencies of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. NARRATIVE Our ongoing research in North Macedonia and at Columbia University / New York State Psychiatric Institute has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale to study schizophrenia.",Application of Advanced Quantitative Methods to Schizophrenia Research,10099068,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Antibodies', 'Architecture', 'Area', 'Arts', 'Autopsy', 'Axon', 'Biochemical', 'Biochemistry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Clinical', 'Collaborations', 'Collection', 'Confocal Microscopy', 'Consensus', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Electron Microscope', 'Electron Microscopy', 'Electrons', 'Evaluation', 'Face', 'Fiber', 'Forensic Medicine', 'Genetic Transcription', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Individual', 'Institutes', 'Interviewer', 'Knowledge', 'Label', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofibrillary Tangles', 'Neurofilament Proteins', 'New York', 'Oligodendroglia', 'Online Systems', 'Optic Nerve', 'Paraffin', 'Pathologist', 'Pharmaceutical Preparations', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Psychiatrist', 'Psychologist', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Schizophrenia', 'Science', 'Shotguns', 'Silver Staining', 'Space Perception', 'Stains', 'Structure', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Toxicology', 'Training', 'Transcript', 'Triad Acrylic Resin', 'Universities', 'Variant', 'Visualization', 'base', 'cognitive function', 'cohort', 'data archive', 'data fusion', 'deep neural network', 'density', 'design', 'diffusion anisotropy', 'high resolution imaging', 'histological studies', 'imaging study', 'innovation', 'instrument', 'interest', 'microscopic imaging', 'multidimensional data', 'multiple omics', 'network models', 'novel', 'precursor cell', 'psychologic', 'reconstruction', 'sex', 'symposium', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,2021,641403,68331629
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,10143171,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,2021,655746,551214295
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,10136081,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'detection test', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",2021,821265,685608202
"Deep learning for renal tumor characterization Our long-term objective is to develop deep learning techniques capable of predicting characteristics and treatment response or response to surveillance to assist clinical decision- making in renal tumors that are potential candidates for ablation therapy, biopsy, active surveillance or surgical resection. An increasing number of renal tumors are being diagnosed, due in part to incidental detection from the increased use of cross-sectional imaging. Although partial nephrectomy is still considered the primary treatment for small renal masses, percutaneous ablation is increasingly performed as a therapeutic, nephron-sparing approach. One challenge for interventional radiologists and urologists who manage these patients is selection for therapy, since the average rate of progression is slow for small renal tumors and metastasis rarely occurs. A technique that could distinguish indolent tumors from those will progress based on data from the imaging methods used to detect and delineate renal masses would enable early triage to observation versus invasive treatment. Deep learning, a type of machine learning technique which takes raw images as input, and applies many layers of transformations to calculate an output signal, has already led to breakthroughs in other areas of image recognition, and is increasingly used for medical image analysis. However, its application in the field of interventional radiology is currently limited. Furthermore, no study in the literature has applied deep learning to kidney lesion segmentation and characteristics/outcome prediction. In this project, we propose to develop novel deep learning architectures based on routine MR imaging that allow for accurate renal mass segmentation and prediction of characteristics and outcome in renal tumors. Using data from four independent cohorts, we will use our deep learning architectures to predict (1) benign versus malignant histology (2) growth rate in stage 1a renal cell carcinoma (3) SSIGN score in clear cell renal cell carcinoma and (4) clinical endpoints. We will integrate segmentation and classification into one net that suitable for clinical application. In addition, we will compare results with those of experts and traditional machine learning approaches. The inability to determine aggressiveness of renal tumors based on pretreatment imaging makes it challenging for urologists or interventional radiologists to select appropriate patients for active surveillance versus therapy with nephrectomy or ablation. Our research project uses deep learning to distinguish renal mass from normal tissue and predict characteristics, treatment response or response to surveillance in renal tumors. By using a multi-institutional patient cohort and conventional MR imaging sequences, we will demonstrate the generalizability and broad applicability of our algorithm. Our models have the potential to help guide clinical management of patients with renal tumors.",Deep learning for renal tumor characterization,10116348,"['3-Dimensional', 'Ablation', 'Algorithms', 'Architecture', 'Area', 'Benign', 'Biopsy', 'Characteristics', 'Classification', 'Clear cell renal cell carcinoma', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Dropout', 'Ensure', 'Excision', 'Future', 'Growth', 'Histology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Intervention', 'Interventional radiology', 'Kidney', 'Kidney Neoplasms', 'Learning', 'Lesion', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Medical Imaging', 'Metastatic Neoplasm to the Kidney', 'Modeling', 'Nephrectomy', 'Nephrons', 'Neural Network Simulation', 'Normal tissue morphology', 'Oncology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient imaging', 'Patients', 'Performance', 'Process', 'Renal Cell Carcinoma', 'Renal Mass', 'Research Project Grants', 'Selection for Treatments', 'Signal Transduction', 'Techniques', 'Therapeutic', 'Training', 'Triage', 'Update', 'Urologist', 'Weight', 'base', 'cancer imaging', 'clinical application', 'clinical decision-making', 'cohort', 'deep learning', 'deep neural network', 'design', 'imaging modality', 'improved', 'interest', 'learning network', 'novel', 'outcome prediction', 'predictive modeling', 'radiologist', 'radiomics', 'random forest', 'treatment response', 'tumor']",NCI,RHODE ISLAND HOSPITAL,2021,80500,37921345
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",2021,242250,685608202
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,10145719,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'in silico', 'indexing', 'learning strategy', 'machine learning method', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,2021,378183,63611576
"A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration PROJECT SUMMARY Age-related macular degeneration (AMD), in the dry or wet form, is the leading cause of vision loss in the developed countries. The Age-Related Eye Disease Study (AREDS) showed that specific antioxidant vitamin supplementation reduces the risk of progression from intermediate stages to late AMD and maintains visual acuity in approximately 25% of patients. While treatment of wet AMD with Intraocular injections can be effective in maintaining vision, such treatments are costly and may be associated with significant cardiovascular risks, or even progression of dry AMD. Hence, it is critical to identify patients at the earlier stages. Unfortunately, there is no effective, automated screening tool to accomplish this, and the patients themselves may be asymptomatic. The goal of this SBIR Direct-to-Phase II proposal is to provide such tool. We have demonstrated the feasibility of AMD screening software ‘iPredictTM’ by successfully identifying 98.1% of individuals with early or intermediate stage AMD. iPredictTM also successfully predicted which individuals would develop late AMD within one year with 87.8% accuracy and two years with 88.4% accuracy. iPredictTM has prototype components for image analysis and machine learning. We also developed a HIPAA compliant telemedicine platform which will enable iPredictTM to perform large-scale screening from remote and rural areas. In order to bring the product to market, these components need to be integrated and tested which is the aim of our proposed Direct-to-Phase II proposal. We aim to develop the finished product which will be ready for the market. We also aim to evaluate the efficacy of iPredictTM in a clinical setup. The AMD preventative market is estimated around $5.4 billion in the U.S. alone. iPredictTM will capture the major market share with its best accuracy and be the first prediction tool for AMD. We aim to commercialize iPredictTM for the screening and prevention of AMD, saving millions of citizens from blindness and reduced quality of life. With iPredictTM’s improvements in speed of delivery, cost of care, and ease of access, the product will be a significant addition to the healthcare system. The iPredictTM’s telemedicine platform will allow large-scale screening from remote/rural areas, primary care clinics, optometry offices and ophthalmology clinics. PROJECT NARRATIVE Age-related macular degeneration (AMD) in its late forms, “dry” or “wet”, is the leading cause of blindness in developed countries. Early intervention and therapy can significantly reduce the progression of early to late AMD. Hence, the identification of patients with early AMD and referral to an ophthalmologist is critically needed to help prevent vision loss. To achieve this goal, we propose to develop an automated screening and prediction system that can be widely deployed to identify these individuals at risk of vision loss.",A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration,10320271,"['Affect', 'Age', 'Age related macular degeneration', 'American', 'Antioxidants', 'Blindness', 'Categories', 'Clinic', 'Clinical', 'Clinics and Hospitals', 'Code', 'Color', 'Computer software', 'Counseling', 'Data', 'Data Set', 'Databases', 'Developed Countries', 'Devices', 'Diagnosis', 'Drusen', 'Ear', 'Early Intervention', 'Evaluation', 'Eye', 'Eye diseases', 'Feasibility Studies', 'Fees', 'Goals', 'Health Insurance Portability and Accountability Act', 'Healthcare Systems', 'Image', 'Image Analysis', 'Incentives', 'Individual', 'Injections', 'Intervention', 'Java', 'Lasers', 'Learning Module', 'Machine Learning', 'Manuals', 'Methods', 'Minerals', 'Modeling', 'New York', 'Nonexudative age-related macular degeneration', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patients', 'Phase', 'Prevention', 'Prevention strategy', 'Primary Health Care', 'Provider', 'Pythons', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Sales', 'Savings', 'Screening procedure', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Smoking', 'Specialist', 'Speed', 'Sun Exposure', 'Supplementation', 'System', 'Telemedicine', 'Testing', 'Therapeutic Intervention', 'Time', 'Trademark', 'Treatment Cost', 'Validation', 'Vision', 'Visit', 'Visual Acuity', 'Vitamins', 'age related', 'base', 'biobank', 'cardiovascular risk factor', 'care costs', 'checkup examination', 'commercial application', 'convolutional neural network', 'cost', 'deep learning', 'follow-up', 'improved', 'photobiomodulation', 'prediction algorithm', 'predictive modeling', 'prevent', 'prognostic', 'programs', 'prospective', 'prototype', 'remote screening', 'research clinical testing', 'retinal imaging', 'rural area', 'screening', 'sociodemographic factors', 'software as a service', 'success', 'tool', 'user-friendly']",NEI,"IHEALTHSCREEN, INC.",2021,45000,585067
